#!/usr/bin/env python 
#
"""
This set of libraries, analysisUtils.py, is a collection of often useful
python and/or CASA related functions.  It is an open package for anyone
on the science team to add to and generalize (and commit).  A few
practices will allow us to keep this useful.

1) Write the routines as generally as you can.

2) Before fundamentally changing the default behavior of a function
or class, consider your coworkers.  Do not modify the default behavior
without extreme need and warning.  If you need to modify it quickly,
consider a separate version until the versions can be blended (but please
do try to do the blending!).

3) There is a comment structure within the routines.  Please keep this
for additions because the documentation is automatically generated from
these comments.
 
All examples assume you have imported the library to aU, as import
analysisUtils as aU. You can of course do whatever you like, but the
examples will thus have to be modified.

Thanks and good luck!  If you have any questions, bother Barkats or
Corder, then Robert.
 
S. Corder, 2010-11-07
"""

import os
import shutil
import distutils.spawn # used in class linfit to determine if dvipng is present
import sys
import re
from types import NoneType
import telnetlib
import math
import numpy as np
import binascii # used for debugging planet()
# from mpfit import mpfit
from pylab import *
import pylab as pb
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from numpy.fft import fft
import fnmatch, pickle, traceback, copy as python_copy
import scipy as sp
from scipy.ndimage.filters import gaussian_filter
import scipy.signal as spsig
from scipy.interpolate import splev, splrep
#    if (np.__version__ < '1.9'):
#        import scipy.signal as spsig
#        from scipy.interpolate import splev, splrep
#    elif (os.getenv('HOSTTYPE') != None):
#        if (os.getenv('HOSTTYPE').find('mac')>=0):
#            import scipy.signal as spsig
#            from scipy.interpolate import splev, splrep

import scipy.special # for Bessel functions
import scipy.odr # for class linfit
import string
import struct # needed for pngWidthHeight
import glob
import pprint
# import readscans as rs
import time as timeUtilities
import datetime
import copy
#from . import tmUtils as tmu
# import compUtils  # used in class SQLD
import pytz  # used in computeUTForElevation
from scipy.special import erf, erfc  # used in class Atmcal
from scipy import ndimage
from scipy import polyfit
from scipy import optimize # used by class linfit
import random  # used by class linfit
import matplotlib.ticker # used by plotWeather
from matplotlib import rc # used by class linfit
from matplotlib.figure import SubplotParams
from matplotlib.ticker import MultipleLocator # used by plotPointingResults
import commands  # useful for capturing stdout from a system call
import warnings
import csv # used by getALMAFluxcsv and editIntentscsv
import StringIO # needed for getALMAFluxcsv
# import O2SounderPlayer
import fileinput  # used by updateSBSummaryASDM
mypath = os.path.dirname(__file__).replace('analysis_scripts',
                                           'scripts/R10.4_WORKING')
sys.path.append(mypath)
import collections # used by convertSMAAntennaPositionsToPads
try:
    if True:
        asdmPath = '/opt/software/acs/ACS-current/ACSSW/intlist/PIPELINE_INTROOT/lib/python/site-packages'
        if (os.path.exists(asdmPath)):
            print "Appended path ", asdmPath
            sys.path.append(asdmPath)
        else:
            asdmPath = '/alma/ACS-2016.5/ACSSW/lib/python/site-packages'
            if (os.path.exists(asdmPath)):
#                    print "Appended path ", asdmPath
                sys.path.append(asdmPath)
    from asdm import ASDM, ASDMParseOptions
    asdmLibraryAvailable = True
except:
    import au_noASDMLibrary
    asdmLibraryAvailable = False
try:
    import AntPosResult as APR
    APRAvailable = True
except:
    APRAvailable = False
try:
    # Try to import TelCal libraries
    import CompareAntPosResults as CAPR
    CAPRAvailable = True
except:
    CAPRAvailable = False
#
# Beginning of casa stuff.
# Set to False if you want to import analysisUtils outside of casa.
#
casaAvailable = False
if (os.getenv('CASAPATH') is not None):
  try:
    from taskinit import *
    import casadef
    # import plotbandpass3 as plotbp3
    import simutil # needed for obslist, getPadLOCsFromASDM; it has useful pad transforming functions
    # This arrangement allows you to call casa commands by name: - T. Hunter
    from listobs_cli import listobs_cli as listobs
    from gencal_cli import gencal_cli as gencal
    from imview_cli import imview_cli as imview
    from plotms_cli import plotms_cli as plotms
    from imstat_cli import imstat_cli as imstat
    from imsmooth_cli import imsmooth_cli as imsmooth
    from flagmanager_cli import flagmanager_cli as flagmanager
    from flagdata_cli import flagdata_cli as flagdata
    from flagcmd_cli import flagcmd_cli as flagcmd
    from vishead_cli import vishead_cli as vishead
    try:
        from imsubimage_cli import imsubimage_cli as imsubimage
        useImsubimage = True
    except:
        useImsubimage = False
    from imfit_cli import imfit_cli as imfit
    from imhead_cli import imhead_cli as imhead
    from gaincal_cli import gaincal_cli as gaincal
    from clean_cli import clean_cli as clean
    from tclean_cli import tclean_cli as tclean
    import cleanhelper
    try:
        from plotuv_cli import plotuv_cli as plotuv
    except:
        # casa <= 3.2
        pass
    from immath_cli import immath_cli as immath # used by complexToSquare()
    from imregrid_cli import imregrid_cli as imregrid # used by complexToSquare()
    from exportfits_cli import exportfits_cli as exportfits # used by makeSimulatedImage()
    from importfits_cli import importfits_cli as importfits # used by addGaussianToFITSImage()
    from visstat_cli import visstat_cli as visstat # used by scaleModel()
    try:
        from wvrgcal_cli import wvrgcal_cli as wvrgcal # used by wvrgcalStats()
        useWvrgcal = True
    except:
        useWvrgcal = False
    if casadef.casa_version >= '5.0.0':
        import casa as mycasa
        if 'cutool' in dir(mycasa):
            cu = mycasa.cutool()
            casaVersion = '.'.join([str(i) for i in cu.version()[:-1]]) + '-' + str(cu.version()[-1])
        else:
            casaVersion = mycasa.casa['build']['version'].split()[0]
    else:
        casaVersion = casadef.casa_version
    predictCompBodies = ['CALLISTO','CERES','EUROPA','GANYMEDE','IO',
                         'JUNO','JUPITER','MARS','NEPTUNE','PALLAS','TITAN',
                         'URANUS','VENUS','VESTA']
    try:
        from predictcomp_cli import predictcomp_cli as predictcomp
        usePredictComp = True
    except:
        usePredictComp = False
        print "Could not import predictcomp"
    try:      # CASA 3.4
        from simobserve_cli import simobserve_cli as simobserve
        from simanalyze_cli import simanalyze_cli as simanalyze
    except:   # CASA 3.3
        try:
            from sim_observe_cli import sim_observe_cli as simobserve
            from sim_analyze_cli import sim_analyze_cli as simanalyze
        except:
            pass  # 3.2
    try:
        import solar_system_setjy as sss
        useSolarSystemSetjy = True
    except:
        useSolarSystemSetjy = False
    from importasdm import importasdm
    from plotcal import plotcal
    try:  # this is no longer in CASA as of 5.0
        from sdplot import sdplot
        sdplotAvailable = True
    except:
        sdplotAvailable = False
        # The following could be workaround for SDcheckSpectra if necessary
#            from sdplotold import sdplotold as sdplot
    from split import split
    from setjy import setjy
    try:
        from plotxy import plotxy
        mymp = mp  # Check if the msplot tool is available, as it is needed by plotxy
        plotxyAvailable = True
    except:
        plotxyAvailable = False
    from fixvis import fixvis
    from bandpass import bandpass
    import viewertool
    from clearstat import clearstat
    if (casadef.casa_version >= '4.0.0'):
        # When this changes, be sure to update the inline help for au.planet
        defaultEphemeris = 'Butler-JPL-Horizons 2012'
    else:
        defaultEphemeris = 'Butler-JPL-Horizons 2010'
    if (casadef.casa_version >= '3.3.0'):  # is not in 3.2, might be in 3.3
        from fixplanets import fixplanets
    # if (casadef.casa_version >= '4.5'):
    #     import checksource
    if (casadef.casa_version >= '4.6.0'):
        from imhistory_cli import imhistory_cli as imhistory
    if int(casadef.casa_version.split('.')[0]) < 5:
        from scipy.stats import nanmean as scipy_nanmean
        from scipy.stats import nanmedian as scipy_nanmedian
        from scipy.stats import nanstd as scipy_nanstd
    else:
        try:
            from scipy import nanmean as scipy_nanmean
            from scipy import nanmedian as scipy_nanmedian
            from scipy import nanstd as scipy_nanstd
        except:
            # Some 5.0 stables were not yet updated to new scipy
            from scipy.stats import nanmean as scipy_nanmean
            from scipy.stats import nanmedian as scipy_nanmedian
            from scipy.stats import nanstd as scipy_nanstd
    casaAvailable = True
    # end of casa stuff
  except:
    raise
    defaultEphemeris = 'Butler-JPL-Horizons 2012'
    if 'casadef' in locals():
        print "The import of casa items did not complete.  You may need to update the version of analysisUtils that you are using.\n See https://casaguides.nrao.edu/index.php/Analysis_Utilities"
        myversion = "$Id: analysisUtils.py,v 1.4003 2018/04/27 10:57:03 thunter Exp $"
        try:
            casaVersion = cu.version().tolist()
            casaVersion = '.'.join([str(i) for i in casaVersion[:-1]])
        except:
            casaVersion = casadef.casa_version
        print "au: %s, casa: %s" % (myversion.split()[2],casaVersion)
    else:
        print "You appear to be importing analysisUtils into python. version = ", '.'.join([str(i) for i in sys.version_info[:3]])
else:
    defaultEphemeris = 'Butler-JPL-Horizons 2012'

# import fileIOPython as fiop
from scipy.stats import scoreatpercentile, percentileofscore
import types
import operator
# import XmlObjectifier
from xml.dom import minidom
import subprocess
import urllib
import urllib2
import itertools
import socket            # used by searchFlux to set tunnel default
# import rootFinder  # functions for solving quadratic and cubic polynomial roots
try:
    import pyfits # needed for getFitsBeam
    pyfitsPresent = True
except:
    pyfitsPresent = False


"""
Constants that are sometimes useful.  Warning these are cgs, we might want to change them
to SI given the propensity in CASA to use SI.
"""
h=6.6260755e-27
k=1.380658e-16
c=2.99792458e10
c_mks=2.99792458e8
jy2SI=1.0e-26
jy2cgs=1.0e-23
pc2cgs=3.0857e18
au2cgs=1.4960e13
solmass2g=1.989e33
earthmass2g=5.974e27
radiusEarthMeters=6371000
solLum2cgs = 3.826e33
mH = 1.673534e-24
G  = 6.67259e-8
Tcmb = 2.725
TROPICAL = 1
MID_LATITUDE_WINTER = 2
MID_LATITUDE_SUMMER = 3
ALMA_LONGITUDE=-67.754748 # ICT-4143,  -67.754694=JPL-Horizons,  -67.754929=CASA observatories
ALMA_LATITUDE=-23.029211  # ICT-4143,  -23.029167=JPL-Horizons,  -23.022886=CASA observatories
ARCSEC_PER_RAD=206264.80624709636

JPL_HORIZONS_ID = {'ALMA': '-7',
                   'VLA': '-5',
                   'GBT': '-9',
                   'MAUNAKEA': '-80',
                   'OVRO': '-81',
                   'geocentric': '500'
}
# Please keep these objects in this order (mean orbital radius from sun)
majorPlanets = ['SUN','MERCURY','VENUS','MOON','MARS','JUPITER','SATURN','URANUS','NEPTUNE','PLUTO']

bandDefinitions = {
    1  : [31.3e9, 45e9  ],
    2  : [67e9  , 84e9  ], # upper end is actually 90, but we do not have logic to choose between 2 and 3
    3  : [84e9  , 116e9 ],
    4  : [125e9 , 163e9 ],
    5  : [163e9 , 211e9 ],
    6  : [211e9 , 275e9 ],
    7  : [275e9 , 373e9 ],
    8  : [385e9 , 500e9 ],
    9  : [602e9 , 720e9 ],
    10 : [787e9 , 950e9]
    }

almaReferencePosition = np.array([2225061.869, -5440061.953, -2481682.085]) # Robert Lucas
allWeatherStationPositions = {'Meteo129': array([ 2226292.373, -5440071.187, -2480490.57 ]),
                              'Meteo130': array([ 2223475.222, -5440620.327, -2481822.703]),
                              'Meteo131': array([ 2226146.018, -5439167.973, -2482751.669]),
                              'Meteo201': array([ 2218047.888, -5442740.475, -2480988.859]),
                              'Meteo309': array([ 2229937.944, -5435387.75 , -2486806.917]),
                              'Meteo410': array([ 2229279.046, -5440478.349, -2476637.931]),
                              'MeteoCentral': array([ 2225008.773, -5440202.705, -2481447.213]),
                              'MeteoTB1': array([ 2225262.839, -5440322.902, -2480961.371]),
                              'MeteoTB2': array([ 2225262.839, -5440322.902, -2480961.371]),
                              'MeteoOSF': array([ 2202176.215, -5445210.627, -2485352.924]),
                              'MeteoAPEX': array([ 2225039.5297, -5441197.6292, -2479303.3597]),
                              'MeteoASTE': array([ 2230817.87779425,  -5440189.64070941, -2475719.54322985])}

casaRevisionWithAlmaspws = '27481' # nominally '26688', but a pipeline version of 27480 does not have it
casaVersionWithMSMD = '4.1.0'
casaVersionWithMSMDFieldnames = '4.5'
casaVersionWithUndefinedFrame = '4.3.0'
weatherStationColors = ['b','r','g','c','m','brown','k','grey','orange','y','salmon']
DEFAULT_HOTLOAD_TEMP = 356
DEFAULT_AMBLOAD_TEMP = 287                

def version(short=False):
    """
    Returns the CVS revision number.
    """
    myversion = "$Id: analysisUtils.py,v 1.4003 2018/04/27 10:57:03 thunter Exp $"
    if (short):
        myversion = myversion.split()[2]
    return myversion

def getCasaVersion():
    """
    Uses cu.version if available, otherwise uses casadef.casa_version
    """
    try:
        casaVersion = cu.version().tolist()
        casaVersion = '.'.join([str(i) for i in casaVersion[:-1]])
    except:
        casaVersion = casadef.casa_version
    return casaVersion

def getCasaSubversionRevision():

    if getCasaVersion >= '5.0':
        return '40000'
    else:
        return casadef.subversion_revision

def versionStringToArray(versionString):
    """
    Converts '5.3.0-22' to np.array([5,3,0,22], dtype=np.int32)
    -Todd Hunter
    """
    tokens = versionString.split('-')
    t = tokens[0].split('.')
    version = [np.int32(i) for i in t]
    if len(tokens) > 1:
        version += [np.int32(tokens[1])]
    return np.array(version)
    
def casaVersionCompare(comparitor, versionString):
    """
    Uses cu.compare_version in CASA >=5, otherwise uses string comparison
    Example: casaVersionCompare('<', '5.3.0-22')
    -Todd Hunter
    """
    if getCasaVersion() < '5':
        if comparitor == '>=':
            comparison = casadef.casa_version >= versionString
        elif comparitor == '>':
            comparison = casadef.casa_version > versionString
        elif comparitor == '<':
            comparison = casadef.casa_version < versionString
        elif comparitor == '<=':
            comparison = casadef.casa_version <= versionString
        else:
            print "Unknown comparitor: ", comparitor
            return False
    else:
        version = versionStringToArray(versionString)
        comparison = cu.compare_version(comparitor, version)
    return comparison

def help(match='', showClassMethods=False, debug=False):
    """
    Print an alphabetized list of all the defined functions at the top level in
    analysisUtils.py.
    match: limit the list to those functions containing this string (case insensitive)
           If match is a list of strings or a list as a comma-delimited string, then
           the function must contain all strings to be considered a match.
    -- Todd Hunter
    """
    myfile = __file__
    if (myfile[-1] == 'c'):
        if (debug): print "au loaded from .pyc file, looking at .py file instead"
        myfile = myfile[:-1]
    aufile = open(myfile,'r')
    lines = aufile.readlines()
    if (debug): print "Read %d lines from %s" % (len(lines), __file__)
    aufile.close()
    commands = []
    if (type(match) == str and match.find(',')>0):
        match = match.split(',')
    for line in lines:
        if (line.find('def ') == 0):
            commandline = line.split('def ')[1]
            tokens = commandline.split('(')
            if (len(tokens) > 1):
                command = tokens[0]
            else:
                command = commandline.strip('\n\r').strip('\r\n')
            if (match == ''):
                commands.append(command)
            elif (type(match) == str):
                if (command.lower().find(match.lower()) >= 0):
                    commands.append(command)
            elif (type(match) == list or type(match) == np.ndarray):
                add = True
                for m in match:
                    if (command.lower().find(m.lower()) < 0):
                        add = False
                if (add): commands.append(command)
            else:
                print "The match argument must be a string or a list of strings."
                return
    # Now identify matching classes
    classMethods = []
    for i,line in enumerate(lines):
        if (line.find('class ') == 0):
            myclass = line[6:-1]
            if (type(match) == str):
                match = match.split(',')
            for m in match:
                if line.lower().find(m.lower()) >= 0:
                    # now find all methods of this class
                    classMethods.append("Methods in class %s" % (myclass))
                    for j in range(i+1,len(lines)):
                        if lines[j].find('def') == 0:
                            # end of the current class
                            break
                        myline = lines[j]
                        loc = myline.find(' def ')
                        if loc >= 0 and myline.find('__init__')<0:
                            classMethods.append("  " + myline[loc+5:].split('(')[0])
                
    commands.sort()
    for command in commands:
        print command
    if len(classMethods) > 1 and (len(commands) == 0 or showClassMethods):
        print classMethods[0]
        classMethods = classMethods[1:]
        classMethods.sort()
        for command in classMethods:
            print command

def aggregate(object):
    """
    This function checks whether the object is a list, and if it is not,
    it wraps it in a list.
    """
    if type(object) == type([]):
        return object
    else:
        return [object]

    
def getBand(freq) :
    """
    Converts a frequency into an ALMA band number.
    freq: can be given either as a floating point value in Hz, or a string
          with units at the end (GHz, MHz, kHz, or Hz).
    Todd Hunter
    """
    if (type(freq) == str):
        freq = parseFrequencyArgument(freq)
    for band in bandDefinitions.keys():
        if ((freq <= bandDefinitions[band][1]) and (freq >= bandDefinitions[band][0])) :
            if band == 3 and freq < 90e9:
                print "Someday, Band 2 will also cover this frequency."
            return band
    print "This frequency does not lie within any ALMA band."

# A useful sequence of 19 unique matplotlib colors to cycle through
overlayColors = [
      [0.00,  0.00,  1.00],
      [0.00,  0.50,  0.00],
      [1.00,  0.00,  0.00],
      [0.00,  0.75,  0.75],
      [0.75,  0.00,  0.75],
      [0.25,  0.25,  0.25],
      [0.75,  0.25,  0.25],
#      [0.95,  0.95,  0.00],  yellow
      [0.25,  0.25,  0.75],
      [1.00,  0.75,  0.75], # [0.75, 0.75, 0.75] is invisible on gray border
      [0.00,  1.00,  0.00],
      [0.76,  0.57,  0.17],
      [0.54,  0.63,  0.22],
      [0.34,  0.57,  0.92],
      [1.00,  0.10,  0.60],
      [0.70,  1.00,  0.70], # [0.88,  0.75,  0.73], hard to see on gray
      [0.10,  0.49,  0.47],
      [0.66,  0.34,  0.65],
      [0.99,  0.41,  0.23]]
overlayMarkers = len(overlayColors) * 'o'
overlayColors += overlayColors + overlayColors + overlayColors
overlayMarkers += len(overlayMarkers) * '^' + len(overlayMarkers) * '*' + len(overlayMarkers) * 'v'

tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),
             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),
             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),
             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),
             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]
tableau20 += tableau20 + tableau20
# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.
for i in range(len(tableau20)):
    r, g, b = tableau20[i]
    tableau20[i] = (r / 255., g / 255., b / 255.) 

def makeTimeStamp():
    """
    Creates a current timestamp string like '2017-05-06T17:14:37'
    Used by manualAsdmExport.py.  See also convertTimeStamp(s)
    """
    return timeUtilities.strftime('%Y-%m-%dT%H:%M:%S')

def makeList(input) :
    """
    If a value is not a list, then make it a list.
    Used by locate, getAllanVariance, plotTrxFreq, plotTrxInfo, convertTimeStamps, etc.
    """
    if list not in [type(input)] : return [input]
    else : return input

def locate(msfile):
    """
    Script used to locate an ASDM or an MS file in the RADIO data directory tree.
    """
    host=os.getenv('HOSTNAME')
    if 'gns' in host:
        datadir='/groups/science/data/RADIO'
    elif 'red' in  host:
        datadir="/data/RADIO/"
    else:
        datadir="/data/RADIO/"
        
    if not msfile.find(':') == []:  msfile=msfile.replace('/','_').replace(':','_')
    print msfile

    # first search via locate utility
    a=os.popen('locate %s' %(msfile)).read()
    m=re.search('/data/RADIO/[A-Z]*/.*/[0-9].*/%s/' %msfile,a)
  
    if  type(m) is not(NoneType):
        location=m.group(0)
        print 'using Unix locate'
        location=makeList(location)
    else:
        print 'using Unix find'
        location=os.popen('find  %s -name %s' %(datadir,  msfile)).read().split('\n')
        
    if location != ['']:
        for i in range(size(location)):
            if ('ASDMBinary' not in location[i]):
                location=location[i]
                break
            else:
                print 'could not find this file in local dir or in /data/RADIO'
                return
        dir=location.strip(msfile)
        return [location, dir]
    else:
        print 'could not find this file in local dir or in /data/RADIO'
        return

def psd(d, fsample):
    """
    Function to take the psd of a timestream and return also the freq axis and the phase. 
    input should be 1D
    fsample in Hz
    """
    d = double(d)
    if floor(size(d) / 2) * 2 != size(d):
        d=d[1:]
        
    n = size(d) / 2
    transform = fft(d)
    transform=transform[0:n+1]
    freq = (fsample / 2.0) * (arange(n+1)) / n
    factor = repeat([2.0],n+1)
    factor[0]=1.
    factor[-1]=1.
    spec = sqrt(factor / freq[1]) * transform/ (2*n);
    spec = abs(spec);
        
    return freq,spec


def avpsd(d, fsample, fres,  deg=1):
    """
    function [freq,spec,nrep]=avpsd(input, fsample, fres, med, deg)
    make an average psd by averaging the psd from small segments of resolution fres
    """
    n = size(d);
    nout = floor(fsample / fres)
    nrep = floor(n / nout)
    x=arange(nout)
    psdarr = zeros([nrep, nout/2+1])
    print "%i %i" %(nout, nrep)
    
    if (deg !=-1):
        for i in arange(nrep): 
            y=d[i*nout : (i+1)* nout]
            p =polyfit(x,y, deg);
            baseline=polyval(p,x);
            y=y-baseline;
            [freq,ps]=psd(y, fsample);        
            psdarr[i, :] = ps
    else:
        for i in arange(nrep):
            y=d[i*nout : (i+1) * nout]
            [freq,ps]=psd(y, fsample);
            psdarr[i, :] = ps;

    print shape(psdarr)
    spec=sqrt(mean(psdarr*psdarr,0));
    
    return freq, spec

def smooth(x, window_len=10, window='hanning'):
    """
    smooth the data using a window with requested size.
    
    This method is based on the convolution of a scaled window with the signal.
    The signal is prepared by introducing reflected copies of the signal 
    (with the window size) in both ends so that transient parts are minimized
    in the beginning and end part of the output signal.
    
    input:
        x: the input signal 
        window_len: the dimension of the smoothing window
        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'
            flat window will produce a moving average smoothing.

    output:
        the smoothed signal
        
    example:

    t = linspace(-2,2,0.1)
    x = sin(t)+random.randn(len(t))*0.1
    y = smooth(x)
    
    see also: 
    
    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve
    scipy.signal.lfilter
 
    TODO: the window parameter could be the window itself if an array instead of a string   
    """

    if x.ndim != 1:
        raise ValueError, "smooth only accepts 1 dimension arrays."

    if x.size < window_len:
        raise ValueError, "Input vector needs to be bigger than window size."

    if window_len < 3:
        return x

    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman', 'gauss']:
        raise ValueError, "Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman', 'gauss'"

    s = np.r_[2*x[0]-x[window_len:1:-1], x, 2*x[-1]-x[-1:-window_len:-1]]
    #print(len(s))
    
    if window == 'flat': #moving average
        w = np.ones(window_len,'d')
    elif window == 'gauss':
        w = gauss_kern(window_len)
    else:
        w = getattr(np, window)(window_len)
    y = np.convolve(w/w.sum(), s, mode='same')
    return y[window_len-1:-window_len+1]

def casaHanning(x, padOutput=False):
    """
    Simulates the CASA task hanningsmooth as described here:
    http://casa.nrao.edu/docs/taskref/hanningsmooth-task.html
    Inputs: 
    x: vector of values
    padOutput: if True, then include the 2 edge points with weights of 2/3 of edge channel 
               and 1/3 on adjacent channel
    Returns: array 
    -Todd Hunter
    """
    if (len(x) < 3):
        print "Spectrum has too few points"
        return
    output = np.zeros(len(x)-2)
    for i in range(len(output)):
        output[i] = x[i]*0.25 + x[i+1]*0.5 + x[i+2]*0.25
    if padOutput:
        output = [x[0]*2/3. + x[1]*1/3.] + list(output) + [x[-1]*2/3. + x[-2]*1/3.]
    return(np.array(output))

def compareHanning(npts=30000, bw=300, noise=0.5, ncomponents=50, maxtime=200,
                   xlimits = [45,80], ylimits = [-10, 3000], denominator=0.025,
                   drawstyle='default'):   
    """
    This was written to answer helpdesk ticket 5680.
    Compares Hanning smoothing in time domain (ALMA correlator) vs. CASA (hanningsmooth task)
    drawstyle: 'default' or 'steps' (stairsteps)
    -Todd Hunter
    """
    t = linspace(-maxtime,maxtime,num=npts)
    datastream = np.zeros(len(t))
    for freq in np.linspace(0.90, 1.1, num=ncomponents):
        amplitude = np.exp(-((freq-1.0)/denominator)**2)
        datastream += np.sin(t*freq)*amplitude + np.random.randn(len(t))*noise
    datastream /= np.max(datastream)
    almaHannWindow = scipy.signal.hann(len(datastream))
    almaDatastream = datastream * almaHannWindow
    almaDatastream /= np.max(almaDatastream)
    rawSpectrum = np.abs(np.fft.fft(datastream))
    casaSpectrum = np.append(np.abs(casaHanning(rawSpectrum)),[0])
    # Pad casa spectrum with two zeros
    casaSpectrum = np.append([0],casaSpectrum)
    almaSpectrum = np.abs(np.fft.fft(almaDatastream))
    pb.clf()
    desc = pb.subplot(211)
    pb.subplots_adjust(hspace=0.3)
    pb.plot(range(len(datastream)), datastream, 'k', range(len(almaHannWindow)), almaHannWindow, 'g',
            range(len(almaDatastream)), almaDatastream, 'r')
    pb.xlabel('Time sample')
    pb.title('Simulated timestream of a sum of sinewaves plus noise')
    pb.ylim([-1.1,1.1])
    size = 10
    pb.text(0.02, 0.18, 'Black: Raw data', transform=desc.transAxes, size=size)
    pb.text(0.02, 0.11, 'Green: Hann window in lag space', transform=desc.transAxes, size=size, color='g')
    pb.text(0.02, 0.04, 'Red: Data weighted by Hann window', transform=desc.transAxes, size=size, color='r')

    desc = pb.subplot(212)
    pb.plot(range(len(casaSpectrum[:npts/bw])), casaSpectrum[:npts/bw], 'b.-', 
            range(len(rawSpectrum[:npts/bw])), rawSpectrum[:npts/bw], 'k.-', 
            range(len(almaSpectrum[:npts/bw])), almaSpectrum[:npts/bw], 'r.-', markeredgewidth=0,
            drawstyle=drawstyle)
    pb.xlabel('Frequency bin')
    pb.xlim(xlimits)
    pb.ylim(ylimits)
    pb.title('Power Spectra')
    pb.text(0.02, 0.9, 'Black: Raw spectrum', transform=desc.transAxes, size=size)
    pb.text(0.02, 0.81, 'Blue: after CASA hanningsmooth', transform=desc.transAxes, size=size, color='b')
    pb.text(0.02, 0.72, 'Red: ALMA correlator output', transform=desc.transAxes, size=size, color='r')
    pb.text(0.07, 0.64, '(with Hann window weighting)', transform=desc.transAxes, size=size, color='r')
    rms = np.std(almaSpectrum-casaSpectrum)
    output = "rms of Red-Blue residual"
    pb.text(0.02, 0.5, output, transform=desc.transAxes, size=size)
    output = " = %f = %f%% of peak" % (rms, rms/np.max(almaSpectrum))
    pb.text(0.02, 0.42, output, transform=desc.transAxes, size=size)
    pb.draw()
    pb.savefig('compareHanning.png')

# some quick code I added.

def wtvar(X, W, method = "R"):
    """
    Only used by BaselineReducer.py, but commented-out there
    """
    sumW = sum(W)
    if method == "nist":
        xbarwt = sum([w * x for w,x in zip(W, X)])/sumW    # fixed.2009.03.07, divisor added.
        Np = sum([ 1 if (w != 0) else 0 for w in W])
        D = sumW * (Np-1.0)/Np
        return sum([w * (x - xbarwt)**2 for w,x in zip(W,X)])/D
    else: # default is R
        sumW2 = sum([w **2 for w in W])
        xbarwt = sum([(w * x)  for (w,x) in zip(W, X)])/sumW
        return sum([(w * (x - xbarwt)**2) for (w,x) in zip(W, X)])* sumW/(sumW**2 - sumW2)

def movingStD(a, w):
   """
   Not currently used anywhere.
   Moving standard deviation of array a calculated with window size w
   """
   res=[std(a[i:i+w]) for i in range(len(a)-w)]
   return res


def movStd(t,d, w,removeoutlier=True):
    """
    Not currently used anywhere.
    """
    trms=[]
    drms=[]

    #if removeoutlier:
    #    d = remove_outlier(d, sigma_th=10)
    
    s=size(d)
    #print s, pl.ceil(s/w)
    
    for i in range(s/w):

        
        x=arange(w-1)
        y=d[w*i:w*(i+1)-1]
        polycoeffs=polyfit(x, y, 2)
        yfit=polyval(polycoeffs, x)
        #pl.clf()
        #pl.plot(x,y)
        #pl.plot(x,yfit)
        y=y-yfit
        #pl.plot(x,y)
        #raw_input()
           
        trms.append(t[w*(i+1)])
        drms.append(std(y))

    return trms, drms


def gauss_kern(size):
    """ 
    Returns a normalized 2D gauss kernel array for convolutions.  Used by smooth.
    """
    size = int(size)
    x= np.mgrid[-size:size+1]
    g = np.exp(-(x**2/float(size)))
    return g / g.sum()

def onedgaussianplus(x, H,A,dx,w, r):
    #fit a 1D gaussian plus a linear term
    return H+A*np.exp(-(x-dx)**2/(2*w**2))+r*(x-dx)

def onedgaussian(x,H,A,dx,w):
    """
    Returns a 1-dimensional gaussian of form
    H+A*np.exp(-(x-dx)**2/(2*w**2))
    """
    return H+A*np.exp(-(x-dx)**2/(2*w**2))

def onedgaussfit(xax,data,err=None,params=[0,1,0,1,0],fixed=[False,False,False,False,False],limitedmin=[False,False,False,False,False],
        limitedmax=[False,False,False,False,False],minpars=[0,0,0,0,0],maxpars=[0,0,0,0,0],quiet=True,shh=True):
    """
    Inputs:
       xax - x axis
       data - y axis
       err - error corresponding to data

       params - Fit parameters: Height of background, Amplitude, Shift, Width, Linear
       fixed - Is parameter fixed?
       limitedmin/minpars - set lower limits on each parameter
       limitedmax/maxpars - set upper limits on each parameter
       quiet - should MPFIT output each iteration?
       shh - output final parameters?

    Returns:
       Fit parameters
       Model
       Fit errors
       chi2
    """

    def mpfitfun(x,y,err):
        if err is None:
            def f(p,fjac=None): return [0,(y-onedgaussianplus(x,*p))]
        else:
            def f(p,fjac=None): return [0,(y-onedgaussianplus(x,*p))/err]
        return f

    if xax is None:
        xax = np.arange(len(data))

    parinfo = [ {'n':0,'value':params[0],'limits':[minpars[0],maxpars[0]],'limited':[limitedmin[0],limitedmax[0]],'fixed':fixed[0],'parname':"HEIGHT",'error':0} ,
                {'n':1,'value':params[1],'limits':[minpars[1],maxpars[1]],'limited':[limitedmin[1],limitedmax[1]],'fixed':fixed[1],'parname':"AMPLITUDE",'error':0},
                {'n':2,'value':params[2],'limits':[minpars[2],maxpars[2]],'limited':[limitedmin[2],limitedmax[2]],'fixed':fixed[2],'parname':"SHIFT",'error':0},
                {'n':3,'value':params[3],'limits':[minpars[3],maxpars[3]],'limited':[limitedmin[3],limitedmax[3]],'fixed':fixed[3],'parname':"WIDTH",'error':0},
                {'n':4,'value':params[4],'limits':[minpars[4],maxpars[4]],'limited':[limitedmin[4],limitedmax[4]],'fixed':fixed[4],'parname':"LINEAR",'error':0}]
    
    mp = mpfit(mpfitfun(xax,data,err),parinfo=parinfo,quiet=quiet)
    mp.status
    mpp = mp.params
    mpperr = mp.perror
    chi2 = mp.fnorm

    if not shh:
        for i,p in enumerate(mpp):
            parinfo[i]['value'] = p
            print parinfo[i]['parname'],p," +/- ",mpperr[i]
        print "Chi2: ",mp.fnorm," Reduced Chi2: ",mp.fnorm/len(data)," DOF:",len(data)-len(mpp)

    return mpp,onedgaussianplus(xax,*mpp),mpperr,chi2


def almaToGeo(lon, lat, alma):
    """
    Convert the local (horizontal) coordinates into geocentric
    lon: longitude in radians, e.g. np.radians(au.ALMA_LONGITUDE)
    lat: latitude in radians, e.g. np.radians(au.ALMA_LATITUDE)
    alma: local coordinates: [E,N,U]
    """
    geo = [0, 0, 0]
    geo[0] = -math.sin(lon) * alma[0] \
             - math.cos(lon) * math.sin(lat) * alma[1] \
             + math.cos(lon) * math.cos(lat) * alma[2]
    geo[1] = math.cos(lon) * alma[0] \
             - math.sin(lon) * math.sin(lat) * alma[1] \
             + math.sin(lon) * math.cos(lat) * alma[2]
    geo[2] = math.cos(lat) * alma[1] + math.sin(lat) * alma[2]
    return geo

def geoToAlma(lon, lat, geo):
    """
    Convert the geocentric coordinates into the local (horizontal) ones.
    lon: longitude in radians (e.g. au.ALMA_LONGITUDE)
    lat: latitude in radians (e.g. au.ALMA_LATITUDE)
    geo: geocentric coordinates: [X,Y,Z]
    """
    alma = [0, 0, 0]
    alma[0] = -geo[0] * math.sin(lon) + geo[1] * math.cos(lon)
    alma[1] = -geo[0] * math.cos(lon) * math.sin(lat)  \
              - geo[1] * math.sin(lon) * math.sin(lat) \
              + geo[2] * math.cos(lat)
    alma[2] = geo[0] * math.cos(lon) * math.cos(lat) \
              + geo[1] * math.sin(lon) * math.cos(lat) \
              + geo[2] * math.sin(lat)
    return alma

def getDataColumnName(inputms):
    """
    Gets the name of the data column of a measurement set: either 'DATA'
    or 'FLOAT_DATA'
    """
    mytb = createCasaTool(tbtool)
    mytb.open(inputms)
    colnames = mytb.colnames()
    if 'FLOAT_DATA' in colnames:
        data_query= 'FLOAT_DATA'
    else:
        data_query = 'DATA'
    mytb.close()
    return(data_query)

def dataColumns(vis):
    """
    Returns the names of the data columns (data, model, corrected) in a measurement set.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    names = mytb.colnames()
    mytb.close()
    columns = []
    for i in ['DATA','FLOAT_DATA','MODEL_DATA','CORRECTED_DATA']:
        if i in names:
            columns.append(i)
    return columns
    
def getSpectralData(inputms, dd, scanum=[]):
    """
    Used by Coherence.py
    """
    mytb = tbtool()
    mytb.open(inputms)
    if size(scanum) == 0:
        specTb = mytb.query('ANTENNA1==0 && ANTENNA2==1 && DATA_DESC_ID==%d'%(dd))
    else:
        specTb = mytb.query('ANTENNA1==0 && ANTENNA2==1 && DATA_DESC_ID==%d && SCAN_NUMBER == %d'%(dd,scanum))
    if 'FLOAT_DATA' in specTb.colnames():
        data_query= 'FLOAT_DATA'
    else:
        data_query='DATA'
    specData = specTb.getcol(data_query)
    specTime = specTb.getcol('TIME')
    specTb.close()
    mytb.close()
    date  = int(specTime[0]/ 86400)
    specTime = specTime - date*86400
    return [specTime, specData]

def getSpectralAutoData(inputms,iant, dd, scanum=[]):
    """
    Used by Coherence.py, reduc_cutscans.py and reduc_oof.py
    """
    mytb = tbtool()
    mytb.open(inputms)
    if size(scanum) == 0:
        specTb = mytb.query('ANTENNA1==%d && ANTENNA2==%d && DATA_DESC_ID==%d'%(iant, iant,dd))
    else:
        specTb = mytb.query('ANTENNA1==%d && ANTENNA2==%d && DATA_DESC_ID==%d && SCAN_NUMBER == %d' % (iant, iant ,dd, scanum))
    if 'FLOAT_DATA' in specTb.colnames():
        data_query= 'FLOAT_DATA'
    else:
        data_query='DATA'
    specData = specTb.getcol(data_query)
    specTime = specTb.getcol('TIME')
    specTb.close()
    mytb.close()
    date  = int(specTime[0]/ 86400)
    specTime = specTime - date*86400
    return [specTime, specData]

#def getMeasFocus(msfile, aid, scanum):
#    """
#    Now obsolete
#    Look into EditfocusModel for more upto date versions
#    """
#    
#    try:
#        print "Focus values from actual measurements at start of Beam map."
#        if os.path.isdir(msfile+'/ASDM_FOCUS'):
#            tb.open(msfile+'/ASDM_FOCUS')
#            antid=tb.getcol('antennaId')
#            foc=tb.getcol('measuredFocusPosition')
#            asdmtime=tb.getcol('timeInterval')
#
#            q=find(antid== 'Antenna_%i' %aid)
#            asdmtime=asdmtime[0,q]
#            foc=foc[:,q]
#            
#            tb.open(msfile+'/ANTENNA')
#            antennas=tb.getcol('NAME')
#            tb.open(msfile)
#            scan=tb.getcol('SCAN_NUMBER')
#            t0=tb.getcol('TIME')
#            tb.close() 
#            f=find(scan==int(scanum))[0]
#            scanbeg=t0[f]
#           
#            # cross reference asdmtime and standard time for start of beam map.
#            asdmindex=find(asdmtime > scanbeg)[0]
#            focus=zeros([3])
#            um=1e6
#            antenna=antennas[aid]
#            focus[0]=foc[0,asdmindex]
#            focus[1]=foc[1,asdmindex]
#            focus[2]=foc[2,asdmindex]
#            print "%s (X  Y  Z)= (%.0f %.0f %.0f) microns " \
#                  % (antenna, focus[0]*um, focus[1]*um, focus[2]*um)
#            return focus
#        else:
#            print "The ms file is missing /ASDM_FOCUS table. Regenerate the MS file with that table. Using batchasdm2MS for exemple"
#
#    except:
#        return (NaN, NaN, NaN)


plotOption = {'0-1' : 'b.', '0-2' : 'r.'}
def getAllanVariance(vis,antenna1=None,antenna2=None,spwID=None,param='phase',scan=None,state=None,doPlot=True) :
    """
    Currently unused by anything else in analysis_scripts.
    """
    if param not in ['phase','real','imag'] : return 'you are a dumb fuck.'
    if spwID is None : spwID = getChanAverSpwIDBaseBand0(vis)
    if antenna2 is None : antenna2 = getAntennaNames(vis)
    else : antenna2 = makeList(antenna2)
    if antenna1 is None : antenna1 = getAntennaNames(vis)
    else : antenna1 = makeList(antenna1)
    data = Visibility(vis,antenna1=antenna1[0],antenna2=antenna2[0],spwID=spwID,scan=scan,state=state)
    aV = {}
    for i in antenna1 :
        for j in antenna2 :
            if i < j :
                data.setAntennaPair(i,j)
                aV[("%s-%s" % (i,j))] = allanVariance(data.phase,data.specTime,data.specFreq.mean())
                if doPlot : pb.plot(aV[("%s-%s" % (i,j))][:,0],np.log10(aV[("%s-%s" % (i,j))][:,1]),'.')
    return aV

def allanVariance(phase,time,ref_freq) :
    Nallan=[]
    ave=[]
    Ndata = len(time)
    Nmax = int(floor(Ndata/2))
    dt = (time[1:]-time[:-1]).mean()
    for i in range(1,Nmax):
        n=0
        y = []
        for j in range(Ndata):
            k=j+2*i
            if k > Ndata-1:
                break
            z=phase[:,:,k]-2*phase[:,:,i+j]+phase[:,:,j]
            y.append(z**2)
            n+=1
        ave.append(mean(y))
        Nallan.append(n)
    Ntau=len(ave)
    Allan=array(Ntau*[2*[0.0]],dtype=float)
    for i in range(Ntau):
        y=[]
        Allan[i][0]=dt*(i+1)
        Allan[i][1]=math.sqrt(ave[i]/2.0/(2*math.pi*ref_freq*Allan[i][0])**2)
    return Allan

def phaseClosure(vis, antenna1, antenna2, antenna3, spw, field, scan, vm=''):
     antennas=sorted([antenna1,antenna2,antenna3])
     antenna1=antennas[0]
     antenna2=antennas[1]
     antenna3=antennas[2]
     visVal=Visibility(vis,antenna1=antenna1,antenna2=antenna2,spwID=spw,field=field,scan=scan, vm=vm)
     phi01=visVal.phase
     visVal.setAntenna2(antenna3)
     phi02=visVal.phase
     visVal.setAntenna1(antenna2)
     phi12=visVal.phase
     close=phi01+phi02-phi12
     
     return close,visVal

def phaseClosureStats(msName='', scan='', intent='CALIBRATE_BANDPASS#ON_SOURCE', chanEdge=0.2):

    if casadef.casa_version < casaVersionWithMSMD:
        sys.exit('ERROR: CASA versions earlier than %s are not supported.' % (casaVersionWithMSMD))

    if msName == '': sys.exit('ERROR: no ms name specified.')

    if scan == '':
        if casadef.casa_version >= casaVersionWithMSMD:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(msName)
            scan2 = mymsmd.scansforintent(intent).tolist()
            mymsmd.close()
        else:
            sys.exit('ERROR: no scan specified.')
    else:
        scan2 = scan.split(',')
        scan2 = [int(i) for i in scan2]
    mytb = tbtool()
    mytb.open(msName+'/ANTENNA')
    antIndex = range(mytb.nrows())
    mytb.close()

#     es = stuffForScienceDataReduction()
#     spwInfo = es.getSpwInfo(msName, intent=intent)
#     spwIds = spwInfo.keys()

    mytb.open(msName+'/DATA_DESCRIPTION')
    spwIds1 = mytb.getcol('SPECTRAL_WINDOW_ID').tolist()
    mytb.close()

    phase2 = {}

    mytb.open(msName)

    for scan1 in scan2:

        phase2[scan1] = {}

        mymsmd.open(msName)
        spwIds = mymsmd.spwsforscan(scan1)
        spwIds = [i for i in spwIds if i in mymsmd.tdmspws().tolist()+mymsmd.fdmspws().tolist()]
        mymsmd.close()

        for i in spwIds:

            phase2[scan1][i] = {}

            tb1 = mytb.query('SCAN_NUMBER == '+str(scan1)+' AND DATA_DESC_ID == '+str(spwIds1.index(i)))

            time1 = tb1.getcol('TIME')
            ant1 = tb1.getcol('ANTENNA1')
            ant2 = tb1.getcol('ANTENNA2')
            data1 = tb1.getcol('DATA')
            data2 = data1.swapaxes(0,2)
            flagrow1 = tb1.getcol('FLAG_ROW')
            flag1 = tb1.getcol('FLAG')
            flag2 = flag1.swapaxes(0,2)

            phase3 = []

            for time2 in np.unique(time1):

                ij = itertools.combinations(antIndex, 3)

                for j in ij:

                    j = sorted(j)

                    ij2 = []

                    for k in range(3):

                        ij1 = np.argwhere((time1 == time2) & (((ant1 == j[k%3]) & (ant2 == j[(k+1)%3])) | ((ant1 == j[(k+1)%3]) & (ant2 == j[k%3])))).flatten()
                        if len(ij1) == 1: ij2.append(ij1[0]*math.copysign(1, ant2[ij1[0]] - ant1[ij1[0]]))

                    if len(ij2) == 3:

                        if flagrow1[abs(ij2[0])] == 0 and flagrow1[abs(ij2[1])] == 0 and flagrow1[abs(ij2[2])] == 0:

                            k1 = int(len(data2[0]) * chanEdge)
                            k2 = int(len(data2[0]) * (1-chanEdge))

                            for kl in range(len(data2[0][0])):

                                phase1 = []
                                for k in range(k1, k2):
                                    if flag2[abs(ij2[0])][k][kl] == 0 and flag2[abs(ij2[1])][k][kl] == 0 and flag2[abs(ij2[2])][k][kl] == 0:
                                        phase4 = np.rad2deg(math.copysign(1, ij2[0])*np.angle(data2[abs(ij2[0])][k][kl]) + math.copysign(1, ij2[1])*np.angle(data2[abs(ij2[1])][k][kl]) - math.copysign(1, ij2[2])*np.angle(data2[abs(ij2[2])][k][kl]))
                                        phase4 = phase4 - round(phase4/360.)*360.
                                        phase1.append(phase4)

                                phase3.append(np.mean(phase1))

            phase2[scan1][i]['min'] = min(phase3)
            phase2[scan1][i]['max'] = max(phase3)
            phase2[scan1][i]['mean'] = np.mean(phase3)
            phase2[scan1][i]['stddev'] = np.std(phase3)

    mytb.close()

#     pb.figure()
#     n, bins, patches = pb.hist( phase3, bins=range(int(np.ceil(max(phase3))+1)), histtype='bar')

    return phase2

class StuffToLieAbout:
    """
    This class is defunct.
    """
    def __init__(self,calTable=None):
        if calTable <> None :
            self.calTable = calTable
            #self.calTableExplorer = CalTableExplorer(self.calTable,antenna=0,spwID=1)
            self.calTableExplorer = CalTableExplorer(self.calTable,antenna=0)
        else :
            self.calTable = None

    def setCalTable(self,calTable) :
        self.calTable = calTable
        self.calTableExplorer = CalTableExplorer(self.calTable,antenna=0,spwID=1)

    def getCalTable(self) : return self.calTable

    def tsysInSpectralWindow(self,badSpw,goodSpw=None,setValue=False) :
        inputMs  = self.calTableExplorer.inputMs
        badRaw   = Visibility(inputMs,spwID=badSpw, correctedData = False)
        if ((goodSpw == None) and (not setValue)) :
           goodSpw = list(self.calTableExplorer.getSpwID())
           goodSpw.remove(badSpw)[0]
           goodCorr = Visibility(inputMs,spwID=goodSpw,correctedData = True)
           goodRaw  = Visibility(inputMs,spwID=goodSpw,correctedData = False)
           tsysToApply = goodCorr.amp/goodRaw.amp
        elif setValue :
            tsysToApply = setValue*np.ones(tsysToApply.shape,'complex128')
        badCorr  = badRaw.amp*tsysToApply
        self.stuffVisInDataset(badCorr,badSpw)

    def TFBOffset(self,offsetFromOT,inputMs=None,spwIds=None) :
        if inputMs == None and self.calTable == none :
            return "Please identify a visibility dataset."
        elif inputMs == None :
            inputMs = self.calTableExplorer.intputMs
        if offsetFromOT < 1000.0 : return "Please input your offsetFromOT in MHz."        
        vm = ValueMapping(inputMs)
        if spwIds == None :
            spwIds = []
            print "I am assuming you want to fix all FDM modes by the same amount."
            for i in vm.spwInfo.keys() :
                if vm.spwInfo[i]["numChannels"] > 256 : spwIds.append(i)
        else :
            spwIds = makeList(spwIds)
        for i in spwIds :
            tb.open("%s/SPECTRAL_WINDOW" % inputMs,nomodify=False)
            delta = 3000.0-offsetFromOT
            correction = 2.0*delta*vm.spwInfo[i]["sideband"]*1e6
            newChanFreq = vm.spwInfo[i]["chanFreqs"]-correction
            print ("Subtracting %f to your channel frequencies in spectral window %i" % (correction,i) )
            print vm.spwInfo[i]["chanFreqs"].mean(),newChanFreq.mean()
            tb.putcell("CHAN_FREQ",i,newChanFreq)
        tb.close()
        vm.doSpwAndFrequency()

    def doTsysInfo(self) :
        return

    def stuffVisInDataset(self,badCorr) :
        inputMs = self.calTableExplorer.inputMs
        tb.open(inputMs,nomodify=False)
        for i in range(len(badCorr.subtable.rownumbers())) :
            tb.putcell('CORRECTED_DATA',badCorr.subtable.rownumbers()[i],badCorr.specData[...,i])
        tb.close()
    
    def gain(self,antennaToReplace,replacementAntenna=None) :
        if str(antennaToReplace).isdigit() :
            antennaToReplace = self.calTableExplorer.ValueMapping.antennaNamesForAntennaIds[int(antennaToReplace)]
        if replacementAntenna==None :
            antList = list(self.calTableExplorer.ValueMapping.antennaNamesForAntennaIds)
            antList.pop(antennaToReplace)
            replacementAntenna = antList[0]
        elif str(replacementAntenna).isdigit() :
            replacementAntenna = self.calTableExplorer.ValueMapping.antennaNamesForAntennaIds[int(replacementAntenna)]
        print antennaToReplace,replacementAntenna
        antennaToReplace = self.calTableExplorer.ValueMapping.getAntennaIdsForAntennaName(antennaToReplace)
        replacementAntenna = self.calTableExplorer.ValueMapping.getAntennaIdsForAntennaName(replacementAntenna)
        print antennaToReplace,replacementAntenna        
        tb.open(self.calTable,nomodify=False)
        retb  = tb.query('ANTENNA1 == %s' % replacementAntenna)
        rerow = retb.rownumbers()
        badtb = tb.query('ANTENNA1 == %s' % antennaToReplace)
        badrow = badtb.rownumbers()
        for i in range(len(badrow)) :
            _badrow = badrow[i]
            _rerow  = rerow[i]
            goodGain = tb.getcell('GAIN',_rerow)
            tb.putcell('GAIN',_badrow,goodGain)
        tb.close()


class ValueMapping:
    """
    Input: The name of an MS dataset as a string.
    Purpose: This class provides details on the mapping of various parameters to each other.  For example, if you would like to
             know which scans observed a given field source or over which time interval a scan was executed, this is the place to look.
             Included in that are functions which map antenna name to antenna id and field name to field id.  This is useful in building
             other routines that allow you to not require the user to input one or the other type of information.  It also gets unique
             lists of items, like antennas, field sources, scans, intents, etc.

    Responsible: S. Corder and other contributors
    Example: vm = aU.ValueMapping('myInputMS.ms')
    Suggested Improvements:
          (done, 06-04-2011, scorder)1) Change some of the get methods to do methods because they aren't really returning anything
          2) Add spectral window mapping information, spectral windows, spectral windows to fields, spectral windows to scans,
             spectral windows to frequency (central and channelized): Basically make a dictionary of all the spectral line info stuff,
             per spectral window.  Rework combination of SensitivityCalculator and VM....
          3) Add integration time calculator per source
          4) Do sensitivity calculator (maybe needs to be separate function/class that inhereits this)
    """
    def __init__(self,inputMs):
        """
        Instantiation of this class calls this, i.e., vm = aU.ValueMapping('myInputMS.ms').  The dataset name is the only allowed
        input.  It generates the mappings are part of this instantiation.
        """
        self.inputMs = inputMs
        self.setInputMs(self.inputMs)

    def getInputMs(self):
        """
        Input: None
        Output: The active measurement set in the class as a string
        Responsible: S. Corder
        Purpose: Return the name of the active dataset
        """
        return self.inputMs

    def setInputMs(self,inputMs):
        """
        Input: New measurement set that you wish to become the active one, as a string and activate that change to all other parameters
        Output: None
        Responsible: S. Corder
        Purpose: This changes the active dataset and remakes the relevant mappings.  The order of the functions is very
                 important.
        """
        self.inputMs = inputMs
        self.doScanTimeMapping()
        self.doFieldsAndSources()   ;  self.doStatesAndIntents()
        self.doAntennasAndNames()
        self.doScanStateMapping()   ;  self.doFieldTimeMapping() ;
        self.doAntennaTimeMapping() ;  self.doAntennaStateMapping()
        self.doDataDescId()         ; self.doSpwAndDataDescId()
        self.doPolarizations()
        self.doSpwAndFrequency()    
        self.doSpwScanMapping()     ;  self.doSpwFieldMapping()
        self.doSpwIntentMapping()

    def doSpwAndFrequency(self,ignoreWVR=True) :
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: Creates a dictionary (spwInfo) of spectral windows, with keys of the spectral window number.
                 For each spectral window, another dictionary is formed that has keys of bandwidth, sideband,
                 chanFreqs, chanWidth, numChannels, and meanFreq.
        """
        self.spwInfo = {}
        tb.open("%s/SPECTRAL_WINDOW" % self.inputMs)
        specWinIds = range(tb.nrows())
        junk = []
        for i in specWinIds :
            self.spwInfo[i] = {}
            self.spwInfo[i]["bandwidth"] = tb.getcell("TOTAL_BANDWIDTH",i)
            self.spwInfo[i]["chanFreqs"] = tb.getcell("CHAN_FREQ",i)
            self.spwInfo[i]["chanWidth"] = tb.getcell("CHAN_WIDTH",i)[0]
            self.spwInfo[i]["edgeChannels"] = [min(self.spwInfo[i]["chanFreqs"]),max(self.spwInfo[i]["chanFreqs"])]
            netSideband  = tb.getcell("NET_SIDEBAND",i)
            if netSideband == 2 : self.spwInfo[i]["sideband"] = 1
            else : self.spwInfo[i]["sideband"] = -1
            self.spwInfo[i]["meanFreq"]  = self.spwInfo[i]["chanFreqs"].mean()
            self.spwInfo[i]["numChannels"] = self.spwInfo[i]["chanFreqs"].shape[0]
            if ((ignoreWVR) and (self.spwInfo[i]['numChannels'] == 4)) :
                junk.append(i)
                self.spwInfo.pop(i)
        tb.close()
        if ignoreWVR:
            if (len(junk) > 0):
                print "Ignoring spectral window %s because it is WVR related" % junk

    def doSpwAndDataDescId(self) :
        tb.open("%s/DATA_DESCRIPTION" % self.inputMs)
        self.spwForDataDescId = tb.getcol('SPECTRAL_WINDOW_ID')
        tb.close()

    def doSpwFieldMapping(self) :
        tb.open("%s" % self.inputMs)
        self.fieldsForSpw = {}
        for i in self.spwForDataDescId :
            spw = self.spwForDataDescId[i]
            indices = np.where(self.dataDescId == i)
            self.fieldsForSpw[spw] = np.unique(self.fields[indices])
        tb.close()
        return

    def doDataDescId(self) :
        tb.open("%s" % self.inputMs)
        self.dataDescId = tb.getcol('DATA_DESC_ID')
        tb.close()

    def doPolarizations(self) :
        # Determine the number of polarizations for the first OBSERVE_TARGET intent.
        # Used by plotbandpass for BPOLY plots since the number of pols cannot be inferred
        # correctly from the caltable alone.  You cannot not simply use the first row, because
        # it may be a pointing scan which may have different number of polarizations than what
        # the TARGET and BANDPASS calibrator will have.
        # -- T. Hunter
        myscan = -1
        starttime = timeUtilities.time()
        for s in self.uniqueScans:
            intents = self.getIntentsForScan(s)
            for i in intents:
                if (i.find('OBSERVE_TARGET')>=0):
                    myscan = s
#                    print "First OBSERVE_TARGET scan = ", myscan
                    break
            if (myscan >= 0):
                break
        if (myscan == -1):
            # if there is no OBSERVE_TARGET, then just use the first scan
            myscan = 0
        self.getDataColumnNames()
        tb.open("%s" % self.inputMs)
        if (myscan == 0):
            # assume the first row in the table is for the first scan, to save time
            self.nPolarizations = np.shape(tb.getcell(self.dataColumnName,0))[0]
        else:
            scans = tb.getcol('SCAN_NUMBER')
            self.nPolarizations = 0
            for s in range(len(scans)):
                if (scans[s]==myscan):
                    self.nPolarizations = np.shape(tb.getcell(self.dataColumnName,s))[0]
                    break
        tb.close()
        donetime = timeUtilities.time()
#        print "doPolarizations took %.1f sec" % (donetime-starttime)

    def getDataColumnNames(self):
        tb.open(self.inputMs)
        colnames = tb.colnames()
        self.correctedDataColumnName = ''
        self.modelDataColumnName = ''
        if 'FLOAT_DATA' in colnames:
            self.dataColumnName = 'FLOAT_DATA'
            self.correctedDataColumnName = 'FLOAT_DATA'
        elif 'DATA' in colnames:
            self.dataColumnName = 'DATA'
        if 'CORRECTED_DATA' in colnames:
            self.correctedDataColumnName = 'CORRECTED_DATA'
        if 'MODEL_DATA' in colnames:
            self.modelDataColumnName = 'MODEL_DATA'
        tb.close()
        return

    def doSpwScanMapping(self) :
        tb.open("%s" % self.inputMs)
        self.scansForSpw = {}
        for i in self.spwForDataDescId :
            spw = self.spwForDataDescId[i]
            indices = np.where(self.dataDescId == i)
            self.scansForSpw[spw] = np.unique(self.scans[indices])
        tb.close()
        return
    
    def doSpwIntentMapping(self) :
        tb.open("%s" % self.inputMs)
        self.intentsForSpw = {}
        for i in self.spwForDataDescId :
            spw = self.spwForDataDescId[i]
            indices = np.where(self.dataDescId == i)
            statesForSpw = np.unique(self.states[indices])
            _intent = []
            for i in statesForSpw :
                __intent = []
# The 'if' statement is needed to support telescopes w/o intents. -T. Hunter
                if (len(self.intentsForStates) > 0):
                  for j in self.intentsForStates[i] :
#                    __map = j.split('#')[0]
                    __map = j
                    __intent.append(__map)
                  _intent += __intent
            self.intentsForSpw[spw] = np.unique(np.array(_intent))
        tb.close()


    def getSpwsForIntent(self,intent) :
        spwsForIntent = []
        for i in self.intentsForSpw.keys() :
            if (intent in self.intentsForSpw[i]) : spwsForIntent.append(i)
        return spwsForIntent

    def getIntentsForSpw(self,spw) :
        return self.intentsForSpw[spw]

    def getSpwsForField(self,field) :
        if not str(field).isdigit() : field = self.getFieldIdsForFieldName(field)
        spwsForField = []
        for i in self.fieldsForSpw.keys() :
            if (field in self.fieldsForSpw[i]) : spwsForField.append(i)
        return spwsForField

    def getFieldsForSpw(self,spw,returnName = True) :
        if returnName :
            return self.getFieldNamesForFieldId(np.unique(np.array(self.fieldsForSpw[spw])))
        else :
            return np.unique(np.array(self.fieldsForSpw[spw]))

    def getSpwsForScan(self,scan):
        spwsForScan = []
        for i in self.scansForSpw.keys() :
            if (scan in self.scansForSpw[i]) : spwsForScan.append(i)
        return spwsForScan

    def getScansForSpw(self,spw) :
        return self.scansForSpw[spw]

    def getAntennaNamesForAntennaId(self,id):
        """
        Input: Antenna id as an integer or string
        Output: Antenna name as a string
        Responsible: S. Corder
        Purpose: Allows translation between antenna id and antenna name.
        """

        return self.antennaNamesForAntennaIds[int(id)]

    def getAntennaIdsForAntennaName(self,antennaName):
        """
        Input: Antenna names as a string
        Output: Antenna index as an integer.
        Responsible: S. Corder
        Purpose: This allows translation between antenna name and antenna id
        """

        return np.where(self.antennaNamesForAntennaIds == antennaName)[0][0]

    def doStatesAndIntents(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines two attributes, uniqueStates, which is a python list of the different intents present in the dataset,
                 and intentsForStates is another python list which give the intents for state id as a nested list.  The first index of
                 the intentsForStates is the state id.  If you choose a state id, then the result is a list of intents for that state.
        """
        tb.open("%s/STATE" % self.inputMs)
        intents = tb.getcol("OBS_MODE")
        tb.close()
        _intents = []
        for i in intents : _intents.append(i.split(','))
        self.intentsForStates = _intents
        self.uniqueIntents = []
        for i in self.intentsForStates : self.uniqueIntents.extend(i)
        self.uniqueIntents = np.unique(np.array(self.uniqueIntents))

    def doFieldsAndSources(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines two attributes, uniqueField and fieldNamesForFieldIds.  For the time being these are identical.
                 fieldNamesForFieldIds is simply a numpy array where the index is the field id and the value is the name of the field source.
        """
        tb.open("%s/FIELD" % self.inputMs)
        self.fieldNamesForFieldIds = tb.getcol('NAME')
#        print '%d field names = '%len(self.fieldNamesForFieldIds), self.fieldNamesForFieldIds
        self.uniqueFields = self.fieldNamesForFieldIds
        tb.close()

    def doAntennasAndNames(self) :
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines two attributes, uniqueAntennas (which is a little excessive) and antennaNamesForAntennaIds.
                 antennaNamesForAntennaIds is a numpy array and has indices that are the antenna ids and values that are the antenna names.
        """
        tb.open("%s/ANTENNA" % self.inputMs)
        self.antennaNamesForAntennaIds = tb.getcol('NAME')
        self.uniqueAntennas = np.unique(self.antennaNamesForAntennaIds)
        self.numAntennas = len(self.uniqueAntennas)
        tb.close()

    def doScanStateMapping(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines an attribute, statesForScans, that is the mapping between states and scan numbers.  It is
                 a python dictionary that has keys of the scan number and values, in a list, of the states used in that scan.
        """
        tb.open("%s" % self.inputMs)
        self.states = tb.getcol("STATE_ID")
        tb.close()
        self.statesForScans = {}
        for i in self.uniqueScans :
            indices = np.where(self.scans == i)
            self.statesForScans[i] = np.unique(self.states[indices])

    def doScanTimeMapping(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines four attributes, scans, time, uniqueScans and scansForTiems.  scans and time are simply
                 the scan number and time table from the main data table as python arrays.  uniqueScans is a numpy array of the independent scans
                 in the table.  scansForTimes is a python dictionary with keys as scans and values as times in which data was taken
                 for that scan.
        """
        tb.open(self.inputMs)
        self.scans = tb.getcol('SCAN_NUMBER')
        self.time = tb.getcol('TIME')
        tb.close()
        self.uniqueScans = np.unique(self.scans)
        self.scansForTimes = {}
        for i in self.uniqueScans :
            indices = np.where(self.scans == i)
            self.scansForTimes[i] = self.time[indices]

    def doFieldTimeMapping(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines two attributes, fields, a numpy array, and fieldsForTimes, a dictionary with keys of field name.
                 The fields is just the field id from the data table.  The values of fieldsForTimes are the times during which data was
                 collected for that field source.
        """
        
        tb.open(self.inputMs)
        self.fields = tb.getcol('FIELD_ID')
        tb.close()
        self.fieldsForTimes = {}
        for i in range(len(self.fieldNamesForFieldIds)) :
            indices = np.where(self.fields == i)
            self.fieldsForTimes[self.fieldNamesForFieldIds[i]] = self.time[indices]

    def doAntennaTimeMapping(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines three attributes. antenna1 and antenna2 are numpy arrays containing the antenna1 and antenna2 columns
                 from the data table.  antennasForTimes defines the times over which data was collected for that antenna.  It is a python
                 dictionary with keys of baseline (using antenna names) and values of numpy array of times.
        """

        tb.open(self.inputMs)
        self.antennas1 = tb.getcol('ANTENNA1')
        self.antennas2 = tb.getcol('ANTENNA2')
        tb.close()
        self.antennasForTimes = {}
        for i in range(len(self.uniqueAntennas)) :
            for j in range(len(self.uniqueAntennas)) :
                if i <= j :
                    antennaKey = "%s-%s" % (str(self.uniqueAntennas[j]),str(self.uniqueAntennas[i]))
                    indices = np.where((self.antennas1 == list(self.antennaNamesForAntennaIds).index(self.uniqueAntennas[i])) *
                                       (self.antennas2 == list(self.antennaNamesForAntennaIds).index(self.uniqueAntennas[j])))
                    self.antennasForTimes[antennaKey] = self.time[indices]

    def doAntennaStateMapping(self):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose: This function defines one attribute, antennasForStates, a python dictionary.  The keys are baselines (using
                 antenna names) and values are staes used for that baseline.  Usually the autocorrelations are most useful.
        """

        self.antennasForStates = {}
        for i in range(len(self.uniqueAntennas)) :
            for j in range(len(self.uniqueAntennas)) :
                if i <= j :
                    antennaKey = "%s-%s" % (str(self.uniqueAntennas[j]),str(self.uniqueAntennas[i]))
                    indices = np.where((self.antennas1 == list(self.antennaNamesForAntennaIds).index(self.uniqueAntennas[i])) *
                                       (self.antennas2 == list(self.antennaNamesForAntennaIds).index(self.uniqueAntennas[j])))
                    self.antennasForStates[antennaKey] = self.states[indices]

    
    def getScansForTime(self,time,fudge=0.0):
        """
        Input: Time stamp in CASA native units as a string or float
        Output: Scan number associated with that time stamp.
        Responsible: S. Corder
        Purpose: This function returns the scan number for a specific timestamp.  It allows translation between time and scan.
        """
        for i in self.scansForTimes.keys() :
            if ((float(time) >= self.scansForTimes[i][0]-fudge) and (float(time) <= self.scansForTimes[i][-1]+fudge)) :
                return i

    def getTimesForScans(self,scans):
        """
        Input: Scan number as an integer or string or list of integers
        Output: A list of time ranges over which data exists for that scan (or those scans), each as a numpy array.
        Responsible: S. Corder, copied from getTimesForScan and modified by T. Hunter
        Purpose: Return the times associated with a given timestamp.  This allows translation between scan and time.
        """
        times = []
        if (type(scans) == int or type(scans) == np.int32):
            scans = [scans]
        for scan in scans:
            times.append(self.scansForTimes[int(scan)])
        return (times)

    def getTimesForScan(self,scan):
        """
        Input: Scan number as an integer or string
        Output: Time range over which data exists for that scan as a numpy array.
        Responsible: S. Corder
        Purpose: Return the times associated with a given timestamp.  This allows translation between scan and time.
        """
        return self.scansForTimes[int(scan)]

    def getScansForState(self,state):
        """
        Input: State id as an integer or string
        Output: The scan numbers, as a list, that use that specific state.
        Responsible: S. Corder
        Purpose: Return the scans that used a specific state.  This allos translation between state and scan.
        """

        scansForState = []
        for i in self.uniqueScans :
            if int(state) in self.statesForScans[i] : scansForState.append(i)
        return scansForState

    def getStatesForScan(self,scan):
        """
        Input: Scan number as a string or integer
        Output: States used during that scan.
        Responsible: S. Corder
        Purpose: Returns the states used during a given scan.  This allows translation between scan and state
        """

        return self.statesForScans[int(scan)]

    def getIntentsForScan(self,scan) :
        """
        Input: Scan as an integer or string.
        Output: Intent as a an array of strings with the names of the intents as values.
        Responsible: S. Corder
        Purpose: This returns the intents used in a specific scan allowing translation between scan and intent.
        """

        intentsForScan = []
        for i in range(len(self.intentsForStates)) :
            subIntents = self.intentsForStates[i]
            if int(scan) in self.getScansForState(i) : intentsForScan.extend(subIntents)
        return np.unique(intentsForScan)
            
    def getScansForIntent(self,intent) :
        """
        Input: Intent (as a string)
        Output: A numpy array of scans using the input intent.
        Responsible: S. Corder
        Purpose: This returns the scans using a specific intent.  This allows flagging based on intent and translation
                 between intent and scan.
        """

        scansForIntent = []
        for i in range(len(self.states)) :
            if intent in self.intentsForStates[self.states[i]] :
                scansForIntent.extend(self.getScansForState(self.states[i]))
        return np.unique(scansForIntent)
        
    def getScansForFieldID(self,field):
        """
        Input: Field, as an id.
        Output: Scans using that field
        Responsible: T. Hunter
        Purpose: This takes a field ID and tells you what scans it was used in.  It was
                 created to avoid a strange behavior of getScansForField for integer inputs.
        """
        indices = np.where(self.fields == field)
        return np.unique(self.scans[indices])
        
    def getScansForField(self,field):
        """
        Input: Field, as a name or id.
        Output: Scans using that field
        Responsible: S. Corder
        Purpose: This takes a field source and tells you what scans it was used in.
        """

        if not str(field).isdigit() : field = self.getFieldIdsForFieldName(field)
        indices = np.where(self.fields == field)
        return np.unique(self.scans[indices])

    def getFieldsForScans(self,scans,returnName=True):
        slist = []
        for scan in scans:
            slist.append(self.getFieldsForScan(scan))
        return([item for sublist in slist for item in sublist])
    
    def getFieldsForScan(self,scan,returnName=True):
        """
        Input: Scan as an integer or string
        Output: Field ids observed during that scan.
        Responsible: S. Corder
        Purpose: This takes a scan number and returns a field observed during that scan.  This allows translation between
                 scan and field.
        """

        indices = np.where(self.scans == int(scan))
        if returnName : return self.getFieldNamesForFieldId(np.unique(self.fields[indices]))
        else : return np.unique(self.fields[indices])

    def getFieldsForIntent(self,intent,returnName=True):
        """
        Input: intent as a string
        Output: field id as integer or array of names
        Responsible: S. Corder
        Purpose: This retrieves all of the fields that have been assigned a given intent during an observation.  
        """        
        _fields = []
        scans = self.getScansForIntent(intent)
        for i in scans :
            _field = self.getFieldsForScan(i)
            if _field not in _fields : _fields.append(_field)
        if returnName :
            return _fields
        else :
            return self.getFieldIdsForFieldName(_fields)
        
    def getFieldIdsForFieldName(self,sourceName):
        """
        Input: source name as string
        Output: field id as integer (actually it is returning the source id-Todd)
        Responsible: S. Corder
        Purpose: This translates between source/field name and field id.
        """
# The following fails because the case varies when .title() is applied: QSO vs. Qso, and TW Hya vs Tw Hya
#        return np.where(upper == sourceName.title())[0][0]
        if (type(sourceName) == list):
            sourceName = sourceName[0]
#        print "looking for %s in " % (sourceName), self.fieldNamesForFieldIds
        return np.where(self.fieldNamesForFieldIds == sourceName)[0]
        
    def getFieldNamesForFieldId(self,sourceId):
        """
        Input: field id (as string or integer)
        Output: field name
        Responsible: S. Corder
        Purpose: This translates between field id and field/source name.
        """
        if (type(sourceId) == int or type(sourceId) == np.int32 or type(sourceId) == np.int64 or type(sourceId) == str):
            if (len(self.fieldNamesForFieldIds) > int(sourceId)):
                # prevent "index out of bounds" error if field is not present 
                return self.fieldNamesForFieldIds[int(sourceId)]
            else:
                return (None)
        else:
            # Todd added this check which was necessary for the Antennae Band 7 mosaic
            return [self.fieldNamesForFieldIds[s] for s in sourceId]

    def getFieldsForTime(self,time,returnName=True):
        """
        Input: Time in casa native units, returnName (boolean).  If returnName is true, the name is returned, else the id is returned.
               Default is returnName=True
        Output: Field name or id (depending on value of returnName).
        Responsible: S. Corder
        Purpose: Allows the field id/name to be returned for a specific observation time.
        """

        for i in self.fieldsForTimes.keys() :
            if (time in self.fieldsForTimes[i]) :
                if returnName : return i
                else : return self.getFieldNamesForFieldId(i)

    def getTimesForField(self,field):
        """
        Input: Field name or id (as a string or integer)
        Output: Times as a numpy array over which that field was observed in casa native units.
        Responsible: S. Corder
        Purpose: This allows you to determine the data time stamps for observations of a specific field source.
        """

        if str(field).isdigit() : field = self.fieldNamesForFieldIds(int(field))
        return self.fieldsForTimes[field]


class TsysExplorer:
    """
    Used only by plotWeeklyTrx().
    Put something in about updating the Tsys on TDM observations in real time.
    """
    def __init__(self,inputMs,antenna=None,spwID=None,autoSubtableQuery=True,queryString='',cross_auto_all='all'):
        if autoSubtableQuery==False and queryString=='' : return 'Must either automatically generate the (autoSubtableQuery=True) or provide a subtable query string (queryString)'
        self.inputMs = inputMs
        self.valueMapping = ValueMapping(inputMs)
        if antenna == None :
            antenna = self.valueMapping.getAntennaNamesForAntennaId(0)
        self.antenna = antenna
        self.checkAntenna()
        if spwID == None :
            spwID = getChanAverSpwIDBaseBand0(inputMs)
        self.spwID = spwID
        self.elevation = None
        self.time      = None
 #       self.tcal      = None
        self.trx       = None
        self.tsky      = None
        self.tsys      = None
        self.freq      = None
        self.elevTime  = None
        self.scan      = []
        self.field     = []
        self.autoSubtableQuery = autoSubtableQuery
        self.queryString = queryString
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def getScanAndField(self):
        for i in self.time : 
            self.scan.append(self.valueMapping.getScansForTime(i))
            self.field.append(self.valueMapping.getFieldsForTime(i))

    def restrictTimeField(self):
        return

    def getElevation(self):
        mytb = tbtool()
        mytb.open("%s/POINTING" % self.inputMs)
        subtable = mytb.query("ANTENNA_ID == %s" % self.antenna)
        mytb.close()        
        self.elevation = subtable.getcol("DIRECTION")
        self.elevTime  = subtable.getcol("TIME")
        elev = []
        for i in self.time :
            diffTime = abs(self.elevTime - i)
            indy = np.where(diffTime == diffTime.min())
            elev.append(self.elevation[...,indy[0][0]]*180.0/math.pi)
        elev = np.array(elev)
#        print elev.shape,elev
        self.elevation = elev[:,1]

    def getFreq(self) :
        mytb = tbtool()
        mytb.open("%s/SPECTRAL_WINDOW" % self.inputMs)
        rows = mytb.selectrows(self.spwID)
        freqs = rows.getcol("CHAN_FREQ")
        mytb.close()
        self.freq = freqs
        
    def getTsysData(self) :
        self.time = self.subtable.getcol("TIME")-self.subtable.getcol("INTERVAL")/2.0
#        self.tcal = self.subtable.getcol("TCAL_SPECTRUM")
        self.trx  = self.subtable.getcol("TRX_SPECTRUM")
        self.tsky = self.subtable.getcol("TSKY_SPECTRUM")
        self.tsys = self.subtable.getcol("TSYS_SPECTRUM")

    def getAntenna(self) : return self.antenna

    def setAntenna(self,antenna) :
        self.antenna = antenna
        self.checkAntenna()
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def getInputMs(self) : return self.inputMs

    def setInputMs(self,inputMs) :
        self.inputMs = inputMs
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()
        self.ValueMapping.setInputMs(inputMs)

    def checkAntenna(self) :
        if self.antenna <> None : 
            self.antenna = str(self.antenna)
            if not self.antenna.isdigit() : self.antenna = getAntennaIndex(self.inputMs,self.antenna)

    def getSpwID(self) : return self.spwID

    def setSpwID(self,spwID) :
        self.spwID = spwID
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def makeSubtableQuery(self) :
        self.parameterList = []
        queryString = ''
        if self.antenna <> None : self.parameterList.append('ANTENNA_ID == %s' % self.antenna)
#        if self.field <> None    : self.parameterList.append('FIELD_ID == %s' % self.field)
        if self.spwID <> None    : self.parameterList.append('SPECTRAL_WINDOW_ID == %s' % self.spwID)
#        if self.state <> None    : self.parameterList.append('STATE_ID == %s' % self.state)
#        if self.scan <> None     : self.parameterList.append('SCAN_NUMBER == %s' % self.scan)
        for i in self.parameterList : queryString = self.appendQuery(queryString,i)
        self.queryString = queryString

    def appendQuery(self,queryString,additive) :
        if queryString == '' :
            if additive == '' : return queryString
            else : return additive
        else :
            if additive == '' : return queryString
            else : 
                queryString = queryString + ' && ' + additive
                return queryString

    def makeAutoSubtable(self) :
        self.checkAntenna()
        self.makeSubtableQuery()
        mytb = tbtool()
        mytb.open("%s/SYSCAL" % self.inputMs)
        self.subtable = mytb.query(self.queryString)
        mytb.close()
        self.getTsysData()
        self.getFreq()
        #self.getElevation()
        self.getScanAndField()

    def makeSubtable(self) :
        mytb = tbtool()
        mytb.open("%s/SYSCAL" % self.inputMs)
        self.subtable = mytb.query(self.queryString)
        mytb.close()
        self.getTsysData()
        self.getFreq()
        #self.getElevation()
        self.getScanAndField()

    def setAutoSubtableQuery(self,autoSubtableQuery) :
        self.autoSubtableQuery = autoSubtableQuery

    def getAutoSubtableQuery(self) : return self.autoSubtableQuery
        
def plotWeeklyTrx(uid,showPlots=False) :
    msFile=uid+'.ms'
    vm = ValueMapping(msFile)
    tsys = TsysExplorer(msFile,antenna=0,spwID=1)
    tsysSpw = vm.getSpwsForIntent('CALIBRATE_ATMOSPHERE#OFF_SOURCE')[1:]
    figureIndex = 0
    band = getBand(tsys.freq.mean())
    ObsDate=qa.time({'value' : vm.time[0],'unit': 's'}, form=['ymd'])
    fnDate=(''.join([str(l) for l in (ObsDate.split(':')[0].split('/'))]))
    fnDate2=(''.join([str(l) for l in ((''.join([str(l2) for l2 in (ObsDate.split('/'))])).split(':'))]))
    fDir=('/data/RADIO/TRX/AOS/%.8s' %(fnDate))
    if not os.path.exists(fDir): os.makedirs(fDir)
    F = open(fDir+'/TrxRB%s_%s.txt' %(band,fnDate2),'w')
    print >> F, ('%s %s ALMARB_%s' % (msFile, ObsDate, band))
    print >> F, ('Mean Freq. Mean Trx  Std. Dev.')
    print >> F, ('GHz.       K         K')
    badAnts = []
    for antenna in vm.uniqueAntennas :
        figureIndex +=1 
        if showPlots: pb.figure(figureIndex)
        meanVals = []
        meanFreq = []
        stdVals  = []
        for spw in tsysSpw :
            if vm.spwInfo[spw]['numChannels'] == 128 :
                tsys.setSpwID(int(spw))
                tsys.setAntenna(antenna)
                meanFreq.append(tsys.freq.mean())
                meanVals+=(list(tsys.trx[:,3:125].mean(1).transpose()[0]))
                stdVals+=(list(tsys.trx[:,3:125].std(1).transpose()[0]))
                if showPlots:
                    pb.plot(tsys.freq[3:125]/1e9,tsys.trx[0,3:125],'g.')
                    pb.plot(tsys.freq[3:125]/1e9,tsys.trx[1,3:125],'b.')
        print >> F, antenna
        print >> F,('\n'.join(['%6.2f'%round(float(l1/1e9),2)+"     "+'%6.2f'%round(float(l2),2)+"     "+'%6.2f'%round(float(l3),2) for (l1,l2,l3) in zip(meanFreq,meanVals,stdVals)]))
#        specVal100 = {3: 60, 6: 136, 7: 219, 9: 261} #This is specification over 100% of the bands
        specVal80 = {3: 45, 6: 83, 7: 147, 9: 175} #This is specification over 80% of the bands

        if band == 3 : spec = specVal80[3]
        elif band == 6 : spec = specVal80[6]
        elif band == 7 : spec = specVal80[7]
        elif band == 9 : spec = specVal80[9]
        else: return 'Not a valid weekly Trx testing Frequency'
        for i in meanVals :
            if i >= spec :
                badAnts.append(antenna)
        if showPlots:
            pb.plot((100*np.arange(len(meanFreq))),(spec*np.ones(len(meanFreq))),'r-')
            pb.xlim(meanFreq[0]/1e9-10,meanFreq[len(meanFreq)-1]/1e9+10)
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Trx (K)')
            pb.suptitle('%s %s %s' % (antenna,qa.time({'value' : vm.time[0],'unit': 's'},form=['ymd']),msFile), size='14')
            pb.title('Green--Pol0   Blue--Pol1   Red--Specification(80%)', size='12')
            pb.savefig(fDir+'/TrxRB%s%s_%s.png' % (band,antenna,fnDate2))
    print >> F, "Problematic Antennas: %s" % str(badAnts)
    F.close()    
    print "Antennas: %s seem to have problems." % str(badAnts)
    raw_input("Hit Return to quit: ")
#    pb.close('all')
#Keep on having problem with close all
    fig_numbers = [x.num
               for x in matplotlib._pylab_helpers.Gcf.get_all_fig_managers()]
    for n in fig_numbers: pb.close(n)

class CalTableExplorer:
    """Stuff: Only works for antenna based solutions"""
    """Stuff to add: start and end channels (started, but need to make it consaistent, good metrics for differences"""
    """plotting routines, interpolation? In freq and/or time?  Basics are done"""
    """I need to make the residual functions make sense, I think the names are screwy. """
    
    def __init__(self,inputTable,antenna=None,spwID=None,feed=None,scan=None,state=None,field=None,autoSubtableQuery=True,queryString='',startChan=None,endChan=None):
        self.inputTable   = inputTable
        self.inputMs      = self.getMS_NAME(self.inputTable)
        self.ValueMapping = ValueMapping(self.inputMs)
        self.antenna     = antenna
        self.checkAntenna()
        self.startChan   = startChan
        self.endChan     = endChan
        self.spwID        = spwID
        self.feed         = feed
        self.scan         = scan
        self.state        = state
        self.field        = field
        self.checkField()
        self.getCalDescSpwIDMapping()
        if spwID == None : self.spwID = self.calDescSpwIDMapping[0]
        self.autoSubtableQuery = autoSubtableQuery
        self.queryString  = queryString
        if self.autoSubtableQuery == True :
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def getFreq(self) :
        mytb = tbtool()
        mytb.open("%s/SPECTRAL_WINDOW" % self.inputMs)
        rows = mytb.selectrows(self.spwID)
        freqs = rows.getcol("CHAN_FREQ")
        mytb.close()
        self.freq = freqs

    def getTimeAndInterval(self) :
        self.time     = self.subtable.getcol("TIME")
        self.mjd      = mjdSecondsVectorToMJD(self.time)
        self.ut       = mjdVectorToUTHours(self.mjd)
        self.interval = self.subtable.getcol("INTERVAL")

    def getFit(self) :
        self.gain     = self.subtable.getcol("GAIN")
        self.solOkay  = self.subtable.getcol("SOLUTION_OK")
        self.flags    = self.subtable.getcol("FLAG")
        self.fit      = self.subtable.getcol("FIT")
        self.snr      = self.subtable.getcol("SNR")
        self.real     = np.real(self.gain)
        self.imag     = np.imag(self.gain)
        self.phase = np.arctan2(self.imag,self.real)
        self.amp   = abs(self.gain)

    def plotFit(self,pol,xtype=''):
        date = (mjdSecondsToMJDandUT(self.time[0])[1]).split()[0]
        if (xtype=='ut'):
            pb.plot(self.ut,self.gain[pol,:,:][0],'b.')
            pb.xlabel('UT (hours)')
        elif (xtype=='mjd'):
            pb.plot(self.mjd,self.gain[pol,:,:][0],'b.')
            pb.xlabel('MJD days')
        else:
            pb.plot(self.time,self.gain[pol,:,:][0],'b.')
            pb.xlabel('MJD seconds')
        pb.ylabel('Gain')
        pb.title(date)
        
    def timeAverageSolutions(self) :
        self.tavgGain  = self.gain.mean(-1)
        self.tavgReal  = self.tavgGain.real
        self.tavgImag  = self.tavgGain.imag
        self.tavgPhase = np.arctan2(self.tavgImag,self.tavgReal)
        self.tavgAmp   = abs(self.tavgGain)
        
    def freqAverageSolutions(self) :
        self.favgGain  = self.gain[...,self.startChan:self.endChan,...].mean(1)
        self.favgReal  = self.favgGain.real
        self.favgImag  = self.favgGain.imag
        self.favgPhase = np.arctan2(self.favgImag,self.favgReal)
        self.favgAmp   = abs(self.favgGain)

    def generateSpectralResiduals(self) :
        self.fresidGain = self.gain
        for i in range(self.gain.shape[-1]) :
            self.fresidGain[:,:,i] = self.fresidGain[:,:,i]-self.tavgGain
        self.fresidGain = self.fresidGain
        self.fresidReal = self.fresidGain.real
        self.fresidImag = self.fresidGain.imag
        self.fresidPhase = np.arctan2(self.fresidImag,self.fresidReal)
        self.fresidAmp   = abs(self.fresidGain)

    def unwrapPhase(self,simple=True) :
        from math import pi
        phaseShape = self.phase.shape
        for i in range(phaseShape[2]-1) :
            diff = self.phase[:,:,i]-self.phase[:,:,i+1]
            _diffg = (diff > 1.*pi)*2*pi
            _diffl = (diff < -1.*pi)*2*pi
            self.phase[:,:,i+1] = self.phase[:,:,i+1]+_diffg-_diffl

    def generateTimeResiduals(self) :
        self.tresidGain = self.gain
        for i in range(self.gain.shape[1]) :
            self.tresidGain[:,i,:] = self.tresidGain[:,i,:]-self.favgGain
        self.tresidGain = self.tresidGain[...,self.startChan:self.endChan,...]
        self.tresidFreq = self.freq[self.startChan:self.endChan]
        self.tresidReal = self.tresidGain.real
        self.tresidImag = self.tresidGain.imag
        self.tresidPhase = np.arctan2(self.tresidImag,self.tresidReal)
        self.tresidAmp   = abs(self.tresidGain)

    def getMS_NAME(self,inputTable) :
        mytb = tbtool()
        mytb.open("%s/CAL_DESC" % inputTable)
        msFiles = mytb.getcol("MS_NAME")
        mytb.close()
        return np.unique(msFiles)[0]

    def getCalDescForSpwID(self,calDesc) :
        try:
            return np.where(self.calDescSpwIDMapping[0] == self.spwID)[0][0]
        except:
            print 'The identified spwID does not have a solution in this table.'
            sys.exit()
        
    def getCalDescSpwIDMapping(self) :
        mytb = tbtool()
        mytb.open("%s/CAL_DESC" % self.inputTable)
        self.calDescSpwIDMapping = mytb.getcol("SPECTRAL_WINDOW_ID")
        mytb.close()

    def setField(self,field) :
        self.field = field
        self.checkField()
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def getField(self) : return self.field

    def checkField(self) :
        if self.field <> None : 
            self.field = str(self.field)
            if not self.field.isdigit() : self.field = self.ValueMapping.getFieldIdsForFieldName(self.field)[0]

    def checkAntenna(self) :
        if self.antenna <> None : 
            self.antenna = str(self.antenna)
            if not self.antenna.isdigit() : self.antenna = getAntennaIndex(self.inputMs,self.antenna)

    def getAntenna(self) : return self.antenna

    def setAntenna(self,antenna) :
        self.antenna = antenna
        self.checkAntenna()
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def getInputTable(self) : return self.inputTable

    def setInputTable(self,inputMs) :
        self.inputTable = inputTable
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()
        self.ValueMapping.setInputMs(inputMs)

    def getSpwID(self) : return self.spwID

    def setSpwID(self,spwID) :
        self.spwID = spwID
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def setScan(self,scan) :
        self.scan = scan
        if self.autoSubtableQueyry == True :
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def setFeed(self,feed) :
        self.feed = feed
        if self.autoSubtableQueyry == True :
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def setState(self,state) : 
        self.state = state
        if self.autoSubtableQueyry == True :
            self.makeAutoSubtable()
        else : self.makeSubtable()

    def getScan(self) : return self.scan

    def getFeed(self) : return self.feed

    def getState(self) : return self.state

    def makeSubtableQuery(self) :
        self.parameterList = []
        queryString = ''
        if self.antenna <> None : self.parameterList.append('ANTENNA1 == %s' % self.antenna)
        if self.field <> None    : self.parameterList.append('FIELD_ID == %s' % self.field)
        if self.spwID <> None    : self.parameterList.append('CAL_DESC_ID == %s' % self.getCalDescForSpwID(self.spwID))
        if self.state <> None    : self.parameterList.append('STATE_ID == %s' % self.state)
        if self.scan <> None     : self.parameterList.append('SCAN_NUMBER == %s' % self.scan)
        if self.feed <> None     : self.parameterList.append('FEED_ID == %s' % self.feed)
        for i in self.parameterList : queryString = self.appendQuery(queryString,i)
        self.queryString = queryString

    def appendQuery(self,queryString,additive) :
        if queryString == '' :
            if additive == '' : return queryString
            else : return additive
        else :
            if additive == '' : return queryString
            else : 
                queryString = queryString + ' && ' + additive
                return queryString

    def makeAutoSubtable(self) :
        self.checkAntenna()
        self.makeSubtableQuery()
        mytb = tbtool()
        mytb.open("%s" % self.inputTable)
        self.subtable = mytb.query(self.queryString)
        mytb.close()
        self.getFreq()
        self.getTimeAndInterval()
        self.getFit()
#        self.freqAverageSolutions()
#        self.timeAverageSolutions()
#        self.generateSpectralResiduals()
#        self.generateTimeResiduals()

    def makeSubtable(self) :
        mytb = tbtool()
        mytb.open("%s" % self.inputTable)
        self.subtable = mytb.query(self.queryString)
        mytb.close()
        self.getFreq()
        self.getTimeAndInterval()
        self.getFit()
        self.freqAverageSolutions()
        self.timeAverageSolutions()
        self.generateFrequencyResiduals()
        self.generateTimeResiduals()

    def setAutoSubtableQuery(self,autoSubtableQuery) :
        self.autoSubtableQuery = autoSubtableQuery

    def getAutoSubtableQuery(self) : return self.autoSubtableQuery

class ScaleGainsClass(CalTableExplorer):
    
    def __init__(self,calTable) :
        self.calTable = calTable
        CalTableExplorer.__init__(self,self.calTable)
        self.vm      = ValueMapping(self.inputMs)

    def calculateGainsScaling(self,calfieldL,calfieldH,caltableL,caltableH):

        mytb = tbtool()
        mytb.open("%s" % caltableL,nomodify=False)
        tableRow = mytb.selectrows(0,'table_junk')
        polgainshape=len(tableRow.getcol('GAIN'))
        tb.close()	
        
        ####### Setting up dictionaries for low frequency table ######

        # Initialising cal to spw mapping dictionary
        self.calSpwMapL = {}

        #open descriptor file
        mytb.open("%s/CAL_DESC" % caltableL ,nomodify=False)

        for k in range(mytb.nrows()):
            tableRow = mytb.selectrows(k,'table_junk')
            self.calSpwMapL[k] = tableRow.getcol('SPECTRAL_WINDOW_ID')[...,0]
	       
        mytb.close()
	
        #Delete file containing each table row    
        os.system('rm -rf table_junk')

        ####### Setting up dictionaries for high frequency table ######

        # Initialising cal to spw mapping dictionary
        self.calSpwMapH = {}

        #open descriptor file
        mytb = tbtool()
        mytb.open("%s/CAL_DESC" % caltableH ,nomodify=False)

        for k in range(mytb.nrows()):
            tableRow = mytb.selectrows(k,'table_junk')
            self.calSpwMapH[k] = tableRow.getcol('SPECTRAL_WINDOW_ID')[...,0]
	       
        mytb.close()
	
        #Delete file containing each table row    
        os.system('rm -rf table_junk')

        phasediff = np.zeros([self.vm.uniqueAntennas.shape[0],len(self.calSpwMapL),polgainshape]) 

        for pol in range(polgainshape):
             for calid in self.calSpwMapL:
                for antname1 in self.vm.uniqueAntennas:
           
                    ant = self.vm.getAntennaIdsForAntennaName(antname1)
                    spw = self.calSpwMapL[calid]
                     
                    print "Antenna, spw, Corr", antname1, spw, pol

                    ###### Caltable low: read in and unwrap phases ######

                    ct = CalTableExplorer("%s" % caltableL,spwID=spw,field=calfieldL)
                    
                    ct.setAntenna(antname1)
                    
                    phaseLpol=ct.phase[pol,0,:]
                    sizeL=ct.phase[pol,0,:].shape
           
                    ct.unwrapPhase()
                    
                    timeL=ct.time

                    pLinterp=interp1d(timeL,phaseLpol,kind=1,bounds_error=False,fill_value=np.nan)
                    
                    ###### Caltable high: read in and unwrap phases ######

                    if spw+4 in self.calSpwMapH.values():

                        ct = CalTableExplorer("%s" % caltableH,spwID=spw+4,field=calfieldH)
                    
                        ct.setAntenna(antname1)

                        phaseHpol=ct.phase[pol,0,:]

                        ct.unwrapPhase()
                        
                        timeH =ct.time

                        # Find interpolated values of low frequency at high data times
                        phaseLtoH= pLinterp(timeH)

                    else:
                        phaseHpol=np.zeros(sizeL)
                        phaseLtoH=np.zeros(sizeL)

                    keep = ~np.isnan(phaseHpol) & ~np.isnan(phaseLtoH)
                    
                    phasediff[ant,spw,pol] = np.mean(phaseHpol[keep]-phaseLtoH[keep])
                    
        return phasediff


    def scaleGains(self,phasediff,newTable=None) :
        
        # Define table name
        if newTable == None :
            self.newTable = '%s.scaled' % self.calTable
        else :
            self.newTable = newTable
            
        # Create copy of table, deep=True copies all tables not just data
        tb.open(self.calTable,nomodify=False)
        tb.copy(self.newTable,deep=True,valuecopy=True)
        tb.close()
        
        # Initialising cal to spw mapping dictionary, and row holders
	self.calSpwMap = {}

	#open descriptor file
        tb.open("%s/CAL_DESC" % self.calTable,nomodify=False)

        #Initialise row holder
	descrowvals  = {}

        for k in range(tb.nrows()):
            tableRow = tb.selectrows(k,'table_junk')
	    #Convert row to a dictionary
	    for i in tableRow.colnames():
                descrowvals[i] = tableRow.getcol(i)[...,0]
            self.calSpwMap[k] = descrowvals['SPECTRAL_WINDOW_ID'][0]
	       
	    # Write out to new table
	    #self.reconstructRow(descrowvalsp,"%s" % self.newTable)

	tb.close()
	
	#Delete file containing each table row    
	os.system('rm -rf table_junk')

	#Open caltable, find number of rows in table
        tb.open("%s" % self.calTable,nomodify=False)
        numsoln=tb.nrows()
        tb.close()

	#Initialise row holder
	rowvals  = {}

        # Loop over rows/solutions in caltable
        for k in range(numsoln) :

            tb.open("%s" % self.calTable,nomodify=False)

            #Read each row and write it into table_junk
            tableRow = tb.selectrows(k,'table_junk')
            
	    #Convert row to a dictionary
            for i in tableRow.colnames():
	        if 'REF_' in i : continue
	        else:
                    rowvals[i] = tableRow.getcol(i)[...,0]

            tb.close()

            #Set atribute of this class = rowvals
            self.rowvals = rowvals
                            
	    #Copy parameters for a given solution
	    self.rowvalsp = rowvals.copy()
                              
            #initialise scaled phase and amp arrays         
	    sphase = np.zeros(self.rowvals['GAIN'].shape)
	    samp = np.zeros(self.rowvals['GAIN'].shape)

	    ant = self.rowvalsp['ANTENNA1']
	    spw = self.calSpwMap[int(self.rowvalsp['CAL_DESC_ID'])]

            sphase[:,:]=np.angle(self.rowvals['GAIN']) + phasediff[ant,spw][:,np.newaxis]
            samp[:,:]=np.abs(self.rowvals['GAIN'])
   
            self.rowvalsp['GAIN'] = samp * np.exp(sp.sqrt(-1.)*sphase)
       
	    # Write out result to new table
	    self.reconstructRow(self.rowvalsp,"%s" % self.newTable)
             
        tb.open("%s" % self.newTable,nomodify=False)
        tb.removerows(range(numsoln))
        tb.close()

        #Delete table_junk file            
        os.system("rm -rf table_junk")
        
        #Remove table locks
        os.system("rm -rf %s/table.lock" % self.calTable)
        os.system("rm -rf %s/CAL_DESC/table.lock" % self.calTable)

    def reconstructRow(self,rowVals,tableName,tableRow=None) :
        tb.open(tableName,nomodify=False)
        if tableRow == None :
            tb.addrows()
            rownum = tb.nrows()-1L
        else :
            rownum = tableRow
        for i in rowVals.keys() :
            if rowVals[i].shape == () : isRealArray = False
            else : isRealArray = True
            rownum,i,rowVals[i]
            try:
                dt = tb.coldatatype(i)
                if dt == 'boolean' :
                    if not isRealArray :
                        if not rowVals[i] :
                            tb.putcell(i,rownum,0)
                        else :
                            tb.putcell(i,rownum,1)
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'double' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'float' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i]))
                    else :
                        junk = np.array(rowVals[i],dtype='float32')
                        tb.putcell(i,rownum,junk)                    
                elif dt == 'integer' :
                    if not isRealArray :
                        tb.putcell(i,rownum,int(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'string' :
                    if not isRealArray :
                        tb.putcell(i,rownum,str(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                else :
                    tb.putcell(i,rownum,rowVals[i])
            except:
                print 'skipping'
        tb.close()
#                tb.putcell(i,rownum,rowVals[i])


class InterpolateTsys(CalTableExplorer):
    """The Flag "iKnowWhatIAmDoing" should be used with care.  It implies that the user knows very well that the
       ordering of the basebands vs frequency was proper and consistent between the tdm and fdm mode and that the
       tdm mode was listed in the OT ranging from BB1, BB2, BB3 and BB4, not some other order.  Failure to use this
       options will in some cases result in slightly poorer performance and slightly better in other cases...thus
       you should really know what you are doing before you use it.
    """
       
    def __init__(self,calTable) :
        self.calTable = calTable
        self.inputMs = self.getMS_NAME(calTable)
        #CalTableExplorer.__init__(self,self.calTable)
        self.vm      = ValueMapping(self.inputMs)

    def getMS_NAME(self,inputTable) :
        tb.open("%s/CAL_DESC" % inputTable)
        msFiles = tb.getcol("MS_NAME")
        tb.close()
        return np.unique(msFiles)[0]

    def setCalTable(self,calTable) :
        self.calTable = calTable
        CalTableExplorer.__init__(self.calTable)
        self.vm.setInputMs(self.inputMs)

    def correctBadTimes(self, force=False):
        tb.open(self.calTable,nomodify=False)
        time=tb.getcol('TIME')
        interval = tb.getcol('INTERVAL')
        if max(time) < 7.0e9 and force == False:
            return "This process appears to have been done already."
        else :
            corr_time = time-interval/2.0
            tb.putcol("TIME",corr_time)
        tb.close()
        os.system("rm -rf %s/table.lock" % self.calTable)

    def assignFieldAndScanToSolution(self, iKnowWhatImDoing=False) :
        tb.open(self.calTable,nomodify=False)
        fieldId = tb.getcol("FIELD_ID")
        scans   = tb.getcol("SCAN_NUMBER")
        times   = tb.getcol("TIME")
        linesToRemove = []
        for i in range(tb.nrows()):
            _scan = self.vm.getScansForTime(times[i],5e-6)
            if _scan is not None:
                  fieldId[i] = self.vm.getFieldsForScan(_scan,False)
                  scans[i] = _scan
            else:
                  linesToRemove.append(i)
        if iKnowWhatImDoing:
              for i in sorted(linesToRemove, reverse=True):
                  fieldId = np.delete(fieldId, i)
                  scans = np.delete(scans, i)
                  tb.removerows(i)
        tb.putcol('FIELD_ID',fieldId)
        tb.putcol("SCAN_NUMBER",scans)
        tb.close()
        os.system("rm -rf %s/table.lock" % self.calTable)
        

    def getTdmFdmSpw(self,iKnowWhatIAmDoing=True):
        """
        Input: None
        Output: None
        Responsible: S. Corder
        Purpose:
        """
        tb.open("%s/SYSCAL" % self.inputMs)
        tsysTdmSpw = sorted(dict.fromkeys(tb.getcol('SPECTRAL_WINDOW_ID')).keys())
        tb.close()
        tb.open("%s/SPECTRAL_WINDOW" % self.inputMs)
        #self.tdm = tb.query("(NUM_CHAN == 128) or (NUM_CHAN == 256) or (NUM_CHAN == 64)")
        self.tdm = tb.selectrows([int(i) for i in tsysTdmSpw])
        self.tdmSpw = self.tdm.rownumbers()
        if self.tdm.nrows() == 1: self.tdmSpw = [self.tdmSpw]
        self.tdmBBC = self.tdm.getcol('BBC_NO')
        self.fdm = tb.query("(NUM_CHAN == 7680) or (NUM_CHAN == 3840) or (NUM_CHAN == 1920) or (NUM_CHAN == 4096)")
        self.fdmSpw = self.fdm.rownumbers()
        if self.fdm.nrows() == 1: self.fdmSpw = [self.fdmSpw]
        self.fdmBBC = self.fdm.getcol('BBC_NO')
        if iKnowWhatIAmDoing : self.fdmBBC.sort()
        fdmFreqs = self.fdm.getcol('CHAN_FREQ')
        tdmFreqs = self.tdm.getcol('CHAN_FREQ')
        self.fdmFreqs = fdmFreqs
        self.tdmFreqs = tdmFreqs
        tb.close()
        self.tdmFdmMap = {}
        self.fdmTdmMap = {}
        for i in range(len(fdmFreqs[0])) :
            for j in range(len(tdmFreqs[0])) :
                delT = abs(tdmFreqs[1,j]-tdmFreqs[0,j])   # Added by S. Corder 2012/5/18
                minF = np.min(fdmFreqs[:,i])
                maxF = np.max(fdmFreqs[:,i])
                minT = np.min(tdmFreqs[:,j])
                maxT = np.max(tdmFreqs[:,j])
#                if ((minF >= minT) and (maxF <= maxT)) :  # Change requested by S. Corder 2012/5/18
                if ((minF >= (minT-0.5*delT)) and (maxF <= (maxT+0.5*delT))) :
                    if self.fdmTdmMap.has_key(int(self.fdmSpw[i])) :
                        if self.fdmBBC[i] == self.tdmBBC[j] :
                           self.fdmTdmMap[self.fdmSpw[i]] = self.tdmSpw[j]
                    else :
                        self.fdmTdmMap[self.fdmSpw[i]] = self.tdmSpw[j]
        for k,v in self.fdmTdmMap.iteritems() :
            self.tdmFdmMap[v] = self.tdmFdmMap.get(v,[])
            self.tdmFdmMap[v].append(k)
        print '# Mapping of Tsys and science spws.'
        print '# Please check that you have only one science spw per Tsys spw.'
        print '# ' + str(self.tdmFdmMap)
            
    def interpolateTsys(self,newTable=None,interpType='linear') :
        self.badRows = []
        if newTable == None :
            self.newTable = '%s.fdm' % self.calTable
        else :
            self.newTable = newTable
        tb.open(self.calTable,nomodify=False)
        tb.copy(self.newTable,deep=True,valuecopy=True)
        tb.close()
        tb.open("%s/CAL_DESC" % self.calTable,nomodify=False)
        self.numCalSol = tb.nrows()
        self.calSpwMap = {}
        tb.close()
        noSpw = []
        for k in range(self.numCalSol) :
            tb.open("%s/CAL_DESC" % self.calTable,nomodify=False)            
            tableRow = tb.selectrows(k,'table_junk')
            rowvals  = self.extractRow(tableRow)
            x = self.fdmFreqs.shape[0]
            y = rowvals['CHAN_WIDTH'].shape[0]
            y1 = rowvals['CHAN_RANGE'].shape[0]
            self.calSpwMap[k] = rowvals['SPECTRAL_WINDOW_ID'][0]
            self.calSpwMap[tb.nrows()+k]  = self.fdmSpw[k]
            rowvals['MS_NAME'] = np.array(rowvals['MS_NAME'],'str')
            rowvals['JONES_TYPE'] = np.array(rowvals['JONES_TYPE'],'str')
            rowvals['NUM_CHAN'] = np.array([x],'int')
            rowvals['SPECTRAL_WINDOW_ID'] = np.array([self.fdmSpw[k]],'int')
            rowvals['CHAN_FREQ'] = np.zeros((1,x))
            rowvals['CHAN_WIDTH'] = np.zeros((1,x))
            rowvals['CHAN_RANGE'] = np.zeros((y1,1,x),'int')
            rowvals['POLARIZATION_TYPE'] = np.zeros((1,x),'str')
            if self.fdmSpw[k] in self.fdmTdmMap.keys() : self.reconstructRow(rowvals,"%s/CAL_DESC" % self.newTable)
            tb.close()
        os.system('rm -rf table_junk')
        tb.open("%s/CAL_DESC" % self.calTable)
        calIds = tb.getcol("SPECTRAL_WINDOW_ID")
        tb.close()
        tb.open("%s" % self.calTable,nomodify=False)
        self.calrows = tb.nrows()
        self.spwCalMap = {}
        tb.close()
        noData = []
        for k,v in self.calSpwMap.iteritems() :
            self.spwCalMap[v] = self.spwCalMap.get(v,[])
            self.spwCalMap[v].append(k)
        counter = 0
        countMe = 0
        for k in range(self.calrows) :
#            if self.calSpwMap.has_key(int(rowvals['CAL_DESC_ID'])):
            tb.open("%s" % self.calTable,nomodify=False)
            tableRow = tb.selectrows(k,'table_junk')
            tb.close()
            rowvals = self.extractRow(tableRow)
            self.rowvals = rowvals
            if 1:
                tdmSpwID = self.calSpwMap[int(rowvals['CAL_DESC_ID'])]
                tdmRow = self.tdmSpw.index(tdmSpwID)
                tdmFreq = self.tdmFreqs[:,tdmRow]
                self.tdmFreq = tdmFreq
                if self.tdmFdmMap.has_key(tdmSpwID):
                    for i in self.tdmFdmMap[tdmSpwID] :
                        fdmSpwID = i
                        fdmRow = self.fdmSpw.index(i)
                        fdmFreq = self.fdmFreqs[:,fdmRow]
                        self.fdmFreq = fdmFreq
                        rowvalsp = rowvals.copy()
                        self.rowvalsp = rowvalsp
                        self.rowvals  = rowvals
                        val = int(self.spwCalMap[i][0])-self.numCalSol
                        rowvalsp['CAL_DESC_ID'] = np.array(int(self.spwCalMap[i][0])-self.numCalSol,'int')
                        if interpType == 'cubicspline' :
                            _real = (self.interpSpline(tdmFreq,fdmFreq,np.real(rowvals['GAIN'])))
                            _imag = (self.interpSpline(tdmFreq,fdmFreq,np.imag(rowvals['GAIN'])))
                            rowvalsp['GAIN'] = np.zeros(_real.shape,'complex64')
                            for i in range(rowvalsp['GAIN'].shape[0]) :
                                for j in range(rowvalsp['GAIN'].shape[1]) :
                                    rowvalsp['GAIN'][i,j] = np.complex(_real[i,j],_imag[i,j])
#                            rowvalsp['GAIN'] = (self.interpSpline(tdmFreq,fdmFreq,np.real(rowvals['GAIN'])))
                            rowvalsp['SOLUTION_OK'] = np.ones((rowvals['SOLUTION_OK'].shape[0],x),'bool') #self.interpSpline(tdmFreq,fdmFreq,rowvals['SOLUTION_OK'])
                            rowvalsp['FIT'] = np.ones((1,x),'float32') #self.interpSpline(tdmFreq,fdmFreq,rowvals['FIT'])
                            rowvalsp['FIT_WEIGHT'] = np.ones((1,x),'float32') #self.interpSpline(tdmFreq,fdmFreq,rowvals['FIT_WEIGHT'])
                            rowvalsp['FLAG'] = np.zeros((rowvals['FLAG'].shape[0],x),'bool') #self.interpSpline(tdmFreq,fdmFreq,rowvals['FLAG'])
                            rowvalsp['SNR'] = np.ones((rowvals['SNR'].shape[0],x),'float32') #self.interpSpline(tdmFreq,fdmFreq,rowvals['SNR'])
                        elif interpType == 'linear' :
                            _real = (self.interpLinear(tdmFreq,fdmFreq,np.real(rowvals['GAIN'])))
                            _imag = (self.interpLinear(tdmFreq,fdmFreq,np.imag(rowvals['GAIN'])))
                            rowvalsp['GAIN'] = np.zeros(_real.shape,'complex64')
                            for i in range(rowvalsp['GAIN'].shape[0]) :
                                for j in range(rowvalsp['GAIN'].shape[1]) :
                                    rowvalsp['GAIN'][i,j] = np.complex(_real[i,j],_imag[i,j])
#                            rowvalsp['GAIN'] = (self.interpLinear(tdmFreq,fdmFreq,np.real(rowvals['GAIN'])))
                            rowvalsp['SOLUTION_OK'] = np.ones((rowvals['SOLUTION_OK'].shape[0],x),'bool') #self.interpLinear(tdmFreq,fdmFreq,rowvals['SOLUTION_OK'])
                            rowvalsp['FIT'] = np.ones((1,x),'float32') #self.interpLinear(tdmFreq,fdmFreq,rowvals['FIT'])
                            rowvalsp['FIT_WEIGHT'] = np.ones((1,x),'float32') #self.interpLinear(tdmFreq,fdmFreq,rowvals['FIT_WEIGHT'])
                            rowvalsp['FLAG'] = np.zeros((rowvals['FLAG'].shape[0],x),'bool') #self.interpLinear(tdmFreq,fdmFreq,rowvals['FLAG'])
                            rowvalsp['SNR'] = np.ones((rowvals['SNR'].shape[0],x),'float32') #self.interpLinear(tdmFreq,fdmFreq,rowvals['SNR'])
                        else :
                            return "Invalid interpType, please pick linear or cubicspline."
                        self.reconstructRow(rowvalsp,"%s" % self.newTable,counter)
                        counter+=1
#                        sys.stdin.readline()
                    countMe+=1
                else :
                    #self.nullRow("%s" % self.newTable,k)
                    noData.append(counter)
        os.system("rm -rf table_junk")
        print counter
        print noData
        tb.close()
        if noData <> [] : 
            if min(makeList(noData)) < self.calrows :
                while max(makeList(noData)) >= self.calrows :
                    noData.remove(max(makeList(noData)))
        os.system("rm -rf %s/table.lock" % self.newTable)    
        tb.open(self.newTable,nomodify=False)
        if noData <> [] : tb.removerows(noData)
        tb.close()
        os.system("rm -rf %s/CAL_DESC/table.lock" % self.newTable)
        tb.open("%s/CAL_DESC" % self.newTable,nomodify=False)
        tb.removerows(range(self.numCalSol))
        tb.close()
        os.system("rm -rf %s/table.lock" % self.calTable)
        os.system("rm -rf %s/CAL_DESC/table.lock" % self.calTable)
        os.system("rm -rf table_junk")

       
    def interpLinear(self,tmpFreq,newFreq,tmpData) :
        tmpFreq,tmpData,checker = self.checkOrder(tmpFreq,tmpData)
        if newFreq[1]-newFreq[0] < 0 : newFreq = newFreq[::-1]
        newData = np.zeros((tmpData.shape[0],newFreq.shape[0]))
        for i in range(tmpData.shape[0]) :
            newData[i,:] = np.interp(newFreq,tmpFreq,tmpData[i,:])
        if checker :
            return newData.transpose()[::-1].transpose()
        else :
            return newData

    def interpSpline(self,tmpFreq,newFreq,tmpData) :
        tmpFreq,tmpData,checker = self.checkOrder(tmpFreq,tmpData)        
        newData = np.zeros((tmpData.shape[0],newFreq.shape[0]))
        for i in range(tmpData.shape[0]) :
            tck = splrep(tmpFreq,tmpData[i,:],s=0)
            newData[i,:] = splev(newFreq,tck,der=0)
        if checker :
            return newData.transpose()[::-1].transpose()
        else :
            return newData

    def checkOrder(self,inpFreq,inpData) :
        if ((inpFreq[1]-inpFreq[0]) > 0) :
            return inpFreq,inpData,0
        else :
            return inpFreq[::-1],inpData.transpose()[::-1].transpose(),1
        
    def extractRow(self,row) :
        rowvals = {}
        for i in row.colnames() :
            try:
                rowvals[i] = row.getcol(i)[...,0]
            except:
                print "Unable to extract data for %s" % i
        return rowvals

    def reconstructRow1(self,tableName,tableRow=None) :
        tb.open(tableName,nomodify=False)
        if tableRow == None : tb.addrows()
        else :
            self.badRows.append(tableRow)
        tb.close()

    def nullRow(self,tableName,tableRow) :
        tb.open(tableName,nomodify=False)
        row = tb.selectrows(tableRow,'table_null')
        rowVals = self.extractRow(row)
        for i in rowVals.keys() :
            if rowVals[i].shape == () : isRealArray = False
            else : isRealArray = True
            row,i,rowVals[i]
            try:
                dt = tb.coldatatype(i)
                if dt == 'boolean' :
                    if not isRealArray :
                        if not rowVals[i] :
                            tb.putcell(i,rownum,0)
                        else :
                            tb.putcell(i,rownum,1)
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'double' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i])*0)
                    else :
                        tb.putcell(i,rownum,rowVals[i]*0)
                elif dt == 'float' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i])*0)
                    else :
                        junk = np.array(rowVals[i]*0,dtype='float32')
                        tb.putcell(i,rownum,junk)                    
                elif dt == 'integer' :
                    if not isRealArray :
                        tb.putcell(i,rownum,int(rowVals[i]*0))
                    else :
                        tb.putcell(i,rownum,rowVals[i]*0)
                elif dt == 'string' :
                    if not isRealArray :
                        tb.putcell(i,rownum,str(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i]*0)
                else :
                    tb.putcell(i,rownum,rowVals[i])
            except:
                print 'skipping'
        tb.close()
        os.system("rm -rf table_null")

    def reconstructRow(self,rowVals,tableName,tableRow=None) :
        tb.open(tableName,nomodify=False)
        if tableRow == None :
            tb.addrows()
            rownum = tb.nrows()-1L
        else :
            rownum = tableRow
        for i in rowVals.keys() :
            if rowVals[i].shape == () : isRealArray = False
            else : isRealArray = True
            rownum,i,rowVals[i]
            try:
                dt = tb.coldatatype(i)
                if dt == 'boolean' :
                    if not isRealArray :
                        if not rowVals[i] :
                            tb.putcell(i,rownum,0)
                        else :
                            tb.putcell(i,rownum,1)
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'double' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'float' :
                    if not isRealArray :
                        tb.putcell(i,rownum,float(rowVals[i]))
                    else :
                        junk = np.array(rowVals[i],dtype='float32')
                        tb.putcell(i,rownum,junk)                    
                elif dt == 'integer' :
                    if not isRealArray :
                        tb.putcell(i,rownum,int(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                elif dt == 'string' :
                    if not isRealArray :
                        tb.putcell(i,rownum,str(rowVals[i]))
                    else :
                        tb.putcell(i,rownum,rowVals[i])
                else :
                    tb.putcell(i,rownum,rowVals[i])
            except:
                print 'skipping'
        tb.close()
#                tb.putcell(i,rownum,rowVals[i])

class Visibility:
    """
    Uses the tb tool to read visibility data from a measurement set.
    Instantiation requires the input MS file.  Also, if spwID is not
    set and there is more than one, beware as a failure will occur if
    the spw have different shapes.  If you create this instance, what
    you get is a structure with various attributes.  If you use the
    data.setX methods the table selection is redone,
    i.e. data.antenna1='DV01' (or 0, it interprets both, I am working
    on the same thing for field) will not make you a new table but
    data.setAntenna1('DV01') will make a new table with antenna1 as
    DV01 instead of whatever it was before.  You can also make the
    table not automatically create the subtable by setting
    autoSubtableQuery==False and then you can put in your own
    queryString.  cross_auto_all is set to 'all' by default but if you
    put in 'cross' or 'auto' it will select the relevant items.  There
    are a few functions that return the amplitude and phase (or
    recalculate them) and there is an unwrap and wrap phase option
    however, use this with caution as it depends on having alot of
    signal to noise in each measurement, i.e. it is not smart.  Let me
    know if you have questions, additions, or whatever...additions can
    just be made and a warning ;) Try to make changes backwards
    compatible...that'll make it ugly but it'll make it work!
    scan: can be a single number or a range: e.g. '1~3'
    """
    
    def __init__(self,inputMs,antenna1=0,antenna2=0,spwID=None,field=None,state=None,scan=None,autoSubtableQuery=True,queryString='',cross_auto_all='all',correctedData=False, vm=''):
        if autoSubtableQuery==False and queryString=='' : return 'Must either automatically generate the (autoSubtableQuery=True) or provide a subtable query string (queryString)'
        if spwID == None :
            spwID = getChanAverSpwIDBaseBand0(inputMs)
        self.inputMs = inputMs
        if (casadef.casa_version >= casaVersionWithMSMD):
            self.mytb = createCasaTool(tbtool)
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(inputMs)
            self.fieldsforname = {}
            for f in range(mymsmd.nfields()):
                fname = mymsmd.namesforfields(f)[0]
                self.fieldsforname[fname] = f
            mymsmd.close()
        else:
            if vm == '':
                self.valueMap = ValueMapping(self.inputMs)
            else:
                self.valueMap = vm
        self.antenna1 = antenna1
        self.antenna2 = antenna2
        if self.antenna1 <> None : self.antenna1    = str(antenna1)
        if self.antenna2 <> None : self.antenna2    = str(antenna2)
        self.checkAntenna()
        if cross_auto_all.lower() in ['cross','auto','all'] :
            self.cross_auto_all = cross_auto_all
        else :
            return "Improper value for cross_auto_all, please select, cross, auto or all."
        self.spwID       = spwID
        self.field       = field
        self.checkField()
        self.correctedData = correctedData
        self.state       = state
        self.scan        = scan
        self.autoSubtableQuery = autoSubtableQuery
        self.queryString = queryString
        if self.autoSubtableQuery == True : 
            self.makeAutoSubtable()
        else : self.makeSubtable()
        self.getSpectralData()
        self.getAmpAndPhase()

    def checkAntenna(self) :
        if self.antenna1 <> None : 
            self.antenna1 = str(self.antenna1)
            if not self.antenna1.isdigit() : self.antenna1 = getAntennaIndex(self.inputMs,self.antenna1)
        if self.antenna2 <> None :
            self.antenna2 = str(self.antenna2)
            if not self.antenna2.isdigit() : self.antenna2 = getAntennaIndex(self.inputMs,self.antenna2)

    def makeAutoSubtable(self) :
        self.checkAntenna()
        self.makeSubtableQuery()
        mytb = tbtool()
        mytb.open(self.inputMs)
        self.subtable = mytb.query(self.queryString)
        mytb.close()
        self.getSpectralData()
        self.getAmpAndPhase()

    def makeSubtable(self) :
        mytb = tbtool()
        mytb.open(self.inputMs)
        self.subtable = mytb.query(self.queryString)
        mytb.close()

    def makeSubtableForWriting(self) :
        self.mytb = tbtool()
        self.mytb.open(self.inputMs, nomodify=False)
        self.subtable = self.mytb.query(self.queryString)
        self.rowsToWrite = self.subtable.rownumbers()  

    def setAutoSubtableQuery(self,autoSubtableQuery) :
        self.autoSubtableQuery = autoSubtableQuery

    def getAutoSubtableQuery(self) : return self.autoSubtableQuery

    def setAntennaPair(self,antenna1,antenna2) :
        self.antenna1 = str(antenna1)
        self.antenna2 = str(antenna2)
        self.checkAntenna()
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def setAntenna1(self,antenna1) :
        self.antenna1 = str(antenna1)
        self.checkAntenna()
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def setAntenna2(self,antenna2) :
        self.antenna2 = str(antenna2)
        self.checkAntenna()
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def getAntenna1(self) : return self.antenna1

    def getAntenna2(self) : return self.antenna2

    def getAntennaPair(self) :
        return [self.antenna1,self.antenna2]

    def setSpwID(self,spwID) :
        self.spwID = spwID
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def getSpwID(self) : return self.spwID

    def setField(self,field) :
        self.field = field
        self.checkField()
        if self.autoSubtableQuery : self.makeAutoSubtable()

    def getField(self) : return self.field

    def checkField(self) :
        if self.field <> None : 
            self.field = str(self.field)
            if not self.field.isdigit(): 
                if (casadef.casa_version >= casaVersionWithMSMD):
                    self.field = self.fieldsforname[self.field]
                else:
                    self.field = self.valueMap.getFieldIdsForFieldName(self.field)[0]

    def setState(self,state) :
        self.state = state
        if self.autoSubtableQuery : self.makeAutoSubtable()
    
    def getState(self) : return self.state
    
    def setScan(self,scan) :
        self.scan = scan
        if self.autoSubtableQuery : self.makeAutoSubtable()
    
    def getScan(self) : return self.scan
    
    def makeSubtableQuery(self) :
        self.parameterList = []
        queryString = ''
        if self.antenna1 <> None : self.parameterList.append('ANTENNA1 == %s' % self.antenna1)
        if self.antenna2 <> None : self.parameterList.append('ANTENNA2 == %s' % self.antenna2)
        if self.field <> None    : self.parameterList.append('FIELD_ID == %s' % self.field)
        if self.spwID <> None    : self.parameterList.append('DATA_DESC_ID == %s' % getDataDescriptionId(self.inputMs,self.spwID))
        if self.state <> None    : self.parameterList.append('STATE_ID == %s' % self.state)
        if self.scan <> None     :
            if (type(self.scan) == str):
                # Added by Todd on 2014-09-22
                if (self.scan.find('~') > 0):
                    self.parameterList.append('SCAN_NUMBER in %s' % str(range(int(self.scan.split('~')[0]),1+int(self.scan.split('~')[1]))))
                else:
                    self.parameterList.append('SCAN_NUMBER == %s' % self.scan)
            else:
                self.parameterList.append('SCAN_NUMBER == %s' % self.scan)
        if self.cross_auto_all == 'cross' : self.parameterList.append('ANTENNA1 <> ANTENNA2')
        elif self.cross_auto_all == 'auto' : self.parameterList.append('ANTENNA1 == ANTENNA2')
        for i in self.parameterList : queryString = self.appendQuery(queryString,i)
        self.queryString = queryString

    def getSpectralData(self) :
        if 'FLOAT_DATA' in self.subtable.colnames() :
            if self.correctedData :
                self.specData = self.subtable.getcol('FLOAT_DATA')
            else :
                self.specData = self.subtable.getcol('FLOAT_DATA')
        else :
            if self.correctedData:
                self.specData = self.subtable.getcol('CORRECTED_DATA')
            else :
                self.specData = self.subtable.getcol('DATA')
        self.specTime = self.subtable.getcol('TIME')
        self.specFreq = getFrequencies(self.inputMs,self.spwID)
        self.tavgSpecData = self.specData.mean(-1)
        self.favgSpecData = self.specData.mean(-2)
            
    def putSpectralData(self, data, i):
        if 'FLOAT_DATA' in self.subtable.colnames() :
            if self.correctedData :
                self.mytb.putcell('FLOAT_DATA', self.rowsToWrite[i], data)
            else :
                self.mytb.putcell('FLOAT_DATA', self.rowsToWrite[i], data)
        else :
            if self.correctedData:
                self.mytb.putcell('CORRECTED_DATA', self.rowsToWrite[i], data)
            else :
                self.mytb.putcell('DATA', self.rowsToWrite[i], data)

    def getAmpAndPhase(self) :
        rData = self.specData.real
        rTavgData = self.tavgSpecData.real
        rFavgData = self.favgSpecData.real
        iData = self.specData.imag
        iTavgData = self.tavgSpecData.imag
        iFavgData = self.favgSpecData.imag
        self.phase = np.arctan2(iData,rData)
        self.amp   = (rData**2.0+iData**2.0)**0.5
        self.tavgPhase = np.arctan2(iTavgData,rTavgData)
        self.tavgAmp   = (rTavgData**2.0+iTavgData**2.0)**0.5
        self.favgPhase = np.arctan2(iFavgData,rFavgData)
        self.favgAmp   = (rFavgData**2.0+iFavgData**2.0)**0.5

    def wrapPhase(self,simple=True) :
        from math import pi
        phaseShape = self.phase.shape
        for i in range(phaseShape[2]) :
            if self.phase[:,:,i] <  -pi : self.phase[:,:,i]=self.phase[:,:,i]+2*pi
            elif self.phase[:,:,i] > pi : self.phase[:,:,i]=self.phase[:,:,i]-2*pi
        
    def unwrapPhase(self,simple=True) :
        from math import pi
        phaseShape = self.phase.shape
        for i in range(phaseShape[2]-1) :
            diff = self.phase[:,:,i]-self.phase[:,:,i+1]
            _diffg = (diff > 1.*pi)*2*pi
            _diffl = (diff < -1.*pi)*2*pi
            self.phase[:,:,i+1] = self.phase[:,:,i+1]+_diffg-_diffl

    def appendQuery(self,queryString,additive) :
        if queryString == '' :
            if additive == '' : return queryString
            else : return additive
        else :
            if additive == '' : return queryString
            else : 
                queryString = queryString + ' && ' + additive
                return queryString
    # end of Visibility class

def plotCorrectedMinusModel(vis, spw, field='', antenna1=None, antenna2=None,
                            xaxis='uvdist', avgtime=False, avgchannel='',plotfile=''):
    """
    Computes and plots the scalar amplitude difference between the corrected data
    and the model.
    spw: integer or string (comma-delimited)
    field: integer or string ID or string name (optional)
    xaxis: 'uvdist' or 'chan'
    avgtime: if True, then avgtime across all selected rows 
    avgchannel: string or integer number of channels to average
    plotfile: name of plotfile to produce (default: <vis>.ampCorrectedMinusModel.png)
    -Todd Hunter
    """
    if (xaxis not in ['uvdist','chan']):
        print "xaxis must be either 'uvdist' or 'chan'"
        return
    if (xaxis == 'uvdist' and avgtime):
        print "avgtime not support for 'uvdist' (thanks to the ms tool)"
        return
    pb.clf()
    spws = parseSpw(vis,spw)
    for i,spw in enumerate(spws):
        difference, uvdist = correctedMinusModel(vis, spw, field, antenna1, antenna2, avgtime, avgchannel)
        # axes of difference: [pol][chan][time]
        nrows = len(uvdist)
        if avgtime:
            nchan = np.shape(difference)[1]
        if xaxis == 'chan':
            xpol = difference[0]
            ypol = difference[1]
            pb.plot(range(nchan), xpol, 'bo', range(nchan), ypol, 'go')
            pb.xlabel('Channel')
        elif xaxis == 'uvdist':
            for bin in range(np.shape(difference)[1]):
                xpol = difference[0][bin]
                ypol = difference[1][bin]
                pb.plot(uvdist, xpol, 'bo', uvdist, ypol, 'go')
            pb.xlabel('uvdist (m)')
    pb.ylabel('Amp corrected - Amp model')
    if plotfile != '':
        png = plotfile
    else:
        png = vis + '.ampCorrectedMinusModel.png'
    if field != '':
        field_id, fieldname = parseFieldArgument(vis, field)
        fieldstr = ' ' + ','.join(fieldname)
    pb.title(os.path.basename(vis) + ' spw %d'%spw + fieldstr)
    pb.savefig(png)
    pb.draw()

def correctedMinusModel(vis, spw, field='', antenna1=None, antenna2=None,
                        avgtime=False, avgchannel=''):
    """
    Uses the ms tool to retrieve and compute the difference between the 
    corrected column and model column of visibilities for the specified 
    spw and field.
    spw: integer 
    field: integer or string ID or string name (optional)
    antenna1,2: antenna ID or name
    avgtime: if True, then avgtime across all selected rows 
    avgchannel: string or integer number of channels to average

    Returns: 2 lists: difference of amplitudes, uvdist
    -Todd Hunter
    """
    if (avgchannel != ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        spwchan = mymsmd.nchan(spw)
        mymsmd.close()
    myms = createCasaTool(mstool)
    myms.open(vis)
    myms.selectinit(datadescid=spw)
    if (field != ''):
        field_id, fieldname = parseFieldArgument(vis, field)
        print "Using field_id = ", field_id
        myms.select({'field_id':field_id})
    if (type(spw) == str):
        spw = int(spw)
    if (antenna1 is not None):
        if type(antenna1) == str:
            antenna1 = parseAntenna(vis, antenna1)
        myms.select({'antenna1': antenna1})
    if (antenna2 is not None):
        if type(antenna2) == str:
            antenna2 = [int(i) for i in antenna2.split(',')]
        myms.select({'antenna2': antenna2})
    if (avgchannel != ''):
        width = int(avgchannel)
        mydata = myms.getdata(['flag'])
        if (len(np.shape(mydata['flag'])) == 0):
            print "No data found"
            return
        meanflag = np.mean(np.mean(mydata['flag'],axis=2),axis=0)
        goodchannels = np.where(meanflag < 1.0)[0]
        nchan = (goodchannels[-1]-goodchannels[0]+1)/width
        start = goodchannels[0]
        inc = width
        myms.selectchannel(nchan, start, width, inc)
    mydata = myms.getdata(['corrected_amplitude','model_amplitude','uvdist'], average=avgtime)
    myms.close()
    difference = mydata['corrected_amplitude'] - mydata['model_amplitude']
    return(difference, mydata['uvdist'])

def alignFunctions(xaxis1, intensity1, xaxis2, intensity2, points=None, k=3):
    """
    Takes any two functions and returns spline-fit versions sampled onto a 
    common grid which is set to span the common range of their x-axes with 
    at least as many points as the input function.
    Optional inputs:
    points: the number of points desired in the output grid
    k: passed to interpolateSpectrum
    Returns:
    xaxis, function1, function2
    -Todd Hunter
    """
    newmin = np.max([np.min(xaxis1),np.min(xaxis2)])
    newmax = np.min([np.max(xaxis1),np.max(xaxis2)])
    if points == None:
        points = np.max([len(xaxis1), len(xaxis2)])
    xaxis = np.linspace(newmin,newmax,points)
    int1 = interpolateSpectrum(xaxis1, intensity1, xaxis, k)
    int2 = interpolateSpectrum(xaxis2, intensity2, xaxis, k)
    return xaxis, int1, int2
    
def interpolateSpectrum(inputFreq, inputSpec, outputFreq, k=3, verbose=True,
                        bounds_error=True, fill_value=0.0):
    """
    Interpolates a spectrum onto a finer grid of frequencies using a spline fit.
    If the inputFreq is narrower than the outputFreq, it will extrapolate the
    inputSpec with 'nearest' .
    k: if an integer, then use scipy.interpolate.splrep and splev
    k: if a string, then use scipy.interpolate.interp1d
       options: 'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'
    inputFreq: input x-axis values
    inputSpec: input y-axis values
    outputFreq: desired x-axis values
    Returns:
    outputSpec: y-axis values corresponding to the desired x-axis values
    Todd Hunter
    """
    tmpFreq, tmpData, checker = checkOrder(inputFreq, inputSpec)
    if (k == 'linear' or k=='nearest' or k=='zero' or k=='slinear' or k=='quadratic' or k=='cubic'):
        myfunc = scipy.interpolate.interp1d(inputFreq,inputSpec, kind=k,
                                            bounds_error=bounds_error, fill_value=fill_value)
        fdmSpectrum = myfunc(outputFreq)
    elif (type(k) == str):
        print "Invalid value for k: must be an integer, or one of the following strings:"
        print "  'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic' "
        return
    else:
        if (len(tmpFreq) <= k):
            k = len(tmpFreq)-1
            if verbose: print "Reducing spline order to %d due to too few data points (%d)" % (k,len(tmpFreq))
        tck = splrep(tmpFreq, tmpData, s=0, k=k)
        fdmSpectrum = splev(outputFreq, tck, der=0)
    return(fdmSpectrum)

def multiSingleDishSpectrum(vis,antenna=0,spw=None,field=None,offstate=None,
                            scan=None,pol=0,intent='OBSERVE_TARGET#ON_SOURCE',asdm=None,
                            tsystable=None, plotfile='', ut='', showMeanIntegration=True,
                            showMaxIntegration=False,plotEveryIntegration=False, ylimits=[0,0],
                            scaleFactor=1.0, smoothing=1, cleanup=True, onstate=None,
                            tsysvis=None,tsysspw=None,verbose=False,xlimits=[0,0],
                            xlimitsFdm=[0,0],removeMedian=False):
    """
    A test function to try alternative SD calibration equations.
    -Todd Hunter
    """
    tcal = []
    sd = []
    tsys = []
    meanTcal = []
    atmcal = None
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antennaName = mymsmd.antennanames(antenna)[0]
    mymsmd.close()
    if (onstate == None):
        # find all the ON states
        a = singleDishSpectrum(vis,antenna,spw,field,offstate,
                               scan, pol, intent, asdm,
                               tsystable, plotfile, ut, showMeanIntegration,
                               showMaxIntegration, plotEveryIntegration, ylimits,
                               scaleFactor, smoothing, cleanup, onstate, atmcal=atmcal,
                               tsysvis=tsysvis,tsysspw=tsysspw,verbose=verbose,
                               xlimits=xlimits,xlimitsFdm=xlimitsFdm)
        onstate = a[5]
        attenuatorCorrectionFactor = a[7]
        scaleFactor = a[8]
        alpha = a[9]
        alphaFdm = a[10]
        print "all onstates = ", onstate
    for state in onstate:
        result = singleDishSpectrum(vis,antenna,spw,field,offstate,
                                    scan, pol, intent, asdm,
                                    tsystable, plotfile, ut, showMeanIntegration,
                                    showMaxIntegration, plotEveryIntegration, ylimits,
                                    scaleFactor, smoothing, cleanup,onstate=state,atmcal=atmcal,
                                    attenuatorCorrectionFactor=attenuatorCorrectionFactor,
                                    tsysvis=tsysvis,tsysspw=tsysspw,verbose=verbose,
                                    xlimits=xlimits,xlimitsFdm=xlimitsFdm,alpha=alpha,alphaFdm=alphaFdm)
                                    
        freq, tcalMethod, sdimagingMethod, meanTsysMethod, meanTcalMethod, allOnStates, atmcal, attenuatorCorrectionFactor, scaleFactor, alpha, alphaFdm = result
        tcal.append(tcalMethod)
        sd.append(sdimagingMethod)
        tsys.append(meanTsysMethod)
        meanTcal.append(meanTcalMethod)
    tcalMean = np.mean(tcal,axis=0)
    sdMean = np.mean(sd,axis=0)
    tsysMean = np.mean(tsys,axis=0)
    meanTcalMean = np.mean(meanTcal,axis=0)
    pb.clf()
    pb.subplots_adjust(hspace=0.20)
    pb.subplots_adjust(wspace=0.20)
    adesc = pb.subplot(221)
    print np.shape(freq), np.shape(tcalMean)
    mysize = 12
    if (tsysvis == None):
        pb.text(0,1.15,'%s %s'%(vis,antennaName), size=mysize, transform=adesc.transAxes)
    else:
        pb.text(0,1.15,'%s %s (Tsys=%s)'%(vis,antennaName,tsysvis), size=mysize-1, transform=adesc.transAxes)
    pb.plot(freq, tcalMean, 'k-')
    if (removeMedian):
        tcalMean -= computeYStatsForXLimits(freq, tcalMean, xlimits)['median']
        meanTcalMean -= computeYStatsForXLimits(freq, meanTcalMean, xlimits)['median']
        sdMean -= computeYStatsForXLimits(freq, sdMean, xlimits)['median']
        tsysMean -= computeYStatsForXLimits(freq, tsysMean, xlimits)['median']
    ylimits = np.array(computeYLimitsForXLimits(freq,sdMean,xlimits))*1.1
    pb.xlim(xlimits)
    pb.ylim(ylimits)
    pb.title('spectral Tcal method', size=mysize)
    ticksize = 10
    resizeFonts(adesc, ticksize)

    adesc = pb.subplot(222)
    pb.plot(freq, meanTcalMean, 'k-')
    pb.xlim(xlimits)
    pb.ylim(ylimits)
    pb.title('mean Tcal method', size=mysize)
    resizeFonts(adesc, ticksize)

    adesc = pb.subplot(223)
    pb.plot(freq, sdMean, 'k-')
    pb.xlim(xlimits)
    pb.ylim(ylimits)
    pb.title('spectral Tsys method (sdimaging)', size=mysize)
    pb.xlabel('Sky frequency (GHz)')
    resizeFonts(adesc, ticksize)

    adesc = pb.subplot(224)
    pb.plot(freq, tsysMean, 'k-')
    pb.xlim(xlimits)
    pb.ylim(ylimits)
    pb.xlabel('Sky frequency (GHz)')
    pb.title('mean Tsys method', size=mysize)
    resizeFonts(adesc, ticksize)

    pb.savefig('tcal_vs_sdimaging.png')

def computeYStatsForXLimits(x, y, xlimits):
    """
    Computes the Y-axis statistics (mean, std, median, min, max) over the 
    specified x-axis range, rather than over the whole x-axis range.  
    Returns a dictionary.
    -Todd Hunter
    """
    idx0 = np.where(x >= xlimits[0])[0]
    idx1 = np.where(x <= xlimits[1])[0]
    idx = np.intersect1d(idx1,idx0)
    if (len(idx) < 1):
        print "No points match the x-range.  Using entire range."
        idx = range(len(y))
    return({'mean': scipy_nanmean(y[idx]), 'std': scipy_nanstd(y[idx]), 'median': scipy_nanmedian(y[idx]),
            'min': np.nanmin(y[idx]), 'max': np.nanmax(y[idx])})

def computeYLimitsForXLimits(x, y, xlimits, verbose=False):
    """
    Computes the Y-axis limits to autorange over the specified x-axis range, rather
    than over the whole x-axis range, which is what pylab plot does by default.
    -Todd Hunter
    """
    mydict = computeYStatsForXLimits(x, y, xlimits)
    if (verbose):
        print "full ylimits: %f,%f   within x-range: %f,%f" % (np.nanmin(y), np.nanmax(y), mydict['min'], mydict['max'])
    ylimits = [mydict['min'], mydict['max']]
    return(ylimits)
                            
def singleDishSpectrum(vis,antenna=0,spw=None,field=None,offstate=None,
                       scan=None,pol=0,intent='OBSERVE_TARGET#ON_SOURCE',asdm=None,
                       tsystable=None, plotfile='', ut='', showMeanIntegration=False,
                       showMaxIntegration=False,plotEveryIntegration=False, ylimits=[0,0],
                       scaleFactor=1.0, smoothing=1, cleanup=True,onstate=None,
                       atmcal=None, attenuatorCorrectionFactor=None,tsysvis=None,
                       tsysspw=None,verbose=False,xlimits=[0,0],xlimitsFdm=[0,0],
                       alpha=None,alphaFdm=None):
    """
    A test function to try alternative SD calibration equations.
    vis: the measurement set containing the ON, OFF data
    tsysvis: the measurement set containing the Tsys scan to use
    asdm: the dataset corresponding to tsysvis
    antenna = antenna number as integer
    spw: spw number as integer
    field: field number as integer
    onstate: integer STATE_ID for the on source integration
    offstate: integer STATE_ID for the off source integration
    pol: 0 or 1
    ut: a string representing UT time '12:00:00' (date will be prepended)
    showMaxIntegration: if True, show the single integration with largest mean
                        if False, show the single integration closest to the requested UT
    showMeanIntegration: if True, show the mean of all integrations in a row/state_id,
                         if False, show the single integration closest to the requested UT
    plotEveryIntegration: make a plot for every dump rather than the mean, and build PDF
    scaleFactor: the factor by which to multiply Robert's formula
    cleanup: if True, remove the png files if multiple ones were made
    attenuatorCorrectionFactor: the value to multiply the ON and OFF spectrum by
    xlimits: the x-axis limits for the Tcal/Tsys spectra (in GHz)
    xlimitsFdm: the x-axis limits for the FDM data spectra (in GHz)
    Returns: 10 items:
      chanfreqs, spectrum using Tcal method, spectrum using Tsys method, spectrum using mean Tsys
      method, list of all on-source state IDs, atmcal instance, attenuatorCorrectionFactor,
      scaleFactor, alpha, alphaFdm
    
    Todd Hunter
    """
    if (type(onstate) == list):
        print "onstate must be an integer, not a list"
        return
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine."
        return
    from almahelpers_localcopy import tsysspwmap
    if (tsysvis == None):
        tsysvis = vis
    if (asdm == None):
        asdm = tsysvis.split('.')[0]
    if (tsystable == None):
        tsystable = tsysvis+'.tsys'
    if (os.path.exists(tsystable) == False):
        print "Running gencal to create the tsys caltable."
        gencal(tsysvis, caltype='tsys', caltable=tsystable)
    if (atmcal == None):
        atmcal = Atmcal(tsysvis)
    mymsmd = createCasaTool(msmdtool)
    mjdsec = 0
    if (ut != ''):
        mydate = getObservationStartDate(vis).split()[0]
        mydate = mydate + ' ' + ut
        mjdsec = dateStringToMJDSec(mydate)
        print "Finding closest data to %s = %f" % (mydate, mjdsec)
    mymsmd.open(vis)
    antennaName = mymsmd.antennanames(antenna)[0]
    if (spw == None):
        spws = spwsforintent_nonwvr_nonchanavg(mymsmd, intent)
        if (len(spws) < 1):
            print "No spws match this intent"
            return
        spw = spws[0]
        print "Picking spw = %d" % (spw)
    if (field == None):
        fields = mymsmd.fieldsforintent(intent)
        if (len(fields) < 1):
            print "No fields match this intent"
            return
        field = fields[0]
        fieldName = mymsmd.namesforfields(field)[0]
        print "Picking field = %d = %s" % (field, fieldName)
    fieldName = mymsmd.namesforfields(field)[0]
    if (scan == None):
        scans = np.intersect1d(mymsmd.scansforintent(intent), mymsmd.scansforfield(field))
        if (len(scans) < 1):
            print "No scans match this intent+field"
            return
        scan = scans[0]
        print "Picking data scan = ", scan
    chanfreqs = mymsmd.chanfreqs(spw) * 1e-9
    meantime = np.mean(mymsmd.timesforscan(scan))
    mymsmd.close()
    atmcalscan = atmcal.nearestCalScan(meantime)
    print "Picking ATMCal scan = ", atmcalscan
    if (tsysspw == None):
        tcalSpw = tsysspwmap(vis, tsystable)[spw]
    else:
        tcalSpw = tsysspw
        if (tcalSpw not in atmcal.datadescids.keys()):
            print "spw %d is not an ATMCal spw in %s" % (tcalSpw, tsysvis)
            return
    skyLoad = atmcal.getSpectrum(atmcalscan, tcalSpw, pol, 'sky', antenna)
    ambLoad = atmcal.getSpectrum(atmcalscan, tcalSpw, pol, 'amb', antenna)
    hotLoad = atmcal.getSpectrum(atmcalscan, tcalSpw, pol, 'hot', antenna)
    if (verbose):
        print "Calling readTcal('%s', %d, %d, %f)" % (asdm, antenna, tcalSpw,meantime)
    tcal, tcalTime = readTcal(asdm, antenna, tcalSpw, meantime, verbose=verbose)
    if (verbose):
        print "Calling readTcal('%s', %d, %d, %f, spectrum='tsys')" % (asdm, antenna, tcalSpw,meantime)
    tsys, tsysTime = readTcal(asdm, antenna, tcalSpw, meantime, spectrum='tsys', verbose=verbose)
    tcal = tcal[pol]
    tsys = tsys[pol]
    mymsmd.open(tsysvis)
    tcalChanfreqs = mymsmd.chanfreqs(tcalSpw) * 1e-9
    mymsmd.close()
    if (verbose):
        print "%d chanfreqs: %f-%f,  %d tcalChanfreqs: %f-%f" % (len(chanfreqs),chanfreqs[0],chanfreqs[-1],
                                                                 len(tcalChanfreqs),tcalChanfreqs[0],tcalChanfreqs[-1])
    tcalFdm = interpolateSpectrum(tcalChanfreqs, tcal, chanfreqs)
    tsysFdm = interpolateSpectrum(tcalChanfreqs, tsys, chanfreqs)
    meanTsysFdm = computeYStatsForXLimits(chanfreqs,tsysFdm,xlimits)['mean']
    skyLoadFdm = interpolateSpectrum(tcalChanfreqs, skyLoad, chanfreqs)
    ambLoadFdm = interpolateSpectrum(tcalChanfreqs, ambLoad, chanfreqs)
    hotLoadFdm = interpolateSpectrum(tcalChanfreqs, hotLoad, chanfreqs)
    
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    allstates = mytb.getcol('STATE_ID')
    myt = mytb.query('ANTENNA1==%d and ANTENNA2==%d and DATA_DESC_ID==%d and FIELD_ID==%d and SCAN_NUMBER==%d' % (antenna,antenna,spw,field,scan))
    rows = myt.rownumbers()
    times = myt.getcol('TIME')
    print "%d matching rows: %s" % (len(rows), str(rows))
    if (len(rows) == 0):
        return
    states = myt.getcol('STATE_ID')
    myt.close()
    mytb.close()

    mytb.open(vis+'/STATE')
    obsMode = mytb.getcol('OBS_MODE')
    allOnStates = []
    if (onstate == None):
        if (mjdsec > 0):
            # Pick the closest row in time
            mindiff = 1e20
            for row in range(len(rows)):
                if (obsMode[allstates[rows[row]]].find('ON_SOURCE') >= 0):
                    deltaTime = abs(times[row]-mjdsec)
                    if (deltaTime < mindiff):
                        mindiff = deltaTime
#                        print "New mindiff on = ", mindiff
                        onstate = states[row]
                        onstateTime = times[row]
        else:            
            # Pick the first row that contains ON_SOURCE
            for row in range(len(rows)):
                if (obsMode[allstates[rows[row]]].find('ON_SOURCE') >= 0):
                    onstate = states[row]
                    onstateTime = times[row]
#                    print "onstate = ", onstate
                    break
    else:
        row = np.where(states == onstate)[0][0]
        onstateTime = times[row]
    # Just do this so I can return the value for other usage.
    for myrow in range(len(rows)):
        if (obsMode[allstates[rows[myrow]]].find('ON_SOURCE') >= 0):
            allOnStates.append(states[myrow])
    on_intents = obsMode[allstates[rows[row]]]
    print "on source intents = %s" % (str(on_intents))
    if (offstate == None):
        if (mjdsec > 0):
            # Pick the closest row in time
            mindiff = 1e20
            for row in range(len(rows)):
                if (obsMode[allstates[rows[row]]].find('OFF_SOURCE') >= 0):
                    deltaTime = abs(times[row]-mjdsec)
                    if (deltaTime < mindiff):
                        mindiff = deltaTime
                        offstate = states[row]
                        offsourceRow = row
        else:            
            # Pick the row closest to the ON_SOURCE in time
            mindiff = 1e20
            for row in range(len(rows)):
                if (obsMode[allstates[rows[row]]].find('OFF_SOURCE') >= 0):
                    deltaTime = abs(times[row]-onstateTime)
                    if (deltaTime < mindiff):
                        mindiff = deltaTime
                        offstate = states[row]
                        offsourceRow = row
    else:
        row = np.where(states == offstate)[0][0]
        offsourceRow = row

    row = offsourceRow
    off_intents = obsMode[allstates[rows[row]]]
    print "offsource row = ", row
    print "offsource rows[row] = ", rows[row]
    print "allstates[rows[row]] = ", allstates[rows[row]]    
    print "offstate = ", offstate
    print "offsource intents = %s" % (str(off_intents))
    v = Visibility(vis, antenna, antenna, spw, field, onstate, scan, cross_auto_all='auto')

    if (plotEveryIntegration):
        dumps = range(len(v.specTime))
        on_spectrum = []
        for dump in dumps:
            on_spectrum.append(np.abs(v.specData[pol,:,dump]))
        on_time = v.specTime[:]
        on_duration = v.specTime[1] - v.specTime[0]
    elif (showMeanIntegration == False):
        if (showMaxIntegration):
            peakspec = -1e10
            for s in range(len(v.specData[pol][0])):
                spec = v.specData[pol,:,s]
                meanspec = np.mean(spec)
                if (meanspec > peakspec):
                    peakspec = meanspec
                    pick = s
        elif (mjdsec > 0):
            # pick the one closest to the requested UT time
            nearestTime = 1e10
            for s in range(len(v.specData[pol][0])):
                deltaTime = abs(v.specTime[s]-mjdsec)
                if (deltaTime < nearestTime):
                    nearestTime = deltaTime
                    pick = s
        else:
            # Just pick the first one
            pick = 0
        on_spectrum = [np.abs(v.specData[pol,:,pick])]
        on_time = [v.specTime[pick]]
        if (pick == 0):
            on_duration = v.specTime[pick+1] - v.specTime[pick]
        else:
            on_duration = v.specTime[pick] - v.specTime[pick-1]
        dumps = [0]
    else:
        dumps = [0]
        on_spectrum = [np.mean(v.specData[pol],axis=1)]
        on_time = [np.mean(v.specTime)]
        on_duration = np.max(v.specTime) - np.min(v.specTime)
            
    v.setState(offstate)
    off_time = np.mean(v.specTime)
    off_spectrum = np.mean(v.specData[pol],axis=1)
    off_duration = np.max(v.specTime) - np.min(v.specTime)
    off_spectrum = abs(off_spectrum)
    
    channels = np.intersect1d(np.where(tcalChanfreqs >= np.min(chanfreqs))[0], np.where(tcalChanfreqs <= np.max(chanfreqs))[0])
    print "Channels to average = %d-%d" % (channels[0], channels[-1])
    if (attenuatorCorrectionFactor == None):
        attenuatorCorrectionFactor = np.mean(skyLoad[channels]) / np.mean(off_spectrum)  
    off_spectrum *= attenuatorCorrectionFactor
    print "TDM/FDM plus attenuator correction factor = %f = %f dB" % (attenuatorCorrectionFactor, 10*np.log10(attenuatorCorrectionFactor))
    if (alpha==None):
        jSky, jAmb, jHot, frequency, jatmDSB, jspDSB, jbg, tauA, alpha, gb, tebbsky = atmcal.computeJs(atmcalscan, antenna, pol, tcalSpw, computeJsky=True)
        alphaFdm =  interpolateSpectrum(tcalChanfreqs, np.array(alpha), chanfreqs)
    mysize = 10
    if (plotEveryIntegration):
        rows = 2
        cols = 1
        ticksize = 9
    else:
        rows = 3
        cols = 3
        ticksize = 7
    pnglist = []
    for dump in dumps:
      on_spectrum[dump] = abs(on_spectrum[dump]) * attenuatorCorrectionFactor
      pb.clf()
      pb.subplots_adjust(hspace=0.30)
      pb.subplots_adjust(wspace=0.40)
      scale = 1e8
      if (xlimits == [0,0]):
          xlimits = [np.min([np.min(tcalChanfreqs),np.min(chanfreqs)]), np.max([np.max(tcalChanfreqs),np.max(chanfreqs)])]
      if (xlimitsFdm == [0,0]):
          xlimitsFdm = [np.min(chanfreqs), np.max(chanfreqs)]
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,5)
        pb.plot(chanfreqs, on_spectrum[dump]/scale, 'k-', chanfreqs, off_spectrum/scale, 'r-')
        pb.xlim(xlimitsFdm)
        resizeFonts(adesc, ticksize)
        pb.ylabel('Raw data / %.0e'%(scale),size=mysize)
        print "Mean ON-OFF = %f,  Mean ON/OFF = %f" % (np.mean(on_spectrum[dump]-off_spectrum),
                                                       np.mean(on_spectrum[dump])/np.mean(off_spectrum))
        pb.title('ON=black, OFF=red',size=mysize)
        
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,1)
        pb.plot(tcalChanfreqs, tcal, 'k-', chanfreqs, tcalFdm, 'r-')
        pb.xlim(xlimits)
        resizeFonts(adesc, ticksize)
#        pb.title('Tcal at %s (spw %d, %d)' % (mjdsecToUTHMS(tcalTime), tcalSpw, spw), size=mysize)
        pb.title('Tcal at %s (spw %d, %d)' % (mjdsecToUT(tcalTime), tcalSpw, spw), size=mysize)
        pb.ylabel('Temperature (K)',size=mysize)
        pb.text(-0.10*cols,1.17,vis + ', ant%02d=%s, spw=%02d, field=%d=%s, scan=%d, onstate=%d, offstate=%d'%(antenna, antennaName, spw, field, fieldName, scan, onstate, offstate), transform=adesc.transAxes, size=mysize)
    
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,2)
        pb.plot(tcalChanfreqs, tsys, 'k-', chanfreqs, tsysFdm, 'r-')
        pb.xlim(xlimits)
        pb.text(0.1,0.85,'mean=%.1f' % (meanTsysFdm),size=mysize+1-cols,transform=adesc.transAxes)
        resizeFonts(adesc, ticksize)
        pb.title('Tsys',size=mysize) # at %s (spw %d, %d)' % (mjdsecToUTHMS(tcalTime), tcalSpw, spw), size=mysize)
        pb.ylim(computeYLimitsForXLimits(tcalChanfreqs, tsys, xlimits))
        pb.ylabel('Temperature (K)',size=mysize)
        if ((rows-1)*cols < 3):
            pb.xlabel('Sky frequency (GHz)',size=mysize)
    
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,4)
        pb.plot(tcalChanfreqs, ambLoad/scale,'k-', tcalChanfreqs, hotLoad/scale,'k-',
                chanfreqs, ambLoadFdm/scale,'r-', chanfreqs, hotLoadFdm/scale,'r-',
                tcalChanfreqs, skyLoad/scale, 'k-', chanfreqs, skyLoadFdm/scale,'r-')
        pb.ylim([np.min(ambLoad/scale), np.max(hotLoad/scale)])
        resizeFonts(adesc, ticksize)
        pb.xlim(xlimits)
        pb.title('Ambient, Hot load, Sky', size=mysize)
        pb.ylabel('Raw data / %.0e'%scale,size=mysize)
        pb.text(0.05,0.28, 'C=mean(skyLoad/OFF)=%.2f' % (attenuatorCorrectionFactor),
                size=7, transform=adesc.transAxes)
    
      if (plotEveryIntegration == False and False):
        adesc = pb.subplot(rows,cols,5)
        yaxis = skyLoad/scale
        pb.plot(tcalChanfreqs, yaxis, 'k-', chanfreqs, skyLoadFdm/scale,'r-')
        resizeFonts(adesc, ticksize)
        pb.xlim(xlimits)
        pb.ylim(computeYLimitsForXLimits(tcalChanfreqs, yaxis, xlimits))
        pb.title('Sky load', size=mysize)
        pb.text(0.05,0.88, 'C=mean(skyLoad/OFF)=%.2f' % (attenuatorCorrectionFactor),
                size=7, transform=adesc.transAxes)
        pb.ylabel('Raw data / %.0e'%scale,size=mysize)
    
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,3)
        pb.plot(tcalChanfreqs, alpha,'k-', chanfreqs, alphaFdm, 'r-')
        resizeFonts(adesc, ticksize)
        pb.xlim(xlimits)
        pb.title('Alpha (red=interpolated to FDM)', size=mysize)
        pb.ylabel('Unitless',size=mysize)
    
      if (plotEveryIntegration == False):
          panel = 8
      else:
          panel = 1
      adesc = pb.subplot(rows,cols,panel)
      if (plotEveryIntegration):
          pb.text(-0.10*cols,1.17,vis + ', ant%02d=%s, spw=%02d, field=%d=%s, scan=%d, onstate=%d, offstate=%d'%(antenna, antennaName, spw, field, fieldName, scan, onstate, offstate), transform=adesc.transAxes, size=mysize)
          pb.text(-0.08*cols,-0.08*rows,'ON: %s (%.2f sec duration)  OFF: %s (%.2f sec duration)' % (mjdsecToUTHMS(on_time[dump],prec=8), on_duration,
                                                                                                mjdsecToUTHMS(off_time,prec=8), off_duration),
                  transform=adesc.transAxes, size=mysize)
          pb.text(0.9,-0.08*rows, '%2d/%d'%(dump+1,len(dumps)), transform=adesc.transAxes, size=mysize)
      print "mean(alpha) = %f, mean(tcalFdm)=%f" % (np.mean(alphaFdm), np.mean(tcalFdm))
      print "mean(ambLoad) = %e, mean(hotLoad) = %e, mean(OFF) = %e" % (np.mean(ambLoadFdm), np.mean(hotLoadFdm), np.mean(off_spectrum))
      onoff_sdimaging = tsysFdm * (on_spectrum[dump] - off_spectrum) / off_spectrum
      onoff_meanTsys = meanTsysFdm * (on_spectrum[dump] - off_spectrum) / off_spectrum
      onoff_cso = atmcal.loadTemperatures[antenna][atmcalscan]['amb'] * (on_spectrum[dump] - off_spectrum) / (ambLoadFdm - off_spectrum)
      if (True):
          # original posting to CSV-2986
          onoff = scaleFactor * tcalFdm * (on_spectrum[dump] - off_spectrum) / ((1-alphaFdm)*hotLoadFdm + alphaFdm*ambLoadFdm - off_spectrum)
          onoff_meanTcal = scaleFactor * np.mean(tcalFdm) * (on_spectrum[dump] - off_spectrum) / ((1-alphaFdm)*hotLoadFdm + alphaFdm*ambLoadFdm - off_spectrum)
          if (scaleFactor != 1.0):
              pb.title('%g*C*Tcal*(ON-OFF)/((1-alpha)*HOT+alpha*AMB-C*OFF)' % (scaleFactor), size=8)
          else:
              scaleFactor = computeYStatsForXLimits(chanfreqs,onoff_sdimaging,xlimits)['mean']/computeYStatsForXLimits(chanfreqs,onoff,xlimits)['mean']
              scaleFactor = np.round(scaleFactor*10)/10.0
              pb.title('C*Tcal*(ON-OFF)/((1-alpha)*HOT+alpha*AMB-C*OFF)', size=8)
      else:
          onoff = tcalFdm * (on_spectrum[dump] - off_spectrum) / ((1-alphaFdm)*ambLoadFdm + alphaFdm*hotLoadFdm - off_spectrum) 
          pb.title('C*Tcal*(ON-OFF)/((1-alpha)*AMB+alpha*HOT-C*OFF)', size=8)
      if (smoothing > 1):
          onoff = smooth(onoff, window_len=smoothing, window='flat')
          onoff_cso = smooth(onoff_cso, window_len=smoothing, window='flat')
          onoff_meanTcal = smooth(onoff_meanTcal, window_len=smoothing, window='flat')
          onoff_sdimaging = smooth(onoff_sdimaging, window_len=smoothing, window='flat')
          onoff_meanTsys = smooth(onoff_meanTsys, window_len=smoothing, window='flat')

      pb.plot(chanfreqs, onoff,'k-')
      pb.text(0.1,0.9,'mean=%.2f, std=%.3f'%(computeYStatsForXLimits(chanfreqs,onoff,xlimits)['mean'],
                                             computeYStatsForXLimits(chanfreqs,onoff,xlimits)['std']),
                                             size=mysize+1-cols, transform=adesc.transAxes)
      resizeFonts(adesc, ticksize)
      pb.xlim(xlimitsFdm)
      if (ylimits == [0,0] or ylimits == []):
          ylimits = [np.min([np.min(onoff_sdimaging), np.min(onoff)]), np.max([np.max(onoff_sdimaging),np.max(onoff)])]
          ylimits = [ylimits[0]-0.1*ylimits[1], ylimits[1]*1.1]
          if (ylimits[0] > 0): ylimits[0] = 0
      pb.ylim(ylimits)
      pb.ylabel('Temperature (K)',size=mysize)

      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,6)
        # CSO method
        pb.plot(chanfreqs, onoff_cso,'k-')
        pb.title('CSO method = Tamb*(ON-OFF)/(AMB-SKY)', size=mysize-1)
        pb.ylabel('Temperature (K)',size=mysize)
        resizeFonts(adesc, ticksize)
        pb.xlim(xlimitsFdm)
        pb.ylim(ylimits)
        pb.text(0.1,0.9,'mean=%.2f, std=%.3f'%(computeYStatsForXLimits(chanfreqs,onoff_cso,xlimits)['mean'],
                                               computeYStatsForXLimits(chanfreqs,onoff_cso,xlimits)['std']),
                size=mysize+1-cols, transform=adesc.transAxes)
        pb.text(0.1,0.1,'Tamb=%.2fK'%(atmcal.loadTemperatures[antenna][atmcalscan]['amb']),
                size=mysize+1-cols, transform=adesc.transAxes)
    
      if (plotEveryIntegration == False):
        adesc = pb.subplot(rows,cols,7)
        if (False):
            onoff = (on_spectrum[dump] - off_spectrum) / off_spectrum
            pb.plot(chanfreqs, onoff,'k-')
            pb.title('(ON-OFF)/OFF', size=mysize)
            pb.ylabel('Raw data',size=mysize)
            pb.text(0.1,0.9,'mean=%.2f, std=%.3f'%(computeYStatsForXLimits(chanfreqs,onoff,xlimits)['mean'],
                                                   computeYStatsForXLimits(chanfreqs,onoff,xlimits)['std']),
                    size=mysize+1-cols, transform=adesc.transAxes)
        else:
            pb.plot(chanfreqs, onoff_meanTsys, 'k-')
            pb.title('mean(Tsys)*(ON-OFF)/OFF', size=mysize-2)
            pb.ylim(ylimits)
            pb.ylabel('Temperature (K)',size=mysize)
            pb.text(0.1,0.9,'mean=%.2f, std=%.3f'%(computeYStatsForXLimits(chanfreqs,onoff_meanTsys,xlimits)['mean'],
                                                   computeYStatsForXLimits(chanfreqs,onoff_meanTsys,xlimits)['std']),
                    size=mysize+1-cols, transform=adesc.transAxes)
        resizeFonts(adesc, ticksize)
        pb.xlim(xlimitsFdm)
        pb.text(-0.08*cols,-0.08*rows,'ON: %s (%.2f sec duration)  OFF: %s (%.2f sec duration)' % (mjdsecToUTHMS(on_time[dump],prec=8), on_duration,
                                                                                     mjdsecToUTHMS(off_time,prec=8), off_duration),
                transform=adesc.transAxes, size=mysize)
    
      adesc = pb.subplot(rows,cols,panel+1)
      pb.plot(chanfreqs, onoff_sdimaging,'k-')
      pb.text(0.1,0.9,'mean=%.2f, std=%.3f'%(computeYStatsForXLimits(chanfreqs,onoff_sdimaging,xlimits)['mean'],
                                             computeYStatsForXLimits(chanfreqs,onoff_sdimaging,xlimits)['std']),
              size=mysize+1-cols, transform=adesc.transAxes)
      resizeFonts(adesc, ticksize)
      pb.xlim(xlimitsFdm)
      pb.ylim(ylimits)
      pb.title('Tsys*(ON-OFF)/OFF', size=mysize)
      pb.ylabel('Temperature (K)',size=mysize)
      pb.xlabel('Sky frequency (GHz)',size=mysize)
      print "mean of sdimaging / Robert = ", computeYStatsForXLimits(chanfreqs,onoff_sdimaging,xlimits)['mean']/computeYStatsForXLimits(chanfreqs,onoff,xlimits)['mean']
      pb.draw()
      if (plotfile != ''):
          if (plotfile == True):
              if (len(dumps) > 1):
                  png = vis+'.%s.%s.spw%02d.pol%d.dump%02d.png' % (fieldName,antennaName,spw,pol,dump)
                  pb.savefig(png)
                  pnglist.append(png)
              else:
                  pb.savefig(vis+'.%s.%s.spw%02d.pol%d.png' % (fieldName,antennaName,spw,pol))
          else:
              pb.savefig(plotfile)
    if (len(pnglist) > 0):
        if (smoothing > 1):
            pdf = vis+'.%s.%s.spw%02d.pol%d.pdf' % (fieldName,antennaName,spw,pol)
        else:
            pdf = vis+'.%s.%s.spw%02d.pol%d.smooth%g.pdf' % (fieldName,antennaName,spw,pol,smoothing)
        buildPdfFromPngs(pnglist, pdf)
        if (cleanup):
            for png in pnglist:
                os.system('rm -f %s' % png)
    else:
        if (len(allOnStates) > 0):
            print "on states = ", np.unique(allOnStates)
        return(chanfreqs, onoff, onoff_sdimaging, onoff_meanTsys, onoff_meanTcal,
               np.unique(allOnStates), atmcal, attenuatorCorrectionFactor,scaleFactor,
               alpha, alphaFdm)

def getAntennaIndex(msFile,antennaName) :
    """
    Returns the index number of the specified antenna in the specified ms.
    The antennaName must be a string, e.g. DV01.  Obsoleted by msmd.antennaids('DV01')[0].
    """
    if str(antennaName).isdigit() : 
        return antennaName
    else :
        ids = getAntennaNames(msFile)
        if (antennaName not in ids):
            print "Antenna %s is not in the dataset.  Available antennas = %s" % (antennaName, str(ids))
            return(-1)
        return np.where(ids == antennaName)[0][0]

def getAntennaName(msFile,antennaID) :
    """
    Returns the antenna name of the specified antenna in the specified ms.
    The antennaID must be an integer.Obsoleted by msmd.antennanames(1)[0].
    Todd Hunter
    """
    names = getAntennaNames(msFile)
    if (antennaID >= 0 and antennaID < len(names)):
        return (names[antennaID])
    else:
        print "This antenna ID (%d) is not in the ms." % (antennaID)
        return ('')

def commonAntennas(vislist, returnPads=False, returnDict=False):
    """
    Returns a list of the common antenna names between two (or more) datasets, or
    between all the obsids of a single multi-obsid dataset.
    vis: either a comma-delimited string, or a python list of strings
    returnPads: if True, then return the list of pads that are common between these datasets
    returnDict: if True, then return dictionary keyed by vis name, with values being a comma-delimited
             string of antenna names that occupy the subset of pads that is common to all datasets
             (does not yet work for the case of a single multi-obsid dataset)
    -Todd Hunter
    """
    if (type(vislist) == str):
        if vislist.find('*') >= 0:
            vislist = sorted(glob.glob(vislist))
        else:
            vislist = vislist.split(',')
    vis = vislist[0].strip()
    if (len(vislist) == 1):
        mytb = createCasaTool(tbtool)
        mytb.open(vis)
        obsids = np.unique(mytb.getcol('OBSERVATION_ID'))
        mytb.close()
        if returnPads or returnDict:
            print "Finding pads common to %d obsids" % (len(obsids))
            common = getAntennaPadsForObsID(vis, obsids[0])
            for obsid in obsids[1:]:
                common = np.intersect1d(common, getAntennaPadsForObsID(vis, obsid))
        else:
            print "Finding antennas common to %d obsids" % (len(obsids))
            common = getAntennaNamesForObsID(vis, obsids[0])
            for obsid in obsids[1:]:
                common = np.intersect1d(common, getAntennaNamesForObsID(vis, obsid))
    else:
        if returnPads or returnDict:
            common = getAntennaPads(vis)
            if returnDict:
                antennaPads = {}
                antennaNames = {}
                antennaPads[vis] = list(common)
                antennaNames[vis] = np.array(getAntennaNames(vis))
        else:
            common = getAntennaNames(vislist[0].strip())
        for vis in vislist[1:]:
            vis = vis.strip()
            if returnPads or returnDict:
                ants = getAntennaPads(vis)
                if returnDict:
                    antennaPads[vis] = list(ants)
                    antennaNames[vis] = np.array(getAntennaNames(vis))
            else:
                ants = getAntennaNames(vis)
            common = np.intersect1d(common,ants)
    if returnDict and len(vislist) > 1:
        mydict = {}
        for vis in vislist:
            mylist = [antennaPads[vis].index(pad) for pad in common]
            mydict[vis] = ','.join(sorted(antennaNames[vis][mylist]))
        return(mydict)
    else:
        return(list(common))

def getAntennaNamesForObsID(vis, obsid=0):
    """
    Gets the list of antenna names associated to a specific obsid.
    -Todd 
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    obsids = np.unique(mytb.getcol('OBSERVATION_ID'))
    if (obsid not in obsids):
        print "obsid=%d is not in the dataset, which contains obsids: %s" % (obsid, str(obsids))
        mytb.close()
        return
    t = mytb.query('OBSERVATION_ID == %d'%obsid)
    ant1 = np.unique(t.getcol('ANTENNA1'))
    ant2 = np.unique(t.getcol('ANTENNA2'))
    t.close()
    ids = np.union1d(ant1,ant2)
    mytb.close()
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    names = list(mymsmd.antennanames(ids))
    mymsmd.close()
    return(names)

def getAntennaNames(msFile) :
    """
    Returns the list of antenna names in the specified ms ANTENNA table.
    Obsoleted by msmd.antennanames(range(msmd.nantennas())).
    """
    if (msFile.find('*') >= 0):
        mylist = glob.glob(msFile)
        if (len(mylist) < 1):
            print "getAntennaNames: Could not find measurement set."
            return
        msFile = mylist[0]
    mytb = createCasaTool(tbtool)
    mytb.open(msFile+'/ANTENNA')
    names = mytb.getcol('NAME')
    mytb.close()
    return names

def convertTimeStamps(timesIn) :
    """
    Converts a list of makeTimeStamp strings to a list of Julian day numbers
    """
    timesIn = makeList(timesIn)
    timesOut = []
    for i in timesIn :
        timesOut.append(convertTimeStamp(i))
    return timesOut

def convertTimeStamp(timeIn) :
    """
    Converts a makeTimeStamp string to Julian day number
    """
    conv   = timeIn.split('T')
    date   = conv[0].split('-')
    time   = conv[1].split(':')
    year   = float(date[0])
    month  = float(date[1])
    day    = float(date[2])
    hour   = float(time[0])
    minute = float(time[1])
    second = float(time[2])
    ut=hour+minute/60+second/3600
    if (100*year+month-190002.5)>0:
        sig=1
    else:
        sig=-1
    return 367*year - int(7*(year+int((month+9)/12))/4) + int(275*month/9) + day + 1721013.5 + ut/24 - 0.5*sig +0.5

def parseTrx(antennaSel,polSel=0,bandNumberSel=3,filename='/data/checkTrx.txt') :
    data = fiop.readcolPy(filename,'s,f,s,f,i,s,f,f,f,f,f')
    recTime = np.array(data[0])
    elev    = np.array(data[1])
    jdTime  = recTime
    for i in range(len(recTime)) : jdTime[i] = convertTimeStamp(recTime[i])-2455198
    antenna = np.array(data[2])
    freq    = np.array(data[3])*1e9
    pol     = np.array(data[4])
    chan    = np.array(data[5])
    trx     = np.array(data[6])
    errtrx  = np.array(data[7])
    gain    = np.array(data[8])
    errgain = np.array(data[9])
    tsys    = np.array(data[10])
    indexAnt  = np.where(antenna == antennaSel)[0]
    indexPol  = np.where(pol == polSel)[0]
    indexFreqLow = np.where(freq <= bandDefinitions[bandNumberSel][1])[0]
    indexFreqHigh = np.where(freq >= bandDefinitions[bandNumberSel][0])[0]
    indexVal = list((set(indexAnt) & set(indexPol) & set(indexFreqLow) & set(indexFreqHigh)))
    return jdTime[indexVal],elev[indexVal],recTime[indexVal],chan[indexVal],trx[indexVal],errtrx[indexVal],gain[indexVal],errgain[indexVal],freq[indexVal],tsys[indexVal]

def parseTrxInfo(antennaList=['DV01','DV02','DV03','DV04','DV05','PM02','PM03'],polList=[0,1],bandList=[3,6],filename=None) :
    if filename == None : filename='/data/checkTrx.txt'
    info = {}
    for i in antennaList :
        info[i] = {}
        for j in bandList :
            info[i][j] = {}
            for k in polList :
                info[i][j][k] = {'jdTime' : [], 'recTime' : [], 'chan' : [], 'trx' : [], 'errtrx' : [], 'gain' : [], 'errgain' : [], 'freq' : [],'elev' : [],'tsys':[]}
                info[i][j][k]['jdTime'],info[i][j][k]['elev'],info[i][j][k]['recTime'],info[i][j][k]['chan'],info[i][j][k]['trx'],info[i][j][k]['errtrx'],info[i][j][k]['gain'],info[i][j][k]['errgain'],info[i][j][k]['freq'],info[i][j][k]['tsys'] = parseTrx(i,k,j,filename)
    return info


def plotTrxInfo(antennaList=['DV01','DV02','DV03','DV04','DV05','PM02','PM03'],polList=[0,1],bandList=[3,6],filename=None) :
    if filename == None : filename='/data/checkTrx.txt'
    antennaList = makeList(antennaList)
    polList = makeList(polList)
    bandList = makeList(bandList)
    colorList = ['b','g','r','c','m','y','k']
    pointList = ['x','.','o','^','<','>','s','+',',','D','1','2','3','4','h','H','o','|','_']
    info = parseTrxInfo(antennaList,polList,bandList,filename)
    clf()
    limits = {3 : 100, 6: 100, 7:300, 9:500}
    spec = {3 : 30, 6: 70, 7:137, 9: 500}
    subplot(len(bandList),1,1)
    hold(True)
    rcParams['font.size'] = 9.0
    for i in range(len(antennaList)) :
        for j in range(len(bandList)) :
            subplot(len(bandList),1,j+1)
            for k in range(len(polList)) :
                legendInfo = 'Antenna %s' % (antennaList[i])
                time = info[antennaList[i]][bandList[j]][polList[k]]['jdTime']
                trx  = info[antennaList[i]][bandList[j]][polList[k]]['trx']
                err  = info[antennaList[i]][bandList[j]][polList[k]]['errtrx']
                psym = colorList[i]+pointList[k]
#                errorbar(time,trx,yerr=err,fmt=None)
                try:
                   if k==0 : plot(time,trx,psym,label=legendInfo)
                   else : plot(time,trx,psym)
                except:
                    print len(info[antennaList[i]][bandList[j]][polList[k]]['trx'])
                    print 'invalid data for antenna %s, polarization %i, band %i' % (antennaList[i],polList[k],bandList[j])
                print len(time),spec[bandList[j]]
                try: plot(time,[spec[bandList[j]]]*len(time),'k-')
                except: continue
            legend(loc=0)
            title('Trx vs time')
            xlabel('Julian Date')
            ylabel('Receiver Temperature (K)')
            ylim(0,limits[bandList[j]])
#    legend(loc=1)
    show()

def makeSpecTrx(freq,band) :
    newSpec = []
    for i in freq :
        low = (bandDefinitions[band][1]-bandDefinitions[band][0])*0.1/1e9+bandDefinitions[band][0]/1e9+6
        high = -(bandDefinitions[band][1]-bandDefinitions[band][0])*0.1/1e9+bandDefinitions[band][1]/1e9-6
        print low,high
        if band == 3 :
            if (i < low) or (i > high) : alpha = 10
            else : alpha = 6
        if band == 6 :
            if (i < low) or (i > high) : alpha = 10
            else : alpha = 6
            alpha = 6
        if band == 7 :
            if (i < low) or (i > high) : alpha = 12
            else : alpha = 8
        if band == 9 :
            if (i < low) or (i > high) : alpha = 15
            else : alpha = 10
        newSpec.append(0.048*alpha*i+4)
    return newSpec
                     
def plotTrxFreq(antennaList=['DV01','DV02','DV03','DV04','DV05','PM02','PM03'],polList=[0,1],bandList=[3,6],filename=None) :
    if filename == None : filename='/data/checkTrx.txt'
    
    antennaList = makeList(antennaList)
    polList = makeList(polList)
    bandList = makeList(bandList)
    colorList = ['b','g','r','c','m','y','k']
    pointList = ['x','o','.','^','<','>','s','+',',','D','1','2','3','4','h','H','o','|','_']
    info = parseTrxInfo(antennaList,polList,bandList,filename)
    clf()
    subplot(len(bandList),1,1)
    limits = {3 : 100, 6: 150, 7:300, 9:500}
    rcParams['font.size'] = 9.0
    hold(True)
    for i in range(len(antennaList)) :
        for j in range(len(bandList)) :
            subplot(len(bandList),1,j+1)
            legendInfo = 'Antenna %s, Band %s' % (antennaList[i],bandList[j])
            for k in range(len(polList)) :
                freq = info[antennaList[i]][bandList[j]][polList[k]]['freq']/1e9
                trx  = info[antennaList[i]][bandList[j]][polList[k]]['trx']
                err  = info[antennaList[i]][bandList[j]][polList[k]]['errtrx']
                psym = colorList[j]+pointList[i] ; print psym,len(trx),len(freq)
                plot(freq,trx,psym)
                newSpec = makeSpecTrx(freq,bandList[j])
                newSpec = np.array(newSpec)
                freq = np.array(freq)
                print newSpec.shape,freq.shape
                freq.sort()
                newSpec.sort()
                plot(freq,newSpec,'k-')
                ylim(0,limits[bandList[j]])
        legend(loc=0)
        title('Trx vs Frequency')
        xlabel('Frequency (GHz)')
        ylabel('Receiver Temperature (K)')
#    ylim(20,200)
    subplot(len(bandList),1,1)
    title('Trx vs Frequency')
    show()
    return newSpec

class MakeTable: 
    def __init__(self,inputMs,queryString='') :
        self.inputMs = inputMs
        self.queryString = queryString
        mytb = tbtool()
        self.makeSubtable(mytb)
        self.data = {}
        for i in self.subtable.colnames() : self.data[i] = self.subtable.getcol(i)
        mytb.close()

    def makeSubtable(self, mytb) :
        mytb.open(self.inputMs)
        self.subtable = mytb.query(self.queryString)

class Weather(MakeTable):
    def __init__(self,inputMs,pressureCut=700,location='AOS'):
        queryString = ("PRESSURE < %s" % pressureCut)
        MakeTable.__init__(self,"%s/WEATHER" % inputMs,queryString)
        self.location      = location
        self.getAtmProfile()
        self.data['ATM_TEMP'] = self.getAtmProfile()
        
    def getAtmProfile(self) :
        if self.location == 'AOS'   : alt = casac.Quantity(5000.0,'m')
        elif self.location == 'OSF' : alt = casac.Quantity(3000.0,'m')
        tatm = []
        tProfile = []
        for i in range(len(self.data["REL_HUMIDITY"])) : 
            tmp = casac.Quantity(self.data['TEMPERATURE'][i],'K')
            pre = casac.Quantity(self.data['PRESSURE'][i],'mbar')
            maxA = casac.Quantity(48.0,'km')
            hum = self.data["REL_HUMIDITY"][i]
            myatm   = at.initAtmProfile(alt,tmp,pre,maxA,hum)
            tempPro = at.getProfile()['temperature'] 
            tProfile.append(np.array(tempPro.value))
            tatm.append(sum(tempPro.value)/len(tempPro.value))
        return np.array(tatm)
        
class InterpolateTableTime: #I think this also would work for Frequency without trying at all, just have to fix verbage?  I also think the call in Tsys is wrong..and probably giving me all sorts of errors.
    def __init__(self,table,timeSeries=None,nonRealInterp='nearest',realInterp='linear',ifRepeat='average',tableQuery=None) :
        print """Warning: Interpolation of many variables may be inaccurate, be careful of using anything interpolated."""
        if nonRealInterp <> 'nearest' and nonRealInterp <> 'change' :
            print """You must enter nearetst or change for the nonRealInterp value.  Nearest is nearest neighbor, change
                     is the same value is repeated until the boolean changes values."""
            return
        else :
            self.nonrealInterpType = nonRealInterp
        if realInterp <> 'linear' and realInterp <> 'cubicspline' :
            print """You must enter linear or cubicspline for the nonRealInterp value.  Nearest is nearest neighbor, change
                     is the same value is repeated until the boolean changes values."""
            return
        else :
            self.realInterpType = realInterp
        self.table = table
        print self.table
        self.colNames = table.data.keys()
        if "TIME" not in self.colNames :
            print """CRITICAL: Time must be a component of the table to use this function."""
            return
        self.time = self.table.data["TIME"]
        self.oldData = self.table.data.copy()
        self.oldTime = self.oldData.pop("TIME")
        self.colNames.remove('TIME')
        self.timeSeries = timeSeries
        
    def interpolateData(self,timeSeries,quiet=False) :
        self.newTime = timeSeries
        self.newData = {}
        self.newTime.sort()
        if self.newTime.shape <> np.unique(self.newTime).shape :
            if not quiet : print "Removing repeated times."
            self.newTime = np.unique(self.newTime)

        for i in self.colNames :
            if not quiet : print "Doing parameter %s" % i
            if 'float' in str(self.oldData[i].dtype) or 'complex' in str(self.oldData[i].dtype) :
                if self.oldTime.shape <> np.unique(self.oldTime).shape :
                    tmpTime,tmpData = self.handleTimeRepeats(i)
                else :
                    tmpTime = self.oldTime ;  tmpData = self.oldData[i]
                tuppleMax  = self.oldData[i].shape[:-1]
                indexList  = np.ndindex(tuppleMax)
                _newTmp = []
                for j in indexList :
                    _tmpData = np.transpose(tmpData)[j][:]
                    if self.realInterpType == 'cubicspline' : _new = self.interpSpline(tmpTime,_tmpData)
                    elif self.realInterpType == 'linear' : _new = self.interpLinear(tmpTime,_tmpData)
                    _newTmp.append(np.transpose(_new))
                self.newData[i] = np.array(_newTmp)
                for j in range(len(self.newTime)) :
                    if self.oldTime[0]-self.newTime[j] > 0 :
                        self.newData[i][...,j] = self.oldData[i][...,0]
            else :
                if self.nonrealInterpType == 'change' : self.interpChange(i)
                elif self.nonrealInterpType == 'nearest' : self.interpNearest(i)
            self.newData[i] = np.squeeze(self.newData[i])

    def handleTimeRepeats(self,colname) : 
        tmpTime = []
        tmpData = []
        for j in np.unique(self.oldTime) :
            locos = np.where(self.oldTime == j)
            tmpTime.append(np.mean(self.oldTime[locos]))
            tmpData.append(np.mean(self.oldData[colname][...,locos],-1))
        tmpTime = np.array(tmpTime)
        tmpData = (np.squeeze(np.array(tmpData)))
        return tmpTime,tmpData

    def interpLinear(self,tmpTime,tmpData) :
        return np.interp(self.newTime,tmpTime,tmpData)

    def interpSpline(self,tmpTime,tmpData) :
        tck = splrep(tmpTime,tmpData,s=0)
        return splev(self.newTime,tck,der=0)

    def interpChange(self,colname) :
        self.newData[colname] = []
        for j in self.newTime :
            timeDiff = self.oldTime-j
            goodIndex = max(np.where(timeDiff < 0)[0])
            self.newData[colname].append(self.oldData[colname][goodIndex])
            self.newData[colname] = np.array(self.newData[colname])

    def interpNearest(self,colname) :
        self.newData[colname] = []
        for j in self.newTime :
            timeDiff = (self.oldTime-j)
            indexCount = abs(timeDiff).min()
            locos      = np.where(abs(timeDiff) == indexCount)
            self.newData[colname].append(np.mean(self.oldData[colname][locos]))
        self.newData[colname] = np.array(self.newData[colname])        

def getSourceFieldMapping(inputMs) :
    mytb = tbtool()
    mytb.open("%s/FIELD" % (inputMs) )
    sourceNames = mytb.getcol('NAME')
    sourceIds = {}
    for i in range(len(sourceNames)) :
        sourceIds[sourceNames[i]] = i
    mytb.close()
    return sourceIds,sourceNames

def getSourceScans(inputMs,sourceName) :
    if str(sourceName).isdigit() : fieldId = sourceName
    else:
        sourceIds,sourceNames = getSourceFieldMapping(inputMs)
        try:
            fieldId = sourceIds[sourceName]
        except:
            return 'What you talking about Willis?'
    tb.open(inputMs)
    scans = tb.getcol('SCAN_NUMBER')
    fields = tb.getcol('FIELD_ID')
    tb.close()
    list1 = where(fields == fieldId)
    fieldscans = scans[list1]
    return np.unique(fieldscans)

def getBasebandNumber(inputMs,spwId) :
    """
    Returns the number of the baseband for the specified spw in the specified ms.
    Obsoleted by msmd.baseband.
    """
    if (os.path.exists(inputMs) == False):
        print "au.getBasebandNumber(): measurement set not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    if ('BBC_NO' in mytb.colnames()):
        bbNums = mytb.getcol("BBC_NO")
    else:
        return -1
    mytb.close()
    return bbNums[spwId]

def getBasebandNumbers(inputMs) :
    """
    Returns the baseband numbers associated with each spw in the specified ms.
    Does not use msmd.
    Todd Hunter
    """
    if (os.path.exists(inputMs) == False):
        print "au.getBasebandNumbers(): measurement set not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    if ("BBC_NO" in mytb.colnames()):
        bbNums = mytb.getcol("BBC_NO")
    else:
        mytb.close()
        return(-1)
    mytb.close()
    return bbNums

def getTelescopeNameFromCaltable(caltable):
    return(plotbp3.getTelescopeNameFromCaltable(caltable))

def getFieldNamesFromCaltable(caltable):
    """
    Returns the field names in the specified caltable using casac.calanalysis.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "caltable not found"
        return -1
    myca = casac.calanalysis()
    myca.open(caltable)
    fieldnames = myca.field()
    myca.close()
    return fieldnames

def getFieldIDsFromCaltable(caltable):
    """
    Returns the field IDs in the specified caltable using casac.calanalysis.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "caltable not found"
        return -1
    myca = casac.calanalysis()
    myca.open(caltable)
    fieldids = [int(i) for i in myca.field(name=False)]
    myca.close()
    return fieldids

def unifyFieldTimes(vislist, field):
    """
    Copies the time for a field in the FIELD table from one ms to a list of
    ms.
    vislist: a list of measurement sets, or comma-delimited string
    field: integer ID or name (name is safer if IDs vary per ms)
    -Todd Hunter
    """
    if type(vislist) == str:
        vislist = vislist.split(',')
    ids, names = parseFieldArgument(vislist[0],field)
    field = names[0]
    mjdsec = getFieldTimes(vislist[0], ids[0])
    vislist = vislist[1:]
    myfield = field
    for vis in vislist:
        ids, names = parseFieldArgument(vis,field)
        result = setFieldTime(vis, field, mjdsec)
        if (result == -1): return
        # I don't see why the following is needed, but it gets an error without it
        # Objects/listobject.c:169: bad argument to internal function
        if (vis == vislist[-1]): break

def setFieldTime(vis, field, mjdsec):
    """
    Sets a cell in the TIME column of the field table.
    field: integer ID or name
    Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "vis not found: ", vis
        return -1
    ids, names = parseFieldArgument(vis,field)
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FIELD', nomodify=False)
    oldmjdsec = mytb.getcol('TIME')
    print "Updating field %d = %s in %s from %f to %f" % (ids[0],names[0],vis,oldmjdsec[ids[0]],mjdsec)
    oldmjdsec[ids[0]] = mjdsec
    mytb.putcol('TIME',oldmjdsec)
    mytb.close()

def getFieldTime(vis, field):
    """
    Returns the time (in mjd seconds) in the FIELD table for the specified
    field.
    field: integer ID or string ID or name
    -Todd Hunter
    """
    ids, names = parseFieldArgument(vis, field)
    mytimes = getFieldTimes(vis)
    return mytimes[ids[0]]

def getFieldTimes(vis, field=''):
    """
    Returns the TIME column of the field table from one measurement set,
    or a list of measurement sets.
    vis: string, list, or comma-delimited string
    field: integer ID or name (name is safer if IDs vary by ms)
    Todd Hunter
    """
    if (type(vis) == str):
        vislist = vis.split(',')
    else:
        vislist = vis
    mjdsecs = []
    for vis in vislist:
        if (not os.path.exists(vis)):
            print "vis not found"
            return -1
        if (field != -1 and field != ''):
            ids, names = parseFieldArgument(vis,field)
            myfield = ids[0]
        else:
            myfield = field
        if field != '' and field != -1:
            print "%s: field = %d" % (vis, myfield)
        mytb = createCasaTool(tbtool)
        mytb.open(vis+'/FIELD')
        mjdsec = mytb.getcol('TIME')
        mytb.close()
        if field == -1 or field == '':
            mjdsecs.append(mjdsec)
        else:
            mjdsecs.append(mjdsec[myfield])
    if len(mjdsecs) == 1:
        return mjdsecs[0]
    else:
        return mjdsecs
        

def getBasebandNumbersFromCaltable(caltable):
    """
    Returns the baseband numbers associated with each spw in the specified 
    caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getBasebandNumbersFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    spectralWindowTable = mytb.getkeyword('SPECTRAL_WINDOW').split()[1]
    mytb.close()
    mytb.open(spectralWindowTable)
    if ("BBC_NO" in mytb.colnames()):
        bbNums = mytb.getcol("BBC_NO")
    else:
        # until CAS-6853 is solved, need to get it from the name
#        print "BBC_NO not in colnames (CAS-6853).  Using NAME column."
        names = mytb.getcol('NAME')
        bbNums = []
        trivial = True
        for name in names:
            if (name.find('#BB_') > 0):
                bbNums.append(int(name.split('#BB_')[1].split('#')[0]))
                trivial = False
            else:
                bbNums.append(-1)
        if (trivial): bbNums = -1
    mytb.close()
    return bbNums

def getMeasurementSetFromCaltable(caltable) :
    """
    Returns the name of the parent measurement set from a caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getBasebandNumbersFromCaltable(): caltable not found"
        return -1
    myca = casac.calanalysis()
    myca.open(caltable)
    spectralWindowTable = myca.msname()
    myca.close()
#    mytb = createCasaTool(tbtool)
#    mytb.open(caltable)
#    spectralWindowTable = mytb.getkeyword('MSName')
#    mytb.close()
    return(spectralWindowTable)

def getAntennaNamesFromCaltable(caltable) :
    """
    Returns the antenna names from the specified caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getAntennaNamesFromCaltable(): caltable not found"
        return -1
#    myca = casac.calanalysis()
#    myca.open(caltable)
#    names = myca.antenna()  # a list
#    myca.close()
    mytb = createCasaTool(tbtool)
    mytb.open(caltable+'/ANTENNA')
    names = mytb.getcol('NAME')  # an array
    mytb.close()
    return names

def getMJDSecFromCaltable(caltable):
    """
    Returns the mean value of MJD seconds for the specified caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "Caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    mjdsec = np.mean(mytb.getcol('TIME'))
    mytb.close()
    return mjdsec

def getFlagsFromCaltable(caltable, returnDict=False, includeZeros=False, 
                         antenna='', spw=''):
    """
    Reads the number of flags in an antenna-based caltable, or reports a 
    dictionary of the number of flags keyed by scan, spw ID, and antenna name.
    antenna: limit to these specified antenna name(s) (comma-delimited string)
    spw: limit to these specified spws(s) (comma-delimited string)
    See also: au.snrFromCaltable
    -Todd Hunter
    """
    spws = getSpwsFromCaltable(caltable)
    antennas = getAntennaIDsFromCaltable(caltable)
    names = getAntennaNamesFromCaltable(caltable)
    scans = getScansFromCaltable(caltable)
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    antennaNames = antenna.split(',')
    d = {}
    nflags = 0
    spwIDs = []
    if spw != '':
        if type(spw) == str:
            vis = getMeasurementSetFromCaltable(caltable)
            if os.path.exists(vis):
                spwIDs = parseSpw(vis, spw)
            else:
                spwIDs = [int(i) for i in str(spw).split(',')]
        elif type(spw) == list or type(spw) == np.ndarray:
            spwIDs = [int(i) for i in spw]
        else:
            spwIDs = [spw]
    for scan in scans:
        d[scan] = {}
        for myspw in spws:
            if (spw == '' or myspw in spwIDs):
                d[scan][myspw] = {}
                for ant in antennas:
                    if (antenna == '' or names[ant] in antennaNames):
                        myt = mytb.query('ANTENNA1 == %d and SPECTRAL_WINDOW_ID == %d and SCAN_NUMBER == %d' % (ant, myspw, scan))
                        flags = myt.getcol('FLAG')
                        nflag = sum(flags.flatten())
                        nflags += nflag
                        myt.close()
                        if (nflag > 0 or includeZeros):
                            d[scan][myspw][names[ant]] = nflag
    mytb.close()
    if returnDict:
        return d
    else:
        return nflags
    
def getAntennaIDsFromCaltable(caltable) :
    """
    Returns the antenna IDs for which solutions exist in the specified caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.AntennaIDsFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    antennas = np.unique(mytb.getcol('ANTENNA1'))
    mytb.close()
    return antennas

def getTimesFromCaltable(caltable, datestring=False, prec=8, keyBy='',
                         antenna='', spw=''):
    """
    Returns the unique list of times in MJD seconds for which solutions exist 
    in the specified caltable. 
    datestring: if True, then return the date strings 
    prec: precision to use for datestring (6: nearest second, 7: tenth sec, etc)
    antenna: restrict search to times for this antenna1 ID
    spw: restrict search to times for this spw ID
    keyBy: 'antenna' or 'spw';  if set, then return a dictionary keyed by this
           parameter
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getTimesFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    antennaIDs = mytb.getcol('ANTENNA1')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    times = mytb.getcol('TIME')
    if (antenna != ''):
        idx = np.where(antennaIDs == int(antenna))
        times = times[idx]
        spws = spws[idx]
        antennaIDs = antennaIDs[idx]
    if (spw != ''):
        idx = np.where(spws == int(spw))
        times = times[idx]
        spws = spws[idx]
        antennaIDs = antennaIDs[idx]
    times, idx = np.unique(times, return_index=True)
    mytb.close()
    if datestring:
        times = mjdsecToUT(times, prec=prec)
    if keyBy in ['antenna','spw']:
        mydict = {}
        for i in range(len(times)):
            if (keyBy == 'antenna'):
                key = antennaIDs[idx[i]]
            elif (keyBy == 'spw'):
                key = spws[idx[i]]
            if key not in mydict:
                mydict[key] = []
            mydict[key].append(times[i])
        return mydict
    else:
        return times

def compareASDMSizeToCalibratedMS(path):
    """
    Computes the ratio of the total size of *.ms files in a pipeline run
    to the total size of the rawdata ASDMs.
    path: single string, list, or string with wildcard
          Assumes the subtree is S*/G*/M*/rawdata working etc.
    Returns: the ratio, or list of ratios
    -Todd Hunter
    """
    if type(path) == list:
        paths = path
    elif path.find('*') > 0:
        paths = glob.glob(path)
    else:
        paths = [path]
    ratios = []
    for path in paths:
        asdms = path+'/S*/G*/M*/rawdata/uid*'
        asdmSize = directorySize(asdms)
        if asdmSize <= 0:
            print "No ASDMs found. Skipping ", path
            continue
        working = path+'/S*/G*/M*/working/*.ms'
        msSize = directorySize(working)
        ratio = msSize / float(asdmSize)
        ratios.append(ratio)
    if len(ratios) == 1:
        return ratios[0]
    else:
        print "Median +- scaled MAD: %.2f +- %.2f" % (np.median(ratios),MAD(ratios))
        return ratios

def directorySize(path):
    """
    Returns the size in bytes of a directory tree, using os.path.getsize for
    each file.  Accepts wildcards, and will compute the sum of those paths.
    -Todd Hunter
    """
    total_size = 0
    if path.find('*') < 0:
        paths = [path]
    else:
        paths = glob.glob(path)
        print "Using %d paths" % (len(paths))
    for path in paths:
        for dirpath, dirnames, filenames in os.walk(path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                total_size += os.path.getsize(fp)
    return total_size

def tsysFromMOUSListobs(mous):
    """
    Parses a pipeline MOUS directory for all the listobs.txt files that are not associated with
    _target.ms and runs tsysFromListobs on all of them.
    -Todd Hunter
    """
    files = []
    for dirpath, dnames, fnames in os.walk(mous):
        for f in fnames:
            if f == 'listobs.txt':
                fullname = os.path.join(dirpath, f)
                if fullname.find('_target.ms') < 0:
                    files.append(fullname)
    for f in files:
        tsysFromListobs(f)
        print ""
    
def tsysFromListobs(listfile):
    """
    Parses a listobs text file and determines the number of Tsys scans on the phase calibrator(s)
    and science target(s).
    -Todd Hunter
    """
    if not os.path.exists(listfile):
        print "Could not find file: ", listfile
        return
    phaseCals = []
    scienceTargets = []
    phaseCalTsysScans = []
    scienceTargetTsysScans = []
    result = grep(listfile,'MeasurementSet Name: ')[0]
    vis = result.split(':')[2].strip().split()[0]
    print os.path.basename(vis)
    result = grep(listfile,'PHASE')[0]
    if result == '':
        print "No phase calibrators."
    else:
        lines = result.split('\n')
        for line in lines:
            loc = line.find('[')
            if loc > 0:
                firstHalf = line[:loc]
                lineNumber, startTime, dash, endTime, scan, fieldID, fieldName, nrows = firstHalf.split()
                spwlist, intents = line[loc:].split('] [')
                intents = intents.strip(']').split(',')
                phaseCals.append(fieldName)
        phaseCals = np.unique(phaseCals)
    result = grep(listfile,'TARGET')[0]
    if result == '':
        print "No science targets."
    else:
        lines = result.split('\n')
        for line in lines:
            loc = line.find('[')
            if loc > 0:
                firstHalf = line[:loc]
                lineNumber, startTime, dash, endTime, scan, fieldID, fieldName, nrows = firstHalf.split()
                spwlist, intents = line[loc:].split('] [')
                intents = intents.strip(']').split(',')
                scienceTargets.append(fieldName)
        scienceTargets = np.unique(scienceTargets)
    result = grep(listfile,'ATMOSPHERE')[0]
    if result == '':
        print "No Tsys scans"
    else:
        lines = result.split('\n')
        for line in lines:
            loc = line.find('[')
            if loc > 0:
                firstHalf = line[:loc]
                lineNumber, startTime, dash, endTime, scan, fieldID, fieldName, nrows = firstHalf.split()
                if fieldName in phaseCals:
                    phaseCalTsysScans.append(scan)
                if fieldName in scienceTargets:
                    scienceTargetTsysScans.append(scan)
    print "%d phaseCalibrator Tsys scans: '%s'  %s" % (len(phaseCalTsysScans), ','.join(phaseCalTsysScans), ','.join(phaseCals))
    print "%d scienceTarget   Tsys scans: '%s'  %s" % (len(scienceTargetTsysScans), ','.join(scienceTargetTsysScans), ','.join(scienceTargets))
    
def getScansFromCaltable(caltable, field=''):
    """
    Returns the unique list of scans for which solutions exist in 
    the specified caltable. 
    field: if specified, restrict to this field ID or name, or list thereof
         including comma-delimited string
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getScansFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    scans = []
    if field == '':
        scans = list(np.unique(mytb.getcol('SCAN_NUMBER')))
    else:
        vis = getMeasurementSetFromCaltable(caltable)
        if os.path.exists(vis):
            fields = parseFieldArgument(vis,field)[0]
            if len(fields) > 0:
                for field in fields:
                    myt = mytb.query('FIELD_ID==%d'%(field))
                    scans += list(np.unique(myt.getcol('SCAN_NUMBER')))
                myt.close()
                scans = np.unique(scans) # probably not necessary
        else:
            print "Could not find measurement set."
    mytb.close()
    return np.array(scans)

def getFieldsFromCaltable(caltable):
    """
    Returns the unique list of field IDs for which solutions exist in 
    the specified caltable. 
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getFieldsFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    fields = np.unique(mytb.getcol('FIELD_ID'))
    mytb.close()
    return fields

def snrFromCaltables(caltable, intent='PHASE', stat='median', bins=None, 
                     plotfile='', snr=[], xlim2=[0,58], ylim2=[0,0.71]):
    """
    Generates a histogram of the per-spw, per-field, per-interval SNRs (using 
    the requested statistic over antennas and polarizations) from the specified
    list of caltables.
    caltable: python list or wildcard string containing a 'hifa' table type
     e.g. '/lustre/naasc/sciops/comm/sbooth/pipeline/root/5.1.0_validation/*/S*/G*/M*/working/*hifa_timegaincal*solintint.gpcal.tbl'
      or  '/lustre/naasc/sciops/comm/sbooth/pipeline/root/5.1.0_validation/*/S*/G*/M*/working/*hifa_gfluxscale.s15*solintint.gpcal.tbl'
    intent: limit the solutions to this intent (must be 'PHASE' or 'CHECK')
    stat: 'max', 'median', 'min', 'scaledMad', 'fractionBelow3sigma'
    bins: default is range(0,max,1)
    plotfile: default is snrFromCaltables.png
    snr: a pre-computed list from a prior run of this function, to allow rapid
         re-plotting after changing the code
    Returns: list of SNRs
    """
    if type(caltable) == str:
        if (caltable.find('*')>=0):
            caltables = glob.glob(caltable)
        else:
            caltables = caltable.split(',')
        tableType = caltable.split('hifa_')[1].split('.tbl')[0]
    else:
        caltables = caltable
        tableType = caltable[0].split('hifa_')[1].split('.tbl')[0]
    projects = 0
    lowsnr = {}
    if len(snr) == 0:
        print "Working on %d caltables" % (len(caltables))
        intents = {}
        for i,caltable in enumerate(caltables):
            msname = getMeasurementSetFromCaltable(caltable)
            vis = os.path.join(os.path.dirname(caltable),msname)
            if not os.path.exists(vis):
                print "Could not find measurement set"
                continue
            if intent == 'PHASE':
                # Here we assume that there will be a phase calibrator.
                # Otherwise, we would have to do similar logic as for CHECK.
                field = getPhaseCalibrators(vis)[0]
            elif intent.find('CHECK') >= 0:
                if msname not in intents:
                    mymsmd = createCasaTool(msmdtool)
                    mymsmd.open(vis)
                    intents[msname] = mymsmd.intents()
                    mymsmd.close()
                myintents = intents[msname]
                if 'OBSERVE_CHECK_SOURCE#ON_SOURCE' in myintents:
                    field = getPhaseCalibrators(vis, intent='OBSERVE_CHECK_SOURCE#ON_SOURCE')
                else:
                    field = []
                if len(field) == 0: 
                    print "%3d: No CHECKSOURCE in %s (%s)" % (i, os.path.basename(caltable), os.path.dirname(caltable))
                    continue
                field = field[0]
            else:
                print "Unrecognized intent.  Must be either PHASE or CHECK."
                return
            mydict = snrFromCaltable(caltable, field=field)
            for spw in mydict:
                for field in mydict[spw].keys():
                    mysnr = mydict[spw][field][stat]
                    print "SNR=%.1f in spw %d field %d in %s" % (mysnr, spw, field, msname)
                    if mysnr < 3:
                        if caltable not in lowsnr:
                            lowsnr[caltable] = {}
                        lowsnr[caltable][spw] = mysnr
                    snr.append(mysnr)
            projects += 1
    else:
        print "No recomputing results, since snr was specified: ", snr
    print "min %s snr, max %s snr = " % (stat,stat), min(snr), max(snr)
    print "lowsnr results: ", lowsnr
    if bins is None:
        inc = 1
        bins = np.arange(0, ceil(max(snr))+inc*1.5, inc)
    pb.clf()
    pb.subplot(211)
    pb.hist(snr, bins)
    pb.xlim([0,max(snr)+max([1,0.01*max(snr)])])
    pb.xlabel('%s SNR in %s table' % (stat,tableType))
    pb.ylabel('Number of occurrences')
    pb.title(intent+' Calibrators from %d C5.1P2 pipeline benchmark datasets (%d spws)' % (projects, len(snr))) # len(caltables),len(snr)))

    adesc = pb.subplot(212)
    pb.hist(snr, bins, cumulative=True, normed=True)
    pb.xlim(xlim2)
    pb.ylim(ylim2)
    pb.xlabel('%s SNR in %s table' % (stat,tableType))
    pb.ylabel('Cumulative fraction with SNR < x')
    pb.grid(True)
    majorLocator = MultipleLocator(5)
    adesc.xaxis.set_major_locator(majorLocator)
    adesc.yaxis.grid(True,which='both')
    pb.show()
    if plotfile == '':
        plotfile = 'snrFromCaltables.png'
    pb.savefig(plotfile)
    return snr

def snrFromCaltable(caltable, spw='', field='', doplot=False, plotfile='',
                    perscan=False):
    """
    Extracts the SNR from a caltable, on a per-spw, per-field basis
    and computes the median, min, max, and scaled MAD of each.
    spw: limit spw to this spw or list of spws (integer, string, list or 
         comma-delimited string)
    field: limit field selection to this field ID, name or list thereof (or
         comma-delimited string)
    doplot: if True, plot a histogram of the values per spw per field
            multi-panel plot has: spws = columns, fields = rows
    plotfile: string, or True=automatic name: caltable+'_histogram.png'
    perscan: if True, then break down statistics per scan
    Returns: a dictionary keyed by spw, with subdictionaries keyed
       by field ID, and optionally, subdictionaries keyed by scan number
    See also: au.getFlagsFromCaltable
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "au.getSpwsFromCaltable(): caltable not found"
        return -1
    spws = getSpwsFromCaltable(caltable)
    fields = getFieldsFromCaltable(caltable)
    snrs = {}
    if spw != '':
        spws = parseSpwArgument(spw, spws)
    if field != '':
        vis = getMeasurementSetFromCaltable(caltable)
        if not os.path.exists(vis):
            vis = os.path.join(os.path.dirname(caltable), vis)
        if os.path.exists(vis):
            fields = parseFieldArgument(vis, field)[0]
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    if doplot:
        pb.clf()
        i = 0
    nspws = len(spws)
    nfields = len(fields)
    for spw in spws:
        snrs[spw] = {}
        for field in fields:
            if doplot:
                i += 1
                desc = pb.subplot(nfields, nspws, i)
            if perscan:
                scans = getScansFromCaltable(caltable, field)
                snrs[spw][field] = {}
                allsnr = np.array([])
                for scan in scans:
                    myt = mytb.query('SPECTRAL_WINDOW_ID == %d && FIELD_ID == %d && SCAN_NUMBER == %d' % (spw, field, scan))
                    snr = myt.getcol('SNR')
                    fraction = np.where(snr < 3)[0]
                    fraction = float(np.shape(fraction)[0]) / np.prod(np.shape(snr))
                    snrs[spw][field][scan] = {'median': np.median(snr), 'min': np.min(snr), 'max': np.max(snr), 'scaledMAD': MAD(snr), 'fractionBelow3sigma': fraction}
                    allsnr = np.append(allsnr,snr)
                snr = allsnr
                fraction = np.where(snr < 3)[0]
                fraction = float(np.shape(fraction)[0]) / np.prod(np.shape(snr))
                snrs[spw][field]['allscans'] = {'median': np.median(snr), 'min': np.min(snr), 'max': np.max(snr), 'scaledMAD': MAD(snr), 'fractionBelow3sigma': fraction}
            else:
                myt = mytb.query('SPECTRAL_WINDOW_ID == %d && FIELD_ID == %d' % (spw, field))
                snr = myt.getcol('SNR')
                if len(np.shape(snr)) == 0 or np.prod(np.shape(snr))==0:
                    print "Skipping spw=%s, field=%s, because shape(snr) = " % (str(spw),str(field)), np.shape(snr)
                    continue
                if np.shape(snr)[0] == 1:
                    print "Found a single pol solution in spw %d of %s" % (spw, caltable)
#                else:
#                    print "Found a %d-pol solution in spw %d of %s" % (np.shape(snr)[0], spw, caltable)
                fraction = np.where(snr < 3)[0]
                fraction = float(np.shape(fraction)[0]) / np.prod(np.shape(snr))
                snrs[spw][field] = {'median': np.median(snr), 'min': np.min(snr), 'max': np.max(snr), 'scaledMAD': MAD(snr), 'fractionBelow3sigma': fraction}
                myt.close()
            if doplot:
                pb.hist(snr.flatten(), 10)
                pb.xlabel('SNR in spw %d' % (spw))
                if spw > spws[0]:
                    desc.set_yticklabels([])
                else:
                    pb.ylabel('Number of occurrences')
    mytb.close()
    if doplot:
        pb.text(0.5,0.99, caltable, 
                transform=pb.gcf().transFigure, va='top', ha='center')
        pb.text(0.5,0.94, 'field=%s'%str(fields), 
                transform=pb.gcf().transFigure, va='top', ha='center')
        pb.show()
        if plotfile != '' and plotfile != False:
            if plotfile == True:
                plotfile = caltable+'_histogram.png'
            pb.savefig(plotfile)
            print "Wrote ", plotfile
    return snrs

def getSpwsFromCaltable(caltable, getNumberOfChannels=False):
    """
    Returns the unique list of spw IDs for which solutions exist in 
    the specified caltable. 
    getNumberOfChannels: if True, then return a dictionary, with values=nchan
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getSpwsFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    spws = np.unique(mytb.getcol('SPECTRAL_WINDOW_ID'))
    mytb.close()
    if getNumberOfChannels:
        mytb.open(caltable+'/SPECTRAL_WINDOW')
        spwdict = {}
        for spw in spws:
            spwdict[spw] = len(mytb.getcell('CHAN_FREQ',spw))
        mytb.close()
        return spwdict
    else:
        return spws

def getSpwMeanFreqFromCaltable(caltable, spw):
    """
    Returns the mean frequency (in GHz) of the specified spw in a caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    spectralWindowTable = mytb.getkeyword('SPECTRAL_WINDOW').split()[1]
    mytb.close()
    mytb.open(spectralWindowTable)
    spws = range(len(mytb.getcol('MEAS_FREQ_REF')))
    chanFreqGHz = []
    for i in spws:
        # The array shapes can vary.
        chanFreqGHz.append(np.mean(1e-9 * mytb.getcell('CHAN_FREQ',i)))
    mytb.close()
    return chanFreqGHz[spw]

def getNChanFromCaltable(caltable, spw=None):
    """
    Returns the number of channels of the specified spw in a caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    spectralWindowTable = mytb.getkeyword('SPECTRAL_WINDOW').split()[1]
    mytb.close()
    mytb.open(spectralWindowTable)
    if spw is None:
        nchan = mytb.getcol('NUM_CHAN')
    else:
        nchan = mytb.getcell('NUM_CHAN',spw)
    return nchan
    
def getChanFreqFromCaltable(caltable, spw, channel=None):
    """
    Returns the frequency (in GHz) of the specified spw channel in a caltable.
    channel: if not specified, then return array of all channel frequencies
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    spectralWindowTable = mytb.getkeyword('SPECTRAL_WINDOW').split()[1]
    mytb.close()
    mytb.open(spectralWindowTable)
    spws = range(len(mytb.getcol('MEAS_FREQ_REF')))
    chanFreqGHz = {}
    for i in spws:
        # The array shapes can vary, so read one at a time.
        spectrum = mytb.getcell('CHAN_FREQ',i)
        chanFreqGHz[i] = 1e-9 * spectrum
    mytb.close()
    if channel is None:
        return chanFreqGHz[spw]
    if channel > len(chanFreqGHz[spw]):
        print "spw %d has only %d channels"% (spw, len(chanFreqGHz[spw]))
    else:
        return chanFreqGHz[spw][channel]

def getConfig(vis):
    """
    Reads the ASDM_EXECBLOCK table for the configName. (available Cycle 5 onward)
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set"
        return
    mytable = os.path.join(vis,'ASDM_EXECBLOCK')
    if not os.path.exists(mytable):
        print "Could not find ASDM_EXECBLOCK table"
        return
    mytb = tbtool()
    mytb.open(mytable)
    configNames = mytb.getcol('configName')
    mytb.close()
    return configNames[0]

def getConfigFromASDM(asdm):
    """
    Reads the ASDM ExecBlock.xml file for the configName.
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM."
        return
    result = grep(asdm+'/ExecBlock.xml', 'configName')[0]
    if len(result) == 0:
        print "No configName in the ExecBlock.xml file."
        return
    configName = result.split('configName>')[1].replace('</','')
    return configName

def configs(telescope='alma', cycle=''):
    """
    List the configurations in the data/alma/simmos directory.  To view them:
    os.system('ls '+os.getenv('CASAPATH').split()[0]+'/data/alma/simmos')
    cycle: integer or string integer;  use 'cycle' to ignore the 'outN.cfg' files
    -Todd Hunter
    """
    print "Searching directory = ", os.getenv('CASAPATH').split()[0]+'/data/alma/simmos'
    if telescope != 'WSRT':
        telescope = telescope.lower()
    if (cycle != ''):
        if cycle != 'cycle':
            cycle = 'cycle' + str(cycle)
        else:
            cycle = 'cycle'
    myglob = os.getenv('CASAPATH').split()[0]+'/data/alma/simmos/%s*%s*'%(telescope,cycle)
    biglist = sorted([os.path.basename(i) for i in glob.glob(myglob)])
    uniqueList = []
    # remove the duplicates for cycle 1
    for b in biglist:
        if b.find('_') < 0:
            uniqueList.append(b)
    return uniqueList

def getBaselineLengthForStations(station1, station2, config='alma.all.cfg'):
    """
    Computes the baseline length between two ALMA stations.
    station1: name of first pad
    station2: name of second pad
    config: config file to search.  For ACA, use alma.aca.cfg, for VLA-A, use vla.a.cfg
    -Todd Hunter
    """
    if (not os.path.exists(config)):
        config = os.getenv('CASAPATH').split()[0]+'/data/alma/simmos/'+config
    mylist = np.array(getBaselineLengths(config=config, verbose=False))
    mykey = 'pad'+station1+'-pad'+station2
    mylengths = mylist[:,1]
    mypads = mylist[:,0]
    if (mykey in mypads):
        return float(mylengths[np.where(mypads==mykey)[0][0]])
    else:
        myOtherkey = 'pad'+station2+'-pad'+station1
        if (myOtherkey in mypads):
            return float(mylengths[np.where(mypads==myOtherkey)[0][0]])
        else:
            print "Baseline not found: %s or %s" % (mykey, myOtherkey)
            return 0

def getAntennaStationsFromCaltable(caltable) :
    """
    Returns the antenna names from the specified caltable.
    Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "au.getAntennaStationsFromCaltable(): caltable not found"
        return -1
    mytb = createCasaTool(tbtool)
    mytb.open(caltable+'/ANTENNA')
    names = mytb.getcol('STATION')
    mytb.close()
    return names

def imageChannelFrequency(img, channel=0):
    """
    Returns the frequency (in GHz) of the specified channel of any CASA or FITS
    image cube with a spectral axis.
    channel: can be a scalar or a list/vector, if -1 then return all channels
    Returns: scalar (if one channel) or array (if more than 1 channel)
    -Todd Hunter
    """
    maxchan = numberOfChannelsInCube(img)-1
    if (channel < 0 or channel > maxchan):
        print "Invalid channel, max=%d" % (maxchan)
        return
    pixel = [0,0,0,channel]
    myia = createCasaTool(iatool)
    myia.open(img)
    spectralAxis = findSpectralAxis(myia)
    freq = []
    nchan = myia.shape()[spectralAxis]
    if type(channel) != list and type(channel) != np.ndarray:
        if channel < 0:
            channels = range(nchan)
        else:
            channels = [channel]
    else:
        channels = channel
    for channel in channels:
        pixel[spectralAxis] = channel
        mydict = myia.toworld(pixel)
        if (len(mydict['numeric']) <= spectralAxis):
            print "Not a cube?"
            return
        freq.append(mydict['numeric'][spectralAxis])
    myia.close()
    freq = np.array(freq)
    if len(freq) == 1:
        freq = freq[0]
    return freq * 1e-9

def imageChannel(img, velocity):
    """
    Returns the channel corresponding to the specified velocity (in km/s) 
    in an image cube with a spectral axis.
    velocity: can be a scalar or a list/vector (in km/s)
    Returns: scalar (if one channel) or array (if more than 1 velocity)
    Not yet implemented.
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    pixel = np.zeros(len(myia.shape()))  # initialize an array to [0,0,0,0]
    spectralAxis = findSpectralAxis(myia)
    nchannels = myia.shape()[spectralAxis]
    mychannel = []
    if type(velocity) != list and type(velocity) != np.ndarray:
        velocities = [velocity]
    else:
        velocities = velocity
    for velocity in velocities:
        # stopped here
        chanvelocity = []
        for channel in range(nchannels):
            pixel[spectralAxis] = channel
            mydict = myia.toworld(pixel, 'm', dovelocity=True)
            vel = mydict['measure']['spectral']['radiovelocity']['m0']['value']
            unit = mydict['measure']['spectral']['radiovelocity']['m0']['unit']
            if unit=='m/s':
                vel *= 0.001
            elif unit != 'km/s':
                print "Unrecognized velocity unit: ", unit
                return
            chanvelocity.append(vel)
        idx = np.argsort(np.abs(np.array(chanvelocity)-velocity))
        deltaV = np.abs(chanvelocity[idx[0]] - chanvelocity[idx[1]])
        mychannel.append((np.abs(chanvelocity[idx[0]]-velocity)*idx[1] + np.abs(chanvelocity[idx[1]]-velocity)*idx[0]) / deltaV)
    myia.close()
    mychannel = np.array(mychannel)
    if len(mychannel) == 1:
        mychannel = mychannel[0]
    return mychannel
    
def imageChannelVelocity(img, channel=0, showEquation=False):
    """
    Returns the velocity (in km/s) of the specified channel of any CASA or FITS
    image cube with a spectral axis.
    channel: can be a scalar or a list/vector
    showEquation: if True, then derive an equivalent equation that could be used
    Returns: scalar (if one channel) or array (if more than 1 channel)
    -Todd Hunter
    """
    pixel = [0,0,0,channel]
    myia = createCasaTool(iatool)
    myia.open(img)
    spectralAxis = findSpectralAxis(myia)
    velocity = []
    if type(channel) != list and type(channel) != np.ndarray:
        channels = [channel]
    else:
        channels = channel
    for channel in channels:
        pixel[spectralAxis] = channel
        mydict = myia.toworld(pixel, 'm', dovelocity=True)
        vel = mydict['measure']['spectral']['radiovelocity']['m0']['value']
        unit = mydict['measure']['spectral']['radiovelocity']['m0']['unit']
        if unit=='m/s':
            vel *= 0.001
        elif unit != 'km/s':
            print "Unrecognized velocity unit: ", unit
            return
        velocity.append(vel)
        if channel == channels[0] and showEquation:
            pixel[spectralAxis] = channel+1
            mydict = myia.toworld(pixel, 'm', dovelocity=True)
            vel2 = mydict['measure']['spectral']['radiovelocity']['m0']['value'] 
            if unit=='m/s':
                vel2 *= 0.001
            increment = vel2 - vel
            print "Equivalent equation: velocity = %f + channel*%f" % (vel,increment)
    myia.close()
    velocity = np.array(velocity)
    if len(velocity) == 1:
        velocity = velocity[0]
    return velocity

def listImageRestFreq(img, includeChan0freq=True):
    """
    Prints the rest frequency from the header of one or more images.
    img: a list of images as a list or comma-delimited string; or a string with wildcards
    -Todd Hunter
    """
    if (type(img) == str):
        if (img.find('*') >= 0):
            img = sorted(glob.glob(img))
        else:
            img = img.split(',')
    print "RestFreq Chan0  image"
    for i in img:
        restfreq = parseFrequencyArgumentToGHz(imhead(i, mode='get', hdkey='restfreq'))
        if (includeChan0freq):
            freq = imageChannelFrequency(i)
            print "%.6f %.6f GHz  %s" % (restfreq, freq, i)
        else:
            print "%.6f GHz  %s" % (restfreq, i)

def medianTsysForRestFrequencySpw(vis, restfreq, field='3'):
    """
    Finds the median Tsys of the Tsys spw that maps to the science spw
    that contains the requested rest frequency (as defined in the OT).
    restfreq: requested value in GHz, Hz, or a string with units
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    spw = spwForRestFrequency(vis, restfreq, mymsmd=mymsmd)
    tsysspw = tsysspwmapWithNoTable(vis, field, spw, mymsmd=mymsmd)
    print "Using science spw = %d (tsys=%d)" % (spw, tsysspw)
    tsys = medianTsysForField(vis, field, tsysspw, mymsmd=mymsmd)
    mymsmd.close()
    return tsys

def spwForRestFrequency(vis, restfreq, warningThresholdMHz=10, mymsmd=''):
    """
    Finds the spw that contains the rest frequency definition (from the OT)
    that is closest to the requested value.
    restfreq: requested value in GHz, Hz or a string with units
    """
    hz = parseFrequencyArgumentToHz(restfreq)
    mydict = restFrequencies(vis, mymsmd=mymsmd)
    values = []
    spws = []
    for i in mydict:
        spws += [i]*len(mydict[i])
        values += list(mydict[i])
    values = np.array(values)
    freqdiff = np.abs(hz - values)
    idx = np.argmin(freqdiff)
    spw = spws[idx]
    if freqdiff[idx] > warningThresholdMHz*1e6:
        print "Closest rest frequency differs by more than %.1fMHz from the request." % (warningThresholdMHz)
    return spw
    
def restFrequencies(vis, spw='', source='', intent='OBSERVE_TARGET', 
                    verbose=False, showIF=False, showSpwFreq=False, 
                    showBB=False, mymsmd=''):
    """
    Returns a dictionary of rest frequencies (in Hz) for specified spw(s) (and source).
    spw: list or comma-delimited string;  if blank, then use all science spws
    source: can be integer ID or string name or list or comma-delimited string
    intent: if source is blank, then use first one with matching intent and spw
    showIF: if True, then show the IF frequency as well in the dictionary
    showSpwFreq: if True, then show the spw center frequency as well in the dictionary
    showBB: if True, then show the center frequency of the baseband (via the SQLD spws)
    """
    if (not os.path.exists(vis)):
        print "Could not find ms"
        return
    freq = {}
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    if (spw == ''):
        spw = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)
    else:
        spw = parseSpw(vis, spw, mymsmd=mymsmd)
    if showIF:
        LOs = interpretLOs(vis, mymsmd=mymsmd)  # dictionary keyed by spw
    if showBB:
        basebandFreqs = getScienceBasebandFrequencies(vis, mymsmd=mymsmd)
        if basebandFreqs is None:
            print "The showBB option is not available for this dataset."
            showBB = False
    for myspw in spw:
        freq[myspw] = restFrequency(vis, myspw, source, intent, verbose, 
                                    mymsmd=mymsmd)
        if showIF or showBB or showSpwFreq:
            freq[myspw] = {'frequency': freq[myspw]}
        if showIF:
            ifFreq = freq[myspw]['frequency'] - LOs[myspw]  # negative values are LSB
            freq[myspw]['IF'] = ifFreq
        if showSpwFreq:
            spwFreq = getMeanFreqOfSpwlist(vis, myspw, mymsmd=mymsmd)
            freq[myspw]['spwCenterFreq'] = spwFreq
        if showBB:
            baseband = mymsmd.baseband(myspw)
            freq[myspw]['basebandFreq'] = basebandFreqs[baseband]
            freq[myspw]['baseband'] = baseband
    if needToClose:
        mymsmd.close()
    return freq

def restFrequenciesASDM(asdm):
    """
    Reads the rest frequencies for the science target spws in an ASDM and returns a dictionary,
    keyed by the spw number, as they will appear in a measurement set once it is imported.
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    if (not os.path.exists(asdm+'/Source.xml')):
        print "Could not find Source.xml"
        return
    xmlscans = minidom.parse(asdm+'/Source.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    restFreqs = {}
    for rownode in rowlist:
        row = rownode.getElementsByTagName("velRefCode")
        if (len(row) > 0):
            row = rownode.getElementsByTagName("spectralWindowId")
            spw = int(str(row[0].childNodes[0].nodeValue).split('_')[1])
            row = rownode.getElementsByTagName("restFrequency")
            tokens = (row[0].childNodes[0].nodeValue).split()
            restFreqs[spw] = []
            for i in range(int(tokens[1])):
                restFreqs[spw].append(float(tokens[2+i]))
    scienceSpwsASDM = restFreqs.keys()
    spwmap = asdmspwmap(asdm)
    scienceSpws = []
    mydict = getSpwsFromASDM(asdm)
    restFreqMS = {}
    for spw in scienceSpwsASDM:
        myspw = spwmap.index(spw)
        if mydict[myspw]['numChan'] > 1:
            restFreqMS[myspw] = restFreqs[spw]
    return restFreqMS

def restFrequency(vis, spw, source='', intent='OBSERVE_TARGET', verbose=True, 
                  mymsmd=None):
    """
    Returns the list of rest frequencies (in Hz) for specified spw (and source).
    source: can be integer ID or string name
    intent: if source is blank, then use first one with matching intent and spw
    """
    if (not os.path.exists(vis)):
        print "restFrequency: Could not find measurement set"
        return
    needToClose = False
    if mymsmd is None:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    spw = int(spw)
    if (spw >= mymsmd.nspw()):
        print "spw %d not in the dataset" % (spw)
        if needToClose:
            mymsmd.close()
        return
    meanfreq = mymsmd.meanfreq(spw)
    bandwidth = mymsmd.bandwidths(spw)
    chanwidth = mymsmd.chanwidths(spw)[0]
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SOURCE')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    sourceIDs = mytb.getcol('SOURCE_ID')
    names = mytb.getcol('NAME')
    spw = int(spw)
    if (type(source) == str):
        if (source.isdigit()):
            source = int(source)
        elif (source == ''):
            # pick source
            fields = mymsmd.fieldsforintent(intent+'*')
            fields2 = mymsmd.fieldsforspw(spw)
            fields = np.intersect1d(fields,fields2)
            source = mymsmd.namesforfields(fields[0])[0]
            if verbose:
                print "For spw %d, picked source: " % (spw), source
    if (type(source) == str):
        sourcerows = np.where(names==source)[0]
        if (len(sourcerows) == 0):
            # look for characters ()/ and replace with underscore
            names = np.array(sanitizeNames(names))
            if verbose:
                print "Checking %s against sanitized names = " % source, names
            sourcerows = np.where(names==source)[0]
    else:
        sourcerows = np.where(sourceIDs==source)[0]
    if needToClose:
        mymsmd.close()
    spwrows = np.where(spws==spw)[0]
    row = np.intersect1d(spwrows, sourcerows)
    if mytb.iscelldefined('REST_FREQUENCY',row):
        freq = mytb.getcell('REST_FREQUENCY',row)
    else:
        freq = 0
        print "Rest frequency cell not defined for this source/spw combination (row=%s)." % row
        return([])
    mytb.close()
    velocity = c_mks*0.001*(freq-meanfreq)/freq
    deltav = c_mks*0.001*bandwidth/freq
    if verbose:
        print "Velocity of central channel = %f km/s (width = %f km/s)" % (velocity, chanwidth*c_mks*0.001/freq)
        print "Width of spw = %f km/s,  87.5%% = %f km/s, half that = %f km/s" % (deltav,0.85*deltav,0.5*0.85*deltav)
    return(freq)

def approximateBarycentricCoordinatesOfEarth(date=''):
    """
    Based on astronomical almanac for 1998.
    """
    jd = mjdToJD(dateStringToMJD(date,verbose=False))
    X = -0.00450 + 0.999760*np.cos(2*np.pi * (jd - 2451078.5) / 365.24219 )
    Y = -0.01389 + 0.916742*np.cos(2*np.pi * (jd - 2451169.5) / 365.24219 )
    return(X,Y)

def meanObliquity(date=''):
    """
    Returns the mean obliquity in radians for the specified date/time.
    Explanatory supplment to astronomical almanac, equation 3.222-1
    date: blank means use the current time; otherwise:
    Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
    """
    if (date == ''):
        mjd = getMJD()
    else:
        mjd = dateStringToMJD(date,verbose=False)
    t = (mjdToJD(mjd) - 2451545.0)/36525.
    epsilon0 = 23+26/60.+21.448/3600.+(-46.8160*t - 0.00059*t**2 + 0.001813*t**3)/3600.
    return(np.radians(epsilon0))

def radecParallaxToRadec(parallax, radec='', date='', vis='', field=-1,
                         verbose=False):
    """
    parallax: a value in arcsec
    radec: a sexagesimal string
    date: date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
    vis: measurement set from which to read date (if it is not specified)
    field: field in vis from which to read radec
    """
    if (radec == ''):
        if (vis== '' or field<0):
            print "Must specify vis&field or radec"
            return
        if (not os.path.exists(vis)):
            print "Could not find measurement set."
            return
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        radec = direction2radec(mymsmd.phasecenter(int(field)))
        mymsmd.close()
        if (date == ''):
            date = getObservationStartDate(vis)
    rarad, decrad = radec2rad(radec)
    c = np.cos(rarad)/np.cos(decrad)/15.0 # see B23 of 1998 almanac for /15
    d = np.sin(rarad)/np.cos(decrad)/15.0 # see B23 of 1998 almanac for /15
    epsilon0 = meanObliquity(date)
    cprime = np.tan(epsilon0)*np.cos(decrad) - np.sin(rarad)*np.sin(decrad)
    dprime = np.cos(rarad)*np.sin(decrad)
    X,Y = approximateBarycentricCoordinatesOfEarth(date)
    rao = 15*np.cos(decrad)* parallax * (d*X - c*Y)
    deco = parallax * (dprime*X - cprime*Y)
    if verbose:
        print "X=%f, Y=%f, c=%f, d=%f, c'=%f, d'=%f, rao=%f, dec=%f" % (X, Y, c, d, cprime, dprime, rao, deco)
    newradec = radecOffsetToRadec([rarad,decrad], rao, deco, verbose=False)
    result = angularSeparationOfStrings(radec,newradec,returnComponents=True,verbose=False)
    separation,raSep,decSep,raSepCosDec,positionAngle = result
    print 'Shift = %f arcsec = %.2f%% (%f" in RA, %f" in Dec)' % (separation*3600, separation*360000/parallax, raSepCosDec*3600, decSep*3600)
    return newradec

def applyProperMotion(vis, source, field=-1, otCoordinates='', parallax=0, 
                      verbose=True):
    """
    Reads the proper motion for a source, then subtracts it from the phase center
    of the specified field (to produce the epoch 2000 position).
    source: ID (integer or string integer or name)
    field: ID (integer or string integer or name), if not specified, then use first field for the source
    otCoordinates: if specified, then also compute angular separation in arcsec from these coordinates
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "properMotion: Could not find measurement set"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if type(source) == str:
        if source not in mymsmd.sourcenames():
            if source.isdigit():
                source = int(source)
            else:
                print "Source name not found among: %s" % (str(mymsmd.sourcenames()))
                mymsmd.close()
                return
        # leave it as a name string, since properMotion can accept it this way
    else:
        source = int(source)
    if (field < 0 and type(source) is not str):
        uniqueIDs = np.unique(mymsmd.sourceidsfromsourcetable())
        if source in uniqueIDs:
            field = mymsmd.fieldsforsource(source)[0]
        else:
            print "There are only %d sources in this ms." % (len(uniqueIDs))
            return
    else:
        if field < 0:
            field = source
        fieldids, fieldnames = parseFieldArgument(vis, field)
        field = fieldids[0]
    pmra, pmdec = properMotion(vis, source)
    mydir = mymsmd.phasecenter(field)
    mytime = np.mean(mymsmd.timesforfield(field))
    mymsmd.close()
    ra = mydir['m0']['value']
    dec = mydir['m1']['value']
    phaseCenter = rad2radec(ra,dec, prec=7, verbose=False)
    if verbose: print "Phase center = ", phaseCenter
    years = (mytime - dateStringToMJDSec('2000/01/01 12:00',verbose=False))/31556925.
    print "Applying %f years of motion" % (years)
    rao = -pmra*years
    deco = -pmdec*years
    radec = radecOffsetToRadec([ra,dec], rao, deco, verbose=False)
    if verbose: print "Inferred epoch 2000 center = ", radec
    if (otCoordinates != ''):
        separation = angularSeparationOfStrings(radec,otCoordinates, verbose=False)
        if (parallax > 0):
            percentage = 3600*100.*separation/parallax
            print "Difference from OT coordinates = %f arcsec = %.2f%% of the parallax." % (separation*3600,percentage)
        else:
            print "Difference from OT coordinates = %f arcsec" % (separation*3600)
    else:
        separation, longsep, latsep, longsepcosdec, pa = angularSeparationOfStrings(radec, phaseCenter, returnComponents=True, returnArcsec=True)
        print "Angular motion = %g arcsec:  RA = %g arcsec, Dec = %g arcsec" % (separation, longsepcosdec, latsep)
    return radec

def properMotionASDM(asdm, source=None, arcsecPerYear=True):
    """
    Reads the proper motion from the ASDM Source.xml file 
    and returns a dictionary, keyed by the source name
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    if (not os.path.exists(asdm+'/Source.xml')):
        print "Could not find Source.xml"
        return
    xmlscans = minidom.parse(asdm+'/Source.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    properMotion= {}
    for rownode in rowlist:
        row = rownode.getElementsByTagName("sourceName")
        tokens = (row[0].childNodes[0].nodeValue).split()
        sourceName = str(tokens[0])
        row = rownode.getElementsByTagName("properMotion")
        if (len(row) > 0 and sourceName not in properMotion):
            tokens = (row[0].childNodes[0].nodeValue).split()
            properMotion[sourceName] = [float(tokens[2]), float(tokens[3])]
            if arcsecPerYear:
                properMotion[sourceName] = list(np.degrees(np.array(properMotion[sourceName]))*3600*31556925)
    if source is not None and source in properMotion:
        properMotion = properMotion[source]
    return properMotion

def properMotion(vis, source=None, spw='', arcsecPerYear=True):
    """
    Reads the SOURCE table of a measurement set and returns the proper 
    motion for specified source in native units (rad/sec) or in arcsec/year.
    source: can be integer ID or string name, if None, then show all of them
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "properMotion: Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SOURCE')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    sources = mytb.getcol('SOURCE_ID')
    names = mytb.getcol('NAME')
    if (type(source) == str):
        if (source.isdigit()):
            source = int(source)
    if (type(source) == str):
        source = sources[np.where(names==source)[0]][0]
    
    if source is not None:
        sourcerows = np.where(sources==source)[0]
        if (len(sourcerows) == 0):
            print "Did not find %s in %s" % (str(source), str(sources))
            return
        if (spw == ''):
            row = sourcerows[0]
        else:
            spwrows = np.where(spws==int(spw))[0]
            row = np.intersect1d(spwrows, sourcerows)
        try:
            propermotion = mytb.getcell('PROPER_MOTION',row)
        except:
            propermotion = 0
            print "Source does not match with spw."
        mytb.close()
        if arcsecPerYear:
            propermotion = np.degrees(propermotion)*3600*31556925
        return(propermotion)
    else:
        pm = {}
        for i,source in enumerate(sources):
            sourcerows = np.where(sources==source)[0]
            if (spw == ''):
                row = sourcerows[0]
            else:
                spwrows = np.where(spws==int(spw))[0]
                row = np.intersect1d(spwrows, sourcerows)
            try:
                pm[names[i]] = mytb.getcell('PROPER_MOTION',row)
            except:
                pm[names[i]] = 0
                print "Source does not match with spw."
            if arcsecPerYear:
                pm[names[i]] = np.degrees(pm[names[i]])*3600*31556925
        return pm

def radialVelocity(vis, source, spw=''):
    """
    Returns the systemic velocity (or list) for specified spw and source.
    source: can be integer ID or string name
    spw: integer or string; if not specified, then use first TDM or
         FDM spw with OBSERVE_TARGET intent
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "radialVelocity: Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SOURCE')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    sources = mytb.getcol('SOURCE_ID')
    names = mytb.getcol('NAME')
    if (type(source) == str):
        if (source.isdigit()):
            source = int(source)
    if (type(source) == str):
        sourcerows = np.where(names==source)[0]
    else:
        sourcerows = np.where(sources==source)[0]
    if (spw == ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        almaspws = mymsmd.almaspws(tdm=True,fdm=True)
        targetspws = mymsmd.spwsforintent('OBSERVE_TARGET*')
        mymsmd.close()
        spw = np.intersect1d(np.intersect1d(targetspws, spws),almaspws)[0]
        print "Choosing spw = ", spw
    else:
        spw = int(spw)
    spwrows = np.where(spws==spw)[0]
    row = np.intersect1d(spwrows, sourcerows)
    frame = 'unknown frame'
    veltype = 'velocity'
    units = 'm/s'
    try:
        velocity = mytb.getcell('SYSVEL',row)
        if len(velocity) == 1:
            velocity = velocity[0]
        mydict = mytb.getcolkeywords('SYSVEL')
        if 'MEASINFO' in mydict:
            frame = mydict['MEASINFO']['Ref']
            veltype = mydict['MEASINFO']['type']
        if 'QuantumUnits' in mydict:
            units = mydict['QuantumUnits'][0]
    except:
        velocity = 0
        print "Source does not match with spw."
    mytb.close()
    velocity_kms = velocity*1e-3
    print "%s = %s %s (%s)" % (veltype, str(velocity), units, frame)
    return(velocity)

def representativeSpw(vis, verbose=True):
    """
    Reads the representative frequency from the measurement set, then computes which science
    spw(s) contains it.
    -Todd Hunter
    """
    freq = representativeFrequency(vis, verbose, reportSpw=False)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    spws = getScienceSpwsForFrequency(vis, freq, mymsmd=mymsmd)
    if (len(spws) == 1):
        value = spws[0]
    elif (len(spws) == 0):
        print "No spws cover the representative frequency (%g GHz)" % (freq)
        spws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False)
        print "Spw central frequencies in GHz: ", np.array([mymsmd.meanfreq(spw) for spw in spws]) * 1e-9
        value = None
    else:
        print "Multiple spws (%s) cover the representative frequency (%g GHz)" % (str(spws),freq)
        print "Returning the one nearest to the center."
        spw = getScienceSpwsForFrequency(vis, freq, nearestOnly=True, mymsmd=mymsmd)
        value = spw
    mymsmd.close()
    return value

def observingMode(vis):
    """
    Reads the observing mode from the ASDM_SUMMARY table (if imported).
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/ASDM_SBSUMMARY')):
        print "ASDM_SBSUMMARY table does not exist for this measurement set."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ASDM_SBSUMMARY')
    mode = mytb.getcol('observingMode')
    return(mode)

def representativeFrequency(vis, verbose=True, reportSpw=True):
    """
    Get the representative frequency from the ASDM_SBSUMMARY table of a
    measurement set, if it has been imported with asis.
    e.g. [representativeFrequency = 230.0348592858192 GHz, ...] 
    verbose: if True, then also print the min/max acceptable angular resolutions
    reportSpw: if True, then also report the spw that contains this frequency
    Returns the value in GHz.
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    if (not os.path.exists(vis+'/ASDM_SBSUMMARY')):
        print "Could not find ASDM_SBSUMMARY table.  Did you not import it with asis='SBSummary'?"
        return
    mytb.open(vis+'/ASDM_SBSUMMARY')
    scienceGoal = mytb.getcol('scienceGoal')
    mytb.close()
    freq = 0
    minAcceptableResolution = 0
    maxAcceptableResolution = 0
    bw = None
    for args in scienceGoal:
        for arg in args:
            loc = arg.find('representativeFrequency')
            if (loc >= 0):
                tokens = arg[loc:].split()
                freq = parseFrequencyArgumentToGHz(tokens[2]+tokens[3])
            loc = arg.find('representativeBandwidth')
            if (loc >= 0):
                tokens = arg[loc:].split()
                bw = parseFrequencyArgumentToGHz(tokens[2]+tokens[3])
            loc = arg.find('minAcceptableAngResolution')
            if (loc >= 0):
                tokens = arg[loc:].split()
                minAcceptableResolution = float(tokens[2])
                minUnits = tokens[3]
            loc = arg.find('maxAcceptableAngResolution')
            if (loc >= 0):
                tokens = arg[loc:].split()
                maxAcceptableResolution = float(tokens[2])
                maxUnits = tokens[3]
    if verbose:
        print "minAcceptableResolution = %f %s" % (minAcceptableResolution, minUnits)
        print "maxAcceptableResolution = %f %s" % (maxAcceptableResolution, maxUnits)
        if bw is not None:
            print "representativeBandwidth = %f GHz" % (bw)
        if reportSpw:
            print "Looking for spw that contains this frequency..."
            spw = representativeSpw(vis, verbose=False)
            if spw is not None:
                print "representative spw = ", spw
    return(freq)

def representativeSource(vis, verbose=True):
    """
    Get the representative source from the ASDM_SBSUMMARY table of a
    measurement set, if it has been imported with asis.
    If the direction is not (0,0), i.e. Cycle 5 onward data, then return a 
    dictionary of {fieldID: fieldName}
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    if (not os.path.exists(vis+'/ASDM_SBSUMMARY')):
        print "Could not find ASDM_SBSUMMARY table.  Did you not import it with asis='SBSummary'?"
        return
    mytb.open(vis+'/ASDM_SBSUMMARY')
    direction = mytb.getcol('centerDirection')
    directionCode = mytb.getcol('centerDirectionCode')
    directionEquinox = mytb.getcol('centerDirectionEquinox')
    mytb.close()
    if (direction[0][0] == 0. and direction[1][0] == 0.):
        print "The values are not filled.  It should be present starting in Cycle 5 data (CPM6)."
        return
    fieldID,separation = findNearestFieldInVis(vis, rad2radec(direction[0], direction[1], verbose=False), 
                                               returnSeparation=True)
    if verbose:
        print "Separation = %f deg" % separation
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    fieldName = mymsmd.namesforfields(fieldID)[0]
    mymsmd.close()
    return({fieldID: fieldName})

def updateSBSummary(vis, representativeFrequency=None, 
                    minAcceptableAngResolution=None, 
                    maxAcceptableAngResolution=None,
                    dynamicRange=None, representativeBandwidth=None,
                    representativeSource=None):
    """
    Updates the ASDM_SBSUMMARY table of a measurement set with one or more new
    values.  If a value is not present in the existing table and also not 
    specified, then it will remain not present in the updated table.
    representativeFrequency: float value in typical units (GHz), 
            or string with units (space before units is optional)
    minAcceptableAngResolution: float value in typical units (arcsec), 
            or string with units (space before units is required)
    maxAcceptableAngResolution: float value in typical units (arcsec), 
            or string with units (space before units is required)
    dynamicRange: float value
    representativeBandwidth: float value in typical units (GHz), 
            or string with units (space before units is optional)
    representativeSource: string
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find ms."
        return
    t = vis+'/ASDM_SBSUMMARY'
    if not os.path.exists(t):
        print "Could not find ASDM_SBSUMMARY table for this ms.  Was it imported?"
        return
    if (representativeFrequency is not None or 
        minAcceptableAngResolution is not None or 
        maxAcceptableAngResolution is not None or
        dynamicRange is not None or representativeBandwidth is not None or
        representativeSource is not None):
        update = True
    else:
        update = False
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ASDM_SBSUMMARY', nomodify=False)
    scienceGoal = mytb.getcol('scienceGoal')
    numScienceGoal = mytb.getcol('numScienceGoal')[0]
    # Read the existing values for those that were not specified
    for i,args in enumerate(scienceGoal):
        # args will look like: 
        # array(['representativeFrequency = 219.55647641503566 GHz'])
        for arg in args:
            # arg will look like: 
            #  'representativeFrequency = 219.55647641503566 GHz'
            loc = arg.find('representativeFrequency')
            if (loc >= 0 and representativeFrequency is None):
                tokens = arg[loc:].split()
                representativeFrequency = float(tokens[2])
                freqUnits = tokens[3]
            loc = arg.find('minAcceptableAngResolution')
            if (loc >= 0 and minAcceptableAngResolution is None):
                tokens = arg[loc:].split()
                minAcceptableAngResolution = float(tokens[2])
                minUnits = tokens[3]
            loc = arg.find('maxAcceptableAngResolution')
            if (loc >= 0 and maxAcceptableAngResolution is None):
                tokens = arg[loc:].split()
                maxAcceptableAngResolution = float(tokens[2])
                maxUnits = tokens[3]
            loc = arg.find('dynamicRange')
            if (loc >= 0 and dynamicRange is None):
                tokens = arg[loc:].split()
                dynamicRange = float(tokens[2])
            loc = arg.find('representativeBandwidth')
            if (loc >= 0 and representativeBandwidth is None):
                tokens = arg[loc:].split()
                representativeBandwidth = float(tokens[2])
                bwUnits = tokens[3]
            loc = arg.find('representativeSource')
            if (loc >= 0 and representativeSource is None):
                tokens = arg[loc:].split()
                representativeSource = str(tokens[2])
    if update:
        # convert any command-line arguments from string to value and units
        if type(representativeFrequency) is str:
            representativeFrequency = parseFrequencyArgumentToGHz(representativeFrequency)
            freqUnits = 'GHz'
        if type(representativeBandwidth) is str:
            representativeBandwidth = parseFrequencyArgumentToGHz(representativeBandwidth) * 1000
            bwUnits = 'MHz'
        if type(dynamicRange) is str:
            dynamicRange = float(dynamicRange)
        if type(minAcceptableAngResolution) is str:
            result = minAcceptableAngResolution.split()
            if len(result) == 1:
                value = result
                minUnits = 'arcsec'
            else:
                value, minUnits = result
            minAcceptableAngResolution = float(value)
        if type(maxAcceptableAngResolution) is str:
            result = maxAcceptableAngResolution.split()
            if len(result) == 1:
                value = result
                maxUnits = 'arcsec'
            else:
                value, maxUnits = result
            maxAcceptableAngResolution = float(value)
        newvalues = []
        if representativeFrequency is not None:
            newvalues += [['representativeFrequency = %f %s'%(representativeFrequency,freqUnits)]]
        if minAcceptableAngResolution is not None:
            newvalues += [['minAcceptableAngResolution = %f %s'%(minAcceptableAngResolution, minUnits)]]
        if maxAcceptableAngResolution is not None:
            newvalues += [['maxAcceptableAngResolution = %f %s'%(maxAcceptableAngResolution, maxUnits)]]
        if dynamicRange is not None:
            newvalues += [['dynamicRange = %f'%(dynamicRange)]]
        if representativeBandwidth is not None:
            newvalues += [['representativeBandwidth = %f %s'%(representativeBandwidth, bwUnits)]]
        if representativeFrequency is not None:
            newvalues += [['representativeSource = %s'%representativeSource]]
        newvalues = np.array(newvalues, dtype=str)
        if len(newvalues) != numScienceGoal:
            print "Updating numScienceGoal to %d" % (len(newvalues))
            mytb.putcol('numScienceGoal',[len(newvalues)])
            casalog.post('Wrote new value of numScienceGoal to %s/ASDM_SBSUMMARY: %d'%(vis,len(newvalues)))
        print "Putting new values:\n", newvalues
        mytb.putcol('scienceGoal',newvalues)
        casalog.post('Wrote new values to %s/ASDM_SBSUMMARY: %s'%(vis,str(newvalues)))
    else:
        print "Current values: shape=%s\n" % (str(np.shape(scienceGoal))), scienceGoal
        print "Looking for spw that contains the representative frequency..."
        spw = representativeSpw(vis,verbose=False)
        if spw is not None:
            print "spw = ", spw
    mytb.close()

def updateSBSummaryASDM(asdm, representativeFrequency=None, 
                        minAcceptableAngResolution=None, 
                        maxAcceptableAngResolution=None,
                        dynamicRange=None, representativeBandwidth=None,
                        representativeSource=None):
    """
    Updates the SBSummary.xml file of an ASDM with one or more new
    values.  If a value is not present in the existing table and also not 
    specified, then it will remain not present in the updated table.
    representativeFrequency: float value in typical units (GHz), 
            or string with units (space before units is optional)
    minAcceptableAngResolution: float value in typical units (arcsec), 
            or string with units (space before units is required)
    maxAcceptableAngResolution: float value in typical units (arcsec), 
            or string with units (space before units is required)
    dynamicRange: float value
    representativeBandwidth: float value in typical units (GHz), 
            or string with units (space before units is optional)
    representativeSource: string
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find asdm."
        return
    t = asdm+'/SBSummary.xml'
    if not os.path.exists(t):
        print "Could not find SBSummary.xml for this ASDM."
        return
    if (representativeFrequency is not None or 
        minAcceptableAngResolution is not None or 
        maxAcceptableAngResolution is not None or
        dynamicRange is not None or representativeBandwidth is not None or
        representativeSource is not None):
        update = True
    else:
        update = False
    result = grep(t, 'numScienceGoal')
    if len(result[0]) == 0:
        print "Could not find numScienceGoal"
        return
    numScienceGoal = int(result[0].split('>')[1].split('<')[0])
    result = grep(t, 'scienceGoal')
    if len(result[0]) == 0:
        print "Could not find scienceGoal"
        return
    scienceGoalString = result[0].split('<scienceGoal>')[1].split('</scienceGoal')[0]
    scienceGoals = scienceGoalString.split('"')
    scienceGoal = []
    for s in scienceGoals:
        if (s.find('=') > 0):
            scienceGoal.append(s)
    
    # Read the existing values for those that were not specified
    for i,arg in enumerate(scienceGoal):
        # arg will look like: 
        #  'representativeFrequency = 219.55647641503566 GHz'
        loc = arg.find('representativeFrequency')
        if (loc >= 0 and representativeFrequency is None):
            tokens = arg[loc:].split()
            representativeFrequency = float(tokens[2])
            freqUnits = tokens[3]
        loc = arg.find('minAcceptableAngResolution')
        if (loc >= 0 and minAcceptableAngResolution is None):
            tokens = arg[loc:].split()
            minAcceptableAngResolution = float(tokens[2])
            minUnits = tokens[3]
        loc = arg.find('maxAcceptableAngResolution')
        if (loc >= 0 and maxAcceptableAngResolution is None):
            tokens = arg[loc:].split()
            maxAcceptableAngResolution = float(tokens[2])
            maxUnits = tokens[3]
        loc = arg.find('dynamicRange')
        if (loc >= 0 and dynamicRange is None):
            tokens = arg[loc:].split()
            dynamicRange = float(tokens[2])
        loc = arg.find('representativeBandwidth')
        if (loc >= 0 and representativeBandwidth is None):
            tokens = arg[loc:].split()
            representativeBandwidth = float(tokens[2])
            bwUnits = tokens[3]
        loc = arg.find('representativeSource')
        if (loc >= 0 and representativeSource is None):
            tokens = arg[loc:].split()
            representativeSource = str(tokens[2])
    if update:
        # convert any command-line arguments from string to value and units
        shutil.copyfile(t, t+'.backup')
        if type(representativeFrequency) is str:
            representativeFrequency = parseFrequencyArgumentToGHz(representativeFrequency)
            freqUnits = 'GHz'
        if type(representativeBandwidth) is str:
            representativeBandwidth = parseFrequencyArgumentToGHz(representativeBandwidth) * 1000
            bwUnits = 'MHz'
        if type(dynamicRange) is str:
            dynamicRange = float(dynamicRange)
        if type(minAcceptableAngResolution) is str:
            value, minUnits = minAcceptableAngResolution.split()
            minAcceptableAngResolution = float(value)
        if type(maxAcceptableAngResolution) is str:
            value, maxUnits = maxAcceptableAngResolution.split()
            maxAcceptableAngResolution = float(value)
        newvalues = []
        if representativeFrequency is not None:
            newvalues += ['representativeFrequency = %f %s'%(representativeFrequency,freqUnits)]
        if minAcceptableAngResolution is not None:
            newvalues += ['minAcceptableAngResolution = %f %s'%(minAcceptableAngResolution, minUnits)]
        if maxAcceptableAngResolution is not None:
            newvalues += ['maxAcceptableAngResolution = %f %s'%(maxAcceptableAngResolution, maxUnits)]
        if dynamicRange is not None:
            newvalues += ['dynamicRange = %f'%(dynamicRange)]
        if representativeBandwidth is not None:
            newvalues += ['representativeBandwidth = %f %s'%(representativeBandwidth, bwUnits)]
        if representativeFrequency is not None:
            newvalues += ['representativeSource = %s'%representativeSource]
        newvalues = np.array(newvalues, dtype=str)
        if len(newvalues) != numScienceGoal:
            print "Updating numScienceGoal to %d" % (len(newvalues))
        print "Putting new values:\n", newvalues
        if casaAvailable:
            casalog.post('Wrote new values to %s/SBSummary.xml: %s'%(asdm,str(newvalues)))
        for line in fileinput.input(t, inplace=True):
            if line.find('numScienceGoal') > 0:
                line = "    <numScienceGoal>%d</numScienceGoal>\n" % (len(newvalues))
            elif line.find('scienceGoal') > 0:
                line = "    <scienceGoal>1 %d " % (len(newvalues))
                for sg in newvalues:
                    line += '"%s" ' % (sg)
                line += "</scienceGoal>\n"
            print line[:-1]
    else:
        print "Current values: \n ", scienceGoal

def cmd_exists(cmd):
    return subprocess.call("type " + cmd, shell=True, 
        stdout=subprocess.PIPE, stderr=subprocess.PIPE) == 0

def projectCodeFromDataset(dataset, wget='wget', verbose=False, overwrite=False):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    project code, SB name, and MOUS for a dataset.  (See SCIREQ-412).
    dataset: ASDM or ms (underscores)
    wget: the full path to the wget executable
    verbose: if True, then print complete information 
    overwrite: if True, then get new table even if one exists in the PWD
    Returns: a tubple of: project code, SB name, MOUS, region, and status (all as strings)
    -Todd Hunter
    """
    dataset = uidToUnderscores(dataset)
    dataset = dataset.rstrip('/')
    dataset = os.path.basename(dataset).split('.')[0] # strip off .ms or .vis, etc.
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    try:
        output = getFelixTable(wget, overwrite, verbose)
        for line in output.split('\n'):
            loc = line.find(dataset)
            if (loc >= 0):
                if (verbose):
                    print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME  Region  Status  Type"
                    print line
                tokens = line.split()
                if (len(tokens) > 1):
                    return(tokens[0], tokens[-4], tokens[4], tokens[-3], tokens[-2])
                else:
                    return('Error in parsing the result.')
        return('This EB does not appear to be associated with a science project.')
    except:
        return('Could not reach the server.  Try again at a different time.')

def getFelixTable(wget, overwrite=False, verbose=True):
    """
    Opens a local copy (if present) or downloads the table of project/SB/EB
    information from Felix's machine.
    overwrite: if True, then get new table even if one exists in the PWD
    -Todd Hunter
    """
    url = 'http://www.eso.org/~fstoehr/project_ous_eb_hierarchy.txt'
    filename = 'fstoehr.txt'
    if not os.access('./', os.W_OK):
        filename = os.path.join('/tmp',filename)
    if (not os.path.exists(filename) or overwrite):
        output = subprocess.check_output('%s -q -O - %s' % (wget,url), 
                                         shell=True)
        f = open(filename,'w')
        f.write(output)
        f.close()
    else:
        if verbose:
            print "Using existing search results file: %s.  Set overwrite=True to refresh it." % (filename)
        f = open(filename,'r')
        output = f.read()
        f.close()
    return output

def datasetsForProjectCode(project,wget='wget',verbose=False,overwrite=False,
                           sevenMeter=True, twelveMeter=True, totalPower=True,
                           status='', sb='', exactStatus=True):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    executions for a project.
    project: project code
    wget: the full path to the wget executable
    verbose: if True, then print complete information 
    overwrite: if True, then download new copy of the table (fstoehr.txt)
    status: '' or 'Pass' or 'Fail' or 'SemiPass' or 'None' (case-insensitive)
    exactStatus: if True, then prepend a 'tab' character to status 
                 (e.g. to differentiate between Pass and SemiPass)
    sb: '' or name of sb to match
    Returns: project code, SB name, MOUS, and region (all as strings)
    -Todd Hunter
    """
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    if (status != '' and exactStatus):
        status = '\t'+status
    try:
        output = getFelixTable(wget, overwrite)
        executions = []
        if (verbose):
            print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME"
        for line in output.split('\n'):
            loc = line.find(project)
            if (loc >= 0):
                lline = line.lower()
                if (((lline.find('7m"')>0 or lline.find('_ac"')>0) and sevenMeter) or
                    ((lline.find('_12m"')>0 or lline.find('_12m_')>0 or lline.find('12m ')>0 or lline.find('_te"')>0 or 
                      lline.find('_tc"')>0) and twelveMeter) or
                    (lline.find('_tp"')>0 and totalPower)):
                    if (status == '' or line.lower().find(status.lower())>=0):
                        if (sb == '' or line.find(sb)>=0):
                            tokens = line.split()
                            if (len(tokens) > 1): 
                                executions.append(tokens[5])
                                if (verbose):
                                    print line
                else:
                    print "rejected line: ", line
        if (len(executions) < 1):
            return('This project code does not appear to be associated with a science project.')
        else:
            return executions
    except:
        return('Could not reach the server.  Try again at a different time.')

def projectCodeFromSB(sb, wget='wget', allEBs=False, verbose=False, 
                      overwrite=False):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    project code, MOUS, region and first EB for an SB.
    sb: SB uid (underscores)
    wget: the full path to the wget executable
    allEBs: if True, then return a list of all EBs
    verbose: if True, then print complete information 
    overwrite: if True, then download new copy of table even if it exists in PWD
    Returns: project code, region, MOUS and EB (all as strings)
    -Todd Hunter
    """
    dataset = uidToUnderscores(sb)
    dataset = dataset.split('.')[0] # strip off .ms or .vis, etc.
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    try:
        output = getFelixTable(wget, overwrite)
        results = []
        for line in output.split('\n'):
            loc = line.find(dataset)
            if (loc >= 0):
                if (verbose):
                    print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME  Region  Status  Type"
                    print line
                tokens = line.split()
                if (len(tokens) > 1):
                    result = tokens[0], tokens[-4], tokens[4], tokens[-3], tokens[-2]
                    if (allEBs):
                        results.append(tokens[5])
                    else:
                        return(result)
                else:
                    return('Error in parsing the result.')
        if (allEBs):
            return results
        return('This SB does not appear to be associated with a science project.')
    except:
        return('Could not reach the server.  Try again at a different time.')

def projectCodeForMOUS(mous, wget='wget',verbose=False, overwrite=False):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    project code for an MOUS.
    mous: mous uid (underscores or colon/slash format)
    wget: the full path to the wget executable
    verbose: if True, then print complete information 
    overwrite: if True, then download new copy of table even if it exists in PWD
    Returns: project code string
    -Todd Hunter
    """
    dataset = uidToUnderscores(mous.lstrip('MOUS_'))
    dataset = dataset.split('.')[0] # strip off .ms or .vis, etc.
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    try:
        output = getFelixTable(wget, overwrite)
        results = []
        for line in output.split('\n'):
            loc = line.find(dataset)
            if (loc >= 0):
                if (verbose):
                    print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME  Region  Status  Type"
                    print line
                tokens = line.split()
                if (len(tokens) > 1):
                    result = tokens[0]
                else:
                    return('Error in parsing the result.')
                return result
        return('This SB does not appear to be associated with a science project.')
    except:
        return('Could not reach the server.  Try again at a different time.')

def maxBaselineForRequestedResolutionFromASDM(asdm, resolution=None):
    """
    Uses the representative frequency and requested resolution from an ASDM
    and returns the maximum baseline length for the nominal ALMA configuration 
    that would achieve it.  To do this, it first computes the L80 baseline
    using the formula in the technical handbook, then scales this upward by
    the sine of the median elevation of science targets observed, then finds 
    the Cycle 4 configuration with the nearest (but larger) L80 value, finds
    its maximum baseline, then scales L80 by max_config)/L80_config
    resolution: if specified (in floating point arcsec), use this value instead
                of what is in the ASDM
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    if resolution == None:
        resolution = np.min(requestedResolutionFromASDM(asdm))
        if (resolution <= 0):
            print "Requested resolution not present in the ASDM."
            return 0
    L80 = 3600*np.degrees(1)*0.574*c_mks/(representativeFrequencyFromASDM(asdm)*1e9*resolution)
    result = getElevationStatsForIntentFromASDM(asdm)
    if (result == None):
        return
    minElev, medianElev, maxElev = result
    print "elevation: min = %.1f, median = %.1f, max = %.1f deg" % (minElev, medianElev, maxElev)
    print "Required L80 = %.0f m" % (L80)
    L80 /= np.sin(np.radians(minElev))
    print "Required L80 (accounting for minimum elevation) = %.0f m" % (L80)
    for config in range(1,10):
        L80config = getBaselineStats(config='alma.cycle4.%d.cfg'%config, percentile=80, verbose=False)[0]
        if (L80config > L80):
            print "Nominal required configuration: Cycle4-%d" % config
            break
    maxBaselineConfig = getBaselineStats(config='alma.cycle4.%d.cfg'%config, verbose=False)[2]
    maxBaseline = L80 * (maxBaselineConfig/L80config)
    return(maxBaseline)

def requestedResolutionFromASDM(asdm):
    """
    Get the min/max acceptable resolution from the SBSummary.xml file of an ASDM
    Returns a tuple of values in arcsec
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    if (not os.path.exists(asdm+'/SBSummary.xml')):
        print "Could not find SBSummary.xml, are you sure that this is an ASDM?"
        return
    f = open(asdm+'/SBSummary.xml')
    minAcceptableReoslution = 0
    maxAcceptableReoslution = 0
    for line in f.readlines():
        loc = line.find('minAcceptableAngResolution')
        if (loc >= 0):
            tokens = line[loc:].split()
            minAcceptableResolution = float(tokens[2])
            minUnits = tokens[3]
        loc = line.find('maxAcceptableAngResolution')
        if (loc >= 0):
            tokens = line[loc:].split()
            maxAcceptableResolution = float(tokens[2])
            maxUnits = tokens[3]
    f.close()
    return(minAcceptableResolution, maxAcceptableResolution)
    return(freq)
    
def requestedResolution(vis):
    """
    Get the min/max acceptable resolution from the ASDM_SBSUMMARY table of
    a measurement set, if it has been imported with the asis parameter set.   
    Returns a tuple of values in arcsec
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    if (not os.path.exists(vis+'/ASDM_SBSUMMARY')):
        print "Could not find ASDM_SBSUMMARY table.  Did you not import it with asis='SBSummary'?"
        print "If not, you can run this on the asdm: au.requestedResolutionFromASDM(asdm)"
        return
    mytb.open(vis+'/ASDM_SBSUMMARY')
    scienceGoal = mytb.getcol('scienceGoal')
    mytb.close()
    minAcceptableResolution = 0
    maxAcceptableResolution = 0
    for args in scienceGoal:
        for arg in args:
            loc = arg.find('minAcceptableAngResolution')
            if (loc >= 0):
                tokens = arg[loc:].split()
                minAcceptableResolution = float(tokens[2])
                minUnits = tokens[3]
            loc = arg.find('maxAcceptableAngResolution')
            if (loc >= 0):
                tokens = arg[loc:].split()
                maxAcceptableResolution = float(tokens[2])
                maxUnits = tokens[3]
    return(minAcceptableResolution, maxAcceptableResolution)
    
def representativeFrequencyFromASDM(asdm, verbose=True):
    """
    Get the representative frequency from the SBSummary.xml file of an ASDM
    e.g. <scienceGoal>1 4 "representativeFrequency = 230.0348592858192 GHz" 
    Returns the value in GHz.
    verbose: if True, then also print the min/max acceptable angular resolutions
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    if (not os.path.exists(asdm+'/SBSummary.xml')):
        print "Could not find SBSummary.xml, are you sure that this is an ASDM?"
        return
    f = open(asdm+'/SBSummary.xml')
    minAcceptableResolution = 0
    maxAcceptableResolution = 0
    representativeBandwidth = None
    representativeSource = None
    for line in f.readlines():
        loc = line.find('representativeFrequency')
        if (loc > 0):
            tokens = line[loc:].split()
            freq = parseFrequencyArgumentToGHz(tokens[2]+tokens[3])
        loc = line.find('minAcceptableAngResolution')
        if (loc >= 0):
            tokens = line[loc:].split()
            minAcceptableResolution = float(tokens[2])
            minUnits = tokens[3].strip('"')
        loc = line.find('maxAcceptableAngResolution')
        if (loc >= 0):
            tokens = line[loc:].split()
            maxAcceptableResolution = float(tokens[2])
            maxUnits = tokens[3].strip('"')
        loc = line.find('representativeBandwidth')
        if (loc >= 0):
            tokens = line[loc:].split()
            representativeBandwidth = float(tokens[2].strip('"'))
            bwUnits = tokens[3].strip('"')
            if bwUnits.find('Hz') < 0:
                bwUnits = ''
        loc = line.find('representativeSource')
        if (loc >= 0):
            tokens = line[loc:].split()
            representativeSource = str(tokens[2]).split('"')[0]
    f.close()
    if verbose:
        print "minAcceptableResolution = %f %s" % (minAcceptableResolution, minUnits)
        print "maxAcceptableResolution = %f %s" % (maxAcceptableResolution, maxUnits)
        print "representative frequency = %f GHz" % (freq)
        if representativeBandwidth is not None:
            print "representative bandwidth = %f %s" % (representativeBandwidth, bwUnits)
        if representativeSource is not None:
            print "representative source = %s" % (representativeSource)
    return(freq)

def sanitizeNames(names, newchar='_'):
    """
    Replaces various special characters with specified character.
    -Todd Hunter
    """
    if (type(names) == str):
        names = names.split(',')
    newnames = []
    for name in names:
        newname = name
        for ch in [')','(','/']:
            newname = newname.replace(ch,newchar)
        newnames.append(newname)
    return newnames

def transitions(vis, spws='', source='', intent='OBSERVE_TARGET', mymsmd=None):
    """
    Returns a dictionary of the line transition names for each science spw of the
    specified measurement set.
    spw: list or comma-delimited string;  if blank, then use all science spws
    -Todd Hunter
    """
    if (spws == ''):
        spws = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)
        print "Got science spws: ", spws
    elif (type(spws) == str):
        spws = parseSpw(vis, spws, mymsmd)
    elif (type(spws) != list and type(spws) != np.ndarray):
        spws = [int(spws)]
    lines = {}
    for spw in spws:
        lines[spw] = transition(vis,spw,source,intent,mymsmd=mymsmd)
    return lines

def isSingleContinuumASDM(asdm):
    """
    Checks whether the phrase Single_Continuum appears in the Source.xml file of an ASDM.
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM."
        return
    result = grep(asdm+'/Source.xml','Single_Continuum')
    return len(result[0]) > 0
    
def isSingleContinuum(vis, spw='', source='', intent='OBSERVE_TARGET', verbose=False, mymsmd=None):
    """
    Checks whether the first science spw (or specific spw) was defined as single continuum in the OT
    by looking at the transition name.
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find vis."
        return
    needToClose = False
    if spw=='':
        if mymsmd is None:
            needToClose = True
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
        spw = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)[0]
    info = transition(vis, spw, source, intent, verbose, mymsmd)
    if needToClose:
        mymsmd.close()
    if len(info) > 0:
        if info[0].find('Single_Continuum') >= 0:
            return True
    return False
    
def isSpectralScanASDM(asdm):
    """
    Checks whether the phrase Spectral_Scan appears in the Source.xml file of an ASDM.
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM."
        return
    result = grep(asdm+'/Source.xml','Spectral_Scan')
    return len(result[0]) > 0
    
def isSpectralScan(vis, spw='', source='', intent='OBSERVE_TARGET', verbose=False, mymsmd=None):
    """
    Checks whether a project was defined as Spectral Scan in the OT
    by looking at the transition name in the first science spw.
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find vis."
        return
    needToClose = False
    if (spw == ''):
        if mymsmd is None:
            needToClose = True
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
        spws = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)
        if (len(spws) < 1):
            print "No science spws in this measurement set."
            return
        spw = spws[0]
    info = transition(vis, spw, source, intent, verbose, mymsmd)
    if needToClose:
        mymsmd.close()
    if len(info) > 0:
        if info[0].find('Spec_') >= 0 and info[0].find('_Scan') >= 0:
            return True
    return False
    
def transition(vis, spw='', source='', intent='OBSERVE_TARGET', verbose=True, mymsmd=None):
    """
    Returns the list of transitions for specified spw (and source).
    source: can be integer ID or string name
    intent: if source is blank then use first one with matching intent and spw
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    if (spw >= mymsmd.nspw()):
        print "spw not in the dataset"
        if needToClose:
            mymsmd.close()
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SOURCE')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    sourceIDs = mytb.getcol('SOURCE_ID')
    names = mytb.getcol('NAME')
    spw = int(spw)
    if (type(source) == str):
        if (source.isdigit()):
            source = int(source)
        elif (source == ''):
            # pick source
            fields1 = mymsmd.fieldsforintent(intent+'*')
            fields2 = mymsmd.fieldsforspw(spw)
            fields = np.intersect1d(fields1,fields2)
            source = mymsmd.namesforfields(fields[0])[0]
            if verbose:
                print "For spw %d, picked source: " % (spw), source
    if (type(source) == str or type(source) == np.string_):
        sourcerows = np.where(names==source)[0]
        if (len(sourcerows) == 0):
            # look for characters ()/ and replace with underscore
            names = np.array(sanitizeNames(names))
            sourcerows = np.where(source==names)[0]
    else:
        sourcerows = np.where(sourceIDs==source)[0]
        
    spwrows = np.where(spws==spw)[0]
    row = np.intersect1d(spwrows, sourcerows)
    if (len(row) > 0):
        if (mytb.iscelldefined('TRANSITION',row[0])):
            transitions = mytb.getcell('TRANSITION',row[0])
        else:
            transitions = []
    else:
        transitions = []
    if (len(transitions) == 0):
        print "No value found for this source/spw (row=%s)." % row
    mytb.close()
    if needToClose:
        mymsmd.close()
    return(transitions)

def getFrequencies(inputMs,spwId) :
    """
    Returns the list of channel frequencies in the specified spw in the
    specified ms. Obsoleted by msmd.chanfreqs.
    """
    mytb = tbtool()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    chanFreq = mytb.getcol("CHAN_FREQ",startrow=spwId,nrow=1)
    mytb.close()
    return chanFreq
    
def getChanAverSpwIDBaseBand0(inputMs) :
    """
    Called by getFlux, getAllanVariance and classes: Tsys, TsysExplorer & Visibility
    """
    mytb = tbtool()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    bbc_no = mytb.getcol('BBC_NO')
    ind1 = np.where(bbc_no == 1)[0]
    num_chan = mytb.getcol('NUM_CHAN')
    mytb.close()
    ind2 = np.where(num_chan == 1)[0]
    return np.intersect1d(ind1,ind2)[0]

def getDataDescriptionId(inputMs,spwId) :
    """
    Called by class Visibility
    """
    mytb = tbtool()
    mytb.open("%s/DATA_DESCRIPTION" % inputMs)
    spectralWindows = mytb.getcol("SPECTRAL_WINDOW_ID")
    mytb.close()
    ids = np.where(spectralWindows == spwId)[0]
    return int(ids)

# No longer called by anything.  Should be deleted.
#def getSpectralWindowId(inputMs,dataDesId) :
#    tb.open("%s/DATA_DESCRIPTION" % inputMs)
#    spectralWindows = tb.getcol("SPECTRAL_WINDOW_ID")
#    tb.close()
#    return spectralWindows[dataDesId]
    
def getFlux(inputMs,spwID=None,jyPerK=33,badAntennas=[],useCorrected=False) :
    if spwID == None :
        spwID = getChanAverSpwIDBaseBand0(inputMs)
    sourceIds,sourceNames = getSourceFieldMapping(inputMs)
    antennas = getAntennaNames(inputMs)
    tsys = Tsys(inputMs,spwID=spwID)
    sourceFlux = {}
    averageFlux = {}
    for i in range(len(badAntennas)) :
        badAntennas[i] = getAntennaIndex(inputMs,badAntennas[i])
    for i in range(len(sourceIds)) :
        fieldId = sourceIds[sourceNames[i]]
        sourceName = sourceNames[i]
        sourceFlux[sourceName] = {}
        averageFlux[sourceName] = {}
        sourceScans = getSourceScans(inputMs,fieldId)
        for k in range(len(sourceScans)/2) :
            tsysScan = sourceScans[2*k]
            sourceScan = sourceScans[2*k+1]
            tsys_ = {}
            sourceFlux[sourceName][sourceScan] = {}
            for j in range(len(antennas)) :
#                print antennas[j]
                tsys_[antennas[j]] = tsys.sysInfo[antennas[j]][tsysScan]['Tsys']['value']
            averageFlux[sourceName][sourceScan] = {'Flux' : np.zeros(tsys_[tsys.sysInfo.keys()[0]].shape)}
            for j in range(len(antennas)) :
                for m in range(len(antennas)) :
                    if j < m :
                        if j in badAntennas or m in badAntennas :
                            continue
                        else :
                            sourceFlux_ = Visibility(inputMs,antenna1=j,antenna2=m,spwID=spwID,field=fieldId,scan=sourceScan,correctedData=useCorrected)
                            flux_  = ((tsys_[antennas[j]]*tsys_[antennas[m]])**0.5)*sourceFlux_.amp.mean(-1)*jyPerK
                            dflux_ = ((tsys_[antennas[j]]*tsys_[antennas[m]])**0.5)*sourceFlux_.amp.std(-1)*jyPerK/sourceFlux_.amp.shape[-1]**0.5
                            baseline = ('%i-%i' % (j,m))
                            sourceFlux[sourceName][sourceScan][baseline] = {'Flux' : flux_, 'Error' : dflux_}
            for j in sourceFlux[sourceName][sourceScan].keys() :
                averageFlux[sourceName][sourceScan]['Flux'] = averageFlux[sourceName][sourceScan]['Flux']+sourceFlux[sourceName][sourceScan][j]['Flux']/len(sourceFlux[sourceName][sourceScan].keys())
    return sourceFlux,tsys,averageFlux


class Tsys(Weather):
    def __init__(self,inputMs,spwID=None,tau=0.05,etaF=0.99,doRefSub=False):
        if spwID == None :
            spwID = getChanAverSpwIDBaseBand0(inputMs)
        Weather.__init__(self,inputMs)
        self.inputMs = inputMs
        self.atm = AtmStates(inputMs)
        self.loads = self.atm.antennaInfo[self.atm.antennaNames[0]].keys()
        self.spwID = spwID
        self.tau = tau
        self.etaF = etaF
        interTab = InterpolateTableTime(self,self.spwID)
        mytb = tbtool()
        mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
        self.freq = mytb.getcol("REF_FREQUENCY")[self.spwID]
        mytb.close()
        self.specFreq = getFrequencies(inputMs,spwID)
        self.atmRes = {}
        for i in self.atm.antennaNames :
#            print i
            _visVal = Visibility(inputMs,spwID=spwID,antenna1=i,antenna2=i)
            scanNums = np.unique(_visVal.subtable.getcol('SCAN_NUMBER'))
            self.atmRes[i] = {}
            noScan = []
            for m in scanNums :
                self.atmRes[i][m] = {}
                for j in self.loads :
                    stateVal = self.atm.antennaInfo[i][j]['state']
                    self.atmRes[i][m][j] = {}
                    for k in stateVal :
                        try:
                            visVal = Visibility(inputMs,spwID=spwID,antenna1=i,antenna2=i,scan=m,state=k)
                            self.atmRes[i][m][j]['power'] = np.mean(visVal.amp,len(visVal.amp.shape)-1)
                            self.atmRes[i][m][j]['error'] = np.std(visVal.amp,len(visVal.amp.shape)-1)
                            self.atmRes[i][m][j]['time']  = np.mean(visVal.subtable.getcol("TIME"))
                            if j in ["HOT","AMB"] :
                                states = self.atm.antennaInfo[i][j]['state']
                                loadTemps = self.atm.antennaInfo[i][j]['loadTemp']
                                checker = states.index(k)
                                self.atmRes[i][m][j]['loadTemp'] = loadTemps[checker]
                        except:
                            continue
                if self.atmRes[i][m]["AMB"].keys() == [] : noScan.append(m)
            noScan = np.unique(np.array(noScan))
            for m in noScan :
                self.atmRes[i].pop(m)
            counter = 0
            for m in self.atmRes[i].keys() :
                try:
                    if self.atmRes[i][m]['REF'].keys() == [] : self.atmRes[i][m]['REF'] = self.atmRes[i][scanNums[counter-1]]['REF']
                    if self.atmRes[i][m]['HOT'].keys() == [] : self.atmRes[i][m]['HOT'] = self.atmRes[i][scanNums[counter-1]]['HOT']
                    counter+=1
                except:
                    continue
        self.sysInfo = {}
        for i in self.atmRes.keys() :
            self.sysInfo[i] = {}
            for m in self.atmRes[i].keys() :
                print m,i
                self.sysInfo[i][m] = {}
                pHot = self.atmRes[i][m]['HOT']['power']
                eHot = self.atmRes[i][m]['HOT']['error']
                timetHot = self.atmRes[i][m]['HOT']['time']
                tHot = jVal(self.freq,self.atmRes[i][m]['HOT']['loadTemp'])
                pAmb = self.atmRes[i][m]['AMB']['power']
                eAmb = self.atmRes[i][m]['AMB']['error']
                timeAmb = self.atmRes[i][m]['AMB']['time']
                tAmb = jVal(self.freq,self.atmRes[i][m]['AMB']['loadTemp'])
#                print self.atmRes[i][m]['AMB']
                try:
                    pRef = self.atmRes[i][m]['REF']['power']
                    eRef = self.atmRes[i][m]['REF']['error']
                    timeRef = self.atmRes[i][m]['REF']['time']
                except:
                    pRef = np.zeros(self.atmRes[i][m]['AMB']['power'].shape)
                    eRef = pRef
                    timeRf = self.atmRes[i][m]['AMB']['time']
                pSky = self.atmRes[i][m]['SKY']['power']
                eSky = self.atmRes[i][m]['SKY']['error']
                timeSky = self.atmRes[i][m]['SKY']['time']
                tCmb = jVal(self.freq,Tcmb)
                Gain,dGain,Trx,dTrx,Tsky,dTsky,y,dy = calcTrxGain(pHot,pAmb,pSky,tHot,tAmb,pRef,eHot,eAmb,eRef,doRefSub=doRefSub)
                meanTime = (timeAmb+timeSky)/2.0
                interTab.interpolateData(np.array(meanTime),quiet=True)
                tOut = interTab.newData['TEMPERATURE'].mean()
                tAtm = interTab.newData['ATM_TEMP'].mean()
                alph = solveAlpha(tHot,tAmb,tAtm,tOut,etaF)
                tCal,tSys = solveTsys(tAtm,pHot,pAmb,pSky,tCmb,alph,pRef,doRefSub=doRefSub)
                self.sysInfo[i][m]['gain'] = {'value' : Gain, 'error' : dGain}
                self.sysInfo[i][m]['Trx']  = {'value' : Trx, 'error' : dTrx}
                self.sysInfo[i][m]['Tsky'] = {'value' : Tsky, 'error' : dTsky}
                self.sysInfo[i][m]['y']    = {'value' : y, 'error' : dy}
                self.sysInfo[i][m]['Tcal'] = {'value' : tCal, 'error' : 0}
                self.sysInfo[i][m]['Tsys'] = {'value' : tSys, 'error' : 0}
                self.sysInfo[i][m]['Time'] = {'value' : meanTime, 'error' : 0}
#                self.sysInfo[i][m]['Freq'] = {'value' : , 'error' : 0}

def solveTsys(tAtm,pHot,pAmb,pSky,tCmb,alpha,pRef,doRefSub=False) :
    if not doRefSub : pRef = pRef-pRef
    tCal  = tAtm-tCmb
    pLoad = alpha*pHot+(1-alpha)*pAmb
    tSys  = tCal*(pSky-pRef)/(pLoad-pSky)
    return tCal,tSys

def calcTrxGain(pHot,pAmb,pSky,tHot,tAmb,pRef=0,eHot=0,eAmb=0,eSky=0,eRef=0,etHot=0,etAmb=0,Gain=None,dGain=None,Trx=None,dTrx=None,doRefSub=False) :
    if not doRefSub : pRef = pRef-pRef
    if Gain == None  : Gain  = (pHot-pAmb)/(tHot-tAmb)
    if dGain == None : dGain = (((eHot**2.0+eAmb**2.0)/(tHot-tAmb)**2.0)+((pHot-pAmb)**2.0/(tHot-tAmb)**4.0)*(etHot**2.0+etAmb**2.0))**0.5
    if Trx == None   : Trx   = ((pHot-pRef)/Gain)-tHot
    if dTrx == None  : dTrx  = ((eHot/Gain)**2.0+(eRef/Gain)**2.0+((pHot-pRef)*dGain/Gain**2.0)**2.0 + etHot**2.0)**0.5
    Tsky  = tAmb-(pAmb-pSky)/Gain
    dTsky = ((eAmb/Gain)**2.0+(eSky/Gain)**2.0+((pAmb-pSky)*dGain/Gain**2.0)**2.0+etAmb**2.0)**0.5
    y     = (pHot-pRef)/(pAmb-pRef)
    dy    = ((eHot/(pAmb-pRef))**2.0+((pHot-pRef)*eAmb/(pAmb-pRef)**2.0)**2.0+(eRef/(pAmb-pRef)+(pAmb*eRef)/(pAmb-pRef)**2.0)**2.0)**0.5
    return Gain,dGain,Trx,dTrx,Tsky,dTsky,y,dy

def solveAlpha(tHot,tAmb,tAtm,tOut,etaF) :
    # Equation 16 of Lucas & Corder "Dual Load Amplitude Calibration in ALMA"
    return (etaF*tAtm-tAmb+(1-etaF)*tOut)/(tHot-tAmb)

def jVal(freq,temp) :
    import math as m
    x = h*freq/k
    return x*(m.exp(x/temp)-1)**(-1)

def djVal(freq,temp,detemp) :
    x = h*freq*1e9/k
    return abs(x*(m.exp(x/temp)-1)**(-2)*(x*dtemp/temp**2.0)*m.exp(x/temp))

def overlayTsys(vis1,vis2,antenna=0,spw=1,scan=1,pol=0,plotrange=[0,0,0,0],
                overlayTelcal=True):
    """
    Calls the Atmcal class to overlay a Tsys result from one scan of two 
    different DelayCal measurement sets.  It was written to compare TDM 
    and FDM Tsys spectra.
    -Todd Hunter
    """
    a1 = Atmcal(vis1)
    tsys1, freqHz1, trec, tsky, tcal = a1.computeTsys(antenna=antenna, spw=spw, scan=scan, pol=pol)
    a2 = Atmcal(vis2)
    tsys2, freqHz2, trec, tsky, tcal = a2.computeTsys(antenna=antenna, spw=spw, scan=scan, pol=pol)
    pb.clf()
    adesc = pb.subplot(111)
    freqHz1 *= 1e-9
    freqHz2 *= 1e-9
    if (overlayTelcal):
        tsys1_telcal = a1.getTelcalTsys(antenna,spw,scan,pol) 
        tsys2_telcal = a2.getTelcalTsys(antenna,spw,scan,pol) 
        pb.plot(freqHz1, tsys1_telcal, 'k-', freqHz2, tsys2_telcal, 'k-', lw=3)
        pb.hold(True)
    pb.plot(freqHz1, tsys1, 'r-', freqHz2, tsys2, 'r-')
    if (len(tsys1) <= 256):
        tdmMedian = np.median(tsys1)
        fdmMedian = np.median(tsys2)
    else:
        tdmMedian = np.median(tsys2)
        fdmMedian = np.median(tsys1)

    pb.xlabel('Frequency (GHz)')
    pb.ylabel('Tsys (K)')
    if (plotrange != [0,0,0,0]):
        if (plotrange[0] != 0 or plotrange[1] != 0):
            pb.xlim(plotrange[:2])
        if (plotrange[2] != 0 or plotrange[3] != 0):
            pb.ylim(plotrange[2:])
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    if (type(antenna) != str):
        antennaName = a1.antennaNames[antenna]
    else:
        antennaName = antenna
    pb.title('%s / %s  %s  scan=%d  spw=%d  pol=%d' % (vis1,vis2,antennaName, scan, spw, pol), fontsize=10)
    pb.text(0.1,0.95,'Black = TelCal,  Red = au.Atmcal().computeTsys', transform=adesc.transAxes)
    xoffset = pb.xlim()[0] + (pb.xlim()[1]-pb.xlim()[0])*0.03
    pb.text(xoffset, tdmMedian, "TDM")
    pb.text(xoffset, fdmMedian, "FDM")
    pb.draw()
    png = '%s_%s.%s.scan%d.spw%d.pol%d.tsys.png' % (vis1, vis2, antennaName,scan,spw,pol)
    pb.savefig(png)

def overlayTrx(vis1,vis2,antenna=0,spw=1,scan=1,pol=0,plotrange=[0,0,0,0],
                overlayTelcal=True):
    """
    Calls the Atmcal class to overlay a Trx result from one scan of two 
    different DelayCal measurement sets.  It was written to compare TDM 
    and FDM Trx spectra.
    -Todd Hunter
    """
    a1 = Atmcal(vis1)
    trx1, gain, tsky, freqHz1 = a1.computeTrec2(antenna=antenna, spw=spw, scan=scan, pol=pol)
    a2 = Atmcal(vis2)
    trx2, gain, tsky, freqHz2 = a2.computeTrec2(antenna=antenna, spw=spw, scan=scan, pol=pol)
    pb.clf()
    adesc = pb.subplot(111)
    freqHz1 *= 1e-9
    freqHz2 *= 1e-9
    if (overlayTelcal):
        trx1_telcal = a1.getTelcalTrx(antenna,spw,scan,pol) 
        trx2_telcal = a2.getTelcalTrx(antenna,spw,scan,pol) 
        pb.plot(freqHz1, trx1_telcal, 'k-', freqHz2, trx2_telcal, 'k-', lw=3)
        pb.hold(True)
    pb.plot(freqHz1, trx1, 'r-', freqHz2, trx2, 'r-')
    if (len(trx1) <= 256):
        tdmMedian = np.median(trx1)
        fdmMedian = np.median(trx2)
    else:
        tdmMedian = np.median(trx2)
        fdmMedian = np.median(trx1)
    
    pb.xlabel('Frequency (GHz)')
    pb.ylabel('Trx (K)')
    if (plotrange != [0,0,0,0]):
        if (plotrange[0] != 0 or plotrange[1] != 0):
            pb.xlim(plotrange[:2])
        if (plotrange[2] != 0 or plotrange[3] != 0):
            pb.ylim(plotrange[2:])
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    if (type(antenna) != str):
        antennaName = a1.antennaNames[antenna]
    else:
        antennaName = antenna
    pb.title('%s / %s  %s  scan=%d  spw=%d  pol=%d' % (vis1,vis2,antennaName, scan, spw, pol), fontsize=10)
    pb.text(0.1,0.95,'Black = TelCal,  Red = au.Atmcal().computeTrx', transform=adesc.transAxes)
    xoffset = pb.xlim()[0] + (pb.xlim()[1]-pb.xlim()[0])*0.03
    pb.text(xoffset, tdmMedian, "TDM")
    pb.text(xoffset, fdmMedian, "FDM")
    pb.draw()
    png = '%s_%s.%s.scan%d.spw%d.pol%d.trx.png' % (vis1, vis2, antennaName,scan,spw,pol)
    pb.savefig(png)

def repairSidebandRatio(asdm, scan, showplot=False):
    """
    Prepares an ASDM for running offline casapy-telcal's tc_sidebandratio() command
    to regenerate the CalAtmosphere.xml table.  Useful for computing sideband ratios
    if the values in the ASDM are simply the default values, yet sideband_ratio data
    exists in the ASDM. Renames the CalAtmosphere.xml and .bin tables (to *.old), sets the
    number CalAtmosphere rows to zero in the ASDM.xml table, then
    runs tc_sidebandratio on one scan at a time (if the command is available).
    scan: list of scans, e.g. '1,2,3' or [1,2,3]
    -Todd Hunter
    """
    if (type(scan) == str):
        scan = scan.split(',')
    elif (type(scan) == int):
        scan = [scan]
    if (os.path.exists(asdm) == False):
        print "Could not find ASDM"
        return
    f = open(asdm+'/ASDM.xml')
    fc = f.read()
    f.close()
    asdmBlockList = re.findall('<Table>.*?</Table>', fc, re.DOTALL|re.MULTILINE)
    if len(asdmBlockList) == 0:
        print 'Found 0 blocks.'
        return
    for i in range(len(asdmBlockList)):
        if re.search('<Name> *CalAtmosphere *</Name>', asdmBlockList[i]) is not None or re.search('<Name> *CalAtmosphere *</Name>', asdmBlockList[i]) is not None:
            asdmBlockList1 = re.sub('<NumberRows> *[0-9]+ *</NumberRows>', '<NumberRows> 0 </NumberRows>', asdmBlockList[i])
            fc = re.sub(asdmBlockList[i], asdmBlockList1, fc)

    f = open(asdm+'/ASDM.xml', 'w')
    f.write(fc)
    f.close()
    if (os.path.exists(asdm+'/CalAtmosphere.xml')):
        os.system('mv '+asdm+'/CalAtmosphere.xml '+asdm+'/CalAtmosphere.xml.old')
    if (os.path.exists(asdm+'/CalAtmosphere.bin')):
        os.system('mv '+asdm+'/CalAtmosphere.bin '+asdm+'/CalAtmosphere.bin.old')
    try:
        from tc_sidebandratio_cli import tc_sidebandratio_cli as tc_sidebandratio
        for s in scan:
            print "Running tc_sidebandratio('%s', dataorigin='avercross', calresult='%s', showplot=%s, scans='%s')" % (asdm,asdm,showplot,str(s))
            tc_sidebandratio(asdm, dataorigin='avercross', calresult=asdm, showplot=showplot, scans=str(s))
    except:
        print "Now you can start casapy-telcal and run the following on each sideband_ratio scan:"
        print "tc_sidebandratio('%s', dataorigin='avercross', calresult='%s', showplot=False, scans='')" % (asdm,asdm)
        print "(Note: At present, the scans parameter of tc_sidebandratio only accepts one scan number.)"

def getAtmcalStateIDsFromASDM(asdm):
    """
    Reads the State.xml file of an ASDM and returns a dictionary of the form:
    {'AMBIENT_LOAD': 'State_1', 'HOT_LOAD': 'State_2', 'NONE': 'State_0'}
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find ASDM."
        return
    f = open(asdm + '/State.xml', 'r')
    lines = f.readlines()
    f.close()
    mydict = {}
    for line in lines:
        if (line.find('<stateId>') >= 0):
            stateId = line.split('<stateId>')[1].split('</stateId>')[0]
        if (line.find('<calDeviceName>') >= 0):
            mydict[line.split('<calDeviceName>')[1].split('</calDeviceName>')[0]] = stateId
    return(mydict)
            
def repairAtmcalStateIDs(asdm, dryrun=False):
    """
    Replaces <stateId> entries in the Main.xml file of an ASDM for all the
    AtmCal scans, so that offline casapy-telcal can then be run in order
    to regenerate the SysCal.xml file.  It forces all appearances of
    "State_0" to be "State_X" such that X = the stateId from the State.xml table
    corresponding to load for the subscan number (1=NONE, 2=AMBIENT, 3=HOT for
    a 3-subscan AtmCal, and 1=NONE, 2=NONE, 3=AMBIENT, 4=HOT for a 4-subscan Atmcal.
    asdm: the name of the ASDM
    dryrun: if True, then simply print the scans that would be changed, do not change them
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find ASDM."
        return
    calscans, nsubscans = getScanNumbersFromASDM(asdm,'CALIBRATE_ATMOSPHERE')
    AtmcalStateIds = getAtmcalStateIDsFromASDM(asdm)
    print "AtmcalStateIds = ", AtmcalStateIds
    f = open(asdm + '/Main.xml', 'r')
    if (not dryrun):
        o = open(asdm + '/Main.xml.new', 'w')
    lines = f.readlines()
    f.close()
    scan = 0
    subscan = 0
    changed = 0
    scansToFix = []
    print "Read %d lines from Main.xml" % (len(lines))
    for line in lines:
        originalLine = line[:]
        if (line.find('<scanNumber>') >= 0):
            scan = int(line.split('>')[1].split('<')[0])
        elif (line.find('<subscanNumber>') >= 0):
            subscan = int(line.split('>')[1].split('<')[0])
        elif (line.find('<stateId>') >= 0):
            if (scan in calscans):
                if (nsubscans[calscans.index(scan)] == 3):
                    if (subscan == 1):
                        for state in range(3):
                            line = line.replace('State_%d'%state,AtmcalStateIds['NONE'])
                    elif (subscan == 2):  
                        for state in range(3):
                            line = line.replace('State_%d'%state,AtmcalStateIds['AMBIENT_LOAD'])
                    elif (subscan == 3):
                        for state in range(3):
                            line = line.replace('State_%d'%state,AtmcalStateIds['HOT_LOAD'])
                else:
                    if (subscan == 1 or subscan == 2):  
                        for state in range(4):
                            line = line.replace('State_%d'%state,AtmcalStateIds['NONE'])
                    elif (subscan == 3):  
                        for state in range(4):
                            line = line.replace('State_%d'%state,AtmcalStateIds['AMBIENT_LOAD'])
                    elif (subscan == 4):
                        for state in range(4):
                            line = line.replace('State_%d'%state,AtmcalStateIds['HOT_LOAD'])
        if (line != originalLine):
            changed += 1
            scansToFix.append(scan)
        if not dryrun:
            o.write(line)
        
    if dryrun:
        if (len(scansToFix) > 0):
            print "Scans that need fixing: ", np.unique(scansToFix)
        else:
            print "No scans need fixing."
    else:
        print "Changed %d lines" % (changed)
        o.close()
        os.rename(asdm + '/Main.xml', asdm + '/Main.xml.old') 
        os.rename(asdm + '/Main.xml.new', asdm + '/Main.xml') 
        
def repairSysCal(asdm, sidebandgainoption='observed', showplot=False, 
                 sidebandgain=-1, water='', tsysmode='ALPHA', verbose=True,
                 scan=''):
    """
    Prepares an ASDM for running offline casapy-telcal's tc_atmosphere() command
    to regenerate the SysCal.xml table.  It first moves the SysCal.xml table to
    Syscal.xml.old, then sets the number of SysCal rows to zero in the ASDM.xml
    table.  It then tries to run that task if you are running casapy-telcal.
    This task is useful for computing Tsys solutions that are missing in the
    ASDM.  Based on Neil Phillips' posting to PRTSIR-305.  Before running
    tc_atmosphere, it preserves the other .xml files and copies them back to
    avoid issues with flagcmd.
    scan: use only the specified scans, otherwise, use all ATMOSPHERE scans
    sidebandgainoption: 'observed' or 'fixed' or 'userdefined'
    sidebandgain: use this for 'userdefined'
    water: PWV (in meters) pass this to tc_atmosphere
    tsysmode: either 'WVR' or 'ALPHA' (default)
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find ASDM"
        return
    f = open(asdm+'/ASDM.xml')
    fc = f.read()
    f.close()
    asdmBlockList = re.findall('<Table>.*?</Table>', fc, re.DOTALL|re.MULTILINE)
    if (scan != ''):
        scan = scan.replace(',',' ')
    else:
        # find the scans automatically
        d = readscans(asdm)
        scan = ''
        for s in d[0].keys():
            if (d[0][s]['intent'].find('ATMOSPHERE') > 0):
                print "adding scan %d to list" % (s)
                if (len(scan) > 0): scan += ' '
                scan += str(s)
        if (len(scan) == 0):
            print "No ATMOSPHERE scans found."
            return
    if len(asdmBlockList) == 0:
        print 'Found 0 blocks.'
        return
    for i in range(len(asdmBlockList)):
        if re.search('<Name> *SysCal *</Name>', asdmBlockList[i]) is not None or re.search('<Name> *CalAtmosphere *</Name>', asdmBlockList[i]) is not None:
            asdmBlockList1 = re.sub('<NumberRows> *[0-9]+ *</NumberRows>', '<NumberRows> 0 </NumberRows>', asdmBlockList[i])
            fc = re.sub(asdmBlockList[i], asdmBlockList1, fc)

    f = open(asdm+'/ASDM.xml', 'w')
    f.write(fc)
    f.close()
    newdir = asdm + '.originalxml'
    print "Creating directory ", newdir
    if (os.path.exists(newdir) == False):
        os.mkdir(newdir)
    print "Copying all .xml files to %s..." % (newdir)
    os.system('cp %s/*.xml %s/' % (asdm, newdir))
    modifiedFiles = ['SysCal.xml','ASDM.xml']
    print "...except ", modifiedFiles
    for mF in modifiedFiles:
        if (os.path.exists(newdir+'/'+mF)):
            os.remove(newdir+'/'+mF)              
    if (os.path.exists(asdm+'/SysCal.xml')):
        os.system('mv '+asdm+'/SysCal.xml '+asdm+'/SysCal.xml.old')
#    print "CASA_TELCAL = ", os.getenv('CASA_TELCAL')
#    tasksum = {}  # needed to prevent exception with execfile
#    execfile(os.getenv('CASA_TELCAL')) # still fails upon tc_atmosphere
    try:
        from tc_atmosphere_cli import tc_atmosphere_cli as tc_atmosphere
        print "Running tc_atmosphere('%s', dataorigin='specauto', calresult='%s', showplot=%s, sidebandgainoption='%s', sidebandgain=%f, water='%s', tsysmode='%s',verbose=%s,scan='%s')" % (asdm,asdm, showplot, sidebandgainoption, sidebandgain, water, tsysmode, verbose, scan)
        tc_atmosphere(asdm, dataorigin='specauto', calresult=asdm, 
                      showplot=showplot, sidebandgainoption=sidebandgainoption,
                      sidebandgain=sidebandgain, water=water,tsysmode=tsysmode,
                      verbose=verbose, scans=scan)
        print "Copying the original .xml files back to the ASDM."
        os.system('cp %s/*.xml %s/' % (newdir,asdm))
        print "Done"
    except:
        print "Now you can start casapy-telcal and run:"
        print "execfile(os.getenv('CASA_TELCAL'))"
        print "tc_atmosphere('%s', dataorigin='specauto', calresult='%s', showplot=False, sidebandgainoption='%s', sidebandgain=%f, water='%s', tsysmode='%s', verbose=%s, scans='%s')" % (asdm,asdm,sidebandgainoption,sidebandgain,water,tsysmode,verbose,scan)

def uidToSlashes(uid):
    """
    Converts uid___A002_Xabcd_X001 to uid://A002_Xabcd_X001.
    For the inverse function, see uidToUnderscores.
    -Todd Hunter
    """
    return(uid.replace('_',':',1).replace('_','/'))

def uidToUnderscores(asdm):
    """
    Converts uids from native name to underscore-delimited name (if necessary), preserving any initial path 
    if it has one.  Will not corrupt a pathname that was previously converted.
    -Todd Hunter
    """
    if (asdm.find('uid://') >= 0):
        asdm = asdm.replace('uid://','uid___')
        asdm = asdm.split('uid___')[0] + 'uid___' + asdm.split('uid___')[1].replace('/','_')
    return asdm

def importandlist(asdmlist, suffix='.listobs', outpath='./', 
                  asis='Antenna Station Receiver Source CalAtmosphere CalWVR CorrelatorMode SBSummary ExecBlock',
                  bdfflags=True, applyflags=False, tbuff=0.0, overwrite=False,
                  rungencal=False, process_caldevice=False, runplotbandpass=False):
    """
    Run importasdm (if necessary) followed by listobs on a list of ASDMs
    asdmlist: either a list ['uid1','uid2'] or a wildcard string 'uid*')
    overwrite: passed to importasdm and listobs
    rungencal: if True, then create Tsys table
    runplotbandpass: if True, then create Tsys table and plot it with overlay='time'
    bdfflags, asis, applyflags, tbuff, process_caldevice: passed to importasdm
    Todd Hunter
    """
    if (type(asdmlist) == str):
        mylist = glob.glob(asdmlist)
        if (len(mylist) == 0):
            uids = asdmlist.split(',')
            asdmlist = []
            for uid in uids:
                asdmlist += glob.glob(uidToUnderscores(uid))
        else:
            asdmlist = mylist
    vislist = []
    if not process_caldevice:
        print "Note: process_caldevice=False.  Set to True if you are experimenting with FDM Tsys."
    for asdm in asdmlist:
        if (asdm[-1] == '/'): asdm = asdm[:-1]
        if (asdm[-3:] == '.ms' or asdm[-8:] == '.listobs' or
            asdm[-4:] == '.log' or asdm[-5:] == '.last' or
            asdm[-13:] == '.flagversions' or asdm[-8:] == '_cmd.txt'): continue
        asdm = uidToUnderscores(asdm)
        outvis = outpath + os.path.basename(asdm) + '.ms'
        if (not os.path.exists(outvis) or overwrite):
            for xmlfile in asis.split():
                if len(glob.glob(asdm+'/'+xmlfile.strip()+'.xml')) < 1:
                    print "Could not find an xml file for asis parameter: %s. Dropping from asis." % (xmlfile)
                    asis = asis.replace(xmlfile,'')
            if (casadef.casa_version >= '4.3.0'):
                print "Running importasdm('%s', vis='%s', asis='%s', bdfflags=%s, applyflags=%s, tbuff=%f, process_caldevice=%s)" % (asdm, outvis, asis, bdfflags, applyflags, tbuff, process_caldevice)
                importasdm(asdm, vis=outvis, asis=asis, bdfflags=bdfflags, process_caldevice=process_caldevice,
                           applyflags=applyflags, tbuff=tbuff, overwrite=overwrite)
            else:
                print "Running importasdm('%s', vis='%s', asis='%s', applyflags=%s, tbuff=%f)" % (asdm,outvis, asis,applyflags,tbuff)
                importasdm(asdm, vis=outvis, asis=asis, applyflags=applyflags, tbuff=tbuff, 
                           overwrite=overwrite, process_caldevice=process_caldevice)
        else:
            print "Not running importasdm because ms exists and overwrite=False"
        if (rungencal or runplotbandpass):
            gencal(outvis, caltype='tsys', caltable=outvis+'.tsys')
        if (runplotbandpass):
            plotbandpassOverlayTime(outvis+'.tsys')
        vislist.append(outvis)
    listobslist(vislist, overwrite=overwrite, outpath='')
    
def asdmExportImport(asdmlist, args='', suffix='.listobs', outpath='./', 
                     asis='Antenna Station Receiver Source CalAtmosphere CalWVR CorrelatorMode SBSummary',
                     bdfflags=True, applyflags=False, tbuff=0.0, overwrite=False,
                     rungencal=False, process_caldevice=False, runplotbandpass=False):
    """
    Runs asdmExportLight on the NRAO-CV Lustre system on one ASDM or a list
    of ASDMs, then runs au.importandlist.
    args: passed to asdmExportLight
    rest of arguments: passed to au.importandlist
    -Todd Hunter
    """
    if (outpath[-1] != '/'): outpath += '/'
    asdmlist = asdmExport(asdmlist, args, outpath)
    print "Running importandlist(%s,outpath='%s')" % (asdmlist, outpath)
    importandlist(asdmlist, suffix, outpath, asis, bdfflags, applyflags, tbuff,
                  overwrite, rungencal, process_caldevice, runplotbandpass)

def fillAsdmList(asdmlist):
    """
    Takes a list like: 'uid___A002_Xabf8b9_X504, X38f'
         and returns ['uid___A002_Xabf8b9_X504',
                      'uid___A002_Xabf8b9_X38f']
    -Todd Hunter
    """
    asdmlist = asdmlist.split(',')
    asdms = []
    for i,asdm in enumerate(asdmlist):
        asdm = uidToUnderscores(asdm)
        if (len(asdm.split('_')) < 6):
            if (i==0):
                print "First ASDM in the list must be a complete name (with 5 underscores)"
                return
            loc = asdms[0].replace('_','-',4).find('_')
            asdms.append(asdms[0][:loc+1] + asdm.strip())
        else:
            asdms.append(asdm.strip())
    return(asdms)

def asdmUpdate(asdm, options='-y'):
    """
    Checks whether an ASDM has been updated in the Archive.
    -Todd Hunter
    """
    cmd = 'bash -c "source /lustre/naasc/sciops/pipeline/pipeline_env.asdmExportLight.sh ; asdmUpdate %s %s"' % (options,asdm)
    os.system(cmd)
    
def asdmExportFromPPR(ppr, args='', outpath='./', dryrun=False):
    """
    Runs asdmExportLight on all ASDMs found in a PPR.
    -Todd Hunter
    """
    lines = grep(ppr, 'AsdmDiskName')[0].split('\n')
    asdmlist = []
    for line in lines:
        if (len(line) > 0):
            asdmlist.append(line.split('>')[1].split('<')[0])
    print "Working on list: ", asdmlist
    if not dryrun:
        asdmExport(asdmlist, args, outpath)

def unpackWeblogs(mydir, dryrun=False):
    """
    Given a list of directories, unpacks the first *.tar.gz (or *.tgz) weblog in all of them.
    mydir: list of strings, or single comma-delimited string with optional wildcard characters
    Example: au.unpackWeblogs('*qa')
    -Todd Hunter
    """
    if (mydir.find('*') >= 0):
        mydir = glob.glob(mydir)
    elif type(mydir) == str:
        mydir = mydir.split(',')
    for d in mydir:
        tarball = glob.glob(d+'/*z')
        if (len(tarball) > 0):
            cmd = 'tar xzf %s -C %s' % (tarball[0],d)
            print "Running: ", cmd
            if not dryrun:
                os.system(cmd)

def rebuildWeblog(stages, context='last'):
    """
    Execute this from the working directory of a pipeline run.
    Commands posted to CAS-8906 by Stewart Williams.
    stages: 'imaging' --> uvcontfit, uvcontsub, makeimlist, makeimages
           'timegaincal' --> hifa_timegaincal
    context: 'last', None, or the name of a pickle file
    -Todd Hunter
    """
    import pipeline
    import pipeline.infrastructure.renderer.htmlrenderer
    import pipeline.infrastructure.renderer.weblog as weblog

    if stages == 'imaging':
        weblog.add_renderer(pipeline.hif.tasks.findcont.findcont.FindCont, pipeline.hif.tasks.findcont.renderer.T2_4MDetailsFindContRenderer(always_rerender=True), group_by=weblog.UNGROUPED)
        weblog.add_renderer(pipeline.hif.tasks.uvcontsub.uvcontfit.UVcontFit, pipeline.hif.tasks.uvcontsub.renderer.T2_4MDetailsUVcontFitRenderer(always_rerender=True), group_by=weblog.UNGROUPED)
        weblog.add_renderer(pipeline.hif.tasks.uvcontsub.uvcontsub.UVcontSub, pipeline.hif.tasks.uvcontsub.renderer.T2_4MDetailsUVcontSubRenderer(always_rerender=True), group_by=weblog.UNGROUPED)
        weblog.add_renderer(pipeline.hif.tasks.makeimlist.makeimlist.MakeImList, pipeline.infrastructure.renderer.basetemplates.T2_4MDetailsDefaultRenderer(uri='makeimlist.mako', description='Compile a list of cleaned images to be calculated', always_rerender=True), group_by=weblog.UNGROUPED)
        weblog.add_renderer(pipeline.hif.tasks.makeimages.makeimages.MakeImages, pipeline.hif.tasks.tclean.renderer.T2_4MDetailsTcleanRenderer(description='Calculate clean products', always_rerender=True), group_by=weblog.UNGROUPED)
    elif stages == 'timegaincal':
        weblog.add_renderer(pipeline.hifa.tasks.gaincal.timegaincal.TimeGaincal, pipeline.hif.tasks.gaincal.renderer.T2_4MDetailsGaincalRenderer(description='Gain calibration', always_rerender=True), group_by='session')
    else:
        print "stages must be either 'timegaincal' or 'imaging'"
        return
    context = pipeline.Pipeline(context=context).context
    pipeline.infrastructure.renderer.htmlrenderer.WebLogGenerator.render(context)

def asdmExport(asdmlist, args='', outpath='./', env='/lustre/naasc/sciops/comm/rindebet/pipeline/scripts/pipeline_env_trunk.sh'):
    """
    Runs asdmExportLight on the NRAO-CV Lustre system on one ASDM or
    a list of ASDMs.  Replaces '.ms' with ''.
    asdmlist: comma-delimited list: 'asdm1,asdm2',  or list of strings: ['asdm1','asdm2']
    args: for example "-m" to export only the metadata (XML files)
    -Todd Hunter
    """
    if (type(asdmlist) == str):
        asdmlist = fillAsdmList(asdmlist)
        if (asdmlist == None): return
    newlist = []
    if (outpath[-1] != '/'):
        outpath += '/'
    if args == 'm':
        print "Are you sure you didn't mean -m?"
        return
    for asdm in asdmlist:
        asdm = asdm.replace('.ms','')
        if (outpath != './' and outpath != ''):
            cmd = 'bash -c "source %s ; asdmExportLight %s --outputdirectory=%s %s"' % (env,args,outpath,asdm)
        else:
            cmd = 'bash -c "source /lustre/naasc/sciops/comm/rindebet/pipeline/scripts/pipeline_env_trunk.sh ; asdmExportLight %s %s"' % (args,asdm)
#            cmd = 'bash -c "source /lustre/naasc/sciops/pipeline/pipeline_env.asdmExportLight.sh ; asdmExportLight %s %s"' % (args,asdm)
        print "Running ", cmd
        os.system(cmd)
        newlist.append(outpath+asdm)
    return(newlist)

def examineContext(context, msNumber=0, use_qa_tos=False):
    """
    Examines a pipeline context file for the PI science goals and prints them
       f = open(context, 'r')' 
       c = pickle.load(f)
       for attr in c.observing_run.measurement_sets[msNumber].science_goals: print attr
    use_qa_tos: if True then print quantities as human readable strings
    -Todd Hunter
    """
    f = open(context,'r')
    c = pickle.load(f)
    sgs = c.observing_run.measurement_sets[msNumber].science_goals
    for i,attr in enumerate(sgs):
        if use_qa_tos:
            print '%s: %s' % (attr, qa.tos(qa.quantity(sgs.values()[i])))
        else:
            print attr, sgs.values()[i]
    f.close()

def pipelineMakeRequest(ous, env='pipeline_env_C5P2.sh', imaging=True, downloadAsdms=False):
    """
    Runs pipelineMakeRequest on the NRAO-CV Lustre system on an ALMA OUS and recipe.
    ous: name of uid (either underscore delimited or colon slash delimited)
    env: name of script in Remy's pipeline/scripts area
    imaging: if True, then use procedure_hifa.xml, otherwise use procedure_hifacal.xml
    downloadAsdms: if True, then retrieve the ASDMs
    Example run: pipelineMakeRequest <mous> intents_hifa.xml procedure_hifa.xml False
    -Todd Hunter
    """
    if imaging:
        proc = 'procedure_hifa_calimage.xml'
    else:
        proc = 'procedure_hifa_cal.xml'
    ous = uidToSlashes(ous)
    cmd = 'bash -c "source /lustre/naasc/sciops/comm/rindebet/pipeline/scripts/%s ; pipelineMakeRequest %s intents_hifa.xml %s %s"' % (env, ous,proc,str(downloadAsdms))
    print "Running ", cmd
    os.system(cmd)

def listobslist(vislist, suffix='.listobs', outpath='', overwrite=False, verbose=True, field=''):
    """
    Run listobs on a list of measurement sets
    vislist: either a list ['a.ms','b.ms'], a comma-delimited string, or a wildcard string e.g. '*.ms'
    outpath: if blank, write to same directory as measurement set, otherwise 
             write to specified directory, using basename of measurement set
    -Todd Hunter
    """
    if (type(vislist) == str):
        if vislist.find('*') >= 0:
            vislist = glob.glob(vislist)
        else:
            vislist = vislist.split(',')
    for vis in vislist:
        vis = vis.rstrip('/')
        if len(outpath) > 0:
            listfile = outpath+os.path.basename(vis)+suffix
        else:
            listfile = vis+suffix
        if (not os.path.exists(listfile) or overwrite):
            if (os.path.exists(listfile)):
                os.remove(listfile)
            print "Running listobs('%s', listfile='%s', field='%s')" % (vis, listfile, field)
            listobs(vis, listfile=listfile, field=field)

class CrossScan:
    def __init__(self, vis, intent='CALIBRATE_POINTING#ON_SOURCE'):
        self.vis = vis
        self.myms = createCasaTool(mstool)
        self.myms.open(self.vis)
        self.mymsmd = createCasaTool(msmdtool)
        self.mymsmd.open(self.vis)
        self.scans = self.mymsmd.scansforintent(intent)
        self.spws = self.mymsmd.spwsforintent(intent)
        try:
            self.sqldspws = np.intersect1d(self.mymsmd.almaspws(sqld=True), self.spws)
        except:
            self.sqldspws = np.intersect1d(self.mymsmd.chanavgspws(), self.spws)
        self.mymsmd.close()
        print "Scans for %s = %s" % (intent, self.scans)
        print "Spws for %s = %s" % (intent, self.spws)
        print "SQLDs for %s = %s" % (intent, self.sqldspws)
        self.datadescids = {}
        for spw in self.spws:
            self.datadescids[spw]=spw  # assume this is true for now, use msmd in casa 4.3

    def onMinusOffOverOff(self, antenna, spw, scan, subscan, pol=0, verbose=False):
        includeDate = False
        result = computeDurationOfScan(scan, vis=self.vis, returnSubscanTimes=True, 
                                       verbose=verbose,includeDate=includeDate)
        self.timestamps = {}
        self.timestamps[scan] = result[2]
        print "Found %d subscans" % (len(self.timestamps[scan]))
        self.myms.selectinit(datadescid=self.datadescids[spw])
        self.myms.select({'time':self.timestamps[scan][subscan],
                          'antenna1':antenna, 'antenna2':antenna})
        data0 = self.myms.getdata(['amplitude'])['amplitude']  # keyed by pol: 0, 1
        pb.clf()
        print "shape(self.timestamps[scan][subscan]=%s, shape(data0[pol])=%s" % (np.shape(self.timestamps[scan][subscan]), np.shape(data0[pol]))
        pb.plot(self.timestamps[scan][subscan], data0[pol])
        pb.draw()

def sqldspws(vis):
    """
    Return the SQLD spws for version of casa prior to 26688 which do 
    not have msmd.almaspws().  - Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW')
    names = mytb.getcol('NAME')
    mytb.close()
    sqld = []
    for i,name in enumerate(names):
        if (name.find('#SQLD')>0):
            sqld.append(i)
    return(sqld)

class SQLD():
    def __init__(self, vis, copy_ms=False, gettmcdb=False, outpath='./', verbose=False, dbm=True):
        """
        vis: the measurement set to operate with
        copy_ms: if set to True, it will first copy vis.ms into vis.sqld in the pwd
                 and then operate on that dataset instead of vis.ms
        gettmcdb: if True, then also get the BB detector values from the TMC DB
        outpath: the path to write the TMC DB data (default = './')
        dbm: if True, convert TMC DB values to dBm;  if False, convert to mW
        """
        if not os.path.exists(vis):
            print "Could not find measurement set."
            return
        if not os.path.exists(vis+'/table.dat'):
            print "This does not appear to be a measurement set."
            return
        if copy_ms:
            basename = vis.rstrip('.ms')
            newname = os.path.basename(basename)
            if (os.path.exists(newname+'.sqld')):
                print "Removing existing .sqld directory"
                shutil.rmtree(newname+'.sqld')
            cmd = 'rsync -au %s/ %s.sqld' % (vis, newname)
            print "Running: %s" % (cmd)
            os.system(cmd)
            vis = newname + '.sqld'
            print "Setting vis=%s" % (vis)
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        self.vis = vis

        if (casadef.subversion_revision < casaRevisionWithAlmaspws):
            self.sqldspws = sqldspws(self.vis)
        else:
            self.sqldspws = mymsmd.almaspws(sqld=True)
        if (casadef.subversion_revision > '27480'):
            self.antennaNames = mymsmd.antennanames() 
        else:
            self.antennaNames = getAntennaNames(self.vis)
        self.intents = mymsmd.intents()
        if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in self.intents):
            self.atmcalscans = []
        else:
            self.atmcalscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
        if ('OBSERVE_TARGET#ON_SOURCE' not in self.intents):
            self.observeTargetScans = []
        else:
            self.observeTargetScans = mymsmd.scansforintent('OBSERVE_TARGET#ON_SOURCE')
        if (len(self.sqldspws) == 0):
            print "There are no SQLD spws in this dataset."
            if (not gettmcdb):
                gettmcdb = True
                print "Setting gettmcdb to True"
        self.datadescIDs = {}
        self.basebands = {}
        self.pols = [0,1]  # call findNumberOfPolarizations
        self.date = getObservationStartDate(self.vis).split()[0]  # YYYY-MM-DD
        self.yyyymmdd = self.date
        if (self.yyyymmdd < '2013-05-29' and gettmcdb):
            gettmcdb = False
            print "These data are too old to have BB detector values stored in the TMCDB."
        self.yyyymmdd2 = getObservationStopDate(self.vis).split()[0]
        if (self.yyyymmdd != self.yyyymmdd2):
            print "WARNING: This dataset spans two UT days, which is not yet fully supported."
        self.IFProc = {}
        self.startTime = np.min(mymsmd.timesforscan(mymsmd.scannumbers()[0]))
        self.endTime =   np.max(mymsmd.timesforscan(mymsmd.scannumbers()[-1]))
        self.scanTimes = {}
        self.intents = {}
        for scan in mymsmd.scannumbers():
            self.scanTimes[scan] = [np.min(mymsmd.timesforscan(scan)),
                                    np.mean(mymsmd.timesforscan(scan)),
                                    np.max(mymsmd.timesforscan(scan))]
            self.intents[scan] = mymsmd.intentsforscan(scan)
        for spw in self.sqldspws:
            try:
                self.datadescIDs[spw] = mymsmd.datadescids(spw)
            except:
                self.datadescIDs[spw] = spw
            self.basebands[spw] = mymsmd.baseband(spw)
        self.sqldData = {}
        self.sqldDataDBm = {}
        self.sqldDataUTC = {}
        self.dbm = dbm
        if (gettmcdb):
            print "Retrieving the periodic measurements from TMCDB."
            self.getTMCDBData(outpath=outpath, verbose=verbose)
        mymsmd.close()

    def plotTMCDB(self, antenna='', pol='', basebands='', wholeDay=False, 
                  labelscans=True, labelintents=True, plotfile=True, yrange=[0,5],
                  verbose=False, markdbm=[+2.4,+3.8], timeBuffer=40, units='dBm'):
        """
        Plots the power vs. time of the total power detectors as read from the
        ALMA TMC database.
        antenna: integer, string, or list of antenna IDs or names
        pol: 0, 1 or [0,1] (default)
        basebands: string or list of basebands numbers to plot (1..4)
        wholeDay: if True, plot the whole day of data, not just during the dataset
        labelscans: if True, demarcate and label the scan numbers
        labelintents: if True, label ATM, POI, SID, OBS intent scans
        plotfile: path and name of png to produce, or True for automatic
        yrange: the y-axis plotrange: [y0,y1]
        markdbm: draw a horizontal line at the specified level(s), set to None for none
        timeBuffer: value in seconds to widen the beginning and end of the dataset
        units: the y-axis units (either 'dBm' or 'milliwatt')
        """
        if (pol==''):
            polList = [0,1]
        antennaList = parseAntenna(self.vis, antenna)
        pb.clf()
        pb.hold(True)
        if (basebands == ''):
            basebands = self.sqldDataDBm[self.antennaNames[antennaList[0]]][polList[0]].keys()
        else:
            basebands = parseBasebandArgument(basebands)
        linestyles = ['.-','.--']
        for baseband in basebands:
            if (len(basebands) == 1):
                desc = pb.subplot(1,1,1)
                nplots = 1
                nrows = 1
                column = 1
                row = 1
            else:
                desc = pb.subplot(2,2,baseband)
                nplots = 4
                nrows = 2
                if (baseband % 2 == 1):
                    column = 1
                else:
                    column = 2
                if (baseband < 3):
                    row = 1
                else:
                    row = 2
            pb.title('Baseband %d' % (baseband))
            for antennaID in antennaList:
                antenna = self.antennaNames[antennaID]
                if (verbose): print "Working on antenna %s baseband %d" % (antenna, baseband)
                for pol in polList:
                    if (wholeDay):
                        timeStamps = pb.date2num(mjdSecondsListToDateTime(list(self.sqldDataUTC[antenna][pol])))
                        day = mjdsecToUT(self.sqldDataUTC[antenna][pol][0]).split()[0]
                        yaxis = self.sqldDataDBm[antenna][pol][baseband]
                        if (units.lower() == 'milliwatt' or units.lower() == 'mw'):
                            yaxis = 10**(0.1*yaxis)
                        pb.plot_date(timeStamps, yaxis, linestyles[pol], color=overlayColors[antennaID])
                        setXaxisTimeTicks(desc, np.min(self.sqldDataUTC[antenna][pol]),
                                          np.max(self.sqldDataUTC[antenna][pol]))
                    else:
                        idx1 = np.where(self.sqldDataUTC[antenna][pol] >= self.startTime-timeBuffer)[0]
                        idx2 = np.where(self.sqldDataUTC[antenna][pol] <= self.endTime+timeBuffer)[0]
                        idx = np.intersect1d(idx1,idx2)
                        timeStamps = pb.date2num(mjdSecondsListToDateTime(list(np.array(self.sqldDataUTC[antenna][pol])[idx])))
                        day = mjdsecToUT(self.sqldDataUTC[antenna][pol][idx[0]]).split()[0]
                        yaxis = self.sqldDataDBm[antenna][pol][baseband][idx]
                        if (units.lower() == 'milliwatt' or units.lower() == 'mw'):
                            yaxis = 10**(0.1*yaxis)
                        pb.plot_date(timeStamps, yaxis, 
                                     linestyles[pol], color=overlayColors[antennaID])
                        setXaxisTimeTicks(desc, self.startTime, self.endTime, verbose=False)
                if (nplots==1 or baseband==2):
                    pb.text(1.02,1.04-antennaID*0.025*nrows, antenna, size=9,
                            transform=desc.transAxes,color=overlayColors[antennaID])
                    pb.text(0.5, 1.08, os.path.basename(self.vis))
            if (column == 1):
                if (self.dbm and units.lower()=='dbm'):
                    pb.ylabel('Power (dBm)')
                else:
                    pb.ylabel('Power (mW)')
                if (row == 2):
                    pb.xlabel(os.path.basename(self.vis))
            if (yrange != [0,0]):
                pb.ylim(yrange)
            if (labelscans):
                y0 = pb.ylim()[1]-(pb.ylim()[1]-pb.ylim()[0])*0.04*nrows
                for scan in self.scanTimes.keys():
                    myTimes = pb.date2num(mjdSecondsListToDateTime([self.scanTimes[scan][0],self.scanTimes[scan][0]]))
                    pb.plot(myTimes, pb.ylim(), ':', color='k')
                    if (scan == self.scanTimes.keys()[-1]):
                        myTimes = pb.date2num(mjdSecondsListToDateTime([self.scanTimes[scan][2],self.scanTimes[scan][2]]))
                        pb.plot(myTimes, pb.ylim(), ':', color='k')

                    pb.text(mjdSecondsListToDateTime([self.scanTimes[scan][1]])[0], y0, str(scan), size=8)
                pb.xlim(pb.date2num(mjdSecondsListToDateTime([self.startTime-timeBuffer, self.endTime+timeBuffer])))
            if (yrange != [0,0]):
                pb.ylim(yrange)
            if (labelintents):
                for scan in self.scanTimes.keys():
                    for intent in ['ATM','SIDEBAND','POINTING','OBSERVE','AMPLI','FLUX','BANDPASS']:
                        y0 = pb.ylim()[1]-(pb.ylim()[1]-pb.ylim()[0])*0.11*nrows
                        if (','.join(self.intents[scan]).find(intent) > 0):
                            pb.text(mjdSecondsListToDateTime([self.scanTimes[scan][1]])[0], y0, intent[:5], size=7, rotation='vertical', ha='left', va='bottom')
                            break  # be sure only one intent is written per scan
            if (self.dbm):
                if (markdbm is not None and markdbm != []):
                    if (type(markdbm) != list):
                        markdbm = [markdbm]
                    for mrk in markdbm:
                        pb.plot(pb.xlim(), [mrk,mrk], 'k:')
            else:
                if (markdbm is not None and markdbm != []):
                    if (type(markdbm) != list):
                        markdbm = [markdbm]
                    for mrk in markdbm:
                        pb.plot(pb.xlim(), [10**(mrk*0.1),10**(mrk*0.1)], 'k:')
            if (nrows == 2):
                pb.setp(desc.get_xticklabels(), fontsize=8)
                pb.setp(desc.get_yticklabels(), fontsize=8)
            if (yrange != [0,0]):
                pb.ylim(yrange)
        pb.xlabel('Time (UT on %s)'%(day))        
        yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
        desc.yaxis.set_major_formatter(yFormat)
        pb.draw()
        if (plotfile != ''):
            if (plotfile == True):
                if (self.dbm):
                    plotfile = self.vis.replace('.sqld','') + '.sqld.dBm.png'
                else:
                    plotfile = self.vis.replace('.sqld','') + '.sqld.mW.png'
            dirname = os.path.dirname(plotfile)
            if (dirname == ''):
                dirname = './'
            if (os.access(dirname,os.W_OK) == False):
                plotfile = '/tmp/' + os.path.basename(plotfile)
            pb.savefig(plotfile)
            print "Plot left in: ", plotfile

    def convertTMCDBtoPower(self, calibration='auto', verbose=False):
        """
        convert self.sqldData from voltage to dBm
        into self.sqldDataDBm.  The structure of sqldDataDBm is:
        [antenna][pol][baseband: 'A','B','C','D'][list of voltages vs. time]
        """
        query = False
        basebands = [0, 'A','B','C','D']
        if (self.IFProc == {}):  # contains the calibration coefficients
            query = True
        else:
            for antenna in self.antennaNames:
                if (antenna not in self.IFProc.keys()):
                    query = True
        if (query):
            for i,antenna in enumerate(self.antennaNames):
                if (antenna not in self.IFProc.keys()):
                    if (antenna not in self.sqldDataDBm.keys()):
                        self.sqldDataDBm[antenna] = {}
                        self.sqldDataUTC[antenna] = {}
                    self.IFProc[antenna] = self.readSQLDCalibration(antenna, calibration)
                    if (verbose):
                        print "Antenna %2d = %s: " % (i,antenna), self.IFProc[antenna]
                    for pol in self.pols:
                        self.sqldDataUTC[antenna][pol] = self.sqldData[antenna][pol][0]
                        self.sqldDataDBm[antenna][pol] = {}
                        for channel, baseband in enumerate(np.unique(self.basebands.values())):  # need unique in case multiple groups of 4 SQLD spws
                            basebandLetter = basebands[baseband]
                            inputPowerAtZeroVoltage = self.IFProc[antenna][pol][basebandLetter]['icept']
                            # Scale by the gain slope, then add the offset
#                            print "shape(sqldData) = ", np.shape(self.sqldData[antenna][pol][1])
#                            print "len(shape(sqldData)) = ", len(np.shape(self.sqldData[antenna][pol][1]))
                            if (len(np.shape(self.sqldData[antenna][pol][1])) < 2):
                                print "There is a problem with the TMCDB data for %s pol %d (probably missing)" % (antenna,pol)
                                break
                            else:
                                voltages = np.transpose(np.array(self.sqldData[antenna][pol][1]))
                                self.sqldDataDBm[antenna][pol][baseband] = voltages[channel]*self.IFProc[antenna][pol][basebandLetter]['slope']+self.IFProc[antenna][pol][basebandLetter]['icept']
                                if (self.dbm):
                                    self.sqldDataDBm[antenna][pol][baseband] = 10*np.log10(self.sqldDataDBm[antenna][pol][baseband])
        return
        
    def getTMCDBData(self, outpath='./', verbose=False):
        monitorPoint = 'DATA_MONITOR_2'  # BB SQLDs  (_1=SB SQLDs)
        self.sqldData = {}
        for antenna in self.antennaNames:
            self.sqldData[antenna] = {}
            for pol in self.pols:  
                # need to get file for second date if necessary
                localfile = tmu.retrieve_daily_tmc_data_file_name_only(antenna,'IFProc'+str(pol), monitorPoint, self.yyyymmdd, outpath=outpath)
                if (os.path.exists(localfile)):
                    tmcfile_ifproc = localfile
                else:
                    try:
                        mydict=tmu.get_tmc_data(antenna,'IFProc'+str(pol),monitorPoint, self.yyyymmdd, self.yyyymmdd, outpath=outpath)
                        tmcfile_ifproc = mydict['files'][0]
                        self.tmcfile_ifproc = tmcfile_ifproc
                    except:
                        print "Failed to retrieve data for antenna %s" % (antenna)
                        continue
                self.sqldData[antenna][pol] = self.readIFProcBBSQLDs(tmcfile_ifproc, pol)
        self.convertTMCDBtoPower(verbose=verbose)
        return

    def readIFProcBBSQLDs(self, tmcfile, pol=0):
        """
        Returns 2 lists: dateTimeStamp in MJD second, and SQLD readings
        """
        loc = tmcfile.find('IFProc')+6
        if (loc > 0):
            tmcfile = tmcfile[:loc] + str(pol) + tmcfile[loc+1:]
            print "Using existing file = ", tmcfile
        if (os.path.exists(tmcfile) == False):
            print "Could not open IF Proc TMC database file"
            return
        tmclines = open(tmcfile,'r').readlines()
        dateTimeStamp = []
        voltages = []
        for line in tmclines:
            tokens = line.split()
            if (len(tokens) == 0):
                print "len(tokens) = %d" % (len(tokens))
            dateTimeStamp.append(dateStringToMJDSec(tokens[0],verbose=False))
            voltages.append([float(x) for x in tokens[1:]])
        return(dateTimeStamp, voltages)

    def convertSQLDtodBm(self, antenna='', calibration='auto', spw='',
                         zeroLevel=-20, verbose=False):
        """
        Converts the amplitude data in the SQLD spws of an ALMA measurement set
        from counts to dBm.
        Inputs:
        * vis: the measurement set
        Optional inputs:
        * calibration: a text file that contains the slope and intercept values
                 for each of the IF channels (A,B,C,D for each sideband)
        * antenna: the list of antenna names or IDs to convert
        * spw: the list of spws to convert (default is all SQLD spws)
        * zeroLevel: what value (in dBm) to assign to data points with 0 counts
        Theory:
        a) convert from counts to mV using (counts/65536)*2.5
        b) apply the slope and intercept to convert to mW
        d) convert from mW to dBm by 10*log10(mW)
        -Todd Hunter
        """
        if (len(self.sqldspws) == 0):
            print "There are no SQLD spws in this dataset!"
            return
        antennaList = parseAntenna(self.vis, antenna)
        query = False
        if (self.IFProc == {}):
            query = True
        else:
            for antenna in antennaList:
                if (antenna not in self.IFProc.keys()):
                    query = True
        if (query):
            for antenna in antennaList:
                if (antenna not in self.IFProc.keys()):
                    self.IFProc[antenna] = self.readSQLDCalibration(self.antennaNames[antenna], calibration)
                    print "Antenna %2d = %s: " % (antenna,self.antennaNames[antenna]), self.IFProc[antenna]
        basebands = [0, 'A','B','C','D']
        channel = 0
        if (spw == ''):
            spws = self.sqldspws
        else:
            spws = [int(x) for x in spw.split(',')]
        dataColumnName = getDataColumnName(self.vis)
        myt = createCasaTool(tbtool)
        myt.open(self.vis, nomodify=False)
        history = []
        for spw in spws:
            for antenna in antennaList:
                ddid = self.datadescIDs[spw]
                print "Working on spw %d (DD=%d), antenna %d (%s)" % (spw, ddid, antenna, self.antennaNames[antenna])
                mytb = myt.query('DATA_DESC_ID==%d and ANTENNA1==%d and ANTENNA2==%d' % (ddid,antenna,antenna))
                complexData = mytb.getcol(dataColumnName)
                baseband = basebands[self.basebands[spw]]
                for pol in range(len(complexData)):
                    if (verbose):
                        print "min/max of spw=%d, pol=%d is %f/%f" % (spw,pol,np.min(np.real(complexData[pol][channel])), np.max(np.real(complexData[pol][channel])))
                        print "complexData[pol][channel] = ", str(complexData[pol][channel])
                    inputPowerAtZeroVoltage = self.IFProc[antenna][pol][baseband]['icept']
                    # Scale by the gain slope, then add the offset
                    arg = (complexData[pol][channel]*2.5/65536.)*self.IFProc[antenna][pol][baseband]['slope']+self.IFProc[antenna][pol][baseband]['icept']
                    if verbose:
                        print "    inputPowerAtZeroVoltage level = %f mW" % (inputPowerAtZeroVoltage)
                        if (len(np.where(np.real(arg)<=inputPowerAtZeroVoltage)[0]) > 0):
                            print "Replacing %d/%d zero values in pol 0 with -20dBm" % (len(np.where(np.real(arg)<=inputPowerAtZeroVoltage)[0]),len(arg))
                    if (self.dbm):
                        if (dataColumnName == 'DATA'):
                            arg[np.where(np.real(arg) <= inputPowerAtZeroVoltage)[0]] = np.complex(10**(zeroLevel*0.1),0)  # i.e. convert -20 to 1e-2
                        else: # FLOAT_DATA
                            arg[np.where(np.real(arg) <= inputPowerAtZeroVoltage)[0]] = 10**(zeroLevel*0.1)
                        complexData[pol][channel] = 10*np.log10(arg)
                    else:
                        complexData[pol][channel] = arg
                        
                    if (verbose):
                        print "    after scaling, min/max is %f/%f" % (np.nanmin(np.real(complexData[pol][channel])), 
                                                                       np.nanmax(np.real(complexData[pol][channel])))
                mytb.putcol(dataColumnName,complexData)
                mytb.close()
                history.append('Scaled antenna %2d SQLD spw %2d data into dBm' % (antenna,spw))
        myt.close()
        myms = createCasaTool(mstool)
        myms.open(self.vis, nomodify=False)
        for h in history:
            myms.writehistory(h)
        myms.listhistory()
        myms.close()

    def plotms(self, antenna='*&&&', scan='', spw='', coloraxis='spw',
               correlation='XX', iteraxis='antenna', avgtime='1s',
               plotrange=[0,0,0,0], intent='OBSERVE_TARGET',
               plotfile='', buildpdf=False, overwrite=True):
        """
        Runs plotms on a measurement set with useful parameters
        scan: if '', then plot all scans with specified intent(s)
        spw: if '', then find all SQLD spws
        intent: a list of intents, as a comma-delimited string
        buildpdf: if True, build a PDF of all antennas, one per page
                  if False, use iteraxis='antenna'
        """
        if (scan == '' and intent != ''):
            targetscans = []
            if (intent.find('OBSERVE_TARGET')>=0):
                scan = ','.join([str(i) for i in self.observeTargetScans])
                targetscans = scan
            if (intent.find('CALIBRATE_ATMOSPHERE')>=0):
                scan = ','.join(targetscans+[str(i) for i in self.atmcalscans])
                    
        if (spw == ''):
            spw = ','.join([str(i) for i in self.sqldspws])
        if (buildpdf == False):
            showgui = True
            if (antenna.find('&&&') < 0):
                antenna += '&&&'
            print "Running plotms('%s', antenna='%s', coloraxis='%s', yaxis='real', xaxis='time', correlation='%s', ylabel='Power', spw='%s', scan='%s', iteraxis='%s', avgtime='%s', plotrange=%s, plotfile='%s', overwrite=%s, showgui=%s)" % (self.vis,antenna,coloraxis,correlation,spw,scan,iteraxis,avgtime,str(plotrange),plotfile,str(overwrite),showgui)
            plotms(self.vis, antenna=antenna, coloraxis=coloraxis, yaxis='real',
                   xaxis='time',correlation=correlation,ylabel='Power',
                   spw=spw, scan=scan, iteraxis=iteraxis, avgtime=avgtime, showgui=showgui,
                   plotrange=plotrange, plotfile=plotfile, overwrite=overwrite)
        else:
            plotfiles = []
            showgui = False
            for antname in self.antennaNames:
                plotfile = self.vis + '.' + antname + '.png'
                ant = antname + '&&&'
                mytitle = os.path.basename(self.vis) + ' ' + antname + ' ' + correlation + ' Power vs. time'
                print "Running plotms('%s', antenna='%s', coloraxis='%s', yaxis='real', xaxis='time', correlation='%s', ylabel='Power (dBm)', spw='%s', scan='%s', avgtime='%s', plotrange=%s, plotfile='%s', showgui=%s, overwrite=%s, title='%s')" % (self.vis,ant,coloraxis,correlation,spw,scan,avgtime,str(plotrange),plotfile,showgui,str(overwrite),mytitle)
                plotms(self.vis, antenna=ant, coloraxis=coloraxis, yaxis='real',
                       xaxis='time',correlation=correlation,ylabel='Power (dBm)',
                       spw=spw, scan=scan, avgtime=avgtime, title=mytitle,
                       plotrange=plotrange, plotfile=plotfile, showgui=showgui,
                       overwrite=overwrite)
                plotfiles.append(plotfile)
            pdfname = self.vis + '.pdf'
            buildPdfFromPngs(plotfiles, pdfname=pdfname)
            
    def readSQLDCalibration(self, antenna, calibration='auto',overwrite=False,verbose=False):
        """
        Reads the gains (slope and intercept) of the SQLDs from a
        container log text file.
        calibration: if 'auto', then retrieve the files from the computing web server
                     if '', then use the default values for DA64 on April 1, 2014
                     if a filename, then search for values in it
        overwrite: if False (default), then check if the files have already
                   been retrieved in the current working directory
                   if True, then re-retrieve them
        -Todd Hunter
        """
        if (calibration == 'auto'):
            cal = open(compUtils.retrieve_abm_container_data_files(antenna, self.date, overwrite, verbose=False), 'r')
            lines = cal.readlines()
            cal.close()
        else:
            if not os.path.exists(calibration):
                print "Could not find calibration table. Using defaults."
                calibration = ''
            if (calibration==''):
                lines = ['2014-03-31T22:40:08.142   IFProc0:\n',
                     '<DET ch="A" slope="1.645000" icept="-0.140000"/>\n',
                     '<DET ch="B" slope="1.585000" icept="-0.122000"/>\n',
                     '<DET ch="C" slope="1.515000" icept="-0.099200"/>\n',
                     '<DET ch="D" slope="1.490000" icept="-0.122000"/> \n',
                     '2014-03-31T22:40:33.310   IFProc1:\n',
                     '<DET ch="USB" slope="0.004900" icept="-0.000440"/>\n',
                     '<DET ch="LSB" slope="0.005900" icept="-0.000585"/>\n',
                     '<DET ch="A" slope="1.595000" icept="-0.140000"/>\n',
                     '<DET ch="B" slope="1.555000" icept="-0.113000"/>\n',
                     '<DET ch="C" slope="1.460000" icept="-0.115000"/>\n',
                     '<DET ch="D" slope="1.560000" icept="-0.118000"/>\n']
            else:
                cal = open(calibration,"r")
                lines = cal.readlines()
                cal.close()
        processor = -1
        IFProc = {}
        for line in lines:
            if (line.find('IFProc0') >= 0):
                processor = 0
            if (line.find('IFProc1') >= 0):
                processor = 1
            if (processor >= 0):
                if (line.find('DET ch=') >= 0 and line.find('SB') < 0):
                    a,b,c,d = line.split()
                    if (processor not in IFProc.keys()):
                        IFProc[processor] = {}
                    if (b[4] not in IFProc[processor].keys()):
                        IFProc[processor][b[4]] = {}
                    IFProc[processor][b[4]]['slope'] = float(c.split('"')[1])
                    IFProc[processor][b[4]]['icept'] = float(d.split('"')[1])
        return(IFProc)
    
def readAttenuatorSettings(dataset, antenna=0, pol=0, outpath='./'):
    """
    Queries the TMCDB for attenuator settings during an ALMA dataset.
    If text file already exists in the output, then it will read it.
    antenna: the antenna ID (integer)
    pol: 0 or 1
    """
    if (not os.path.exists(dataset)):
        print "Could not find dataset"
        return
    if (os.path.exists(dataset+'/table.dat')):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(dataset)
        antennaNames = mymsmd.antennanames()
        mymsmd.close()
        yyyymmdd = getObservationStartDate(dataset).split()[0]
    else:
        antennaNames = readAntennasFromASDM(dataset, verbose=False)
        yyyymmdd = getObservationStartDateFromASDM(dataset)[0].split()[0]
    sidebands = [1,2]
    localfile = tmu.retrieve_daily_tmc_data_file_name_only(antennaNames[antenna],'IFProc'+str(pol),
                                                           'GAINS', yyyymmdd, outpath=outpath)
    if (os.path.exists(localfile)):
        tmcfile_ifproc = localfile
    else:
        try:
            mydict = tmu.get_tmc_data(antennaNames[antenna],'IFProc'+str(pol),'GAINS', yyyymmdd, yyyymmdd, outpath=outpath)
            tmcfile_ifproc = mydict['files'][0]
            tmcfile_ifproc = tmcfile_ifproc
        except:
            return False
    tmcfile_ifswitch = {}
    for sideband in sidebands:
        localfile = tmu.retrieve_daily_tmc_data_file_name_only(antennaNames[antenna],'FrontEnd_IFSwitch',
                                                               'CHANNEL%d%d_ATTENUATION'%(pol,sideband), yyyymmdd, outpath=outpath)
        if (os.path.exists(localfile)):
            tmcfile_ifswitch[sideband] = localfile
        else:
            mydict = tmu.get_tmc_data(antennaNames[antenna],'FrontEnd_IFSwitch',
                               'CHANNEL%d%d_ATTENUATION'%(pol,sideband), yyyymmdd, yyyymmdd, outpath=outpath)
            tmcfile_ifswitch[sideband] = mydict['files'][0]

    ifproc_time, ifproc_dB = readIFProcAttenuatorSettings(tmcfile_ifproc, pol=pol)
    ifswitchLSB_time, ifswitchLSB_dB = readIFSwitchAttenuatorSettings(tmcfile_ifswitch, pol=pol, sideband=1)
    ifswitchUSB_time, ifswitchUSB_dB = readIFSwitchAttenuatorSettings(tmcfile_ifswitch, pol=pol, sideband=2)
    return(ifproc_time, ifproc_dB, ifswitchLSB_time, ifswitchLSB_dB, ifswitchUSB_time, ifswitchUSB_dB)

def plotAttenuatorSettings(dataset, antenna=0, pol=0, outpath='./', buildPDF=False):
    """
    Reads the attenuators settings from the TMCDB for a specified ALMA dataset
    (measurement set or ASDM) and plots them vs. time.
    dataset: name of measurement set or ASDM
    antenna: name or ID (or a list of names or IDs)
    pol: 0 or 1
    outpath: the path to look for (or save) the attenuator files
    """
    if (not os.path.exists(dataset)):
        print "Could not find dataset."
        return
    dataset = dataset.rstrip('/')
    if (os.path.exists(dataset+'/table.dat')): # dataset is a measurement set
        antennaIDs = parseAntenna(dataset, antenna)
        yyyymmdd = getObservationStartDate(dataset).split()[0]
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(dataset)
        scans = mymsmd.scannumbers()
        scantimes = []
        for scan in scans:
            scantimes.append(np.min(mymsmd.timesforscan(scan)))
        antennaNames = mymsmd.antennanames()
        mymsmd.close()
        startMJDSec = getObservationStart(dataset)
        stopMJDSec = getObservationStop(dataset)
    else:  # dataset is an ASDM
        antennaNames = readAntennasFromASDM(dataset, verbose=False)
        antennaIDs = parseAntennaASDM(dataset, antenna)
        yyyymmdd = getObservationStartDateFromASDM(dataset)[0].split()[0]
        scaninfo = readscans(dataset)
        scans = scaninfo[0].keys()
        scantimes = []
        for scan in scans:
            scantimes.append(scaninfo[0][scan]['startmjd']*86400)
        startMJDSec = getObservationStartDateFromASDM(dataset)[1]
        stopMJDSec = getObservationEndDateFromASDM(dataset)[1]
    pngs = []
    for antenna in antennaIDs:
        antennaName = antennaNames[antenna]
        ifproc_time, ifproc_dB, ifswitchLSB_time, ifswitchLSB_dB, ifswitchUSB_time, ifswitchUSB_dB = readAttenuatorSettings(dataset, antenna, pol, outpath)
        pb.clf()
        desc = pb.subplot(211)
        pb.hold(True)
        col = ['k', 'b', 'r', 'g']
        idx1 = np.where(ifproc_time >= startMJDSec)[0]
        idx2 = np.where(ifproc_time <= stopMJDSec)[0]
        idx = np.intersect1d(idx1,idx2)
        timeStamps = pb.date2num(mjdSecondsListToDateTime(ifproc_time[idx]))
        for bb in range(4):
            pb.plot_date(timeStamps, ifproc_dB[bb][idx], '%s-' % col[bb]) 
        pb.ylabel('IF Processor (dB)')
        pb.title(os.path.basename(dataset) + ' ' + antennaName + ' pol ' + str(pol))
        desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        desc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,20)))
        desc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        desc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
        pb.xlabel('UT on '+yyyymmdd)
        timeStamps = pb.date2num(mjdSecondsListToDateTime(scantimes))
        ylims = pb.ylim()
        pb.ylim([ylims[0]-0.5, ylims[1]+0.5])
        ylims = pb.ylim()
        for i, timestamp in enumerate(timeStamps):
            if (i==0):
                t = 'scan %d' % scans[i]
                ha = 'center'
            else:
                t = str(scans[i])
                ha = 'left'
            pb.text(timestamp, ylims[1]-0.05*(ylims[1]-ylims[0]), t, size=8, ha=ha)
            pb.plot_date([timestamp,timestamp], pb.ylim(), 'k:')

        desc = pb.subplot(212)
        idx1 = np.where(ifswitchLSB_time >= startMJDSec)[0]
        idx2 = np.where(ifswitchLSB_time <= stopMJDSec)[0]
        idx = np.intersect1d(idx1,idx2)
        timeStampsLSB = pb.date2num(mjdSecondsListToDateTime(ifswitchLSB_time[idx]))
        pb.plot_date(timeStampsLSB, ifswitchLSB_dB[idx], '%s-' % col[0]) 

        idx1 = np.where(ifswitchUSB_time >= startMJDSec)[0]
        idx2 = np.where(ifswitchUSB_time <= stopMJDSec)[0]
        idx = np.intersect1d(idx1,idx2)
        timeStampsUSB = pb.date2num(mjdSecondsListToDateTime(ifswitchUSB_time[idx]))
        pb.plot_date(timeStampsUSB, ifswitchUSB_dB[idx], '%s-' % col[1]) 
        pb.ylabel('IF switch (dB)')
        desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        desc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,20)))
        desc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        desc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
        pb.xlabel('UT on '+yyyymmdd)
        ylims = pb.ylim()
        pb.ylim([ylims[0]-0.5, ylims[1]+0.5])
        ylims = pb.ylim()
        for i, timestamp in enumerate(timeStamps):
            if (i==0):
                t = 'scan %d' % scans[i]
                ha = 'center'
            else:
                t = str(scans[i])
                ha = 'left'
            pb.text(timestamp, ylims[1]-0.05*(ylims[1]-ylims[0]), t, size=8, ha=ha)
            pb.plot_date([timestamp,timestamp], pb.ylim(), 'k:')
        pb.draw()
        png = dataset+'.%s.pol%d.attenuators.png' % (antennaName,pol)
        pngs.append(png)
        pb.savefig(png)
        print "Wrote plot = ", png
        pb.hold(False)
    if (buildPDF and (len(pngs) > 1)):
        pdf = dataset+'.attenuators.pdf'
        buildPdfFromPngs(pngs, pdf)
        print "Wrote PDF = ", pdf

def readIFProcAttenuatorSettings(tmcfile, pol=0):
    """
    Parses an IF processor attenuator text file read from the TMCDB and returns
    an array of timestamps (MJDsec) and an array of attenuator values 
    (in dB, one per sideband) for the specified polarization and sideband.
    -Todd Hunter
    """
    loc = tmcfile.find('IFProc')+6
    if (loc > 0):
        tmcfile = tmcfile[:loc] + str(pol) + tmcfile[loc+1:]
        print "Using file = ", tmcfile
    if (os.path.exists(tmcfile) == False):
        print "Could not open IF Proc TMC database file"
        return
    tmclines = open(tmcfile,'r').readlines()
    dateTimeStamp = []
    dB = []
    for line in tmclines:
        tokens = line.split()
        if (len(tokens) == 0):
            print "len(tokens) = %d" % (len(tokens))
        dateTimeStamp.append(dateStringToMJDSec(tokens[0],verbose=False))
        dB.append([float(x) for x in tokens[1:]])
    return(np.array(dateTimeStamp), np.array(np.transpose(dB)))

def readIFSwitchAttenuatorSettings(tmcfile_ifswitch, pol=0, sideband=1):
    """
    Parses an IF switch attenuator text file read from the TMCDB and returns
    an array of timestamps (MJDsec) and an array of attenuator 
    values (in dB) for the specified polarization and sideband.
    -Todd Hunter
    """
    tmcfile = tmcfile_ifswitch[sideband]
    loc = tmcfile.find('CHANNEL')+7
    if (loc > 0):
        tmcfile = tmcfile[:loc] + str(pol) + str(sideband) + tmcfile[loc+2:]
        print "Using file = ", tmcfile
    if (os.path.exists(tmcfile) == False):
        print "Could not open IF Switch TMC database file"
        return
    tmclines = open(tmcfile,'r').readlines()
    dateTimeStamp = []
    dB = []
    for line in tmclines:
        tokens = line.split()
        dateTimeStamp.append(dateStringToMJDSec(tokens[0],verbose=False))
        dB.append(float(tokens[1]))
    return(np.array(dateTimeStamp), np.array(dB))

def createTsysTable(vis, caltable='', partype='Float', caltype='B TSYS', 
                    singlechan=False, overwrite=True):
    """
    Creates a new blank Tsys table for a measurement set.
    caltable: if '', then append '.tsys' to ms, if that exists, append '.tsys_new'
    -Todd Hunter
    """
    mycb = createCasaTool(cbtool)
    mycb.open(vis, addcorr=False, addmodel=False) # default of addcorr=True which adds model and corrected columns
    if caltable == '':
        caltable = vis + '.tsys'
        if os.path.exists(caltable):
            caltable = vis + '.tsys_new_' + casadef.casa_version
    if os.path.exists(caltable) and overwrite:
        print "Removing existing table: ", caltable
        shutil.rmtree(caltable)
    print "Creating ", caltable
    mycb.createcaltable(caltable, partype=partype, caltype=caltype, singlechan=singlechan)
    mycb.close()
    return caltable

def compareTsysSpectralWindowTableChanFreqsWithMS(caltable, spw, vis=None):
    """
    Checks the agreement between the spectral window frequencies in a caltable
    with its parent measurement set.
    """
    if vis is None:
        vis = getMeasurementSetFromCaltable(caltable)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    visfreqs = mymsmd.chanfreqs(spw)
    mymsmd.close()
    calfreqs = getChanFreqFromCaltable(caltable, spw) * 1e9
    difference = np.mean(visfreqs) - np.mean(calfreqs)
    chanwidth = visfreqs[1] - visfreqs[0]
    if abs(difference) < 0.01*chanwidth:
        print "difference = %.0f Hz (less than 1% of channel width, which is %.4f Hz)" % (difference,chanwidth)
    else:
        print "difference = %.0f Hz = %.3f channel width, which is %.4f Hz" % (difference, abs(difference/chanwidth),chanwidth)

class Atmcal:
    """
    This class examines the CAL_ATMOSPHERE scans in a measurement set and
    determines the time ranges associated with the sky, ambient and hot load
    in each scan based on the data itself, and checks it for sanity against
    the subscan order specified in the STATE table.  It also has methods to
    independently compute and/or plot the Trx and Tsys, with an option to
    overlay the TelCal result.  It can also compute and apply the FDM 
    quantization correction.  For the Trec2 and Tsys solving code, I have 
    endeavored to use the same function names and variables as the original 
    Telcal C-code.
    The source code for Telcal can be found on machines at the OSF at $ACSROOT, e.g.
    red-osf.osf.alma.cl:/alma/ACS-current/ACSSW/Sources/Engines/src/AtmosphereScan.cpp
    -Todd Hunter
    """
    def __init__(self,vis,verbose=False,showSummary=False,readAttenuatorSettings=False,
                 decimalDigits=2, includeDate=False, restoreBackup=False, outpath='./',
                 includeSQLD=False, maxscans=0, warnIfNoLoadTemperatures=True, mymsmd='',
                 loadLOs=False, distinguishLoads=True):
        """
        loadLOs: only needed for generateHighResTsysTable
        """
        self.vis = vis[:]
        self.visBasename = os.path.basename(vis)
        # Remove the following line once everything works well in fixSyscalTable.
        if (os.path.exists(self.vis+'/SYSCAL.backup') and restoreBackup):
            print "Copying the SYSCAL backup  into place"
            os.system('rm -rf %s' % (self.vis+'/SYSCAL'))
            os.system('rsync -vau %s %s' % (self.vis+'/SYSCAL.backup/', self.vis+'/SYSCAL'))
        self.correctedColumnPresent = 'CORRECTED_DATA' in dataColumns(vis)
        startTime = timeUtilities.time()
        if (outpath == ''): outpath = './'
        if (outpath[-1] != '/'): outpath += '/'
        self.sidebands = [1,2]
        self.polarizations = [0,1]  # assume we always want to operate on X and Y
        self.verbose = verbose
        if (os.path.exists(vis) == False):
            print "Cannot find this measurement set."
            return
        if (os.path.exists(vis+'/table.dat') == False):
            print "No table.dat.  This does not appear to be an ms."
            return
        if (verbose): print "Dataset begins at %s." % (mjdsecToUT(getObservationStart(self.vis)))
        print "Analyzing the Atmospheric Cal scans and various metadata may take a minute..."
        if (verbose): print "Reading the STATE table"
        self.readStateTable()
        if (verbose): print "Finding the cal scans"
        self.needToCloseMymsmd = False
        if mymsmd == '':
            #print "Opening msmd..."
            self.mymsmd = createCasaTool(msmdtool)
            self.mymsmd.open(vis)
            self.needToCloseMymsmd = True
        else:
            self.mymsmd = mymsmd
        self.findCalScans(includeDate,includeSQLD,maxscans,verbose=verbose,
                          warnIfNoLoadTemperatures=warnIfNoLoadTemperatures)
        self.calscandict = buildCalDataIdDictionary(self.vis, mymsmd=self.mymsmd)
        if distinguishLoads:
            if (verbose): print "Distinguishing the load data"
            self.distinguishLoadData(verbose)
        if (verbose): print "Finding scans in the SYSCAL table"
        self.findSyscalScans(maxscans, verbose=verbose)
        if (showSummary): self.printCalScans(decimalDigits, includeDate)
        self.scienceSpws = getScienceSpws(self.vis, mymsmd=self.mymsmd)
        if len(self.scienceSpws) == 0:
            self.scienceSpws = getScienceSpws(self.vis, mymsmd=self.mymsmd, intent='CALIBRATE_FLUX#ON_SOURCE')
            if len(self.scienceSpws) == 0:
                self.scienceSpws = getScienceSpws(self.vis, mymsmd=self.mymsmd, intent='CALIBRATE_AMPLI#ON_SOURCE')
        self.hanningSmoothed = {}
        self.onlineChannelAveraging = {}
        scienceSpwsList = [int(i) for i in self.scienceSpws.split(',')]
        # include science and Tsys windows since they will differ for BLC and old ACA datasets
        for spw in np.unique(scienceSpwsList + self.spws):  
            spw = int(spw)
            self.onlineChannelAveraging[spw] = onlineChannelAveraging(self.vis, spw, self.mymsmd)
            if self.onlineChannelAveraging[spw] == 1:
                self.hanningSmoothed[spw] = True
            else:
                self.hanningSmoothed[spw] = False
        self.initializeAttenuatorDictionaries()
        self.radec = {}
        if (readAttenuatorSettings):
            if (verbose): print "Reading the attenuator settings"
            if (self.readAttenuatorSettings(outpath=outpath) == False):
                print "Stopping"
                return
        else:
            if (verbose): print "Not reading the attenuator settings (to do this: set readAttenuatorSettings=True)"
        if loadLOs:
            self.lo1s = interpretLOs(self.vis, parentms=None, mymsmd=self.mymsmd)
        else:
            self.lo1s = None
        stopTime = timeUtilities.time()
        self.xxyy = {} 
        for spw in self.spws:
            # fills in self.xxyy dictionary: will be [9,12] for dual-linear
                                          # or [9,10,11,12] for full-pol linear
            self.findPolarizationProducts(spw)  
                                               
        print "Atmcal class initialization completed in %.0f seconds" % (stopTime-startTime)

    # The following six functions are from R. Amestica (Nov 2013)
    def afun(self, sigma1, sigma2):
        """
        Compute 'a' parameter as defined in memo 583, section 7.3. Input values must be 
        3 bits sigma levels.
        """
        s1 = 0.
        s2 = 0.
        for i in range(1, 4):
            s1 += exp(- (i ** 2) / (2 * double(sigma1) ** 2))
            s2 += exp(- (i ** 2) / (2 * double(sigma2) ** 2))
        return (pi * sigma1 * sigma2) / (2 * (1. + 2 * s1) * (1. + 2 * s2))
    
    def bfun(self, sigma1, sigma2):
        """
        Compute 'b' parameter as defined in memo 583, section 7.3. Input values must be 3 bits sigma levels.
        """ 
        return self.afun(sigma1, sigma2) * self.R0(sqrt(sigma1 * sigma2), 8) - sigma1 * sigma2
    
    def STAR2(self, x):
        """
        Just a helper artifact.
        """
        return x * x
    
    def sign(self, a, b):
        """
        Just a helper artifact.
        """
        if b < 0.0:
            return -fabs(a)
        return fabs(a)
    
    def R0(self, sigma, n):
        """
        Equation 4 in memo 583.
        """
    
        ret = 0.
        for k in range(1, n / 2 - 1 + 1):
            ret += k * erf(k / (sqrt(2) * sigma))
        return (n - 1) ** 2 - 8. * ret 
    
    def sigma(self, zerolag, n):
        """
        Inverse of equation 4 in memo 583.
        """
        x = 0.0
        SQRT_05_PI = sqrt(2.0 / pi)
        M_SQRT2 = sqrt(2.0)
        if n % 2 == 0:
            x = 1.
        itmax = 30
        tol = 1.0e-8
        for i in range(itmax):
            f = zerolag
            fp = 0.0
            if n % 2 == 1:
                for k in range((n - 1) / 2):
                    kd = double(k + 1)
                    f = f - (2.0 * kd - 1.0) * erfc((2.0 * kd - 1.0) * x / M_SQRT2)
                    fp = fp + SQRT_05_PI * self.STAR2(2.0 * kd - 1.0) * exp(-0.5 * self.STAR2((2.0 * kd - 1.0) * x));
            else:
                f = f - double(1)
                for k in range((n - 1) / 2):
                    kd = double(k + 1)
                    f = f - 8 * kd * erfc(kd * x / M_SQRT2);
                    fp = fp + 8.0 * self.STAR2(kd) * SQRT_05_PI * exp(-0.5 * self.STAR2(kd * x));
            deltax = -f / fp
            deltax = self.sign(1.0, deltax) * fmin(0.5, fabs(deltax));
            x += deltax;
            if n % 2 == 1:
                x = fmax(0, x);
            if fabs(deltax / x) < tol:
                break
        return 1. / x;
    # The preceeding six functions are from R. Amestica (Nov 2013)

    def correctVisibilities(self, fdmscan, tdmscan=None, tdm=None, dataFraction=[0.0,1.0], 
                            ignoreFlags=False, useGetSpectrum=True):
        """
        Corrects cross-correlation FDM data for quantization on the basis of TDM 
        auto-correlation on the two antennas.
        fdmscan: the scan number to correct in the current Atmcal instance
        tdmscan: the scan number to use as the total power (default=same as fdmscan, but
                     in different measurement set)
        tdm: the name of the measurement set to get the TDM data from, or the Atmcal
               instance created from this different measurement set
        dataFraction: the portion of the subscan to use
        ignoreFlags: set to True to ignore the flag column
        useGetSpectrum: set to False to use Visibility class to get TDM data
        Note: in the future, I should pass self.mymsmd to Visibility() to save time
        """
        warnings.simplefilter("ignore", np.ComplexWarning)
        if (tdm == None):
            tdm = self  # the TDM data are in the same MS as the FDM data
        else:
            # the TDM data are in a different MS from the FDM data
            if (type(tdm) == str):
                # the name of the TDM measurement set was passed as 'tdm'
                tdm = Atmcal(tdm)
        tdmv = Visibility(tdm.vis)
        fdmv = Visibility(self.vis)
        fdmv.autoSubtableQuery = False
        if (tdmscan == None): tdmscan = fdmscan
        print "tdm.spwsforscan_nonchanavg = ", tdm.spwsforscan_nonchanavg
        if (tdmscan not in tdm.spwsforscan_nonchanavg):
            print "tdmscan=%d is not an Atmcal scan" % (tdmscan)
            return
        tdmspws = tdm.spwsforscan_nonchanavg[tdmscan]
        if (fdmscan not in self.spwsforallscans_nonchanavg):
            print "fdmscan=%d is not an Atmcal scan" % (fdmscan)
        fdmspws = self.spwsforallscans_nonchanavg[fdmscan]
        nBaselines = len(self.antennas)*(len(self.antennas)-1)/2
        for spw in range(len(tdmspws)):
            baseline = 0
            for ant1 in self.antennas[:-1]:
                for ant2 in range(ant1+1, len(self.antennas)):
                    baseline += 1
                    print "Applying TDM spw %d to FDM spw %d for baseline %02d-%02d (%d/%d)" % (tdmspws[spw], fdmspws[spw], ant1, ant2, baseline, nBaselines)
                    tdm1spectrum = []
                    for pol in range(2):
                        if (useGetSpectrum):
                            tdm1spectrum.append(tdm.getSpectrum(tdmscan,tdmspws[spw],pol,'sky',ant1,dataFraction,ignoreFlags=ignoreFlags))
                        else:
                            tdmv.setAntennaPair(ant1,ant1)
                            tdmv.setSpwID(tdmspws[spw])
                            tdmv.setScan(tdmscan)
                            tdm1spectrum.append(np.mean(np.abs(tdmv.specData)[pol],axis=1))
                    tdm2spectrum = []
                    for pol in range(2):
                        if (useGetSpectrum):
                            tdm2spectrum.append(tdm.getSpectrum(tdmscan,tdmspws[spw],pol,'sky',ant2,dataFraction,ignoreFlags=ignoreFlags))
                        else:
                            tdmv.setAntennaPair(ant2,ant2)
                            tdm2spectrum.append(np.mean(np.abs(tdmv.specData)[pol],axis=1))
                    fdmv.setAntennaPair(ant1,ant2)
                    fdmv.setSpwID(fdmspws[spw])
                    fdmv.setScan(fdmscan)
                    fdmv.makeSubtableQuery()
                    fdmv.makeSubtableForWriting()
                    fdmv.getSpectralData()
                    fdmSpectra = fdmv.specData

                    # need to get individual integrations, not the average, so cannot use getSpectrum
                    nSpectra = len(fdmSpectra[0][0])
#                    print "Got %d spectra, shape = %s" % (nSpectra, np.shape(fdmv.specData))
                    npol = len(fdmv.specData)
                    for i in np.arange(nSpectra):
                        fdmSpectra = []
                        for pol in range(npol):
                            fdmSpectra.append([])
                            fdmSpectrum = fdmv.specData[pol][:][i]
                            fdmSpectra[pol] = self.applyCorrectionToFDMSpectrum(fdmSpectrum, tdm1spectrum[pol],
                                                                                tdm2spectrum[pol])
                        fdmv.putSpectralData(fdmSpectra, i)
        fdmv.subtable.close()
        fdmv.mytb.close() # write out the changes

    def applyCorrectionToFDMSpectrum(self, spectrum, TDM_X, TDM_Y, 
                                     useZeroLagsBinaryAttachment=False):
        """
        spectrum: the FDM spectrum to be corrected
        TDM_X: TDM spectrum for antenna X (can also be a single-valued SQLD "spectrum")
        TDM_Y: TDM spectrum for antenna Y (can also be a single-valued SQLD "spectrum")
        """
#        print "applyCorrectionToFDMSpectrum(): np.shape(spectrum) = ", np.shape(spectrum)
        if (useZeroLagsBinaryAttachment):
            print "Not yet implemented"
            sigma4_X = self.sigma(R4_X0, 4)
            sigma4_Y = self.sigma(R4_Y0, 4)
        else:
            sigma4_X = sqrt(np.mean(TDM_X))
            sigma4_Y = sqrt(np.mean(TDM_Y))
        sigma8_X = 2*sigma4_X
        sigma8_Y = 2*sigma4_Y
        a = self.afun(sigma8_X, sigma8_Y)
        b = self.bfun(sigma8_X, sigma8_Y)
        print "corrected=spectrum*a - b  where  a=%f, b=%f" % (a,b)
        if (type(spectrum[0]) == np.complex128):
            correctedSpectrum = []
            for chan in spectrum:
                correctedSpectrum.append(np.complex(np.real(spectrum[chan])*a - b, np.imag(spectrum[chan])))
        else:
            correctedSpectrum = spectrum*a - b
        return(correctedSpectrum)
        
    def initializeAttenuatorDictionaries(self):
        self.IFProc = {}
        self.IFSwitch = {}
        self.IFProcMin = {}
        self.IFProcMax = {}
        self.IFSwitchMin = {}
        self.IFSwitchMax = {}
        for a in self.antennas:
            self.IFProc[a] = {}
            self.IFSwitch[a] = {}
            self.IFProcMin[a] = {}
            self.IFProcMax[a] = {}
            self.IFSwitchMin[a] = {}
            self.IFSwitchMax[a] = {}
            for pol in self.polarizations:
                self.IFProc[a][pol] = None
                self.IFSwitch[a][pol] = {}
                self.IFSwitchMin[a][pol] = {}
                self.IFSwitchMax[a][pol] = {}
                for sb in self.sidebands:
                    self.IFSwitch[a][pol][sb] = None

    def fixSyscalTable(self, scan='', dataFraction=[0.0,1.0], ignoreFlags=False, spws='', clear=False):
        """
        Copies the existing SYSCAL table and appends entries calculated offline in casa
        for the specified scan.
        scan: which scan number(s) to process (default='' which means all)
              (integer, integer list, or comma-delimited string)
        dataFraction: which part of each load scan to use in the calculations
        ignoreFlags: if True, then ignore flags on the autocorrelation data
        spws: which spw(s) to process (default='' which means all)
        clear: if True, then remove all rows before appending new rows
               Select this option if you are trying to regenerate the table.
        """
        if (scan == None or scan == '' or scan == []):
            scan = self.scans
        else:
            if (self.unrecognizedScan(scan)): return
        startTime = timeUtilities.time()
        originalName = self.vis+'/SYSCAL.old'
        os.system('cp -r %s %s' % (self.vis+'/SYSCAL', originalName))
        calscandict = buildCalDataIdDictionary(self.vis)
        mytb = createCasaTool(tbtool)
        mytb.open(self.vis+'/SYSCAL', nomodify=False)
        nrows = len(mytb.getcol('ANTENNA_ID'))
        originalRows = nrows
        if (spws is not None and spws != '' and spws != []):
            if (type(spws) != list and type(spws) != np.ndarray):
                if (type(spws) == str):
                    spws = [int(i) for i in spws.split(',')]
                else:
                    spws = list([spws])
            restrictSpws = True
        else:
            restrictSpws = False
                    
        if (type(scan) != list and type(scan) != np.ndarray):
            if (type(scan) == str):
                scan = [int(i) for i in scan.split(',')]
            else:
                scan = list([scan])
        # Copy the list of scans, so that we can re-use the existing variable name as a scalar
        myscans = scan[:]
        if (clear):
            print "Clearing out all rows"
            mytb.removerows(range(nrows))
            nrows = 0
        for iscan,scan in enumerate(myscans):
          for antenna in self.antennas:
            if (not restrictSpws):
                spws = self.spwsforscan_nonchanavg[scan]
            for spw in spws:
                if (restrictSpws):
                    if (spw not in self.spwsforscan_nonchanavg[scan]): continue
                print "-------- Working on scan=%d (%d of %d)  antenna=%s (%d/%d), spw=%d (%d/%d) ----------" % (scan, iscan+1, len(myscans), self.antennaNames[antenna],antenna+1,len(self.antennas),spw,list(spws).index(spw)+1,len(spws))
                mytb.addrows(1)
                mytb.putcell('ANTENNA_ID',nrows,antenna)
                mytb.putcell('SPECTRAL_WINDOW_ID',nrows,spw)
                mytb.putcell('FEED_ID',nrows,0)
                mytb.putcell('TIME',nrows,self.meantime[scan]+0.5*self.interval[scan])
                mytb.putcell('INTERVAL',nrows,self.interval[scan])
                result_pol0 = self.computeTsys(scan,antenna,0,spw,altscan='auto',
                                               dataFraction=dataFraction,
                                               ignoreFlags=ignoreFlags,calscandict=calscandict)
                result_pol1 = self.computeTsys(scan,antenna,1,spw,altscan='auto',
                                               dataFraction=dataFraction,
                                               ignoreFlags=ignoreFlags,calscandict=calscandict)
                if (result_pol0 is not None and result_pol1 is not None):
                    tsys0, freqHz, trx0, tsky0, tcal0 = result_pol0
                    tsys1, freqHz, trx1, tsky1, tcal1 = result_pol1
                    mytb.putcell('TCAL_SPECTRUM',nrows,np.array([tcal0,tcal1]))
                    mytb.putcell('TRX_SPECTRUM',nrows,np.array([trx0,trx1]))
                    mytb.putcell('TSKY_SPECTRUM',nrows,np.array([tsky0,tsky1]))
                    mytb.putcell('TSYS_SPECTRUM',nrows,np.array([tsys0,tsys1]))
#                    flags = np.array([np.array(tsys0)*0, np.array(tsys1)*0])
#                    idx = np.where(np.array([tsys0,tsys1]) <= 0)
#                    flags[idx] = 1
#                    print "Flagged %d/%d channels for negative Tsys" % (len(idx), len(tsys0))
#                    mytb.putcell('FLAG', nrows, flags)
                else:
                    print "Stopping due to missing data.  Try removing the online flags."
                    mytb.close()
                    return
                mytb.putcell('TANT_SPECTRUM',nrows,np.array([],np.float))
                mytb.putcell('TANT_TSYS_SPECTRUM',nrows,np.array([],np.float))
                # The following values are what all normal SYSCAL tables contain.
                mytb.putcell('TCAL_FLAG',nrows,1)
                mytb.putcell('TRX_FLAG',nrows,1)
                mytb.putcell('TSKY_FLAG',nrows,1)
                mytb.putcell('TSYS_FLAG',nrows,1)
                mytb.putcell('TANT_FLAG',nrows,0)
                mytb.putcell('TANT_TSYS_FLAG',nrows,0)
                nrows += 1
        mytb.addreadmeline('Table has been modified by au.Atmcal().fixSyscalTable')
        mytb.close()
        print "Added %d rows.  The original table was moved to %s" % (nrows-originalRows,os.path.basename(originalName))
        stopTime = timeUtilities.time()
        print "Task completed in %.0f seconds" % (stopTime-startTime)
        
    def nearestCalScan(self, mjdsec):
        mindiff=1e38
        for scan in self.scans:
            mydiff = abs(self.meantime[scan]-mjdsec)
            if (mydiff < mindiff):
                mindiff = mydiff
                myscan = scan
        return myscan
    
    def findSyscalScans(self, maxscans=0, verbose=False):
        mytb = createCasaTool(tbtool)
        mytb.open(self.vis+'/SYSCAL')
        times = mytb.getcol('TIME')
        interval = mytb.getcol('INTERVAL')
        times -= 0.5*interval
#        print "times-0.5*interval: min=%f=%s max=%f=%s" % (np.min(times), mjdsecToUTHMS(np.min(times)), np.max(times), mjdsecToUTHMS(np.max(times)))
#        print "interval: min=%f max=%f" % (np.min(interval), np.max(interval))
        mytb.close()
        times = np.unique(times)
        scans = []
        timestamps = []
        for t in times:
            scan = self.nearestCalScan(t)
            if scan not in scans:
                scans.append(scan)
                timestamps.append(mjdsecToUTHMS(t))
        print "scans = %s" % (str(scans))
        print "times = %s" % (str(timestamps))
        self.syscalScans = scans
        if (maxscans > 0):
            self.syscalScans = scans[:maxscans]
        missingScans = np.setdiff1d(self.scans, scans)
        if (len(missingScans) > 0):
            print "There are %d atmcal scans missing from the SYSCAL table: %s" % (len(missingScans),str(missingScans))
            spwString = ''
            for scan in missingScans:
                spwString += str(np.setdiff1d(np.setdiff1d(self.mymsmd.spwsforscan(scan),self.mymsmd.wvrspws()),
                                              self.mymsmd.chanavgspws()))
            print "They correspond to spws: %s" % (spwString)
        
    def getScans(self):
        return(self.scans)
            
    def distinguishLoadData(self, verbose=False):
        myms = createCasaTool(mstool)
        myms.open(self.vis)
        # Just use the first scan and first spw and first antenna
        antenna = 0
        datadescid = self.datadescids[self.spws[0]]
        if (verbose):
            print "Using datadescid=%d for spw=%d" % (datadescid, self.spws[0])
            print "ms.selectinit(datadescid=%d)" % (datadescid)
        myms.selectinit(datadescid=datadescid)
        scan = sorted(self.timestamps.keys())[0]
        mytimestamps = self.timestamps[scan][self.loadsubscans[0]]
        if verbose:
            print "self.loadsubscans[0] = ", self.loadsubscans[0]
            print "Timerange = %s" % (mjdsecToTimerange(self.timestamps[scan][self.loadsubscans[0]]))
            print "Timerange = ", self.timestamps[scan][self.loadsubscans[0]]
        myms.select({'time':self.timestamps[scan][self.loadsubscans[0]], 'antenna1':antenna, 'antenna2':antenna})
        data0 = myms.getdata(['amplitude'])['amplitude']
        print "data0[0][0] = ", data0[0][0]

        myms.selectinit(reset=True)  # required for CASA 5.3, (see CAS-11088)
        myms.selectinit(datadescid=datadescid)
        mytimestamps = self.timestamps[scan][self.loadsubscans[1]]
        if verbose:
            print "self.loadsubscans[1] = ", self.loadsubscans[1]
            print "Timerange = %s" % (mjdsecToTimerange(mytimestamps))
            print "Timerange = ", mytimestamps
            print "Calling myms.select({'time': %s, 'antenna1': %d, 'antenna2':%d})" % (mytimestamps,antenna,antenna)
        myms.select({'time': mytimestamps, 'antenna1':antenna, 'antenna2':antenna})
        data1 = myms.getdata(['amplitude'])['amplitude']
        print "data1[0][0] = ", data1[0][0]
        Yfactor = []
        
        for pol in range(len(data0)):
            if (np.median(data0[pol]) < np.median(data1[pol])):
                Yfactor.append(np.median(data1[pol])/np.median(data0[pol]))
                self.target[self.loadsubscans[1]] = 'hot'
                self.target[self.loadsubscans[0]] = 'amb'
            else:
                Yfactor.append(np.median(data0[pol])/np.median(data1[pol]))
                self.target[self.loadsubscans[0]] = 'hot'
                self.target[self.loadsubscans[1]] = 'amb'
        self.targetInverse[self.target[self.loadsubscans[0]]] = self.loadsubscans[0]
        self.targetInverse[self.target[self.loadsubscans[1]]] = self.loadsubscans[1]
        if (verbose):
            print "Information from scan %d:" % (scan)
            print "Y-factors for pol %s: %s" % (range(len(data0)), str(Yfactor))
        self.yfactor = {}
        self.yfactor[scan] = Yfactor  # only holds the first scan, for now
        if (len(Yfactor) > 1):
            if ((Yfactor[0] < 1 and Yfactor[1] > 1) or (Yfactor[0] > 1 and Yfactor[1] < 1)):
                print "The two polarizations do not agree on the order of the subscans (ambient vs. hot load)"
            else:
                loadlist = ''
                durationlist = ''
                totalDuration = 0
                for t in range(len(self.sub_scan_unique)):
                    if (t>0):
                        loadlist += ','
                        durationlist += ','
                    loadlist += self.target[self.sub_scan_unique[t]]
#                    print "self.timestamps = %s" % (self.timestamps.keys())
#                    print "self.timestamps[scan=%d] = %s" % (scan, self.timestamps[scan].keys())
#                    print "self.sub_scan_unique = %s" % (self.sub_scan_unique)
#                    print "self.sub_scan_unique[t=%d] = %s" % (t,self.sub_scan_unique[t])
                    myduration = self.timestamps[scan][self.sub_scan_unique[t]][1] - \
                                 self.timestamps[scan][self.sub_scan_unique[t]][0] + \
                                 self.integrationTime[scan]  # because need to add 1/2 integration time on each end
                    durationlist += '%.2f' % (myduration)
                    totalDuration += myduration
                if (verbose):
                    print "Standard order of the load subscans is confirmed (%s)" % (loadlist)
                    print "Subscan durations: %ss; total=%.2fs; integration=%.3fs" % (durationlist,totalDuration,self.integrationTime[scan])
        myms.close()
        
    def readStateTable(self):
        mytb = createCasaTool(tbtool)
        mytb.open('%s/STATE' % self.vis)
        sub_scan = mytb.getcol('SUB_SCAN')
        obs_mode = mytb.getcol('OBS_MODE')
        sig = mytb.getcol('SIG')
        mytb.close()
        calatm_rows = []
        self.stateID_off_source = []
        for row in range(len(obs_mode)):
            om = obs_mode[row]
            if (om.find('CALIBRATE_ATMOSPHERE') >= 0):
                calatm_rows.append(row)
                if (om.find('OFF_SOURCE') >= 0 and sig[row]==0):
                    self.stateID_off_source.append(row)
        self.sub_scan = sub_scan[calatm_rows]
        self.sub_scan_unique = np.unique(self.sub_scan)
        self.obs_mode = obs_mode[calatm_rows]
        self.loadsubscans = []
        self.refsubscan = None
        self.ambsubscan = None
        self.hotsubscan = None
        for i in range(len(self.obs_mode)):
            if (self.obs_mode[i].find('OFF_SOURCE')>=0):
                self.skysubscan = self.sub_scan[i]
            elif (self.obs_mode[i].find('REFERENCE')>=0):
                self.refsubscan = self.sub_scan[i]
            elif (self.obs_mode[i].find('HOT')>=0):
                self.loadsubscans.append(self.sub_scan[i])
                self.hotsubscan = self.sub_scan[i]
            elif (self.obs_mode[i].find('AMBIENT')>=0):
                self.loadsubscans.append(self.sub_scan[i])
                self.ambsubscan = self.sub_scan[i]
            else:
                self.loadsubscans.append(self.sub_scan[i])
        self.loadsubscans = np.unique(self.loadsubscans)
        self.nsubscans = len(self.sub_scan_unique)
        self.target = dict.fromkeys(self.sub_scan_unique)
        self.targetInverse = {}
        for i in self.sub_scan_unique:
            if (i == self.hotsubscan):
                self.target[i] = 'hot'
            elif (i == self.ambsubscan):
                self.target[i] = 'amb'
            elif (i in self.loadsubscans):
                self.target[i] = 'load'
            elif (i==self.refsubscan):
                self.target[i] = 'ref'
                self.targetInverse['ref'] = i
            else:
                self.target[i] = 'sky'
                self.targetInverse['sky'] = i

    def setLoadTemperatures(self, ambient=None, hot=None):
        """
        Set a new value of ambient and hot load temperatures for all scans on all antennas.
        """
        if (ambient == None and hot == None):
            print "No changes requested."
            return
        for antenna in self.loadTemperatures.keys():
            for scan in self.loadTemperatures[antenna].keys():
                if (ambient is not None):
                    self.loadTemperatures[antenna][scan]['amb'] = ambient
                if (hot is not None):
                    self.loadTemperatures[antenna][scan]['hot'] = hot
    
    def deleteScan(self, scan):
        for i in [self.timestamps, self.timestampsString, self.timerange, self.timerangeString, self.meantime,
                  self.meantimestring, self.spwsforscan, self.spwsforscan_nonchanavg]:
            if scan in i: del i[scan]
        self.scans = list(self.scans)
        self.scans.remove(scan)
        self.scans = np.array(self.scans)
        
    def findCalScans(self, includeDate, includeSQLD=False, maxscans=0, verbose=False, 
                     warnIfNoLoadTemperatures=True):
        self.loadTemperatures = getLoadTemperatures(self.vis, mymsmd=self.mymsmd, warnIfNoLoadTemperatures=warnIfNoLoadTemperatures)
        self.antennas = range(self.mymsmd.nantennas())
        self.antennaNames = np.array(self.mymsmd.antennanames(self.antennas))
        self.basebands = getBasebands(self.mymsmd)
        self.observationStart = getObservationStart(self.vis)
        self.observationStop = np.max(self.mymsmd.timesforscan(self.mymsmd.scannumbers()[-1]))
        self.telescopeName = self.mymsmd.observatorynames()[0]
        self.yyyymmdd = mjdSecondsToMJDandUT(self.mymsmd.timesforscans(1)[0])[1].split()[0]
        self.intentsforscan = {}
        for scan in self.mymsmd.scannumbers():
            self.intentsforscan[scan] = self.mymsmd.intentsforscan(scan)
        self.intents = self.mymsmd.intents()
        calIntents = ['CALIBRATE_ATMOSPHERE#ON_SOURCE', 'CALIBRATE_ATMOSPHERE#OFF_SOURCE',
                      'CALIBRATE_ATMOSPHERE#HOT']
        self.scans = []
        for calIntent in calIntents:
            if (calIntent in self.intents):
                self.scans = self.mymsmd.scansforintent(calIntent)
                break
        if (len(self.scans) == 0):
            print "No atm cal intents found."
            return
        if (len(self.scans) == self.scans[-1]):
            self.attenuatorTest = True
        else:
            self.attenuatorTest = False
        self.spws = spwsforintent_nonwvr_nonchanavg(self.mymsmd, calIntent, includeSQLD)
        if verbose: print "Found spws: ", self.spws
        self.nchan = self.mymsmd.nchan(self.spws[0]) # assume all are the same
        self.datadescids = {}
        self.meanfreq = {}
        self.sidebandsforspw = {}
        self.chanfreqs = {}
        for spw in self.spws:
            self.datadescids[spw]=spw  # assume this is true for now, but may not be someday
            self.meanfreq[spw] = self.mymsmd.meanfreq(spw)
            self.chanfreqs[spw] = self.mymsmd.chanfreqs(spw)
            self.sidebandsforspw[spw] = sidebandToNetSideband(self.mymsmd.sideband(spw))
        self.timestamps = {}
        self.timestampsString = {}
        self.timerangeString = {}
        self.timerange = {}
        self.meantime = {}
        self.interval = {}
        self.meantimestring = {}
        self.integrationTime = {}
        self.spwsforscan = {}
        self.spwsforscan_nonchanavg = {}
        self.spwsforallscans_nonchanavg = spwsForScan(self.mymsmd)
        if (maxscans > 0):
            self.scans = self.scans[:maxscans]
        for scan in self.scans:
            if False:
                t = self.mymsmd.timesforscan(scan)
                # Round to nearest tenth of a second, to avoid long processing times for 0.016-sec SQLD data 
                t = np.unique(np.round(t,1)) # July 31, 2015
            else:
                t = None # June 6, 2017
            result = computeDurationOfScan(scan, t, vis=self.vis, returnSubscanTimes=True, 
                                           verbose=self.verbose,includeDate=includeDate, mymsmd=self.mymsmd)
            if (result[1] != len(self.sub_scan_unique)):
                print "Found %d subscans in scan %d instead of %d!" % (result[1], scan, len(self.sub_scan_unique))
                line = '     '
                for mysubscan in range(result[1]):
                    line += result[3][mysubscan+1] + ', '
                print line
            else:
                if verbose: print "findCalScans(): Working on scan %d" % (scan)
            self.timestamps[scan] = result[2]
            self.timestampsString[scan] = result[3]
            self.timerange[scan] = [result[2][1][0], result[2][len(result[2])][1]]
            self.timerangeString[scan] = [mjdsecToUTHMS(result[2][1][0]), mjdsecToUTHMS(result[2][len(result[2])][1])]
            self.meantime[scan] = np.mean(self.timerange[scan])
            self.meantimestring[scan] = mjdsecToUTHMS(self.meantime[scan])
            self.spwsforscan[scan] = np.setdiff1d(self.mymsmd.spwsforscan(scan),self.mymsmd.wvrspws())  # get rid of WVR spws
            self.spwsforscan_nonchanavg[scan] = np.setdiff1d(self.spwsforscan[scan],self.mymsmd.chanavgspws())
            if verbose: 
                print "chanavgspws = ", self.mymsmd.chanavgspws()
                print "wvrspws = ", self.mymsmd.wvrspws()
                print "self.spwsforscan[%d] = " % (scan), self.spwsforscan[scan]
                print "self.spwsforscan_nonchanavg[%d] = " % (scan), self.spwsforscan_nonchanavg[scan]
            if (len(self.spwsforscan_nonchanavg[scan]) == 0):
                print "Removing scan %d because it appears to be missing data (PRTSPR-21604)." % scan
                self.deleteScan(scan)
                continue
            if verbose: 
                print "Running exposuretime with spwid=", self.spwsforscan_nonchanavg[scan][0]
                startTime = timeUtilities.time()
            exposureTimeDict = self.mymsmd.exposuretime(scan=scan, spwid=self.spwsforscan_nonchanavg[scan][0])
            if verbose: 
                stopTime = timeUtilities.time()
                print "done after %f sec" % (stopTime-startTime)
            self.integrationTime[scan] = exposureTimeDict['value']
#            This was the original, slower method
#            self.integrationTime[scan] = getIntegrationTime(self.vis, scan=scan, intent='CALIBRATE_ATMOSPHERE#ON_SOURCE', verbose=False)
        for scan in self.scans:
            if (scan < self.scans[-1]):
                nextscan = self.scans[list(self.scans).index(scan)+1]
                self.interval[scan] = self.meantime[nextscan]-self.meantime[scan]
            else:
                self.interval[scan] = 3600

    def getSubscanTimes(self, scan, stringFormat=False, decimalDigits=2, includeDate=False):
        # currently not used
        timestamps = {}
        timestamp = self.timestamps[scan]
        for subscan in timestamp.keys():
            if (stringFormat):
                timestamps[self.target[subscan]] = mjdsecToTimerange(timestamp[subscan][0],
                                                                     timestamp[subscan][1],
                                                                     decimalDigits,includeDate)
            else:
                timestamps[self.target[subscan]] = timestamp[subscan]
        return(timestamps)
    
    def printCalScans(self, decimalDigits=1, includeDate=False):
        for scan in sorted(self.timestamps.keys()):
            timestamp = self.timestamps[scan]
            for subscan in timestamp.keys():
                print '%2d: %d: %4s %s [%.2f,%.2f]' % (scan, subscan, self.target[subscan],
                                              mjdsecToTimerange(timestamp[subscan][0],
                                                                timestamp[subscan][1],
                                                                decimalDigits,
                                                                includeDate),
                                              timestamp[subscan][0], timestamp[subscan][1]
                                              )
            print ""

    def findPolarizationProducts(self, spw):
        """
        Translates the CORR_TYPE value from the POLARIZATION table that
        corresponds to the POLARIZATION_ID in the DATA_DESCRIPTION table for a specified spw.
        Returns: a list of 1, 2 or 4 values,  selected from 9,10,11,12 (for linear 
                 polarization products)
        """
        mytb = createCasaTool(tbtool)
        mytb.open(self.vis +'/DATA_DESCRIPTION')
        polId = mytb.getcol('POLARIZATION_ID') # will have length = number of spws
        # each integer value of polId corresponds to a set of correlations
        # so for an ACA dataset with dualpol pointing and 4-pol observations, 
        #      0 == XX,YY; 1 = XX,XY,YX,YY
        # for a 12m dataset with dualpol only, then 0 = WVR, 1=XX,YY
        mytb.close()
        mytb.open(self.vis +'/POLARIZATION')
        corrType = mytb.getcell('CORR_TYPE',polId[spw])
        mytb.close()
        xxpol = -1
        yypol = -1
        for i,corr in enumerate(corrType):
            if (corr == 12):
                yypol = i
            if (corr == 9):
                xxpol = i
        self.xxyy[spw] = [xxpol, yypol]
        return(corrType)

    def getSpectrum(self, scan, spw, pol, target, antenna, 
                    dataFraction=[0.0,1.0],
                    median=False, ignoreFlags=False, antenna2=None):
        """
        Uses the ms tool to retrieve the average spectrum over all 
        integrations in the specified scan, for the subscan corresponding 
        to the target, and the specified spw, polarization and antenna.
        scan: integer
        spw: integer
        pol: integer
        target: 'hot', 'sky', amb'
        antenna: the antenna ID
        """
        scan = int(scan)
        spw = int(spw)
        pol = int(pol)
        mypol = pol
        if (spw not in self.xxyy):
            print "spw not found, did you run Atmcal(includeSQLD=True)?"
            return
        pol = self.xxyy[spw][pol]
#        print "Chose position %d for pol %d" % (pol, mypol)
        antenna = int(antenna)
        antennaName = self.antennaNames[antenna]
        dataColumnsDefined = dataColumns(self.vis)
        myms = createCasaTool(mstool)
        myms.open(self.vis)
        subscan = self.targetInverse[target]
        myms.selectinit(datadescid=self.datadescids[spw])
        # normally, one could just bass 'time':self.timestamps[scan][subscan]
        # but here I give the option to use only part of the subscan
        endtime = self.timestamps[scan][subscan][1]
        starttime = self.timestamps[scan][subscan][0]
        timerange = [starttime+(endtime-starttime)*dataFraction[0],
                     starttime+(endtime-starttime)*dataFraction[1]]
        # because need to add 1/2 integration time on each end
        duration = timerange[1]-timerange[0]+self.integrationTime[scan]  
        if (antenna2 == None):
            antenna2 = antenna
        myms.select({'time':timerange,'antenna1':antenna, 'antenna2':antenna2})
        if 'float_data'.upper() not in dataColumnsDefined:
            datadict = myms.getdata(['amplitude'])
            if ('amplitude' not in datadict.keys()):
                print "No amplitude in ms.getdata result: %s" % (str(datadict.keys()))
                return
            data = datadict['amplitude']
            if len(data) == 0:
                print "No amplitude found."
                return
        else:
            datadict = myms.getdata(['float_data'])
            data = datadict['float_data']
            if len(data) == 0:
                print "No float_data found."
                return
        datamean = np.zeros(len(data[pol]))
        flag = myms.getdata(['flag'])['flag']
        myms.close()
        nflags = np.sum(flag[pol].flatten())
        line = ''
        if nflags > 0:
            line = "scan%d spw%d pol%d %s: %s flags: %d/%d" % (scan,spw,pol,antennaName, target, nflags,
                                                               len(flag[pol].flatten()))
        try:
            if (ignoreFlags):
                datamean = np.mean(data[pol], 1)
            else:
                weights = 1.0-flag[pol].astype(float)
                if np.sum(weights) == 0.:
                    line +=  " ignoring flags since all data are flagged"
                    if self.correctedColumnPresent:
                        line += " (probably since this is a calibrated dataset)"
                    datamean = np.mean(data[pol], 1)
                    #weights = flag[pol].astype(float)
                    # the following produces a MaskedIterator which cannot be later used with things like np.min
                    #datamean = np.ma.average(data[pol], 1, weights=weights)
                else:
                    # The following fails if the weights sum to zero
                    datamean = np.average(data[pol], 1, weights=weights)
        except:
            datamean = -1
            print "This subscan data (scan=%d, spw=%d, pol=%d, antenna=%d) is either missing or totally flagged (%s)." % (scan,spw,pol,antenna,self.vis)
        if len(line) > 0:
            print line
        return(datamean)
        
    def computeMeanSpectrum(self, spw, pol, target, antenna, dataFraction=[0.0,1.0], median=False):
        """
        antenna: the antenna ID
        """
        means = []
        myms = createCasaTool(mstool)
        myms.open(self.vis)
        subscan = self.targetInverse[target]
        for i in range(len(self.scans)):
            # produce a mean spectrum for each scan
            scan = self.scans[i]
            myms.selectinit(datadescid=self.datadescids[spw])
            endtime = self.timestamps[scan][subscan][1]
            starttime = self.timestamps[scan][subscan][0]
            timerange = [starttime+(endtime-starttime)*dataFraction[0], starttime+(endtime-starttime)*dataFraction[1]]
            duration = timerange[1]-timerange[0]
            myms.select({'time':timerange, 'antenna1':antenna, 'antenna2':antenna})
            data = myms.getdata(['amplitude'])['amplitude']
            if (median):
                datamean = np.median(data[pol], 1)
                means.append(datamean/np.median(datamean))
            else:
                datamean = np.mean(data[pol], 1)
                means.append(datamean/np.mean(datamean))
        myms.close()
        # compute the mean spectrum over all scans
        if (median):
            return(np.median(means,0),duration)
        else:
            return(np.mean(means,0),duration)

    def readIFProcAttenuatorSettings(self, tmcfile, pol=0):
        """
        Returns 2 lists: dateTimeStamp in MJD second, and attenuation in dB
        """
        loc = tmcfile.find('IFProc')+6
        if (loc > 0):
            tmcfile = tmcfile[:loc] + str(pol) + tmcfile[loc+1:]
            print "Using file = ", tmcfile
        if (os.path.exists(tmcfile) == False):
            print "Could not open IF Proc TMC database file"
            return
        tmclines = open(tmcfile,'r').readlines()
        dateTimeStamp = []
        dB = []
        for line in tmclines:
            tokens = line.split()
            if (len(tokens) == 0):
                print "len(tokens) = %d" % (len(tokens))
            dateTimeStamp.append(dateStringToMJDSec(tokens[0],verbose=False))
            dB.append([float(x) for x in tokens[1:]])
        return(dateTimeStamp, dB)

    def readIFSwitchAttenuatorSettings(self, tmcfile_ifswitch, pol=0, sideband=1):
        """
        Returns the timestamp and (single) value for the specified polarization and sideband.
        """
        tmcfile = tmcfile_ifswitch[sideband]
        loc = tmcfile.find('CHANNEL')+7
        if (loc > 0):
            tmcfile = tmcfile[:loc] + str(pol) + str(sideband) + tmcfile[loc+2:]
            print "Using file = ", tmcfile
        if (os.path.exists(tmcfile) == False):
            print "Could not open IF Switch TMC database file"
            return
        tmclines = open(tmcfile,'r').readlines()
        dateTimeStamp = []
        dB = []
        for line in tmclines:
            tokens = line.split()
            dateTimeStamp.append(dateStringToMJDSec(tokens[0],verbose=False))
            dB.append(float(tokens[1]))
        return(dateTimeStamp, dB)

    def getAttenuatorSettings(self, antenna=0, pol=0, tmcfile_ifswitch=None, tmcfile_ifproc=None):
        if (self.IFProc[antenna][pol] == None or self.IFSwitch[antenna][pol][1] == None):
            self.readAttenuatorSettings(antenna,pol,tmcfile_ifswitch,tmcfile_ifproc)
        return(self.IFProc[antenna][pol], self.IFSwitch[antenna][pol])

    def plotAttenuatorSettings(self, antenna=0, pol=0, dateTimeStamp=None, dB=None):
        """
        Plot the IF Proc attenuator settings.
        """
        if (self.IFProc == {}):
            print "You must first readAttenuatorSettings()"
            return
        if (dateTimeStamp == None or dB == None):
            dateTimeStamp, dB = self.readIFProcAttenuatorSettings(self.tmcfile_ifproc, pol)
            idx0 = np.where(dateTimeStamp < self.observationStop)[0]
            idx1 = np.where(dateTimeStamp > self.observationStart)[0]
            indices = np.intersect1d(idx0,idx1)
            dateTimeStamp = np.array(dateTimeStamp)[indices]
            print "np.shape(dB) = ", np.shape(dB)
            print "np.shape(dB[0]) = ", np.shape(dB[0])
            print "indices = ", indices
            dB[0] = np.array(dB[0])[indices]
            print "np.shape(dB) = ", np.shape(dB)
        timeStamps = pb.date2num(mjdSecondsListToDateTime(list(dateTimeStamp)))
        for bb in range(1):
            print "bb=%d: len(timeStamps)=%d, len(dB[bb])=%d" % (bb, len(timeStamps), len(dB[bb]))
            pb.plot_date(timeStamps, dB[bb], color=overlayColors[bb])
            pb.hold(True)
        pb.ylabel('dB')
        pb.xlabel('Universal time')
        pb.title('%s: Antenna %d, pol %d' % (os.path.basename(self.vis), antenna, pol))
        png = os.path.basename(self.vis) + '.ifproc.ant%d.pol%d.png' % (antenna,pol)
        pb.savefig(png)
        pb.draw()
        return(dateTimeStamp, dB)
                               
    def readAttenuatorSettings(self, antenna=0, pol=0, tmcfile_ifswitch=None, tmcfile_ifproc=None, outpath='./'):
        # Example: tmu.get_tmc_data('DA62','FrontEnd_IFSwitch','CHANNEL01_ATTENUATION','2013-07-23','2013-07-23')
        if (tmcfile_ifproc==None):
            localfile = tmu.retrieve_daily_tmc_data_file_name_only(self.antennaNames[antenna],'IFProc'+str(pol),
                                                                   'GAINS', self.yyyymmdd, outpath=outpath)
            if (os.path.exists(localfile)):
                tmcfile_ifproc = localfile
            else:
                try:
                    mydict=tmu.get_tmc_data(self.antennaNames[antenna],'IFProc'+str(pol),'GAINS', self.yyyymmdd, self.yyyymmdd, outpath=outpath)
                    tmcfile_ifproc = mydict['files'][0]
                    self.tmcfile_ifproc = tmcfile_ifproc
                except:
                    return False
        if (tmcfile_ifswitch==None):
            tmcfile_ifswitch = {}
            for sideband in self.sidebands:
                localfile = tmu.retrieve_daily_tmc_data_file_name_only(self.antennaNames[antenna],'FrontEnd_IFSwitch',
                                                                       'CHANNEL%d%d_ATTENUATION'%(pol,sideband), self.yyyymmdd, outpath=outpath)
                if (os.path.exists(localfile)):
                    tmcfile_ifswitch[sideband] = localfile
                else:
                    mydict = tmu.get_tmc_data(self.antennaNames[antenna],'FrontEnd_IFSwitch',
                                       'CHANNEL%d%d_ATTENUATION'%(pol,sideband), self.yyyymmdd, self.yyyymmdd, outpath=outpath)
                    tmcfile_ifswitch[sideband] = mydict['files'][0]
        else:
            print "tmcfile_ifswitch is not None = ", tmcfile_ifswitch
            
        self.associateAttenuatorSettingsToScans(tmcfile_ifproc, tmcfile_ifswitch, antenna, pol)
        print "Range of attenuator settings for pol %d: IFproc=%4.1f-%4.1f, IFswitch:sb1=%4.1f-%4.1f, sb2=%4.1f-%4.1f" % (pol, self.IFProcMin[antenna][pol],
                                                                              self.IFProcMax[antenna][pol],
                                                                              self.IFSwitchMin[antenna][pol][1],
                                                                              self.IFSwitchMax[antenna][pol][1],
                                                                              self.IFSwitchMin[antenna][pol][2],
                                                                              self.IFSwitchMax[antenna][pol][2]
                                                                                             )
        return(True)

    def associateAttenuatorSettingsToScans(self, tmcfile_ifproc,
                                           tmcfile_ifswitch=None,
                                           antenna=0, pol=0, debug=False,
                                           subscan=2, verbose=False):
        """
        Builds two dictionaries, keyed by scan number, and baseband number:
        (1) IFProcessor attenuator settings: a vector of 4 values (one for each baseband).
        (2) IFSwitch attenuator settings: a single value
        pol: 0 or 1
        """
        if (pol != 0 and pol != 1):
            print "Invalid pol, must be 0 or 1"
            return
        dateTimeStamp, dB = self.readIFProcAttenuatorSettings(tmcfile_ifproc, pol)
        self.IFProc[antenna][pol] = {}     # start with empty list of scans
        self.IFSwitch[antenna][pol][1] = {}
        self.IFSwitch[antenna][pol][2] = {}
        alldB = []
#        print "IF Proc TMC timestamps range from %f to %f" % (dateTimeStamp[0], dateTimeStamp[-1])
        for scan in self.scans:
            startTime = self.timestamps[scan][1][0]
            endTime = self.timestamps[scan][self.nsubscans][-1]
            # Look for the attenuator measurements after the start time of the first subscan.
            indices1 = np.where(dateTimeStamp > startTime+1)[0]
            # Look for the attenuator measurements before the end of the last subscan.
            indices2 = np.where(dateTimeStamp < endTime-2.5)[0]
            if (debug): print "startTime-endTime = %s-%s" % (mjdsecToUTHMS(startTime+1), mjdsecToUTHMS(endTime-2.5))
            indices = np.intersect1d(indices1,indices2)
            if (len(indices) < 1):
                print "The IFProc TMC file (%s) does not contain data within scan %d (%s-%s)." % (tmcfile_ifproc,scan,mjdsecToUTHMS(startTime),mjdsecToUTHMS(endTime))
                self.IFProc[antenna][pol][scan] = -1
            if (verbose):
                outline = "Found %d %s IF proc pol%d attenuator measurements during scan %2d.  " % (len(indices),self.antennaNames[antenna],pol,scan)
            else:
                outline = ''
            if (len(indices) > 1):
                for bb in range(4):
                    if (dB[indices[0]][bb] != dB[indices[-1]][bb]):
                        outline += "The IFProc pol%d:bb%d attenuator value changed from %4.1f to %4.1f during scan %d!" % (pol,bb+1,dB[indices[0]][bb], dB[indices[-1]][bb], scan)
                if (verbose==False and len(outline)>0):
                    print outline
                    for j in range(len(indices)):
                        print "start = %.1f    end = %.1f" % (startTime, endTime)
                        print "%s dB at %.1f (%.1f--%.1f sec)\n" % (str(dB[indices[j]]),
                                                                    dateTimeStamp[indices[j]],
                                                                    dateTimeStamp[indices[j]]-startTime,
                                                                    endTime-dateTimeStamp[indices[j]]
                                                                    )
                else:
                    outline += "No inconsistencies seen."
            if (verbose):
                print outline
            if (len(indices) > 0):
                firstIndex = indices[0]
                self.IFProc[antenna][pol][scan] = dB[firstIndex]
                alldB += dB[firstIndex]
        if (len(alldB) < 1):
            self.IFProcMin[antenna][pol] = -1
            self.IFProcMax[antenna][pol] = -1
        else:
            self.IFProcMin[antenna][pol] = np.min(alldB)
            self.IFProcMax[antenna][pol] = np.max(alldB)
        # Build baseband keys
        for bb in range(4):
            self.IFProc[antenna][pol]['bb%d'%(bb+1)] = []
            for scan in self.scans:
                if (scan in self.IFProc[antenna][pol]):
                    if (self.IFProc[antenna][pol][scan] != -1):
                        self.IFProc[antenna][pol]['bb%d'%(bb+1)].append(self.IFProc[antenna][pol][scan][bb])
                    else:
                        print "Scan %d is not in the IFProc dictionary" % (scan)
                else:
                    print "Scan %d is not in the IFProc dictionary" % (scan)
        if (tmcfile_ifswitch is not None):
          for sideband in self.sidebands:
            dateTimeStamp, dB = self.readIFSwitchAttenuatorSettings(tmcfile_ifswitch, pol, sideband)
            alldB = []
            for scan in self.scans:
                startTime = self.timestamps[scan][1][0]
                endTime = self.timestamps[scan][self.nsubscans][-1]
                # Look for the attenuator measurements after the start time of the first subscan
                if (debug): print "startTime of scan %d = %f" % (scan,startTime)
                indices1 = np.where(dateTimeStamp > startTime+1)[0]
                # Look for the attenuator measurements before then end of the last subscan
                indices2 = np.where(dateTimeStamp < endTime-2.5)[0]
                indices = np.intersect1d(indices1,indices2)
                if (len(indices) < 1):
                    print "The IFSwitch TMC file does not contain data during scan %d (%s-%s)." % (scan,mjdsecToUTHMS(startTime+1), mjdsecToUTHMS(endTime-2.5))
                    self.IFSwitchMin[antenna][pol][sideband] = -1
                    self.IFSwitchMax[antenna][pol][sideband] = -1
                if (verbose):
                    outline = "Found %d %s IF switch pol%d:sb%d attenuator measurements during scan %2d.  " % (len(indices),self.antennaNames[antenna],pol,sideband,scan)
                else:
                    outline = ''
                if (len(indices) > 1):
                    if (dB[indices[0]] != dB[indices[-1]]):
                        outline += "The attenuation changed from %.1f to %.1f during scan %d!" % (dB[indices[0]], dB[indices[-1]],scan)
                        if (verbose==False and len(outline)>0):
                            print outline
                            for j in range(len(indices)):
                                print "start = %.1f    end = %.1f" % (startTime, endTime)
                                print "%s dB at %.1f (%.1f--%.1f sec)\n" % (str(dB[indices[j]]),
                                                                    dateTimeStamp[indices[j]],
                                                                    dateTimeStamp[indices[j]]-startTime,
                                                                    endTime-dateTimeStamp[indices[j]]
                                                                    )
                    else:
                        outline += "No inconsistencies seen."
                if (verbose): print outline
                if (len(indices) > 0):
                    firstIndex = indices[0]
                    self.IFSwitch[antenna][pol][sideband][scan] = dB[firstIndex]
                    alldB.append(dB[firstIndex])
            if (len(indices) > 0):
                self.IFSwitchMin[antenna][pol][sideband] = np.min(alldB)
                self.IFSwitchMax[antenna][pol][sideband] = np.max(alldB)
            # Build baseband keys
            self.IFSwitch[antenna][pol][sideband]['bb0'] = []
            for scan in self.scans:
                if (scan in self.IFSwitch[antenna][pol][sideband]):
                    self.IFSwitch[antenna][pol][sideband]['bb0'].append(self.IFSwitch[antenna][pol][sideband][scan])
                else:
                    print "Scan %d not in IFSwitch dictionary" % (scan)

    def computeBitRanges(self, delta=1.0):
        """
        returns a matrix:  len=64 levels, nBits entries for each
        and its transpose: len=nBits, 64 entries for each
        and a dictionary keyed by each possible attenuation value with the value being
           the number of bits that must be changed when the increment is delta from there.
        """
        a = np.arange(64.0)
        atten = a*0.5
        levels = [16,8,4,2,1,0.5]  # dB
        attenlevels = []  # will hold 0 or 1 for each of the bit levels
        for a in range(len(atten)):
            i = atten[a]
            levs = []
            att = i
            for l in levels: 
                if (i >= l):
                    levs.append(1)
                    i = i-l
                else:
                    levs.append(0)
            attenlevels.append(levs)  # 0->0dB, 1->0.5dB
        deltaBits = {}
        if (delta > 0):
            start = 0
            end = 32-delta
            inc = 0.5
        else:
            start = 32
            end = 0-delta
            inc = -0.5
        for a in np.arange(start,end,inc):
            # deltaBits = how many bits changed when going from the key dB
            #             to key+delta dB
            startBits = attenlevels[int(a*2)]
            endBits = attenlevels[int((a+delta)*2)]
            deltaBits[a] = abs(np.array(startBits)-np.array(endBits)).sum()
#            print "%4.1f dB: startBits=%s, endBits=%s, deltaBits=%d" % (a, startBits, endBits, deltaBits[a])
            
        bitstatus = np.transpose(attenlevels) # len=nBits, each entry=64 levels
        return(attenlevels, bitstatus, deltaBits)

    def plotCalScansAll(self, target=['sky','amb','hot'],
                        normalize='meanspectrum', plotfile=True,
                        startdBm=4.0, incrementdBm=-1.0, plotSlopes=True,
                        maxSlope=20, edge=5, xaxis='dB', 
                        pdfname=None, tmcfile_ifswitch=None,
                        tmcfile_ifproc=None, xlim=[8,26], y_autoscale=True,
                        dataFraction=[0.0, 1.0], logPower=False, median=False,
                        printSlopes=False, debug=False,ylimitsForRatio=[0.9,1.1]):
        """
        Calls plotCalScans repeatedly for each antenna, pol, spw.
        dataFraction: use this range of the each integration
        median: normalize by the median rather than the mean spectrum
        """
        pngs = []
        for antenna in self.antennas:
            for pol in self.polarizations:
                for spw in self.spws:
                    png = self.plotCalScans(spw=spw, pol=pol, antenna=antenna,
                                            target=target,
                                            normalize=normalize,
                                            plotfile=plotfile,
                                            startdBm=startdBm,
                                            incrementdBm=incrementdBm,
                                            plotSlopes=plotSlopes,
                                            maxSlope=maxSlope, edge=edge,
                                            xaxis=xaxis,
                                            tmcfile_ifswitch=tmcfile_ifswitch,
                                            tmcfile_ifproc=tmcfile_ifproc,
                                            xlim=xlim, y_autoscale=y_autoscale,
                                            dataFraction=dataFraction, logPower=logPower,
                                            median=median, printSlopes=printSlopes,debug=debug,
                                            ylimitsForRatio=ylimitsForRatio)
                    pngs.append(png)
        if (normalize==''):
            normalize = 'raw'
        if (pdfname == None):
            if (dataFraction != [0.0,1.0]):
                pdfname = self.vis + '.%s.%.1f-%.1f.plotCalScans.pdf' % (normalize,dataFraction[0],dataFraction[1])
            else:
                pdfname = self.vis + '.%s.plotCalScans.pdf' % (normalize)
        mystatus = buildPdfFromPngs(pngs, pdfname=pdfname)
        print mystatus
        
    def plotCalScans(self, spw=0, pol=0, antenna=0, target='hot',
                     normalize=False, plotfile=None, startdBm=4.0,
                     incrementdBm=-1.0, plotSlopes=False,
                     maxSlope=20, edge=5, xaxis='dB',
                     tmcfile_ifswitch=None, tmcfile_ifproc=None, xlim=None,
                     y_autoscale=True, dataFraction=[0.0,1.0], logPower=False,
                     median=False, printSlopes=False, debug=False,
                     ylimitsForRatio=[0.9,1.1], fontsize=12, overlay=False):
        """
        Plot the atm cal subscans for a specified spw/pol/antenna combination,
        and the specified subscans.
        
        plotSlopes: if True, make 2 rows of plots, with the slope vs. scan
                    on the bottom row
        edge: number of edge channels to ignore when fitting a linear slope
        maxSlope: use this to set the +-y axis range when plotSlopes=True
        xlim: use this to set the x axis range when plotSlopes=True
        xaxis: 'dB' to put the IFProc attenuator setting on the x-axis
               (otherwise, use scan#)
        y_autoscale: True will set y-axis range to automatic
                     False will set y-axis range to [min(all_targets),max(all_targets)]
        dataFraction: use this range of the each integration
        logPower: if True, show the power spectra in log units instead of linear
        overlay: if True, show all on the same panel
        target: 'hot', 'sky', amb' or lists:  ['hot','sky','amb']
        fontsize: for tick labels, axis labels and target labels
        """
        loadNames = {'amb': 'ambient load', 'hot': 'hot load', 'sky': 'sky'}
        spw = int(spw)
        antenna = int(antenna)
        if (self.unrecognizedSpw(spw)): return
        if (self.unrecognizedAntenna(antenna)): return
        pb.clf()
        pb.hold(True)
        if (type(target) != list):
            target = [target]
        if (plotSlopes):
            nx = 2
            if (normalize==False):
                normalize = 'meanspectrum'
                print "Since plotSlopes=True, set normalize to '%s'" % (normalize)
        else:
            nx = 1
            if (normalize==False or normalize==''):
                normalize = 'raw'
        if (not overlay):
            adesc = pb.subplot(nx,len(target),1)
        else:
            adesc = pb.subplot(1,1,1)
            pb.hold(True)
        if (y_autoscale):
            wspace=0.15
        else:
            wspace=0.1
        pb.subplots_adjust(wspace=wspace, right=0.85, hspace=0.2)
        data0max = 0
        data0min = 1e38
        for t in range(len(target)):
            mytarget = target[t]
            if (not overlay):
                adesc = pb.subplot(nx,len(target),t+1)
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            if (mytarget not in self.targetInverse):
                print "The %s subscan is not in this dataset (valid targets = %s)." % (mytarget,str(self.targetInverse))
                return
            subscan = self.targetInverse[mytarget]
            if (normalize == 'meanspectrum'):
                self.meanspectrum,duration = self.computeMeanSpectrum(spw,pol,mytarget,
                                                             antenna,dataFraction,median)
            myms = createCasaTool(mstool)
            myms.open(self.vis)
            if (overlay):
                pb.text(0.1,0.9-t*0.1,loadNames[mytarget],size=fontsize,
                        transform=adesc.transAxes,color=overlayColors[t])
            else:
                pb.text(0.1,0.9,loadNames[mytarget],size=fontsize,transform=adesc.transAxes)
            slopes = []
            for i in range(len(self.scans)):
                scan = self.scans[i]
                myms.selectinit(datadescid=self.datadescids[spw])
                myms.select({'time':self.timestamps[scan][subscan],
                             'antenna1':antenna, 'antenna2':antenna})
                data0 = myms.getdata(['amplitude'])['amplitude']
                data0mean = np.median(data0[pol], 1)
                if (normalize == 'meanvalue'):
                    if (median):
                        data0mean /= np.median(data0mean)
                    else:
                        data0mean /= np.mean(data0mean)
                elif (normalize == 'meanspectrum'):
                    if (median):
                        data0mean /= np.median(data0mean)
                    else:
                        data0mean /= np.mean(data0mean)
                    data0mean /= self.meanspectrum
                if ((i < len(self.scans)/2) or (normalize=='raw')):
                    ls = '-'
                else:
                    ls = '--'
                if (logPower):
                    yaxisData = 10*np.log10(data0mean)
                else:
                    yaxisData = data0mean
                if (overlay):
                    colorIndex = t # i*len(target)+t
                else:
                    colorIndex = i
                pb.plot(range(len(data0mean)), yaxisData, ls=ls,
                        color=overlayColors[colorIndex],
                        markerfacecolor=overlayColors[colorIndex], lw=2.0)
                resizeFonts(adesc,fontsize)
                pb.xlim([-2, len(data0mean)+1])
                data0max = np.max([data0max,np.max(data0mean)])
                data0min = np.min([data0min,np.min(data0mean)])
                if (overlay):
                    if (data0min > 0): data0min = 0
                slope,intercept = linfit().linfit(range(len(data0mean[edge:-edge])),
                                                  data0mean[edge:-edge],
                                                  data0mean[edge:-edge]*0.0001)
                slopes.append(slope)
#                print "%4s %2d = %+f" % (mytarget, scan, slope*1000)
            # end for 'i'
            baseband = self.basebands[spw]
            antspwpol= self.antennaNames[antenna]+'.spw%02d.bb%d.pol'%(spw,baseband)+str(pol)
            titleString = mytarget+'.'+antspwpol
            pb.title(titleString,size=13-len(target))
            if (normalize == 'meanvalue' or normalize=='meanspectrum'):
                pb.ylim(ylimitsForRatio)
                if (t != 0 and not overlay):
                    adesc.set_yticklabels([])
            if (t==0):
                obsdateString = mjdsecToUT(getObservationStart(self.vis))
                pb.text(0.1,1+0.05*nx,self.vis + '  ' + obsdateString + ' %.3fGHz'%(self.meanfreq[spw]*1e-9),transform=adesc.transAxes)
                if (normalize == 'meanvalue'):
                    pb.ylabel('Normalized amplitude', size=fontsize)
                elif (normalize == 'meanspectrum'):
                    if (plotSlopes):
                        pb.ylabel('Normalized_Amp / Mean_of_all_scans', size=fontsize)
                    else:
                        pb.ylabel('Normalized_Amplitude / Mean_of_all_scans', size=fontsize)
                else:  # raw
                    if (logPower):
                        pb.ylabel('Relative Amplitude (dB)', size=fontsize)
                    else:
                        pb.ylabel('Amplitude', size=fontsize)

            pb.xlabel('Channel', size=fontsize)
            if (t==len(target)-1):
                font0 = FontProperties()
                font = font0.copy()
                font.set_weight('heavy')
                if (self.attenuatorTest):
                    heading = 'Scan=ReqPower'
                else:
                    heading = 'Scan'
                pb.text(1+0.02*len(target), 1.06, heading,
                        transform=adesc.transAxes, size=9)
                pb.text(1+0.02*len(target), 1.13, 'nsubscans=%d'%self.nsubscans,
                        transform=adesc.transAxes, size=9)
                for j in range(len(self.scans)):
                    if (startdBm == None or self.attenuatorTest==False):
                        mytext = str(self.scans[j])
                    else:
                        mytext = str(self.scans[j]) + "=%+.1fdBm"%(startdBm+j*incrementdBm)
                    if ((j < len(self.scans)/2) or (normalize=='raw')):
                        mytext = mytext
                    else:
                        mytext = ":" + mytext
                    pb.text(1+0.01*len(target), 1-j*0.04*nx, mytext,
                            color=overlayColors[j], size=9,
                            transform=adesc.transAxes, fontproperties=font)
            if (plotSlopes):
                adesc = pb.subplot(nx,len(target),t+1+len(target))
                slopes = np.array(slopes)*100*self.nchan
                bitranges,bitstatus,deltaBits = self.computeBitRanges()
                baseband = self.basebands[spw]
                for i in range(len(self.scans)):
                    if (xaxis=='dB'):
                        self.getAttenuatorSettings(tmcfile_ifswitch=tmcfile_ifswitch,
                                                   tmcfile_ifproc=tmcfile_ifproc, pol=pol, antenna=antenna)
                        if (debug):
                            print "self.IFProc[antenna][pol] = ", self.IFProc[antenna][pol]
                            print "self.IFProc[antenna][pol][self.scans[i]] = ", self.IFProc[antenna][pol][self.scans[i]]
                            print "baseband = ", baseband
                        dB = self.IFProc[antenna][pol][self.scans[i]][baseband-1]
                        if (debug):
                            print "spw%d: bb%d: dB = %f, slope=%f" % (spw, self.basebands[spw], dB, slopes[i])
                        pb.plot(dB, slopes[i], 'o',markerfacecolor=overlayColors[i],
                                markeredgecolor=overlayColors[i])
                        if (i>0):
                            pb.text(dB, slopes[i]+1.2, str(deltaBits[previousAttenuation]),
                                    color=overlayColors[i], size=9)
                        previousAttenuation = dB
                    else:
                        pb.plot(self.scans[i],slopes[i],'o',markerfacecolor=overlayColors[i],
                                markeredgecolor=overlayColors[i])
                    if (printSlopes and t==len(target)-1):
                        print "slopes(hot) = ", slopes[i]
                resizeFonts(adesc,9)
                if (xaxis=='dB'):
                    adesc.xaxis.set_minor_locator(MultipleLocator(1.0))
                    adesc.xaxis.grid(True,which='minor')
                    pb.xlabel('IFProc%d:bb%d atten (dB)' % (pol,baseband))
                    # draw a square waveform corresponding to the status of each bit
                    yrange = 2*maxSlope
                    if (xlim == None):
                        startdB = self.IFProcMin[antenna][pol]-1
                        stopdB =  self.IFProcMax[antenna][pol]+1
                    else:
                        startdB, stopdB = xlim
                    pb.xlim([startdB,stopdB])
                    for i in range(len(bitstatus)):
                        xlevel = np.arange(self.IFProcMin[antenna][pol], self.IFProcMax[antenna][pol]+0.6, 0.5)
                        # 0dB --> 0,  0.5dB --> 1, 1dB--> 2
                        ylevel = bitstatus[i][(xlevel*2).astype(int)]*0.015*yrange + (maxSlope-yrange*(0.11+0.05*(i-1)))
                        xlevel -= 0.25
                        pb.plot(xlevel, ylevel, 'k-', drawstyle='steps-post')
                        dB = [16,8,4,2,1,0.5][i]
                        pb.text(stopdB+0.25, np.min(ylevel), str(dB), size=8)
                        if (t == len(target)-1):
                            if (dB < 1):
                                pb.text(stopdB+0.5+0.6*(3), np.min(ylevel)-0.3, 'off', size=5)
                                pb.text(stopdB+0.5+0.6*(3), np.min(ylevel)+0.8, 'on', size=5)
                            else:
                                pb.text(stopdB+0.5+0.6*(1+dB/10), np.min(ylevel)-0.3, 'off', size=5)
                                pb.text(stopdB+0.5+0.6*(1+dB/10), np.min(ylevel)+0.8, 'on', size=5)
                            if (i==0):
                                pb.text(stopdB+0.5, 5, 'duration=%.1f sec' % (duration), size=8)
                                pb.text(stopdB+0.5, 2.5, '(%.1f-%.1f)' % (dataFraction[0],dataFraction[1]), size=8)
                                pb.text(stopdB+0.5, -0.5, 'colored digits', size=8)
                                pb.text(stopdB+0.5, -3, 'denote the number', size=8)
                                pb.text(stopdB+0.5, -6, 'of bits changed', size=8)
                                pb.text(stopdB+0.5, -9, 'when switching', size=8)
                                pb.text(stopdB+0.5, -12, 'to this level', size=8)
                                pb.text(stopdB+0.5, -16, 'IFswSB1:%.1f-%.1fdB'%(self.IFSwitchMin[antenna][pol][1],
                                                                                    self.IFSwitchMax[antenna][pol][1]),size=8)
                                pb.text(stopdB+0.5, -19, 'IFswSB2:%.1f-%.1fdB'%(self.IFSwitchMin[antenna][pol][2],
                                                                                    self.IFSwitchMax[antenna][pol][2]),size=8)
                    pb.xlim([startdB,stopdB])
                else:
                    pb.xlabel('scan number')
                if (t == 0):
                    pb.ylabel('fitted slope (% per BW)')
                else:
                    adesc.set_yticklabels([])
                pb.ylim([-maxSlope, maxSlope])
            # endif plotSlopes
            resizeFonts(adesc,fontsize)
            myms.close()
        #end 'for' t in range(len(target)):
        # set the ylimits for the amp. vs channel plots
        for t in range(len(target)):
            if (not overlay):
                adesc = pb.subplot(nx,len(target),t+1)
            if (y_autoscale == False):
                if (logPower==False):
                    pb.ylim([data0min,data0max])
                else:
                    pb.ylim([np.min(10*np.log10(data0min)),np.max(10*np.log10(data0max))])
                if (t > 0 and not overlay):
                    adesc.set_yticklabels([])
        pb.draw()
        if (plotfile is not None):
            if (plotfile == True):
                png = '.'.join(target) + '.' + antspwpol
                if (normalize != ''):
                    png += '.%s' % (normalize)
                png += '.png'
            else:
                png = plotfile
            pb.savefig(png)
            print "plot saved to %s" % (png)
            return(png)

    def getAntenna(self, antenna):
        """
        Converts an antenna ID or name into a tuple of ID, name.
        """
        if (str(antenna) in self.antennaNames):
            antennaName = antenna
            antennaId = self.antennaNames.index(antennaName)
        elif (antenna in self.antennas or antenna in [str(a) for a in self.antennas]):
            antennaId = int(antenna)
            antennaName = self.antennaNames[antennaId]
        else:
            print "Antenna %s is not in the dataset" % (str(antenna))
            return None
        return(antennaId, antennaName)

    def getTelcalTrx(self, antenna, spw, scan, pol):
        return(self.getTelcalTspectrum('TRX_SPECTRUM', antenna, spw, scan, pol))
        
    def getTelcalTsys(self, antenna, spw, scan, pol):
        return(self.getTelcalTspectrum('TSYS_SPECTRUM', antenna, spw, scan, pol))
        
    def getTelcalTsky(self, antenna, spw, scan, pol):
        return(self.getTelcalTspectrum('TSKY_SPECTRUM', antenna, spw, scan, pol))
        
    def getTelcalTspectrum(self, tspec, antenna, spw, scan, pol):
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
        mytb = createCasaTool(tbtool)
        mytb.open(self.vis+'/SYSCAL')
        myt = mytb.query('ANTENNA_ID == %s and SPECTRAL_WINDOW_ID == %d' % (antennaId,spw))
        times = myt.getcol('TIME')
        trx = myt.getcol(tspec)
        myt.close()
        mytb.close()
        mindiff = 1e38
        pickrow = -1
        if (scan in self.syscalScans):
            for row in range(len(times)):
                diff = abs(times[row] - self.meantime[scan])
                if (diff < mindiff):
                    mindiff = diff
                    pickrow = row
        if (pickrow < 0):
            print "There are no TelCal-generated Trx/Tsys spectra found for this spw/antenna/pol/scan."
            return None
        else:
            return(trx[pol,:,pickrow])

    def unrecognizedAntenna(self, antenna):
        if (antenna not in self.antennas and antenna not in self.antennaNames and
            antenna not in [str(a) for a in self.antennas]):
            print "antenna %s is not available.  valid antennas = %s, %s" % (str(antenna), str(self.antennas), str(self.antennaNames))
            return(True)
        return(False)

    def unrecognizedSpw(self, spw):
        if (spw not in self.spws):
            print "spw %d is not available.  valid spws = %s" % (spw, str(self.spws))
            return(True)
        return(False)

    def nonExistentTable(self, mytable):
        exists = os.path.exists(mytable)
        if (not exists):
            print "Could not find table = %s" % (mytable)
            print "Did you importasdm with asis='CalAtmosphere' ?"
        return not exists

    def unrecognizedScan(self, scan):
        if (type(scan) != int and type(scan) != np.int32):
            if (scan.isdigit()):
                scan = int(scan)
            else:
                print "The scan number must be an integer or integer string."
                return(False)
        if (int(scan) not in self.scans):
            print "Scan %d is not a cal scan.  Available scans = %s" % (int(scan), str(self.scans))
            return(True)
        return(False)

    def plotTsys(self, scan, antenna, pol, spw, tdmspw=None, asdm=None, etaF=0.98, lo1=None,
                 dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                 siteAltitude_m=5000, computeJsky=True, altscan=None, overlayTelcal=True,
                 plotrange=[0,0,0,0], fdmCorrection=False, tdmscan=None, tdmdataset=None, plotfile='',
                 showAttenuators=False, takeLoadsFromTdmDataset=False):
        """
        Computes Tsys and then plots the newly-calculated Tsys.
        See also plotTsysTrec2 to plot both Tsys and Trec2.
        """
        spw = int(spw)
#        if ((tdmspw is not None or tdmdataset is not None or tdmspw is not None) and takeLoadsFromTdmDataset==False):
#            if (fdmCorrection == False): print "Setting fdmCorrection to True"
#            fdmCorrection = True
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (spw == 'auto'):
            spw = self.spwsforscan[scan][0]
            print "Choosing spw = %d" % (spw)
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
        startTime = timeUtilities.time()
        result = self.computeTsys(scan, antenna, pol, spw, tdmspw, asdm, etaF, lo1,
                                  dataFraction, parentms, verbose,
                                  siteAltitude_m, computeJsky, altscan, fdmCorrection=fdmCorrection,
                                  tdmscan=tdmscan, tdmdataset=tdmdataset,
                                  takeLoadsFromTdmDataset=takeLoadsFromTdmDataset)
        stopTime = timeUtilities.time()
        if (stopTime-startTime > 5):
            print "Computation required %.1f seconds" % (stopTime-startTime)
        if (result == None):
            return
        if computeJsky:
            tsys, freqHz, trec, tsky, tcal, atmosphere = result
        else:
            trec, gain, tsky, freqHz = result
        pb.clf()
        pol = int(pol)
        adesc = pb.subplot(111)
        freqHz = self.chanfreqs[spw]
        casaTsysColor = 'r'
        pb.plot(freqHz*1e-9, tsys, '-', color=casaTsysColor)
        if (verbose):
            print "len(freqHz) = %d,  shape(tsys) = %s" % (len(freqHz), str(np.shape(tsys)))
        if (overlayTelcal):
            if (fdmCorrection):
                lw = 1
            else:
                lw = 3
            tsys_telcal = self.getTelcalTsys(antenna,spw,scan,pol)  # TelCal's result
            if (tsys_telcal == None):
                print "No Tsys result is available from TelCal "
                overlayTelcal = False
            else:
                pb.plot(freqHz*1e-9, tsys_telcal, 'g-', lw=lw)
                y0,y1 = pb.ylim()
                pb.ylim([y0,y1+(y1-y0)*0.2])
                if (fdmCorrection):
                    mylabel = ' FDM'
                else:
                    mylabel = ''
                pb.text(0.05,0.95,'TelCal'+mylabel, color='g', transform=adesc.transAxes) # ,weight='extra bold')
                pb.text(0.42,0.95,'casa'+mylabel, color=casaTsysColor, transform=adesc.transAxes)
                pb.text(0.05,0.80, 'HotLoad = %.2fK' % (self.loadTemperatures[antennaId][scan]['hot']),
                        transform=adesc.transAxes,color='k')
                pb.text(0.05,0.75, 'AmbLoad = %.2fK' % (self.loadTemperatures[antennaId][scan]['amb']),
                        transform=adesc.transAxes,color='k')
                if (showAttenuators):
                    if (self.IFProc[antennaId][pol] == None or self.IFSwitch[antennaId][pol][1] == None):
                        self.readAttenuatorSettings(antennaId,pol)
                    if (scan in self.IFProc[antennaId][pol]):
                      if (self.IFProc[antennaId][pol][scan] != -1):
                        pb.text(0.05,0.85,'IFSw %.1fdB, IFPr %.1fdB'%(self.IFSwitch[antennaId][pol][self.sidebandsforspw[spw]][scan],
                                                       self.IFProc[antennaId][pol][scan][self.basebands[spw]-1]),
                            color='g',transform=adesc.transAxes)
                pb.hold(True)
            if (fdmCorrection or takeLoadsFromTdmDataset):
                if (tdmspw == None): tdmspw = spw
                if (tdmscan == None): tdmscan = scan
                if (tdmdataset == None):
                    tdmdataset = self
                tsys = tdmdataset.getTelcalTsys(antenna,tdmspw,tdmscan,pol)  # TelCal's result for the TDM spectrum
                freqHz = tdmdataset.chanfreqs[tdmspw]
                pb.plot(freqHz*1e-9, tsys, 'r-')
                y0,y1 = pb.ylim()
                pb.ylim([y0,y1+(y1-y0)*0.2])
                pb.text(0.65,0.95, 'TelCal TDM (%s)' % (mjdsecToUTHMS(np.mean(tdmdataset.timerange[tdmscan]))),
                        color='r', transform=adesc.transAxes)
                pb.text(0.60,0.90, tdmdataset.visBasename, color='r', transform=adesc.transAxes)
                tdmAntennaId, antennaName = tdmdataset.getAntenna(antenna)
                pb.text(0.60,0.80, 'HotLoad = %.2fK' % (tdmdataset.loadTemperatures[tdmAntennaId][tdmscan]['hot']),transform=adesc.transAxes,color='r')
                pb.text(0.60,0.75, 'AmbLoad = %.2fK' % (tdmdataset.loadTemperatures[tdmAntennaId][tdmscan]['amb']),transform=adesc.transAxes,color='r')
                if (showAttenuators):
                    if (tdmdataset.IFProc[antennaId][pol] == None or tdmdataset.IFSwitch[antennaId][pol][1] == None):
                        tdmdataset.readAttenuatorSettings(antennaId,pol)
#                    print "tdmdataset.IFSwitch[antennaId=%d][pol=%d] = %s" % (antennaId,pol,str(tdmdataset.IFSwitch[antennaId][pol]))
                    if (tdmscan in tdmdataset.IFProc[antennaId][pol]):
                      if (tdmdataset.IFProc[antennaId][pol][tdmscan] != -1):
                        pb.text(0.65,0.85,'IFSw %.1fdB, IFPr %.1fdB'%(tdmdataset.IFSwitch[antennaId][pol][tdmdataset.sidebandsforspw[spw]][tdmscan],
                                                       tdmdataset.IFProc[antennaId][pol][tdmscan][tdmdataset.basebands[spw]-1]),
                            color='r',transform=adesc.transAxes)
        pb.xlabel('Frequency (GHz)')
        pb.ylabel('Tsys (K)')
        if (plotrange != [0,0,0,0]):
            if (plotrange[0] != 0 or plotrange[1] != 0):
                pb.xlim(plotrange[:2])
            if (plotrange[2] != 0 or plotrange[3] != 0):
                pb.ylim(plotrange[2:])
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        ut = mjdsecToUTHMS(self.meantime[scan])
        pb.title('%s  %s  scan=%d  spw=%d  pol=%d  mean_time=%s' % (os.path.basename(self.vis), antennaName, scan, spw, pol, ut), fontsize=11)
        pb.draw()
        if (plotfile == '' or plotfile==True):
            png = os.path.basename(self.vis) + '.%s.scan%02d.spw%02d.pol%d.tsys.png' % (antennaName,scan,spw,pol)
        else:
            png = plotfile
        pb.savefig(png)
        print "Result left in ", png
        return png

    def plotTsysTrec2(self, scan, antenna, pol, spw, tdmspw=None, asdm=None, etaF=0.98,
                      lo1=None, dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                      siteAltitude_m=5000, computeJsky=True, altscan=None,
                      overlayTelcal=True,
                      plotrange=[0,0,0,0], fdmCorrection=False, tdmscan=None,
                      tdmdataset=None,
                      plotfile='', showAttenuators=False, trxDifferences=None,
                      tsysDifferences=None, takeLoadsFromTdmDataset=False):
        """
        Plots Tsys in one panel and Trec2 in another panel on the same page, for a specified
        combination of scan, antenna, pol, spw.
        """
        spw = int(spw)
#        if ((tdmspw is not None or tdmdataset is not None or tdmspw is not None) and takeLoadsFromTdmDataset==False):
#            if (fdmCorrection == False): print "Setting fdmCorrection to True"
#            fdmCorrection = True
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (spw == 'auto'):
            spw = self.spwsforscan[scan][0]
            print "Choosing spw = %d" % (spw)
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
        antenna = antennaId
        startTime = timeUtilities.time()
        result = self.computeTsys(scan, antenna, pol, spw, tdmspw, asdm, etaF, lo1,
                                  dataFraction, parentms, verbose,
                                  siteAltitude_m, computeJsky, altscan, fdmCorrection=fdmCorrection,
                                  tdmscan=tdmscan, tdmdataset=tdmdataset,
                                  takeLoadsFromTdmDataset=takeLoadsFromTdmDataset)
        stopTime = timeUtilities.time()
        if (stopTime-startTime > 5):
            print "Computation required %.1f seconds" % (stopTime-startTime)
        if (result == None):
            return
        tsys, freqHz, trec, tsky, tcal = result
        pb.clf()
        pol = int(pol)
        freqHz = self.chanfreqs[spw]
        adesc = pb.subplot(211)
        pb.plot(freqHz*1e-9, trec, 'k-', lw=2)
#        print "Median Trec (black) = ", np.median(trec)
        if (verbose):
            print "len(freqHz) = %d,  shape(trec) = %s" % (len(freqHz), str(np.shape(trec)))
        if (overlayTelcal):
            trx_telcal = self.getTelcalTrx(antenna,spw,scan,pol)  # TelCal's result
            if (trx_telcal == None):
                print "No Trx result is available from TelCal "
                overlayTelcal = False
            else:
                pb.plot(freqHz*1e-9, trx_telcal, 'g-', lw=1)
                y0,y1 = pb.ylim()
                pb.ylim([y0,y1+(y1-y0)*0.2])
                if (fdmCorrection):
                    mylabel = ' FDM'
                else:
                    mylabel = ''
                pb.text(0.05,0.92,'TelCal'+mylabel,color='g',transform=adesc.transAxes) # ,weight='extra bold')
                pb.text(0.42,0.92,'casa'+mylabel,color='k',transform=adesc.transAxes)
                pb.hold(True)
                if (showAttenuators):
                    if (self.IFProc[antenna][pol] == None or self.IFSwitch[antenna][pol][1] == None):
                        self.readAttenuatorSettings(antenna,pol)
                    if (scan in self.IFProc[antenna][pol]):
                      if (self.IFProc[antenna][pol][scan] != -1):
                        pb.text(0.05,0.84,'IFSw %.1fdB, IFPr %.1fdB'%(self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]][scan],
                                                       self.IFProc[antenna][pol][scan][self.basebands[spw]-1]),
                            color='g',transform=adesc.transAxes)
            if (fdmCorrection or takeLoadsFromTdmDataset):
                if (tdmspw == None): tdmspw = spw
                if (tdmscan == None): tdmscan = scan
                if (tdmdataset == None):
                    tdmdataset = self
                trx = tdmdataset.getTelcalTrx(antenna,tdmspw,tdmscan,pol)  # TelCal's result for the TDM spectrum
                freqHzTDM = tdmdataset.chanfreqs[tdmspw]
                pb.plot(freqHzTDM*1e-9, trx, 'r-')
                pb.text(0.65,0.92, 'TelCal TDM (%s)' % (mjdsecToUTHMS(np.mean(tdmdataset.timerange[tdmscan]))),
                        color='r', transform=adesc.transAxes)
                pb.text(0.65,0.84, tdmdataset.vis,color='r',transform=adesc.transAxes)
                trxDiff = np.median(trx)-np.median(trec)
                pb.text(0.42,0.84, 'diff %.1fK'%(trxDiff),color='k',transform=adesc.transAxes)
                if (showAttenuators):
                    if (tdmdataset.IFProc[antenna][pol] == None or tdmdataset.IFSwitch[antenna][pol][1] == None):
                        tdmdataset.readAttenuatorSettings(antenna,pol)
                    print "tdmdataset.IFSwitch[antenna][pol] = ", tdmdataset.IFSwitch[antenna][pol]
                    print "tdmdataset.IFProc[antenna][pol] = ", tdmdataset.IFProc[antenna][pol]
                    if (tdmscan in tdmdataset.IFProc[antenna][pol]):
                      if (tdmdataset.IFProc[antenna][pol][tdmscan] != -1):
                        pb.text(0.65,0.84,'IFSw %.1fdB, IFPr %.1fdB'%(tdmdataset.IFSwitch[antenna][pol][tdmdataset.sidebandsforspw[spw]][tdmscan],
                                                       tdmdataset.IFProc[antenna][pol][tdmscan][tdmdataset.basebands[spw]-1]),
                            color='r',transform=adesc.transAxes)
                        if (scan in self.IFProc[antenna][pol] and
                            scan in self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]]):
                          if ((tdmdataset.IFSwitch[antenna][pol][tdmdataset.sidebandsforspw[spw]][tdmscan] ==
                             self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]][scan]) and
                            (tdmdataset.IFProc[antenna][pol][tdmscan][tdmdataset.basebands[spw]-1] ==
                             self.IFProc[antenna][pol][scan][self.basebands[spw]-1])):
                            if (trxDifferences is not None):
                                if (antenna not in trxDifferences['antenna'].keys()):
                                    trxDifferences['antenna'][antenna] = []
                                if (spw not in trxDifferences['spw'].keys()):
                                    trxDifferences['spw'][spw] = []
                                trxDifferences['antenna'][antenna].append(trxDiff)
                                trxDifferences['spw'][spw].append(trxDiff)
        pb.xlabel('Frequency (GHz)')
        pb.ylabel('Trec2 (K)')
        if (plotrange != [0,0,0,0]):
            if (plotrange[0] != 0 or plotrange[1] != 0):
                pb.xlim(plotrange[:2])
            if (plotrange[2] != 0 or plotrange[3] != 0):
                pb.ylim(plotrange[2:])
        else:
            if (fdmCorrection or takeLoadsFromTdmDataset):
                pb.xlim([np.min(freqHzTDM)*1e-9, np.max(freqHzTDM)*1e-9])
                # trec, trx_telcal  and if fdmCorrection, you have trx 
                pb.ylim([np.min([np.min(trec), np.min(trx), np.min(trx_telcal)]), np.max([np.max(trec),np.max(trx),np.max(trx_telcal)])])
            else:
                pb.xlim([np.min(freqHz)*1e-9, np.max(freqHz)*1e-9])
                pb.ylim([np.min([np.min(trec), np.min(trx_telcal)]), np.max([np.max(trec), np.max(trx_telcal)])])
            y0,y1 = pb.ylim()
            if (y0 < 0 and y0 > -100000 and np.median(trec)>0 and np.median(trx_telcal)>0): y0 = 0
            pb.ylim([y0,y1+(y1-y0)*0.2])

        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        ut = mjdsecToUTHMS(self.meantime[scan])
        pb.title('%s  %s  scan=%d  spw=%d  pol=%d  mean_time=%s' % (os.path.basename(self.vis), antennaName, scan, spw, pol, ut), fontsize=11)

        adesc = pb.subplot(212)
        pb.plot(freqHz*1e-9, tsys, 'k-')
        if (verbose):
            print "len(freqHz) = %d,  shape(tsys) = %s" % (len(freqHz), str(np.shape(tsys)))
        if (overlayTelcal):
            tsys_telcal = self.getTelcalTsys(antenna,spw,scan,pol)  # TelCal's result
            if (tsys_telcal == None):
                print "No Tsys result is available from TelCal "
                overlayTelcal = False
            else:
                pb.plot(freqHz*1e-9, tsys_telcal, 'g-', lw=1)
                if (fdmCorrection):
                    mylabel = ' FDM'
                else:
                    mylabel = ''
                pb.text(0.05,0.92,'TelCal'+mylabel,color='g',transform=adesc.transAxes) # ,weight='extra bold')
                pb.text(0.42,0.92,'casa'+mylabel,color='k',transform=adesc.transAxes)
                pb.hold(True)
            if (fdmCorrection or takeLoadsFromTdmDataset):
                if (tdmspw == None): tdmspw = spw
                if (tdmscan == None): tdmscan = scan
                if (tdmdataset == None):
                    tdmdataset = self
                tsysTDM = tdmdataset.getTelcalTsys(antenna,tdmspw,tdmscan,pol)  # TelCal's result for the TDM spectrum
                freqHzTDM = tdmdataset.chanfreqs[tdmspw]
                pb.plot(freqHzTDM*1e-9, tsysTDM, 'r-')
                pb.text(0.65,0.92, 'TelCal TDM (%s)' % (mjdsecToUTHMS(np.mean(tdmdataset.timerange[tdmscan]))),
                        color='r', transform=adesc.transAxes)
                tsysDiff = np.median(tsysTDM)-np.median(tsys)
                pb.text(0.42,0.84, 'diff %.1fK'%(tsysDiff),color='k',transform=adesc.transAxes)
                if (tsysDifferences is not None):
                  if (scan in self.IFProc[antenna][pol] and
                      scan in self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]]):
                    if ((tdmdataset.IFSwitch[antenna][pol][tdmdataset.sidebandsforspw[spw]][tdmscan] ==
                         self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]][scan]) and
                        (tdmdataset.IFProc[antenna][pol][tdmscan][tdmdataset.basebands[spw]-1] ==
                         self.IFProc[antenna][pol][scan][self.basebands[spw]-1])):
                        if (antenna not in tsysDifferences['antenna'].keys()):
                            tsysDifferences['antenna'][antenna] = []
                        if (spw not in tsysDifferences['spw'].keys()):
                            tsysDifferences['spw'][spw] = []
                        tsysDifferences['antenna'][antenna].append(tsysDiff)
                        tsysDifferences['spw'][spw].append(tsysDiff)

        pb.xlabel('Frequency (GHz)')
        pb.ylabel('Tsys (K)')
        if (plotrange != [0,0,0,0]):
            if (plotrange[0] != 0 or plotrange[1] != 0):
                pb.xlim(plotrange[:2])
            if (plotrange[2] != 0 or plotrange[3] != 0):
                pb.ylim(plotrange[2:])
        else:
            if (fdmCorrection or takeLoadsFromTdmDataset):
                pb.xlim([np.min(freqHzTDM)*1e-9, np.max(freqHzTDM)*1e-9])
                pb.ylim([np.min([np.min(tsys), np.min(tsys_telcal), np.min(tsysTDM)]), np.max([np.max(tsys),np.max(tsys_telcal),np.max(tsysTDM)])])
            else:
                pb.xlim([np.min(freqHz)*1e-9, np.max(freqHz)*1e-9])
                pb.ylim([np.min([np.min(tsys), np.min(tsys_telcal)]), np.max([np.max(tsys),np.max(tsys_telcal)])])
            y0,y1 = pb.ylim()
            if (y0 < 0 and y0 > -100000): y0 = 0
            pb.ylim([y0,y1+(y1-y0)*0.2])
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        ut = mjdsecToUTHMS(self.meantime[scan])
        pb.draw()
        if (plotfile == '' or plotfile==True):
            png = os.path.basename(self.vis) + '.%s.scan%02d.spw%02d.pol%d.tsys_trx.png' % (antennaName,scan,spw,pol)
        else:
            png = plotfile
        pb.savefig(png)
        print "Result left in ", png
        return png

    def computeTsys(self, scan, antenna, pol, spw, tdmspw=None, asdm=None, etaF=0.98, lo1=None,
                    dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                    siteAltitude_m=5000, computeJsky=True, altscan=None, ignoreFlags=False,
                    calscandict=None, fdmCorrection=False, tdmscan=None, tdmdataset=None,
                    takeLoadsFromTdmDataset=False, showplot=False, atmosphere=None):
        """
        Computes FDM Tsys from an FDM CALIBRATE_ATMOSPHERE scan by applying
        quantization correction using either a prior calscan in a TDM spw or
        the concurrent scan in an SQLD spw.
        tdmspw:  the spw from which to get the total power in order to apply fdmCorrection
        tdmscan: the scan from which to get the data from the tdmspw in order to apply fdmCorrection
        tdmdataset: the Atmcal instance for the dataset containing the TDM scans
        takeLoadsFromTdmDataset: set to True to use the hot/amb from one dataset, and sky from another
            So, to compute new TDM Tsys for dataset1 using the TDM hot/amb from dataset2,
            set tdmdataset=Atmcal(dataset2), self=Atmcal(dataset1), with fdmCorrection=False.
        fdmCorrection: if True, apply FDM quantization correction
        atmosphere: dictionary keyed by 'signal', 'image', with values returned by
                    au.CalcAtmosphere()
        Returns 5 masked arrays and a dict:  tsys, freqHz, trec, tsky, tcal, atmosphere
        """
        spw = int(spw)
        if (spw == 'auto'):
            spw = self.spwsforscan[scan][0]
            print "Choosing spw = %d" % (spw)
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (self.unrecognizedSpw(spw)): return
        if (spw not in self.spwsforscan[scan]):
            print "spw %d is not in scan %d.  Available spws are: %s" % (spw, scan, str(self.spwsforscan[scan]))
            return
        result = self.computeTrec2(scan, antenna, pol, spw, tdmspw,
                                   asdm, etaF, lo1,dataFraction,
                                   parentms, verbose, siteAltitude_m,
                                   computeJsky, altscan,ignoreFlags=ignoreFlags,
                                   calscandict=calscandict, fdmCorrection=fdmCorrection,
                                   tdmscan=tdmscan, tdmdataset=tdmdataset,
                                   takeLoadsFromTdmDataset=takeLoadsFromTdmDataset, 
                                   showplot=showplot, atmosphere=atmosphere)
        if (result == None):
            print "No result from computeTrec2()"
            return(None)
        if (computeJsky):
            trec, gain, tsky, freqHz, tcal, tsys, atmosphere = result
            return(tsys, freqHz, trec, tsky, tcal, atmosphere)
        else:
            trec, gain, tsky, freqHz = result
            return(result)

    def generateHighResTsysTable(self, oldcaltable='', newcaltable='', 
                                 maxRows=-1, maxScans=-1, verbose=False, 
                                 showplots=False, keepLowRes=True, 
                                 simulateTDMTsysScan=-1, showplotLoads=False, 
                                 writeNewLowResSpectrum=False, antenna='',
                                 spw='', filterOrder=8, showpoints=True,
                                 separateFigures=False, scan='', maxAltitude=60,
                                 s=0, mode='difference', highresEB='', pwv=None):
        """
        Takes an existing TDM Tsys table for the active measurement set that 
        contains FDM science data scans, and builds a high resolution version 
        of the Tsys spectra using the atmospheric model and an upsampled
        version of the Trx spectra, producing one resampled Tsys spw 
        per science spw.
        oldcaltable: name of existing TDM Tsys table to read
        newcaltable: name for new FDM Tsys table to write
        maxRows: if > 0, then limit the number of rows processed
        maxScans: if > 0, then limit the number of scans processed
        keepLowRes: if True, then also copy the low resolution Tsys solutions 
            to the new table
        simulateTDMTsysScan: if > 0, then smooth the high-res Tsys scan data 
            to this many channels before using it
        writeNewLowResSpectrum: if True, and simulateTDMTsysScan<=0, then instead 
           of copying the existing low-res spectrum from the old table to the new, 
           write the newly-calculated low-res spectrum;   if simulateTDMTsysScan>0,
           then write another new cal table containing the simulated TDM Tsys result
        antenna: if specified, then restrict new caltable to this list of 
            antennas (python list of IDs, or comma-delimited string of names)
        scan: if specified, then restrict to these scans (python list of integers,
             single integer, or comma-delimited string)
        showplots: passed to simulateHighResTsys
        s: smoothing parameter passed to scipy.interpolate.UnivariateSpline when
           up-interpolating to high-res Tsys again
        mode: 'model', 'data', 'ratio', or 'difference' (passed to simulateHighResTsys)
        maxAltitude: of the atmosphere, in km
        highresEB: if the high-resolution data is in a different EB from the TDM Tsys
          scan, then set this parameter to the former
        pwv: if specified, then use this value to override what was in the ASDM
        Note: the ATM model spectrum is Hanning smoothed if self.hanningSmoothed[spw] == True,
            which is set automatically upon initialization of the Atmcal class.  To override
            this feature, one can set that dictionary entry to True or False before calling
            this function.
        """
        # loop over scan, spw, antenna, pol
        if oldcaltable == '':
            oldcaltable = self.vis + '.tsys'
            if not os.path.exists(oldcaltable):
                print "You must specify the existing Tsys table name."
                return
            print "Using ", oldcaltable
        if highresEB != '':
            print "Creating new caltable for: ", highresEB
            newcaltable = createTsysTable(highresEB, newcaltable)
        else:
            newcaltable = createTsysTable(self.vis, newcaltable)
        siteAltitude_m = getObservatoryAltitude(getObservatoryName(self.vis))
        mytbold = createCasaTool(tbtool)
        mytbnew = createCasaTool(tbtool)
        mytblowres = createCasaTool(tbtool)
        if writeNewLowResSpectrum and simulateTDMTsysScan > 0:
            lowrescaltable = createTsysTable(self.vis, newcaltable+'_lowres')
            mytblowres.open(newcaltable+'_lowres', nomodify=False)
        print "Opening existing table: ", oldcaltable
        mytbold.open(oldcaltable)
        print "Opening new table:      ", newcaltable
        mytbnew.open(newcaltable, nomodify=False)
        nrows = mytbold.nrows()
        if (maxRows > 0):
            myrows = np.min([maxRows,nrows])
        else:
            myrows = nrows
        scienceSpws = {}
        atmLowRes = {}
        atmHighRes = {}
        myscans = list(self.scans)
        startTime = timeUtilities.time()
        scanNumberPerRow = mytbold.getcol('SCAN_NUMBER')
        timePerRow = mytbold.getcol('TIME')
        fieldPerRow = mytbold.getcol('FIELD_ID')
        spwPerRow = mytbold.getcol('SPECTRAL_WINDOW_ID')
        antennaPerRow = mytbold.getcol('ANTENNA1')
        intervalPerRow = mytbold.getcol('INTERVAL')
        obsidPerRow = mytbold.getcol('OBSERVATION_ID')
        print "spws in the caltable: ", np.unique(spwPerRow)
        newrows = 0
        if antenna != '':
            antennaList = parseAntenna(self.vis, antenna, self.mymsmd)
            print "Processing antenna IDs: ", antennaList
        if spw != '':
            spwList = parseSpw(self.vis, spw, self.mymsmd)
            print "Processing spw IDs: ", spwList
        if scan != '':
            if type(scan) == str:
                scansRequested = [int(i) for i in scan.split(',')]
            elif type(scan) == list:
                scansRequested = scan
            else:
                scansRequested = [scan]
        else:
            scansRequested = myscans
        print "Processing scans: ", scansRequested
        for i in range(myrows):
            if i % 10 == 0:
                line =  "***** Working row %d/%d *****" % (i+1,myrows)
            if antenna != '':
                if antennaPerRow[i] not in antennaList:
                    continue
            if spw != '':
                if spwPerRow[i] not in spwList:
                    continue
            if scansRequested != '':
                if scanNumberPerRow[i] not in scansRequested:
                    continue
            if i > 10:
                eta = (timeUtilities.time()-startTime)*(myrows-i)/(3600.*i)
                if maxScans > 0:
                    eta *= maxScans/float(len(myscans))
                line += "***** ETA: %.2f hours *****" % (eta)
            if i % 10 == 0:
                print line
            scan = scanNumberPerRow[i]
            if (myscans.index(scan) >= maxScans and maxScans > 0):
                print "Stopping due to maxScans."
                break
            mytime = timePerRow[i]
            field = fieldPerRow[i]
            antennaID = antennaPerRow[i]
            if field not in self.radec:
                self.radec[field] = getRADecForField(self.vis, field, usemstool=True, mymsmd=self.mymsmd)
            spwid = spwPerRow[i]
            if spwid not in scienceSpws:
                scienceSpws[spwid] = inverseTsysspwmapWithNoTable(self.vis, field, spwid, mymsmd=self.mymsmd,
                                                                  alternateIntents=['OBSERVE_TARGET#ON_SOURCE',
                                                                                    'CALIBRATE_AMPLI#ON_SOURCE'])
                print "Tsys spw %d: science spws = " % (spwid), scienceSpws[spwid]
            defaultError = 0.1
            defaultSNR = 1.0
            if keepLowRes:
                myspws = sorted(np.unique([spwid] + scienceSpws[spwid]))
            else:
                myspws = sorted(np.unique(scienceSpws[spwid]))
            for myspw in myspws:
                tsys = mytbold.getcell('FPARAM', i)
                if scan not in atmLowRes.keys():
                    atmLowRes[scan] = {}
                if spwid not in atmLowRes[scan]:
                    atmLowRes[scan][spwid] = None
                if scan not in atmHighRes.keys():
                    atmHighRes[scan] = {}
                if myspw not in atmHighRes[scan].keys():
                    atmHighRes[scan][myspw] = None
                mytbnew.addrows(1)
                mytbnew.putcell('SPECTRAL_WINDOW_ID',newrows,myspw)
                mytbnew.putcell('TIME',newrows,mytime)
                mytbnew.putcell('FIELD_ID',newrows,field)
                mytbnew.putcell('ANTENNA1',newrows,antennaID)
                mytbnew.putcell('ANTENNA2',newrows,antennaID)
                mytbnew.putcell('INTERVAL',newrows,intervalPerRow[i])
                mytbnew.putcell('SCAN_NUMBER',newrows,scan)
                mytbnew.putcell('OBSERVATION_ID', newrows, obsidPerRow[i])
                if writeNewLowResSpectrum and simulateTDMTsysScan > 0:
                    mytblowres.addrows(1)
                    mytblowres.putcell('SPECTRAL_WINDOW_ID',newrows,myspw)
                    mytblowres.putcell('TIME',newrows,mytime)
                    mytblowres.putcell('FIELD_ID',newrows,field)
                    mytblowres.putcell('ANTENNA1',newrows,antennaID)
                    mytblowres.putcell('ANTENNA2',newrows,antennaID)
                    mytblowres.putcell('INTERVAL',newrows,intervalPerRow[i])
                    mytblowres.putcell('SCAN_NUMBER',newrows,scan)
                    mytblowres.putcell('OBSERVATION_ID', newrows, obsidPerRow[i])
                npol = len(np.shape(tsys))
                trec = {}
                gain = {}
                tsky = {}
                tcal = {}
                tsysHighRes = {}
                tsysLowRes = {}
                for j in range(npol):
                    trec[j] = []
                    gain[j] = []
                    tsky[j] = []
                    tcal[j] = []
                    tsysHighRes[j] = []
                    tsysLowRes[j] = []
                if myspw != spwid or highresEB != '':
                    print "Working on FDM spw %d for ant%2d=%s in %s" % (myspw, antennaID, self.antennaNames[antennaID], highresEB)
                    newFDMFrequencyAxis = getChanFreqFromCaltable(newcaltable, myspw) * 1e9
                    for j in range(npol): 
                        result = self.simulateHighResTsys(scan, antennaID, j, spwid, myspw, atmosphereLowRes=atmLowRes[scan][spwid], atmosphereHighRes=atmHighRes[scan][myspw], verbose=verbose, showplot=showplots, filterOrder=filterOrder, showpoints=showpoints, separateFigures=separateFigures, maxAltitude=maxAltitude, s=s, mode=mode, highresEB=highresEB, newFDMFrequencyAxis=newFDMFrequencyAxis, pwv=pwv, siteAltitude_m=siteAltitude_m)
                        if result is None:
                            return
                        trec[j], gain[j], tsky[j], newfreqHz, tcal[j], tsysHighRes[j], atmLowRes[scan][spwid], atmHighRes[scan][myspw], tsysLowRes[j] = result
                    channel0 = getChanFreqFromCaltable(newcaltable, myspw, 0)
                    finalchannel = getChanFreqFromCaltable(newcaltable, myspw, -1)
                    if verbose:
                        print "start: newfreqGHz[0]=%f  spw%dFreq[0]=%f, diff=%f, meanfreq=%f" % (newfreqHz[0]*1e-9, myspw, channel0, (newfreqHz[0]*1e-9)-channel0, getSpwMeanFreqFromCaltable(newcaltable,myspw))
                        print "  end: newfreqGHz[-1]=%f  spw%dFreq[-1]=%f, meanfreq=%f" % (newfreqHz[-1]*1e-9, myspw, finalchannel, getSpwMeanFreqFromCaltable(newcaltable,myspw))
                        idx = np.argmax(tsky[0])
                        print "generateHighResTsysTable(): Peak tsky[0]=%f at freq=%f at idx=%d" % (tsky[0][idx], newfreqHz[idx], idx)
                        idx = np.argmax(tsysHighRes[0])
                        print "generateHighResTsysTable(): Peak tsys[0]=%f at freq=%f at idx=%d" % (tsysHighRes[0][idx], newfreqHz[idx], idx)
                        caltableFreq = getChanFreqFromCaltable(newcaltable, myspw, idx)
                        print "                            channel %d in SPECTRAL_WINDOW table of caltable = %fGHz, diff=%fGHz" % (idx, caltableFreq, newfreqHz[idx]*1e-9-caltableFreq)
                        if highresEB != '':
                            mymsmd = createCasaTool(msmdtool)
                            mymsmd.open(highresEB)
                            msFreq = mymsmd.chanfreqs(myspw)[idx] * 1e-9
                            mymsmd.close()
                            print "                            channel %d in SPECTRAL_WINDOW table of ms       = %fGHz, diff=%fGHz" % (idx, msFreq, newfreqHz[idx]*1e-9 - msFreq)
                    if npol == 0:
                        tsys = np.array([tsysHighRes[0]])
                        tsysLowRes = np.array([tsysLowRes[0]])
                    else:
                        tsys = np.array([tsysHighRes[0],tsysHighRes[1]])
                        tsysLowRes = np.array([tsysLowRes[0],tsysLowRes[1]])
                    if writeNewLowResSpectrum:
                        # print "Writing the low-res spectrum"
                        mytbnew.putcell('FLAG', i, tsysLowRes<0)
                        mytbnew.putcell('FPARAM', i, tsysLowRes)
                        mytbnew.putcell('SNR', i, defaultSNR*tsysLowRes/tsysLowRes)
                        mytbnew.putcell('PARAMERR', i, defaultError*tsysLowRes/tsysLowRes)
                    else:
                        # print "Writing the new high-res spectrum"
                        mytbnew.putcell('FLAG', newrows, tsys<0)
                        mytbnew.putcell('FPARAM', newrows, tsys)
                        mytbnew.putcell('SNR', newrows, defaultSNR*tsys/tsys)
                        mytbnew.putcell('PARAMERR', newrows, defaultError*tsys/tsys)
                elif simulateTDMTsysScan > 0:
                    for j in range(npol):
                        print "Calling simulateHighResTsys(simulateTDMTsysScan=%d, pol=%d, antenna=%d)" % (simulateTDMTsysScan, j, antennaID)
                        result = self.simulateHighResTsys(scan, antennaID, j, spwid, myspw, atmosphereLowRes=atmLowRes[scan][spwid], atmosphereHighRes=atmHighRes[scan][myspw], verbose=verbose, showplot=showplots, simulateTDMTsysScan=simulateTDMTsysScan, showplotLoads=showplotLoads, filterOrder=filterOrder, showpoints=showpoints, separateFigures=separateFigures, maxAltitude=maxAltitude, s=s, mode=mode, newFDMFrequencyAxis=newFDMFrequencyAxis, pwv=pwv, siteAltitude_m=siteAltitude_m)
                        if result is None:
                            return
                        trec[j], gain[j], tsky[j], newfreqHz, tcal[j], tsysHighRes[j], atmLowRes[scan][spwid], atmHighRes[scan][myspw], tsysLowRes[j] = result
                    if npol == 0:
                        tsys = np.array([tsysHighRes[0]])
                        tsysLowRes = np.array([tsysLowRes[0]])
                    else:
                        tsys = np.array([tsysHighRes[0],tsysHighRes[1]])
                        tsysLowRes = np.array([tsysLowRes[0],tsysLowRes[1]])
                    mytbnew.putcell('FLAG', newrows, tsys<0)
                    mytbnew.putcell('FPARAM', newrows, tsys)
                    mytbnew.putcell('SNR', newrows, defaultSNR*tsys/tsys)
                    mytbnew.putcell('PARAMERR', newrows, defaultError*tsys/tsys)
                    if writeNewLowResSpectrum:
                        print "Writing the low-res spectrum, row %d" % (i)
                        mytblowres.putcell('FLAG', newrows, tsysLowRes<0)
                        mytblowres.putcell('FPARAM', newrows, tsysLowRes)
                        mytblowres.putcell('SNR', newrows, defaultSNR*tsysLowRes/tsysLowRes)
                        mytblowres.putcell('PARAMERR', newrows, defaultError*tsysLowRes/tsysLowRes)
                else:
                    print "Copying the existing Tsys spw (%d) to the output table." % (spwid)
                    mytbnew.putcell('FLAG', newrows, mytbold.getcell('FLAG',i))
                    mytbnew.putcell('FPARAM', newrows, tsys)
                    mytbnew.putcell('SNR', newrows, mytbold.getcell('SNR',i))
                    mytbnew.putcell('PARAMERR', newrows, mytbold.getcell('PARAMERR',i))
                newrows += 1
        mytbold.close()
        mytbnew.close()
        if writeNewLowResSpectrum and simulateTDMTsysScan > 0:
            mytblowres.close()
            for spw in spwList:
                nchan = getNChanFromCaltable(newcaltable+'_lowres', spw)
                spwtable = newcaltable+'_lowres/SPECTRAL_WINDOW'
                print "Calling smoothSpectralWindowTable('%s', %d, %d)" % (spwtable, spw, nchan/simulateTDMTsysScan)
                smoothSpectralWindowTable(spwtable, spw, nchan/simulateTDMTsysScan)
        print "total time = %.1f seconds" % (timeUtilities.time() - startTime)
        return

    def simulateHighResTsys(self, scan, antenna, pol, spw, fdmspw, asdm=None, etaF=0.98, 
                            lo1=None, dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                            siteAltitude_m=5000, altscan=None, ignoreFlags=False,
                            tdmscan=None, tdmdataset=None, showplot=True,
                            showplotLoads=False, atmosphereLowRes=None, atmosphereHighRes=None,
                            showpoints=False, simulateTDMTsysScan=-1, 
                            plotedge=10, listpeak=False, filterOrder=8, 
                            separateFigures=False, maxAltitude=60, s=0, mode='difference',
                            highresEB='', newFDMFrequencyAxis=None, pwv=None):
        """
        For a specified scan, antenna, pol, spw in the current caltable, 
        takes the low-resolution Trx spectrum and predicts a high resolution
        Trx and Tsys using the atmospheric model for this spw.  Trims resulting
        spectra to match the extent of the FDM spectrum.
        scan: integer or string
        antenna: integer ID, string ID or string name
        pol: 0 or 1, integer or string
        spw: Tsys spw (integer or string integer)
        fdmspw: science spw (integer or string integer), only the channel 
                width is used
        simulateTDMTsysScan: if > 0, then smooth the high-res Tsys scan data 
                to this many channels
        plotedge: skip this many edge channels when plotting Tsys
        separateFigures: if True, then open a new gui for each figure
        s: smoothing parameter passed to scipy.interpolate.UnivariateSpline when
          up-interpolating to high-res Tsys again
        mode: 'model', 'data', 'ratio', or 'difference'
        maxAltitude: of the atmosphere, in km
        highresEB: if the high-resolution data is in a different EB from the TDM Tsys
          scan, then set this parameter to the former
        newFDMFrequencyAxis: use this spectral grid to compute Tsys (e.g. from the proto-caltable)
        pwv: if specified, then use this value to override what was in the ASDM
        filterOrder: only used in simulating a TDM Tsys scan from a higher resolution one (e.g. ACA)
        Returns: trec, gain, tsky, freqHz, tcal, tsys, atmosphereLowRes, atmosphereHighRes, tsysLowRes
                  1D,   1D,   1D,    1D,    2D,  2D,   dictionary, dictionary, 2D
        Note: the ATM model spectrum is Hanning smoothed if self.hanningSmoothed[spw] == True,
            which is set automatically upon initialization of the Atmcal class.  To override
            this feature, one can set that dictionary entry to True or False before calling
            this function.
        """
        if fdmspw != spw and verbose:
            print "FDM spw = %d, Tsys spw = %d" % (fdmspw, spw)
        if separateFigures:
            pb.close('all')
        figctr = 0
        spw = int(spw)  # allow string integers
        pol = int(pol)  # allow string integers
        if (self.nonExistentTable(self.vis+'/ASDM_CALATMOSPHERE')): return
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (self.unrecognizedSpw(spw)): return
        if showpoints:
#            print "Setting marker to ."
            marker = '.'
        else:
#            print "Setting marker to (None)"
            marker = ''
        antennaId, antennaName = self.getAntenna(antenna)
        p0 = self.getSpectrum(scan,spw,pol,'amb',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        if p0 is None:
            return
        p1 = self.getSpectrum(scan,spw,pol,'hot',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        sky = self.getSpectrum(scan,spw,pol,'sky',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        p0observed = p0
        p1observed = p1
        skyObserved = sky
        newFrequencyAxis = None
        if simulateTDMTsysScan > 0 and len(p0) not in [64,128,256]:
            mychanfreqs = self.mymsmd.chanfreqs(spw)
            window_len = len(p0) / simulateTDMTsysScan
            if verbose: print "Will smooth and decimate by %d with filter order %d" % (window_len, filterOrder)
            newFrequencyAxis, p0 = filterAndDecimate(mychanfreqs, p0, window_len, filterOrder)
            newFrequencyAxis, p1 = filterAndDecimate(mychanfreqs, p1, window_len, filterOrder)
            newFrequencyAxis, sky = filterAndDecimate(mychanfreqs, sky, window_len, filterOrder)
        else:
            if verbose: print "Not filtering since number of channels %d is in %s" % (len(p0),[64,128,256])
            newFrequencyAxis = self.mymsmd.chanfreqs(spw)
        computeJsky = True
        startTime = timeUtilities.time()
        if (len(newFrequencyAxis) % 2 == 0 and casaVersion < '5.0'):
            # adjust by half a channel so that output spectrum from atm 
            # will match what is in the spectral window table 
            print "******* applying half channel frequency offset because this is CASA < 5.0"
            freqOffset = 0.5*self.mymsmd.chanwidths(spw)[0]
        else:
            freqOffset = 0
        result = self.computeJs(scan, antenna, pol, spw, asdm, etaF, lo1,
                                dataFraction, parentms, verbose, siteAltitude_m,
                                computeJsky, altscan=altscan, atmosphere=atmosphereLowRes,
                                calscandict=self.calscandict, newFrequencyAxis=newFrequencyAxis-freqOffset,
                                maxAltitude=maxAltitude, pwv=pwv)
        if verbose: print "time spent in computeJs lowres = %.1f seconds" % (timeUtilities.time() - startTime)
        if (result is None):
            print "computeJs returned None. Aborting"
            return None
        if computeJsky:
            JskyLowRes, t0, t1, freqHz, jatmDSBLowRes, jspDSBLowRes, jbgLowRes, tauALowRes, alphaLowRes, gb, atmosphereLowRes, tebbskyLowRes = result
            tebbskyLowRes = tebbskyLowRes[0]*gb[0] + tebbskyLowRes[1]*gb[1]
        else:
            JskyLowRes, t0, t1, freqHz = result
        if (abs(freqHz[0] - newFrequencyAxis[0]) > 1):
            print "low-res input freq[0]=%f output[0]=%f diff=%f" % (freqHz[0], newFrequencyAxis[0], freqHz[0]-newFrequencyAxis[0])
        if verbose:
            print "len(newFrequencyAxis)=%d, len(p1)=%d, p0=%d, sky=%d, alphaLowRes=%d" % (len(newFrequencyAxis), len(p1),len(p0),len(sky),len(alphaLowRes))
        tcalLowRes, tsysLowRes = self.solveTsys(p1, p0, sky, jatmDSBLowRes, jbgLowRes, gb, alphaLowRes, tauALowRes, verbose)
        if verbose:
            print "lowres sky: min=%f, max=%f, p0: min=%f, max=%f;  p1: min=%f, max=%f" % (np.nanmin(sky), np.nanmax(sky), np.nanmin(p0), np.nanmax(p0), np.nanmin(p1), np.nanmax(p1))
        a = t1*p0 - t0*p1
        c = p1-p0
        b = t1-t0
        p0LowRes = p0
        p1LowRes = p1
        trecLowRes = a/c
        gainLowRes = c/b
        tskyLowRes = sky/gainLowRes - trecLowRes
        freqGHz = freqHz*1e-9
        suffix = 'spw%d_pol%d_%s' % (spw,pol,antennaName)
        plotTitle = self.vis + ', spw%d:%d, pol%d, scan%d, ant%d=%s' % (spw,fdmspw,pol,scan,antennaId,antennaName)
        if showplotLoads:
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            if verbose: print "shapes: ", np.shape(freqGHz), np.shape(sky), np.shape(p0), np.shape(p1)
            desc = pb.subplot(111)
            pb.plot(freqGHz, sky, 'b-')
            pb.hold(True)
            pb.plot(freqGHz, p0, 'k-')
            pb.plot(freqGHz, p1, 'r-', mec='r')
            if simulateTDMTsysScan > 0:
                pb.plot(mychanfreqs*1e-9, p0observed, 'k--')
                pb.plot(mychanfreqs*1e-9, p1observed, 'r--', mec='r')
                pb.plot(mychanfreqs*1e-9, skyObserved, 'b--', mec='r')
                asciifile = 'sky_hot_ambient.txt'
                f = open(asciifile,'w')
                for i in range(len(mychanfreqs)):
                    f.write('%f %f\n' % (mychanfreqs[i]*1e-9, p0observed[i]))
                f.close()
                print "wrote ", asciifile
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Counts')
            pb.title(plotTitle,size=12)
            pb.text(0.5,0.95,'Lowres: blue = sky,  red = hot_load,  black = ambient_load',
                    transform=desc.transAxes,ha='center')
            pb.text(0.75,0.01,'casa %s' % casadef.casa_version, transform=desc.transAxes)
            addDateToPlot()
            pb.draw()
            png = 'sky_hot_ambient_lowres_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png
#            showplotLoads = False
#            showplot = False

        xaxis = freqHz
        if simulateTDMTsysScan > 0:
            tdmfreqs = newFrequencyAxis
            tdmwidth = self.mymsmd.chanwidths(spw)[0]*self.mymsmd.nchan(spw)/len(newFrequencyAxis)
#            print "Scaling native chanwidth of %f by *%d/%d to get simulated TDM width = %f" % (self.mymsmd.chanwidths(spw)[0],self.mymsmd.nchan(spw),len(newFrequencyAxis),tdmwidth)
        else:
            tdmfreqs = self.mymsmd.chanfreqs(spw)    
            tdmwidth = self.mymsmd.chanwidths(spw)[0]  # this will be negative in LSB


        if highresEB == '':
            mymsmd = self.mymsmd
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(highresEB)
        fdmwidth = mymsmd.chanwidths(fdmspw)[0]     # these will be negative in LSB
        if verbose:
            print "fdmwidth=%f, tdmwidth=%f" % (fdmwidth,tdmwidth)

        if newFDMFrequencyAxis is None:
            # You should really be passing this in from the proto-caltable. But this was the old way
            # of doing it, which got within 11.66 MHz.
            # compute edge to edge TDM freq, then offset to middle of first high-res fdm channel
            freqstart = tdmfreqs[0] - 0.5*tdmwidth + 0.5*fdmwidth
            freqstop = tdmfreqs[-1] + 0.5*tdmwidth - 0.5*fdmwidth 
            newFDMFrequencyAxis = np.linspace(freqstart, freqstop, len(tdmfreqs)*tdmwidth/fdmwidth) 
        if verbose:
            print "Defined newFDMFrequencyAxis from %f to %f by %f (mean=%f)" % (newFDMFrequencyAxis[0], newFDMFrequencyAxis[-1], newFDMFrequencyAxis[1]-newFDMFrequencyAxis[0],np.mean(newFDMFrequencyAxis))
        fdmXaxis = newFDMFrequencyAxis # in Hz
        # Store the original spectra
        oldp0 = p0
        oldp1 = p1
        oldsky = sky

        # Resample the three original spectra to higher resolution
        # print "Resampling ambient,hot,sky to %d channels." % (len(fdmXaxis))
        if False:
            # spline method -- produces artifacts
            p0 = p0model(fdmXaxis)
            p1 = p1model(fdmXaxis)
            sky = skymodel(fdmXaxis)
            JskyLowResResampled = Jskymodel(fdmXaxis)
            tebbskyLowResResampled = tebbskymodel(fdmXaxis)
        else:
            reverse = False
            if xaxis[1] < xaxis[0]:
                # np.interp requires x-axis in increasing order
                reverse = True
                fdmXaxis = fdmXaxis[::-1]
                xaxis = xaxis[::-1]
                p0 = p0[::-1]
                p1 = p1[::-1]
                sky = sky[::-1]
                JskyLowRes = JskyLowRes[::-1]
                tebbskyLowRes = tebbskyLowRes[::-1]
            if verbose:
                if xaxis[0] < xaxis[1]:
                    print "spw %d: xaxis order is increasing" % (spw)
                else:
                    print "NOT EXPECTED !!!!  spw %d: xaxis order is decreasing" % (spw)
                if fdmXaxis[0] < fdmXaxis[1]:
                    print "spw %d: fdmXaxis order is increasing" % (spw)
                else:
                    print "NOT EXPECTED !!!!  spw %d: fdmXaxis order is decreasing" % (spw)
            p0 = np.interp(fdmXaxis, xaxis, p0)
            p1 = np.interp(fdmXaxis, xaxis, p1)
            sky = np.interp(fdmXaxis, xaxis, sky)
            JskyLowResResampled = np.interp(fdmXaxis, xaxis, JskyLowRes)
            tebbskyLowResResampled = np.interp(fdmXaxis, xaxis, tebbskyLowRes)
            if reverse:
                # Put them back to the original format
                xaxis = xaxis[::-1]
                fdmXaxis = fdmXaxis[::-1]
                p0 = p0[::-1]
                p1 = p1[::-1]
                sky = sky[::-1]
                JskyLowRes = JskyLowRes[::-1]
                tebbskyLowRes = tebbskyLowRes[::-1]
                # the following 2 lines were added on the plane
                JskyLowResResampled = JskyLowResResampled[::-1]
                tebbskyLowResResampled = tebbskyLowResResampled[::-1]
            if verbose:
                if xaxis[0] < xaxis[1]:
                    if fdmXaxis[0] < fdmXaxis[1]:
                        print "spw %d: xaxis and fdmXaxis orders match (increasing)" % (spw)
                    else:
                        print "NOT EXPECTED !!!!  spw %d: xaxis and fdmXaxis order is opposite" % (spw)
                if xaxis[0] > xaxis[1]:
                    if fdmXaxis[0] > fdmXaxis[1]:
                        print "spw %d: xaxis and fdmXaxis orders match (decreasing)" % (spw)
                    else:
                        print "NOT EXPECTED !!!!  spw %d: xaxis and fdmXaxis order is opposite" % (spw)
        if showplot:
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            pb.plot(fdmXaxis*1e-9,p0,'k-', fdmXaxis*1e-9,p1,'r-',fdmXaxis*1e-9,sky,'b-',
                    xaxis*1e-9,oldp0,'k--', xaxis*1e-9,oldp1,'r--',xaxis*1e-9,oldsky,'b--')
            pb.text(0.05,0.8,'solid: resampled to FDM',color='k',transform=desc.transAxes)
            pb.text(0.05,0.85,'dashed: smoothed to TDM',color='k',transform=desc.transAxes)
            if simulateTDMTsysScan > 0:
                pb.hold(True)
                pb.text(0.05,0.9,'dotted: observed',color='k',transform=desc.transAxes)
                pb.plot(mychanfreqs*1e-9,p0observed,'k:', mychanfreqs*1e-9,p1observed,'r:', 
                        mychanfreqs*1e-9,skyObserved,'b:')
            pb.xlabel('Frequency (GHz)')
            pb.title(plotTitle,size=12)
            pb.ylabel('Counts (before scaling the sky scan)')
            addDateToPlot()
            pb.draw()
            png = 'sky_hot_ambient_lowres_highres_%s.png' % (suffix)
            pb.savefig(png)

        # compute a higher resolution Jsky, Trec and Tsys
        startTime = timeUtilities.time()
        if (len(newFDMFrequencyAxis) % 2 == 0 and casaVersion < '5.0'):
            # adjust by half a channel so that output spectrum from atm 
            # will match what we want
            print "******* applying half channel frequency offset because this is CASA < 5.0"
            freqOffset = 0.5*fdmwidth  # note that fdmwidth will be negative in LSB spws
        else:
            freqOffset = 0
        result = self.computeJs(scan, antenna, pol, spw, asdm, etaF, lo1,
                                dataFraction, parentms, verbose, siteAltitude_m,
                                computeJsky, altscan=altscan, calscandict=self.calscandict, 
                                atmosphere=atmosphereHighRes, newFrequencyAxis=newFDMFrequencyAxis-freqOffset,
                                maxAltitude=maxAltitude, pwv=pwv)
        if verbose: print "time spent in computeJs highres = %.1f seconds" % (timeUtilities.time() - startTime)
        if computeJsky:
            JskyHighRes, t0, t1, ignorefreqHz, jatmDSB, jspDSB, jbg, tauA, alpha, gb, atmosphereHighRes, tebbsky = result
            tebbskyDSB = tebbsky[0]*gb[0] + tebbsky[1]*gb[1]
        else:
            JskyHighRes, t0, t1, ignorefreqHz = result

        if showplot:
            pb.clf()
            desc = pb.subplot(111)
            pb.plot(fdmXaxis*1e-9, tebbskyDSB,'k-', fdmXaxis*1e-9,tebbskyLowResResampled,'r-', 
                    xaxis*1e-9, tebbskyLowRes,'b-')
            pb.ylabel('TebbskyDSB')
            pb.xlabel('Frequency (GHz)')
            pb.title(plotTitle,size=12)
            pb.text(0.05,0.85,'high-res',color='k',transform=desc.transAxes)
            pb.text(0.05,0.80,'low-res resampled',color='r',transform=desc.transAxes)
            pb.text(0.05,0.75,'low-res',color='b',transform=desc.transAxes)
            addDateToPlot()
            pb.draw()
            png = 'tebbsky_lowres_highres_%s.png' % (suffix)
            pb.savefig(png) 

        if (abs(ignorefreqHz[0] - newFDMFrequencyAxis[0]) > 1):
            print "input freq[0]=%f output[0]=%f" % (newFDMFrequencyAxis[0], ignorefreqHz[0])
        if (abs(ignorefreqHz[-1] - newFDMFrequencyAxis[-1]) > 1):
            print "input freq[-1]=%f output[-1]=%f" % (newFDMFrequencyAxis[-1], ignorefreqHz[-1])
        newfreqGHz = newFDMFrequencyAxis*1e-9
        # ignorefreqGHz is equal to newfreGHz
        if showplot:
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(211)
            pb.plot(newfreqGHz, JskyHighRes, 'r-', freqGHz, JskyLowRes, 'k%s-'%marker, 
                    newfreqGHz, JskyLowResResampled, 'b%s-'%marker)
            pb.text(0.02,0.9,'low resolution (%d pts)'%(len(JskyLowRes)),color='k',transform=desc.transAxes)
            pb.text(0.02,0.85,'low resolution resampled',color='b',transform=desc.transAxes)
            pb.text(0.02,0.8,'high resolution (%d pts)'%(len(JskyHighRes)),color='r',transform=desc.transAxes)
            yFormatter = ScalarFormatter(useOffset=False)
            desc.xaxis.set_major_formatter(yFormatter)
            pb.xlim([np.min(newfreqGHz),np.max(newfreqGHz)])
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Jsky')
            pb.title(plotTitle,size=12)

            desc = pb.subplot(212)
            pb.plot(newfreqGHz, JskyHighRes-JskyLowResResampled, 'k-')
            desc.xaxis.set_major_formatter(yFormatter)
            pb.ylabel('Residual (JskyHighRes-LowResResampled)')
            pb.xlabel('Frequency (GHz)')
            pb.xlim([np.min(newfreqGHz),np.max(newfreqGHz)])
            addDateToPlot()
            pb.draw()
            png = 'jsky_lowres_highres_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png

            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            pb.plot(freqGHz, alphaLowRes, 'k-',newfreqGHz, alpha, 'r-')
            pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
            pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('alpha')
            pb.title(plotTitle,size=12)
            addDateToPlot()
            pb.draw()
            png = 'alpha_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png

            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            pb.plot(freqGHz, jatmDSBLowRes[0]*gb[0]+jatmDSBLowRes[1]*gb[1], 'k-',
                    newfreqGHz, jatmDSB[0]*gb[0]+jatmDSB[1]*gb[1], 'r-')
            pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
            pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('JatmDSB (sum of both sidebands)')
            pb.title(plotTitle,size=12)
            addDateToPlot()
            pb.draw()
            png = 'JatmDSB_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png

            if False:
                figctr += 1
                if separateFigures: pb.figure(figctr)
                pb.clf()
                desc = pb.subplot(111)
                pb.plot(freqGHz, jspDSBLowRes, 'k-',newfreqGHz, jspDSB, 'r-')
                pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
                pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
                pb.xlabel('Frequency (GHz)')
                pb.ylabel('JspDSB')
                pb.title(plotTitle,size=12)
                addDateToPlot()
                pb.draw()
                png = 'JspDSB_%s.png' % (suffix)
                pb.savefig(png)
                print "Wrote ", png

                figctr += 1
                if separateFigures: pb.figure(figctr)
                pb.clf()
                desc = pb.subplot(111)
                pb.plot(freqGHz, jbgLowRes[0], 'k-',newfreqGHz, jbg[0], 'r-')
                pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
                pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
                pb.xlabel('Frequency (GHz)')
                pb.ylabel('Jbg')
                pb.title(plotTitle,size=12)
                addDateToPlot()
                pb.draw()
                png = 'Jbg_%s.png' % (suffix)
                pb.savefig(png)
                print "Wrote ", png

            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            pb.plot(freqGHz, tauALowRes[0], 'k-', newfreqGHz, tauA[0], 'r-')
            pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
            pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('tauA')
            pb.title(plotTitle,size=12)
            addDateToPlot()
            pb.draw()
            png = 'tauA_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png

        if False:
            skyRatio = JskyHighRes/JskyLowResResampled
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            print "Ignoring %d edge pixels on each side" % (plotedge)
            pb.plot(newfreqGHz[plotedge:-plotedge], skyRatio[plotedge:-plotedge], 'k%s-'%marker)
            yFormatter = ScalarFormatter(useOffset=False)
            desc.yaxis.set_major_formatter(yFormatter)
            pb.title(plotTitle,size=12)
            pb.ylabel('Jsky ratio (highres / lowres)')
            pb.xlabel('Frequency (GHz)')
            addDateToPlot()
            png = 'Jsky_ratio_lowres_highres_%s.png' % (suffix)
            pb.draw()
            pb.savefig(png)
            print "Wrote ", png

        # compute higher resolution Trec and Tsys
        a = t1*p0 - t0*p1
        c = p1-p0
        b = t1-t0
        trec = a/c
        gain = c/b
        print "spw %d: Median gain = " % (spw), np.median(gain)
        if mode == 'data':
            # Try to transfer the high resolution features from atmospheric model (as encoded 
            # into JskyHighRes) into the sky scan
            skyIncrement = (JskyHighRes - JskyLowResResampled)*np.median(sky)/np.median(JskyLowResResampled)
            percentage = np.max(skyIncrement)*100/np.median(sky)
            print "Sky: median=%f,  max increment added: %f (%.3f%%)" % (np.median(sky), np.max(skyIncrement), percentage)
            sky += skyIncrement
            tsky = sky/gain - trec
        elif mode == 'ratio':
            tsky = sky/gain - trec
            # Compute high-resolution sky scan
            sky = (tsky*tebbskyDSB/tebbskyLowResResampled + trec)*gain  
            tsky = sky/gain - trec
        elif mode == 'difference':
            tsky = sky/gain - trec
            # Compute high-resolution sky scan: add full-res model and subtract low-res model
            sky = (tsky + tebbskyDSB - tebbskyLowResResampled + trec)*gain  
            tsky = sky/gain - trec
        elif mode == 'model':
            # Just use the Tsky from the model, and infer a theoretical sky spectrum
            tsky = tebbskyDSB
            print "**** Setting Tsky spectrum to signal sideband model, median = %f" % (np.median(tsky))
            sky = (tsky + trec)*gain
        if verbose: print "highres: sky: min=%f, max=%f, p0: min=%f, max=%f;  p1: min=%f, max=%f" % (np.nanmin(sky), np.nanmax(sky), np.nanmin(p0), np.nanmax(p0), np.nanmin(p1), np.nanmax(p1))

        tcal, tsys = self.solveTsys(p1, p0, sky, jatmDSB, jbg, gb, alpha, tauA, verbose)
        if showplot:
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            if verbose: print "Ignoring %d edge pixels on each side" % (plotedge)
            pb.plot(freqGHz[plotedge:-plotedge], tsysLowRes[plotedge:-plotedge], 'k%s-'%marker)
            n = len(tsysLowRes)/10
            idx = np.argmax(tsysLowRes[n:-n])
            if listpeak:
                print "peak of low-res spectrum:  %fK at %f GHz" % (tsysLowRes[idx+n],freqGHz[idx+n])
            pb.hold(True)
            pb.plot(newfreqGHz[plotedge:-plotedge], tsys[plotedge:-plotedge], 'r%s-'%marker, mec='r')
            n = len(tsys)/10
            idx = np.argmax(tsys[n:-n])
            if listpeak:
                print "peak of high-res spectrum: %fK at %f GHz" % (tsys[idx+n],newfreqGHz[idx+n])
            pb.text(0.1,0.9,'low resolution',color='k',transform=desc.transAxes)
            pb.text(0.1,0.8,'high resolution',color='r',transform=desc.transAxes)
            pb.title(plotTitle,size=12)
            pb.ylabel('Tsys (K)')
            pb.xlabel('Frequency (GHz)')
            addDateToPlot()
            pb.draw()
            png = 'Tsys_lowres_highres_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png
        if showplotLoads:
            figctr += 1
            if separateFigures: pb.figure(figctr)
            pb.clf()
            desc = pb.subplot(111)
            if verbose: print "shapes: ", np.shape(freqGHz), np.shape(sky), np.shape(p0), np.shape(p1)
            pb.plot(newfreqGHz, sky, 'b-', newfreqGHz, p0, 'k-', newfreqGHz, p1, 'r-')
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Counts (after scaling the sky scan)')
            pb.title(plotTitle,size=12)
            pb.text(0.5,0.95,'Highres: blue = sky,  red = hot_load,  black = ambient_load',transform=desc.transAxes,ha='center')
            addDateToPlot()
            pb.draw()
            png = 'sky_hot_ambient_highres_%s.png' % (suffix)
            pb.savefig(png)
            print "Wrote ", png
            pb.clf()
            pb.plot(xaxis*1e-9, oldsky, 'k-', newfreqGHz, sky, 'r-')
            pb.text(0.5,0.95,'Low-res sky: black,  high-res sky: red',transform=desc.transAxes,ha='center')
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Sky counts')
            pb.title(plotTitle,size=12)
            addDateToPlot()
            pb.draw()
            png = 'oldsky_newsky_%s.png' % (suffix)
            print "Wrote ", png
            pb.savefig(png)

        fdmnchan = mymsmd.nchan(fdmspw)
        if highresEB != '':
            mymsmd.close()
        edge = (len(trec)-fdmnchan)/2
        # Note that a 468 MHz spw will require 16384 channels to span, so literally
        # thousands of channels need to be trimmed from each side for narrow FDM spws.
        if edge > 0:
            trec = trec[edge:-edge]
            if verbose:
                print "Trimming %d pixels from each edge to be width = %d" % (edge,len(trec))
            tsky = tsky[edge:-edge]
            tsys = tsys[edge:-edge]
            tcal = tcal[edge:-edge]
            newFDMFrequencyAxis = newFDMFrequencyAxis[edge:-edge]
        if verbose:
            idx = np.argmax(tsky)
            print "simulateHighResTsys(): Peak Tsky=%f at freq=%f" % (tsky[idx], newFDMFrequencyAxis[idx])
        return(trec, gain, tsky, newFDMFrequencyAxis, tcal, tsys, atmosphereLowRes, atmosphereHighRes, tsysLowRes)

    def joinNearbyWindows(self, selection, signal=None, sigma=0, verbose=False):
        """
        Takes [1,2,3,4,5,8,9,10,11] and converts to [1,2,3,4,5,6,7,8,9,10,11], i.e. removes the gap
        if mean of the signal[6:7] minues mean of the signal[4,5,8,9]
        is more than sigma*np.std([4,5,8,9])
        selection: a list or array of consecutive integer values that must be within 0..len(signal)-1
        signal: a list or array of all y-axis values (with no gaps)
        sigma: if > 0, then only join if gapSignal is larger than sigma*std, otherwise join if 
            gap is narrower than both neighbors
        """
        if signal is not None:
            signal = np.array(signal) # e.g. [0,1,1,1,1,1,5,5,1,2,3,4]   of length 12
        idxs = splitListIntoContiguousLists(selection)
        droppedWindows = 0
        newselection = []
        skipNext = False
        for i in range(len(idxs)-1):
            if skipNext:
                skipNext = False
                continue
            idx = idxs[i]        # e.g. [1,2,3,4,5]
            nextidx = idxs[i+1]  # e.g. [8,9,10,11]
            gapWidth = nextidx[0]-idx[-1]-1  # eg. 2
            if sigma > 0:
                x0 = np.max([0,len(idx)-gapWidth])  # e.g.  3  idx[3] = 4
                x1 = np.min([len(nextidx)-1, gapWidth])  # e.g. 2 nextidx[2] = 10
                leftside = signal[idx[x0]:idx[x0]+gapWidth] #  [1,1]
                rightside = signal[nextidx[:x1]]            #  [1,2]
                sides = list(leftside) + list(rightside)    #  [1,1,1,2]
                gap = np.arange(idx[-1]+1, nextidx[0])      #  [6,7]
                if verbose: print "gap=%s" % (str(gap))
                gapSignal = np.mean(signal[gap])        #  5.0
                gapNetSignal = gapSignal - np.mean(sides)  # 3.75
                drop = gapNetSignal > sigma*np.std(sides)    #  3.75 > sigma*0.433  True
                if verbose: 
                    print "gapSignal=%f  gapNetSignal=%f  gapNetSignal/std = %f" % (gapSignal, gapNetSignal, gapNetSignal/np.std(sides))
            else:
                if len(idx) > gapWidth and len(nextidx) > gapWidth:
                    drop = True
                else:
                    drop = False
            if drop:
                newselection += range(idx[0],nextidx[-1]+1)
                droppedWindows += 1
                skipNext = True
            else:
                newselection += idx
                if i == len(idxs)-2:
                    newselection += nextidx
        if droppedWindows > 0: 
            print "Dropped %d/%d windows because they were narrow." % (droppedWindows,len(idxs))
#        print "n=%d, unique=%d" % (len(newselection), len(np.unique(newselection)))
        newselection = np.unique(newselection)
        return newselection

    def computeTrec2(self, scan, antenna, pol, spw, tdmspw=None, asdm=None, etaF=0.98, lo1=None,
                     dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                     siteAltitude_m=5059, computeJsky=False, altscan=None,ignoreFlags=False,
                     calscandict=None, fdmCorrection=False, tdmscan=None, tdmdataset=None,
                     takeLoadsFromTdmDataset=False, showplot=False, atmosphere=None):
        """
        Compute Trec and saturation parameter from a 2-load measurement.
        This is the normal ALMA calibration procedure. The formula is:
        p = G * (tRec+t)
        If computeJsky is True, then it also computes Tsys.
        """
        spw = int(spw)
        if (self.nonExistentTable(self.vis+'/ASDM_CALATMOSPHERE')): return
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
        p0 = self.getSpectrum(scan,spw,pol,'amb',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        p1 = self.getSpectrum(scan,spw,pol,'hot',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        sky = self.getSpectrum(scan,spw,pol,'sky',antennaId,dataFraction,ignoreFlags=ignoreFlags)
        print "sky: min=%f, max=%f, p0: min=%f, max=%f;  p1: min=%f, max=%f" % (np.nanmin(sky), np.nanmax(sky), np.nanmin(p0), np.nanmax(p0), np.nanmin(p1), np.nanmax(p1))
        if (takeLoadsFromTdmDataset):
            tdmAntennaId, antennaName = tdmdataset.getAntenna(antennaName)
            print "Translated %s from id=%d in one dataset to %d in the other (%s)" % (antennaName,antennaId,tdmAntennaId,antennaName)
            amb = tdmdataset.getSpectrum(tdmscan,tdmspw,pol,'amb',tdmAntennaId,dataFraction,ignoreFlags=ignoreFlags)
            hot = tdmdataset.getSpectrum(tdmscan,tdmspw,pol,'hot',tdmAntennaId,dataFraction,ignoreFlags=ignoreFlags)
            scalingFactor = np.median(amb)/np.median(p0)
            p0 = amb
            p1 = hot
            print "Applying scaling factor %f = %.2f dB to the sky subscan." % (scalingFactor, 10*np.log10(scalingFactor))
            sky *= scalingFactor
        if (fdmCorrection):
            if (tdmscan == None): tdmscan = scan
            if (tdmspw == None): tdmspw = spw
            if (tdmdataset == None):
                tdmdataset = self
            tdmSpectrumAmb = tdmdataset.getSpectrum(tdmscan,tdmspw,pol,'amb',antennaId,dataFraction,ignoreFlags=ignoreFlags)
            tdmSpectrumHot = tdmdataset.getSpectrum(tdmscan,tdmspw,pol,'hot',antennaId,dataFraction,ignoreFlags=ignoreFlags)
            tdmSpectrumSky = tdmdataset.getSpectrum(tdmscan,tdmspw,pol,'sky',antennaId,dataFraction,ignoreFlags=ignoreFlags)
            print "Applying FDM correction using %d-channel total power" % (len(tdmSpectrumAmb))
            p0 = self.applyCorrectionToFDMSpectrum(p0, tdmSpectrumAmb, tdmSpectrumAmb)
            p1 = self.applyCorrectionToFDMSpectrum(p1, tdmSpectrumHot, tdmSpectrumHot)
            sky = self.applyCorrectionToFDMSpectrum(sky, tdmSpectrumSky, tdmSpectrumSky)
        if (type(p0) != np.ndarray and type(p0) != np.ma.core.MaskedArray):
            print "type(p0) = %s, len(p0) = %d" % (str(type(p0)), len(p0))
            return None
        result = self.computeJs(scan, antenna, pol, spw, asdm, etaF, lo1,
                                dataFraction, parentms, verbose, siteAltitude_m,
                                computeJsky, altscan=altscan, 
                                calscandict=calscandict, atmosphere=atmosphere)
        if (computeJsky):
#            skyResult, t0, t1, freqHz, jatmDSB, jspDSB, jbg, tauA, alpha, gb, atmosphere = result
#            tcal, tsys = self.solveTsys(p1, p0, sky, jatmDSB, jbg, gb, alpha, tauA, verbose)
            skyResult, t0, t1, freqHz, jatm, jspDSB, jbg, tauA, alpha, gb, atmosphere, tebbsky = result
            tcal, tsys = self.solveTsys(p1, p0, sky, jatm, jbg, gb, alpha, tauA, verbose)
        else:
            skyResult, t0, t1, freqHz = result
        a = t1*p0-t0*p1
        c = p1-p0
        b = t1-t0
        trec = a/c
        gain = c/b
        print "mean gain (deltaLoadPower/deltaT) = %f counts/Kelvin" % (np.mean(gain))
        tsky = sky/gain - trec
        if (showplot):
            freqGHz = freqHz*1e-9
            pb.clf()
            pb.plot(freqGHz, sky, 'b-', freqGHz, p0, 'k-', freqGHz, p1, 'r-')
            pb.xlabel('Frequency (GHz)')
            pb.ylabel('Counts')
            pb.title('blue = sky,  red = hot_load,  black = ambient_load')
            pb.draw()
        if (computeJsky):
            return(trec, gain, tsky, freqHz, tcal, tsys, atmosphere)
        else:
            return(trec, gain, tsky, freqHz)

    def plotTrec2All(self, spw, tdmspw=None, asdm=None, etaF=0.98, lo1=None,
                     dataFraction=[0.0, 1.0], parentms=None, siteAltitude_m=5059):
        spw = int(spw)
        pngs = []
        if (self.unrecognizedSpw(spw)): return
        for scan in self.scans:
            print "Working on scan ", scan
            for antenna in self.antennas:
                print "Working on antenna %d/%d" % (antenna+1,len(self.antennas))
                for pol in range(2):
                    png = self.plotTrec2(scan,antenna,pol,spw, tdmspw, asdm, etaF, lo1,
                                         dataFraction, parentms, siteAltitude_m=siteAltitude_m)
                    if (png is not None):
                        pngs.append(png)
        buildPdfFromPngs(pngs, pdfname='%s.trec2.pdf'%(self.vis))

    def plotTsysTrec2AllMedian(self, spw=None, scans=None, tdmspw=None, asdm=None, 
                               antennas=None, etaF=0.98, lo1=None,
                               dataFraction=[0.0, 1.0], parentms=None, siteAltitude_m=5059,
                               fdmCorrection=False, tdmscan=None, tdmdataset=None, showAttenuators=False,
                               buildPDF=True, verbose=False):
        """
        Plots channel-medianed Trx and Tsys vs. antenna ID on a 2-panel plot, with one plot 
        per spw/scan combination (the two pols are shown in green and blue).
        """
        if (spw is not None):
            spw = int(spw)
            if (self.unrecognizedSpw(spw)): return
            spws = [spw]
        else:
            spws = self.spws
        if (scans == None):
            scans = self.scans
        elif type(scans) == str:
            scans = [int(i) for i in scans.split(',')]
        if (antennas==None):
            antennas = self.antennas
        elif (type(antennas) == str):
            antennas = [int(i) for i in antennas.split(',')]
        pngs = []
        trxDifferences = {'antenna': {}, 'spw':{}}
        tsysDifferences = {'antenna': {}, 'spw':{}}
        computeJsky = True # must be True when asking for Tsys
        for spw in spws:
          for scan in scans:
            print "Working on scan ", scan
            tsys = []
            trec = []
            atmosphere = None
            for antenna in antennas:
                print "Working on spw %d antenna %s (%d/%d)" % (spw, self.antennaNames[antenna], antenna+1,len(antennas))
                tsyspol = []
                trecpol = []
                for pol in range(2):
                    result = self.computeTsys(scan,antenna,pol,spw, tdmspw, asdm, etaF, lo1,
                                              dataFraction, parentms, verbose, siteAltitude_m,
                                              computeJsky, fdmCorrection=fdmCorrection, tdmscan=tdmscan,
                                              tdmdataset=tdmdataset, atmosphere=atmosphere)
                    atmosphere = result[-1]
                    tsyspol.append(np.median(result[0]))
                    trecpol.append(np.median(result[2]))
                tsys.append(tsyspol)
                trec.append(trecpol)
            pb.clf()
            adesc = pb.subplot(211)
            pb.plot(range(len(antennas)), trec, 'o', color=overlayColors[0])
            pb.ylabel('Trec')
            pb.title(os.path.basename(self.vis) + ' spw %d scan %d' % (spw,scan))
            xlim = pb.xlim()
            pb.xlim([xlim[0]-0.5, xlim[1]+0.5])
            xlim = pb.xlim()
            adesc.xaxis.set_major_locator(MultipleLocator(1))
            adesc.set_xticklabels(self.antennaNames[antennas], rotation='vertical', size=8, ha='left')
            adesc = pb.subplot(212)
            pb.plot(range(len(antennas)), tsys, 'o', color=overlayColors[1])
            pb.xlim(xlim)
            pb.xlabel('Antenna')
            pb.ylabel('Tsys')
            adesc.xaxis.set_major_locator(MultipleLocator(1))
            adesc.set_xticklabels(self.antennaNames[antennas], rotation='vertical', size=8, ha='left')
            png = self.vis+'_spw%d_scan%d_tsys.png'%(spw,scan)
            pb.savefig(png)
            pngs.append(png)
        pdf = self.vis+'_tsys.pdf'
        buildPdfFromPngs(pngs,pdf)

    def plotTsysTrec2All(self, spw=None, tdmspw=None, asdm=None, antennas=None, etaF=0.98, lo1=None,
                         dataFraction=[0.0, 1.0], parentms=None, siteAltitude_m=5059,
                         fdmCorrection=False, tdmscan=None, tdmdataset=None, showAttenuators=False):
        """
        Plots Tsys in one panel and Trec2 in another panel on the same page, for all requested
        combinations of antennas and spws.
        spw: a single spw ID (integer or string)
        antennas: an integer list of antenna IDs, or a comma-delimited string
        """
        if (spw is not None):
            spw = int(spw)
            if (self.unrecognizedSpw(spw)): return
            spws = [spw]
        else:
            spws = self.spws
        if (scans == None):
            scans = self.scans
        elif type(scans) == str:
            scans = [int(i) for i in scans.split(',')]
        if (antennas==None):
            antennas = self.antennas
        elif (type(antennas) == str):
            antennas = [int(i) for i in antennas.split(',')]
        pngs = []
        trxDifferences = {'antenna': {}, 'spw':{}}
        tsysDifferences = {'antenna': {}, 'spw':{}}
        for spw in spws:
          for scan in self.scans:
            print "Working on scan ", scan
            for antenna in antennas:
                print "Working on spw %d antenna %s (%d/%d)" % (spw, self.antennaNames[antenna], antenna+1,len(self.antennas))
                for pol in range(2):
                    png = self.plotTsysTrec2(scan,antenna,pol,spw, tdmspw, asdm, etaF, lo1,
                                             dataFraction, parentms, siteAltitude_m=siteAltitude_m,
                                             fdmCorrection=fdmCorrection, tdmscan=tdmscan,
                                             tdmdataset=tdmdataset, showAttenuators=showAttenuators,
                                             trxDifferences=trxDifferences, tsysDifferences=tsysDifferences)
                    if (png is not None):
                        pngs.append(png)
        buildPdfFromPngs(pngs, pdfname='%s.tsys_trx.pdf'%(self.vis))
        for spw in spws:
          if (spw in trxDifferences['spw']):
            print "               25%ile  median  75%ile"
            print "Trx: spw %02d = %.2f  %.2f  %.2fK" % (spw,scoreatpercentile(trxDifferences['spw'][spw],25),
                                                         np.median(trxDifferences['spw'][spw]),
                                                         scoreatpercentile(trxDifferences['spw'][spw],75))
            print "Tsys spw %02d = %.2f  %.2f  %.2fK" % (spw,scoreatpercentile(tsysDifferences['spw'][spw],25),
                                                         np.median(tsysDifferences['spw'][spw]),
                                                         scoreatpercentile(tsysDifferences['spw'][spw],75))
        for antenna in antennas:
          if (antenna in trxDifferences['antenna']):
            print "Trx: antenna %02d (%s) = %.2f  %.2f  %.2fK" % (antenna,self.antennaNames[antenna],
                                                                  scoreatpercentile(trxDifferences['antenna'][antenna],25),
                                                                  np.median(trxDifferences['antenna'][antenna]),
                                                                  scoreatpercentile(trxDifferences['antenna'][antenna],75))
            print "Tsys antenna %02d (%s) = %.2f  %.2f  %.2fK" % (antenna,self.antennaNames[antenna],
                                                                  scoreatpercentile(tsysDifferences['antenna'][antenna],25),
                                                                  np.median(tsysDifferences['antenna'][antenna]),
                                                                  scoreatpercentile(tsysDifferences['antenna'][antenna],75))
                                                                  
        return(trxDifferences, tsysDifferences)
    
    def plotTrec2(self, scan, antenna, pol, spw, tdmspw=None, asdm=None, etaF=0.98,
                  lo1=None, dataFraction=[0.0, 1.0], parentms=None, 
                  siteAltitude_m=5059, altscan=None, overlayTelcal=True,
                  fdmCorrection=False, tdmscan=None, tdmdataset=None, plotfile='',
                  showAttenuators=False):
        """
        Computes Trec2 then plots it, and optionally overlays the Telcal result.
        """
#        if (tdmspw is not None or tdmdataset is not None or tdmspw is not None):
#            fdmCorrection = True
        spw = int(spw)
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (spw == 'auto'):
            spw = self.spwsforscan[scan][0]
            print "Choosing spw = %d" % (spw)
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
#        pb.text(0.65, 0.93, 'fractional portion of subscan used', transform=adesc.transAxes)
        if (overlayTelcal):
            trx = self.getTelcalTrx(antenna,spw,scan,pol)  # TelCal's result
            if (trx == None):
                overlayTelcal = False
        result = self.computeTrec2(scan, antenna, pol, spw, tdmspw, asdm=None,
                                   etaF=etaF, lo1=None, dataFraction=dataFraction,
                                   parentms=None, siteAltitude_m=5059, altscan=altscan,
                                   fdmCorrection=fdmCorrection, tdmscan=tdmscan,
                                   tdmdataset=tdmdataset)
        if (result == None):
            return(None)
        trec, gain, tsky, freqHz = result 
        pb.clf()
        adesc = pb.subplot(111)
        freqHz = self.chanfreqs[spw]
        pb.plot(freqHz*1e-9, trec, 'k-')
        pb.text(0.82, 0.85-c*0.07, '[%.2f,%.2f]' % (dataFraction[0],dataFraction[1]),
                color='k', transform=adesc.transAxes)
        pb.xlabel('Frequency (GHz)')
        pb.ylabel('Trec2(K)')
        ylims=pb.ylim()
#        if (ylims[0] < 0):
#            pb.ylim([0,ylims[1]])
        if (overlayTelcal):
            pb.hold(True)
            if (fdmCorrection):
                lw = 1
            else:
                lw = 3
            pb.plot(freqHz*1e-9, trx, 'g-', lw=lw)
            print "mean residual = ", np.mean(trx-trec)
            if (fdmCorrection):
                mylabel = ' FDM'
            else:
                mylabel = ''
            pb.text(0.05,0.95, 'TelCal'+mylabel, color='g', transform=adesc.transAxes)
            pb.text(0.42,0.95, 'casa'+mylabel, color='k', transform=adesc.transAxes)
            if (showAttenuators):
                if (self.IFProc[antenna][pol] == None or self.IFSwitch[antenna][pol][1] == None):
                    self.readAttenuatorSettings(antenna,pol)
                if (scan in self.IFProc[antenna][pol]):
                  if (self.IFProc[antenna][pol][scan] != -1):
                    pb.text(0.05,0.85,'IFSw %.1fdB, IFPr %.1fdB'%(self.IFSwitch[antenna][pol][self.sidebandsforspw[spw]][scan],
                                                   self.IFProc[antenna][pol][scan][self.basebands[spw]-1]),
                        color='g',transform=adesc.transAxes)
            if (fdmCorrection):
                if (tdmspw == None): tdmspw = spw
                if (tdmscan == None): tdmscan = scan
                if (tdmdataset == None):
                    tdmdataset = self
                trx = tdmdataset.getTelcalTrx(antenna,tdmspw,tdmscan,pol)  # TelCal's result for the TDM spectrum
#                print "Got TelcalTrx for spw=%d: " % (tdmspw, trx)
                freqHz = tdmdataset.chanfreqs[tdmspw]
                pb.plot(freqHz*1e-9, trx, 'r-')
                y0,y1 = pb.ylim()
                if (y0 < 0 and y0 > -100000): y0 = 0
                pb.ylim([y0,y1+(y1-y0)*0.2])
                pb.text(0.65,0.95, 'TelCal TDM (%s)' % (mjdsecToUTHMS(np.mean(tdmdataset.timerange[tdmscan]))),
                        color='r', transform=adesc.transAxes)
                if (showAttenuators):
                    if (tdmdataset.IFProc[antenna][pol] == None or tdmdataset.IFSwitch[antenna][pol][1] == None):
                        tdmdataset.readAttenuatorSettings(antenna,pol)
                    if (tdmscan in tdmdataset.IFProc[antenna][pol]):
                      if (tdmdataset.IFProc[antenna][pol][tdmscan] != -1):
                        pb.text(0.65,0.85,'IFSw %.1fdB, IFPr %.1fdB'%(tdmdataset.IFSwitch[antenna][pol][tdmdataset.sidebandsforspw[spw]][tdmscan],
                                                       tdmdataset.IFProc[antenna][pol][tdmscan][tdmdataset.basebands[spw]-1]),
                            color='r',transform=adesc.transAxes)
        ut = mjdsecToUTHMS(self.meantime[scan])
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        pb.title('%s  %s  scan=%d  spw=%d  pol=%d  mean_time=%s' % (os.path.basename(self.vis), antennaName, scan, spw, pol, ut), fontsize=11)
        if (plotfile == '' or plotfile==True):
            png = '%s.%s.scan%02d.spw%02d.pol%d.trec2.png' % (os.path.basename(self.vis), antennaName, scan, spw, pol)
        else:
            png = plotfile
        print "Result left in ", png
        pb.savefig(png)
        pb.draw()
        return(png)
                  
    def computeTrec3(self, scan, antenna, pol, spw, asdm=None, etaF=0.98, lo1=None,
                     dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                     altscan=None, calscandict=None):
        """
        This function is not really used in TelCal (computeTrec2 is used).
        Trec and saturation parameter from a 3-load measurement.
        the formula is
             p = G * (tRec+t) / (1+s*t)
        """
        spw = int(spw)
        if (self.unrecognizedAntenna(antenna)): return
        if (self.unrecognizedScan(scan)): return
        if (self.unrecognizedSpw(spw)): return
        antennaId, antennaName = self.getAntenna(antenna)
        result = self.computeJs(scan, antenna, pol, spw, asdm, etaF, lo1,
                                dataFraction, parentms, verbose,
                                computeJsky=True, altscan=altscan, 
                                calscandict=calscandict)
        t0, t1, t2, freqHz, jatm, jspDSB, jbg, tauA, alpha, gb, atmosphere, tebbsky = result
        p0 = self.getSpectrum(scan,spw,pol,'sky',antennaId,dataFraction)
        p1 = self.getSpectrum(scan,spw,pol,'amb',antennaId,dataFraction)
        p2 = self.getSpectrum(scan,spw,pol,'hot',antennaId,dataFraction)
        a = p0*p1*t2*(t0-t1) + p1*p2*t0*(t1-t2) + p2*p0*t1*(t2-t0)
        c = p0*p1*(t1-t0) + p1*p2*(t2-t1) + p2*p0*(t0-t2)
        b = p0*t0*(t2-t1) + p1*t1*(t0-t2) + p2*t2*(t1-t0)
        d = p0*(t1-t2) + p1*(t2-t0) + p2*(t0-t1)
        if (True):
            trec = a/c
            gain = c/b
            saturation = d/b
        else:
            # DBL_MIN taken from aos-gns:/alma/ACS-12.0/ACSSW/Sources/xercesc/src/xerces-c-src_2_8_0/tests/XSValueTest/XSValueTest.cpp
            DBL_MIN = 2.2250738585072014e-308
            if (fabs(c)>DBL_MIN):
                trec = a/c
            else:
                trec=999999
                gain=DBL_MIN
            if (fabs(b)>DBL_MIN and fabs(c)>DBL_MIN):
                saturation    = d/b
                gain = c/b
            else:
                saturation = 0
                gain = DBL_MAX
        pb.clf()
        adesc = pb.subplot(111)
        trx = self.getTelcalTrx(antenna,spw,scan,pol)
        pb.plot(freqHz*1e-9, trec, 'k-', freqHz*1e-9, trx, 'r-')
        pb.xlabel('Frequency (GHz)')
        pb.ylabel('Trec3(K)')
        print "Median Trx=%f" % (np.median(trec))
        ut = mjdsecToUTHMS(np.mean(self.mymsmd.timesforscan(scan)))
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        pb.title('Trec3  %s  %s  scan=%d  pol=%d  time=%s' % (os.path.basename(self.vis), antennaName, scan, pol, ut), fontsize=11)
        pb.text(0.5,0.95,'red=TelCal result', transform=adesc.transAxes)
        pb.text(0.5,0.9,'mean=%f'%(np.mean(trec)),transform=adesc.transAxes)
        pb.savefig('%s.scan%d.pol%d.trec3.png' % (os.path.basename(self.vis), scan,pol))
        pb.draw()
        return(trec, saturation, gain)

    def solveTsys(self, pHot, pAmb, pSky, jatm, jbg, gb, alpha, tauA, verbose=False):
        #               dbl   dbl  dbl   vector vec vec  dbl   vector
     #                                  --2 sidebands--
        pRef = 0
        # Equation 17 of Lucas & Corder
        tCal  = jatm[0]-jbg[0]
        if (len(jatm) > 1):
            tCal += (gb[1]/gb[0])*np.exp(-tauA[1]+tauA[0])*(jatm[1]-jbg[1])
        pLoad = alpha*pHot+(1-alpha)*pAmb     # Eq 18b of Lucas & Corder
        tSys  = tCal*(pSky-pRef)/(pLoad-pSky) # Eq 18a of Lucas & Corder
        if verbose: 
            print "solveTsys: shapes: tSys=%s, tCal=%s, pSky=%s, pRef=%s, pLoad=%s, jatm=%s, jbg=%s, gb=%s, tauA=%s" % (np.shape(tSys), np.shape(tCal), np.shape(pSky), np.shape(pRef), np.shape(pLoad), np.shape(jatm), np.shape(jbg), np.shape(gb), np.shape(tauA))
        return tCal,tSys
        
    def solveAlpha(self, jHot, jAmb, jAtm, jspDSB, etaF):
        # Eq. 16 of Lucas & Corder "Dual Load Amplitude Calibration in ALMA"
        alpha = (etaF*jAtm-jAmb+(1-etaF)*jspDSB) / (jHot-jAmb)
        return(alpha)
        
    def computeJs(self, scan, antenna, pol, spw, asdm=None, etaF=0.98, lo1=None,
                  dataFraction=[0.0, 1.0], parentms=None, verbose=False,
                  siteAltitude_m=5059, computeJsky=False, altscan=None, 
                  calscandict=None, atmosphere=None, newFrequencyAxis=None,
                  maxAltitude=80.0, pwv=None):
        """
        Compute Jamb, Jhot, and (optionally) Jsky
        Reads the number of channels, their widths and freqs for the spw using self.mymsmd
        if computeJsky == True
           returns: jSky, jAmb, jHot, frequency[0], jatmDSB, jspDSB, jbg,   tauA,  alpha, gb, atmosphere, tebbsky
            shapes: (128) (1)   (1)   (128)        (2, 128)  (128) (2,128) (2,128) (128) (2,1)   dict     (2,128)
                    but JspDSB is currently a constant temperature, of order 268K
                    The (2) size is for 2 sidebands.
                    atmosphere is the dictionary returned by CalcAtmosphere
        else:
           returns: jSky=0, jAmb, jHot, frequency[0]
        Inputs:
        scan: integer or string
        antenna: integer ID, string ID or string name
        pol: 0 or 1
        spw: Tsys spw (integer or string integer)
        maxAltitude: of the atmosphere, in km
        atmosphere: dictionary keyed by 'signal', 'image', with values returned by
                    au.CalcAtmosphere()
        pwv: if specified, then use this value to override what was in the ASDM
        newFrequencyAxis: a grid of frequencies to calculate on; direction is unclear
        Note: the ATM model spectrum is Hanning smoothed if self.hanningSmoothed[spw] == True,
            which is set automatically upon initialization of the Atmcal class.  To override
            this feature, one can set that dictionary entry to True or False before calling
            this function.
        """
        spw = int(spw)
        antennaId, antennaName = self.getAntenna(antenna)
        baseband = self.basebands[spw] # mymsmd.baseband(spw)
        result = getCalAtmosphereInfo(self.vis, scan=scan, antenna=antennaName, pol=pol,
                                      baseband=baseband, debug=verbose, altscan=altscan,
                                      calscandict=calscandict, mymsmd=self.mymsmd)
        if (result == None and altscan == 'auto'):
            scanlist = sorted(list(self.scans))
            scanindex = scanlist.index(scan)
            if (scanindex==0):
                altscan = scanlist[1]
            else:
                altscan = scanlist[scanindex-1]
            print "Choosing alternate scan=%d" % (altscan)
            result = getCalAtmosphereInfo(self.vis, scan=scan, antenna=antennaName, pol=pol,
                                          baseband=baseband, debug=verbose, altscan=altscan,
                                          calscandict=calscandict, mymsmd=self.mymsmd)
        if (result == None): return
        myIndex = result[10]
        if (len(myIndex) > 1):
            print "More than 1 row returned.  Be more specific in your selection"
            return
        if (len(myIndex) == 0):
            print "No rows match these values."
            return
        sbGains = result[0]
        gb = [sbGains, 1-sbGains]  # signal, image
        mjdsec = result[4]
        row = 0
        net_sideband = sidebandToNetSideband(self.mymsmd.sideband(spw))
        field = self.mymsmd.fieldsfortimes([mjdsec[row]])[0]
        if newFrequencyAxis is None:
            freq_signal_sideband = self.mymsmd.chanfreqs(spw)
        else:
            if verbose: print "computeJs(): Using newFrequencyAxis len = ", len(newFrequencyAxis)
            freq_signal_sideband = newFrequencyAxis
        if (len(freq_signal_sideband) == 1):
            chanwidth = 2e9 # channel-averaged spw
        else:
            chanwidth = freq_signal_sideband[1]-freq_signal_sideband[0]
        refFreq = freq_signal_sideband[0] - 0.5*chanwidth
        
        chans_signal = range(len(freq_signal_sideband))
        if field not in self.radec:
            self.radec[field] = getRADecForField(self.vis, field, usemstool=True, mymsmd=self.mymsmd)
        mydirection = self.radec[field]
        myazel = computeAzElFromRADecMJD(mydirection, mjdsec[row]/86400., self.telescopeName, verbose=False)
        airmass = elevationToAirmass(np.degrees(myazel[1]))
        water = result[6]
        if pwv is None:
            pwv = water[row]  # could take the mean instead?
        if (verbose):
            print "Using airmass = %f" % (airmass)
            print "Using 1st pwv of %d = %f" % (len(water), water[row])
        antenna_id = result[1][row]
        if (antenna_id != antennaName):
            print "Mismatch in antenna ID!  antenna_id=%s, antennaId=%s" % (str(antenna_id), antennaName)
            return
        groundPressure = result[7][row]
        groundTemperature = result[8][row]
        groundRelHumidity = result[9][row]
        Tatm = groundTemperature
        frequency = []
        tebbsky = []
        if (computeJsky):
            if atmosphere is None:
                if verbose: print "computeJs(): Running CalcAtmosphere (chans=%s,signalSB)" % (len(chans_signal))
                startTime = timeUtilities.time()
                atmosphere = {}
                atmosphere['signal'] = \
                      CalcAtmosphere(chans_signal, freq_signal_sideband*1e-9, pwv, 
                                     refFreq, net_sideband, groundPressure,
                                     groundRelHumidity, Tatm, airmass, 
                                     siteAltitude_m=siteAltitude_m, maxAltitude=maxAltitude, 
                                     hanning=self.hanningSmoothed[spw])
                if (verbose):
                    print "Done CalcAtmosphere after %.1f sec" % (timeUtilities.time()-startTime)
#                print "input freq range: " , freq_signal_sideband[0]*1e-9, freq_signal_sideband[-1]*1e-9
#                print "output freq range: ", atmosphere['signal'][0][0], atmosphere['signal'][0][-1]
            freq, chans, transmission, tebb, opacity = atmosphere['signal']
            tauA = []
            tebbsky.append(tebb)
            tauA.append(opacity)
            frequency.append(freq*1e9)
        else:
            frequency.append(freq_signal_sideband)

        if self.lo1s is not None:
            LO1 = self.lo1s[spw]
        else:
            getLOsStatus = getLOs(self.vis)
            if (verbose):
                print "Done getLOs()"
            if (len(getLOsStatus) > 0):
                startTime = timeUtilities.time()
                intent = 'OBSERVE_TARGET#ON_SOURCE'
                if (intent not in self.intents):
                    # This is necessary in order to correct cal survey datasets
                    # which do not have an OBSERVE_TARGET intent
                    intent = 'CALIBRATE_FLUX#ON_SOURCE'
                    if (intent not in self.intents):
                        intent = 'CALIBRATE_DELAY#ON_SOURCE'
                self.lo1s = interpretLOs(self.vis, parentms, intent=intent, mymsmd=self.mymsmd)
                if (self.lo1s == None): return
                if (spw not in self.lo1s):
                    print "spw map returned by interpretLOs is suspect!"
                    LO1 = self.lo1s[self.lo1s.keys()[-1]]
                else:
                    LO1 = self.lo1s[spw]
                if (verbose):
                    print "Found LO1 = %f" % (LO1)
                print "Done getting LOs after %.1f sec" % (timeUtilities.time()-startTime)
            elif (lo1 is not None):
                LO1 = lo1
            else:
                print "Could not find LO1"
                return
            self.LO1 = LO1
        if verbose:
            print "signal SB refFreq = %.0f = %.0f - 0.5*%.0f,  IF=%.0f" % (refFreq, freq_signal_sideband[0], 
                                                                        chanwidth, refFreq-LO1)

        ##### Repeat for image sideband
        refFreq_image = 2*LO1 - refFreq
        freq_image_sideband = 2*LO1 - freq_signal_sideband
        if verbose:
            print " image SB refFreq = %.0f = %.0f - 0.5*%.0f, IF=%f" % (refFreq_image, freq_image_sideband[0], 
                                                                     chanwidth, refFreq_image-LO1)
        if (computeJsky):
            if 'image' not in atmosphere:
                if verbose: print "computeJs(): Running CalcAtmosphere (chans=%d,imageSB)" % (len(chans))
                startTime = timeUtilities.time()
                atmosphere['image'] = \
                      CalcAtmosphere(chans, freq_image_sideband*1e-9, pwv,
                                     refFreq_image, net_sideband, groundPressure,
                                     groundRelHumidity, Tatm, airmass, siteAltitude_m=siteAltitude_m,
                                     maxAltitude=maxAltitude, hanning=self.hanningSmoothed[spw])
                if verbose:
                    print "Done CalcAtmosphere after %.1f sec" % (timeUtilities.time()-startTime)
            freq, chans, transmission, tebb, opacity = atmosphere['image']
            frequency.append(freq*1e9)
            tebbsky.append(tebb)
            tauA.append(opacity)  # tauA means tau(Zenith)*Airmass
            jem = frequency*0 # initialize an array to zero
        else:
            frequency.append(freq_image_sideband)
        frequency = np.array(frequency)
        jSky = 0; jAmb = 0; jHot = 0
        jatmDSB = 0
        jspDSB = 0
        jbg = frequency*0 # initialize an array to zero
        jem = frequency*0 # initialize an array to zero
        jsp = frequency*0 # initialize an array to zero
        jatm = frequency*0 # initialize an array to zero
        cosmicBackgroundTemp = Tcmb
        if len(self.loadTemperatures) > 0:
            ambLoad = self.loadTemperatures[antennaId][scan]['amb']
            hotLoad = self.loadTemperatures[antennaId][scan]['hot']
        else:
            ambLoad = 0
            hotLoad = 0
        numSideband = 2
        for iside in range(numSideband):
            hvk = h*np.mean(frequency[iside])/k  # telcal uses the frequency of the middle channel
            if (computeJsky):
                expMinusTau = np.exp(-tauA[iside])
                jebb = hvk/(np.exp(hvk/tebbsky[iside])-1)
                jbg[iside] = hvk/(np.exp(hvk/cosmicBackgroundTemp)-1)
                jem[iside] = jebb - jbg[iside]*expMinusTau
                jsp[iside] = hvk/(np.exp(hvk/groundTemperature)-1)
                jatm[iside] = (jebb - jbg[iside]*expMinusTau) / (1.-expMinusTau)
                jSky += gb[iside]*(etaF*jem[iside] + (1.-etaF)*jsp[iside])
                jatmDSB += gb[iside]*jatm[iside]
                jspDSB += gb[iside]*jsp[iside]
            jAmb += gb[iside]*hvk/(np.exp(hvk/ambLoad)-1)
            jHot += gb[iside]*hvk/(np.exp(hvk/hotLoad)-1)
        if (verbose):
            print "gainratio=%f, ambLoad=%f, hotLoad=%f, means: jSky=%f, jAmb=%f, jHot=%f" % (gb[0], ambLoad, hotLoad, np.mean(jSky),np.mean(jAmb),np.mean(jHot))
        if (computeJsky):
            if verbose: print "computeJs(): shape jatmDSB = ", np.shape(jatmDSB)
            alpha = self.solveAlpha(jHot, jAmb, jatmDSB, jspDSB, etaF)
            return(jSky, jAmb, jHot, frequency[0], jatm, jspDSB, jbg, tauA, alpha, gb, atmosphere, tebbsky)
        else:
            return(jSky, jAmb, jHot, frequency[0])  # jSky will be 0 here
        # end of computeJs()
# end of class Atmcal

def checkSamplers(vis, state_id=None, ac=None, spws=None, threshold1=1.25, threshold2=2.0,
                  maxChannel=3, maxScan=None, useMedian=False):
    """
    Gets the TDM full-resolution spws for a dataset, finds the sky subscan timerange
    of each ATM cal scan, and computes the ratio of channel zero to the median (or
    minimum) of channels 1-3 (or otherwise specified).  Ratios above the specified
    threshold are indicated with asterisks.

    state_id: the state_id number to use for the sky subscan (default: row with REF=1,SIG=0)
    ac: the Atmcal instance to use (default=None which means create a new one)
    spws: the spws to consider (default=None which means use all spws)
    threshold1: if ratio is above this, then print one pair of asterisks
    threshold2: if ratio is above this, then print two pairs of asterisks
    maxChannel: adjust the upper bound of the block of channels to take the median of
    maxScan: the highest scan number to consider (default=None which means use all scans)
    useMedian: default=False, if True, then take the median of channels 1..maxChannel as
               the denominator of the ratio, otherwise take the mininum
    Return values:
    dictionary of ratios, keyed by antenna name, then baseband number (1..4)
    -Todd Hunter
    """
    if (ac == None):
        ac = Atmcal(vis)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (spws == None):
        if (casadef.subversion_revision < casaRevisionWithAlmaspws):
            index1 = mymsmd.tdmspws()
            index2 = mymsmd.chanavgspws()
            index1 = np.setdiff1d(index1,index2)
        else:
            index1 = mymsmd.almaspws(tdm=True)
        index2 = mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
        spws = np.intersect1d(index1,index2)
    elif (type(spws) == int):
        spws = [spws]
    print "Processing spws = ", spws
    scans = []
    band = getBand(mymsmd.chanfreqs(spws[0])[0])
    field = mymsmd.fieldsforspw(spws[0])[0]
    antennaNames = mymsmd.antennanames(range(mymsmd.nantennas()))
    basebands = {}
    uniqueBasebands = []
    scansforspw = {}
    for spw in spws:
        index1 = mymsmd.scansforspw(spw)
        index2 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
        scansforspw[spw] = list(np.intersect1d(index1,index2))
        scans += scansforspw[spw]
        basebands[spw] = mymsmd.baseband(spw)
        if (basebands[spw] not in uniqueBasebands):
            uniqueBasebands.append(basebands[spw])
    scans = np.unique(np.array(scans))
    if (maxScan is not None):
        scans = list(scans[np.where(scans <= maxScan)[0]])
        if (len(scans) < 1):
            print "No scans within the specified value of maxScan=%d" % (maxScan)
            return
    print "Processing scans = ", scans
    mymsmd.close()
    timerange = ''
    for scan in scans:
        if (scan in ac.timestampsString.keys()):
            if (len(timerange) > 0):
                timerange += ','
            timerange += ac.timestampsString[scan][ac.skysubscan]
    scan=','.join([str(a) for a in scans])
    spw = ','.join([str(a) for a in spws])
    if (state_id == None):
        state_id = str(ac.stateID_off_source[0])
    elif (state_id == []):
        state_id = None
    else:
        state_id = str(state_id)
    v = Visibility(vis,antenna1=0,antenna2=0,spwID=spws[0],correctedData=False,
                   scan=scans[0],cross_auto_all='auto',autoSubtableQuery=True,
                   state=state_id)
    print "using state id = ", v.getState()
    ratio = {}
    pols = [0,1] # assume both are present (for now)
    for ant1 in range(len(antennaNames)):
        ratio[ant1] = {}
        for baseband in uniqueBasebands:
            ratio[ant1][baseband] = {}
            for pol in pols:
                ratio[ant1][baseband][pol] = []
            
    for ant1 in range(len(antennaNames)):
        print "Working on antenna %d/%d" % (ant1+1,len(antennaNames))
        v.autoSubtableQuery = False
        v.setAntennaPair(ant1,ant1)
        for spwID in spws:
            v.autoSubtableQuery = False
            v.setSpwID(spwID)
            myscans = np.intersect1d(scans,scansforspw[spwID])
            for scan in myscans:
              v.autoSubtableQuery = True
              try:
                v.setScan(scan)
                d = v.amp
                if (len(d) < 1):
                    print "ant%d spw%d scan%d has zero length data" % (ant1,spwID,scan)
                else:
                    for pol in pols:
                        if (len(d[pol]) < 1):
                            print "ant%d  spw%d scan%d pol%d has zero length data" % (ant1,spwID,scan,pol)
                        else:
                            if (useMedian):
                                myratio = d[pol][0] / np.median(d[pol][1:maxChannel+1])
                            else:
                                myratio = d[pol][0] / np.min(d[pol][1:maxChannel+1])
                            ratio[ant1][basebands[spwID]][pol].append(myratio)
              except:
                  print "Antenna %d, spw %d: no data for scan " % (ant1,spwID), scan
                  continue
    print "Band %d   %s   %s" % (band,os.path.basename(vis),getObservationStartDate(vis))
    print "Ratio of Channel 0 to the median of channels 1~%d in auto-correlation spectra" % (maxChannel)
    outline = "Antenna "
    for baseband in uniqueBasebands:
        for pol in pols:
            outline += " BB%dpol%d  " % (baseband-1,pol)
    print outline
    mydict = {}
    for ant1 in range(len(antennaNames)):
        mydict[antennaNames[ant1]] = {}
        outline = "%2d=%4s" % (ant1,antennaNames[ant1])
        for baseband in uniqueBasebands:
            mydict[antennaNames[ant1]][baseband] = []
            for pol in pols:
                myratio = np.median(ratio[ant1][baseband][pol])
                mydict[antennaNames[ant1]][baseband].append(myratio)
                npts = len(ratio[ant1][baseband][pol])
                outline += " "
                if (myratio > threshold2):
                    if (myratio >= 100):
                        outline += "**%4.1f**" % (myratio)
                    else:
                        outline += "**%5.2f**" % (myratio)
                elif (myratio > threshold1):
                    if (myratio >= 100):
                        outline += " *%4.1f* " % (myratio)
                    else:
                        outline += " *%5.2f* " % (myratio)
                else:
                    outline += "  %5.2f  " % (myratio)
        print outline
    return(mydict)
    # end of class AtmCal
    
class AtmStates:
    """
    This class is essentially defunct since the table contents were changed
    circa 2011. See the new class Atmcal.
    -Stuartt Corder
    """
    def __init__(self,inputMs):
        self.inputMs = inputMs
        mytb = tbtool()
        mytb.open('%s/STATE' % self.inputMs)
        self.loadTemps    = celsiusToKelvin(mytb.getcol("LOAD"))
        self.stateIntents = mytb.getcol("OBS_MODE")
        mytb.close()
        self.atmSky = []
        self.atmRef = []
        self.atmHot = []
        self.atmAmb = []
        self.atmScans = []
        self.antennaNames = getAntennaNames(self.inputMs)
        self.antennaInfo  = {}
        self.numAtmCals = 0
        for i in self.antennaNames:
            self.antennaInfo[i] = {'AMB' : {'state' : [], 'loadTemp' : []},
                                   'HOT' : {'state' : [], 'loadTemp' : []},
                                   'REF' : {'state' : []},
                                   'SKY' : {'state' : []}
                                   }
        self.getAtmCalTargetStates()
        self.associateStateWithAntenna()

    def getAtmCalTargetStates(self) :
        for i in range(len(self.stateIntents)) :
            if "CALIBRATE_ATMOSPHERE.OFF_SOURCE" in self.stateIntents[i]:
                self.atmSky.append(i)
            if "CALIBRATE_ATMOSPHERE.REFERENCE"  in self.stateIntents[i]:
                self.atmRef.append(i)
            if "CALIBRATE_ATMOSPHERE.ON_SOURCE"  in self.stateIntents[i] and self.loadTemps[i] > 330 : self.atmHot.append(i)
            if "CALIBRATE_ATMOSPHERE.ON_SOURCE"  in self.stateIntents[i] and self.loadTemps[i] < 330 : self.atmAmb.append(i)

    def associateStateWithAntenna(self) :
        self.antennaInfo  = {}
        for i in self.antennaNames:
            self.antennaInfo[i] = {'AMB' : {'state' : [], 'loadTemp' : []},
                                   'HOT' : {'state' : [], 'loadTemp' : []},
                                   'REF' : {'state' : []},
                                   'SKY' : {'state' : []}
                                   }
        visTemp = Visibility(self.inputMs,antenna1=None,antenna2=None,
                             spwID=None,state=None)

        for i in self.atmAmb :
            try:
                visTemp.setState(i)
                ant1 = visTemp.subtable.getcol('ANTENNA1')
                ant2 = visTemp.subtable.getcol('ANTENNA2')
                goodIndex = np.where(ant1 == ant2)[0]
                goodIndex = list(goodIndex)
                antennaIds = np.unique(ant1[goodIndex])
                for j in antennaIds :
                    antName = self.antennaNames[j]
                    antName = getAntennaNames(self.inputMs)[j]
                    self.antennaInfo[antName]['AMB']['state'].append(i)
                    self.antennaInfo[antName]['AMB']['loadTemp'].append(self.loadTemps[i])
            except:
                continue
        for i in self.atmHot :
            try:
                visTemp.setState(i)
                ant1 = visTemp.subtable.getcol('ANTENNA1')
                ant2 = visTemp.subtable.getcol('ANTENNA2')
                goodIndex = np.where(ant1 == ant2)[0]
                goodIndex = list(goodIndex)
                antennaIds = np.unique(ant1[goodIndex])
                for j in antennaIds :
                    antName = self.antennaNames[j]
                    self.antennaInfo[antName]['HOT']['state'].append(i)
                    self.antennaInfo[antName]['HOT']['loadTemp'].append(self.loadTemps[i])
            except:
                continue
        for i in self.atmRef :
            try:
                visTemp.setState(i)
                ant1 = visTemp.subtable.getcol('ANTENNA1')
                ant2 = visTemp.subtable.getcol('ANTENNA2')
                goodIndex = np.where(ant1 == ant2)[0]
                goodIndex = list(goodIndex)
                antennaIds = np.unique(ant1[goodIndex])
                for j in antennaIds :
                    antName = self.antennaNames[j]
                    self.antennaInfo[antName]['REF']['state'].append(i)
            except:
                continue
        for i in self.atmSky :
            try:
               visTemp.setState(i)
               ant1 = visTemp.subtable.getcol('ANTENNA1')
               ant2 = visTemp.subtable.getcol('ANTENNA2')
               goodIndex = np.where(ant1 == ant2)[0]
               goodIndex = list(goodIndex)
               antennaIds = np.unique(ant1[goodIndex])
               for j in antennaIds :
                   antName = self.antennaNames[j]
                   self.antennaInfo[antName]['SKY']['state'].append(i)
            except:
                continue

class processDVTiltMeter:
    def __init__(self,dvTiltmeterFile,outFile=None):
        self.dvTiltmeterFile = dvTiltmeterFile
        self.fulltable = fiop.fileToTable(dvTiltmeterFile,keepType=True)
        self.columns   = fiop.getInvertTable(self.fulltable)
        self.oldtime   = self.columns[0]
        self.time = np.array(convertTimeStamps(self.columns[0]))
        self.time = self.time-self.time[0]
        self.antenna = self.columns[1]
        self.an0    = np.array(self.columns[2])
        self.aw0    = np.array(self.columns[3])
        self.x     = np.array(self.columns[4])
        self.y     = np.array(self.columns[5])
        self.t1    = np.array(self.columns[6])
        self.t2    = np.array(self.columns[7])
        if outFile <> None :
            self.outFile = outFile
            self.fitT2Trend()
            self.removeTrend()
            self.writeResiduals()

    def fitT1Trend(self) :
        self.px = polyfit(self.t1,self.x,1)
        self.py = polyfit(self.t1,self.y,1)
        self.newX=polyval(self.px,self.t1)
        self.newY=polyval(self.py,self.t1)

    def fitT2Trend(self) :
        self.px = polyfit(self.t2,self.x,1)
        self.py = polyfit(self.t2,self.y,1)
        self.newX=polyval(self.px,self.t2)
        self.newY=polyval(self.py,self.t2)

    def removeTrend(self) :
        self.x = self.newX-self.x
        self.y = self.newY-self.y

    def restoreTrend(self) :
        self.x = self.x+self.newX
        self.y = self.y+self.newY

    def plotTime(self) :
        return
    def plotT1(self) :
        return
    def plotT2(self) : 
        return

    def writeResiduals(self) :
        f = open(self.outFile,'w')
        for i in range(len(self.antenna)) :
            f.write("%s %s %f %f %f %f %f %f\n" % (self.oldtime[i],self.antenna[i],self.an0[i],self.aw0[i],self.newX[i],self.newY[i],self.t1[i],self.t2[i]) )
        f.close()

def nameforspw(vis, spw):
    """
    Gets the spw name from the name from the
    NAME column of the SPECTRAL_WINDOW table of a measurement set.
    Obsoleted by msmd.namesforspw in CASA >= 4.3.0.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW')
    names = mytb.getcol('NAME')
    mytb.close()
    if (spw >= len(names)):
        print "spw %d is not in this measurement set"
        return
    return(names[spw])
    
def fixMyDelays(asdm,caltableName=None,vis=None,doImport=True,sign=1) :
    """
    This function will extract the TelCal solutions for delay and generate a
    calibration table, which is useful if the solutions were not applied during
    observations.
    This version will handle single or multiple receiver bands in the ASDM.
    There are two main use cases for this command:
      1) If you have already run importasdm with asis='*', then you don't 
         need to specify the asdm, only the ms:
         fixMyDelays('','my.delaycal',vis='uid.ms',False)
     2) If you want to use this function as a wrapper for importasdm, then 
        you can say:  fixMyDelays('uid__blah_blah',None,None,True)
     The optional 'sign' parameter can be used to flip the sign if and when 
     someone changes the sign convention in TelCal.
    - Todd Hunter
    """
    asis = '*'
    if (len(asdm) > 0):
        [asdm,dir] = locate(asdm)
        print "asdm = %s" % (asdm)
    if (vis == None):
        vis = "%s.ms" % asdm.split('/')[-1]
        print "vis = %s" % (vis)
    elif (len(vis) < 1):
        vis = "%s.ms" % asdm.split('/')[-1]
        print "vis = %s" % (vis)
    if (caltableName == None) or (len(caltableName) < 1):
        if (len(asdm) == 0):
            caltableName = "%s.delaycal" % (vis)
        else:
            caltableName = "%s.delaycal" % asdm.split('/')[-1]
    if doImport : importasdm(asdm=asdm,asis=asis,vis=vis,overwrite=True)
    antennaIds = getAntennaNames(vis)
    bbands     = getBasebandAndBandNumbers(vis)
#    print bbands
    mytb = tbtool()
    mytb.open("%s/ASDM_CALDELAY" % vis)
    antennaNames = mytb.getcol("antennaName")
    if (len(antennaNames) < 1):
        print "The ASDM_CALDELAY table has no data.  Delay correction cannot be done."
        return
    delayOffsets = mytb.getcol("delayOffset")
    basebands    = mytb.getcol("basebandName") # format is 'BB_1'
#    print "basebands = ", basebands
    rxbands    = mytb.getcol("receiverBand")    # format is 'ALMA_RB_%02d'
#    print "rxbands = ", rxbands
    polList = mytb.getcol("polarizationTypes")  # e.g. X or Y or ...
    mytb.close()
    outList = []
    spwNames = []
    rxBands = []
    for j in bbands:
        rxName = "ALMA_RB_%02d" % (j[0])
        rxBands.append(j[0])
        bbName = "BB_%i" % (j[1])
        spwNames.append("%d"%j[2])
#        print "bbName=%s, rxName=%s" % (bbName, rxName)
        for i in antennaIds :
#            print "ith antenna = ", i
            ant = np.where(antennaNames == i)
            bb  = np.where(basebands == bbName)
            rx  = np.where(rxbands == rxName)
#            ind = np.intersect1d_nu(ant,bb)
            newlist = np.intersect1d(ant[0],bb[0])
            newlist = np.intersect1d(newlist,rx[0])
#            print "newlist = ", newlist
            ind = np.unique(newlist)
#            print "ind = ", ind
            if (sign < 0):
                print "Applying the reverse sign of the delays to %s, ant %s" %(bbName,i)
            p  = sign*delayOffsets[:,ind].mean(1)*1e9
            for k in p :
                outList.append(k)
    parameter = outList
    pol = ''
    print "polList[:,0] = ", polList[:,0]
    print "spws = ", spwNames
    print "rx bands = ", rxBands
    for k in range(len(polList[:,0])):
        pol += "%s," % (polList[:,0][k])
    pol = pol[:-1]
    
    antenna   = ",".join(np.unique(antennaNames))
    spw       = ",".join(spwNames)
    print "Removing any old caltable = %s." % (caltableName)
    os.system('rm -rf %s'%(caltableName))
    print "Calling gencal('%s','%s','sbd','%s','%s','%s')" % (vis,caltableName,spw,antenna,pol)
    gencal(vis=vis,caltable=caltableName,caltype='sbd',spw=spw,antenna=antenna,pol=pol,parameter=parameter)
    # end of fixMyDelays
            
def getUniqueBasebandNumbers(inputMs) :
    """
    Returns the list of baseband numbers in the specified ms.
    """
    mytb = tbtool()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    bb = mytb.getcol("BBC_NO")
    mytb.close()
    return np.unique(bb)

def freqToBand(freq):
    """
    Returns the ALMA band integer that can observe the specified frequency.
    It will accept either a single frequency or a list (in Hz).
    It is kind of a kludge until something better is devised.
    Called only by getBasebandAndBandNumbers and plotMosaic.
    See also getBand().
    """
    band = []
    if (type(freq) != list and type(freq) != np.ndarray):
        freq = [freq]
    for f in freq:
        if (f > 750e9):
            band.append(10)
        elif (f > 550e9):
            band.append(9)
        elif (f > 379e9):
            band.append(8)
        elif (f > 275e9):
            band.append(7)
        elif (f > 211e9):
            band.append(6)
        elif (f > 163e9):
            band.append(5)
        elif (f > 120e9):
            band.append(4)
        elif (f > 84e9):
            band.append(3)
        elif (f > 60e9):
            band.append(2)
        elif (f > 30e9):
            band.append(1)
        else:
            band.append(None)
    return(band)
        
def getBasebandAndBandNumbers(inputMs) :
    """
    experimental version to try to deal with band 6/9 phase transfer data
    which uses a bit of a kludge to convert freq to receiverBand
    return orderedlist:  rxBand, baseBand, spw
    Author: unknown
    """
    mytb = tbtool()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    bb = mytb.getcol("BBC_NO")
    freq = mytb.getcol("REF_FREQUENCY")
    numchan = mytb.getcol("NUM_CHAN")
    tbw = mytb.getcol("TOTAL_BANDWIDTH")
    band = freqToBand(freq)
    pair = []
    for i in range(len(band)):
        # remove the channel-average spws and the WVR spws
        if (numchan[i] > 1 and tbw[i] < 7e9):
            pair.append((band[i],bb[i],i))
    mytb.close()
    return np.unique(pair)

def getBasebandAndBandNumbersTest(inputMs) :
    """
    New experimental version to try to deal with band 6/9 phase transfer data
    which tries to determine receiverBand properly, but seems to be impossible.
    return orderedlist:  rxBand, baseBand, spw
    - Todd Hunter
    """
    mytb = tbtool()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    bb = mytb.getcol("BBC_NO")
    numchan = mytb.getcol("NUM_CHAN")
    tbw = mytb.getcol("TOTAL_BANDWIDTH")
    mytb.close()
    mytb.open("%s/ASDM_RECEIVER" % inputMs)
    spws = mytb.getcol('spectralWindowId')
    bands = mytb.getcol('frequencyBand')
    mytb.close()
    pair = []
    band = []
    for i in range(len(numchan)):
        window = ('SpectralWindow_%d'%(i))
        print "window = ", window
        findspw = np.where(spws==window)
        if (len(findspw) > 0):
            print "findspw = ", findspw
            band.append(bands[findspw[0][0]])
            # remove the channel-average spws and the WVR spws
            if (numchan[i] > 1 and tbw[i] < 7e9):
                pair.append((band[i],bb[i],i))
    return np.unique(pair)

def getSpwsForBasebandFromASDM(asdm, bb):
    """
    Returns a list of spws of the specified baseband in an ASDM.
    The spw numbers are the ones they will have upon loading into a measurement set.
    -Todd Hunter
    """
    mydict = getSpwsFromASDM(asdm)  # this will be ms-numbered spws
    spwmap = asdmspwmap(asdm)
    spws = []
    for key in mydict.keys():
        if mydict[key]['basebandNumber'] == bb:
            spws.append(key)
    return(spws)
    
def getSpwsForBaseband(mymsmd,bb):
    """
    This emulates msmd.spwsforbaseband() for older versions of casa that
    do not contain this method.  
    mymsmd: either an instance of an existing msmd tool, or the name of a
            measurement set
    bb: baseband number
    -Todd Hunter
    """
    needToClose = False
    if (type(mymsmd) == str):
        vis = mymsmd
        if (os.path.exists(vis) == False):
            print "First argument must be either an msmd instance or the name of a measurement set."
            return
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose=True
    if (casadef.subversion_revision >= '25612'):
        spws = mymsmd.spwsforbaseband(bb)
    else:
        spws = []
        for spw in range(mymsmd.nspw()):
            if (bb == mymsmd.baseband(spw)):
                spws.append(spw)
    if (needToClose):
        mymsmd.close()
    return(spws)
    
def getBasebands(mymsmd, spw=''):
    """
    Takes an msmd tool instance and builds a list of basebands corresponding 
    to the list of spws.
    Todd Hunter
    """
    basebands = []
    if spw == '':
        spws = range(mymsmd.nspw())
    elif type(spw) == str:
        spws = spw.split(',')
    else:
        spws = spw
    for spw in spws:
        basebands.append(mymsmd.baseband(spw))
    return(basebands)
        
def printLOs(vis, parentms='', showWVR=False,
             showCentralFreq=True, verbose=False, alsoReturnLO2=False,
             showChannelAverageSpws=False, showOnlyScienceSpws=False,
             birdieFreq=None, birdieSpw=None, showEffective=False,
             showWindowFactors=False):
    """
    Print the LO settings for an MS from the ASDM_RECEIVER table.
    Options:
    showCentralFreq: if True, then show the mean frequency of each spw,
                     otherwise show the frequency of the first channel
    showWVR: include the WVR spw in the list
    parentms:  if the dataset has been split from a parent dataset, then
               you may also need to specify the name of the parent ms.
    alsoReturnLO2: if True, return a second dictionary of the LO2 values
    birdieFreq: if specified, compute the IF of this RF feature
    birdieSpw: only necessary if more than one LO1 in the science spws
    
    Returns: a dictionary of the LO1 values (in Hz) for each spw, keyed by
             integer.  This function will warn if the Band 6 YIG can leak
             into the spw (i.e. LO2 between 10.5-11.3 GHz).
             
    For further help and examples, see:
         https://safe.nrao.edu/wiki/bin/view/ALMA/PrintLOs
    - Todd Hunter
    """
    return(interpretLOs(vis, parentms, showWVR, showCentralFreq, 
                        verbose, show=True, alsoReturnLO2=alsoReturnLO2,
                        showChannelAverageSpws=showChannelAverageSpws,
                        showOnlyScienceSpws=showOnlyScienceSpws,
                        birdieFreq=birdieFreq, birdieSpw=birdieSpw,
                        showEffective=showEffective,
                        showWindowFactors=showWindowFactors))

def interpretLOs(vis, parentms='', showWVR=False,
                 showCentralFreq=False, verbose=False, show=False,
                 alsoReturnLO2=False, showChannelAverageSpws=False,
                 showOnlyScienceSpws=False, birdieFreq=None, birdieSpw=None,
                 intent='OBSERVE_TARGET#ON_SOURCE', spwsForIntent=None,
                 showEffective=False, showWindowFactors=False, mymsmd=None):
    """
    Interpret (and optionally print) the LO settings for an MS from the
    ASDM_RECEIVER table.  Note that msmd.spwsforintent is a time hog, and that
    is why passing in spwsForIntent is an option to speed up execution.
    Options:
    showCentralFreq: if True, then show the mean frequency of each spw,
                     otherwise show the frequency of the first channel
    showWVR: include the WVR spw in the list
    parentms:  if the dataset has been split from a parent dataset, then
               you may also need to specify the name of the parent ms.
    alsoReturnLO2: if True, return a second dictionary of the LO2 values
    birdieFreq: if specified, compute the IF of this RF feature
    birdieSpw: only necessary if more than one LO1 in the science spws
    intent: which intent to use in spwsforintent (to find science spws)
    spwsForIntent: if specified, then avoid the call to spwsforintent

    Returns: a dictionary of the LO1 values (in Hz) for each spw, keyed by
             integer.  

    A typical band 7 TDM dataset (prior to splitting) looks like this:
    SPECTRAL_WINDOW table has 39 rows:   row
           WVR                           0
           8 band 3 windows (pointing)   1-8
           8 band 7 windows              9-16
           22 WVR windows                17-38
    The corresponding ASDM_RECEIVER table has only 18 rows:
           WVR                           0
           8 band 3 windows              1-8
           WVR                           9          
           8 band 7 windows              10-17
    After splitting, the ASDM_RECEIVER table remains the same, but the 
    SPECTRAL WINDOW table then has only 4 rows, as the pointing spws and 
    the channel-averaged data are dropped:
           4 band 7 windows               

    Todd Hunter
    """
    lo1s = {} # initialize dictionary to be returned
    lo2s = {}
    try:
        retval =  getLOs(vis)
        [LOs,bands,spws,names,sidebands,receiverIds,spwNames] = retval
    except:
        print "getLOs failed"
        return(retval)
    if (verbose): print "len(spws) = %d: %s" % (len(spws), str(spws))
    maxSpw = np.max(spws)
    sawWVR = False
    indices = []  # will exclude the extraneous WVR spws
    for i in range(len(spws)):
        if (names[i].find('WVR') >= 0):
            if (not sawWVR):
                indices.append(i)
                sawWVR = True
        else:
            indices.append(i)
    LOs = np.array(LOs)[indices]
    bands = np.array(bands)[indices]
    spws = list(np.array(spws)[indices])
    names = np.array(names)[indices]
    sidebands = np.array(sidebands)[indices]
    receiverIds = np.array(receiverIds)[indices]
    index = range(len(spws))
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW')
    # If the data have been split into an ms with fewer spws, then this 
    # table will be smaller (in rows) than the parent MS's table.
    spwNames = mytb.getcol('NAME')
    mytb.close()
    splitted = False
    if (maxSpw != len(spwNames)-1):
        splitted = True
        if (verbose): 
            print "maxSpw=%d != len(spwNames)=%d)" % (maxSpw, len(spwNames))
        if (parentms == '' or parentms is None):
            print "You appear to have split these data.  Please provide the parentms as an argument."
            return
        mytb.open(parentms+'/SPECTRAL_WINDOW')
        parentSpwNames = mytb.getcol('NAME')
        mytb.close()
        extractedRows = []
        index = []
        for s in range(len(spwNames)):
            if (len(spwNames[s]) == 0):
                print "This is an old dataset lacking values in the NAME column of the SPECTRAL_WINDOW table."
                return
            if (verbose): 
                print "Checking for %s in " % (spwNames[s]), parentSpwNames
            extractedRows.append(np.where(parentSpwNames == spwNames[s])[0][0])
            index.append(spws.index(extractedRows[-1]))
            if (verbose): 
                print "spw %d came from spw %d" % (s, extractedRows[-1])
# extractedRows = the row of the parent SPECTRAL_WINDOW table that matches 
#                 the split-out spw
#     index = the row of the ASDM_RECEIVER table that matches the split-out spw
        vis = parentms
    if (verbose): 
        print "spwNames = ", spwNames
        print "spws = ", spws
        print "bands = ", bands
        output = "LOs = "
        for LO in LOs:
            output += "%.3f, " % (LO[0]*1e-9)
        print output
        print "names = ", names
        print "index = ", index

    bbc = getBasebandNumbers(vis) # does not use msmd
    if (show): 
        print 'Row refers to the row number in the ASDM_RECEIVER table (starting at 0).'
        if (showCentralFreq):
            myline = 'Row spw BB RxBand CenFreq Nchan LO1(GHz) LO2(GHz) Sampler YIG(GHz) TFBoffset(MHz)'
        else:
            myline = 'Row spw BB RxBand Ch1Freq Nchan LO1(GHz) LO2(GHz) Sampler YIG(GHz) TFBoffset(MHz)'
        if (showEffective):
            myline += ' Eff.BW(MHz) Res(MHz) Width(MHz)'
        if (showWindowFactors):
            myline += ' windowFactors'
        print myline

    # Loop over all rows in the ASDM_RECEIVER table, unless we've split, in 
    # which case this will loop over the N spws in the table.
    if (casadef.casa_version >= casaVersionWithMSMD):
        needToClose = False
        if mymsmd is None or mymsmd == '':
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            needToClose = True
        if (spwsForIntent is None):
            if intent in mymsmd.intents():
                scienceSpws = np.setdiff1d(mymsmd.spwsforintent(intent),mymsmd.wvrspws())
            else:
                scienceSpws = []
        else:
            scienceSpws = spwsForIntent
    birdieIF = 0
    if (birdieFreq is not None):
        birdieFreq = parseFrequencyArgumentToHz(birdieFreq)
        birdieFreqGHz = parseFrequencyArgumentToGHz(birdieFreq)
    for i in range(len(index)):
        if (verbose): 
            print "index[%d]=%d" % (i,index[i])
            print "spws[%d] = %d" % (index[i], spws[index[i]])
        myspw = i 
        if (birdieFreq is not None and birdieIF == 0):
            if (myspw == birdieSpw):
                if verbose:
                    print "spw=%d, Computing IF = %f - %f" % (myspw, birdieFreq, LOs[index[i]][0])
                birdieIF = np.fabs(birdieFreq - LOs[index[i]][0])
            elif (myspw in scienceSpws and birdieSpw==None):
                if verbose:
                    print "spw=%d (in %s), Computing IF = %f - %f" % (myspw, str(scienceSpws), birdieFreq, LOs[index[i]][0])
                birdieIF = np.fabs(birdieFreq - LOs[index[i]][0])
        if (casadef.casa_version >= casaVersionWithMSMD):
            freqs = mymsmd.chanfreqs(myspw)
            meanFreqGHz = mymsmd.meanfreq(myspw) * (1e-9)
            if (myspw not in scienceSpws and showOnlyScienceSpws): continue
        else:
            if (showOnlyScienceSpws):
                print "The option showOnlyScienceSpws is not supported in this old of a CASA."
                return
            freqs = getFrequencies(vis,myspw) * (1e-9) # does not use msmd
            meanFreqGHz = np.mean(freqs)
        if (len(freqs) < 2 and showChannelAverageSpws==False): 
            continue
        if (bands[index[i]].split('_')[-1].isdigit()):
            rxband = bands[index[i]].split('_')[-1]
        elif (showWVR):
            rxband = 'WVR'
        else:
            continue
        line = "%2d  %2d  %d %3s " % (spws[index[i]], myspw, bbc[myspw], rxband)
        if (showCentralFreq):
            line += "%10.6f %4d " % (meanFreqGHz,len(freqs))
        else:
            line += "%10.6f %4d " % (freqs[0],len(freqs))

        if (LOs[index[i]][0] < 0):
            print line
            continue
        if (bbc[myspw] > 0):
            if (splitted):
                lo1s[i] = LOs[index[i]][0]
                lo2s[i] = LOs[index[i]][1]
            else:
                lo1s[myspw] = LOs[index[i]][0]
                lo2s[myspw] = LOs[index[i]][1]
            for j in range(len(LOs[index[i]])):
                if (j != 2):
                    line = line + '%10.6f' % (LOs[index[i]][j]*1e-9)
                else:
                    line = line + '%5.2f' % (LOs[index[i]][j]*1e-9)
        yig = LOs[index[i]][0] / yigHarmonic(bands[index[i]])
        if (yig > 0):
            line = line + ' %.6f' % (yig*1e-9)
        if (spwType(len(freqs)) == 'FDM'):
            # work out what LO4 must have been
            LO1 = LOs[index[i]][0]
            LO2 = LOs[index[i]][1]
            LO3 = LOs[index[i]][2]
            if (sidebands[index[i]][0] == 'USB'):
                IFlocation = LO3 - (LO2 - (meanFreqGHz*1e9 - LO1))
            else:
                IFlocation = LO3 - (LO2 - (LO1 -  meanFreqGHz*1e9))
            LO4 = 2e9 + IFlocation
            TFBLOoffset = LO4-3e9
            line += '%9.3f %+8.3f ' % (LO4 * 1e-6,  TFBLOoffset * 1e-6)
        else:
            line += 19*' '
        if (showEffective):    
            line += '%9.4f %9.4f %9.4f' % (effectiveBandwidth(vis, myspw)*1e-6,
                                           effectiveResolution(vis, myspw)*1e-6,
                                           getChanWidths(mymsmd, myspw)*1e-6)
        if (showWindowFactors):
            chanwidth = abs(getChanWidths(mymsmd,myspw))
            line += ' %.4f %.4f' % (effectiveBandwidth(vis, myspw)/chanwidth,
                                    effectiveResolution(vis, myspw)/chanwidth)
        if (bands[index[i]].find('ALMA_RB_06')>=0 or bands[index[i]].find('ALMA_RB_09')>=0):
            if (len(LOs[index[i]]) > 1):
                if (LOs[index[i]][1] < 11.3e9 and LOs[index[i]][1] > 10.5e9):
                    line = line + ' leakage of LO2 undesired sideband may degrade dynamic range'
                    if (bands[index[i]].find('ALMA_RB_06')>=0):
                        line += ' (and YIG may leak in)'
                    yigLeakage = LOs[index[i]][0] + (LOs[index[i]][1] - LOs[index[i]][2]) + (yig - LOs[index[i]][1])
                    if (yigLeakage > 0):
                        line = line + ' at %.6f' % (yigLeakage*1e-9)
        if (show): print line
    if (casadef.casa_version >= casaVersionWithMSMD):
        if needToClose:
            mymsmd.done()
    if (birdieIF != 0):
        print "The feature at %f GHz is at IF = %f GHz." % (birdieFreqGHz, birdieIF*1e-9)
    if (alsoReturnLO2):
        return(lo1s, lo2s)
    else:
        return(lo1s)

def yigHarmonic(bandString):
    """
    Returns the YIG harmonic for the specified ALMA band, given as a string 
    used in casa tables, or an integer.
    For example:  yigHarmonic('ALMA_RB_03')  returns the integer 6.
    Todd Hunter
    """
    # remove any leading spaces
    #bandString = bandString[bandString.find('ALMA_RB'):]
    if (bandString in [3,4,6,7,8,9]):
        bandString = 'ALMA_RB_%02d' % bandString
    harmonics = {'ALMA_RB_03':6, 'ALMA_RB_04':6, 'ALMA_RB_06': 18, 
                 'ALMA_RB_07': 18, 'ALMA_RB_08':18, 'ALMA_RB_09':27}
    try:
        harmonic = harmonics[bandString]
    except:
        harmonic = -1
    return(harmonic)

def printLOsFromASDM(sdmfile, spw='', showCentralFreq=True, showYIG=True,
                     showEffective=False, showChannelAverageSpws=False,
                     showWindowFactors=False):
    """
    Prints the values of LO1, LO2 and the TFB LO offset (if applicable).
    If no spw is specified, then it prints the values for all spws in the ASDM.
    spw: limit the result to a single spw
    showCentralFreq: if False, then show the first channel freq
    showYIG: if True, compute what the YIG frequency must have been
    showEffective: if True, show effectiveBw and resolution
    showChannelAverageSpws: if True, then also show single-channel spws
    showWindowFactors: if True, then show ratio of effective bandwidth and
         effective resolution to the channel width (ICT-2542).
    - Todd Hunter
    """
    if (os.path.exists(sdmfile)==False):
        print "Could not find this ASDM file = %s." % (sdmfile)
        return
    if (type(spw) == list):
        spw = spw
    elif (type(spw) == str):
        if (spw != ''):
            spw = [int(x) for x in spw.split(',')]
    else:
        spw = [int(spw)]

    scandict = getLOsFromASDM(sdmfile)
    scandictspw = getSpwsFromASDM(sdmfile)
    if (showCentralFreq):
        line = "Window spw BB Chan RxId CenFrq(GHz) LO1(GHz)  LO2(GHz) Sampler"
    else:
        line = "Window spw BB Chan RxId Ch1Frq(GHz) LO1(GHz)  LO2(GHz) Sampler"
    if (showYIG):
        line += ' YIG(GHz) '
    line += ' TFBoffset(MHz)'
    if (showEffective):
        line += ' Eff.BW(MHz) Res(MHz) Width(MHz)'
    if (showWindowFactors):
        line += ' windowFactors'
    print line
    sawWVR = False
    truespw = -1
    for j in range(len(scandictspw)):
      # find spw
      myspw = -1
      for i in range(len(scandict)):
          if (scandictspw[j]['spectralWindowId'] == scandict[i]['spectralWindowId']):
              myspw = i
              break
      if (myspw < 0):
            continue
      if (scandictspw[j]['numChan'] == 4):
          if (sawWVR): continue
          sawWVR = True
      truespw += 1
      if (spw == '' or truespw in spw):
        myline =  "%4s  %3d %2d " % (scandictspw[j]['windowFunction'][:4], truespw,
                                         scandictspw[j]['basebandNumber'])
        if (scandict[myspw]['frequencyBand'].split('_')[-1].isdigit()):
            rxband = scandict[myspw]['frequencyBand'].split('_')[-1]
        else:
            rxband = 'WVR'
        myline += '%4d  %3s ' % (scandictspw[j]['numChan'],
                                  rxband)
        if (showCentralFreq):
            myline += '%10.6f  ' % (1e-9*scandictspw[j]['centerFreq'])
        else:
            myline += '%10.6f  ' % (1e-9*scandictspw[j]['chanFreqStart'])
        if (scandictspw[j]['basebandNumber'] == 0):
            # don't show (irrelevant) LO for WVR
            print myline
            continue
        for i in range(scandict[myspw]['numLO']):
            if (i<2):
                myline += '%10.6f' % (scandict[myspw]['freqLO'][i]*1e-9)
            else:
                myline += '%5.2f' % (scandict[myspw]['freqLO'][i]*1e-9)
        if (showYIG):
            yigHarm = yigHarmonic(scandict[myspw]['frequencyBand'])
            yig = 1e-9 * scandict[myspw]['freqLO'][0] / (yigHarm*1.0)
            myline += '%10.6f' % yig
        if (spwType(scandictspw[j]['numChan']) == 'FDM'):
            # work out what LO4 must have been
            LO1 = scandict[myspw]['freqLO'][0]
            LO2 = scandict[myspw]['freqLO'][1]
            LO3 = scandict[myspw]['freqLO'][2]
            if (scandictspw[j]['sideband'] > 0):
                IFlocation = LO3 - (LO2 - (scandictspw[j]['centerFreq'] - LO1))
            else:
                IFlocation = LO3 - (LO2 - (LO1 - scandictspw[j]['centerFreq']))
            LO4 = 2e9 + IFlocation
            TFBLOoffset = LO4-3e9
            myline += '%9.3f %+8.3f' % (LO4 * 1e-6,  TFBLOoffset * 1e-6)
        else:
            myline += ' '*18
        if (showEffective):
            myline += '%9.4f  %9.4f  %9.4f' % (scandictspw[j]['effectiveBw']*1e-6,
                                               scandictspw[j]['resolution']*1e-6,
                                               scandictspw[j]['chanWidth']*1e-6)
        if (showWindowFactors):
            myline += ' %.4f %.4f' % (scandictspw[j]['effectiveBw']/scandictspw[j]['chanWidth'],
                                      scandictspw[j]['resolution']/scandictspw[j]['chanWidth'])
        if (showChannelAverageSpws or scandictspw[j]['numChan'] > 1):
            print myline

def spwType(nchan):
    """
    Implements the logic of msmd.almaspws (CAS-5794) to determine the
    type of ALMA spw based on the number of channels.
    -Todd Hunter
    """
    if (nchan >= 15 and nchan not in [256,128,64,32,16,248,124,62,31]):
        t = 'FDM'
    elif (nchan==1):
        t = 'CA'
    elif (nchan==4):
        t = 'WVR'
    else:
        t = 'TDM'
    return(t)
          
def getLOsFromASDM(sdmfile):
    """
    Returns a dictionary of the LO values for every spw in the specified ASDM.
    Dictionary contents: numLO, freqLO, spectralWindowId.  freqLO is itself a
    list of floating point values.
    Todd Hunter
    """
    if (os.path.exists(sdmfile) == False):
        print "getLOsFromASDM(): Could not find file = ", sdmfile
        return
    xmlscans = minidom.parse(sdmfile+'/Receiver.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        scandict[fid] = {}
        rownumLO = rownode.getElementsByTagName("numLO")
        numLO = int(rownumLO[0].childNodes[0].nodeValue)
        rowfreqLO = rownode.getElementsByTagName("freqLO")
        rowreceiverId = rownode.getElementsByTagName("receiverId")
        receiverId = int(rowreceiverId[0].childNodes[0].nodeValue)
        rowfrequencyBand = rownode.getElementsByTagName("frequencyBand")
        frequencyBand = str(rowfrequencyBand[0].childNodes[0].nodeValue)
        freqLO = []
        r = filter(None,(rowfreqLO[0].childNodes[0].nodeValue).split(' '))
        for i in range(2,len(r)):
            freqLO.append(float(r[i]))
        
        rowspwid = rownode.getElementsByTagName("spectralWindowId")
        spwid = int(str(rowspwid[0].childNodes[0].nodeValue).split('_')[1])
        scandict[fid]['spectralWindowId'] = spwid
        scandict[fid]['freqLO'] = freqLO
        scandict[fid]['numLO'] = numLO
        scandict[fid]['receiverId'] = receiverId
        scandict[fid]['frequencyBand'] = frequencyBand
        fid +=1
    return(scandict)

def getNumChanFromASDM(sdmfile, scienceOnly=False):
    """
    Gets the number of channels of each spw from an ASDM.
    scienceOnly: if True, limit the result to the science spws
    Returns: a dictionary keyed by spw ID, with value = number of channels.
    -Todd Hunter
    """
    spws = getSpwsFromASDM(sdmfile)
    scienceSpws = getScienceSpwsFromASDM(sdmfile)
    mydict = {}
    for spw in spws:
#        print "%2d: %4d" % (spw, spws[spw]['numChan'])
        if not scienceOnly or spw in scienceSpws:
            mydict[spw] = spws[spw]['numChan']
    return(mydict)

def getMeanFreqFromASDM(sdmfile, minnumchan=64, spws=None, scienceOnly=True):
    """
    Gets the mean frequency of the spectral windows for each sideband, assuming
    that the bandwidth of each spw is the same.  Useful for holography data.
    spws: limit the calculation to the specified spws (as they will be numbered in the ms)
    scienceOnly: ignore spws that do not have OBSERVE_TARGET intent

    Returns:
    dictionary of the form: {'lsb': {'meanfreq': meanfreq, 'spws': nspws},
                             'usb': {'meanfreq': meanfreq, 'spws': nspws},
                             'mean': {'meanfreq': meanfreq, 'spws': nspws}}
    -Todd Hunter
    """
    mydict = getSpwsFromASDM(sdmfile, minnumchan)
    lsb = []
    usb = []
    if (type(spws) == str):
        spws = spws.split(',')
    elif (type(spws) == int):
        spws = [spws]
    if scienceOnly:
        scienceSpws = getScienceSpwsFromASDM(sdmfile)
    for spw in mydict:
        if (spws is not None):
            if (spw not in spws): continue
        if scienceOnly:
            if spw not in scienceSpws: continue
        if (mydict[spw]['sideband'] == -1):
            lsb.append(mydict[spw]['centerFreq'])
        elif (mydict[spw]['sideband'] == 1):
            usb.append(mydict[spw]['centerFreq'])
    if len(lsb) < 1:
        meanfreq = np.mean(usb)
    elif len(usb) < 1:
        meanfreq = np.mean(lsb)
    else:
        meanfreq = np.mean([np.mean(usb),np.mean(lsb)])
    mydict = {'lsb': {'meanfreq': np.mean(lsb), 'spws': len(lsb)},
              'usb': {'meanfreq': np.mean(usb), 'spws':len(usb)},
              'mean': {'meanfreq': meanfreq,
                       'spws':len(usb)+len(lsb)}
              }
    return(mydict)

def listobsasdm(asdm, listfile=''):
    """
    Prints a summary of the scans, fields and spws, similar to listobs for
    a measurement set.
    listfile: True to create asdm'.listobs', or a filename
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if listfile != '':
        if (listfile == True):
            listfile = asdm + '.listobs'
        f = open(listfile,'w')
    else:
        f = ''
    a = asdm+' observed from %s' % (getObservationDateRangeFromASDM(asdm))
    if listfile != '':
        f.write(a+'\n')
    print a
    listscans(asdm, f)
    mydict = getSpwsFromASDM(asdm)
    a = "SpwID Name %s  #Chans Sideband  Ch0(MHz)  ChanWid(kHz)  TotBW(kHz) CtrFreq(MHz) BB" % (36*' ')
    if listfile != '':
        f.write(a+'\n')
    print a
    for i,key in enumerate(mydict.keys()):
        nchan = mydict[key]['numChan']
        sideband = mydict[key]['sideband']
        sb = 'DSB' 
        if sideband==-1:
            sb = 'LSB'
        elif sideband==1:
            sb= 'USB'
        a = "  %2d  %-42s  %4d    %s  %11.3f  %11.3f  %10.1f  %11.3f  %d" % (i,
                            mydict[key]['name'],
                            nchan, sb,
                            mydict[key]['chanFreqStart']*1e-6,
                            mydict[key]['chanWidth']*1e-3,
                            nchan*mydict[key]['chanWidth']*1e-3,
                            mydict[key]['centerFreq']*1e-6,
                            mydict[key]['basebandNumber'],
                            )
        if listfile != '':
            f.write(a+'\n')
        print a
    if listfile != '':
        f.close()
        print "listobs = ", listfile

def getSpwsFromASDM(sdmfile, minnumchan=0, dropExtraWVRSpws=True):
    """
    Returns a dictionary of the spw information for every spw in the specified
    ASDM.  Dictionary contents: chanFreqStart, chanWidth, windowFunction, name
       spectralWindowId, numChan, refFreq, sideband, effectiveBw, basebandNumber,
       resolution, centerFreq.  
    The keys are the spw numbers that the spws will have upon loading into a 
    measurement set.
    minnumchan: only return information on those spws with at least this many 
                channels
    Todd Hunter
    """
    if (os.path.exists(sdmfile) == False):
        print "getSpwsFromASDM(): Could not find file = ", sdmfile
        return
    xmlscans = minidom.parse(sdmfile+'/SpectralWindow.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    firstWVR = True
    for rowNumber, rownode in enumerate(rowlist):
        rowspwid = rownode.getElementsByTagName("spectralWindowId")
        spwid = int(str(rowspwid[0].childNodes[0].nodeValue).split('_')[1])
        rownumLO = rownode.getElementsByTagName("numChan")
        numChan = int(rownumLO[0].childNodes[0].nodeValue)
        if (numChan < minnumchan): 
            if (numChan == 4):
                if (firstWVR):
                    fid += 1
                    firstWVR = False
            else:
                fid += 1
            continue
        scandict[fid] = {}
        rownumLO = rownode.getElementsByTagName("refFreq")
        refFreq = float(rownumLO[0].childNodes[0].nodeValue)
        rownumNOBB = rownode.getElementsByTagName("basebandName")
        noBB = rownumNOBB[0].childNodes[0].nodeValue
        rownumName = rownode.getElementsByTagName("name")
        name = rownumName[0].childNodes[0].nodeValue
        rownumWF = rownode.getElementsByTagName("windowFunction")
        windowFunction = str(rownumWF[0].childNodes[0].nodeValue)
        try:
            rownumWF = rownode.getElementsByTagName("effectiveBw")
            effectiveBw = float(rownumWF[0].childNodes[0].nodeValue)
        except:
            rownumWF = rownode.getElementsByTagName("effectiveBwArray")
            effectiveBw = float(filter(None,(rownumWF[0].childNodes[0].nodeValue).split())[2])
        try:
            rownumWF = rownode.getElementsByTagName("chanWidth")
            chanWidth = float(rownumWF[0].childNodes[0].nodeValue)
        except:
            rownumWF = rownode.getElementsByTagName("chanWidthArray")
            chanWidth = float(filter(None,(rownumWF[0].childNodes[0].nodeValue).split())[2])
        try:
            rownumWF = rownode.getElementsByTagName("resolution")
            resolution = float(rownumWF[0].childNodes[0].nodeValue)
        except:
            rownumWF = rownode.getElementsByTagName("resolutionArray")
            resolution = float(filter(None,(rownumWF[0].childNodes[0].nodeValue).split())[2])
        scandict[fid]['spectralWindowId'] = spwid
        scandict[fid]['numChan'] = numChan
        scandict[fid]['refFreq'] = refFreq
        scandict[fid]['windowFunction'] = windowFunction
        scandict[fid]['effectiveBw'] = effectiveBw
        scandict[fid]['resolution'] = resolution
        scandict[fid]['chanWidth'] = chanWidth
        scandict[fid]['name'] = name
        if (noBB == 'NOBB'):
            scandict[fid]['basebandNumber'] = 0
        else:
            scandict[fid]['basebandNumber'] = int(noBB.split('_')[-1])
        try:
            rownumLO = rownode.getElementsByTagName("chanFreqStart")
            chanFreqStart = float(rownumLO[0].childNodes[0].nodeValue)
            rownumLO = rownode.getElementsByTagName("chanFreqStep")
            chanFreqStep = float(rownumLO[0].childNodes[0].nodeValue)
            if ((numChan % 2) == 1):
                centerFreq = chanFreqStart + (numChan/2)*chanFreqStep
            else:
                centerFreq = chanFreqStart + (numChan-1)*0.5*chanFreqStep
        except:
            try:
                rownumLO = rownode.getElementsByTagName("chanFreqArray")
                r = filter(None,(rownumLO[0].childNodes[0].nodeValue).split(' '))
                freqLO = []
                for i in range(2,len(r)):
                    freqLO.append(float(r[i]))
                centerFreq = np.mean(freqLO)
                chanFreqStart = freqLO[0]
            except:
                print "Did not find chanFreqStart nor chanFreqArray on row=%d, spw=%d" % (fid,spwid)
                scandict[fid]['centerFreq'] = 0
                continue
        scandict[fid]['centerFreq'] = centerFreq
        scandict[fid]['chanFreqStart'] = chanFreqStart
        if (refFreq > centerFreq):
            scandict[fid]['sideband'] = -1
        else:
            scandict[fid]['sideband'] = +1
        if (scandict[fid]['numChan'] != 4 or firstWVR or dropExtraWVRSpws==False):
            if (firstWVR and scandict[fid]['numChan'] == 4):
                scandict[fid]['sideband'] = 0
                firstWVR = False
            fid +=1
    return(scandict)

def getReceiverId(vis):
    """
    Reads the LO and receiver information from the ASDM_RECEIVER table of 
    a measurement set. -Todd Hunter
    """
    result = getLOs(vis, verbose=False)
    if len(result) == 0: return
    [freqLO,band,spws,names,sidebands,receiverIds,spwNames] = result
    receiverId = np.unique(receiverIds)
    if len(receiverId) == 1: # this is the cyrostat ID number
        # Should only ever be one value (i.e. same for all spws)
        return receiverId[0]
    else:
        return receiverId
    
def getLOs(inputMs, verbose=True):
    """
    Reads the LO information from an ms's ASDM_RECEIVER table.  It returns
    a list of 7 lists: [freqLO,band,spws,names,sidebands,receiverIDs,spwnames]
    The logic for converting this raw list into sensible association with
    spw numbers is in printLOs().  These lists are longer than the true number 
    of spws by Nantennas-1 due to the extra WVR spws.
    -Todd Hunter
    """
    if (os.path.exists(inputMs)):
        mytb = createCasaTool(tbtool)
        if (os.path.exists("%s/ASDM_RECEIVER" % inputMs)):
            try:
                mytb.open("%s/ASDM_RECEIVER" % inputMs)
            except:
                print "Could not open the existing ASDM_RECEIVER table"
                mytb.close()
                return([])
        else:
            if (os.path.exists(inputMs+'/ASDMBinary')):
                print "This is an ASDM, not an ms!  Use printLOsFromASDM."
            else:
                if (verbose):
                    print "The ASDM_RECEIVER table for this ms does not exist."
            mytb.close()
            return([])
    else:
        print "This ms does not exist = %s." % (inputMs)
        return([])
        
    numLO = mytb.getcol('numLO')
    freqLO = []
    band = []
    spws = []
    names = []
    sidebands = []
    receiverIds = []
    for i in range(len(numLO)):
        spw = int((mytb.getcell('spectralWindowId',i).split('_')[1]))
        if (spw not in spws):
            spws.append(spw)
            freqLO.append(mytb.getcell('freqLO',i))
            band.append(mytb.getcell('frequencyBand',i))
            names.append(mytb.getcell('name',i))
            sidebands.append(mytb.getcell('sidebandLO',i))
            receiverIds.append(int(mytb.getcell('receiverId',i)))
    mytb.close()
    mytb.open("%s/SPECTRAL_WINDOW" % inputMs)
    spwNames = mytb.getcol("NAME")
    mytb.close()
    return([freqLO,band,spws,names,sidebands,receiverIds,spwNames])
    
def mjdVectorToUTHours(mjd):
    """
    Converts a vector of MJD values to a vector of floating point hours (0-24).
    Todd Hunter
    """
    return(24*(np.modf(mjd)[0]))

def mjdSecondsVectorToMJD(mjdsec):
    return(mjdsec / 86400.0)

def call_qa_time(arg, form='', prec=0, showform=False):
    """
    This is a wrapper for qa.time(), which in casa 4.0.0 returns a list 
    of strings instead of just a scalar string.  
    arg: a time quantity
    - Todd Hunter
    """
    if (type(arg) == dict):
        if (type(arg['value']) == list or 
            type(arg['value']) == np.ndarray):
            if (len(arg['value']) > 1):
                print "WARNING: call_qa_time() received a dictionary containing a list of length=%d rather than a scalar. Using first value." % (len(arg['value']))
            arg['value'] = arg['value'][0]
    result = qa.time(arg, form=form, prec=prec, showform=showform)
    if (type(result) == list or type(result) == np.ndarray):
        return(result[0])
    else:
        return(result)

def call_qa_angle(arg, form='', prec=0, showform=False):
    """
    This is a wrapper for qa.angle(), which in casa 4.0.0 returns a list 
    of strings instead of just a scalar string.  
    - Todd Hunter
    """
    if (type(arg) == dict):
        if (type(arg['value']) == list or 
            type(arg['value']) == np.ndarray):
            if (len(arg['value']) > 1):
                print "WARNING: call_qa_angle() received a dictionary containing a list of length=%d rather than a scalar. Using first value." % (len(arg['value']))
            arg['value'] = arg['value'][0]
    result = qa.angle(arg, form=form, prec=prec, showform=showform)
    if (type(result) == list or type(result) == np.ndarray):
        return(result[0])
    else:
        return(result)

def yearFraction(date=''):
    """
    Gets the fractional year for a specified date time string.
    Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
    The time portion is optional.
    returns:   2011.78904019
     Note: returns 2000.000 for 2000/01/01 12:00:00 UT as per definition
    -Todd Hunter
    """
    if (date == ''): date = mjdToUT()
    doy = doyFromDate(date)
    mjd = dateStringToMJD(date,verbose=False)
    mydt = mjdListToDateTime([mjd])[0]
    days = (datetime.datetime(mydt.year,12,31)-datetime.datetime(mydt.year,1,1)).days+1
    return mydt.year+(doy-1.5+(mjd%1))*1.0/days

def doyFromDate(date='', fractional=False):
    """
    Gets the day number for a specified date time string"
    Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
    The time portion is optional.
    Returns: integer,  e.g. 288
    -Todd Hunter
    """
    if (date == ''): date = mjdToUT()
    mydt = mjdListToDateTime([dateStringToMJD(date,verbose=False)])[0]
    diff = (mydt - datetime.datetime(mydt.year, 1, 1))
    if fractional:
        doy = 1 + diff.days + (diff.seconds % 86400)/86400.
    else:
        doy = 1 + diff.days
    return doy

def dateFromDoy(year, doy, delimiter='/', hms=False):
    """
    Build a date string from the year and day-of-year.
    Inputs:
    year: integer
    doy: integer (1= Jan1)
    delimiter: string to delimit year, month, day
    hms: if True, then also include HH:MM:SS
    Returns: string of format: YYYY/MM/DD
    -Todd Hunter
    """
    mydate = datetime.datetime(year, 1, 1) + datetime.timedelta(days=doy-1)
    if hms:
        myformat = "%%Y%s%%m%s%%d%s%%H:%%M:%%S" % (delimiter, delimiter,delimiter)
    else:
        myformat = "%%Y%s%%m%s%%d" % (delimiter, delimiter)
    mystring = datetime.datetime.strftime(mydate,myformat)
    return mystring

def getMJD():
    """
    Returns the current MJD.  See also getCurrentMJDSec().
    -Todd
    """
    myme = createCasaTool(metool)
    mjd = myme.epoch('utc','today')['m0']['value']
    myme.done()
    return(mjd)
    
def mjdListToDateTime(mjdList):
    """
    Takes a list of mjd values and converts it to a list of datetime 
    structures.
    - Todd Hunter
    """
    return(mjdSecondsListToDateTime(np.array(mjdList)*86400.0))

def dateTimeListToMJDSeconds(dateTimeList, verbose=False):
    """
    Converts a list of datetime structures to a list of MJD seconds (floating point).
    Inverse of mjdSecondsListToDateTime.
    -Todd Hunter.
    """
    mjdsec = []
    for mydate in dateTimeList:
        mystring = datetime.datetime.strftime(mydate,"%Y/%m/%d %H:%M:%S.%f")
        mjdsec.append(dateStringToMJDSec(mystring,verbose=verbose))
    return(mjdsec)
              
def mjdSecondsListToDateTime(mjdsecList, use_metool=True):
    """
    Takes a list of mjd seconds and converts it to a list of datetime 
    structures.
    use_metool: whether or not to use the CASA measures tool if running from 
        CASA. Automatically set False if CASAPATH is not defined.  Note that 
        results are truncated to seconds if use_metool=False.
    - Todd Hunter
    """
    if (casaAvailable and use_metool):
        myme = createCasaTool(metool)
    dt = []
    typelist = type(mjdsecList)
    if not (typelist == list or typelist == np.ndarray):
        mjdsecList = [mjdsecList]
    for mjdsec in mjdsecList:
        if (not casaAvailable or use_metool==False):
            jd = mjdToJD(mjdsec / 86400.)
            trialUnixTime = 1200000000
            diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
            trialUnixTime -= diff*86400
            diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
            trialUnixTime -= diff*86400
            diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
            timeString = timeUtilities.strftime('%d-%m-%Y %H:%M:%S.0', 
                                                timeUtilities.gmtime(trialUnixTime))
        else:
            today = myme.epoch('utc','today')
            mjd = mjdsec / 86400.
            today['m0']['value'] =  mjd
            hhmmss = call_qa_time(today['m0'])
            date = qa.splitdate(today['m0'])  # date is now a dict
            timeString = '%d-%d-%d %d:%d:%d.%06d'%(date['monthday'],date['month'],date['year'],date['hour'],date['min'],date['sec'],date['usec'])
        mydate = datetime.datetime.strptime(timeString,'%d-%m-%Y %H:%M:%S.%f')
        # previous implementation truncated to nearest second!
#        mydate = datetime.datetime.strptime('%d-%d-%d %d:%d:%f'%(date['monthday'],date['month'],date['year'],date['hour'],date['min'],date['s']),'%d-%m-%Y %H:%M:%S')
        dt.append(mydate)
    if (casaAvailable and use_metool):
        myme.done()
    return(dt)

def mjdToPredictcomp(MJD=None):
    """
    Converts an MJD into a string suitable for the epoch parameter of
    predictcomp:
    i.e., 2011-12-31-5:34:12
    -- Todd Hunter
    """
    if (MJD==None):
        MJD = getMJD()
    mystring = mjdsecToUT(MJD*86400)
    tokens = mystring.split()
    return(tokens[0]+'-'+tokens[1])
    
def mjdToJD(MJD=None):
    """
    Converts an MJD value to JD.  Default = now.
    """
    if (MJD==None): MJD = getMJD()
    JD = MJD + 2400000.5
    return(JD)

def ymdhmsToMJD(year,month,day,hour=0,minute=0,second=0.0):
    """
    converts 2010,12,31 to MJD on Dec 31, 2010 at UT=0
    converts 2010,12,31,9.50 to MJD on Dec 31, 2010 at UT=09:30
    converts 2010,12,31,9,0,5 to MJD on Dec 31, 2010 at UT=09:05
    required arguments: year, month, day
    optional arguments: hour, minute, second
    """
    if (month < 3):
        month += 12
        year -= 1
    a =  floor(year / 100.)
    b = 2 - a + floor(a/4.)
    UT = hour+minute/60.+second/3600.
    day += UT/24.
    jd  = floor(365.25*(year+4716)) + floor(30.6001*(month+1)) + day + b - 1524.5;
    mjd = jdToMJD(jd)
    return(mjd)

def jdToMJD(JD):
    """
    Converts a JD value to MJD by subtracting 2400000.5
    """
    MJD = JD - 2400000.5
    return(MJD)

def mjdsecToDate(mjdsec=None, measuresToolFormat=False):
    """
    Converts an MJD seconds value to the date string YYYY-MM-DD.
    For a string with date and time, use mjdsecToUT().
    -Todd Hunter
    """
    if mjdsec==None:
        mjdsec = getMJDSec()
    if (type(mjdsec) == list or type(mjdsec) == np.ndarray):
        retval = [mjdsecToUT(m).split()[0] for m in mjdsec]
        if measuresToolFormat:
            retval = [mjdsecToUT(m).split()[0].replace(' UT','').replace('-','/').replace(' ','/') for m in mjdsec]
    else:
        retval =  mjdsecToUT(mjdsec).split()[0]
        if measuresToolFormat:
            retval = retval.replace(' UT','').replace('-','/').replace(' ','/')
    return(retval)

def mjdsecToUT(mjdsec=None, prec=6, measuresToolFormat=False):
    """
    Converts an MJD seconds value to a UT date and time string
    such as '2012-03-14 00:00:00 UT'.  For a string with only the
    date, use mjdsecToDate().
    -Todd Hunter
    """
    if mjdsec==None: mjdsec = getCurrentMJDSec()
    if (type(mjdsec) == list or type(mjdsec) == np.ndarray):
        retval = [mjdSecondsToMJDandUT(m, prec=prec)[1] for m in mjdsec]
        if measuresToolFormat:
            retval = [mjdSecondsToMJDandUT(m, prec=prec)[1].replace(' UT','').replace('-','/').replace(' ','/') for m in mjdsec]
    else:
        retval = mjdSecondsToMJDandUT(mjdsec, prec=prec)[1]
        if measuresToolFormat:
            retval = retval.replace(' UT','').replace('-','/').replace(' ','/')
    return(retval)
        
def mjdsecToUTHMS(mjdsec=None, prec=6):
    """
    Converts MJD seconds to HH:MM:SS
    prec: 6 means HH:MM:SS,  7 means HH:MM:SS.S
    -Todd Hunter
    """
    if mjdsec==None: mjdsec = getCurrentMJDSec()
    hms = mjdsecToUT(mjdsec, prec=prec).split()[1]
    return(hms)
    
def mjdsecToUTHM(mjdsec=None):
    """
    Converts MJD seconds to HH:MM
    -Todd Hunter
    """
    if mjdsec==None: mjdsec = getCurrentMJDSec()
    hms = mjdsecToUTHMS(mjdsec)
    hm = hms.split(':')[0] + ':' + hms.split(':')[1]
    return(hm)

def mjdToUT(mjd=None, use_metool=True, prec=6):
    """
    Converts an MJD value to a UT date and time string
    such as '2012-03-14 00:00:00 UT'
    use_metool: whether or not to use the CASA measures tool if running from CASA.
         This parameter is simply for testing the non-casa calculation.
    -Todd Hunter
    """
    if mjd==None:
        mjdsec = getCurrentMJDSec()
    else:
        mjdsec = mjd*86400
    utstring = mjdSecondsToMJDandUT(mjdsec, use_metool, prec=prec)[1]
    return(utstring)
        
def mjdNanosecondsToMJDandUT(mjdnanosec, prec=6, delimiter='-'):
    """
    -Todd Hunter
    """
    return(mjdSecondsToMJDandUT(mjdnanosec*1e-9, prec=prec, delimiter=delimiter))

def acsTimeToUnixTime(acsTime):
    return (acsTime - 122192928e9)/1e7

def dateStringToUnixTime(datestring):
    """
    Converts a UT date string to unix time"
    datestring: format YYYY-MM-DD HH:MM:SS
    -Todd Hunter
    """
    unixtime = dateStringDifference(datestring,'1970-01-01 00:00:00 UT')*60
    return unixtime

def unixTimeToDateString(unixtime=None):
    """
    Converts a time in unix time (seconds since 1970) to a string
    of the format 'YYYY-MM-DD HH:MM:SS UT'
    -Todd Hunter
    """
    if (unixtime == None):
        unixtime = getCurrentUnixTime()
    # could try this someday:
    #      return(datetime.datetime.fromtimestamp(unixtime).astimezone(pytz.utc).strftime('%Y-%m-%d %H:%M:%S UT'))
    jd = ComputeJulianDayFromUnixTime(unixtime)
    mjd = jdToMJD(jd)
    utstring = mjdsecToUT(mjd*86400)
    return(utstring)

def unixTimeToMJD(seconds):
    """
    Uses ComputeJulianDayFromUnixTime and jdToMJD.
    -Todd Hunter
    """
    return(jdToMJD(ComputeJulianDayFromUnixTime(seconds)))

def ComputeJulianDayFromUnixTime(seconds):
    """
    Converts a time expressed in unix time (seconds since Jan 1, 1970)
    into Julian day number as a floating point value.
    - Todd Hunter
    """
    [tm_year, tm_mon, tm_mday, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, tm_isdst] = timeUtilities.gmtime(seconds)
    if (tm_mon < 3):
        tm_mon += 12
        tm_year -= 1
    UT = tm_hour + tm_min/60. + tm_sec/3600.
    a =  floor(tm_year / 100.)
    b = 2 - a + floor(a/4.)
    day = tm_mday + UT/24.
    jd  = floor(365.25*((tm_year)+4716)) + floor(30.6001*((tm_mon)+1))  + day + b - 1524.5
    return(jd) 

def casapath():
    """
    Returns the root path of CASA.
    """
    return(os.getenv('CASAPATH').split()[0])

def mjdsecToDatestring(mjdsec='', delimiter='-'):
    """
    Converts a value (or list) in MJD seconds to YYYY-MM-DD HH:MM:SS
    delimiter: string to use to separate YYYY from MM and DD
    """
    if type(mjdsec) == str:
        if mjdsec == '':
            mjdsec = getMJDSec()
    if type(mjdsec) == list or type(mjdsec) == np.ndarray:
        values = []
        for i in mjdsec:
            values.append(mjdSecondsToMJDandUT(i,delimiter=delimiter)[1].split('UT')[0].strip())
        return values
    else:
        return(mjdSecondsToMJDandUT(mjdsec,delimiter=delimiter)[1].split('UT')[0].strip())

def mjdSecondsToMJDandUT(mjdsec, use_metool=True, debug=False, prec=6, delimiter='-'):
    """
    Converts a value of MJD seconds into MJD, and into a UT date/time string.
    prec: 6 means HH:MM:SS,  7 means HH:MM:SS.S
    example: (56000.0, '2012-03-14 00:00:00 UT')
    Caveat: only works for a scalar input value
    Todd Hunter
    """
    if (not casaAvailable or use_metool==False):
        mjd = mjdsec / 86400.
        jd = mjdToJD(mjd)
        trialUnixTime = 1200000000
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "first difference = %f days" % (diff)
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "second difference = %f seconds" % (diff*86400)
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "third difference = %f seconds" % (diff*86400)
        # Convert unixtime to date string 
        utstring = timeUtilities.strftime('%Y'+delimiter+'%m'+delimiter+'%d %H:%M:%S UT', 
                                          timeUtilities.gmtime(trialUnixTime))
    else:
        me = createCasaTool(metool)
        today = me.epoch('utc','today')
        mjd = np.array(mjdsec) / 86400.
        today['m0']['value'] =  mjd
        hhmmss = call_qa_time(today['m0'], prec=prec)
        date = qa.splitdate(today['m0'])
        utstring = "%s%s%02d%s%02d %s UT" % (date['year'],delimiter,date['month'],delimiter,
                                             date['monthday'],hhmmss)
    return(mjd, utstring)

def mjdsecToTimerange(mjdsec1, mjdsec2=None, decimalDigits=2, includeDate=True, 
                      use_metool=True, debug=False):
    """
    Converts two value of MJD seconds into a UT date/time string suitable for 
    the timerange argument in plotms.  They can be entered as two separated values,
    or a single tuple.
    Example output: '2012/03/14/00:00:00.00~2012/03/14/00:10:00.00'
    input options:
       decimalDigits: how many digits to display after the decimal point
       use_metool: True=use casa tool to convert to UT, False: use formula in aU
    -Todd Hunter
    """
    if (type(mjdsec1) == list or type(mjdsec1)==np.ndarray):
        mjdsec2 = mjdsec1[1]
        mjdsec1 = mjdsec1[0]
    return(mjdsecToTimerangeComponent(mjdsec1, decimalDigits, includeDate, use_metool, debug) + '~' \
           + mjdsecToTimerangeComponent(mjdsec2, decimalDigits, includeDate, use_metool, debug))
        
def mjdsecToTimerangeComponent(mjdsec, decimalDigits=2, includeDate=True, use_metool=True, debug=False):
    """
    Converts a value of MJD seconds into a UT date/time string suitable for one
    member of the timerange argument in plotms.
    example: '2012/03/14/00:00:00.00'
    input options:
       decimalDigits: how many digits to display after the decimal point
       use_metool: True=use casa tool to convert to UT, False: use formula in aU
    Todd Hunter
    """
    if (not casaAvailable or use_metool==False):
        mjd = mjdsec / 86400.
        jd = mjdToJD(mjd)
        trialUnixTime = 1200000000
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "first difference = %f days" % (diff)
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "second difference = %f seconds" % (diff*86400)
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        if (debug): print "third difference = %f seconds" % (diff*86400)
        # Convert unixtime to date string
        if (includeDate):
            utstring = timeUtilities.strftime('%Y/%m/%d/%H:%M:%S', 
                                              timeUtilities.gmtime(trialUnixTime))
        else:
            utstring = timeUtilities.strftime('%H:%M:%S', 
                                              timeUtilities.gmtime(trialUnixTime))
        utstring += '.%0*d'  % (decimalDigits, np.round(10**decimalDigits*(trialUnixTime % 1)))
    else:
        me = createCasaTool(metool)
        today = me.epoch('utc','today')
        mjd = np.array(mjdsec) / 86400.
        today['m0']['value'] =  mjd
        hhmmss = call_qa_time(today['m0'],prec=6+decimalDigits)
        date = qa.splitdate(today['m0'])
        if (includeDate):
            utstring = "%s/%02d/%02d/%s" % (date['year'],date['month'],date['monthday'],hhmmss)
        else:
            utstring = hhmmss
    return(utstring)

def addDays(date1, days=1):
    """
    Takes a string of format 'YYYY-MM-DD' and returns a new string a specified
    number of days later.  Can also use 'YYYYMMDD' or 'YYYY/MM/DD'.
    -Todd Hunter
    """
    return(subtractDays(date1, -days))

def subtractDays(date1, days=1):
    """
    Takes a string of format 'YYYY-MM-DD' and returns a new string a specified
    number of days before.  Can also use 'YYYYMMDD' or 'YYYY/MM/DD'.
    To add days, simply set days to be negative.
    See also computeIntervalBetweenTwoDays.
    -Todd Hunter
    """
    insertDash = False
    insertSlash = False
    if (date1.find('-')>0):
        insertDash = True
    elif (date1.find('/')>0):
        insertSlash = True
    date1 = date1.replace('-','').replace('/','')
    date0 = datetime.date(int(date1[0:4]),int(date1[4:6]),int(date1[6:])) - datetime.timedelta(days=days)
    if (insertDash):
        date0 = datetime.datetime.strftime(date0,'%Y-%m-%d')
    elif (insertSlash):
        date0 = datetime.datetime.strftime(date0,'%Y/%m/%d')
    else:
        date0 = datetime.datetime.strftime(date0,'%Y%m%d')
    return(date0)

def computeIntervalBetweenTwoDays(date1, date2):
    """
    Takes 2 strings of format 'YYYY-MM-DD' and returns the number of
    days between them.  Positive if date1 > date2.  See also subtractDays.
    -Todd Hunter
    """
    date1 = date1.replace('-','').replace('/','')
    date2 = date2.replace('-','').replace('/','')
    delta = datetime.date(int(date1[0:4]),int(date1[4:6]),int(date1[6:])) - \
            datetime.date(int(date2[0:4]),int(date2[4:6]),int(date2[6:]))
    return(delta.days)

def fillZerosInDate(datestring):
    """
    Converts a string like '2014-5-6' into '2014-05-06'.
    """
    if (datestring.find('-') > 0):
        key = '-'
    elif (datestring.find('/') > 0):
        key = '/'
    else:
        return datestring
    datestring = datestring.split(key)
    datestring = ['%02d'%int(i) for i in datestring]
    datestring = key.join(datestring)
    return datestring

def replaceMonth(datestring):
    """
    Replaces a 3-character month string with its 2-character integer string.
    -Todd Hunter
    """
    for i,month in enumerate(['jan','feb','mar','apr','may','jun','jul',
                              'aug','sep','oct','nov','dec']):
        datestring = datestring.lower().replace(month,'%02d'%(i+1))
    return(datestring.upper())
    
def dateStringToMJD(datestring='', datestring2='', verbose=True, use_metool=True):
    """
    Convert a date/time string to floating point MJD
    Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
                    or 2011-10-15_05:00:00
    The time portion is optional.
    If a second string is given, both values will be converted and printed,
    but only the first is returned.
    use_metool: this parameter is simply for testing the non-casa calculation
    -- Todd Hunter
    """
    if (datestring == ''):
        datestring = getCurrentDate()
    datestring = replaceMonth(datestring)
    if (datestring2 != ''): datestring2 = replaceMonth(datestring2)
    if (datestring.find('/') < 0):
        if (datestring.count('-') == 3 or datestring.find('T')>0):
            # This is needed to accept 2010-01-01-12:00:00 (accepted by predictcomp)'
            #                     or   2010-01-01T12:00:00 (output by ALMA TMC DB)'
            # by making it look like 2010-01-01 12:00:00'
            datestring = datestring[0:10] + ' ' + datestring[11:]
        if (datestring.count('-') != 2):
            print "Date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00"
            print"           or 2011-10-15 05:00:00  or   2011-10-15T05:00:00"
            print "The time portion is optional."
            return(None)
        else:
            d = datestring.split('-')
            datestring = d[0] + '/' + d[1] + '/' + d[2].split('T')[0]
    if (datestring2 != ''):
      if (datestring2.find('/') < 0):
        if (datestring2.count('-') == 3 or datestring2.find('T')>0):
            # This is needed to accept 2010-01-01-12:00:00 (accepted by predictcomp)'
            #                     or   2010-01-01T12:00:00 (output by ALMA TMC DB)'
            # by making it look like 2010-01-01 12:00:00'
            datestring2 = datestring2[0:10] + ' ' + datestring2[11:]
        if (datestring2.count('-') != 2):
            print "Date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00"
            print"           or 2011-10-15 05:00:00  or   2011-10-15T05:00:00"
            print "The time portion is optional."
            return(None)
        else:
            d = datestring2.split('-')
            datestring2 = d[0] + '/' + d[1] + '/' + d[2]
    mjd1 = dateStringToMJDSec(datestring, verbose=verbose,
                              use_metool=use_metool) / 86400.
    if (datestring2 != ''):
        mjd2 = dateStringToMJDSec(datestring2, verbose=verbose,
                                  use_metool=use_metool) / 86400.
    return(mjd1)

def replaceFinalAppearanceOfSubstringInString(string, substring, newvalue=' '):
    return string[::-1].replace(substring,newvalue,1)[::-1]

def dateStringListToPlotDate(mylist):
    """
    Converts a list of datetime strings to a list of time axis values that can
    be passed to pylab.plot_date().
    -Todd Hunter
    """
    mjdsecList = dateStringListToMJDSecList(mylist)
    list_of_date_times = mjdSecondsListToDateTime(mjdsecList)
    times = pb.date2num(list_of_date_times)
    return times

def dateStringListToMJDSecList(datestrings):
    """
    Calls dateStringToMJDSec for a list of date strings.
    Returns: a list of MJDseconds
    -Todd Hunter
    """
    mjdsec = []
    for d in datestrings:
        mjdsec.append(dateStringToMJDSec(d, verbose=False))
    return mjdsec
    
def dateStringToMJDSec(datestring='2011/10/15 05:00:00', datestring2='',
                       verbose=True, use_metool=True, plotrangeY=[0,0]):
    """
    Converts a date string into MJD seconds.  This is useful for passing
    time ranges to plotms, because they must be specified in mjd seconds.
    Because me.epoch is used to translate date strings (if use_metool=True), 
    any of these formats is valid: 2011/10/15 05:00:00
                                   2011/10/15/05:00:00
                                   2011/10/15-05:00:00
                                   2011-10-15 05:00:00
                                   2011-10-15_05:00:00
                                   2011-10-15T05:00:00
                                   2011-Oct-15T05:00:00
                                   15-Oct-2011/5:00:00 (listobs format)
    The time portion is optional. The listobs format only works with use_metool=True
    If a second string is given, both values will be converted and a
    string will be created that can be used as a plotrange in plotms.
    use_metool: this parameter is simply for testing the non-casa calculation
    
    For further help and examples, see:
    https://safe.nrao.edu/wiki/bin/view/ALMA/DateStringToMJDSec
    Todd Hunter
    """
    # me.epoch supports '29-Oct-2016 12:12:12', but does not support '29/Oct/2016 12:12:12'
    # so change all slashes to dashes
    datestring = datestring.replace('/','-')
    if (datestring.find('T') > 0):
        datestring = datestring.replace('T',' ')
    if (datestring.find('_') > 0):
        datestring = datestring.replace('_',' ')
    if (datestring.find('"') > 0):
        datestring = datestring.replace('"','')
    if (datestring[-1] in ['-','/']):
        datestring = datestring[:-1]
    mydate = datestring.split()
    
    if (len(mydate) < 2):
        # count slashes and dashes; if only one, then change it to a space
        n = datestring.count('-')
        if n in [1,3]:
            datestring = replaceFinalAppearanceOfSubstringInString(datestring,'-',' ')
        else:
            n = datestring.count('/')
            if n in [1,3]:
                datestring = replaceFinalAppearanceOfSubstringInString(datestring,'/',' ')
        mydate = datestring.split()
            
    # At this point, the date is in the format 2011-10-15
    hours = 0
    if (len(mydate) > 1):
        mytime = (mydate[1]).split(':')
        for i in range(len(mytime)):
            hours += float(mytime[i])/(60.0**i)
    if (not casaAvailable or not use_metool):
        if (mydate[0][4] in ['-','/']): # '2011/Oct/01'
            delimiter = mydate[0][4]
            year, month, day = mydate[0].split(delimiter)
        elif (mydate[0][2] in ['-','/']): # '01/Oct/2011'
            delimiter = mydate[0][2]
            day, month, year = mydate[0].split(delimiter)
        elif (mydate[0][1] in ['-','/']):  # '1/Oct/2011'
            delimiter = mydate[0][1]
            day, month, year = mydate[0].split(delimiter)
        mjd = ymdhmsToMJD(int(year),int(month),int(day),hours)
    else:
        me = createCasaTool(metool)
        me_epoch = me.epoch('utc',mydate[0])
        if (me_epoch != {}):
            mjd = me_epoch['m0']['value'] + hours/24.
        else:
            print "Bad date = ", mydate[0]
            return(0)
    mjdsec = 86400*mjd
    if (verbose):
        print "MJD= %.5f, MJDseconds= %.3f, JD= %.5f" % (mjd, mjdsec, mjdToJD(mjd))
    if (len(datestring2) > 0):
        mydate2 = datestring2.split()
        if (len(mydate2) < 1):
            return(mjdsec)
        if (len(mydate2) < 2):
            mydate2 = datestring2.split('-')
        hours = 0
        if (len(mydate2) > 1):
            mytime2 = (mydate2[1]).split(':')
            if (len(mytime2) > 1):
              for i in range(len(mytime2)):
                hours += float(mytime2[i])/(60.0**i)
#            print "hours = %f" % (hours)
        mjd = me.epoch('utc',mydate2[0])['m0']['value'] + hours/24.
        mjdsec2 = mjd*86400
        plotrange = [mjdsec, mjdsec2, plotrangeY[0], plotrangeY[1]]
        print "plotrange = %s" % (plotrange)
        mystr = '%.0f~%.0f' % (mjdsec, mjdsec2)
        print "plotrange = '%s'" % (mystr)
        return([mjdsec,mjdsec2], plotrange)
    else:
        return(mjdsec)
        

def plotPointingResults(vis='', figfile=False, source='',buildpdf=False,
                        gs='gs', convert='convert',
                        verbose=False, labels=False, pdftk='pdftk',debug=False,
                        interactive=True, nsigma=2, thresholdArcsec=10.0,
                        fractionOfScansBad=0.60, doplot=True):
    """
    This function will plot the pointing results for an ms, assuming that the
    ASDM_CALPOINTING table was filled, e.g. by importasdm(asis='*').  See also
    plotPointingResultsFromASDM(). The default behavior is to plot all sources
    that were pointed on.  In order to plot just one, then give the source
    name.  Setting labels=True will draw tiny antenna names at the points.
    If buildpdf does not work because gs or convert are not in the standard
    location, then you can specify the full paths with gs='' and convert=''.
    For further help and examples, see
    https://safe.nrao.edu/wiki/bin/view/ALMA/PlotPointingResults
    Todd Hunter
    """
    if (buildpdf and figfile==False):
        figfile=True
    fname = '%s/ASDM_CALPOINTING' % vis
    if (os.path.exists(fname)):
#        print "Trying to open table = %s" % fname
        mytb = createCasaTool(tbtool)
        mytb.open(fname)
    else:
        fname = './ASDM_CALPOINTING'
        if (os.path.exists(fname)):
            print "Looking for table in current directory"
            mytb.open(fname)
        else:
            print "No ASDM_CALPOINTING table found."
            return
    colOffsetRelative = ARCSEC_PER_RAD*mytb.getcol('collOffsetRelative')
    calDataId = mytb.getcol('calDataId')
    antennaName = mytb.getcol('antennaName')
    colError = ARCSEC_PER_RAD*mytb.getcol('collError')
    pols = mytb.getcol('polarizationTypes')
    startValidTime = mytb.getcol('startValidTime')
    uniqueAntennaNames = np.unique(antennaName)
    if (len(startValidTime) == 0):
        print "ASDM_CALPOINTING table is empty."
        return
    (mjd, utstring) = mjdSecondsToMJDandUT(startValidTime[0])
    print 'time = %f = %f = %s' % (startValidTime[0], mjd, utstring)
    mytb.close()
    #
    fname = '%s/ASDM_CALDATA'%vis
    if (os.path.exists(fname)):
        mytb.open(fname)
    else:
        fname = './ASDM_CALDATA'
        if (os.path.exists(fname)):
            mytb.open('./ASDM_CALDATA')
        else:
            print "Could not open ASDM_CALDATA table."
            return
    calDataList = mytb.getcol('calDataId')
    calType = mytb.getcol('calType')
    startTimeObserved = mytb.getcol('startTimeObserved')
    endTimeObserved = mytb.getcol('endTimeObserved')
    #        matches = np.where(calDataList == calDataId[0])
    matches = np.where(calType == 'CAL_POINTING')[0]
    print "Found %d pointing calibrations, in ASDM_CALDATA rows: " % (len(matches)), matches
    nscans = len(matches)
    mytb.close()
    if (doplot):
        plotfiles = []
        pointingPlots = []
    filelist = ''
    if (type(figfile)==str):
        if (figfile.find('/')):
            directories = figfile.split('/')
            directory = ''
            for d in range(len(directories)):
                directory += directories[d] + '/'
            if (os.path.exists(directory)==False):
                print "Making directory = ", directory
                os.system("mkdir -p %s" % directory)
    if (casadef.casa_version >= casaVersionWithMSMD):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        vm = 0
    else:
        vm = ValueMapping(vis)
    previousSeconds = 0
    antenna = 0
    uniquePointingScans = []
    outlier = {}
    radialErrors = {}
    for i in range(nscans):
        index = matches[i]
        if (debug):
            print "startTimeObserved[%d]=%f" % (index, startTimeObserved[index])
            print "  endTimeObserved[%d]=%f" % (index, endTimeObserved[index])
        # determine sourcename
        mytime = 0.5*(startTimeObserved[index]+endTimeObserved[index])
        if (debug):
            print "Time = ", mytime
        if (casadef.casa_version >= casaVersionWithMSMD):
            scan = mymsmd.scansfortimes(mytime)[0]
        else:
            scan = getScansForTime(vm.scansForTimes, mytime)
        uniquePointingScans.append(scan)
        radialErrors[uniquePointingScans[i]] = {}
        outlier[uniquePointingScans[i]] = {}
        if (debug):
            print "Scan = ", scan
        [avgazim,avgelev] = listazel(vis,scan,antenna,vm)
        if (casadef.casa_version >= casaVersionWithMSMD):
            pointingSource = mymsmd.namesforfields(mymsmd.fieldsforscan(scan)[0])[0]
        else:
            pointingSource = vm.getFieldsForScan(scan)[0].split(';')[0]
        if (source != ''):
            if (source != pointingSource):
                print "Source does not match the request, skipping"
                continue
        if (doplot):
            pb.clf()
            adesc = pb.subplot(111)
            c = ['blue','red']
        seconds = []
        for p in range(len(pols)):
            seconds.append(np.max(np.max(np.abs(colOffsetRelative[p][0])+colError[p][0])))
            seconds.append(np.max(np.max(np.abs(colOffsetRelative[p][1])+colError[p][1])))
        seconds = np.max(seconds)*1.25
        if (seconds <= previousSeconds):
            seconds = previousSeconds
        previousSeconds = seconds
        if (doplot):
            pb.xlim([-seconds,seconds])
            pb.ylim([-seconds,seconds])
            pb.hold(True)
        thisscan0 = np.where(startTimeObserved[index] < startValidTime)[0]
        thisscan1 = np.where(endTimeObserved[index] > startValidTime)[0]
        thisscan = np.intersect1d(thisscan0,thisscan1)
        mystd = []
        for p in range(len(pols)):
            mystd.append([np.std(colOffsetRelative[p][0]), np.std(colOffsetRelative[p][1])])
        for a in thisscan:
            antenna = np.where(uniqueAntennaNames==antennaName[a])[0][0]
            for p in range(len(pols)):
                if (verbose):
                    print "%s: %.2f, %.2f = %.2e, %.2e" % (uniqueAntennaNames[a],
                       colOffsetRelative[p][0][a], colOffsetRelative[p][1][a], 
                       colOffsetRelative[p][0][a]/ARCSEC_PER_RAD, colOffsetRelative[p][1][a]/ARCSEC_PER_RAD)
                if (doplot):
#                    pb.plot(colOffsetRelative[p][0][a], colOffsetRelative[p][1][a], 'o',
#                        markerfacecolor=overlayColors[antenna], markersize=6, color=overlayColors[antenna],
#                        markeredgecolor=overlayColors[antenna])
                    pb.errorbar(colOffsetRelative[p][0][a], colOffsetRelative[p][1][a], fmt='o',
                            yerr=colError[p][1][a], xerr=colError[p][0][a],
                            color=overlayColors[antenna], markersize=5,
                            markerfacecolor=overlayColors[antenna], markeredgecolor=overlayColors[antenna])
                    if (labels or abs(colOffsetRelative[p][0][a])>nsigma*mystd[p][0] or
                        abs(colOffsetRelative[p][1][a])>nsigma*mystd[p][1]):
                        pb.text(colOffsetRelative[p][0][a], colOffsetRelative[p][1][a],
                                antennaName[a], color='k', size=8)
                totalOffset = (colOffsetRelative[p][0][a]**2 + colOffsetRelative[p][1][a]**2)**0.5
                if (totalOffset > thresholdArcsec):
                    outlier[uniquePointingScans[i]][antennaName[a]] = [True, totalOffset]
                else:
                    outlier[uniquePointingScans[i]][antennaName[a]] = [False]
                radialErrors[uniquePointingScans[i]][antennaName[a]] = totalOffset
                
        if (doplot):
            # Draw spec
            cir = pb.Circle((0, 0), radius=2, facecolor='none', edgecolor='k', linestyle='dotted')
            pb.gca().add_patch(cir)
            pb.hold(False)
            pb.title('Relative collimation offsets at %s - %s scan %d' % (utstring,pointingSource,scan),fontsize=12)
            pb.axvline(0,color='k',linestyle='--')
            pb.axhline(0,color='k',linestyle='--')
            yFormatter = ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
            adesc.xaxis.set_major_formatter(yFormatter)
            if (False):
                minorTickSpacing = 1.0
                xminorLocator = MultipleLocator(minorTickSpacing)
                yminorLocator = MultipleLocator(minorTickSpacing)
                adesc.xaxis.set_minor_locator(xminorLocator)
                adesc.yaxis.set_minor_locator(yminorLocator)
                majorTickSpacing = 5.0
                majorLocator = MultipleLocator(majorTickSpacing)
                adesc.xaxis.set_major_locator(majorLocator)
                adesc.yaxis.set_major_locator(majorLocator)
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            pb.xlabel('Cross-elevation offset (arcsec)')
            pb.ylabel('Elevation offset (arcsec)')
            # now draw the legend for plotPointingResults
            myxlim = pb.xlim()
            myylim = pb.ylim()
            myxrange = myxlim[1]-myxlim[0]
            myyrange = myylim[1]-myylim[0]
            x0 = myxlim[0] + 0.05*myxrange
            y0 = myylim[1]-np.abs(myyrange*0.05)
            mystep = 0.025-0.0001*(len(uniqueAntennaNames)) # 0.020 for 50 antennas, 0.0225 for 25 antennas, etc.
            for a in range(len(antennaName[thisscan])):
                pb.text(myxlim[1]+0.02*myxrange,
                        myylim[1]-(a+1)*myyrange*mystep,
                        antennaName[thisscan][a],
                        color=overlayColors[list(uniqueAntennaNames).index(antennaName[thisscan][a])],
                        fontsize=10)
            pb.text(x0,y0,'azim=%+.0f, elev=%.0f'%(avgazim,avgelev),color='k', fontsize=14)
            pb.text(myxlim[0]+0.02*myxrange, myylim[1]+0.05*myyrange,vis,fontsize=12,color='k')
            pb.axis('scaled')
            pb.axis([-seconds,seconds,-seconds,seconds])
            if (figfile==True):
                myfigfile = vis+'.pointing.scan%02d.png' % (scan)
                pointingPlots.append(myfigfile)
                pb.savefig(myfigfile,density=144)
                plotfiles.append(myfigfile)
                print "Figure left in %s" % myfigfile
            elif (figfile != False):
                myfigfile=figfile
                pb.savefig(figfile,density=144)
                plotfiles.append(myfigfile)
                print "Figure left in %s" % myfigfile
            else:
                print "To make a hardcopy, re-run with figfile=True or figfile='my.png'"
            pb.draw()
            if (buildpdf == True):
                cmd = '%s -density 144 %s %s.pdf'%(convert,myfigfile,myfigfile)
                print "Running command = ", cmd
                mystatus = os.system(cmd)
                if (mystatus == 0):
                    print "plotfiles[i] = ", plotfiles[i]
                    filelist += plotfiles[i] + '.pdf '
                else:
                    print "ImageMagick's convert command is missing, no PDF created."
                    buildpdf = False
        if (i < nscans-1 and interactive):
            mystring = raw_input("Press return for next scan (or 'q' to quit): ")
            if (mystring.lower().find('q') >= 0):
                return
    if (casadef.casa_version >= casaVersionWithMSMD):
        mymsmd.close()
    # end 'for' loop over scans
    badAntennas = {}
    for antenna in uniqueAntennaNames:
        goodscans = 0.0
        radialErrorsThisAntenna = {}
        for scan in uniquePointingScans:
            # datasets with only 2 antennas have 1 antenna solution per scan
            if (antenna in radialErrors[scan]):
                radialErrorsThisAntenna[scan] = radialErrors[scan][antenna]
                if (outlier[scan][antenna][0]==False):
                    goodscans += 1.0
                
        badscans = len(uniquePointingScans)-goodscans
        if (badscans/len(uniquePointingScans) >= fractionOfScansBad):
            print "Antenna %s was an outlier (>%.1f arcsec) for %d/%d scans" % (antenna, thresholdArcsec, badscans, len(uniquePointingScans))
            badAntennas[antenna] = radialErrorsThisAntenna
                
    if (buildpdf and doplot):
        pdfname = vis+'.pointing.pdf'
        if (nscans > 1):
            mystatus = concatenatePDFs(filelist, pdfname, pdftk=pdftk, gs=gs)
        else:
            cmd = 'cp %s %s' % (filelist,pdfname)
            print "Running command = %s" % (cmd)
            mystatus = os.system(cmd)
        if (mystatus == 0):
            print "PDF left in %s" % (pdfname)
            os.system("rm -f %s" % filelist)
        else:
            print "Both pdftk and ghostscript are missing, no PDF created"
    return(pointingPlots, badAntennas)  
# end of plotPointingResults

def getFieldsFromASDMs(asdms):
    """
    Prints a dictionary of the field IDs/names for each ASDM in a list of ASDMs.
    -Todd Hunter
    """
    if type(asdms) == str:
        if asdms.find('*') >= 0:
            asdms = glob.glob(asdms)
        else:
            asdms = asdms.split(',')
    for asdm in asdms:
        if asdm.find('.ms') < 0:
            print '%s: %s' % (asdm,str(getFieldsFromASDM(asdm)[0]))

def getFieldsFromASDM(asdm):
    """
    Returns a dictionary with field IDs as the key, and names as the value,
    and another dictionary with the reverse.
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find file = ", asdm
        return
    xmlscans = minidom.parse(asdm+'/Field.xml')
    mydict = {}
    mydict2 = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        rowpwv = rownode.getElementsByTagName("fieldId")
        fieldid = int(rowpwv[0].childNodes[0].nodeValue.split('_')[1])
        rowpwv = rownode.getElementsByTagName("fieldName")
        fieldname = str(rowpwv[0].childNodes[0].nodeValue)
        mydict[fieldid] = fieldname
        mydict2[fieldname] = fieldid
    return(mydict, mydict2)
    

def getScanNumbersFromASDM(asdm, intent='CALIBRATE_ATMOSPHERE'):
    """
    Returns a list of scan numbers in an ASDM that have the
    specified intent, and a list of the number of subscans in each of these scans.
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    mydict = readscans(asdm)[0]
    scans = []
    subscans = []
    for scan in mydict.keys():
        if (intent == '' or mydict[scan]['intent'].find(intent)>=0):
            scans.append(scan)
            subscans.append(mydict[scan]['nsubs'])
    return(scans, subscans)

def getCalibratorFromASDMs(asdm, intent='PHASE'):
    """
    Returns a dictionary of observed calibrator names for the specified intent from a 
    list of ASDMs.
    asdm: a single ASDM or a comma-delimited list
    intent:  e.g., set to 'CAL' for all calibration intents
    -Todd Hunter
    """
    if type(asdm) == str:
        asdms = asdm.split(',')
    else:
        asdms = asdm
    cals = {}
    for asdm in asdms:
        cals[asdm] = getCalibratorFromASDM(asdm, intent)
    return cals

def getCalibratorFromASDM(asdm, intent='PHASE'):
    """
    Gets a list of calibrator names for the specified intent from an ASDM.
    asdm: a single ASDM 
    intent:  e.g., set to 'CAL' for all calibration intents
    -Todd Hunter
    """
    dicts = readscans(asdm)
    if (len(dicts[0]) == 0): return
    myscans = dicts[0]
    mysources = dicts[1]
    calibrators = []
    for key in myscans.keys():
        mys = myscans[key]
        if mys['intent'].find(intent) >= 0:
            calibrators.append(mys['source'])
    return list(np.unique(calibrators))

def readscans(asdm):
    """
    This function was ported from a version originally written by Steve Myers
    for EVLA.  It works for both ALMA and EVLA data.  It returns a dictionary
    containing: startTime, endTime, timerange, sourcename, intent, nsubs, 
    duration.
    Todd Hunter
    """
    # This function lives in a separate .py file.
    return(rs.readscans(asdm))

def getTargetsForIntent(vis, intent='OBSERVE_TARGET', mymsmd=''):
    """
    Gets a list of target names observed with the specified intent.
    intent: wildcards are added on both sides
    """
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    else:
        needToClose = False
    found = False
    for i in mymsmd.intents():
        if i.find(intent) >= 0:
            found = True
    if found:
        intent = '*' + intent + '*'
        targetNames = list(mymsmd.fieldsforintent(intent, asnames=True))
    else:
        targetNames = []
    if needToClose: mymsmd.close()
    return targetNames

def getTargetsForIntentFromASDM(asdm, intent='OBSERVE_TARGET'):
    """
    Gets a list of target names observed with the specified intent
    from an ASDM (minimum match).  Wildcards (*) are removed.
    intent:  e.g. 'PHASE'
    Returns: e.g. ['3c345']
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    mydict = rs.readscans(asdm)[0]
    targets = []
    intent = intent.replace('*','')
    for scan in mydict.keys():
        if (mydict[scan]['intent'].find(intent) >= 0):
            target = mydict[scan]['source']
            if target not in targets:
                targets.append(target)
    return targets

def getStartTimesForFieldFromASDM(asdm, field):
    """
    Gets a list of start times (in MJD) for the specified fieldname
    from an ASDM.
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    mydict = rs.readscans(asdm)[0]
    mjds = []
    for scan in mydict.keys():
        if (mydict[scan]['source'].find(field) >= 0):
            mjd = mydict[scan]['startmjd']
            mjds.append(mjd)
    return mjds

def getElevationStatsForIntentFromASDM(asdm, intent='OBSERVE_TARGET'):
    """
    Finds all sources observed with a given intent in an ASDM, then
    finds the statistics for the elevation that they were observed at.
    Returns: [minimum, median, max]
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    targets = getTargetsForIntentFromASDM(asdm, intent)
    if (len(targets) == 0):
        print "No targets found with intent = %s in %s" % (intent,asdm)
        return
    observatory = getObservatoryNameFromASDM(asdm)
    elev = []
    for target in targets:
        radec = getRADecForFieldFromASDM(asdm, target, sexagesimal=True)
        mjds = np.array(getStartTimesForFieldFromASDM(asdm, target))
        for mjd in mjds:
            az,el= computeAzElFromRADecMJD(radec, mjd, observatory,degrees=True)
            elev.append(el)
    return [np.min(elev), np.median(elev), np.max(elev)]

def listscans(asdm, listfile='', searchString=''):
    """
    This function was ported from a version originally written by Steve Myers
    for EVLA.  It works for both ALMA and EVLA data.  It prints the summary
    of each scan in the ASDM and the total time on each source.
    asdm: string or comma-delimited list, which can contain a wildcard character
    searchString: only relevant if a list of ASDMs is provided
    Returns:
    * a dictionary or a list of dictionaries if multiple ASDMs are specified
    Useful usage:  a = au.listscans('uid*','FLUX')
    Todd Hunter
    """
    result = []
    listfiles = []
    if (asdm.find('*') >= 0):
        if listfile == '':
            listfile = 'summary'
        asdmlist = glob.glob(asdm)
        for i,asdm in enumerate(asdmlist):
            listfile = listfile+'%02d'%i
            listfiles.append(listfile)
            result.append(rs.listscans(rs.readscans(asdm), listfile, asdm))
        summary = concatenateFiles(listfiles)
        if (searchString != ''):
            print grep(summary,searchString)[0]
    elif (asdm.find(',')>0):
        if listfile == '':
            listfile = 'summary'
        asdmlist = asdm.split(',')
        for i,asdm in enumerate(asdmlist):
            listfile = listfile+'%02d'%i
            listfiles.append(listfile)
            result.append(rs.listscans(rs.readscans(asdm), listfile, asdm))
        summary = concatenateFiles(listfiles)
        if (searchString != ''):
            print grep(summary,searchString)[0]
    else:
        result = rs.listscans(rs.readscans(asdm), listfile, asdm)
    return(result)

def plotPointingResultsFromASDMForDatasets(asdmlist, doplot=False,
            figfile=False, interactive=False, buildpdf=False,
                                           figfiledir=''):
    """
    Runs plotPointingResultsFromASDM on a list of ASDMs.
    Writes a text file with the list of suspect antennas.
    asdmlist: can be a string containing a wildcard character, which will use all matching files in pwd
         or it can be the name of a file which contains a list of files to use
          or it can be a list of asdms, i.e. ['uid1','uid2']
    doplot: create plots for each scan
    buildpdf: create plots for each scan and assemble them into a PDF
    figfile: specify the file name of the plots
         True:   the filenames will be asdm.pointing.scan%02d.png
         String: the filenames will be String.scan%02d, String.scan%02d, ...
    -Todd Hunter
    """
    if (not figfile and figfiledir != ''):
        figfile = True
    if (buildpdf or figfile):
        doplot = True
    if (type(asdmlist) == str):
        if (asdmlist.find('*') >= 0):
            outfile = 'plotPointingResultsForDatasets.txt'
            asdmlist = glob.glob(asdmlist)
        else:
            outfile = asdmlist+'.plotPointingResultsForDatasets.txt'
            asdmlist = getListOfFilesFromFile(asdmlist, appendms=False)
    else:
        outfile = 'plotPointingResultsForDatasets.txt'
    if (not os.access(".",os.W_OK)):
        outfile = '/tmp/' + outfile
    f = open(outfile,'w')
    pngs = []
    for asdm in asdmlist:
        if (asdm.find('.ms') > 0): continue
        if (not os.path.isdir(asdm)): 
            print "%s does not appear to be an ASDM, skipping." % (asdm)
            continue
        print "Working on %s" % (asdm)
        results = plotPointingResultsFromASDM(asdm,figfile=figfile,doplot=doplot,
                                              interactive=interactive,buildpdf=buildpdf,
                                              figfiledir=figfiledir)
        if (results is not None): 
            pointingPlots, badAntennas = results 
            f.write('%s   %s\nsuspect antennas = %s\n\n' % (asdm,getObservationStartDateFromASDM(asdm),str(badAntennas)))
            pngs += pointingPlots
    f.close()
    if (len(pngs) > 0):
        buildPdfFromPngs(pngs, pdfname=outfile+'.pdf', gs='/usr/bin/gs')
    print "Results left in %s" % (outfile)

def readPointingModelFromASDM(asdm, antenna=None, showBothPolarizations=False,
                              returnDictionary=False, verbose=True, showGlobal=True,
                              showAuxiliary=False):
    """
    Reads and lists the pointing model coefficients for one (or all) 
    antennas in an ASDM.
    asdm: ASDM
    antenna: antenna name string or antenna ID (as integer or string)
    showGlobal: show the local pointing corrections
    showAuxiliary: show the full 19-term model
    returnDictionary: if True, then return dictionary keyed by antenna name,
         then polarization ('X', 'Y', 'id'), then type ('GLOBAL', 'AUXILIARY')
         where 'id' is the antenna integer ID (for convenience)
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "readPointingModelFromASDM(): Could not find ASDM = ", asdm
        return(None)
    if (os.path.exists(asdm+'/PointingModel.xml') == False):
        print "readPointingModelFromASDM(): Could not find PointingModel.xml.", asdm
        return(None)
    antennaNames = readAntennasFromASDM(asdm, verbose=False)
    if (antenna is not None and antenna != ''):
        if (type(antenna) == str):
            if antenna.isdigit():
                antenna = int(antenna)
        if (type(antenna) == str):
            if (antenna not in antennaNames):
                print "Antenna %s is not in the ASDM." % (antenna)
                return
        else:
            if (antenna < 0 or antenna >= len(antennaNames)):
                print "Antenna %d is not in the ASDM." % (antenna)
                return
            antenna = antennaNames[antenna]
            
    xmlscans = minidom.parse(asdm+'/PointingModel.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    coeff = {}
    for rownode in rowlist:
        rowAntennaId = rownode.getElementsByTagName("antennaId")
        antennaId = str(rowAntennaId[0].childNodes[0].nodeValue)
        rowCoeffName = rownode.getElementsByTagName("coeffName")
        coeffName = str(rowCoeffName[0].childNodes[0].nodeValue)
        coeffNames = ', '.join(coeffName.split()[2:]).replace('"','')
        rowAssocNature = rownode.getElementsByTagName("assocNature")
        assocNature = str(rowAssocNature[0].childNodes[0].nodeValue)
        rowPolarizationType = rownode.getElementsByTagName("polarizationType")
        polarizationType = str(rowPolarizationType[0].childNodes[0].nodeValue)
        rowCoeffVal = rownode.getElementsByTagName("coeffVal")
        coeffVal = str(rowCoeffVal[0].childNodes[0].nodeValue)
        tokens = coeffVal.split()
        antennaId = int(antennaId.split('_')[1])
        antennaName = antennaNames[antennaId]
        if (antennaName not in coeff.keys()):
            coeff[antennaName] = {}
        if (polarizationType not in coeff[antennaName].keys()):
            coeff[antennaName][polarizationType] = {}
        if (assocNature not in coeff[antennaName][polarizationType].keys()):
            coeff[antennaName][polarizationType][assocNature] = []
        coeff[antennaName][polarizationType][assocNature].append([float(token) for token in tokens[2:]])
        coeff[antennaName]['id'] = antennaId
    antennaNames = coeff.keys()
    print ' '*21 + str(coeffNames)
    for antennaName in antennaNames:
        if (antenna == None or antenna == '' or antenna == antennaName):
            for polarizationType in coeff[antennaName].keys():
                if polarizationType == 'id': continue
                if (polarizationType == coeff[antennaName].keys()[0] or 
                    showBothPolarizations):
                    polString = ' pol'+polarizationType
                    if (not showBothPolarizations): polString = ''
                    for nature in coeff[antennaName][polarizationType].keys():
                        if (verbose and ((nature != 'GLOBAL' or showGlobal) or (nature != 'AUXILIARY' or showAuxiliary))):
                            for i in range(len(coeff[antennaName][polarizationType][nature])):
                                print "Ant%02d: %s%s: %s: %s" % (coeff[antennaName]['id'], antennaName, polString, nature, str(coeff[antennaName][polarizationType][nature][i]))
    if (returnDictionary):                        
        return(coeff)
        
def plotPointingResultsFromASDM(asdm='', figfile=False, buildpdf=False,
                                gs='gs', convert='convert', labels=False,
                                xrange=[0,0],yrange=[0,0], pdftk='pdftk',
                                interactive=True, thresholdArcsec=10.0,
                                figfiledir='', nsigma=2, 
                                fractionOfScansBad=0.60, doplot=True,
                                antenna=None, listsigma=False,
                                scienceSpws=None, figsize=[9,9]):
    """
    This function will plot the pointing results for an ASDM. To use an ms
    instead, see plotPointingResults(). The default behavior is to plot all
    sources that were pointed on.  In order to plot just one, then give the
    source name.
    Setting labels=True will draw tiny antenna names at the points.
    If buildpdf does not work because gs or convert are not in the standard
    location, then you can specify the full paths with gs='' and convert=''.
    figfile: can be False, True, or a string.
         False:  no plot produced
         True:   the filenames will be asdm.pointing.scan%02d.png
         String: the filenames will be String.scan%02d, String.scan%02d, ...
    figfiledir:  useful for figfile=True option, specifies the directory to
                 (create and) write 
    antenna: if name is specified, then plot corrections vs. time for it only
    listsigma: if True, then print ratio of offset/uncertainty
    thresholdArcsec: criterion for bad pointing=min(thresholdArcsec,halfPrimaryBeam)
                 (if a list of scienceSpws is specified)
    scienceSpws: comma-delimited string, or single integer;  if specified, then
         determine halfPrimaryBeam and use that for the threshold
    Returns: a list of figure file names produced, followed by a list of
        suspect antenna names (those that have errors larger than the
        threshold on all scans).
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/PlotPointingResultsFromASDM
    Todd Hunter
    """
    if (buildpdf and figfile==False):
        figfile=True
    asdm = asdm.rstrip('/')
    asdmNoPath = os.path.basename(asdm)
    source = ''
    result = readCalPointing(asdm)
    thresholdArcsec = float(thresholdArcsec) 
    if (result == None):
        return
    [colOffsetRelative,antennaName,startValidTime,pols,calDataID,azim,elev,colError,frequency] = result
    antennaName = np.array(antennaName)
    diameter = almaAntennaDiameter(antennaName[0])
    colOffsetRelative = np.array(colOffsetRelative)
    colError = np.array(colError)
    startValidTime = np.array(startValidTime)
    
    # Need to match calDataId to scan numbers
        
    scandict = rs.readscans(asdm)[0]
    caldict = readCalDataFromASDM(asdm)  # this contains translation from calDataId to scan number
    if (caldict == None):
        return
    uniqueScans = 1+np.array(range(len(scandict)))  # in this list, scans appear only once
    scans = []  # in this list, each scan will appear N times, where N=number of antennas
    for i in calDataID:
      for c in range(len(caldict)):
        if (int(caldict[c]['calDataId'].split('_')[1]) == i):
            scans.append(caldict[c]['scan'])

    pointingScans = []
    for i in range(len(caldict)):
        if (int(caldict[i]['calDataId'].split('_')[1]) in calDataID):
            pointingScans.append(caldict[i]['scan'])
    uniquePointingScans = np.unique(pointingScans)
    
    print "pointing scans = ", pointingScans
    pointingSources = ''
    for i in uniquePointingScans:
        pointingSources += scandict[i]['source'].split(';')[0]
        if (i != uniquePointingScans[-1]):
            pointingSources += ', '
    print "pointing sources = ",pointingSources
    nPointingScans = len(uniquePointingScans)
    if (len(startValidTime) == 0):
        print "CalPointing.xml table is empty."
        return
    
    plotfiles = []
    filelist = ''
    if (figfiledir != ''):
        if (os.path.exists(figfiledir) == False):
            print "Making directory: %s" % (figfiledir)
            os.makedirs(figfiledir)
        if (figfiledir[-1] != '/'): figfiledir += '/'
    if (type(figfile)==str):
        if (figfile.find('/')>=0 and figfiledir == ''):
            directories = figfile.split('/')
            directory = ''
            for d in range(len(directories)):
                directory += directories[d] + '/'
            if (os.path.exists(directory)==False):
                print "Making directory = ", directory
                os.system("mkdir -p %s" % directory)

    previousSeconds = 0
    uniqueAntennaNames = np.unique(antennaName)
    pointingPlots = []
    outlier = {}
    radialErrors = {}
    meanScienceBeam = False
    halfbeamPointingScan = primaryBeamArcsec(frequency = frequency[scans[0]], showEquation=False, diameter=diameter)*0.5
    halfbeamScience = primaryBeamArcsec(frequency=getMeanFreqFromASDM(asdm, scienceOnly=True)['mean']['meanfreq'], showEquation=False, diameter=diameter)*0.5
    if (scienceSpws == None):
        halfbeam = halfbeamPointingScan
        if (halfbeam < thresholdArcsec):
            print "Reducing threshold from %.1f arcsec to half the primary beam of a %.0fm antenna, which is %.1f arcsec for pointing scan %d." % (thresholdArcsec,diameter,halfbeam,scans[0])
            thresholdArcsec = halfbeam
    else:
        if (type(scienceSpws) == str):
            scienceSpws = scienceSpws.split(',')
        elif (type(scienceSpws) == int):
            scienceSpws = [scienceSpws]
        halfbeam = 0.5*primaryBeamArcsec(frequency = np.mean(getFrequenciesFromASDM(asdm,spws=scienceSpws)),
                                         showEquation=False, diameter=diameter)
        if (halfbeam < thresholdArcsec):
            print "Reducing threshold to half the primary beam of a %.0fm antenna, which is %.1f arcsec for mean science spw." % (diameter,halfbeam)
            thresholdArcsec = halfbeam
            meanScienceBeam = True
    if (antenna is not None and antenna.find('!') < 0):
        if (antenna not in uniqueAntennaNames):
            print "%s is not in the list of antennas: %s" % (antenna, uniqueAntennaNames)
            return
        rows = np.where(antennaName==antenna)[0]
        print "Found %d rows for %s = %s" % (len(rows), antenna, str(rows))
        offsets = []
        times = []
        errors = []
        for row in rows:
            times.append(startValidTime[row])
            offsets.append(colOffsetRelative[row])
            errors.append(colError[row])
        pb.clf()
        pb.gcf().set_size_inches(figsize[0], figsize[1], forward=True)
        adesc = pb.subplot(111)
        # azimuth
        times = (times - times[0])/60.
        pol = 0
        offsets = np.transpose(offsets)
        errors = np.transpose(errors)
        p1 = pb.errorbar(times, offsets[0][pol], yerr=errors[0][pol], fmt='o-',color='b')
        pb.hold(True)
        p2 = pb.errorbar(times, offsets[1][pol],fmt='o-',color='r', yerr=errors[1][pol])
        pb.legend([p1,p2],["azimuth","elevation"], loc=1)
        pb.ylabel('Offset (arcsec)')
        pb.title(asdm+'  '+antenna+'   '+getObservationStartDateFromASDM(asdm)[0])
        pb.draw()
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        pb.xlabel('Time (minutes)')
#        pb.ylabel('Elevation offset (arcsec)')
        if (figfile==True):
            myfigfile = figfiledir + asdmNoPath + '.pointing.%s.png' % (antenna)
            pb.savefig(myfigfile,density=144)
            print "Figure left in %s" % myfigfile
        elif (figfile != False):
            myfigfile = figfiledir + figfile.replace('.png','') + '.%s.png' % (antenna)
            pb.savefig(myfigfile, density=144)
            print "Figure left in %s" % myfigfile
        else:
            print "To make a hardcopy, re-run with figfile=True or figfile='my.png'"
            myfigfile = None
        return(myfigfile)
    else:
      if (antenna is not None):
          print "The !antenna option is not yet implemented"
      else:
          antenna = 0
      for i in range(nPointingScans):
        outlier[uniquePointingScans[i]] = {}
        radialErrors[uniquePointingScans[i]] = {}
        if (doplot):
            pb.ion()
            pb.clf()
            pb.gcf().set_size_inches(figsize[0], figsize[1], forward=True)
            adesc = pb.subplot(111)
        c = ['blue','red']
        seconds = []
        for p in range(len(pols)):
            seconds.append(np.max(np.max(np.abs(colOffsetRelative[p][0]))) + np.median(colError[0]))
            seconds.append(np.max(np.max(np.abs(colOffsetRelative[p][1]))) + np.median(colError[1]))
        seconds = np.max(seconds)*1.25
        if (seconds <= previousSeconds):
            # don't allow subsequent plots to cover a smaller range of sky
            seconds = previousSeconds
        previousSeconds = seconds
        if (doplot):
            pb.xlim([-seconds,seconds])
            pb.ylim([-seconds,seconds])
            pb.hold(True)
        thisscan = np.where(scans == uniquePointingScans[i])[0]
        mystd = []
        mystdOfError = [] 
        colOffsetRelativeTrans = np.transpose(colOffsetRelative[thisscan])
        colErrorTrans = np.transpose(colError[thisscan])
#        print "np.shape(colOffsetRelativeTrans) = ", np.shape(colOffsetRelativeTrans)
        for p in range(len(pols[thisscan[0]])):
            mystd.append([np.std(colOffsetRelativeTrans[0][p]), np.std(colOffsetRelativeTrans[1][p])])
            mystdOfError.append([np.std(colErrorTrans[0][p]), np.std(colErrorTrans[1][p])]) 
        for a in thisscan:
            # 'a' is now a row number that corresponds to the ith pointing scan
            antenna = np.where(uniqueAntennaNames==antennaName[a])[0][0]
            for p in range(len(pols[a])):
                if (doplot):
                    pb.errorbar(colOffsetRelative[a][p][0], colOffsetRelative[a][p][1], fmt='o',
                            yerr=colError[a][p][1], xerr=colError[a][p][0],
                            color=overlayColors[antenna], markersize=5,
                            markerfacecolor=overlayColors[antenna], markeredgecolor=overlayColors[antenna])
                totalOffset = (colOffsetRelative[a][p][0]**2 + colOffsetRelative[a][p][1]**2)**0.5
                totalError = (colError[a][p][0]**2 + colError[a][p][1]**2)**0.5
                if (listsigma and p==0):
                    print "%s: cross-elev: %5.1f  elevation: %5.1f   total: %5.1f" % (antennaName[a],
                                                  np.abs(colOffsetRelative[a][p][0]/colError[a][p][0]),
                                                  np.abs(colOffsetRelative[a][p][1]/colError[a][p][1]),
                                                  np.abs(totalOffset/totalError))
                if (totalOffset > thresholdArcsec):
                    outlier[uniquePointingScans[i]][antennaName[a]] = [True, totalOffset]
                else:
                    outlier[uniquePointingScans[i]][antennaName[a]] = [False]
                radialErrors[uniquePointingScans[i]][antennaName[a]] = totalOffset
                if (doplot and (labels or abs(colOffsetRelative[a][p][0])>nsigma*mystd[p][0] or
                                abs(colOffsetRelative[a][p][1])>nsigma*mystd[p][1]) or
                                (colError[a][p][0] > nsigma*mystdOfError[p][0]) or
                                (colError[a][p][1] > nsigma*mystdOfError[p][1])
                    ):
                    pb.text(colOffsetRelative[a][p][0], colOffsetRelative[a][p][1], 
                            antennaName[a], color='k', size=8)
        # Draw spec
        if (doplot):
            cir = pb.Circle((0, 0), radius=2, facecolor='none', edgecolor='k', linestyle='dotted')
            pb.gca().add_patch(cir)
#        print "scandict = ", scandict
#        print "len(scandict) = ", len(scandict)
#        print "\n scandict[%d].keys() = " % (uniquePointingScans[i]), scandict[uniquePointingScans[i]].keys()
        pointingSource = scandict[uniquePointingScans[i]]['source'].split(';')[0]
        (mjd, utstring) = mjdSecondsToMJDandUT(startValidTime[thisscan[0]])
        if (doplot):
            pb.title('Relative collimation offsets at %s - %s scan %d' % (utstring,pointingSource,uniquePointingScans[i]),fontsize=12)
            pb.axvline(0,color='k',linestyle='--')
            pb.axhline(0,color='k',linestyle='--')
            pb.xlabel('Cross-elevation offset (arcsec)')
            pb.ylabel('Elevation offset (arcsec)')
            pb.axis('scaled')
            if (xrange[0] != 0 or xrange[1] != 0):
                if (yrange[0] != 0 or yrange[1] != 0):
                    pb.axis([xrange[0],xrange[1],yrange[0],yrange[1]])
                else:
                    pb.axis([xrange[0],xrange[1],-seconds,seconds])
            elif (yrange[0] != 0 or yrange[1] != 0):
                pb.axis([-seconds,seconds, yrange[0], yrange[1]])
            else:
                pb.axis([-seconds,seconds,-seconds,seconds])

            # now draw the legend for plotPointingResultsFromASDM
            myxlim = pb.xlim()
            myylim = pb.ylim()
            myxrange = myxlim[1]-myxlim[0]
            myyrange = myylim[1]-myylim[0]
            x0 = myxlim[0] + 0.05*myxrange
            y0 = myylim[1]-np.abs(myyrange*0.05)
            cornerRadius = (myxlim[0]**2 + myylim[0]**2)**0.5
            if False:
                if (cornerRadius > thresholdArcsec):
                    cir = pb.Circle((0, 0), radius=thresholdArcsec, facecolor='none', edgecolor='r', linestyle='dashed')
                    pb.gca().add_patch(cir)
                    if (meanScienceBeam):
                        x1 = myxlim[1] - 0.05*myxrange
                        pb.text(x1,y0,'mean science beam',color='r',fontsize=14,ha='right')
            x1 = myxlim[1] - 0.05*myxrange
            pb.text(x1,y0,'all-sky specification',color='k',fontsize=14,ha='right')
            y0 -= np.abs(myyrange*0.05)
            if (cornerRadius > halfbeamScience):
                cir = pb.Circle((0, 0), radius=halfbeamScience, facecolor='none', edgecolor='r', linestyle='dashed')
                pb.gca().add_patch(cir)
                pb.text(x1,y0,'mean science beam',color='r',fontsize=14,ha='right')
                y0 -= np.abs(myyrange*0.05)
            if (cornerRadius > halfbeamPointingScan):
                cir = pb.Circle((0, 0), radius=halfbeamPointingScan, facecolor='none', edgecolor='c', linestyle='dashed')
                pb.gca().add_patch(cir)
                pb.text(x1,y0,'pointing beam',color='c',fontsize=14,ha='right')
            pb.text(x0,y0,'azim=%+.0f, elev=%.0f'%(azim[thisscan[0]],elev[thisscan[0]]),color='k', fontsize=14)
            asdmNoPath = asdm.split('/')[-1]
            pb.text(myxlim[0]+0.02*myxrange, myylim[1]+0.05*myyrange, asdmNoPath+', freq=%.1f GHz, diameter=%.0fm'%(frequency[thisscan[0]],diameter), 
                    fontsize=12,color='k')
            mystep = 0.025-0.0001*(len(uniqueAntennaNames)) # 0.020 for 50 antennas, 0.0225 for 25 antennas, etc.
            for a in range(len(uniqueAntennaNames)):
                pb.text(myxlim[1]+0.02*myxrange, myylim[1]-(a+1)*myyrange*mystep, uniqueAntennaNames[a], color=overlayColors[a],fontsize=10)
            pb.axvline(0,color='k',linestyle='--')
            pb.axhline(0,color='k',linestyle='--')
            yFormatter = ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
            adesc.xaxis.set_major_formatter(yFormatter)
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            if (figfile==True):
                myfigfile = figfiledir + asdmNoPath + '.pointing.scan%02d.png' % (uniquePointingScans[i])
                pointingPlots.append(myfigfile)
                pb.savefig(myfigfile,density=144)
                plotfiles.append(myfigfile)
                print "Figure left in %s" % myfigfile
            elif (figfile != False):
                myfigfile = figfiledir + figfile.replace('.png','') + '.scan%02d.png' % (uniquePointingScans[i])
                pb.savefig(myfigfile, density=144)
                plotfiles.append(myfigfile)
                print "Figure left in %s" % myfigfile
            else:
                print "To make a hardcopy, re-run with figfile=True or figfile='my.png'"
            if (buildpdf):
                cmd = '%s -density 144 %s %s.pdf'%(convert,myfigfile,myfigfile)
                print "Running command = ", cmd
                mystatus = os.system(cmd)
                if (mystatus == 0):
                    print "plotfiles[i] = ", plotfiles[i]
                    filelist += plotfiles[i] + '.pdf '
                else:
                    print "ImageMagick's convert command is missing, no PDF created."
                    buildpdf = False
            pb.draw()
            if (i < nPointingScans-1 and interactive):
                mystring = raw_input("Press return for next scan (or 'q' to quit): ")
                if (mystring.lower().find('q') >= 0):
                    return(pointingPlots)
      # end 'for' loop over scans
      badAntennas = {}
      for antenna in uniqueAntennaNames:
          goodscans = 0.0
          radialErrorsThisAntenna = {}
          for scan in uniquePointingScans:
              # datasets with only 2 antennas have 1 antenna solution per scan
              if (antenna in radialErrors[scan]):
                  radialErrorsThisAntenna[scan] = radialErrors[scan][antenna]
                  if (outlier[scan][antenna][0]==False):
                      goodscans += 1.0
                  
          badscans = len(uniquePointingScans)-goodscans
          if (badscans/len(uniquePointingScans) >= fractionOfScansBad):
              print "Antenna %s was an outlier (>%.1f arcsec) for %d/%d scans" % (antenna, thresholdArcsec, badscans, len(uniquePointingScans))
              badAntennas[antenna] = radialErrorsThisAntenna
                  
      if (buildpdf and doplot):
          pdfname = ''
          if (os.path.dirname(myfigfile) != ''):
              pdfname += os.path.dirname(myfigfile)+'/'
          pdfname += asdm+'.asdmpointing.pdf'
          if (nPointingScans > 1):
              mystatus = concatenatePDFs(filelist, pdfname, pdftk=pdftk, gs=gs)
          else:
              cmd = 'cp %s %s' % (filelist,pdfname)
              print "Running command = %s" % (cmd)
              mystatus = os.system(cmd)
          if (mystatus == 0):
              print "PDF left in %s" % (pdfname)
              os.system("rm -f %s" % filelist)
          else:
              print "Both pdftk and ghostscript are missing, no PDF created"
      return(pointingPlots, badAntennas)  
# end of plotPointingResultsFromASDM
            
def offlineTcAtmosphere(asdm, scanlist, mode='AH', origin='specauto', quantcorrection=False) :
    """
    Runs the casapy-telcal command tc_atmosphere to recompute the Trx/Tsys spectra
    in SysCal table.  Need to set showplot=False to avoid crash.
    """
    from tc_atmosphere_cli import tc_atmosphere_cli as tc_atmosphere
    if type(scanlist) == int:
        scanlist = [scanlist]
    for scan in scanlist :
        print scan
        tc_atmosphere(asdm=asdm, dataorigin=origin, trecmode=mode, scan=str(scan),
                      antenna='', calresult=asdm, showplot=False, verbose=False,
                      quantcorrection=quantcorrection)

def importasdm2(asdm, intent=''):
    """
    Translates a specified intent into a list of scans and then only imports those
    scans into a measurement set.
    """
    f = open(asdm+'/Scan.xml')
    fc = f.read()
    f.close()

    scanBlockList = re.findall('<row>.+?</row>', fc, re.DOTALL|re.MULTILINE)

    scanNumList = []

    for i in range(len(scanBlockList)):
        scanBlocksIntents = re.findall('<scanIntent>.+?</scanIntent>', scanBlockList[i])[0]
        if re.search(intent, scanBlocksIntents) is not None:
            scanNum1 = re.findall('<scanNumber>[0-9]+</scanNumber>', scanBlockList[i])
            if len(scanNum1) != 1: continue
            scanNum1 = re.findall('[0-9]+', scanNum1[0])
            if len(scanNum1) != 1: continue
            scanNumList.append(scanNum1[0])

    scanNumList = ','.join(scanNumList)

    importasdm(asdm, scans=scanNumList)

def readwvr(sdmfile, verbose=False):
    """
    This function reads the CalWVR.xml table from the ASDM and returns a
    dictionary containing: 'start', 'end', 'startmjd', 'endmjd',
    'startmjdsec', 'endmjdsec',
    'timerange', 'antenna', 'water', 'duration'.
    'water' is the zenith PWV in meters.
    This function is called by readpwv(). -- Todd Hunter
    """
    if (os.path.exists(sdmfile) == False):
        print "readwvr(): Could not find file = ", sdmfile
        return
    xmlscans = minidom.parse(sdmfile+'/CalWVR.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        rowpwv = rownode.getElementsByTagName("water")
        pwv = float(rowpwv[0].childNodes[0].nodeValue)
        water = pwv
        scandict[fid] = {}

        # start and end times in mjd ns
        rowstart = rownode.getElementsByTagName("startValidTime")
        start = int(rowstart[0].childNodes[0].nodeValue)
        startmjd = float(start)*1.0E-9/86400.0
        t = qa.quantity(startmjd,'d')
        starttime = call_qa_time(t,form="ymd",prec=8)
        rowend = rownode.getElementsByTagName("endValidTime")
        end = int(rowend[0].childNodes[0].nodeValue)
        endmjd = float(end)*1.0E-9/86400.0
        t = qa.quantity(endmjd,'d')
        endtime = call_qa_time(t,form="ymd",prec=8)
        # antenna
        rowantenna = rownode.getElementsByTagName("antennaName")
        antenna = str(rowantenna[0].childNodes[0].nodeValue)

        scandict[fid]['start'] = starttime
        scandict[fid]['end'] = endtime
        scandict[fid]['startmjd'] = startmjd
        scandict[fid]['endmjd'] = endmjd
        scandict[fid]['startmjdsec'] = startmjd*86400
        scandict[fid]['endmjdsec'] = endmjd*86400
        timestr = starttime+'~'+endtime
        scandict[fid]['timerange'] = timestr
        scandict[fid]['antenna'] = antenna
        scandict[fid]['water'] = water
        scandict[fid]['duration'] = (endmjd-startmjd)*86400
        fid += 1

    if verbose: print '  Found ',rowlist.length,' rows in CalWVR.xml'

    # return the dictionary for later use
    return scandict
# Done

def readpwv(asdm):
  """
  This function assembles the dictionary returned by readwvr() into arrays
  containing the PWV measurements written by TelCal into the ASDM.
  Units are in meters.
  -- Todd Hunter
  """
#  print "Entered readpwv"
  dict = readwvr(asdm)
#  print "Finished readwvr"
  bigantlist = []
  for entry in dict:
      bigantlist.append(dict[entry]['antenna'])
  antlist = np.unique(bigantlist)
  watertime = []
  water = []
  antenna = []
  for entry in dict:
      measurements = 1
      for i in range(measurements):
          watertime.append(dict[entry]['startmjdsec']+(i*1.0/measurements)*dict[entry]['duration'])
          water.append(dict[entry]['water'])
          antenna.append(dict[entry]['antenna'])
  return([watertime,water,antenna])   

def readSysCal(asdm):
    """
    This function reads the SysCal.xml table from the ASDM and checks
    how many Tsys entries there are for each combination of Antenna,
    time and spw (which should be 1). Reports the number of duplicates
    and returns a dictionary keyed by [antenna][spw] = list of timestamps
    -- Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "readsyscal(): Could not find file = ", asdm
        return
    xmlscans = minidom.parse(asdm+'/SysCal.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    duplicates = 0
    scandict = {}
    for rownode in rowlist:
        antennaID = rownode.getElementsByTagName("antennaId")
        antenna = int(str(antennaID[0].childNodes[0].nodeValue).split('_')[1])
        if (antenna not in scandict.keys()):
            scandict[antenna] = {}
        spwID = rownode.getElementsByTagName("spectralWindowId")
        spw = int(str(spwID[0].childNodes[0].nodeValue).split('_')[1])
        if (spw not in scandict[antenna].keys()):
            scandict[antenna][spw] = []
        timeData = rownode.getElementsByTagName("timeInterval")
        timeStamp = int(str(timeData[0].childNodes[0].nodeValue).split()[0])
        timeInterval = int(str(timeData[0].childNodes[0].nodeValue).split()[1])
        if (timeStamp-timeInterval/2 in scandict[antenna][spw]):
            print "Duplicate seen!"
            duplicates += 1
        else:
            scandict[antenna][spw].append(timeStamp-timeInterval/2)

        # start and end times in mjd ns
#        rowstart = rownode.getElementsByTagName("startValidTime")
#        start = int(rowstart[0].childNodes[0].nodeValue)
#        startmjd = float(start)*1.0E-9/86400.0
#        scandict[fid]['start'] = starttime
        fid += 1
    print '  Found ',rowlist.length,' Tsys rows in SysCal.xml'
    print "%d duplicates found" % (duplicates)
    return (scandict)

def replaceTsysFromSQLD(caltable, sqld, asdm, spws, verbose=False):
    """
    This is a utility to replace the Tsys spectrum for one combination
    of antenna+spw+pol+scan with the median value from the square law 
    detector Tsys located in the SysCal.xml table.
    Typically, the SysCal.xml table was produced manually by running 
    casapy-telcal offline.

    caltable: the name of the gencal-produced Tsys cal table to correct
    sqld: the path to the SysCal.xml file to get the SQLD Tsys values from
    asdm: the path to the original ASDM (with SpectralWindow.xml and Scan.xml) 
    spws: a list of spws to replace (in order of baseband number).  The number of
          spws specified must match the number of SQLDs in the SysCal.xml file.
    - Todd Hunter
    """
    tsys = getTsysFromSysCal(asdm, sqld)
    if tsys is None:
        return
    values = 0
    if (type(spws) == str):
        spws = spws.split(',')
    changeFactor = []
    for antenna in tsys.keys():
        for spw in tsys[antenna].keys():
            baseband = tsys[antenna][spw]['baseband']-1 # 1..4  converted here to 0..3
            for scan in tsys[antenna][spw]['scans'].keys():
                for pol in tsys[antenna][spw]['scans'][scan].keys():
                    if (pol == 0): polarization = 'X'
                    if (pol == 1): polarization = 'Y'
                    if (verbose):
                        print "Calling replaceTsysScan('%s', antenna=%d, spw=%d, pol='%s', fromscan=%d, toscan=%d, newvalue=%f)" % (caltable, antenna, int(spws[baseband]), polarization, scan, scan, np.median(tsys[antenna][spw]['scans'][scan][pol]))
                    replaced, change = replaceTsysScan(caltable, antenna, int(spws[baseband]), polarization, scan, scan, tsys[antenna][spw]['scans'][scan][pol],verbose=verbose)
                    values += replaced
                    if (replaced > 0):
                        changeFactor.append(change)
    print "Replaced %d values with a median change of a factor of %f" % (values,np.median(changeFactor))

def getMedianTsys(asdmlist, verbose=False):
    """
    Gets the median Tsys value for each ASDM in a list.
    asdmlist: either a list of strings or a single string with wildcard character(s).
          Files containing .ms and those not starting with uid___ are ignored.
          If the string does not have a wildcard character, then interpret it as a single file.
          If the file is not a directory (i.e. not an ASDM), then interpret it as a file that
            contains a list of ASDMs to process.
    Returns:
    if a wildcard is given: returns a dictionary of Tsys values keyed by ASDM name
    otherwise: returns the single median Tsys value
    -Todd Hunter
    """
    wildcardPresent = False
    if (type(asdmlist) == str):
        if (asdmlist.find('*') >= 0):
            wildcardPresent = True
            asdmlist = glob.glob(asdmlist)
        elif (os.path.isdir(asdmlist)):
            asdmlist = [asdmlist]
        elif (os.path.exists(asdmlist)):
            asdmlist = getListOfFilesFromFile(asdmlist, appendms=False)
        else:
            print "File not found"
            return
    tsysdict = {}
    for asdm in asdmlist:
        basename = os.path.basename(asdm)
        print "Checking ", basename
        if (basename.find('.') < 0 and basename.find('uid___')==0):
            tsys = getTsysFromSysCal(asdm, median=True, verbose=verbose)
            if tsys is None:
                return
            tsys = tsys['median']
            tsysdict[asdm] = tsys
            print "%s:  %f" % (asdm,tsys)
            
    if (len(tsysdict) < 2 and wildcardPresent==False):
        return(tsys)
    else:
        return(tsysdict)
    
def getMedianTsysForChannel(asdm, channel, spw):
    """
    Computes the median over all antennas of a single Tsys channel in one spw in one
    ASDM.
    -Todd Hunter
    """
    mydict = getTsysFromSysCal(asdm,median=True,channel=channel)
    if mydict is None:
        return
    tsys = []
    for antenna in mydict.keys():
        if (antenna != 'median'): 
            tsys.append(mydict[antenna][spw]['median'])
    return(np.median(tsys))

def getTsysFromSysCal(asdm, sqld=None, median=False, verbose=True, channel=None):
    """
    This function reads the Tsys values from a SysCal.xml table 
    associated with an ASDM into a dictionary keyed by antenna ID, 
    spw, scan, and pol (0 or 1).  
    asdm: the path to the original ASDM (containing Scan.xml and SpectralWindow.xml)
    sqld: the path to the SysCal.xml table to use (or its parent directory)
      If sqld is not specified, then assume it is the one inside the ASDM.
      The reason you might need to specify both is because the primary usage is
      to read values from a SysCal.xml file produced by offline casapy-telcal.
    median: if True, then compute the median across frequency on a 
            per-antenna/spw/scan/pol basis and a global basis 
    channel: use the value only from the one specified channel (0..127)
    verbose: if True, print the number of rows and channels found
    -- Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "getTsysFromSysCal(): Could not find ASDM = ", asdm
        return
    if (sqld is None):
        sqld = asdm + '/SysCal.xml'
    if (os.path.exists(sqld) == False):
        print "getTsysFromSysCal(): Could not find file = ", sqld
        return
    if (sqld.split('/')[-1] != 'SysCal.xml'):
        sqld += '/SysCal.xml'
    scanlist = readscans(asdm)[0]
    wvrSpws = []
    xmlscans = minidom.parse(asdm+'/SpectralWindow.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    baseband = {}
    for rownode in rowlist:
        name = rownode.getElementsByTagName("name")
        name = str(name[0].childNodes[0].nodeValue)
        spwID = rownode.getElementsByTagName("spectralWindowId")
        spw = int(str(spwID[0].childNodes[0].nodeValue).split('_')[1])
        basebandName = rownode.getElementsByTagName("basebandName")
        basebandName = str(basebandName[0].childNodes[0].nodeValue).split('_')  # e.g. "BB_1"
        if (len(basebandName) < 2):
            baseband[spw] = -1  # NOBB
        else:
            baseband[spw] = int(basebandName[1])
        if (name.find('WVR') >= 0):
            wvrSpws.append(spw)
    xmlscans = minidom.parse(sqld)
    rowlist = xmlscans.getElementsByTagName("row")
    scandict = {}
    fid = 0
    duplicates = 0
    scandict = {}
    nchans = []
    if len(rowlist) == 0:
        print "Now rows found in SysCal.xml, probably because all the data are now in the binary file."
        return
    for rownode in rowlist:
        antennaID = rownode.getElementsByTagName("antennaId")
        antenna = int(str(antennaID[0].childNodes[0].nodeValue).split('_')[1])
        if (antenna not in scandict.keys()):
            scandict[antenna] = {}
        spwID = rownode.getElementsByTagName("spectralWindowId")
        asdmspw = int(str(spwID[0].childNodes[0].nodeValue).split('_')[1])
        subtract = len(np.where(asdmspw > np.array(wvrSpws))[0])-1 
        spw = asdmspw-subtract # translate this to actual spw number, as only 1 WVR spw is real
        if (spw not in scandict[antenna].keys()):
            scandict[antenna][spw] = {}
            scandict[antenna][spw]['baseband'] = baseband[asdmspw]
            scandict[antenna][spw]['scans'] = {}
        timeData = rownode.getElementsByTagName("timeInterval")
        timeStamp = int(str(timeData[0].childNodes[0].nodeValue).split()[0])
        timeInterval = int(str(timeData[0].childNodes[0].nodeValue).split()[1])
        timeCenter = timeStamp-timeInterval/2
        timeCenterMJD = timeCenter*1e-9/86400.
        scan = -1
        for s in scanlist.keys():
            if (scanlist[s]['endmjd'] >= timeCenterMJD and scanlist[s]['startmjd'] <= timeCenterMJD):
                scan = s
        if (scan not in scandict[antenna][spw]['scans'].keys()):
            scandict[antenna][spw]['scans'][scan] = {}
        tsysSpectrum = rownode.getElementsByTagName("tsysSpectrum")
        values = tsysSpectrum[0].childNodes[0].nodeValue.split()
        npol = int(values[1])  # or is it [0] ?
        nchan = int(values[2])
        nchans.append(nchan)
        for pol in range(npol):
            tsys = []
            for i in range(pol*nchan, nchan*(pol+1)):
                tsys.append(float(values[3+i]))
            if (channel is None):
                scandict[antenna][spw]['scans'][scan][pol] = tsys
            else:
                scandict[antenna][spw]['scans'][scan][pol] = [tsys[channel]]
        fid += 1
    if verbose:
        print '  Found ',rowlist.length,' Tsys rows in SysCal.xml (median # chans = %.0f)' % (np.median(nchans))
    if (median):
        mediandict = {}
        allvalues = []
        for antennaId in scandict.keys():
            if antennaId not in mediandict.keys(): mediandict[antennaId] = {}
            spwvalues = []
            for spw in scandict[antennaId].keys():
                if spw not in mediandict[antennaId].keys(): mediandict[antennaId][spw] = {}
                scanvalues = []
                for scan in scandict[antennaId][spw]['scans'].keys():
                    if scan not in mediandict[antennaId][spw].keys(): mediandict[antennaId][spw][scan] = {}
                    polvalues = []
                    for pol in scandict[antennaId][spw]['scans'][scan].keys():
                        if pol not in mediandict[antennaId][spw][scan].keys(): mediandict[antennaId][spw][scan][pol] = {}
                        values = scandict[antennaId][spw]['scans'][scan][pol]
                        polvalues += values
                        # Use 'median' label to allow future keys like 'mean' or 'std'
                        mediandict[antennaId][spw][scan][pol]['median'] = np.nanmedian(values)
                    mediandict[antennaId][spw][scan]['median'] = np.nanmedian(polvalues)
                    scanvalues += polvalues
                mediandict[antennaId][spw]['median'] = np.nanmedian(scanvalues)
                spwvalues += scanvalues
            mediandict[antennaId]['median'] = np.nanmedian(spwvalues)
            allvalues += spwvalues
        mediandict['median'] = np.nanmedian(allvalues)
        return (mediandict)
    else:
        return (scandict)
        

def getNonWvrSpws(mymsmd):
    """
    Uses the msmd tool instance to find a list of the non-WVR spws, in a backward-compatible way.
    -Todd Hunter
    """
    try:
        spws = list(set(range(mymsmd.nspw())).difference(set(mymsmd.almaspws(wvr=True))))
    except:
        spws = list(set(range(mymsmd.nspw())).difference(set(mymsmd.wvrspws())))
    return(spws)

def getNonChanAvgSpws(mymsmd):
    """
    Uses the msmd tool instance to find a list of the non-WVR spws, in a backward-compatible way.
    -Todd Hunter
    """
    try:
        spws = list(set(range(mymsmd.nspw())).difference(set(mymsmd.almaspws(chavg=True))))
    except:
        spws = list(set(range(mymsmd.nspw())).difference(set(mymsmd.chanavgspws())))
    return(spws)

def getFrequenciesFromASDM(asdm, spws=None, minnumchan=128):
    """
    Gets a list of the central frequencies of each spw in the ASDM. Extraneous
    WVR spws are skipped, so the order of the list should match listobs in CASA.
    spws: a list of spws to which to restrict the result
    minnumchan: limit the spws returned to those with at least this many 
                channels
    Returns:
    an array of frequencies (in Hz)
    - Todd Hunter
    """
    mydict = getSpwsFromASDM(asdm, minnumchan, dropExtraWVRSpws=True)
    freqs = []
    if (type(spws) == str):
        spws = [int(i) for i in spws.split(',')]
    elif (type(spws) == int):
        spws = [spws]
    for spw in sorted(mydict.keys()):
        if (spws is None):
            freqs.append(mydict[spw]['centerFreq'])
        elif (spw in spws):
            freqs.append(mydict[spw]['centerFreq'])
    return(np.array(freqs))

def getScienceBasebandRFRanges(vis, mymsmd=None):
    """
    Reports the 2GHz-wide ranges of ALMA science basebands.
    Returns: a dictionary keyed by baseband number, with values in Hz
    """
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    freqs = getScienceBasebandFrequencies(vis, mymsmd) # dictionary keyed by baseband
    LO1s = interpretLOs(vis, mymsmd=mymsmd, showOnlyScienceSpws=True)  # dictionary keyed by science spw number
    ranges = {}
    for spw in LO1s:
        baseband = mymsmd.baseband(spw)
        basebandFreq = freqs[baseband]
        sqldspw = np.intersect1d(mymsmd.spwsforbaseband(baseband), 
                                 getScienceSpws(vis,sqld=True,fdm=False,tdm=False,returnString=False,mymsmd=mymsmd))
        bandwidth = mymsmd.bandwidths(sqldspw)
        ranges[baseband] = [basebandFreq-bandwidth/2, basebandFreq+bandwidth/2]
    if needToClose:
        mymsmd.close()
    return ranges

def getScienceBasebandIFRanges(vis, mymsmd=None):
    """
    Reports the 2GHz-wide ranges of ALMA science basebands.
    Returns: a dictionary keyed by baseband number, with values in Hz
    """
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    freqs = getScienceBasebandFrequencies(vis, mymsmd) # dictionary keyed by baseband
    LO1s = interpretLOs(vis, mymsmd=mymsmd, showOnlyScienceSpws=True)  # dictionary keyed by science spw number
    ranges = {}
    for spw in LO1s:
        baseband = mymsmd.baseband(spw)
        basebandFreq = freqs[baseband]
        sqldspw = np.intersect1d(mymsmd.spwsforbaseband(baseband), 
                                 getScienceSpws(vis,sqld=True,fdm=False,tdm=False,returnString=False,mymsmd=mymsmd))
        bandwidth = mymsmd.bandwidths(sqldspw)
        ranges[baseband] = [abs(LO1s[spw]-basebandFreq)-bandwidth/2, abs(LO1s[spw]-basebandFreq)+bandwidth/2]
    if needToClose:
        mymsmd.close()
    return ranges

def getScienceSpwIFRanges(vis, mymsmd=None, spws=None):
    """
    Reports the IF ranges of the ALMA science spws of a measurement set.
    spws: if specified, limit the spws to these (python list or comma-delimited string)
    Returns: a dictionary keyed by spw number, with values in Hz
    """
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    if spws is None:
        spws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False) # list of integers
    else:
        spws = parseSpws(vis, spws)
    LO1s = interpretLOs(vis, mymsmd=mymsmd, showOnlyScienceSpws=True)  # dictionary keyed by science spw number
    ranges = {}
    for spw in spws:
        bandwidth = mymsmd.bandwidths(spw)
        spwFreq = mymsmd.meanfreq(spw)
        ranges[spw] = [abs(LO1s[spw]-spwFreq)-bandwidth/2, abs(LO1s[spw]-spwFreq)+bandwidth/2]
    if needToClose:
        mymsmd.close()
    return ranges

def getScienceSpwRFRanges(vis, mymsmd=None, spws=None):
    """
    Reports the RF ranges of the ALMA science spws of a measurement set.
    spws: if specified, limit the spws to these (python list or comma-delimited string)
    Returns: a dictionary keyed by spw number, with values in Hz
    """
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    if spws is None:
        spws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False) # list of integers
    else:
        spws = parseSpws(vis, spws)
    ranges = {}
    for spw in spws:
        bandwidth = mymsmd.bandwidths(spw)
        spwFreq = mymsmd.meanfreq(spw)
        ranges[spw] = [spwFreq-bandwidth/2, spwFreq+bandwidth/2]
    if needToClose:
        mymsmd.close()
    return ranges

def getScienceBasebandFrequencies(vis, mymsmd=None):
    """
    Uses the ALMA SQLD spws to infer the baseband center frequencies of each science spw.
    Returns: a dictionary keyed by baseband number with values of the baseband center frequency in Hz
    """
    spws = getScienceSpws(vis, sqld=True, tdm=False, fdm=False, returnString=False, mymsmd=mymsmd)
    if len(spws) == 0:
        print "There are no SQLD spws in this dataset, so the baseband frequencies are unknown."
        return
    freqs = {}
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    for spw in spws:
        freq = getMeanFreqOfSpwlist(vis, spw)
        baseband = mymsmd.baseband(spw)
        freqs[baseband] = freq
    if needToClose:
        mymsmd.close()
    return freqs

def getSpwSelForFreqRange(vis, frequency, intent='OBSERVE_TARGET#ON_SOURCE',verbose=False):
    """
    Returns a list of science spws and chans that cover a freq range
    vis: name of measurement set
    frequency: 2 LSRK freqs in Hz, GHz, or a string with units
    -Remy Indebetouw
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return

    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)

    #spws = getScienceSpws(vis, returnString=False)
    spws = mymsmd.spwsforintent(intent)
    almaspws = mymsmd.almaspws(tdm=True,fdm=True)
    if (len(almaspws) > 0):
        spws = np.intersect1d(spws,almaspws)

    datestring = getObservationStartDate(vis, measuresToolFormat=True)
    observatory = mymsmd.observatorynames()[0]
    field = mymsmd.fieldsforintent(intent)
    if (len(field) == 0):
        print "No fields with that intent"
        return
    else:
        field = field[0]
        # print "Using field %d" % field
    result = getRADecForField(vis, field, returnReferenceFrame=True)
    if result==None: return
    radec, equinox = result
    ra = radec[0][0]
    dec = radec[1][0]
    rastr,decstr=rad2radec(ra,dec,verbose=False).split(",")

    if not isinstance(frequency,list):
        frequency=[frequency]
    if len(frequency)<2:
        frequency=[frequency[0],frequency[0]]
    LSRKfrequency0 = parseFrequencyArgumentToHz(frequency[0])
    if verbose:
        print "using ",datestring, rastr, decstr, equinox, observatory
    TOPOfreq0 = lsrkToTopo(LSRKfrequency0, datestring, rastr, decstr, equinox, observatory)
    LSRKfrequency1 = parseFrequencyArgumentToHz(frequency[1])
    TOPOfreq1 = lsrkToTopo(LSRKfrequency1, datestring, rastr, decstr, equinox, observatory)
    if TOPOfreq1<TOPOfreq0:
        tmp=TOPOfreq0
        TOPOfreq0=TOPOfreq1
        TOPOfreq1=tmp

    spws2 = []
    spwstr = ""
    for spw in spws:
        freqs = mymsmd.chanfreqs(spw)
        if (np.min(freqs) <= TOPOfreq0 and np.max(freqs) >= TOPOfreq0):
            spws2.append(spw)
            thisdelta=mymsmd.chanwidths(spw).mean()
            if verbose:
                print "spw %i"%spw, "freq ",freqs[0],"-",freqs[-1]

            if thisdelta>0:
                z0=np.where(freqs<=TOPOfreq0)[0].max()
                # increasing freq, freq1>=freq0 so could be beyond maxchan
                z1=np.where(freqs<=TOPOfreq1)[0].max()
            else:
                z1=np.where(freqs<=TOPOfreq0)[0].min()
                # decreasing freq, freq1>=freq0 so could be < 0chan
                z0=np.where(freqs<=TOPOfreq1)[0].min()
            spwstr=spwstr+("%i:%i~%i,"%(spws2[-1],z0,z1))
    mymsmd.close()
    return(spwstr[0:-1])
    
def getScienceSpwsForFrequency(vis, frequency, nearestOnly=False, mymsmd=None):
    """
    Returns a list of science spws that cover a given frequency.
    vis: name of measurement set
    frequency: in Hz, GHz, or a string with units
    nearestOnly: if True, the return only one spw (nearest to center)
    -Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    spws = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)
    frequency = parseFrequencyArgumentToHz(frequency)
    spws2 = []
    delta = []
    for spw in spws:
        freqs = mymsmd.chanfreqs(spw)
        if (np.min(freqs) <= frequency and np.max(freqs) >= frequency):
            spws2.append(spw)
            delta.append(abs(frequency-mymsmd.meanfreq(spw)))
    if needToClose:
        mymsmd.close()
    if nearestOnly:
        return(spws2[np.argmin(delta)])
    else:
        return(spws2)

def checkScienceSpws(dir='./', intent='OBSERVE_TARGET#ON_SOURCE', tdm=True,
                     fdm=True, ignore='_target.ms'):
    """
    For all measurement sets in the specified directory, get the
    science spws and report any differences in ID number.
    dir: comma-delimited list of directories, wildcard string, or 
         list of directories
    -Todd Hunter
    """
    if type(dir) == str:
        if (dir.find('*')>=0):
            dirs = glob.glob(dir)
        else:
            dirs = dir.split(',')
    else:
        dirs = dir
    for dir in dirs:
        print dir+":"
        vis = glob.glob(dir+'/*.ms')
        if (len(ignore) > 0):
            tvis = glob.glob(dir+'/*%s*'%(ignore))
            vis = list(set(vis) - set(tvis))
        if (len(vis) < 2):
            print "    Only %d measurement set found" % (len(vis))
            continue
        spws = getScienceSpws(vis[0], intent, tdm=tdm, fdm=fdm)
        print "%s: %s" % (os.path.basename(vis[0]),spws)
        difference = False
        for v in vis[1:]:
            newspws = getScienceSpws(v, intent, tdm=tdm, fdm=fdm)
            print "%s: %s" % (os.path.basename(v),newspws)
            if spws != newspws:
                difference = True
                print "   Difference!"
    return difference

def getNearestScienceSpw(vis, freqGHz, mymsmd=''):
    """
    Finds the science spw whose mean freq is closest to the specified
    frequency.  - Todd Hunter
    """
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        needToClose = True
    spws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False)
    freqs = []
    for spw in spws:
        freqs.append(mymsmd.meanfreq(spw)*1e-9)
    spw = spws[np.argmin(np.abs(freqs-freqGHz))]
    if needToClose:
        mymsmd.close()
    return spw

def getScienceTimeRanges(vis, field=None, intent='OBSERVE_TARGET*', 
                         mymsmd=None, roundToSmallestRange=False):
    """
    Gets a list of string-formatted time ranges corresponding to the
    scans on the specified field or intent.  Similar to tt.scanTimeRanges.
    roundToSmallestRange: if True, then ceil start and floor end
                            else, then floor start and ceil end
    Returns:  ['2017/10/07/22:18:41~2017/10/07/22:20:07', ...]
    -Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    scans = getScienceScans(vis, field, intent, mymsmd)
    times = []
    for scan in scans:
        t = mymsmd.timesforscan(scan)
        if roundToSmallestRange:
            times.append(mjdsecToTimerange(np.ceil(np.min(t)), np.floor(np.max(t))))
        else:
            times.append(mjdsecToTimerange(np.floor(np.min(t)),np.ceil(np.max(t))))
    return times

def getNonScienceTimeRanges(vis, intent='OBSERVE_TARGET*', obsID=0, tbuffer=0.048):
    """
    Returns a list of timeranges (suitable for flagdata commands) which
    correspond to all times that are not contained by a scan of the
    specified intent. The opposite of this function is getScienceTimeRanges.
    Coped from to tt.nonScanTimeRanges.
    tbuffer: in seconds, flag this much *less* time to avoid flagging good data
           default value is one ALMA timing event
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    scans = mymsmd.scansforintent(intent)
    print "Found %d matching scans: " % (len(scans)), scans
    startTime = 86400*mymsmd.timerangeforobs(obsID)['begin']['m0']['value']
    endTime = 86400*mymsmd.timerangeforobs(obsID)['end']['m0']['value']
    timeranges = []
    for scan in scans:
        t = mymsmd.timesforscan(scan)
        if scan == scans[0]:  # first scan, start from beginning of obs.
            timeranges.append(mjdsecToTimerange(startTime, np.min(t)-tbuffer))
            endOfPreviousGoodScan = np.max(t) + tbuffer
        elif scan == scans[-1]:  # final scan: finish and then go to end of obs.
            timeranges.append(mjdsecToTimerange(endOfPreviousGoodScan, np.min(t)-tbuffer))
            timeranges.append(mjdsecToTimerange(np.max(t)+tbuffer, endTime))
        else:
            timeranges.append(mjdsecToTimerange(endOfPreviousGoodScan, np.min(t)-tbuffer))
            endOfPreviousGoodScan = np.max(t) + tbuffer
    mymsmd.close()
    return timeranges

def getScienceScans(vis, field=None, intent='OBSERVE_TARGET*', 
                    mymsmd=None, debug=False):
    """
    Return a list of scans with the specified intent (and optionally limited 
    to one field).  
    field: one name or ID
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    intents = mymsmd.intents()
    # minimum match OBSERVE_TARGET to OBSERVE_TARGET#UNSPECIFIED
    value = [i.find(intent.replace('*','')) for i in intents]
    if np.mean(value) == -1:
        print "%s not found in this dataset. Available intents: " % (intent), intents
        if needToClose: 
            mymsmd.close()
        return
    sciscans = mymsmd.scansforintent(intent)
    scispws = mymsmd.spwsforintent(intent)
    if debug:
        print "sciscans = ", sciscans
        print "scispws = ", scispws
    if field is not None:
        ids, names = parseFieldArgument(vis,field,mymsmd=mymsmd)
        fieldscans = mymsmd.scansforfields()
        spwscans = mymsmd.scansforspws()
        scispwscans = spwscans[str(scispws[0])]
        if debug:
            print "scispwscans = ", scispwscans
        for field in [str(i) for i in ids]:
            if debug:
                print "scansforfield%s = " % field, fieldscans[field]
            sciscans = np.intersect1d(scispwscans,fieldscans[field])
            if len(sciscans) > 0: 
                break
    if needToClose:
        mymsmd.close()
    return sciscans

def getScienceSpws(vis, intent='OBSERVE_TARGET#ON_SOURCE', returnString=True, 
                   tdm=True, fdm=True, mymsmd=None, sqld=False, verbose=False):
    """
    Return a list of the each spw with the specified intent.  For ALMA data,
    it ignores channel-averaged and SQLD spws.
    returnString: if True, return '1,2,3'
                  if False, return [1,2,3]
    -- Todd Hunter
    """
    needToClose = False
    if (mymsmd is None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    if (intent not in mymsmd.intents()):
        print "intent = ", intent
        if intent.split('#')[0] in [i.split('#')[0] for i in mymsmd.intents()]:
            # VLA uses OBSERVE_TARGET#UNSPECIFIED, so try that before giving up
            intent = intent.split('#')[0]+'*'
        else:
            print "Intent %s not in dataset (nor is %s*)." % (intent,intent.split('#')[0])
    if (intent not in mymsmd.intents()):
        spws = []
    else:
        if verbose:
            print "Running mymsmd.spwsforintent('%s')" % (intent)
        spws = mymsmd.spwsforintent(intent)
    if (getObservatoryName(vis).find('ALMA') >= 0 or getObservatoryName(vis).find('OSF') >= 0):
        almaspws = mymsmd.almaspws(tdm=tdm,fdm=fdm,sqld=sqld)
        if (len(spws) == 0 or len(almaspws) == 0):
            scienceSpws = []
        else:
            scienceSpws = np.intersect1d(spws,almaspws)
    else:
        scienceSpws = spws
    if needToClose:
        mymsmd.close()
    if (returnString):
        return(','.join(str(i) for i in scienceSpws))
    else:
        return(list(scienceSpws))

def getScienceTargetsFromASDM(asdm):
    """
    Get a list of names of the science targets from an ASDM
    """
    mydict = readscans(asdm)[0]
    targets = []
    for key in mydict.keys():
        if (mydict[key]['intent'].find('OBSERVE_TARGET') >= 0):
            targets.append(mydict[key]['source'])
    return np.unique(targets)

def getScienceTargets(vis, intent='OBSERVE_TARGET*', mymsmd=None, returnNames=True, checkSpw=True):
    """
    Get a list of names of the science targets from a measurement set (using msmd).
    checkSpw: if True, confirm that field name was also observed in first science spw
    -Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    ids = mymsmd.fieldsforintent(intent)
    if checkSpw:
        spws = mymsmd.spwsforintent(intent)
        fieldIDs_spw = mymsmd.fieldsforspw(spws[0])
        ids = np.intersect1d(ids,fieldIDs_spw)
    if len(ids) == 0: 
        fields = []
    else:
        fields = mymsmd.namesforfields(ids)
    if needToClose:
        mymsmd.close()
    if returnNames:
        return fields
    else:
        return ids

def getCalibrators(vis, intent=['BANDPASS','FLUX','PHASE','AMP','POLARIZATION'],
                   mymsmd=None, returnNames=True):
    """
    Get a list of names of the calibrators from a measurement set (using msmd)
    intent: can be a comma-delimited string or a python list of strings
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    ids = []
    intents = mymsmd.intents()
    if type(intent) == str:
        intent = intent.split(',')
    for i in intent:
        if 'CALIBRATE_' + i.replace('*','') + '#ON_SOURCE' in intents:
            ids += list(mymsmd.fieldsforintent('*' + i + '*'))
    if len(ids) == 0: 
        fields = []
    else:
        fields = mymsmd.namesforfields(ids)
    if needToClose:
        mymsmd.close()
    if returnNames:
        return fields
    else:
        return ids

def getScienceFrequencies(vis, spw='', intent='OBSERVE_TARGET#ON_SOURCE', verbose=False, mymsmd=None):
    """
    Return a list of the mean frequencies (in Hz) of each spw 
    spw: if specified, then use that spw or list of spws (comma-delimited string or int list)
         if not specified, then use all with the specified intent
         If none have that intent, then use all the spws with more than 4 channels
         i.e. not the WVR data nor the channel-averaged data.  
    -- Todd Hunter
    """
    freqs = []
    if (casadef.casa_version >= casaVersionWithMSMD):
        needToClose = False
        if mymsmd is None or mymsmd == '':
            needToClose = True
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
        if (intent not in mymsmd.intents()):
            if intent.split('#')[0] in [i.split('#')[0] for i in mymsmd.intents()]:
                # VLA uses OBSERVE_TARGET#UNSPECIFIED
                intent = intent.split('#')[0]+'*'
            else:
                print "Intent %s not in dataset (nor is %s*)." % (intent,intent.split('#')[0])

        if (spw == ''):
            if (np.max([i.find(intent.replace('*','')) for i in mymsmd.intents()]) == -1):
                spws = []
            else:
                spws = mymsmd.spwsforintent(intent)
        elif (type(spw) == str):
            spws = [int(i) for i in spw.split(',')]
        elif (type(spw) != list):  
            # i.e. integer
            spws = [spw]
        else:
            spws = spw
        if verbose:
            print "Using spws: ", spws
        if (getObservatoryName(vis).find('ALMA') >= 0 or getObservatoryName(vis).find('OSF') >= 0):
            almaspws = mymsmd.almaspws(tdm=True,fdm=True)
            if (len(spws) == 0):
                nonwvrspws = getNonWvrSpws(mymsmd)
                for spw in nonwvrspws:
                    freqs.append(mymsmd.meanfreq(spw))
            else:
                spws = np.intersect1d(spws,almaspws)
                for spw in spws:
                    freqs.append(mymsmd.meanfreq(spw))
        else:
            for spw in spws:
                freqs.append(mymsmd.meanfreq(spw))
        if needToClose:
            mymsmd.close()
    else:
        mytb = createCasaTool(tbtool)
        try:
            mytb.open("%s/SPECTRAL_WINDOW" % vis)
        except:
            print "Could not open ms table = %s" % (vis)
            return(freqs)
        numChan = mytb.getcol("NUM_CHAN")
        for i in range(len(numChan)):
            if (numChan[i] > 4):
                chanFreq = mytb.getcell("CHAN_FREQ",i)
                freqs.append(np.mean(chanFreq))
        mytb.close()
    return freqs
    
def listConditionsFromASDM(asdm, station=1, verbose=True):
    """
    This function extracts the weather conditions for the specified ASDM,
    and computes and returns a dictionary containing the median values.
    The default weather station to use is 1.
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/ListConditionsFromASDM
    Todd Hunter
    """
    [conditions, medianConditions, stationName] = getWeatherFromASDM(asdm,station=station)
    if (verbose):
        print "Median weather values for %s to %s" % (plotbp3.utstring(conditions[0][0]),plotbp3.utstring(conditions[0][-1]))
        print "  Pressure = %.2f mb" % (medianConditions['pressure'])
        print "  Temperature = %.2f C" % (medianConditions['temperature'])
#        print "  Dew point = %.2f C" % (medianConditions['dewpoint'])
        print "  Relative Humidity = %.2f %%" % (medianConditions['humidity'])
        print "  Wind speed = %.2f m/s" % (medianConditions['windSpeed'])
        print "  Wind max = %.2f m/s" % (np.max(conditions[6]))
        print "  Wind direction = %.2f deg" % (medianConditions['windDirection'])
    return(medianConditions)

def listconditions(vis='', scan='', antenna='0',verbose=True,asdm='',reffreq=0,
                   byscan=False, vm=0, mymsmd='',field='',debug=False):
    """
    Compiles the mean weather, pwv and opacity values for the given scan
    number or scan list for the specified ms.  If a scan number
    is not provided it returns the average over all science spws in whole ms.
    byscan: setting this True will return a dictionary with conditions per scan.
    field: setting this will run msmd.scansforfield, and use only those scans.
    reffreq: value in GHz (use this to restrict to one spw)
    Note: In casa 4.4 and 4.5, when run on concatenated measurement sets, 
          only the scans from the first obsid are detected due to a change 
          in msmd, a behavior which was fixed in casa 4.6.
    Scan can be a single list: [1,2,3] or '1,2,3' or a single range: '1~4'.
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/Listconditions
    Todd Hunter
    """
    if (os.path.exists(vis)==False):
        print "Could not find the ms = %s." % (vis)
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (type(scan) == str):
        if (scan.find(',')>0):
            scan = [int(k) for k in scan.split(',')]
        elif (scan.find('~')>0):
            scan = range(int(scan.split('~')[0]),int(scan.split('~')[1])+1)
    if (casadef.casa_version >= casaVersionWithMSMD):
        if mymsmd == '':
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            needToClose = True
        else:
            needToClose = False
        if (field != ''):
            scan = mymsmd.scansforfield(int(field))
            print "Will use scans: ", str(scan)
    else:
        if (field != ''):
            print "The field parameter is not supported for this old of a CASA."
            return
    if (reffreq==0):
        freqs = 1e-9*np.array(getScienceFrequencies(vis, mymsmd=mymsmd))
    else:
        freqs = [reffreq]
    if (byscan and (type(scan) == list or scan=='')):
        conditions = {}
        if (scan == ''):
            if (casadef.casa_version >= casaVersionWithMSMD):
                scan = mymsmd.scannumbers()
            else:
                if (vm == 0):
                    vm = ValueMapping(vis)
                scan = np.unique(vm.scans)
            print "Scans = ", scan
        pwvstd = 1 # get into the loop the first time, but do not repeat if no WVR file present
        for i in scan:
            if debug:
                print "Calling getWeather('%s',%d,'%s',%s)" % (vis,i,antenna,verbose)
            [cond,myTimes,vm] = getWeather(vis,i,antenna,verbose,vm,mymsmd)
            if (len(myTimes) > 0 and pwvstd>0):
                [pwv,pwvstd] = getMedianPWV(vis,myTimes,asdm,verbose=False)
                if (pwvstd > 0):
                    if (pwv > 0):
                        tau = []
                        zenithtau = []
                        for myfreq in range(len(freqs)):
                            reffreq = freqs[myfreq]
                            [z,t] = estimateOpacity(pwv, reffreq, cond, verbose)
                            zenithtau.append(z)
                            tau.append(t)
                        d2 = {}
                        d2['tauzenith'] = np.mean(zenithtau)
                        d2['tau'] = np.mean(tau)
                        d2['transmissionzenith'] = np.exp(-np.mean(zenithtau))
                        d2['transmission'] = np.exp(-np.mean(tau))
                        d2['pwv'] = pwv
                        d2['pwvstd'] = pwvstd
                        cond = dict(cond.items() + d2.items())
            conditions[i] = cond
    else:
        if debug:
            print "Calling getWeather('%s','%s','%s',%s), len(freqs)=%d" % (vis,str(scan),antenna,verbose,len(freqs))
        [conditions,myTimes,vm] = getWeather(vis,scan,antenna,verbose,vm,mymsmd)
        if debug:
            print "len(myTimes) = %d" % (len(myTimes))
        if (len(myTimes) < 1):
            return(conditions)
        [pwv,pwvstd] = getMedianPWV(vis,myTimes,asdm,verbose=False)
        if debug:
            print "pwv = %f" % (pwv)
        if (pwvstd < 0):
            return(conditions)
        if (pwv > 0):
            tau = []
            zenithtau = []
            for i in range(len(freqs)):
                reffreq = freqs[i]
                [z,t] = estimateOpacity(pwv, reffreq, conditions,verbose)
                zenithtau.append(z)
                tau.append(t)
            d2 = {}
            d2['tauzenith'] = np.mean(zenithtau)
            d2['tau'] = np.mean(tau)
            d2['transmissionzenith'] = np.exp(-np.mean(zenithtau))
            d2['transmission'] = np.exp(-np.mean(tau))
            d2['pwv'] = pwv
            d2['pwvstd'] = pwvstd
            conditions = dict(conditions.items()+d2.items())
    if needToClose:
        mymsmd.close()
    return(conditions)

def buildCalDataIdDictionary(vis, tol=10, debug=False, sbr=True, atm=True, mymsmd=None):
    """
    Provides the mapping from cal data ID to scan number via the times, as an alternative
    to using readCalData which requires the ASDM_CALDATA table.
    vis: string name of ms
    tol: tolerance in seconds (should not have to change this)
    sbr: include SIDEBAND_RATIO scans
    atm: include CALIBRATE_ATMOSPHERE scans
    """
    mytable = vis+'/ASDM_CALATMOSPHERE'
    mytb = createCasaTool(tbtool)
    mytb.open(mytable)
    startValidTime = mytb.getcol('startValidTime')
    calDataId = np.array([int(c.split('_')[-1]) for c in mytb.getcol('calDataId')])
    mytb.close()
    # these range from 2-40 seconds after the first integration of the scan
    # so do a rough correction for this
    startValidTime -= 10  
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    scans = mymsmd.scannumbers()
    times = mymsmd.timesforscans(scans)
    if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' in mymsmd.intents()):
        calscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
    elif ('CALIBRATE_ATMOSPHERE#HOT' in mymsmd.intents()):   
        calscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#HOT')
    else:
        calscans = []
    if ('CALIBRATE_SIDEBAND_RATIO#ON_SOURCE' in mymsmd.intents()):
        sbrscans = mymsmd.scansforintent('CALIBRATE_SIDEBAND_RATIO#ON_SOURCE')
    else:
        sbrscans = []
    if (debug):
        print "%d calscans=%s,  %d sbrscans=%s" % (len(calscans),str(calscans), len(sbrscans), str(sbrscans))
    if (sbr and atm):
        cal_sbr_scans = np.unique(np.union1d(calscans, sbrscans))
    elif (sbr):
        cal_sbr_scans = sbrscans
    else:
        cal_sbr_scans = calscans
        
    calscantimesdict = {}
    for i in range(len(calDataId)):
        cal = calDataId[i]
        if (cal not in calscantimesdict.keys()):
            calscantimesdict[cal] = []
        calscantimesdict[cal].append(startValidTime[i])
    for key in calscantimesdict.keys():
        mylen = len(np.unique(calscantimesdict[key]))
        if (mylen > 1):
            print "Cal data ID %d has multiple startValidTimes (%d). Taking the minimum." % (key, mylen)
        calscantimesdict[key] = np.min(calscantimesdict[key])
        if (debug):
            print "%2d = %s" % (key, mjdsecToUTHMS(calscantimesdict[key]))
        
    calscandict = {}
    scansAssigned = []
    stopTol = 6.01*tol
    for tolerance in np.arange(tol, stopTol, tol):
        if (debug):
            print "tolerance = %.0f sec, calscandict=%s" % (tolerance,str(calscandict))
        for i in range(len(calDataId)):
            cal = calDataId[i]
#            if (debug):
#                print "Working on row %d, calDataId=%d" % (i,cal)
            if (cal not in calscandict.keys()):
                calscandict[cal] = []
            if (tolerance == tol or len(calscandict[cal]) == 0):
                trialscans = mymsmd.scansfortimes(calscantimesdict[cal]+tolerance, tol=tolerance)
                for scan in sorted(list(trialscans)):
                    if (scan not in calscandict[cal] and
                        scan not in scansAssigned):
                        if (scan in cal_sbr_scans):
                            calscandict[cal].append(scan)
                            scansAssigned.append(scan)
                            if (debug):
                                print "tol=%.0f: calscandict[%d].append(%d) of %s (%s-%s)" % (tolerance,cal,scan,str(trialscans), mjdsecToUTHMS(calscantimesdict[cal]), mjdsecToUTHMS(calscantimesdict[cal]+tolerance*2))
        # loosen the tolerance until all are filled with a value
        if (len(scansAssigned) == len(cal_sbr_scans)):
            allFilled = True
            for key in calscandict.keys():
                if (len(calscandict[key]) == 0):
                    allFilled = False
            if (allFilled): break
        unassigned = np.setdiff1d(cal_sbr_scans, scansAssigned) 
        if (tolerance+tol < stopTol):
            scansAssigned = []
            calscandict = {}
        if ((debug or tolerance+tol > stopTol) and sbr and atm and len(unassigned)>0):
            print "not all scans assigned (%d vs. %d), unassigned = %s" % (len(scansAssigned), len(calscans)+len(sbrscans), str(unassigned))
    csd = {}
    for key in calscandict.keys():
        if (len(calscandict[key]) > 0):
            csd[key] = np.array(calscandict[key],int32)
    if needToClose:
        mymsmd.close()
    if (debug):
        print "returning from buildCalDataIdDictionary, %d/%d scans assigned" % (len(scansAssigned),len(cal_sbr_scans))
    return(csd)
    
def readCalData(vis, calType='CAL_ATMOSPHERE'):
    """
    Provides the mapping from cal data ID to scan number
    Returns:
       a translation dictionary from calDataId to scan numbers
    Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    if (os.path.exists(vis+'/ASDM_CALDATA') == False):
        print "No ASDM_CALDATA file.  Either importasdm(asis='CalData') or try readCalDataFromASDM instead."
        return 
    mytb.open(vis+'/ASDM_CALDATA')
    calDataId = np.array([int(c.split('_')[-1]) for c in mytb.getcol('calDataId')])
    calibType = mytb.getcol('calType')
    if (calType not in calibType):
        print "%s is not a calibration type in this dataset.\nAvailable types = %s" % (calType,str(np.unique(calibType)))
        return
    scanSet = []
    for row in range(len(calibType)):
        scanSet.append(mytb.getcell('scanSet',row))
    mytb.close()
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (calType == 'CAL_ATMOSPHERE'):
        calatmscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
    else:
        calatmscans = mymsmd.scansforintent(calType)
    mymsmd.close()
    mydict = {}
    for row in range(len(calibType)):
        cDI = calDataId[row]
        mydict[cDI] = scanSet[row]
    return(mydict)
    
def readCalDataFromASDM(sdmfile):
    """
    Builds a dictionary relating the calDataId to the scan number of an ASDM.
    Todd Hunter
    """
    if (os.path.exists(sdmfile) == False):
        print "readCalDataFromASDM(): Could not find file = ", sdmfile
        return
    xmlscans = minidom.parse(sdmfile+'/CalData.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        scandict[fid] = {}
        rowscan = rownode.getElementsByTagName("scanSet")
        tokens = rowscan[0].childNodes[0].nodeValue.split()
        scan = int(tokens[2])

        rowcaldataid = rownode.getElementsByTagName("calDataId")
        caldataid = str(rowcaldataid[0].childNodes[0].nodeValue)
        scandict[fid]['calDataId'] = caldataid
        scandict[fid]['scan'] = scan
        fid +=1 
    return(scandict)

def readCalPointingTable(sdmfile):
    """
    Reads the CalPointing.xml table for the specified ASDM
    and returns a dictionary of values.
    Todd Hunter
    """
    if (not os.path.exists(sdmfile)):
        print "readCalPointingTable(): Could not find ASDM = ", sdmfile
        return(None)
    if (not os.path.exists(sdmfile+'/CalPointing.xml')):
        print "readCalPointingTable(): Could not find %s/CalPointing.xml." % (sdmfile)
        return(None)
    xmlscans = minidom.parse(sdmfile+'/CalPointing.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        scandict[fid] = {}
        rowAntennaName = rownode.getElementsByTagName("antennaName")
        antenna = str(rowAntennaName[0].childNodes[0].nodeValue)

        rowDirection = rownode.getElementsByTagName("direction")
#        for r in range(len(rowDirection)):
#            for c in range(len(rowDirection[r].childNodes)):
#                print "%d %d = " % (r,c), rowDirection[r].childNodes[c].nodeValue
        tokens = rowDirection[0].childNodes[0].nodeValue.split()
        azimuth = float(tokens[2])
        elevation = float(tokens[3])

        rowFrequency = rownode.getElementsByTagName("frequencyRange")
        tokens = rowFrequency[0].childNodes[0].nodeValue.split()
        frequency1 = float(tokens[2])
        frequency2 = float(tokens[3])
        frequency = 0.5*(frequency1+frequency2)

        rowRelative = rownode.getElementsByTagName("collOffsetRelative")
        tokens = rowRelative[0].childNodes[0].nodeValue.split()
        azOffset = float(tokens[3])
        elOffset = float(tokens[4])
        azOffset2 = float(tokens[5])
        elOffset2 = float(tokens[6])
        
        rowRelative = rownode.getElementsByTagName("collError")
        tokens = rowRelative[0].childNodes[0].nodeValue.split()
        azError = float(tokens[3])
        elError = float(tokens[4])
        azError2 = float(tokens[5])
        elError2 = float(tokens[6])
        
        rowCalDataId = rownode.getElementsByTagName("calDataId")
        calDataId = str(rowCalDataId[0].childNodes[0].nodeValue)
        scan = int(calDataId.split('_')[1])

        rowpol = rownode.getElementsByTagName("polarizationTypes")
        tokens = rowpol[0].childNodes[0].nodeValue.split()
        poltypes = []
        poltypes.append(str(tokens[2]))
        poltypes.append(str(tokens[3]))

        # start and end times in mjd ns
        rowstart = rownode.getElementsByTagName("startValidTime")
        start = int(rowstart[0].childNodes[0].nodeValue)/1000000000
        startmjd = start/86400.0
        t = qa.quantity(startmjd,'d')
        starttime = call_qa_time(t,form="ymd",prec=8)
        rowend = rownode.getElementsByTagName("endValidTime")
        end = int(rowend[0].childNodes[0].nodeValue)
        endmjd = float(end)*1.0E-9/86400.0
        t = qa.quantity(endmjd,'d')
        endtime = call_qa_time(t,form="ymd",prec=8)

        scandict[fid]['startValidTime'] = start
        scandict[fid]['endValidTime'] = end
        scandict[fid]['start'] = starttime
        scandict[fid]['end'] = endtime
        scandict[fid]['startmjd'] = startmjd
        scandict[fid]['endmjd'] = endmjd
        scandict[fid]['startmjdsec'] = startmjd*86400
        scandict[fid]['endmjdsec'] = endmjd*86400
        timestr = starttime+'~'+endtime
        scandict[fid]['azimuth'] = azimuth
        scandict[fid]['elevation'] = elevation
        scandict[fid]['antenna'] = antenna
        scandict[fid]['frequency'] = frequency
        scandict[fid]['azOffset'] = azOffset
        scandict[fid]['elOffset'] = elOffset
        scandict[fid]['azOffset2'] = azOffset2
        scandict[fid]['elOffset2'] = elOffset2
        scandict[fid]['azError'] = azError
        scandict[fid]['elError'] = elError
        scandict[fid]['azError2'] = azError2
        scandict[fid]['elError2'] = elError2
        scandict[fid]['scan'] = scan
        scandict[fid]['duration'] = (endmjd-startmjd)*86400
        scandict[fid]['polarizationTypes'] = poltypes
        fid += 1

    print '  Found ',rowlist.length,' rows in CalPointing.xml'

    # return the dictionary for later use
    return scandict
# end of readCalPointingTable(sdmfile):

def readCalPointing(asdm):
    """
    Calls readCalPointingTable() and converts the returned dictionary to a list
    of lists that is subsequently used by plotPointingResultsFromASDM().
    Todd Hunter
    """
    dict = readCalPointingTable(asdm)
    if (dict is None):
        return
    colOffsetRelative = []
    colError = []
    antennaName = []
    pols = []
    scans = []
    startValidTime = []
    azim = []
    elev = []
    frequency = []
    for entry in dict:
        colOffsetRelative.append([[dict[entry]['azOffset'],dict[entry]['elOffset']],[dict[entry]['azOffset2'],dict[entry]['elOffset2']]])
        antennaName.append(dict[entry]['antenna'])
        startValidTime.append(dict[entry]['startValidTime'])
        pols.append(dict[entry]['polarizationTypes'])
        scans.append(dict[entry]['scan'])
        azim.append(dict[entry]['azimuth'])
        elev.append(dict[entry]['elevation'])
        frequency.append(dict[entry]['frequency']*1e-9)
        colError.append([[dict[entry]['azError'], dict[entry]['elError']], [dict[entry]['azError2'], dict[entry]['elError2']]])
    return([ARCSEC_PER_RAD*np.array(colOffsetRelative), antennaName, startValidTime, pols, scans,
            np.array(azim)*180/math.pi,np.array(elev)*180/math.pi, ARCSEC_PER_RAD*np.array(colError), np.array(frequency)])   


def getMedianPWV(vis='.', myTimes=[0,999999999999], asdm='', verbose=False):
    """
    Extracts the PWV measurements from the WVR on all antennas for the
    specified time range.  The time range is input as a two-element list of
    MJD seconds (default = all times).  First, it tries to find the ASDM_CALWVR
    table in the ms.  If that fails, it then tries to find the 
    ASDM_CALATMOSPHERE table in the ms.  If that fails, it then tried to find 
    the CalWVR.xml in the specified ASDM, or failing that, an ASDM of the 
    same name (-.ms).  If neither of these exist, then it tries to find 
    CalWVR.xml in the present working directory. If it still fails, it looks 
    for CalWVR.xml in the .ms directory.  Thus, you only need to copy this 
    xml file from the ASDM into your ms, rather than the entire ASDM. Returns 
    the median and standard deviation in millimeters.
    Returns:
    The median PWV, and the median absolute deviation (scaled to match rms)
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/GetMedianPWV
    -- Todd Hunter
    """
    pwvmean = 0
    success = False
    if (verbose):
        print "in getMedianPWV with myTimes = ", myTimes
    try:
      if (os.path.exists("%s/ASDM_CALWVR"%vis)):
          mytb = tbtool()
          mytb.open("%s/ASDM_CALWVR" % vis)
          pwvtime = mytb.getcol('startValidTime')  # mjdsec
          antenna = mytb.getcol('antennaName')
          pwv = mytb.getcol('water')
          mytb.close()
          success = True
          if (len(pwv) < 1):
              if (os.path.exists("%s/ASDM_CALATMOSPHERE" % vis)):
                  pwvtime, antenna, pwv = readPWVFromASDM_CALATMOSPHERE(vis)
                  success = True
                  if (len(pwv) < 1):
                      print "Found no data in ASDM_CALWVR nor ASDM_CALATMOSPHERE table"
                      return(0,-1)
              else:
                  if (verbose):
                      print "Did not find ASDM_CALATMOSPHERE in the ms"
                  return(0,-1)
          if (verbose):
              print "Opened ASDM_CALWVR table, len(pwvtime)=", len(pwvtime)
      else:
          if (verbose):
              print "Did not find ASDM_CALWVR table in the ms. Will look for ASDM_CALATMOSPHERE next."
          if (os.path.exists("%s/ASDM_CALATMOSPHERE" % vis)):
              pwvtime, antenna, pwv = readPWVFromASDM_CALATMOSPHERE(vis)
              success = True
              if (len(pwv) < 1):
                  print "Found no data in ASDM_CALATMOSPHERE table"
                  return(0,-1)
          else:
              if (verbose):
                  print "Did not find ASDM_CALATMOSPHERE in the ms"
    except:
        if (verbose):
            print "Could not open ASDM_CALWVR table in the ms"
    finally:
    # try to find the ASDM table
     if (success == False):
       if (len(asdm) > 0):
           if (os.path.exists(asdm) == False):
               print "Could not open ASDM = ", asdm
               return(0,-1)
           try:
               [pwvtime,pwv,antenna] = readpwv(asdm)
           except:
               if (verbose):
                   print "Could not open ASDM = %s" % (asdm)
               return(pwvmean,-1)
       else:
           try:
               tryasdm = vis.split('.ms')[0]
               if (verbose):
                   print "No ASDM name provided, so I will try this name = %s" % (tryasdm)
               [pwvtime,pwv,antenna] = readpwv(tryasdm)
           except:
               try:
                   if (verbose):
                       print "Still did not find it.  Will look for CalWVR.xml in current directory."
                   [pwvtime, pwv, antenna] = readpwv('.')
               except:
                   try:
                       if (verbose):
                           print "Still did not find it.  Will look for CalWVR.xml in the .ms directory."
                       [pwvtime, pwv, antenna] = readpwv('%s/'%vis)
                   except:
                       if (verbose):
                           print "No CalWVR.xml file found, so no PWV retrieved. Copy it to this directory and try again."
                       return(pwvmean,-1)
    try:
        matches = np.where(np.array(pwvtime)>myTimes[0])[0]
    except:
        print "Found no times > %d" % (myTimes[0])
        return(0,-1)
    if (len(pwv) < 1):
        print "Found no PWV data"
        return(0,-1)
    if (verbose):
        print "%d matches = " % (len(matches)), matches
        print "%d pwv = " % (len(pwv)), pwv
    ptime = np.array(pwvtime)[matches]
    matchedpwv = np.array(pwv)[matches]
    matches2 = np.where(ptime<=myTimes[-1])[0]
    if (verbose):
        print "matchedpwv = %s" % (matchedpwv)
        print "pwv = %s" % (pwv)
    if (len(matches2) < 1):
        # look for the value with the closest start time
        mindiff = 1e12
        for i in range(len(pwvtime)):
            if (abs(myTimes[0]-pwvtime[i]) < mindiff):
                mindiff = abs(myTimes[0]-pwvtime[i])
#                pwvmean = pwv[i]*1000
        matchedpwv = []
        for i in range(len(pwvtime)):
            if (abs(abs(myTimes[0]-pwvtime[i]) - mindiff) < 1.0):
                matchedpwv.append(pwv[i])
        pwvmean = 1000*np.median(matchedpwv)
        if (verbose):
            print "Taking the median of %d pwv measurements from all antennas = %.3f mm" % (len(matchedpwv),pwvmean)
        pwvstd = 1000*MAD(matchedpwv)
    else:
        pwvmean = 1000*np.median(matchedpwv[matches2])
        pwvstd = 1000*MAD(matchedpwv[matches2])
        if (verbose):
            print "Taking the median of %d pwv measurements from all antennas = %.3f mm" % (len(matches2),pwvmean)
    return(pwvmean,pwvstd)
# end of getMedianPWV

def getAntennaIDsFromWeatherTable(vis):
    """
    Reads the unique list of antenna IDs from the WEATHER table of a measurement set.
    For ALMA, this will be [-1].
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/WEATHER')
    ids = mytb.getcol('ANTENNA_ID')
    print "Read %d rows" % (len(ids))
    mytb.close()
    uniqueIDs = np.unique(ids)
    return uniqueIDs

def ReadWeatherStation(scandict, station):
    """
    Parses a dictionary returned by readWeatherFromASDM and returns a list of
    lists of weather quantities.
    station: station ID (integer)
    """
    timeInterval = []
    pressure = []
    relHumidity = []
    temperature = []
    windDirection = []
    windSpeed = []
    windMax = []
    for entry in range(len(scandict)):
        if (scandict[entry]['stationId'] == station):
            timeInterval.append(scandict[entry]['timeInterval'])
            pressure.append(scandict[entry]['pressure'])
            relHumidity.append(scandict[entry]['relHumidity'])
            temperature.append(scandict[entry]['temperature'])
            windDirection.append(scandict[entry]['windDirection'])
            windSpeed.append(scandict[entry]['windSpeed'])
            windMax.append(scandict[entry]['windMax'])
#        else:
#            print "scandict=%d != %d" % (scandict[entry]['stationId'],station)
    d1 = [timeInterval, pressure, relHumidity, temperature, windDirection,
          windSpeed, windMax, station]
    return(d1)

def convertASDMTimeIntervalToMJDSeconds(s):
    """
    converts a string of format: 'start=2013-11-10T07:44:17.552000000, duration=369.180000'
    to MJD seconds.
    -Todd Hunter
    """
    ymdhms = s.split('=')[1].split(',')[0]
    return(dateStringToMJDSec(ymdhms,verbose=False))

def asdmspwmap(asdm):
    """
    Generate a list that maps the spw number that will be found in the
    measurement set to the corresponding value in the ASDM xml files.
    In general, the order will be [0,n+1,n+2,....] where n=number of antennas
    with WVR data.  
    Example return list:  [0,5,6,7...] if n=4 antennas, meaning
           that spw 1 in the ms = spw 5 in the ASDM xml files.
    -Todd Hunter
    """
    if (asdmLibraryAvailable == False):
        spwmap = au_noASDMLibrary.asdmspwmap(asdm)
        return spwmap
    a = ASDM()
    a.setFromFile(asdm,True)
    spwTable = a.spectralWindowTable().get()
    spwmap = []
    for row in range(len(spwTable)):
        if (spwTable[row].name().find('WVR#Antenna') < 0):
            spwmap.append(row)
    return(spwmap)

def readTcal(asdm, antenna, spw, meantime=None, spectrum='tcal', verbose=False):
    """
    Read the Tcal, Trx, Tsky, or Tsys spectrum for a specific antenna, spw and time. 
    If the time is not specified, it will return a dictionary of spectra keyed
    by the time (in MJD seconds).  The spw should be an spw number
    in the measurement set that is associated with a CALIBRATE_ATMOSPHERE scan.
    A conversion will be made to the spw number
    in the ASDM. If the spw is FDM, it is up to the user to find
    the associated TDM spw (e.g. via tsysspwmap) and pass it in.
    antenna: the antenna ID (string or integer, not the name)
    spw: the spw ID (string or integer)
    spectrum: 'tsys', 'trx' or 'tcal'

    Returns:
    A dictionary keyed by the MJD in seconds, with values equal to a list of
    arrays (one per polarization) each with N channels.
    
    Todd Hunter
    """
    spectrum = spectrum.lower()
    antenna = str(antenna)
    spw = int(spw)
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine."
        return
    a = ASDM()
    a.setFromFile(asdm,True)
    sysCalTable = a.sysCalTable().get()
    # find offset (usually it is the number of antennas with WVR data)
    spwmap = asdmspwmap(asdm)
    if (verbose):
        print "Spwmap = ", spwmap
    spectra = {}
    timeDelta = 1e20
    for row in sysCalTable:
        antennaId = str(row.antennaId()).split('_')[1]
        if (antennaId == antenna):
            spectralWindowId = str(row.spectralWindowId()).split('_')[1]
            myspw = int(spectralWindowId)
            if (verbose):
                print "spw %d in the MS is spw %d in the ASDM, comparing to ASDM spw %d" % (spw, spwmap[spw], myspw)
            if (spwmap[spw] == myspw):
                mjdsec = convertASDMTimeIntervalToMJDSeconds(str(row.timeInterval()))
                if (spectrum == 'tcal'):
                    values = row.tcalSpectrum()
                elif (spectrum == 'trx'):
                    values = row.trxSpectrum()
                elif (spectrum == 'tsys'):
                    values = row.tsysSpectrum()
                elif (spectrum == 'tsky'):
                    values = row.tskySpectrum()
                elif (spectrum == 'tant'):
                    values = row.tantSpectrum()
                else:
                    print "Unrecognized spectrum type (%s)" % (spectrum)
                    return
                spectra[mjdsec] = []
                for v in values: # there will be one per polarization
                    spectra[mjdsec].append(np.array([v[f].get() for f in range(row.numChan())]))
                if (meantime is not None):
                    if (abs(mjdsec-meantime) < timeDelta):
                        timeDelta = abs(mjdsec-meantime)
                        closestTime = mjdsec
    if (verbose):
        print "Found %d spectra" % (len(spectra))
    if (meantime is None):
        return(spectra)
    else:
        return(spectra[closestTime], closestTime)

def readStationFromASDMKeyedByAntennaName(sdmfile, station=None):
    """
    Similar to readStationFromASDM and readStationsFromASDM, but returns a dictionary keyed
    by antenna name (instead of antenna ID or pad name).
    Todd Hunter
    """
    mydict = readStationFromASDM(sdmfile, station)
    newdict = {}
    antennaNames = readAntennasFromASDM(sdmfile,verbose=False)
    for key in mydict.keys():
        if (key < len(antennaNames)):
            antennaName = antennaNames[key]
            newdict[antennaName] = mydict[key]
    return(newdict)
    
def getAntennaAmbientTemperaturesFromASDM(asdmFile,  debugPlot=False):
    """
    Access the TMCDB for the antenna amibent temperatures recorded during
    an observation.
    Returns: 4 lists:
        timeList, antennaTemps, meanAntennaTemps, meanAntennaTempsErr
    - Denis Barkats.
    """
    from dateutil import rrule
    
    # get the start time of the ASDM
    dateStart, dateStart_mjdSec = getObservationStartDateFromASDM(asdmFile)
    dateEnd, dateEnd_mjdSec = getObservationEndDateFromASDM(asdmFile)
    antList = readAntennasFromASDM(asdmFile)
    start = dateStart.split(' UT')[0].replace(' ','T')
    end = dateEnd.split(' UT')[0].replace(' ','T')
    
    s = datetime.datetime.strptime(start, '%Y-%m-%dT%H:%M:%S')
    e = datetime.datetime.strptime(end, '%Y-%m-%dT%H:%M:%S')

    # time range to interpolate the other monitor points on.
    timeList = list(rrule.rrule(rrule.SECONDLY,interval=30, dtstart=s,until=e))
    ftimeList = pb.date2num(timeList)

    antennaTemps = {}
    meanAntennaTemps = {}
    meanAntennaTempsErr = {}
    for ant in antList:
        if ant[0:2]=='CM':
            # from ICT-1797
            # CM antennas: quadrapod, 4 total:
            # GET_METR_TEMPS_04[0]...[3]
            mpts = {'METR_TEMPS_04': [0,1,2,3]}
            antennaTemps[ant]=[[],[],[],[]]
                        
        elif  ant[0:2]=='DA':
            # DA antennas: apex, 3 total:
            # GET_METR_TEMPS_14[3] + GET_METR_TEMPS_15[0] + GET_METR_TEMPS_15[1]
            mpts = {'METR_TEMPS_14': [3], 'METR_TEMPS_15':[0,1]}
            antennaTemps[ant]=[[],[],[]]
                                               
        elif  ant[0:2]=='DV':
            # DV antennas: hexapod-subreflector interface cylinder, 8 total:
            # GET_METR_TEMPS_00[0]...[3] + GET_METR_TEMPS_01[0]...[3]
            mpts = {'METR_TEMPS_00': [0,1,2,3], 'METR_TEMPS_01': [0,1,2,3]}
            antennaTemps[ant]=[[],[],[],[],[],[],[],[]]
            time = [[],[],[],[],[],[],[],[]]
            
        elif  ant[0:2]=='PM':
            # PM antennas: 'ambient' temperature, 1 total:
            # GET_METR_TEMPS_1B[0]
            mpts = {'METR_TEMPS_1B': [0]}
            antennaTemps[ant]=[[]]

        meanAntennaTempsErr[ant]=[]
        meanAntennaTempsErr[ant]=[]

        # TODO: Put an offset in DV07 sensors before Nov 25th
        # TODO put offset in CM06 until a certain date.
        
        i = 0
        for m in mpts.keys():
            print start, end, ant, m
            t = tmu.get_tmc_data(ant,'Mount',m,start,end, removefile=True, verbose=True)
            q = find((array(t['datetime']) > s) & (array(t['datetime']) < e))
            time = array(t['datetime'])[q]
            # interpolate the temperatures to common timeList range (once every 10s)
            for k in mpts[m]:
                antennaTemps[ant][i]= interp(ftimeList,date2num(time),array(t['value'])[q,k]/100.)
                i +=1
                
        if (debugPlot):
            figure(1); clf()
            for k in range(shape(antennaTemps[ant])[0]):
                plot(timeList,antennaTemps[ant][k], '.')
            
        # take the average over monitorpoints.
        std1 = mean(std(antennaTemps[ant],axis=0))  # std from averaging over monitor points
        antennaTemps[ant] = mean(antennaTemps[ant],axis=0)
        if (debugPlot): plot(timeList,antennaTemps[ant], 'ko')
        
        # take the average over time
        if debugPlot: print ant, mean(antennaTemps[ant]), std(antennaTemps[ant])
        # the err is the quadratic sum of uncertainty over monitor points and uncertainty over time
        meanAntennaTempsErr[ant]= sqrt(std(antennaTemps[ant])**2+std1**2)
        meanAntennaTemps[ant] = mean(antennaTemps[ant])

        if (debugPlot):
            title('%s-%s, T=%3.2f +- %3.2f'%(asdmFile,ant,antennaTemps[ant],antennaTempsErr[ant]))
            savefig('%s_%s_ambientTemp.png'%(asdmFile,ant))
                
    return timeList, antennaTemps, meanAntennaTemps,meanAntennaTempsErr
    
def plotAntennaAmbientTemperatures(asdm):
    """
    Makes two plots of antenna ambient temperature: vs. time and vs. height
    Inputs:
    asdm: name of the ASDM
    -Denis Barkats
    """
    # TODO: add Nanten temps when discrepancy with ASTE is resolved ?
    
    from matplotlib import cm
    import matplotlib as mpl
    
    baselineLength = getBaselineLengthsFromASDM(asdm,'WSTB1')
    heightDiff = getBaselineHeightFromASDM(asdm,'WSTB1', verbose=False)
    pads = getAntennaPadsFromASDM(asdm)
    
    h = array(sorted(heightDiff.values()))
    ant_by_h = sorted(heightDiff,key=heightDiff.get)
    scaled_h = (h - h.min()) / h.ptp()
    colors_h = cm.coolwarm(scaled_h)

    bl= array(sorted(baselineLength.values()))
    ant_by_bl = sorted(baselineLength,key=baselineLength.get)
    scaled_bl = (bl - bl.min()) / bl.ptp()
    colors_bl = cm.jet(scaled_bl)
    
    # get antenna ambient temperatures
    time, temps, meanTemp, meanTempErr = getAntennaAmbientTemperaturesFromASDM(asdm)

    # Get Weather station data. 
    [conditions, medianConditions,stationName] = getWeatherFromASDM(asdm,station=1,verbose=False)
    mjdsec = array(conditions[0])
    weatherTime = mjdSecondsListToDateTime(mjdsec)
    temperature = kelvinToCelsius(array(conditions[3]))

    # plot temperatures vs time
    figure(1,figsize=(12,9));clf()
    i=0
    for ant in ant_by_h:
        plot(time,temps[ant],'o',color=tableau20[i], markeredgecolor=tableau20[i])
        i+=1
    plot(weatherTime, temperature,'k')
    legend(ant_by_h+['WSTB1'], prop={'size':9}, ncol=1,bbox_to_anchor=(1.1,1.02))
    title(asdm+' Weather station and antenna ambient temperatures')
    xlabel('UT time')
    ylabel('Temperature (C)')
    grid()
    fig1 = '%s_ambientTemp_vs_time.png'%(asdm)
    savefig(fig1)

    # plot temperatures vs height diff
    figure(2,figsize=(12,9));clf()
    legendtxt = []
    for ant in ant_by_h:
        marker = 'bo'
        if pads[ant][0] == 'P': marker='ro'
        if pads[ant][0] == 'S': marker='go'
        if pads[ant][0] == 'W': marker='mo'
        if (pads[ant][0] == 'N') or (pads[ant][0] == 'J'): marker='co'
        if pads[ant][0:2] == 'A1': marker='yo'
        errorbar(heightDiff[ant],meanTemp[ant],meanTempErr[ant],fmt= marker)
        legendtxt.append('%s-%s:%2.1f'%(ant,pads[ant],meanTemp[ant]))
    errorbar([0],mean(temperature),std(temperature),fmt= 'ko')
    x = -500+arange(600)
    plot(x, -0.0065*x+mean(temperature),'k-')
    legendtxt.append('WSTB1:%2.1f'%(mean(temperature)))
    title(asdm+' Temperature vs height difference wrt Weather station ')
    legend(legendtxt, prop={'size':9}, ncol=1,bbox_to_anchor=(1.1,1.02))
    xlabel('Height Diff [m]')
    ylabel('Temperature (C)')
    grid()
    fig2 = '%s_ambientTemp_vs_height.png'%(asdm)
    savefig(fig2)

    # plot temperatures vs height diff, color coded with distance to Weather station
    fig = figure(3,figsize=(12,9));clf()
    legendtxt = []
    i=0
    for ant in ant_by_bl:
        m = 'o'
        errorbar(heightDiff[ant],meanTemp[ant],meanTempErr[ant],marker=m, mfc=colors_bl[i], mec=colors_bl[i], ecolor=colors_bl[i])
        legendtxt.append('%s-%s:%2.1f'%(ant,pads[ant],meanTemp[ant]))
        i+=1
    errorbar([0],mean(temperature),std(temperature),fmt= 'ko')
    x = -500+arange(600)
    plot(x, -0.0065*x+mean(temperature),'k-')
    legendtxt.append('WSTB1:%2.1f'%(mean(temperature)))
    title(asdm+' Temperature vs height difference wrt Weather station')
    legend(legendtxt, prop={'size':9}, ncol=1,bbox_to_anchor=(1.1,1.02))
    xlabel('Height Diff [m]')
    ylabel('Temperature (C)')
    grid()
    ax1 = fig.add_axes([0.17, 0.87, 0.65, 0.02])
    cmap = cm.jet
    norm = mpl.colors.Normalize(vmin=min(bl)/1e3, vmax = max(bl)/1e3)
    cb1 = mpl.colorbar.ColorbarBase(ax1,cmap=cmap,orientation='horizontal', norm=norm)
    cb1.set_label('Distance to Weather station [km]')
    fig3 = '%s_ambientTemp_vs_height_distance.png'%(asdm)
    savefig(fig3)
    print "Plots left in: ", fig1
    print "               ", fig2
    print "               ", fig3
    
def getWeatherStationNamesFromASDM(asdm, prefix=['WSTB','Meteo','OSF'], 
                                   returnNearestAntennas=False):
    """
    Gets the names of the weather stations in an ASDM.
    Returns: a dictionary keyed by station ID
    -Todd Hunter
    """
    asdm = uidToUnderscores(asdm)
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm + '/Station.xml')):
        print "Could not find Station.xml, is this really an ASDM?"
        return
    if (type(prefix) != list):
        prefix = [prefix]
    mydict = readStationFromASDM(asdm)
    names = []
    ids = []
    newdict = {}
    for s in mydict.keys():
        for p in prefix:
            if (mydict[s]['name'].lower().find(p.lower()) >= 0):
                names.append(mydict[s]['name'])
                ids.append(s)
                newdict[s] = mydict[s]['name']
    if (returnNearestAntennas):
        stations = getWeatherStationPositionsFromASDM(asdm)
        posdict = getPadPositionsFromASDM(asdm)
        pads = getAntennaPadsFromASDM(asdm,keyByPadName=True)
        for pad in posdict.keys():
            antennaName = pads[pad]
            antennaPosition = readAntennaPositionFromASDM(asdm)[antennaName]['position']
            posdict[pad] += computeITRFCorrection(posdict[pad], antennaPosition)
        newdict = {}
        for station in stations:
            mindistance = 1e12
            for pad in posdict.keys():
                distance = np.linalg.norm([posdict[pad][0] - stations[station][0],
                                           posdict[pad][1] - stations[station][1],
                                           posdict[pad][2] - stations[station][2]])
                if (mindistance > distance):
                    mindistance = distance
                    closestPad = pad
            closestAntenna = pads[closestPad]
            newdict[station] = {'antenna': closestAntenna, 'distance': round(mindistance,1), 'pad': closestPad}
    return(newdict)

def exportAndGetWeatherStationPositionFromASDM(asdm, station='WSOSFLab', outfile=''):
    """
    Returns the position of the specified weather station from an ASDM.
    If asdm is not find, it first exports its metadata from the archive.
    outfile: if specified then append a line with the date, UID and station position vector.
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        asdmExport(asdm, '-m')
    asdm = uidToUnderscores(asdm)
    if not os.path.exists(asdm):
        return
    positions = getWeatherStationPositionsFromASDM(asdm, prefix=station)
    if positions is None:
        print "That weather station was not found.  Present are: ", 
        return
    for i in positions.keys():
        if i.find(station) >= 0:
            if outfile != '':
                f = open(outfile,'a')
                date = getObservationStartDateFromASDM(asdm)[0]
                f.write('%s %s %s\n' % (date,asdm,positions[i]))
            return positions[i]
    
def getWeatherStationPositionsFromASDM(asdm, prefix=['WSTB','Meteo','OSF'],
                                       returnDeltaHeights=False,
                                       returnClosestPads=False,
                                       returnNearbyPads=False, radius=100,
                                       referenceStation=None):
    """
    Gets the geocentric XYZ positions of the weather stations in an ASDM.
    Returns: a dictionary keyed by station ID
    returnDeltaHeights: if True, then return height (in m) relative to highest one
           in a dictionary keyed by station name, and the name of the highest station
    referenceStation: the station name from which to base the zero point of deltaHeights
    radius: threshold in meters for associating with a nearby pad
    -Todd Hunter
    """
    asdm = uidToUnderscores(asdm)
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm + '/Station.xml')):
        print "Could not find Station.xml, is this really an ASDM?"
        return
    if (type(prefix) != list):
        prefix = [prefix]
    mydict = readStationFromASDM(asdm)
    antennaPads = getPadPositionsFromASDM(asdm)
    newdict = {}
    closestPads = {}
    nearbyPads = {}
    stations = []
    for s in mydict.keys():
        for p in prefix:
            if (mydict[s]['name'].lower().find(p.lower()) >= 0):
                newdict[mydict[s]['name']] = np.array(mydict[s]['position'])
                stations.append(mydict[s]['name'])
                minDistance = 1e9
                nearbyPadlist = []
                nearbyAntennas = []
                for pad in antennaPads:
                    distance = np.linalg.norm(np.array(antennaPads[pad])-newdict[mydict[s]['name']])
                    if (distance < minDistance):
                        minDistance = distance
                        closestPad = pad
                        deltaHeight = geocentricXYZToEllipsoidalHeight(np.array(antennaPads[pad]))-\
                                      geocentricXYZToEllipsoidalHeight(newdict[mydict[s]['name']])
                    if (distance < radius):
                        nearbyPadlist.append(pad)
                        nearbyAntennas.append(getAntennaPadsFromASDM(asdm,keyByPadName=True)[pad])
                closestPads[mydict[s]['name']] = {'closestOccupiedPad': closestPad, 
                                                  'distance': minDistance, 
                                                  'deltaHeight': deltaHeight,
                                                  'closestAntenna': getAntennaPadsFromASDM(asdm,keyByPadName=True)[closestPad]}
                nearbyPads[mydict[s]['name']] = {'nearbyPads': nearbyPadlist,
                                                 'nearbyAntennas': nearbyAntennas}
    if (returnDeltaHeights):
        return(computeDeltaEllipsoidalHeights(newdict, referenceStation))
    elif (returnClosestPads):
        return(closestPads)
    elif (returnNearbyPads):
        return(nearbyPads)
    else:
        return(newdict)

def readStationFromASDM(sdmfile, station=None):
    """
    This function uses the ASDM bindings from casapy-telcal and reads the Station 
    position from the Station.xml file ( in the ASDM) and returns a dictionary of 
    station positions if no station is specified.  The dictionary format is:  
    {0: {'name':'J503',position:[x,y,z]}, 1:  etc.}.  If a station is specified, then 
    it returns the name and location as a simple list: ['J503',[x,y,z]].  
    - dbarkats
    """
    if not asdmLibraryAvailable:
#        print "The ASDM bindings library is not available on this machine. Using minidom code instead."
        mydict = au_noASDMLibrary.readStationFromASDM_minidom(sdmfile)
        if (station is None):
            return(mydict)
        else:
            return(mydict[station]['name'],mydict[station]['position'])
    a = ASDM()
    a.setFromFile(sdmfile,True)
    stationTable = a.stationTable().get()  

    staPos = {}
    for row in stationTable:
        stationName = row.name()
        position = [row.position()[0].get(),row.position()[1].get(),row.position()[2].get()]
        id = row.stationId().get()
        if (id not in staPos):  staPos[id] = {}
        staPos[id] = {'position':position, 'name':stationName}
    if (station is not None):
        return(staPos[station]['name'], staPos[station]['position'])
    return staPos

def getPadPositions(vis, includeWeatherStations=False):
    """
    Reads the pad positions in geocentric XYZ coordinates from an ms,
    (excluding the weather stations).
    Returns a dictionary keyed by pad name, with value = its XYZ position.
    - Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    antTable = vis+'/ASDM_STATION'
    if (not os.path.exists(antTable)):
        print "Could not find ASDM_STATION table: %s" % (antTable)
        return
    mytb = createCasaTool(tbtool)
    mytb.open(antTable)
    position = np.transpose(mytb.getcol('position'))
    names = list(mytb.getcol('name'))
    types = list(mytb.getcol('type'))
    mytb.close()
    padDict = {}
    for i,name in enumerate(names):
        if (types[i] == 'ANTENNA_PAD' or includeWeatherStations):
            padDict[name] = position[i]
    return padDict

def getPadHeight(vis, pad=None, LOC=False):
    """
    Reads the XYZ geocentric coordinates for the specified pad and computes
    the Pythagorean distance from the center of the Earth.
    vis: name of measurement set
    pad: name of pad, e.g. 'W207'
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "getPadHeight: Could not find measurement set = ", vis
        return
    padDict = getPadPositions(vis)
    if (padDict is None): return
    names = padDict.keys()
    position = padDict.values()
    if (pad is None):
        mydict = {}
        for i,pad in enumerate(names):
            mydict[pad] = np.linalg.norm(position[i])
        return mydict
    elif (pad not in names):
        print "Pad %s not in dataset" % pad
        return
    else:
        idx = names.index(pad)
        return(np.linalg.norm(position[idx]))
        
def getPadHeightFromASDM(asdm, pad=None, LOC=False):
    """
    Reads the XYZ geocentric coordinates for the specified pad and computes
    the Pythagorean distance from center of the Earth.
    asdm: name of ASDM
    pad: name of pad, e.g. 'W207'
    LOC: if True, use getPadLOC to get local tangent plane
         if False, use raw distance from geocenter
    """
    if LOC:
        return(getPadLOC(pad)[2])
    else:
        result = getPadXYZFromASDM(asdm, pad)
        if result==None: return
        return(np.linalg.norm(result))
    
def getPadXYZFromASDM(asdm, pad=None):
    """
    Reads the XYZ geocentric coordinates for the specified pad
    asdm: name of ASDM
    pad: name of pad, e.g. 'W207'
    """
    if (asdmLibraryAvailable == False):
        mydict = au_noASDMLibrary.readStationsFromASDM_minidom(asdm)
    else:
        mydict = readStationsFromASDM(asdm)
    if (pad is None):
        print "Select one of the available pads: ", mydict.keys()
    if (pad not in mydict.keys()):
        print "This pad is not in the ASDM. Available pads: ", mydict.keys()
        return
    position = mydict[pad]
    return(position)

def getDistanceFromMedianPadLOCFromASDM(asdm):
    """
    Computes a dictionary of distance of each antenna pad from the median 
    pad location in ENU coordinates, keyed by antenna name.
    -Todd Hunter
    """
    medianENU = np.array(getMedianPadLOCFromASDM(asdm))
    locs = getPadLOCsFromASDM(asdm)
    antennaNames = locs.keys()
    distance = {}
    for antennaName in antennaNames:
        distance[antennaName] = np.linalg.norm(locs[antennaName]-medianENU)
    return distance
    
def getMedianPadLOCFromASDM(asdm):
    """
    Computes the median of pad locations in an ASDM in ENU coordinates
    (in meters).  - Todd Hunter
    """
    mydict = getPadLOCsFromASDM(asdm)
    east,north,up = np.transpose(mydict.values())
    return [np.median(east), np.median(north), np.median(up)]

def getPadLOCsFromASDM(asdm):
    """
    Gets a dictionary of pad locations in an ASDM in ENU coordinates 
    (in meters), keyed by antenna name.
    -Todd Hunter
    """
    mydict = readStationFromASDMKeyedByAntennaName(asdm)
    cx,cy,cz,clong,clat = getCOFAForASDM(asdm)
    antennaNames = mydict.keys()
    locs = {}
    for antennaName in antennaNames:
        x,y,z = mydict[antennaName]['position']
        x,y,z = simutil.simutil().itrf2loc(x,y,z,cx,cy,cz)
        locs[antennaName] = np.array([x[0],y[0],z[0]])
    return locs
    
def readAntennaPositionFromASDM(sdmfile, antennaType=''):
    """
    This function uses the ASDM bindings from casapy-telcal and reads the
    Antenna position (relative to its pad) from the Antenna.xml file 
    (in the ASDM) and returns a dictionary of Antenna positions in the 
    ENU coordinate system.
    antennaType: restrict to 'DA' or 'DV' or 'PM' or 'CM'
    - dbarkats
    """
    if (asdmLibraryAvailable == False):
        return(au_noASDMLibrary.readAntennaPositionFromASDM_minidom(sdmfile,antennaType))
#        print "readAntennaPositionFromASDM: The ASDM bindings library is not available on this machine and there is no workaround."
        return
    a = ASDM()
    a.setFromFile(sdmfile,True)
    antennaTable = a.antennaTable().get()  

    antPos = {}
    for row in antennaTable:
        antName = row.name()
        id = row.stationId().get()
        position = [row.position()[0].get(),row.position()[1].get(),row.position()[2].get()]
        if (antName not in antPos):  antPos[antName] = {}
        antPos[antName] = {'position':position, 'id':id}
        
    return antPos

def getAntennaPadsForObsID(vis, obsid=0, keyByAntennaName=False):
    """
    For a concatenated dataset, this function allows you to break the degeneracy when
    a given antenna name occupies more than one pad.  CAS-9358 was created to add this
    ability to msmd.antennaids and msms.antennastations.
    keyByAntennaName: if True, then return a dictionary keyed by antenna name
    Returns: an array of station names
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find ms"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    myt = mytb.query('OBSERVATION_ID==%d'%obsid)
    ant1 = list(np.unique(myt.getcol('ANTENNA1')))
    ant2 = list(np.unique(myt.getcol('ANTENNA2')))
    myt.close()
    mytb.close()
    mytb.open(vis+'/ANTENNA')
    pads = mytb.getcol('STATION')
    names = mytb.getcol('NAME')
    mytb.close()
    ants = np.unique(ant1 + ant2)
    if keyByAntennaName:
        return(dict(itertools.izip(names[ants],pads[ants])))
    else:
        return(pads[ants])

def convertPadDictionaryToAntenna(mydict, vis):
    """
    Takes a dictionary keyed by pad name and converts it to one keyed
    by antenna name.
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    names = mymsmd.antennanames()
    stations = mymsmd.antennastations()
    mymsmd.close()
    newdict = {}
    for i in mydict:
        idx = list(stations).index(i)
        newdict[names[idx]] = mydict[i]
    return newdict

def convertAntennaDictionaryToPad(mydict, vis):
    """
    Takes a dictionary keyed by antenna name and converts it to one keyed
    by pad name.
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    names = mymsmd.antennanames()
    stations = mymsmd.antennastations()
    mymsmd.close()
    newdict = {}
    for i in mydict:
        idx = list(names).index(i)
        newdict[stations[idx]] = mydict[i]
    return newdict

def getAntennaPads(vis, exclude='', keyByAntennaName=False, keyByPadName=False, mymsmd=''):
    """
    Gets a list of antenna pads from a measurement set using msmd, excluding
    weather stations.
    exclude: a comma-separated list of pads to exclude
       'LBC' will remove the 21 pads of the ALMA LB campaign
    keyByAntennaName: will return a dictionary keyed by antenna name
    keyByPadName: will return a dictionary keyed by pad
    - Todd Hunter
    """
    stationList = exclude.split(',')
    if stationList[0] == 'LBC':
        stationList = ['P410','P405','P404','P402','P401','W204',
                       'W206','W207','W210','S301','S305','S306',
                       'A113','A118','A121','A122','A124','A127',
                       'A131','A132','A133']
        print "Ignoring LBC stations: ", stationList
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    stations = mymsmd.antennastations()
    antennas = mymsmd.antennanames()
    if needToClose:
        mymsmd.close()
    if keyByAntennaName:
        if (keyByPadName): 
            print "keyByPadName and keyByAntennaName are mutually exclusive options"
            return
        mydict = {}
        for i,station in enumerate(stations):
            mydict[antennas[i]] = station
        return(mydict)
    elif keyByPadName:
        mydict = {}
        for i,station in enumerate(stations):
            mydict[station] = antennas[i]
        return(mydict)
    else:
        mylist = [x for x in stations if x not in stationList]
        return(mylist)

def padDifferencesFromASDM(asdm1, asdm2, showStableAntennas=False):
    """
    Describes the differences in antennas and pads between two
    datasets by looking at the ASDMs.  It then looks at antennaMoves.txt
    and shows what it thinks was the most recent move for each antenna.
    -Todd Hunter
    """
    obsA = getObservationStartDateFromASDM(asdm1)
    obsB = getObservationStartDateFromASDM(asdm2)
    if (obsA[1] < obsB[1]):
        asdm1dict = getAntennaPadsFromASDM(asdm1, keyByPadName=False)
        asdm2dict = getAntennaPadsFromASDM(asdm2, keyByPadName=False)
        date1 = obsA[0]
        date2 = obsB[0]
    else:
        asdm2dict = getAntennaPadsFromASDM(asdm1, keyByPadName=False)
        asdm1dict = getAntennaPadsFromASDM(asdm2, keyByPadName=False)
        date2 = obsA[0]
        date1 = obsB[0]
    antennas1 = asdm1dict.keys()
    antennas2 = asdm2dict.keys()
    for antenna in antennas1:
        if (antenna not in antennas2):
            print "Antenna %s (on pad %s) is not in the newer dataset. Last move = %s" % (antenna,asdm1dict[antenna],getMostRecentMove(antenna))
        else:
            if (asdm1dict[antenna] == asdm2dict[antenna]):
                if (showStableAntennas):
                    print "Antenna %s is on pad %s in both datasets" % (antenna,asdm1dict[antenna])
            else:
                print "Antenna %s moved from pad %s to %s between datasets (%s to %s). Last move = %s" % (antenna,asdm1dict[antenna], asdm2dict[antenna], date1, date2, getMostRecentMove(antenna))
    for antenna in antennas2:
        if (antenna not in antennas1):
            print "Antenna %s (on pad %s) is not in the older dataset. Last move = %s" % (antenna,asdm2dict[antenna],getMostRecentMove(antenna))

def getAntennaPadsFromASDMs(asdmlist, keyByPadName=False):
    """
    Calls getAntennaPadsFromASDM for a list of ASDMs and produces
    a combined dictionary where the values are lists, which will allow it
    to indicate if an antenna appears on multiple stations, or vice-versa.
    asdmlist: a list of ASDMs, a comma-delimeted string,
         or a string with a wildcard ('*.ms')
    keyByPadName: if True, the reverse the dictionary:  {'S301': ['DA41']}
    -Todd Hunter
    """
    if type(asdmlist) == str:
        asdmlist = asdmlist.split(',')
        final_asdmlist = []
        for asdm in asdmlist:
            if (asdm.find('*') >= 0):
                myasdmlist = glob.glob(asdm)
                print "Found %d ASDMs" % (len(myasdmlist))
                final_asdmlist += myasdmlist
            else:
                final_asdmlist.append(asdm)
        asdmlist = final_asdmlist

    for i,asdm in enumerate(asdmlist):
        if (i == 0):
            mydict = getAntennaPadsFromASDM(asdm, keyByPadName)
            for key in mydict:
                mydict[key] = [mydict[key]]
        else:
            newdict = getAntennaPadsFromASDM(asdm, keyByPadName)
            for key in newdict:
                if key not in mydict:
                    mydict[key] = [newdict[key]]
                elif newdict[key] not in mydict[key]:
                    if keyByPadName:
                        print "Pad %s hosts a second antenna: %s" % (key, newdict[key])
                    else:
                        print "Antenna %s appears on a second pad: %s" % (key, newdict[key])
                    mydict[key].append(newdict[key])
    return mydict

def getAntennaPadsFromASDM(asdm, keyByPadName=False):
    """
    Returns a dictionary of antennas-pads association for that ASDM
    e.g.  {'DA41': 'S301'}
    keyByPadName: if True, the reverse the dictionary:  {'S301': 'DA41'}
    -Todd Hunter
    """
    pads = {}
    asdm = asdm.rstrip('/')
    antList = readAntennasFromASDM(asdm, verbose = False)
    antPos = readAntennaPositionFromASDM(asdm)
    if (antPos is None):
        mydict = au_noASDMLibrary.getAntennaPadsFromASDM_minidom(asdm)
        return mydict
    padPos = readStationFromASDM(asdm)
    for ant in antList:
        if (keyByPadName):
            pads[padPos[antPos[ant]['id']]['name']] = ant
        else:
            pads[ant]= padPos[antPos[ant]['id']]['name']
    return pads

def estimateSynthesizedBeamFromASDM(asdm, useL80method=True, verbose=False):
    """
    Estimates the synthesized beam from the L80 percentile length and
    representative frequency in an ASDM.
    useL80method: if True, use .574lambda/L80; if False, then use the max baseline
    -Todd Hunter
    """
    representativeFrequency = representativeFrequencyFromASDM(asdm,verbose=verbose)
    if representativeFrequency is None: return
    if useL80method:
        L80 = getBaselineStatsFromASDM(asdm, percentile=80, verbose=verbose)[-1] # meters
        arcsec = 3600*np.degrees(1)*0.574*c_mks/(representativeFrequency*1e9*L80)
    else:
        maxBaseline = getBaselineStatsFromASDM(asdm, verbose=False)[2] # meters
        arcsec = printBaselineAngularScale(maxBaseline, representativeFrequency)
    return arcsec

def estimateMRS(vis, field='', verbose=False):
    """
    Estimates the maximum recoverable scale (a.k.a. LAS) from the max baseline length and
    representative frequency (or mean of science spw frequencies) in a measurement set.
    field: if not blank, then find the first integration on the specified
           field ID or name, get its az&el and compute the projected baseline
           lengths rather than the unprojected baseline lengths
      Uses the ALMA Cycle-4 approved formula: 0.983*lambda/L5
    -Todd Hunter
    """
    result = getBaselineStats(vis, field=field, percentile=5, verbose=verbose)
    if (result is None): return
    L5 = result[0] # meters
    if os.path.exists(vis+'/ASDM_SBSUMMARY'):
        freqHz = representativeFrequency(vis, verbose=verbose) * 1e9
        print "Using representative frequency"
    else:
        freqHz = np.mean(getScienceFrequencies(vis)) 
        print "Using mean of the science spw mean frequencies."
    arcsec = 3600*np.degrees(1)*0.983*c_mks/(freqHz*L5)
    return arcsec

def estimateSynthesizedBeam(vis, field='', useL80method=True, verbose=False, 
                            spw=None, mymsmd=None):
    """
    Estimates the synthesized beam from the max baseline length and
    representative frequency in a measurement set.
    field: if not blank, then find the first integration on the specified
           field ID or name, get its az&el and compute the projected baseline
           lengths rather than the unprojected baseline lengths
    useL80method: if True, use .574lambda/L80; if False, then use the max baseline
    spw: if specified (string or int), then use its meanfreq instead of representative freq
    -Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    if useL80method:
        result = getBaselineStats(vis, field=field, percentile=80, verbose=verbose, mymsmd=mymsmd)
    else:
        result = getBaselineStats(vis, field=field, verbose=verbose)
    if (result is None): 
        if needToClose:
            mymsmd.close()
        return
    if useL80method:
        L80 = result[0] # meters
        if spw is None:
            repFreqGHz = representativeFrequency(vis,verbose=verbose)
        else:
            repFreqGHz = mymsmd.meanfreq(int(spw)) * 1e-9
        if repFreqGHz is None:
            print "There is no representative frequency. Using mean of science windows..."
            repFreqGHz = np.mean(getScienceFrequencies(vis, mymsmd=mymsmd)) * 1e-9
            print "which is %f GHz." % (repFreqGHz)
        arcsec = 3600*np.degrees(1)*0.574*c_mks/(repFreqGHz*1e9*L80)
    else:
        maxBaseline = result[2] # meters
        arcsec = printBaselineAngularScale(maxBaseline, representativeFrequency(vis,verbose=verbose))
    if needToClose:
        mymsmd.close()
    return arcsec

def makeFixephem(vis, scriptname='fixephem.py'):
    """
    Builds a script to fix the target measurement sets for multi-execution ephemeris
    projects of Cycle 3 and 4.  See CAS-8984.
    vis: a single measurement set, or a string with a wildcard ('*.ms')
    -Todd Hunter
    """
    if (vis.find('*') >= 0):
        vis = glob.glob(vis)[0]
        print "Using ", vis
    fieldnames = getEphemerisFields(vis)
    f = open(scriptname,'w')
    f.write('from recipes.ephemerides import concatephem\n')
    f.write('import glob\n')
    f.write("myvis = glob.glob('*target.ms')\n")
    f.write("concatephem.concatreplaceephem(vis=myvis, field='%s', commontime=True)\n" % fieldnames)
    f.close()

def makeFlagTemplateOutlierAntennas(asdms, templateType='targets', 
       requestedResolution=None, useUvrange=False, verbose=False):
    """
    Builds a flagtemplate file for the pipeline which flags outlier
    antennas.  If the file already exists, it will be appended to.
    asdms: a single ASDM, a list of ASDMs as a python list of strings, or as a
           single comma-delimited string
    templateType: '' or 'targets' 
                  '':  will produce <asdm>_flagtemplate.txt
           'targets':  will produce <asdm>_flagtargetstemplate.txt
    requestedResolution: if specified, then use this value to override what is
           in the ASDM (which in Cycle 3 was the range provided by the 
           configuration that the OT assigned to the SB, and in Cycle 4 is
           the PI requested value).
    useUvrange: if True, then produce a uvrange flag command instead of an
           an antenna name flag command.  This is not recommended as it can
           produce a sharp edge in the uv coverage which will cause ringing
           in the image plane.
    -Todd Hunter
    """
    if (type(asdms) != list):
        asdms = asdms.split(',')
    for asdm in asdms:
        if (not os.path.exists(asdm)):
            print "Could not find ASDM"
            return
        if (templateType not in ['','targets']):
            print "invalid templateType"
            return
        result = findOutlierAntennas(asdm, requestedResolution, returnSensitivityLoss=True)
        if result is None:  # resolution not found in ASDM
            return
        antennas, sensitivityLoss, maxuvdist = result
        if len(antennas) > 0:
            fname = os.path.basename(asdm) + '_flag%stemplate.txt' % (templateType)
            f = open(fname,'a')
            if (useUvrange):
                print "WARNING!: using a uvrange flag can result in a sharp edge in the uv coverage, which will produce ringing in the image domain."
                if (sensitivityLoss < 20):
                    print "    You should consider flagging by antenna because it will result in only %.1f%% loss in sensitivity." % (sensitivityLoss)
                myline = "mode='manual' uvrange='0~%d' reason='too_many_outlier_antennas'\n" % int(np.round(maxuvdist))
            else:
                myline = "mode='manual' antenna='%s' reason='outlier_antenna'\n" % ';'.join(antennas)
            f.write(myline)
            f.close()
            print "Wrote %s :" % fname
            print myline
        else:
            print "No outliers found in %s." % (asdm)

def findOutlierAntennas(asdm, requestedResolution=None, 
                        returnSensitivityLoss=False, verbose=False):
    """
    Finds outlier antennas in an ASDM by considering the requested
    angular resolution, representative frequency, and minimum elevation of
    the science targets.
    requestedResolution: if specified (in arcsec), then use this value instead
           of what is in the ASDM
    returnSensitivityLoss: if True, then also return the percentage loss in
           sensitivity and the desired max baseline (in meters)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM"
        return
    baseline = maxBaselineForRequestedResolutionFromASDM(asdm, requestedResolution)
    ignoreAntennas = []
    if baseline <= 0:
        if returnSensitivityLoss:
            return ignoreAntennas, 0.0, baseline
        else:
            return ignoreAntennas
    actualMaxBaseline = getBaselineStatsFromASDM(asdm)[2]
    print "Required max baseline: %.1fm.  Actual max baseline: %.1fm" % (baseline,actualMaxBaseline)
    mydict = getMedianBaselinePerAntenna(asdm, ignoreAntennas)
    idx = np.argsort(mydict.values())[::-1]
    antennaNames = np.array(mydict.keys())[idx]
    nAntennas = len(antennaNames)
    medianBaselines = np.array(mydict.values())[idx]
    while (medianBaselines[0] > baseline):
        ignoreAntennas.append(antennaNames[0])
        mydict = getMedianBaselinePerAntenna(asdm, ignoreAntennas)
        idx = np.argsort(mydict.values())[::-1]
        antennaNames = np.array(mydict.keys())[idx]
        medianBaselines = np.array(mydict.values())[idx]
        if verbose:
            print "Dropping %s, new max median baseline=%.1f" % (antennaNames[0],np.max(medianBaselines))
    keepAntennas = nAntennas - len(ignoreAntennas)
    baselinePercentage = 100*(1-keepAntennas*(keepAntennas-1)/(nAntennas*(nAntennas-1.0)))
    sensitivityLossPercentage = 100*(1-np.sqrt(keepAntennas*(keepAntennas-1)/(nAntennas*(nAntennas-1.0))))
    print "%d/%d antennas are outliers, representing %.1f%% of the baselines and %.1f%% of the sensitivity."  % (len(ignoreAntennas), nAntennas, baselinePercentage, sensitivityLossPercentage)
    if returnSensitivityLoss:
        return sorted(ignoreAntennas), sensitivityLossPercentage, baseline
    else:
        return sorted(ignoreAntennas)
        

def getExtremeBaselinePerAntenna(asdm, statistic, ignoreAntennas=[], percentile=0, sort=False):
    """
    Compute the statistcal extreme baseline length per antenna of the specified ASDM.
    statistic: 'median', 'min', 'max', 'mean', or 'std'
    percentile: only return antennas whose median is > L(percentile,e.g. 80) of the array
    sort: if True, then sort by statistic rather than by antenna name
    Returns: a dictionary keyed by antenna name (if sort=False)
              otherwise, a list of tuples [('name', length)...]
    """
    medians = {}
    antList = readAntennasFromASDM(asdm, verbose = False)
    antPos = readAntennaPositionFromASDM(asdm)
    padPos = readStationFromASDM(asdm)
    if (percentile > 0):
        L80 = getBaselineStatsFromASDM(asdm, percentile=percentile, verbose=False)[-1]
        print "L80 = ", L80
    else:
        L80 = 0
    for ant in antList:
        if (ant in ignoreAntennas): continue
        lengths = []
        for ant2 in antList:
            if (ant2 in ignoreAntennas): continue
            if (ant2 != ant):
                lengths.append(computeBaselineLength(padPos[antPos[ant]['id']]['position'], 
                                                     padPos[antPos[ant2]['id']]['position']))
        if (statistic == 'median'):
            mymedian = np.median(lengths)
        elif (statistic == 'min'):
            mymedian = np.min(lengths)
        elif (statistic == 'max'):
            mymedian = np.max(lengths)
        elif (statistic == 'mean'):
            mymedian = np.mean(lengths)
        elif (statistic == 'std'):
            mymedian = np.std(lengths)
        else:
            print "Statistic must be one of: 'median', 'min', 'max', 'mean', 'std'"
            return
        if (mymedian > L80):
            medians[ant] = mymedian
    if sort:
        medians = sorted(medians.items(), key=operator.itemgetter(1))
    return medians

def getMedianBaselinePerAntenna(asdm, ignoreAntennas=[], percentile=0, sort=False):
    """
    Compute median baseline length per antenna of the specified ASDM.
    percentile: only return antennas whose median is > L80 of the array
    sort: if True, then sort by statistic rather than by antenna name
    Returns: a dictionary keyed by antenna name (if sort=False)
           otherwise, a list of tuples [('name', length)...]
    """
    if (not os.path.exists(asdm+'/Antenna.xml')):
        print "Could not find Antenna.xml."
        return
    return(getExtremeBaselinePerAntenna(asdm, 'median', ignoreAntennas, percentile, sort))

def getBaselineStatsFromASDM(asdm, percentile=None, verbose=False): 
    """
    Compute statistics on the baseline lengths of the specified ASDM.
    Returns: a list of: number, min, max, median, mean, st.dev, 20%ile, 
             25%ile, 30%ile, 75%ile, 90%ile
    If percentile is specified, then it is appended to the returned list.
    """
    if (not os.path.exists(asdm+'/Antenna.xml')):
        print "Could not find Antenna.xml."
        return
    antList = readAntennasFromASDM(asdm, verbose = False)
    antPos = readAntennaPositionFromASDM(asdm)
    padPos = readStationFromASDM(asdm)
    lengths = []
    for ant in antList:
        for ant2 in antList:
            if (ant2 > ant):
                lengths.append(computeBaselineLength(padPos[antPos[ant]['id']]['position'], 
                                                     padPos[antPos[ant2]['id']]['position']))
    twenty = scoreatpercentile(lengths, 20)    
    twentyfive = scoreatpercentile(lengths, 25)    
    thirty = scoreatpercentile(lengths, 30)    
    seventyfive = scoreatpercentile(lengths, 75)
    ninety = scoreatpercentile(lengths, 90)
    number = len(lengths)
    mylist = [number,np.min(lengths),np.max(lengths),np.median(lengths),
           np.mean(lengths), np.std(lengths),twenty,twentyfive,thirty,
           seventyfive,ninety]
    if (percentile is not None):
        value = scoreatpercentile(lengths, percentile)
        if verbose: print "%.0f percentile baseline length is %f m" % (percentile, value)
        mylist += [value]
    return(mylist)

def getBaselineLengthsFromASDM(asdm, refAnt):
    """
    returns a dictionary of antennas, baseline length from all antennas to
    refAnt.
    refAnt is either antenna name or a weather station name: WSTB1, WSTB2
    """
    bl = {}
    antList = readAntennasFromASDM(asdm, verbose = False)
    antPos = readAntennaPositionFromASDM(asdm)
    if (antPos == None): return
    padPos = readStationFromASDM(asdm)
    if refAnt.startswith('WSTB1'):
        [key for key,val in padPos.items() if val['name']==refAnt]
        refAntPos = padPos[key]['position']
    else:
        refAntPos = padPos[antPos[refAnt]['id']]['position']
    for ant in antList:
        bl[ant]= computeBaselineLength(padPos[antPos[ant]['id']]['position'], refAntPos)
        #print ant, int(bl[ant]*100)/100.
    return bl

def getBaselineHeightFromASDM(asdm, refAnt, verbose=True):
    hDiff = {}
    antList = readAntennasFromASDM(asdm, verbose = False)
    antPos = readAntennaPositionFromASDM(asdm)
    padPos = readStationFromASDM(asdm)
    if refAnt.startswith('WSTB1'):
        [key for key,val in padPos.items() if val['name']==refAnt]
        refAntPos = padPos[key]['position']
    else:
        refAntPos = padPos[antPos[refAnt]['id']]['position']
    for ant in antList:
        hDiff[ant]= computeBaselineHeightDiff(padPos[antPos[ant]['id']]['position'], refAntPos)
        if verbose == True: print '%s, %7.2f'%(ant, hDiff[ant])
    return hDiff
    
def printSwVersionFromASDM(asdm):
    """
    Reads and prints the contents of the ASDM's Annotation.xml table.
    -Denis Barkats and Todd Hunter
    """
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine. Using the minidom code instead."
        return(au_noASDMLibrary.readSoftwareVersionFromASDM_minidom(asdm))
    a = ASDM()
    a.setFromFile(asdm,True)
    at = a.annotationTable().get()
    print '\n### Annotation table for ASDM: %s contains sw version, atm delayModel... ### \n' %asdm
    for row in at:
        print "%s: %s" %(row.issue(),row.details())

    print "\n####"
    return

def plotDecorrelation(asdm, scan=[], ylim=[0,1], plotfile='', doplot=True,
                      baseband=0, field=-1, corrected=False):
    """
    Plots decorrelation vs. baseline length from the CalPhase.xml file.
    baseband: 0 means all, otherwise 1,2,3, or 4
    field: which field to plot (-1 means all)
           This will be used to find the list of scans to plot.
    corrected: if True, show AP_CORRECTED data, otherwise AP_UNCORRECTED
    Returns:
    The median decorrelation over all measurements.
    -Todd Hunter
    """
    mydict = readDecorrelationFromASDM(asdm)
    scandict = readscans(asdm)[0]  # each entry contains key='source' with value=fieldname
    fielddict, fieldnamedict = getFieldsFromASDM(asdm) # [1]: key=fieldname, value=fieldid
    for i in scandict.keys():
        scandict[i]['fieldid'] = fieldnamedict[scandict[i]['source']]
    uniqueFieldIDs = fielddict.keys()
    scansforfields = {}
    for f in uniqueFieldIDs:
        scansforfields[f] = []
        for i in scandict.keys():
            if scandict[i]['fieldid'] == f:
                scansforfields[f].append(i)
    if (field != -1 and field not in uniqueFieldIDs):
        print "Field %s is not in the xml file." % (str(field))
        return
    asdm = asdm.rstrip('/')
    if (mydict == None): return
    if (doplot):
        pb.clf()
    if (scan == []):
        scan = range(len(mydict['baselineLengths']))
    medianDecorrelation = []
    elevation = []
    measurements = 0
    pb.hold(True)
    for s in scan:
        if ((corrected and mydict['atmPhaseCorrection'][s] == 'AP_CORRECTED') or
            (not corrected and mydict['atmPhaseCorrection'][s] == 'AP_UNCORRECTED')):
            if (baseband == 0 or baseband == int(mydict['basebandName'][s].split('_')[1])):
                if (field==-1 or s in scansforfields[field]):
                    measurements += 1
                    medianDecorrelation.append(mydict['decorrelationFactor'][s])
                    elevation.append(mydict['elevation'][s])
                    if (doplot):
                        length = len(mydict['decorrelationFactor'][s])
                        numReceptor = mydict['numReceptor'][s]
                        for r in range(numReceptor):
                            # plot the individual pols
                            pb.plot(mydict['baselineLengths'][s],
                                    np.array(mydict['decorrelationFactor'][s])[range(r,length,numReceptor)],
                                    'o',color=overlayColors[r])
    print "Processed %d measurements" % (measurements)
    if doplot:
        pb.xlabel('Baseline length (m)')
        pb.ylabel('Decorrelation')
        if (ylim != [0,0]):
            pb.ylim(ylim)
        if baseband==0:
            basebands = 'all basebands'
        else:
            basebands = 'baseband ' + str(baseband)
        elevationString = 'elev %.0f-%.0f' % (np.min(elevation),np.max(elevation))
        pb.title(os.path.basename(asdm) + '  (%s, %s)' % (basebands,elevationString))
        pb.draw()
        if (plotfile != ''):
            if plotfile==True:
                plotfile = asdm.rstrip('/') + '.decorrelation.png'
            pb.savefig(plotfile)
            print "Plot saved in ", plotfile
    if (measurements > 0):
        medianDecorrelation = np.median(medianDecorrelation)
    else:
        medianDecorrelation = 0
    return(medianDecorrelation)
    
def readDecorrelationFromASDM(asdm):
    """
    This function reads the decorrelation information from the CalPhase.xml file.
    Returns a dictionary with keys:
    'baselineLengths
    'decorrelationFactor'
    'startValidTime'
    'endValidTime'
    'atmPhaseCorrection'
    -Todd Hunter
    """
    import au_noASDMLibrary
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine. Using minidom instead."
        mydict = au_noASDMLibrary.readDecorrelationFromASDM_minidom(asdm)
    else:
        print "A version using ASDM bindings library has not yet been written.  Using minidom instead."
        mydict = au_noASDMLibrary.readDecorrelationFromASDM_minidom(asdm)
    # insert scan number into dictionary
    scandict = readCalDataFromASDM(asdm)
    mydict['scan'] = mydict['calDataId']
    for i in range(len(mydict['calDataId'])):
        mydict['scan'][i] = scandict[mydict['calDataId'][i]]['scan']
    return(mydict)

def plotSeeing(asdm, plotfile=''):
    """
    Reads and plots the seeing from the CalPhase.xml file of an ASDM.
    -Todd Hunter
    """
    mydict = readSeeingFromASDM(asdm)
    pb.clf()
    adesc = pb.subplot(111)
    c = {'AP_UNCORRECTED': 'r', 'AP_CORRECTED': 'g'}
    nMeasurements = len(mydict['atmPhaseCorrection'])
    x = []
    y = []
    for n in range(nMeasurements):
        x.append(mydict['startValidTime'][n]*1e-9)
        y.append(mydict['seeing'][n])
    print "len(x)=%d, min(x)=%f, max(x)=%f, median=%f" % (len(x), np.min(x), np.max(x), np.median(x))
#    list_of_date_times = mjdSecondsListToDateTime(x)
#    timeplot = pb.date2num(list_of_date_times)
#    pb.plot_date(timeplot, y, 'o', color = c[mydict['atmPhaseCorrection'][n]])
    pb.plot(x-np.min(x), y, 'o', color = c[mydict['atmPhaseCorrection'][n]])
    x0,x1 = pb.xlim()
    print "x0=%f, x1=%f" % (x0,x1)
    pb.xlim([x0-5, x1+5])
    pb.xlabel('Time')
    ymin,ymax = pb.ylim()
    pb.ylim([0,ymax])
    pb.ylabel('Seeing (arcsec)')
    pb.title(asdm)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = asdm + '.seeing.png'
        pb.savefig(plotfile)
        print "Plot left in ", plotfile
        
def readSeeingFromASDM(asdm):
    """
    This function reads the seeing information from the CalSeeing.xml file.
    Returns a dictionary with the following keys:
    atmPhaseCorrection: AP_UNCORRECTED or AP_CORRECTED
    baselineLengths: typically 3 values (in meters)
    startValidTime: MJD nano seconds
    endValidTime: MJD nano seconds
    phaseRMS:  a value for each baselineLength (radians?) for each timestamp
    seeing: one value per timestamp (arcseconds)
    - thunter
    """
    import au_noASDMLibrary
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine. Using minidom instead."
        mydict = au_noASDMLibrary.readSeeingFromASDM_minidom(asdm)
        return(mydict)
    print "A version using ASDM bindings library has not yet been written.  Using minidom instead."
    mydict = au_noASDMLibrary.readSeeingFromASDM_minidom(asdm)
    return(mydict)

def getPolarizationsFromASDM(asdm):
    """
    Reads the Polarization.xml file of an ASDM and reports the number of
    polarization products in each polarization ID.
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    xmlscans = minidom.parse(asdm+'/Polarization.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    mydict = {}
    for rownode in rowlist:
        rowscan = rownode.getElementsByTagName("numCorr")
        tokens = rowscan[0].childNodes[0].nodeValue.split()
        numCorr = int(tokens[0])
        rowscan = rownode.getElementsByTagName("corrType")
        tokens = rowscan[0].childNodes[0].nodeValue.split()
        corrTypes = [str(i) for i in tokens[2:]]
        rowcaldataid = rownode.getElementsByTagName("polarizationId")
        polarizationId = int(str(rowcaldataid[0].childNodes[0].nodeValue).split('_')[1])
        mydict[polarizationId] =  {'numCorr': numCorr, 'corrTypes': corrTypes}
    return(mydict)

def wvrdata(asdm):
    """
    Checks whether a dataset contains WVR corrected data or not, or both.
    Returns: a tuple of two Booleans (uncorrected present and corrected present)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    corrected = False
    uncorrected = False
    for line in open(asdm+'/CalPhase.xml'):
        if 'AP_CORRECT' in line:
            corrected = True
        elif 'AP_UNCORRECT' in line:
            uncorrected = True
    if (uncorrected and not corrected):
        print "This ASDM contains only WVR-uncorrected data."
    elif (corrected and not uncorrected):
        print "This ASDM contains only WVR-corrected data."
    else:
        print "This ASDM contains both WVR-uncorrected and corrected data."
    return(uncorrected, corrected)

def printFluxesFromASDM(sdmfile, sourcename='', field=-1, useCalFlux=False, spw=-1, 
                        asdmspw=-1, showCenterFreqs=False, fluxprec=4, freqprec=1,
                        scienceSpws=False):
    """
    Calls readFluxesFromASDM, organizes the output and prints it to
    the screen.  Normally this function will read from the Source.xml table,
    but setting useCalFlux=True will force it to read from CalFlux.xml.
    spw: if specified, (or if neither spw nor asdmspw are specified), then 
         the spw numbers will be assumed to be ms spws numbers,
         they will be mapped to ASDM spw numbers to retrieve the flux value
    asdmspw: if specified, the spw numbers will be assumed to be ASDM spw 
             numbers
    fluxprec: precision of frequency display (3 = 1mJy etc.)
    freqprec: precision of frequency display (1 = 0.1 Hz, 2 = 0.01 Hz, etc.)
    -Todd Hunter
    """
    result = readFluxesFromASDM(sdmfile, sourcename, field, useCalFlux)
    if (result == None):
        print "readFluxesFromASDM returns None"
        return
    spwmap = asdmspwmap(sdmfile)
    if (scienceSpws):
        spw = getScienceSpwsFromASDM(sdmfile)
    if (((spw == -1 or spw=='') and (asdmspw == -1 or asdmspw=='')) or (spw != -1)):
        if (spw == -1 or spw == '') and (asdmspw == -1 or asdmspw == ''):
            # Make a list of all ms spws
            spw = range(len(spwmap))
        if (type(spw) == list):
            spwlist = spw
        elif (type(spw) == str):
            spwlist = [int(n) for n in spw.split(',')]
        else:
            spwlist = [spw]
        asdm_spwlist = []
        for spw in spwlist:
            asdm_spwlist.append(spwmap[spw])
        spwlist = asdm_spwlist
    else:
        # Make a list of all asdm spws
        if (type(asdmspw) == list):
            spwlist = asdmspw
        elif (type(asdmspw) == str):
            spwlist = [int(n) for n in asdmspw.split(',')]
        else:
            spwlist = [asdmspw]

    mylist, mydict = result
    if (mylist == []): return
    srcName = mydict.keys()[0]
    stokes = ''
    stokesParameters = mydict[srcName][0]['stokesParameters']
    for sp in stokesParameters:
        stokes += sp + ' '
    intents = getIntentsFromASDM(sdmfile,stripPrefix=True)
    for source in mydict.keys():
        if (source in intents.keys()):
            print "%s intents = %s" % (source, intents[source])
    if ('frequency' in mydict[srcName][0].keys()):
        print "Sourcename    spw     Freq(GHz)  Flux densities (%s)" % (stokes)
        if showCenterFreqs:
            print "           ASDM  ms  FreqOfFlux" + 4*(fluxprec-3)*' ' + freqprec*' ' + "                                  CenterFreq      Difference"
        else:
            print "           ASDM  ms  FreqOfFlux"
    else:
        print "Sourcename  Freq(GHz)  Flux densities (%s)" % (stokes)
    if showCenterFreqs:
        centerFreq = getFrequenciesFromASDM(sdmfile, minnumchan=1)
    for source in mydict.keys():
        for entry in mydict[source]:
          if (entry['spw'] in spwlist or spwlist == [-1]):
            if ('frequency' in entry.keys()):
                for f in range(len(entry['frequency'])):
                    if (entry['spw'] in spwmap):
                        spw_in_ms = spwmap.index(entry['spw'])
                    else:
                        spw_in_ms = ' n/a'
                    line = "%s %3d %4s  " % (source, entry['spw'], spw_in_ms)
                    freq = entry['frequency'][f]
                    line +=  '%.*f  ' % (freqprec, freq)
                    for stokes in range(len(entry['stokesParameters'])):
                        line +=  '%.*f  ' % (fluxprec, entry['fluxDensity'][f][stokes])
                    if showCenterFreqs:
                        line +=  '%.*f %*.*f ' % (freqprec, centerFreq[spw_in_ms], freqprec+13, freqprec, freq-centerFreq[spw_in_ms])
                    print line
            else:  # These results are from the CalFlux.xml file
                for f in range(len(entry['frequencyRange'])):
                    line = "%s  " % (source)
                    freq = entry['frequencyRange'][f]
                    line +=  '%.*f-%.*f  ' % (freqprec, freq[0], freqprec, freq[1])
                    for stokes in range(len(entry['stokesParameters'])):
                        print "entry['fluxDensity'][f] = ", entry['fluxDensity'][f]
                        print "stokes = ", stokes
                        line +=  '%.*f  ' % (fluxprec,entry['fluxDensity'][f][stokes])
                    print line

def checkScienceSpwsFromASDM(dir='./', ignore='.ms'):
    """
    For all ASDMs in the specified directory, get the
    science spws and report any differences in ID number.
    dir: comma-delimited list of directories, wildcard string, or 
         list of directories
    -Todd Hunter
    """
    if type(dir) == str:
        if (dir.find('*')>=0):
            dirs = glob.glob(dir)
        else:
            dirs = dir.split(',')
    else:
        dirs = dir
    if dirs[0][:6] == 'uid___':
        vis = dirs
        dirs = ['./']
    else:
        vis = ''
    print "Processing directories: ", dirs
    for dir in dirs:
        print dir+":"
        if vis == '':
            vis = glob.glob(dir+'/uid___*')
        if (len(ignore) > 0):
            tvis = glob.glob(dir+'/*%s*'%(ignore))
            vis = list(set(vis) - set(tvis))
        if (len(vis) < 2):
            print "    Only %d ASDM found" % (len(vis))
            continue
        spws = getScienceSpwsFromASDM(vis[0])
        print "%s: %s" % (os.path.basename(vis[0]),spws)
        difference = False
        for v in vis[1:]:
            newspws = getScienceSpwsFromASDM(v)
            print "%s: %s" % (os.path.basename(v),newspws)
            if spws != newspws:
                difference = True
                print "   Difference!"
    return difference

def getScienceSpwsFromASDM(asdm):
    """
    Gets the spw IDs for the science target spws in an ASDM.  Single-channel spws are
    ignored.  The IDs are those that will appear in a measurement set once it is imported.
    It determines science spws by the presence of the "velRefCode" tag.
    -Todd Hunter
    """
    xmlscans = minidom.parse(asdm+'/Source.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    scienceSpwsASDM = []
    for rownode in rowlist:
        row = rownode.getElementsByTagName("velRefCode")
        if (len(row) > 0):
            velRefCode = str(row[0].childNodes[0].nodeValue)
            row = rownode.getElementsByTagName("spectralWindowId")
            spw = int(str(row[0].childNodes[0].nodeValue).split('_')[1])
            scienceSpwsASDM.append(spw)
    scienceSpwsASDM = np.unique(scienceSpwsASDM)
    spwmap = asdmspwmap(asdm)
    scienceSpws = []
    mydict = getSpwsFromASDM(asdm)
    for spw in scienceSpwsASDM:
        myspw = spwmap.index(spw)
        if mydict[myspw]['numChan'] > 1:
            scienceSpws.append(myspw)
    return scienceSpws

def readFluxesFromASDM(sdmfile, sourcename='', field=-1, useCalFlux=False, spw=-1):
    """
    Read the flux densities from an ASDM.  If useCalFlux=False,
    look for fluxes in the Source.xml table, otherwise, look in CalFlux.xml.
    Returns a raw list of dictionaries (one per row) and a dictionary of
    the information keyed by the field name. Specify a sourcename or
    field ID to limit the results to a specific source. Inserting the
    wildcard character (*) into sourcename will return partial matches.
            {'sourceName': sourceName, 'stokes': stokesParameters,
            'frequencyRange': frequency, 'fluxDensity': fluxDensity,
            'fluxDensityError': fluxDensityError}
    - Todd Hunter
    """
    if (type(spw) != list):
        if (type(spw) == string):
            spw = [int(a) for a in spw.split(',')]
        else:
            spw = [spw]
    if (os.path.exists(sdmfile) == False):
        print "readFluxesFromASDM(): Could not find file = ", sdmfile
        return(None)
    if (useCalFlux):
        calflux = sdmfile + '/CalFlux.xml'
        if (os.path.exists(calflux) == False):
            print "readFluxesFromASDM(): Could not find file = ", calflux
            print "Looking for Source.xml instead"
            sourcefile = sdmfile + '/Source.xml'
            if (os.path.exists(sourcefile) == False):
                print "readFluxesFromASDM(): Could not find file = ", sourcefile
                return(None)
            useCalFlux = False
    else:
        sourcefile = sdmfile + '/Source.xml'
        if (os.path.exists(sourcefile) == False):
            print "readFluxesFromASDM(): Could not find file = ", sourcefile
            return(None)
    scandict = {}
    fid = 0
    sources = []
    myspw = ''
    sourceid=''
    if (useCalFlux == False):   # Source.xml
        sourcesIdentified = {}
        noFrequencyKeywords = True
        xmlscans = minidom.parse(sourcefile)
        rowlist = xmlscans.getElementsByTagName("row")
        for rownode in rowlist:
            scandict[fid] = {}
            row = rownode.getElementsByTagName("sourceId")
            sourceId = int(str(row[0].childNodes[0].nodeValue))
            if (sourceid != '' and sourceid != sourceId): continue
            row = rownode.getElementsByTagName("sourceName")
            sourceName = str(row[0].childNodes[0].nodeValue).strip(' ')
            if sourceId not in sourcesIdentified:
                sourcesIdentified[sourceId] = [sourceName]
            elif sourceName not in sourcesIdentified[sourceId]:
                print "WARNING: There is a mismatch in the sourceID/sourceName. ID%d has multiple names: " % (sourceId), sourceName, sourcesIdentified[sourceId]
                sourcesIdentified[sourceId].append(sourceName)
            if (sourcename != ''):
                if (sourcename.find('*') >= 0):
                    if (sourceName.find(sourcename.replace('*','')) < 0): continue
                else:
                    if (sourceName != sourcename):
                        continue
            elif (int(field) != -1):
                if (sourceId != int(field)):
                    continue
                
            row = rownode.getElementsByTagName("spectralWindowId")
            spectralWindowId = int(str(row[0].childNodes[0].nodeValue).split('_')[-1])
            if (myspw != '' and myspw != spectralWindowId): continue
            row = rownode.getElementsByTagName("frequency")
            if (row == []):
                continue
            noFrequencyKeywords = False
            r = filter(None, (row[0].childNodes[0].nodeValue).split(' '))
            frequency = []
            for freq in r[2:]:
                frequency.append(float(freq))
            row = rownode.getElementsByTagName("stokesParameter")
            r = filter(None,str(row[0].childNodes[0].nodeValue).split(' '))
            stokesParameters = []
            for stokes in r[2:]:
                stokesParameters.append(stokes)
            row = rownode.getElementsByTagName("flux")
            r = filter(None,(row[0].childNodes[0].nodeValue).split(' '))
            nflux = int(r[1])
            fluxDensity = []
            for flux in range(nflux):
                stokesFlux = []
                for stokes in range(len(stokesParameters)):
                    stokesFlux.append(float(r[3+stokes+flux*len(stokesParameters)]))
                fluxDensity.append(stokesFlux)
            if (spectralWindowId in spw or spw==[-1]):
                sources.append({'sourceId': sourceId, 'sourceName': sourceName,
                                'spw': spectralWindowId,
                                'stokesParameters': stokesParameters,
                                'frequency': frequency, 'fluxDensity': fluxDensity})
                fid +=1
    else:
        # still working on this
        xmlscans = minidom.parse(calflux)
        rowlist = xmlscans.getElementsByTagName("row")
        for rownode in rowlist:
            scandict[fid] = {}
            row = rownode.getElementsByTagName("sourceName")
            sourceName = str(row[0].childNodes[0].nodeValue)
            if (sourcename != ''):
                if (sourcename.find('*') >= 0):
                    if (sourceName.find(sourcename.replace('*','')) < 0): continue
                else:
                    if (sourceName != sourcename):
                        continue
            row = rownode.getElementsByTagName("frequencyRanges")
            if (row == []):
                continue
            r = filter(None, (row[0].childNodes[0].nodeValue).split(' '))
            frequency = []
            for freq in range(3,len(r)-1,2):
                frequency.append([float(r[freq])*1.0e-9, float(r[freq+1])*1.0e-9])
            row = rownode.getElementsByTagName("stokes")
            r = filter(None,str(row[0].childNodes[0].nodeValue).split(' '))
            stokesParameters = []
            for stokes in r[2:]:
                stokesParameters.append(stokes)
            row = rownode.getElementsByTagName("flux")
            r = filter(None,(row[0].childNodes[0].nodeValue).split(' '))
            rowerror = rownode.getElementsByTagName("fluxError")
            rerror = filter(None,(rowerror[0].childNodes[0].nodeValue).split(' '))
            nflux = int(r[1])
            fluxDensity = []
            fluxDensityError = []
            for flux in range(nflux):
                stokesFlux = []
                errorFlux = []
                for stokes in range(len(stokesParameters)):
                    stokesFlux.append(float(r[3+stokes+flux*len(stokesParameters)]))
                    errorFlux.append(float(rerror[3+stokes+flux*len(stokesParameters)]))
                fluxDensity.append(stokesFlux)
                fluxDensityError.append(errorFlux)
            sources.append({'sourceName': sourceName, 'stokes': stokesParameters,
                            'frequencyRange': frequency, 'fluxDensity': fluxDensity,
                            'fluxDensityError':fluxDensityError})
            fid +=1
    mydict = {}
    for src in sources:
        if (src['sourceName'] not in mydict.keys()):
            mydict[src['sourceName']] = []
        if (useCalFlux == False):
            subdict = {'fluxDensity': src['fluxDensity'], 'frequency': src['frequency'], 'spw': src['spw'],
                       'stokesParameters': src['stokesParameters']}
        else:
            subdict = {'fluxDensity': src['fluxDensity'], 'frequencyRange': src['frequencyRange'],
                       'stokesParameters': src['stokes']}
        mydict[src['sourceName']].append(subdict)
    if (useCalFlux == False and noFrequencyKeywords):
        print "No frequency keywords found in the Source.xml file. Try setting useCalFlux=True."
    return(sources, mydict)


def getWeatherFromASDM(sdmfile='',verbose=False, station='WSTB1'):
    """
    Reads the weather table in the ASDM.
    Inputs:
    station:  name of station, default = WSTB1
    Returns three things:
    * a list of value arrays
       0=timeInterval, 1=pressure, 2=relHumidity, 3=temperature,
       4=windDirection, 5=windSpeed, 6=windMax, 7=station
    * a dictionary of the median values
    * the weather station name
    - T. Hunter
    """
    scandict = readWeatherFromASDM(sdmfile)
    if (scandict == None):
        return({},{},'')
    if (verbose):
        print "len(scandict) = ", len(scandict)
    mydict = getWeatherStationNamesFromASDM(sdmfile)
    found = False
    for stationid in mydict.keys():
        if (mydict[stationid] == station):
            found = True
            break
    if (not found):
        print "Station %s is not in the dataset. Available stations: " % (station), getWeatherStationNamesFromASDM(sdmfile)
        return
    stationName = station
    d1 = ReadWeatherStation(scandict, station=stationid)
    medians = {}
    if (len(d1[0]) < 1):
        print "No data found from any stations"
        return(d1,medians,'')

    timeInterval, pressure, relHumidity, temperature, windDirection, windSpeed, windMax, station = d1
    medians['pressure'] = np.median(pressure)
    medians['humidity'] = np.median(relHumidity)
    medians['temperature'] = np.median(temperature)
    sinWindDirection = np.sin(np.array(windDirection)*np.pi/180)
    cosWindDirection = np.cos(np.array(windDirection)*np.pi/180)
    medians['windDirection'] = (180./np.pi)*np.arctan2(np.mean(sinWindDirection),
                                                  np.mean(cosWindDirection))
    if (medians['windDirection'] < 0):
        medians['windDirection'] += 360
    medians['windSpeed'] = np.median(windSpeed)
    medians['windMax'] = np.max(windMax)
    return(d1,medians,stationName)

def readWeatherFromASDM(sdmfile, station=16):
    """
    Reads the weather table in the ASDM, and returns a dictionary containing:
    timeInterval, pressure, relHumidity, temperature, windDirection, windSpeed,
    windMax and stationId.
    - T. Hunter
    """
    if (os.path.exists(sdmfile) == False):
        print "readWeatherFromASDM(): Could not find file = ", sdmfile
        return(None)
    xmlscans = minidom.parse(sdmfile+'/Weather.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        scandict[fid] = {}
        row = rownode.getElementsByTagName("timeInterval")
        tokens = row[0].childNodes[0].nodeValue.split()
        scandict[fid]['timeInterval'] = float(tokens[0])*1e-9  # MJD seconds
        row = rownode.getElementsByTagName("pressure")
        scandict[fid]['pressure'] = float(row[0].childNodes[0].nodeValue)*0.01 # mbar
        row = rownode.getElementsByTagName("relHumidity")
        scandict[fid]['relHumidity'] = float(row[0].childNodes[0].nodeValue)
        row = rownode.getElementsByTagName("temperature")
        scandict[fid]['temperature'] = float(row[0].childNodes[0].nodeValue)
        row = rownode.getElementsByTagName("windDirection")
        scandict[fid]['windDirection'] = float(row[0].childNodes[0].nodeValue)*180/math.pi  # degrees
        row = rownode.getElementsByTagName("windSpeed")
        scandict[fid]['windSpeed'] = float(row[0].childNodes[0].nodeValue)
        row = rownode.getElementsByTagName("windMax")
        scandict[fid]['windMax'] = float(row[0].childNodes[0].nodeValue)
        row = rownode.getElementsByTagName("stationId")
        scandict[fid]['stationId'] = int((str(row[0].childNodes[0].nodeValue)).split('_')[1])
        fid += 1
    return scandict

def readFeedFromASDM(asdm):
    """
    Reads the Feed.xml from the ASDM, and returns a list of unique time values.
    - T. Hunter
    """
    if (not os.path.exists(asdm)):
        print "readFeedFromASDM(): Could not find file = ", asdm
        return(None)
    xmlscans = minidom.parse(asdm+'/Feed.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    values0 = []
    values1 = []
    for rownode in rowlist:
        row = rownode.getElementsByTagName("timeInterval")
        tokens = row[0].childNodes[0].nodeValue.split()
        values0.append(float(tokens[0])*1e-9)
        values1.append(float(tokens[1])*1e-9)
    values0 = np.unique(values0)
    values1 = np.unique(values1)
    for i,value in enumerate(values0):
        print "%f = %s" % (values0[i], mjdSecondsToMJDandUT(values0[i]))
        print "%f = %s" % (values1[i], mjdSecondsToMJDandUT(values1[i]))
    return(values0,values1)


def readStationsFromASDM(sdmfile):
    """
    Similar to readStationFromASDM, but returns different format dictionary
    {'J503': [x,y,z], 'N605': etc.}
    -Todd Hunter
    """
    if (asdmLibraryAvailable == False):
        mydict = au_noASDMLibrary.readStationsFromASDM_minidom(sdmfile)
    else:
        mydict = readStationFromASDM(sdmfile)
        newdict = {}
        for station in mydict.keys():
            name = mydict[station]['name']
            position = mydict[station]['position']
            newdict[name] = position
        mydict = newdict
    return(mydict)

def readAntennasFromASDM(sdmfile, stations=False, diameters=False, 
                         verbose=True):
    """
    Reads the list of antenna names from the ASDM.
    stations: if True, also return the (zero-based integer) station IDs in a second integer list
    diameters: if True, also return the dish diameters in a second (or third) integer list
    - D Barkats
    """
    xmlscans = minidom.parse(sdmfile+'/Antenna.xml')
    antList = []
    stationList = []
    dishDiameterList = []
    rowlist = xmlscans.getElementsByTagName("row")
    for rownode in rowlist:
        row = rownode.getElementsByTagName("name")
        tokens = row[0].childNodes[0].nodeValue.split()
        antList.append(str(tokens[0]))
        if (stations):
            row = rownode.getElementsByTagName("stationId")
            tokens = row[0].childNodes[0].nodeValue.split()
            stationList.append(int(str(tokens[0]).split('_')[1]))
        if (diameters):
            row = rownode.getElementsByTagName("dishDiameter")
            tokens = row[0].childNodes[0].nodeValue.split()
            dishDiameterList.append(float(str(tokens[0])))
    if verbose == True:
        print '%s'%', '.join(map(str, antList))
    if (stations and diameters):
        return antList, stationList, dishDiameterList
    elif (stations):
        return antList, stationList
    elif (diameters):
        return antList, dishDiameterList
    else:
        return antList

def getWeather(vis, scan='', antenna='0',verbose=False, vm=0, mymsmd='',debug=False, obsid=0,
               preferredStation='TB2'):
    """
    Queries the WEATHER and ANTENNA tables of an .ms by scan number or
    list of scan numbers in order to return a dictionary.
    Inputs:
    * antenna: name string, ID string or integer ID
    * preferredStation: minimum match, i.e. 'TB2' or 'MeteoTB2'
    Returns:
    * a dictionary of mean values of: angleToSun,
      pressure, temperature, humidity, dew point, wind speed, wind direction,
      azimuth, elevation, solarangle, solarelev, solarazim.
    * a list of science data timestamps in MJD seconds (not weather data times!)
    * zero, or the ValueMapping object
    If the sun is below the horizon, the solarangle returns is negated.
    If run in casa 4.4 or 4.5, and a concatenated measurement set is used, then the
       obsid must be specified for the desired scan, due to a change in msmd.  This
       behavior is fixed in casa 4.6.
    If run in casa < 4.1.0, this function needs to run ValueMapping, unless
    a ValueMapping object is passed via the vm argument. Otherwise it will
    run mymsmd.open, unless an msmd tool is passed via the mymsmd argument.
    -- Todd Hunter
    """
    if (debug):
        print "Entered getWeather with vis,scan,antenna = ", vis, ",", scan, ",", antenna
    if (os.path.exists(vis) == False):
        print "au.getWeather(): Measurement set not found"
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    try:
        antennaNames = getAntennaNames(vis)
        if str(antenna).isdigit():
            antennaName = antennaNames[int(str(antenna))]
        else:
            antennaName = antenna
            try:
                antenna = getAntennaIndex(vis,antennaName)
            except:
                antennaName = string.upper(antenna)
                antenna = getAntennaIndex(vis,antennaName)
    except:
        print "Either the ANTENNA table does not exist or antenna %s does not exist" % (antenna)
        return([0,[],vm])
    mytb = createCasaTool(tbtool)
    try:
        mytb.open("%s/POINTING" % vis)
    except:
        print "POINTING table does not exist"
        return([0,0,vm])
    subtable = mytb.query("ANTENNA_ID == %s" % antenna)
    mytb.close()
    needToClose_mymsmd = False
    if (vm == 0 or vm==''):
        if (casadef.casa_version < casaVersionWithMSMD):
            print "getWeather: Running ValueMapping... (this may take a minute)"
            vm = ValueMapping(vis)
        elif (mymsmd == ''):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            needToClose_mymsmd = True
    else:
        if (verbose):
            print "getWeather: Using current ValueMapping result"
    try:
        mytb.open("%s/OBSERVATION" % vis)
        observatory = mytb.getcell("TELESCOPE_NAME",0)
        mytb.close()
    except:
        print "OBSERVATION table does not exist, assuming observatory == ALMA"
        observatory = "ALMA"
    if (scan == ''):
        if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
            scan = mymsmd.scannumbers()
        else:
            scan = vm.uniqueScans
    conditions = {}
    conditions['pressure']=conditions['temperature']=conditions['humidity']=conditions['dewpoint']=conditions['windspeed']=conditions['winddirection'] = 0
    conditions['scan'] = scan
    if (type(scan) == str):
        if (scan.find('~')>0):
            tokens = scan.split('~')
            scan = [int(k) for k in range(int(tokens[0]),int(tokens[1])+1)]
        else:
            scan = [int(k) for k in scan.split(',')]
    if (type(scan) == np.ndarray):
        scan = list(scan)
    if (type(scan) == list):
        myTimes = np.array([])
        for sc in scan:
            try:
                if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                    if debug: print "1) Calling mymsmd.timesforscan(%d)" % (sc)
                    if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                        newTimes = mymsmd.timesforscan(sc, obsid=obsid)
                    else:
                        newTimes = mymsmd.timesforscan(sc)
                else:
                    if debug: print "1) Calling vm.getTimesForScan(%d)" % (sc)
                    newTimes = vm.getTimesForScan(sc)
            except:
                print "1) Error reading scan %d, is it in the data?" % (sc)
                if (needToClose_mymsmd): mymsmd.close()
                return([conditions,[],vm])
            myTimes = np.concatenate((myTimes,newTimes))
    elif (scan is not None):
        try:
            if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                if debug: print "2) Calling mymsmd.timesforscan(%d)" % (scan)
                if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                    myTimes = mymsmd.timesforscan(scan, obsid=obsid)
                else:
                    myTimes = mymsmd.timesforscan(scan)
            else:
                if debug: print "2) Calling vm.getTimesForScan(%d)" % (scan)
                myTimes = vm.getTimesForScan(scan)
        except:
            print "2) Error reading scan %d, is it in the data?" % (scan)
            if (needToClose_mymsmd): mymsmd.close()
            return([conditions,[],vm])
    else:
        print "scan = ", scan
        if (needToClose_mymsmd): mymsmd.close()
        return([conditions,[],vm])
    if (type(scan) == str):
        scan = [int(k) for k in scan.split(',')]
    if (type(scan) == list):
        listscan = ""
        listfield = []
        for sc in scan:
            if debug: print "Processing scan ", sc
            if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                    listfield.append(mymsmd.fieldsforscan(sc,obsid=obsid))
                else:
                    listfield.append(mymsmd.fieldsforscan(sc))
            else:
                listfield.append(vm.getFieldsForScan(sc))
            listscan += "%d" % sc
            if (sc != scan[-1]):
                listscan += ","
        if debug: print "listfield = ", listfield
        listfields = np.unique(listfield[0])
        listfield = ""
        for field in listfields:
            listfield += "%s" % field
            if (field != listfields[-1]):
                listfield += ","
    else:
        listscan = str(scan)
        if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
            if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                listfield = mymsmd.fieldsforscan(scan, obsid=obsid)
            else:
                listfield = mymsmd.fieldsforscan(scan)
        else:
            listfield = vm.getFieldsForScan(scan)
    [az,el] = ComputeSolarAzEl(myTimes[0], observatory)
    [az2,el2] = ComputeSolarAzEl(myTimes[-1], observatory)
    azsun = np.mean([az,az2])
    elsun = np.mean([el,el2])
    direction = subtable.getcol("DIRECTION")
    azeltime = subtable.getcol("TIME")
    subtable.close()
    telescopeName = getObservatoryName(vis)
    if (len(direction) > 0 and telescopeName.find('VLA') < 0 and telescopeName.find('NRO') < 0):
        azimuth = direction[0][0]*180.0/math.pi  # a list of values
        elevation = direction[1][0]*180.0/math.pi # a list of values
        if debug:
            print "len(azimuth) = %d, len(myTimes)=%d" % (len(azimuth), len(myTimes))
            print "azimuth = ", azimuth
            print "elevation = ", elevation
        npat = np.array(azeltime)
        matches = np.where(npat>=myTimes[0])[0]
        matches2 = np.where(npat<=myTimes[-1])[0]
        if (len(matches2) > 0 and len(matches) > 0):
            if debug: print "azel time matches[0]=%d, matches2[-1]=%d" % (matches[0],matches[-1])
            matchingIndices = range(matches[0],matches2[-1]+1)
        else:
            matchingIndices = []
        if (len(matchingIndices) > 0):
            if debug: print "azel time matches[0]=%d, matches2[-1]=%d" % (matches[0],matches[-1])
            conditions['azimuth'] = np.mean(azimuth[matches[0]:matches2[-1]+1])
            conditions['elevation'] = np.mean(elevation[matches[0]:matches2[-1]+1])
            if debug: print "elevation = ", conditions['elevation']
        elif (len(matches) > 0):
            conditions['azimuth'] = np.mean(azimuth[matches[0]])
            conditions['elevation'] = np.mean(elevation[matches[0]])
        else:
            conditions['azimuth'] = np.mean(azimuth)
            conditions['elevation'] = np.mean(elevation)
        conditions['airmass'] = elevationToAirmass(conditions['elevation'])
        while (antennaName != antennaNames[-1] and (np.abs(conditions['elevation']) < 0.001 or conditions['elevation'] != conditions['elevation'])):
            # Try the next antenna (needed for uid___A002_Xad565b_X20c4)
            nextAntenna = int(antenna)+1
            nextAntennaName = antennaNames[nextAntenna]
            print "Requested antenna = %s shows elevation at/near zero (%f). Trying next antenna = %s." % (antennaName,conditions['elevation'],nextAntennaName)
            antenna = str(nextAntenna)
            antennaName = nextAntennaName
            mytb.open(vis+'/POINTING')
            subtable = mytb.query("ANTENNA_ID == %s" % antenna)
            direction = subtable.getcol("DIRECTION")
            azeltime = subtable.getcol("TIME")
            subtable.close()
            azimuth = direction[0][0]*180.0/math.pi
            elevation = direction[1][0]*180.0/math.pi
            npat = np.array(azeltime)
            matches = np.where(npat >= myTimes[0])[0]
            matches2 = np.where(npat <= myTimes[-1])[0]
            if debug: print "matches[0]=%d, matches2[-1]=%d" % (matches[0],matches[-1])
            conditions['azimuth'] = np.mean(azimuth[matches[0]:matches2[-1]+1])
            conditions['elevation'] = np.mean(elevation[matches[0]:matches2[-1]+1])
            mytb.close()
        if debug:
            print "%d matches after %f, %d matches before %f" % (len(matches), myTimes[0], len(matches2), myTimes[-1])
            print "%d matchingIndices" % (len(matchingIndices))
        conditions['solarangle'] = angularSeparation(azsun,elsun,conditions['azimuth'],conditions['elevation'])
        conditions['solarelev'] = elsun
        conditions['solarazim'] = azsun
        if (verbose):
            print "Used antenna = %s to retrieve mean azimuth and elevation" % (antennaName)
            print "Separation from sun = %f deg" % (abs(conditions['solarangle']))
        if (elsun<0):
            conditions['solarangle'] = -conditions['solarangle']
            if (verbose):
                print "Sun is below horizon (elev=%.1f deg)" % (elsun)
        else:
            if (verbose):
                print "Sun is above horizon (elev=%.1f deg)" % (elsun)
        if (verbose):
            print "Average azimuth = %.2f, elevation = %.2f degrees" % (conditions['azimuth'],conditions['elevation'])
    else:
      if (verbose):
          print "The POINTING table is either blank or does not contain Azim/Elev."
      if (type(scan) == int or type(scan)==np.int32):
          # compute Az/El for this scan
          if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
              if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                  myfieldId = mymsmd.fieldsforscan(scan,obsid=obsid)
              else:
                  myfieldId = mymsmd.fieldsforscan(scan)
              if (type(myfieldId) == list or type(myfieldId) == type(np.ndarray(0))):
                  myfieldId = myfieldId[0]
              fieldName = mymsmd.namesforfields(myfieldId)
              if (type(fieldName) == list):
                  fieldName = fieldName[0]
          else:
              fieldName = vm.getFieldsForScan(scan)
              if (type(fieldName) == list):
                  fieldName = fieldName[0]
              myfieldId = vm.getFieldIdsForFieldName(fieldName)
              if (type(myfieldId) == list or type(myfieldId) == type(np.ndarray(0))):
                  # If the same field name has two IDs (this happens in EVLA data)
                  myfieldId = myfieldId[0]
  #            print "type(myfieldId) = ", type(myfieldId)
          if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
              if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                  myscantime = np.mean(mymsmd.timesforscan(scan,obsid=obsid))
              else:
                  myscantime = np.mean(mymsmd.timesforscan(scan))
          else:
              myscantime = np.mean(vm.getTimesForScans(scan))
          mydirection = getRADecForField(vis, myfieldId, usemstool=True)
          if (len(telescopeName) < 1):
              telescopeName = 'ALMA'
          if debug:
              print "Running computeAzElFromRADecMJD(%s, %f, %s)" % (str(mydirection),myscantime/86400.,telescopeName)
          myazel = computeAzElFromRADecMJD(mydirection, myscantime/86400., telescopeName, verbose=False)
          if (debug): print "myazel = ", myazel
          conditions['elevation'] = np.degrees(myazel[1])
          conditions['airmass'] = elevationToAirmass(conditions['elevation'])
          conditions['azimuth'] = np.degrees(myazel[0])
          conditions['solarangle'] = angularSeparation(azsun,elsun,conditions['azimuth'],conditions['elevation'])
          conditions['solarelev'] = elsun
          conditions['solarazim'] = azsun
          if (verbose):
              print "Separation from sun = %f deg" % (abs(conditions['solarangle']))
          if (elsun<0):
              conditions['solarangle'] = -conditions['solarangle']
              if (verbose):
                  print "Sun is below horizon (elev=%.1f deg)" % (elsun)
          else:
              if (verbose):
                  print "Sun is above horizon (elev=%.1f deg)" % (elsun)
          if (verbose):
              print "Average azimuth = %.2f, elevation = %.2f degrees" % (conditions['azimuth'],conditions['elevation'])
      elif (type(scan) == list):
          myaz = []
          myel = []
          if (verbose):
              print "Scans to loop over = ", scan
          for s in scan:
              if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                  if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                      fieldName = mymsmd.fieldsforscan(s,obsid=obsid)
                  else:
                      fieldName = mymsmd.fieldsforscan(s)
              else:
                  fieldName = vm.getFieldsForScan(s)
              if (type(fieldName) == list or type(fieldName)==np.ndarray):
                  # take only the first pointing in the mosaic
                  fieldName = fieldName[0]
              if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                  if (type(fieldName) == int or type(fieldName)==np.int32):
                      myfieldId = fieldName
                  else:
                      myfieldId = mymsmd.fieldsforname(fieldName)
              else:
                  myfieldId = vm.getFieldIdsForFieldName(fieldName)
              if (type(myfieldId) == list or type(myfieldId)==np.ndarray):
                  # If the same field name has two IDs (this happens in EVLA data)
                  myfieldId = myfieldId[0]
              if (mymsmd != '' and casadef.casa_version >= casaVersionWithMSMD):
                  if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                      myscantime = np.mean(mymsmd.timesforscan(s,obsid=obsid))
                  else:
                      myscantime = np.mean(mymsmd.timesforscan(s))
              else:
                  myscantime = np.mean(vm.getTimesForScans(s))
              mydirection = getRADecForField(vis, myfieldId, usemstool=True)
              telescopeName = getObservatoryName(vis)
              if (len(telescopeName) < 1):
                  telescopeName = 'ALMA'
              myazel = computeAzElFromRADecMJD(mydirection, myscantime/86400., telescopeName, verbose=False)
              myaz.append(myazel[0]*180/math.pi)
              myel.append(myazel[1]*180/math.pi)
          if debug: print "myel = ", myel
          conditions['azimuth'] = np.mean(myaz)
          conditions['elevation'] = np.mean(myel)
          conditions['airmass'] = elevationToAirmass(np.mean(myel))
          conditions['solarangle'] = angularSeparation(azsun,elsun,conditions['azimuth'],conditions['elevation'])
          conditions['solarelev'] = elsun
          conditions['solarazim'] = azsun
          if (verbose):
              print "*Using antenna = %s to retrieve mean azimuth and elevation" % (antennaName)
              print "Separation from sun = %f deg" % (abs(conditions['solarangle']))
          if (elsun<0):
              conditions['solarangle'] = -conditions['solarangle']
              if (verbose):
                  print "Sun is below horizon (elev=%.1f deg)" % (elsun)
          else:
              if (verbose):
                  print "Sun is above horizon (elev=%.1f deg)" % (elsun)
          if (verbose):
              print "Average azimuth = %.2f, elevation = %.2f degrees" % (conditions['azimuth'],conditions['elevation'])
          
              
    # now, get the weather
    if not os.path.exists('%s/WEATHER' % vis):
        print "There is no WEATHER table for this ms."
        if (needToClose_mymsmd): mymsmd.close()
        return([conditions,myTimes,vm])
    try:
        mytb.open("%s/WEATHER" % vis)
    except:
        print "Could not open the WEATHER table for this ms."
        if (needToClose_mymsmd): mymsmd.close()
        return([conditions,myTimes,vm])
    if (True):
        mjdsec = mytb.getcol('TIME')
        indices = np.argsort(mjdsec)
        mjd = mjdsec/86400.
        pressure = mytb.getcol('PRESSURE')
        relativeHumidity = mytb.getcol('REL_HUMIDITY')
        temperature = mytb.getcol('TEMPERATURE')
        if (np.mean(temperature) > 100):
            # must be in units of Kelvin, so convert to C
            temperature = kelvinToCelsius(temperature)
        if 'DEW_POINT' in mytb.colnames():
            dewPoint = mytb.getcol('DEW_POINT')
            if (np.mean(dewPoint) > 100):
                # must be in units of Kelvin, so convert to C
                dewPoint = kelvinToCelsius(dewPoint)
            if (np.mean(dewPoint) == 0):
                # assume it is not measured and use NOAA formula to compute from humidity:
                dewPoint = ComputeDewPointCFromRHAndTempC(relativeHumidity, temperature)
        else:
            dewPoint = None  # Nobeyama measurement sets do not have a dewpoint column
        sinWindDirection = np.sin(mytb.getcol('WIND_DIRECTION'))
        cosWindDirection = np.cos(mytb.getcol('WIND_DIRECTION'))
        windSpeed = mytb.getcol('WIND_SPEED')
        if 'NS_WX_STATION_ID' in mytb.colnames():
            stations = mytb.getcol('NS_WX_STATION_ID')
        else:
            stations = None
        mytb.close()

        # put values into time order (they mostly are, but there can be small differences)
        mjdsec = np.array(mjdsec)[indices]
        pressure = np.array(pressure)[indices]
        relativeHumidity = np.array(relativeHumidity)[indices]
        temperature = np.array(temperature)[indices]
        if dewPoint is not None:
            dewPoint = np.array(dewPoint)[indices]
        windSpeed = np.array(windSpeed)[indices]
        sinWindDirection = np.array(sinWindDirection)[indices]
        cosWindDirection = np.array(cosWindDirection)[indices]
        if stations is not None:
            stations = np.array(stations)[indices]

        if preferredStation != '':
            wsdict = getWeatherStationNames(vis)
            if wsdict is not None:
                preferredStationID = None
                for w in wsdict.keys():
                    if wsdict[w].find(preferredStation) >= 0:
                        preferredStationID = w
                if preferredStationID is None:
                    print "Preferred station (%s) not found in this dataset. Using all." % (preferredStation)
                else:
                    indices = np.where(stations == preferredStationID)
                    mjdsec = np.array(mjdsec)[indices]
                    pressure = np.array(pressure)[indices]
                    relativeHumidity = np.array(relativeHumidity)[indices]
                    temperature = np.array(temperature)[indices]
                    dewPoint = np.array(dewPoint)[indices]
                    windSpeed = np.array(windSpeed)[indices]
                    sinWindDirection = np.array(sinWindDirection)[indices]
                    cosWindDirection = np.array(cosWindDirection)[indices]
                    stations = np.array(stations)[indices]

        # find the overlap of weather measurement times and scan times
        matches = np.where(mjdsec>=np.min(myTimes))[0]
        matches2 = np.where(mjdsec<=np.max(myTimes))[0]
        if debug:
            print "len(matches)=%d, len(matches2)=%d, len(myTimes)=%d, len(mjdsec)=%d" % (len(matches), len(matches2), len(myTimes), len(mjdsec))
            print "min-max time: %s - %s" % (mjdsecToUTHMS(np.min(myTimes)), mjdsecToUTHMS(np.max(myTimes)))
        noWeatherData = False
        if (len(matches)>0 and len(matches2) > 0):
            # average the weather points enclosed by the scan time range
            selectedValues = range(matches[0], matches2[-1]+1)
            if debug:
                print "--- matches = ", matches
                print "--- matches2 = ", matches2
                print "--- selectedValues = ", selectedValues
            if (len(selectedValues) == 0):
                # there was a either gap in the weather data, or an incredibly short scan duration
                if debug:
                    print "----  Finding the nearest weather value --------------------------- "
                selectedValues = findClosestTime(mjdsec, myTimes[0])
            else:
                if debug: 
                    print "--- Taking the %d values within the scan time range of %.1f seconds -----" % (len(selectedValues),np.max(myTimes)-np.min(myTimes))
        elif (len(matches)>0):
            # all points are greater than myTime, so take the first one
            if debug: print "--- Taking the closest value to the scan time range (after it) -----"
            selectedValues = matches[0]
        elif (len(matches2)>0):
            # all points are less than myTime, so take the last one
            if debug: print "--- Taking the closest value to the scan time range (before it) -----"
            selectedValues = matches2[-1]
        else:
            # table has no weather data!
            noWeatherData = True
        if (noWeatherData):
            conditions['pressure'] = 563.0
            conditions['temperature'] = 0  # Celsius is expected
            conditions['humidity'] = 20.0
            conditions['dewpoint'] = -20.0
            conditions['windspeed'] = 0
            conditions['winddirection'] = 0
            print "WARNING: No weather data found in the WEATHER table!"
        else:
            if (type(selectedValues) == np.int64 or type(selectedValues) == np.int32 or  
                type(selectedValues) == np.int):
                conditions['readings'] = 1
                if (verbose):
                    print "selectedValues=%d, myTimes[0]=%.0f, len(matches)=%d, len(matches2)=%d" % (selectedValues,
                                                 myTimes[0], len(matches), len(matches2))
                    if (len(matches) > 0):
                        print "matches[0]=%f, matches[-1]=%f" % (matches[0], matches[-1])
                    if (len(matches2) > 0):
                        print "matches2[0]=%f, matches2[-1]=%d" % (matches2[0], matches2[-1])
            else:
                conditions['readings'] = len(selectedValues)
            conditions['pressure'] = np.mean(pressure[selectedValues])
            if (conditions['pressure'] != conditions['pressure']):
                # A nan value got through, due to no selected values (should be impossible)"
                if (verbose):
                    print ">>>>>>>>>>>>>>>>>>>>>>>>  selectedValues = ", selectedValues
                    print "len(matches)=%d, len(matches2)=%d" % (len(matches), len(matches2))
                    print "matches[0]=%f, matches[-1]=%f, matches2[0]=%f, matches2[-1]=%d" % (matches[0], matches[-1], matches2[0], matches2[-1])
            conditions['temperature'] = np.mean(temperature[selectedValues])
            conditions['humidity'] = np.mean(relativeHumidity[selectedValues])
            if dewPoint is not None:
                conditions['dewpoint'] = np.mean(dewPoint[selectedValues])
            conditions['windspeed'] = np.mean(windSpeed[selectedValues])
            conditions['winddirection'] = (180./math.pi)*np.arctan2(np.mean(sinWindDirection[selectedValues]),np.mean(cosWindDirection[selectedValues]))
            if (conditions['winddirection'] < 0):
                conditions['winddirection'] += 360
            if (verbose and noWeatherData==False):
                print "Mean weather values for scan %s (field %s)" % (listscan,listfield)
                print "  Pressure = %.2f mb" % (conditions['pressure'])
                print "  Temperature = %.2f C" % (conditions['temperature'])
                if dewPoint is not None:
                    print "  Dew point = %.2f C" % (conditions['dewpoint'])
                print "  Relative Humidity = %.2f %%" % (conditions['humidity'])
                print "  Wind speed = %.2f m/s" % (conditions['windspeed'])
                print "  Wind direction = %.2f deg" % (conditions['winddirection'])

    if (needToClose_mymsmd): mymsmd.close()
    return([conditions,myTimes,vm])
    # end of getWeather   forscan

def correlatorDatarate(antennas, channels=4*3840, nbytes=2, pols=2, visint=2.016, verbose=True):
    """
    Computes expected ALMA data rate in terms of the value on a correlator node
    which scales as N_antennas ** 2, rather than N_baselines+N_antennas.
    See also asdmDatarate.
    nbytes: number of bytes for real integer and for imaginary integer
    visint: integration time in seconds
    Prints coefficient = (antennas**2)*pols*2*nbytes
        where the *2 is for real and imaginary values of the visibility
    Returns: value in MB, where 1 MB = 1024**2 bytes (to match bbDataRate computation
             in validateBasebandDataRate function (see PRTSIR-879) in 
    ICD/CORR/Validator/src/alma/correlatorSrc/CorrConfigValidator/CorrConfigValidator.java
    -Todd Hunter
    """
    coefficient = antennas**2*pols*2*nbytes/(1024*1024.)
    if verbose:
        print "Value scales as N_antennas**2 (according to code in CorrConfigValidator.java)"
        print "coefficient = %f MB/s" % (coefficient)
    return channels*coefficient/visint

def getIntegrationTimeFromASDM(asdm):
    """
    Reads all integration times from Main.xml and returns the maximum
    value, which will usually be the science integration time.
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM"
        return
    xmlscans = minidom.parse(asdm+'/Main.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    integrationTimes = []
    for rownode in rowlist:
        row = rownode.getElementsByTagName("numIntegration")
        tokens = row[0].childNodes[0].nodeValue.split()
        numIntegration = int(str(tokens[0]))
        row = rownode.getElementsByTagName("interval")
        tokens = row[0].childNodes[0].nodeValue.split()
        interval = float(str(tokens[0])) * 1e-9
        integrationTimes.append(interval / numIntegration)
    return np.max(integrationTimes)

def dataratesForASDM(asdm, nbytes=2, verbose=False, antennas=None):
    """
    Reads number of antennas, channels and integration time from ASDM and
    sends it to asdmDatarate and correlatorDataRate.
    nbytes: number of bytes for real part of visibility
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM"
        return
    if antennas is None:
        antennas = len(readAntennasFromASDM(asdm, verbose=False))
        print "Found %d antennas" % (antennas)
    else:
        print "Using %d antennas (regardless of what is in the data)" % (antennas)
    channels = getNumChanFromASDM(asdm,scienceOnly=True)
    channels = sum(channels.values())
    print "Found %d channels" % (channels)
    napc = sum(wvrdata(asdm))
    mydict = getPolarizationsFromASDM(asdm)
    pols = max([mydict[i]['numCorr'] for i in mydict])
    print "Found %d pols" % (pols)
    visint = getIntegrationTimeFromASDM(asdm)
    print "Found integration time = %s seconds" % (visint)
    totalTime = np.diff(getObservationMJDSecRangeFromASDM(asdm))[0]
    asdm = asdmDatarate(antennas, channels, nbytes, pols, visint, napc, verbose)
    correlator = correlatorDatarate(antennas, channels, nbytes, pols, visint, verbose)
    print "Total observing time = %s seconds" % (totalTime)
    volume = asdm*totalTime*0.001
    print "Data rate in terms of ASDM size: %f MB/s (volume=%.2f GB)" % (asdm,volume)
    volume = correlator*totalTime*0.001
    print "Data rate in terms of correlator node: %f MB/s (volume=%.2f GB)" % (correlator,volume)

def asdmDatarate(antennas, channels=4*3840, nbytes=2, pols=2, visint=2.016, napc=2, verbose=True):
    """
    Computes expected ALMA data rate in terms of the size of the ASDM, which
    scales as N_baselines+N_antennas, rather than N_antennas**2.
    See also correlatorDatarate.
    nbytes: number of bytes for real integer and for imaginary integer
    napc: number of atmospheric phase correction streams (1 or 2)
    visint: integration time in seconds
    Prints coefficient = (baselines+antennas)*pols*2*nbytes
        where the +antennas is for the autocorrelations and the *2 is
        for real and imaginary values of the visibility
    Returns: value in MB, where 1 MB = 1024**2 bytes
    -Todd Hunter
    """
    baselines = antennas*(antennas-1)/2.
    coefficient = (baselines+antennas)*napc*pols*2*nbytes/(1024*1024.)
    if verbose:
        print "Value scales as N_baselines (crosscorr) + N_antennas (autocorr)."
        print "coefficient = %f MB/s" % (coefficient)
    return channels*coefficient/visint

def asdmbitsHistograms(mydict, projectCodes=['2013','2015','2016','E2E5'],
                       bins=np.arange(17.5,105,5), plotfile='', xlim=[16,104]):
    """
    Calls asdmbitsHistogram for each set of cycles to produce the plot in ICT-6114.
    mydict: dictionary produced by au.asdmbits
    bins, xlim: passed to asdmbitsHistogram
    plotfile: name of montaged png to produce
    -Todd Hunter
    """
    pngs = []
    for projectCode in projectCodes:
        png = projectCode+'.png'
        asdmbitsHistogram(mydict, bins, png, projectCode)
        pngs.append(png)
    montagePngs(pngs,geometry='auto+10',outname=plotfile,background='white')

def asdmbitsHistogram(mydict, bins=np.arange(17.5,105,5), plotfile='', 
                      projectCode='',xlim=[16,104]):
    """
    Plots a histogram of a dictionary returned by asdmbits.
    projectCode: only show results for project codes containing this string
    bin: integer or list
    -Todd Hunter
    """
    bit16 = []
    projects = []
    for project in mydict:
        for asdm in mydict[project]:
            if projectCode == '' or project.find(projectCode) >= 0:
                print mydict[project]
                bit16.append(mydict[project][asdm][0])
                projects.append(project)
    projects = np.unique(projects)
    if len(bit16) < 1:
        print "No matching datasets found."
        return
    pb.clf()
    pb.hist(bit16,bins)
    pb.xlabel('Percent of values that are 16 bit')
    pb.ylabel('Number of occurrences')
    pb.title('%d ASDMs from %d projects in %s' % (len(bit16),len(projects),projectCode))
    pb.xlim(xlim)
    if plotfile != '':
        if plotfile == True:
            if projectCode == '':
                plotfile = 'asdmbits.png'
            else:
                plotfile = 'asdmbits_%s.png' % (projectCode)
                plotfile = plotfile.replace('..','.')
        pb.savefig(plotfile)

def asdmbits(asdm, verbose=True):
    """
    Searches each ASDMBinary file and tabulates how many
    integrations containing CROSS data are 16 bit vs. 32 bit.
    asdm: single ASDM or a python list, or a string with a wildcard
    Returns: 
    * if single ASDM: 2 percentages: 16 bit and 32 bit
    * if multi ASDM: a dictionary keyed by project code, then asdm name 
          with values being list of 2 percentages: 16 bit and 32 bit
    -Todd Hunter
    """
    if type(asdm) == str:
        if (asdm.find('*')>=0):
            asdms = sorted(glob.glob(asdm))
        else:
            asdms = asdm.split(',')
    else:
        asdms = asdm
    asdms = [i.rstrip('/') for i in asdms]
    mydict = {}
    print "Operating on %d ASDMs" % (len(asdms))
    project = ''
    for asdm in asdms:
        if (not os.path.exists(asdm)):
            print "Could not find asdm: ", asdm
            continue
        asdmBasename = os.path.basename(asdm)
        print "Operating on %s" % (asdmBasename)
        if (asdmBasename.find('201') == 0 or asdmBasename.find('E2E') == 0):
            project = asdm.split('/')[0]
            if project not in mydict:
                mydict[project] = {}
        if not os.path.exists(asdm+'/ASDMBinary'):
            print "This is not an ASDM: ", asdm
            continue
        uidlist = glob.glob(asdm+'/ASDMBinary/*')
        i32 = 0
        i16 = 0
        i32size = 0
        i16size = 0
        fast = False  # this is an inaccurate approach
        for i,uid in enumerate(uidlist):
            f = open(uid,'r')
            if fast:
                line = f.read(3000)
                f.close()
                if (line.find('CROSS')>0):
                    if (line.find('INT32')>0):
                        i32 += 1
                        i32size += os.path.getsize(uid)
                    elif (line.find('INT16')>0):
                        i16 += 1
                        i16size += os.path.getsize(uid)
            else:
                lines = f.readlines()
                if verbose:
                    if ((i+1)%100 == 0):
                        print "Working on %d of %d" % (i+1,len(uidlist))
                f.close()
                for line in lines:
                    loc = line.find('INT')
                    if (loc > 0):
                        if (line[loc:].find('INT16')>=0):
                            i16 += 1
                        elif (line[loc:].find('INT32')>=0):
                            i32 += 1
        if fast:
            print "%d/%d BDFs are 16 bits" % (i16,i16+i32)
            print "%d/%d BDFs are 32 bits" % (i32,i16+i32)
        else:
            print "%d/%d integrations are 16 bits (%.1f%%)" % (i16,i16+i32,100.*i16/(i16+i32))
            print "%d/%d integrations are 32 bits (%.1f%%)" % (i32,i16+i32,100.*i32/(i16+i32))
        if (fast):
            totsize = i16size+i32size
            print "In terms of total size, %.1f%% is 16-bit, %.1f%% is 32-bit." % (i16size*100./totsize, i32size*100./totsize)
            print "But this assumes the integer type is the same within a BDF, but it may not be."
        if project in mydict.keys():
            mydict[project][asdmBasename] = [100.*i16/(i16+i32), 100.*i32/(i16+i32)]
        else:
            mydict[asdm] = [100.*i16/(i16+i32), 100.*i32/(i16+i32)]
        print "mydict = ", mydict
    if len(asdms) == 1:
        return mydict[asdms[0]]
    else:
        return mydict

def azelSeparation(vis, intent1='OBSERVE_TARGET', intent2='CALIBRATE_PHASE', 
                   field1=None, field2=None):
    """
    Computes the azim/elev separation between scans of two intents.
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Cannot find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if intent1 is not None and intent2 is not None:
        intent1 = '*' + intent1 + '*'
        intent2 = '*' + intent2 + '*'
        scans = list(mymsmd.scansforintent(intent1))
        scans += list(mymsmd.scansforintent(intent2))
    elif field1 is not None and field2 is not None:
        scans = list(mymsmd.scansforfield(field1))
        scans += list(mymsmd.scansforfield(field2))
    else:
        print "You must specify intent1 and intent2, or field1 and field2."
        mymsmd.close()
        return
    scans = sorted(scans)
    az0, el0 = listazel(vis, scan=scans[0], mymsmd=mymsmd, verbose=False)
    # timesforscans fails for np.int32 - CAS-10956
    times = mymsmd.timesforscans(int(scans[0]))
    t0 = np.mean(times)
    for i,scan in enumerate(scans[1:]):
        az, el = listazel(vis, scan=scan, mymsmd=mymsmd, verbose=False)
        t = np.mean(mymsmd.timesforscans(int(scan)))
        azdiff = (az-az0)*np.cos(np.radians(el))
        eldiff = el-el0
        print "Scan %3d-%3d: deltaAzim=%+6.2f,  deltaElev=%+5.2f deg  deltaTime=%.2f minutes" % (scans[i],scans[i+1],azdiff,eldiff,(t-t0)/60.)
        az0 = az
        el0 = el
        t0 = t
    mymsmd.close()

def listazel(vis, scan=None, antenna='0', vm=0, verbose=True, value='mean', 
             obsid=0, mymsmd=''):
    """
    Extracts the mean, min, or max azimuth and elevation for the specified 
    'scan' in the specified ms (whose name is passed in by the vis argument)
    from the POINTING table.  Note: this does not work for VLA data because the 
    POINTING table is not populated!  For VLA, you can use au.computeAzElForMS.
    scan: can be a single scan or a list, as in [1,2,3], or in '1,2,3'
       If it is not specified, then all scans are used
    antenna: can be either the antenna number or its name.
    value: 'mean', 'min', 'median', or 'max' for single values, 
        or 'all' for a list of each
    This function uses msmd (or ValueMapping if casa < 4.1.0).
    obsid: only used for casa versions 4.4 and 4.5 because the forscan methods of 
           msmd required obsid if multiple obsids were present in the data
    Returns:
    selected statistical value for [azimuth, elevation] in degrees
    returnDifferences: if True, then also statistical value of the 
                       per-scan differences
    -- Todd Hunter
    """
    if (not os.path.exists(vis+'/POINTING')):
        print "POINTING table does not exist"
        return
    try:
        if str(antenna).isdigit():
            antennaName = getAntennaNames(vis)[int(str(antenna))]
        else:
            try:
                antenna = getAntennaIndex(vis,antennaName)
            except:
                antennaName = string.upper(antenna)
                antenna = getAntennaIndex(vis,antennaName)
                if (antenna == -1): return([0,0])
    except:
        print "Antenna %s does not exist in this dataset" % str(antenna)
        return([0,0])
    try:
        mytb = createCasaTool(tbtool)
        mytb.open("%s/POINTING" % vis)
    except:
        print "Cannot open the POINTING table."
        return([0,0])
    subtable = mytb.query("ANTENNA_ID == %s" % antenna)
    mytb.close()
    if (casadef.casa_version >= casaVersionWithMSMD):
        closeMymsmd = False
        if mymsmd == '':
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            closeMymsmd = True
        scans = mymsmd.scannumbers()
    else:
        if (vm==0):
            vm = ValueMapping(vis)
        scans = vm.uniqueScans
    if (scan is None):
        scan = scans
    if (type(scan) == str):
        scan = [int(k) for k in scan.split(',')]
    if (type(scan) == list or type(scan) == np.ndarray):
        myTimes = []
        for sc in scan:
            if (casadef.casa_version >= casaVersionWithMSMD):
                if (sc not in mymsmd.scannumbers()):
                    print "A: Scan %s is not in the data." % (str(sc))
                    return([0,0])
                if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                    newTimes = mymsmd.timesforscan(sc,obsid=obsid)
                else:
                    newTimes = mymsmd.timesforscan(sc)
            else:
                try:
                    newTimes = vm.getTimesForScan(sc)
                except:
                    print "3) Error reading scan %d, is it in the data?" % (sc)
                    return([0,0])
#            print "Appending times for scan ", sc
            myTimes.append(list(newTimes)) #  = np.concatenate((myTimes,newTimes))
    elif (scan is not None):
        if (casadef.casa_version >= casaVersionWithMSMD):
            if (scan not in mymsmd.scannumbers()):
                print "B: Scan %s is not in the data." % (str(scan))
                return([0,0])
            if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                myTimes = [mymsmd.timesforscan(scan,obsid=obsid)]
            else:
                myTimes = [mymsmd.timesforscan(scan)]
        else:
            try:
                myTimes = [vm.getTimesForScan(scan)]
            except:
                print "4) Error reading scan %d, is it in the data?" % (scan)
                return([0,0])
    else:
        print "scan = ", scan
        return([0,0])
    direction = subtable.getcol("DIRECTION")
    if (len(direction) == 0):
        print "Pointing table is empty"
        return
    time = subtable.getcol("TIME")
    azimuth = direction[0][0]*180.0/math.pi
    elevation = direction[1][0]*180.0/math.pi
    npat = np.array(time)
    if value == 'mean':
        func = np.mean
    elif value == 'median':
        func = np.median
    elif value == 'min':
        func = np.min
    elif value == 'max':
        func = np.max
    elif value == 'all':
        func = np.array
    else:
        func = np.mean

    if (len(myTimes) == 1):
        myTimes = myTimes[0]
        # This logic assumes that scan lists do not have holes in them.
        matches = np.where(npat>myTimes[0])[0]
        matches2 = np.where(npat<myTimes[-1])[0]
        azimuth = func(azimuth[matches[0]:matches2[-1]+1])
        elevation = func(elevation[matches[0]:matches2[-1]+1])
    else:
        # There might be gaps in scan lists
        myazimuth = []
        myelevation = []
        for myTime in myTimes:
            matches = np.where(npat>myTime[0])[0]
            matches2 = np.where(npat<myTime[-1])[0]
            myazimuth.append(func(azimuth[matches[0]:matches2[-1]+1]))
            myelevation.append(func(elevation[matches[0]:matches2[-1]+1]))
        # implement a scan-based mean, rather than time-based mean
        azimuth = func(myazimuth)
        elevation = func(myelevation)
    if (type(scan) == list or type(scan) == np.ndarray):
        listscan = ""
        listfield = []
        for sc in scan:
            if (casadef.casa_version >= casaVersionWithMSMD):
                if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                    fields = mymsmd.fieldsforscan(sc,obsid=obsid)
                else:
                    fields = mymsmd.fieldsforscan(sc)
            else:
                fields = vm.getFieldsForScan(sc)
            for f in fields:
                listfield.append(f)
            listscan += "%d" % sc
            if (sc != scan[-1]):
                listscan += ","
        listfields = np.unique(listfield)
        listfield = ""
        for field in listfields:
            listfield += "%s" % field
            if (field != listfields[-1]):
                listfield += ","
    else:
        listscan = str(scan)
        if (casadef.casa_version >= casaVersionWithMSMD):
            if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.6'):
                listfield = mymsmd.fieldsforscan(scan,obsid=obsid)
            else:
                listfield = mymsmd.fieldsforscan(scan)
        else:
            listfield = vm.getFieldsForScan(listscan)
    if verbose and func != 'all':
        print "Scan %s (field=%s): azim = %.2f,  elev = %.2f  (degrees)" % (listscan, listfield, azimuth, elevation)
    if (casadef.casa_version >= casaVersionWithMSMD):
        if closeMymsmd:
            mymsmd.close()
    return([azimuth, elevation])
# end of listazel()

def plotAzimuthElevationPolar(vis, antenna='0', plotfile='', colorByHalf=False):
    """
    Polar plot of the azimuth and elevation for a specified antenna in an ms
    from the POINTING table.  Note: This will not work for VLA data.
    - Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find the ms = %s" % (vis)
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    try:
      if str(antenna).isdigit():
          antennaName = getAntennaNames(vis)[int(str(antenna))]
      else:
          antennaName = antenna
          try:
              antenna = getAntennaIndex(vis,antennaName)
          except:
              antennaName = string.upper(antenna)
              antenna = getAntennaIndex(vis,antennaName)
    except:
        print "Either the ANTENNA file or antenna %s does not exist" % (antennaName)
        return
    mytb = createCasaTool(tbtool)
    mytb.open("%s/POINTING" % vis)
    ref = mytb.getcolkeywords('DIRECTION')['MEASINFO']['Ref']
    if (ref.upper().find('AZEL') < 0):
        print "Sorry, the POINTING table is in %s format, not AZELGEO" % (ref)
        return
    subtable = mytb.query("ANTENNA_ID == %s" % antenna)
    direction = subtable.getcol("DIRECTION")
    mjdsec = (subtable.getcol("TIME"))
    subtable.close()
    mytb.close()        
    if (len(direction) == 0):
        print "The POINTING table appears to be empty."
        return
    elevation = np.degrees(direction[1][0])
    mymsmd = createCasaTool(msmdtool)
    if (colorByHalf):
        mymsmd.open(vis)
        scans = mymsmd.scansforintent('CALIBRATE_DELAY*')
        firstHalf = scans[:len(scans)/2]
        ts = np.array(mymsmd.timesforscan(firstHalf[-1]), dtype=float)
        breakPointMJDSec = np.max(ts,axis=0)
        mymsmd.close()
    za = 90-elevation
    azimuth = np.degrees(direction[0][0])
    azimuth[np.where(azimuth < 0)[0]] += 2*np.pi
    ax = pb.subplot(111, polar=True, projection='polar')
    ax.set_theta_zero_location('N')
    ax.set_theta_direction(-1)
    ax.plot(azimuth, za,'k+',ms=10,color='k',mew=1)
    if (colorByHalf):
        idx = np.where(mjdsec > breakPointMJDSec)[0]
        ax.plot(azimuth[idx], za[idx],'k+',ms=10,color='r',mew=1)
        pb.text(0.0,1.0,'First half',color='k',transform=ax.transAxes)
        pb.text(0.0,0.95,'Second half',color='r',transform=ax.transAxes)
    pb.ylim([0,90])
    pb.text(np.radians(15),100,'Zenith angle (deg)',va='top')
    pb.title(vis+' (%s)'%getObservationStartDate(vis).split()[0])
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = vis + '.azel_polar.png'
        pb.savefig(plotfile)
    
def plotAzimuthElevation(vis, antenna='0', xrangeAz=None, yrangeAz=None,
                         xrangeEl=None, yrangeEl=None,
                         plotfile=''):
    """
    Plots the azimuth and elevation vs. time for a specified antenna in an ms
    from the POINTING table.  Note: This will not work for VLA data.
    The antenna parameter can be either the number, the number string,
    or the name string of the antenna.  xrange and yrange can be
    used to set the plot range.
    Produces a plot called  <vis>.azel_vs_time.png, unless otherwise
    specified via the plotfile parameter.
    -- Todd Hunter
    """
    plotAzimuth(vis, antenna, xrangeAz, yrangeAz, plotfile, subplot=211)
    plotElevation(vis, antenna, xrangeEl, yrangeEl, plotfile, subplot=212)
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = vis + '.azel_vs_time.png'
        pb.savefig(plotfile)
        print "Wrote ", plotfile
    
def plotElevation(vis, antenna='0', xrange=None, yrange=None, plotfile='',
                  subplot=111):
    """
    Plots the elevation vs. time for a specified antenna in an ms from
    the POINTING table.  Note: This will not work for VLA data.
    The antenna parameter can be either the number, the number string,
    or the name string of the antenna.  xrange and yrange can be
    used to set the plot range.
    Produces a plot called  <vis>.elev.png, unless otherwise
    specified via the plotfile parameter.
    -- Todd Hunter
    """
    plotPosition(vis,1,antenna,xrange,yrange,plotfile, subplot=subplot)

def plotAzimuth(vis, antenna='0',xrange=None,yrange=None,plotfile='',
                forcePositive=True, subplot=111):
    """
    Plots the azimuth vs. time for a specified antenna in an ms from
    the POINTING table.  Note: This will not work for VLA data.
    The antenna parameter can be either the number, the number string,
    or the name string of the antenna.  xrange and yrange can be
    used to set the plot range.  
    Produces a plot called <vis>.azim.png, unless otherwise
    specified via the plotfile parameter.
    See also plotElevation.
     -- Todd Hunter
    """
    plotPosition(vis,0,antenna,xrange,yrange,plotfile,forcePositive,subplot)

def plotPosition(vis, azel, antenna='0', xrange=None, yrange=None,
                 plotfile='', forcePositive=False, subplot=111):
    """
    Plots the azimuth or elevation vs. time for a specified antenna in an ms
    from the POINTING table.  azel=0 means azimuth,  1 means elevation
    This function is useful for showing the az/el of planetary bodies which
    might appear with RA,dec = 0,0 in plotms (in older ALMA data).
    Produces a plot called  <vis>.elev.png or <vis>.azim.png, unless otherwise
    specified via the plotfile parameter.
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find the ms = %s" % (vis)
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    try:
      if str(antenna).isdigit():
          antennaName = getAntennaNames(vis)[int(str(antenna))]
      else:
          antennaName = antenna
          try:
              antenna = getAntennaIndex(vis,antennaName)
          except:
              antennaName = string.upper(antenna)
              antenna = getAntennaIndex(vis,antennaName)
    except:
        print "Either the ANTENNA file or antenna %s does not exist" % (antennaName)
        return
    mytb = createCasaTool(tbtool)
    mytb.open("%s/POINTING" % vis)
    ref = mytb.getcolkeywords('DIRECTION')['MEASINFO']['Ref']
    if (ref.upper().find('AZEL') < 0):
        print "Sorry, the POINTING table is in %s format, not AZELGEO" % (ref)
        return
    subtable = mytb.query("ANTENNA_ID == %s" % antenna)
    mytb.close()        
    direction = subtable.getcol("DIRECTION")
    if (len(direction) == 0):
        print "The POINTING table appears to be empty."
        return
    elevation = np.degrees(direction[azel][0])
    if (azel==0 and forcePositive):
        elevation[np.where(elevation < 0)[0]] += 360
    mjdsec = (subtable.getcol("TIME"))
    mjd  = mjdsec/86400.
    elevTime = (mjd-math.floor(mjd[0]))*24.
    if (subplot == 211 or subplot == 111):
        pb.clf()
    pb.subplot(subplot)
    plot(elevTime,elevation,'r.')
    if (azel == 1):
        ylabel('Elevation (deg)')
        ylim([0,90])
    else:
        ylabel('Azimuth (deg)')
    if (yrange is not None):
        ylim(yrange)
    if (xrange is not None):
        xlim(xrange)
    (mjd, datestring) = mjdSecondsToMJDandUT(mjdsec[0])
    xlabel('UT hour on %s'%(datestring[0:10]))
    if (subplot==111 or subplot==211):
        title('%s  %s'%(vis,antennaName))
    if (subplot==111):
        if (azel==1):
            if (plotfile == ''):
                plotfile= vis+'.elev.png'
            savefig(plotfile)
        else:
            if (plotfile == ''):
                plotfile= vis+'.azim.png'
            savefig(plotfile)

    return elevation

def getMJDSec():
    """
    Returns the current MJD in seconds.
    Todd Hunter
    """
    return(getCurrentMJDSec())

def getCurrentUnixTime():
    """
    Returns the current unix time (seconds since 1970)
    """
    return(timeUtilities.time())

def getCurrentMJDSec():
    """
    Returns the current MJD in seconds.
    Todd Hunter
    """
    mjdsec = getMJD() * 86400
    return(mjdsec)

def getCurrentDate(delimiter='/'):
    """
    returns date in format: 'YYYY/MM/DD'
    delimiter: which character to use as the delimiter
    -Todd Hunter
    """
    return(timeUtilities.strftime('%Y/%m/%d').replace('/',delimiter))

def ComputeLSTDay(mjdsec=-1, date='', longitude=ALMA_LONGITUDE, 
                  verbose=True, observatory=None):
    """
    Computes the LST day (useful for running NRAO dopset)
    and LST (in hours) for a specified time/date and longitude.
    If mjdsec is a string, it will be assumed to be a date string.
    observatory: if specified, then ignore the longitude parameter
    For date, either of these formats is valid: 2011/10/15
                                                2011/10/15 05:00:00
                                                2011/10/15-05:00:00
    longitude: degrees, where east of Greenwich is positive (default=ALMA).
    observatory: if specified, then ignore longitude parameter and look
                 up the value in casa
    -- Todd Hunter
    """
    if (date == ''):
        if (type(mjdsec) == str):
            mjdsec = dateStringToMJDSec(mjdsec,verbose=verbose)
        else:
            if (mjdsec<0):
                mjdsec = getCurrentMJDSec()
                print "Using current date/time"
    else:
        mjdsec = dateStringToMJDSec(date,verbose=verbose)

    LST = ComputeLST(mjdsec, longitude, observatory=observatory)
    if (observatory is not None):
        longitude = getObservatoryLongitude(observatory)
        if (longitude is None): return
    MJD = mjdsec/86400.
    JD = mjdToJD(MJD)
# See http://gge.unb.ca/Pubs/TR171.pdf
    siderealDay = int(np.floor(JD*(0.002737909350795) + MJD) )
    if (verbose):
        print "LST day = %d,  LST = %.4f hours (at longitude=%f)" % (siderealDay,
                                                                     LST,longitude)
        print "Julian day = %f, MJD = %f, MJD seconds = %f" % (JD,MJD,mjdsec)
    return(siderealDay)
      
def ComputeLST(mjdsec=None, longitude=ALMA_LONGITUDE, ut=None, hms=False,
               observatory=None, date=None, verbose=False, prec=0):
    """
    Computes the LST (in hours) for a specified time and longitude. 
    The input longitude is in degrees, where east of Greenwich is > 0.
    Two options to specify the time:
    mjdsec: MJD seconds
    ut: ut time on the current day as a HH:MM:SS string or floating point hours
    hms: if True, return the time as a HH:MM:SS string
    observatory: if specified, ignore the longitude argument
    prec: digits of fractional seconds to show
    date: a date/time string
    Either of these formats is valid: 2011/10/15 05:00:00
                                      2011/10/15-05:00:00
                                      2011-10-15 05:00:00
                                      2011-10-15T05:00:00
                                      2011-Oct-15T05:00:00
    If mjdsec, ut and date are all None, then it uses the current date+time.
    -- Todd Hunter
    """
    if (mjdsec is None and ut is None and date is None):
        mjdsec = getMJDSec()
    elif (ut is not None):
        if (date is None):
            datestring = getCurrentDate()
        else:
            datestring = date
        if (type(ut) == str):
            datestring += ' ' + ut
        else:
            minutes = int(60*(ut-int(ut)))
            datestring += ' %02d:%02d:%02.0f' % (int(ut),minutes,3600*(ut-int(ut)-minutes/60.))
        mjdsec = dateStringToMJDSec(datestring, verbose=False)
    elif (date is not None):
        mjdsec = dateStringToMJDSec(date, verbose=False)
    if verbose: print "MJD seconds = ", mjdsec
    JD = mjdToJD(mjdsec/86400.)
    T = (JD - 2451545.0) / 36525.0
    sidereal = 280.46061837 + 360.98564736629*(JD - 2451545.0) + 0.000387933*T*T - T*T*T/38710000.

    # now we have LST in Greenwich, need to scale back to site
    if (observatory is not None):
        longitude = getObservatoryLongitude(observatory)
        if (longitude is None): return
    sidereal += longitude
    sidereal /= 360.
    sidereal -= np.floor(sidereal)
    sidereal *= 24.0
    if (sidereal < 0):
        sidereal += 24
    if (sidereal >= 24):
        sidereal -= 24
    if (hms):
        return(hoursToHMS(sidereal, prec=prec))
    else:
        return(sidereal)

def getCalibrationIntents(vis, field, mymsmd=None, briefNames=True, drop='WVR,ATMOSPHERE'):
    """
    Returns a list of calibration intents  (if any) for specified field.
    briefNames: if True, then return ['BANDPASS'] instead of ['CALIBRATE_BANDPASS#ON_SOURCE']
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    drop = drop.split(',')
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    intents = mymsmd.intentsforfield(field)
    fullIntents = []
    briefIntents = []
    for intent in intents:
        if intent.find('CALIBRATE') >= 0:
            # the split on . is needed for really old ALMA data
            briefIntent = intent.replace('CALIBRATE_','').split('#')[0].split('.')[0]
            if briefIntent not in drop:
                fullIntents.append(intent)
                briefIntents.append(briefIntent)
    if needToClose:
        mymsmd.close()
    if briefNames:
        intents = np.unique(briefIntents)
    else:
        intents = np.unique(fullIntents)
    return intents
    
def nearestCalibratorToScienceTargets(vis):
    """
    Reports a dictionary keyed by science target name, with values for 'nearest' calibrator
    name, and 'separation' in degrees.
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    fields = getScienceTargets(vis, mymsmd=mymsmd, returnNames=False)
    fieldNames = mymsmd.namesforfields()
    calibrators = getCalibrators(vis, mymsmd=mymsmd, returnNames=False)
    results = {}
    for field1 in fields:
        minSeparation = 1e9
        for calibrator in calibrators:
            separation = angularSeparationOfTwoFields(vis, field1, calibrator, usemsmd=mymsmd)
            if separation < minSeparation:
                intents = getCalibrationIntents(vis, calibrator, mymsmd=mymsmd)
                results[fieldNames[field1]] = {'nearest': fieldNames[calibrator], 'separation': separation, 'intent': intents}
                minSeparation = separation
    mymsmd.close()
    return results

def angularSeparationOfTwoFields(vis, field1, field2, usemsmd='', vis2='', returnComponents=False, returnArcsec=False):
    """
    Copmutes the angular separation (in degrees) between 2 specified fields
    in a measurement set, using msmd.phasecenter.
    field1, field2: the field IDs
    usemsmd: if specified, use this existing instance of msmd
    vis2: if specified, then look for field2 in this other measurement set
    Returns:
    returnComponents=False: single value in degrees
    returnComponents=True: 4 values: [separation, raSeparation, decSeparation, raSeparationCosDec]
    returnArcsec: if True, return the four separations in arcsec
    -Todd Hunter
    """
    if (usemsmd == ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    else:
        mymsmd = usemsmd
    phasecenter1 = mymsmd.phasecenter(field1)
    if (vis2 == ''):
        phasecenter2 = mymsmd.phasecenter(field2)
    else:
        mymsmd2 = createCasaTool(msmdtool)
        mymsmd2.open(vis2)
        phasecenter2 = mymsmd2.phasecenter(field2)
        mymsmd2.close()
    if (usemsmd == ''):
        mymsmd.close()
    degrees = np.degrees(angularSeparationOfDirections(phasecenter1,
                                                       phasecenter2, returnComponents))
    if returnArcsec:
        value = degrees*3600
    else:
        value = degrees
    return value

def plotPhaseCheckTargetOnSky(dataset, plotfile='', checksource='', science='',
                              phase=''):
    """
    For an ASDM or ms, plots the relative locations on the sky of the phase 
    calibrator, check source, and first science target.  Does not work right 
    for ephemeris objects (which will appear at 0,0).
    dataset: name of ASDM or ms file
    checksource: override the checksource with this source (e.g. J0217-0820)
    science: override the science target with this source (e.g. J0217-0820)
    phase: override the phasecal target with this source (e.g. J0217-0820)
    -Todd Hunter
    """
    dataset = dataset.rstrip('/')
    if not os.path.exists(dataset):
        print "Could not find dataset."
        return
    if not os.path.exists(dataset+'/ASDM.xml'):
        asdm = False
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(dataset)
    else:
        asdm = True
    if phase == '':
        if asdm:
            phase = getTargetsForIntentFromASDM(dataset, 'PHASE')
        else:
            phase = getTargetsForIntent(dataset, 'PHASE', mymsmd=mymsmd)
        if len(phase) < 1:
            print "No PHASE calibrator."
            return
    else:
        # phase[0] is a numpy.string_ which 
        phase = [str(phase)]
    if asdm:
        ephemerisFieldDict = getEphemerisFieldsFromASDM(dataset, keyBy='name', verbose=False)
        phasepos = getRADecForFieldFromASDM(dataset, phase[0], sexagesimal=True)
    else:
        ephemerisFieldDict = getEphemerisFields(dataset, verbose=False)
        phasepos = getRADecForField(dataset, str(phase[0]), hms=True, mymsmd=mymsmd)
    print "phasepos = ", phasepos

    if checksource == '':
        if asdm:
            check = getTargetsForIntentFromASDM(asdm, 'CHECK')
        else:
            check = getTargetsForIntent(dataset, 'CHECK', mymsmd=mymsmd)
        if len(check) < 1:
            print "No CHECK source calibrator."
            return
        if asdm:
            checkpos = getRADecForFieldFromASDM(dataset, check[0], sexagesimal=True)
        else:
            checkpos = getRADecForField(dataset, check[0], hms=True)
    else:
        check = [checksource]
        checkpos = searchFlux(checksource, returnPosition=True, verbose=False)
    if science == '':
        if asdm:
            science = getTargetsForIntentFromASDM(dataset, 'TARGET')
        else:
            science = getTargetsForIntent(dataset, 'TARGET', mymsmd=mymsmd)
        if len(science) < 1:
            print "No TARGET source."
            return
    else:
        science = [science]
    if asdm:
        sciencepos = getRADecForFieldFromASDM(dataset, science[0], sexagesimal=True)
    else:
        sciencepos = getRADecForField(dataset, science[0], hms=True)
        mymsmd.close()

    print "sciencepos = ", sciencepos
    phaseDeg = angularSeparationOfStrings(phasepos,sciencepos,True)
    checkDeg = angularSeparationOfStrings(checkpos,sciencepos,True)
    pb.clf()
    desc = pb.subplot(111)
    x = [0, phaseDeg[3], checkDeg[3]]
    y = [0,phaseDeg[2],checkDeg[2]]
    pb.plot(x, y, 'b+', ms=10, mew=2)
    pb.text(0,0,'science='+science[0], ha='center', va='top')
    pb.text(checkDeg[3],checkDeg[2],'check='+check[0], ha='center', va='top')
    pb.text(phaseDeg[3],phaseDeg[2],'phase='+phase[0], ha='center', va='top')
    pb.xlabel('Right Ascension offset from science target (deg)')
    pb.ylabel('Declination offset from science target (deg)')
    padPlotLimits(0.2)
    # reverse x-axis so the RA increases to the left
    pb.xlim([pb.xlim()[1], pb.xlim()[0]])
    pb.title(os.path.basename(dataset))
    pb.draw()
    if plotfile == True:
        plotfile = dataset + '_plotPhaseCheckTarget.png'
    if plotfile != '':
        pb.savefig(plotfile)
        print "Wrote ", plotfile

def addDateToPlot(size=10):
    """
    Adds the current date/time to the bottom right of a pylab plot.
    -Todd Hunter
    """
    pb.text(0.95, 0.03, mjdsecToDatestring(), ha='right', va='bottom', transform=pb.gcf().transFigure,size=size)

def padPlotLimits(fraction=0.1):
    """
    Expand the current pylab plot limits by 10% on each edge.
    -Todd Hunter
    """
    x0,x1 = pb.xlim()
    xspan = x1-x0
    x0 = x0-xspan*fraction
    x1 = x1+xspan*fraction
    y0,y1 = pb.ylim()
    yspan = y1-y0
    y0 = y0-yspan*fraction
    y1 = y1+yspan*fraction
    pb.xlim([x0,x1])
    pb.ylim([y0,y1])

def angularSeparationOfFieldsFromASDM(asdm, intents='PHASE,CHECK', verbose=False):
    """
    Determines angular separation between two intents (i.e between the first 
    objects observed for those intents).  Works correctly for SSOs because it 
    determines field name from intent, then matches it with the source name in the
    Source.xml dictionary returned by readscans rather than Field.xml (which has 0,0).
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find ASDM."
        return
    if type(intents) == str:
        intents = intents.split(',')
    if len(intents) < 2:
        print "Need at least 2 intents"
        return
    targets = {}
    radec = []
    for intent in intents:
        targets[intent] = getTargetsForIntentFromASDM(asdm, '*'+intent+'*')
        if len(targets[intent]) < 1:
            print "No %s targets" % (intent)
            return
        radec.append(getRADecForFieldFromASDM(asdm, targets[intent][0], sexagesimal=True))
        if verbose:
            print "%s: %s %s" % (targets[intent][0], intent, radec[-1])
    separationDeg = angularSeparationOfStrings(radec[0], radec[1], verbose=False)
    print "Separation of %s (%s) from %s (%s)  = %.2f deg" % (targets[intents[0]][0], intents[0], targets[intents[1]][0], intents[1], separationDeg)
    return separationDeg

def angularSeparationOfFields(vis, fields=[], doplot=False, 
                              plotintents=['OBSERVE_TARGET*','CALIBRATE_PHASE*'], allMosaicFields=True):
    """
    Reads an ms and computes the angular separation of all combinations
    of fields, or if the fields parameter is given, only those field
    names or IDs specified in the fields parameter, which can be either
    a list of IDs or names, or an individual ID or name.
    It computes great circle angle using the Vincenty formula.
    doplot: if True, then also make a plot of Declination vs. RA
       The plot aspect ratio is scaled by cos(mean_dec) to reflect sky separation.
    plotintents: only plot fields with these intents, colorized by intent
    allMosaicFields: if False, then only compute for one field of multi-field targets
    Returns:  the max separation of phase cal to science target
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "vis does not exist = ", vis
        return
    if (type(fields) != list):
        fields = [fields]
    mymsmd = createCasaTool(msmdtool)    
    mymsmd.open(vis)
    if (casadef.casa_version < casaVersionWithMSMDFieldnames):
        name = mymsmd.namesforfields()
    else:
        name = mymsmd.fieldnames()
    pos = []
    myms = createCasaTool(mstool)
    myms.open(vis)
    for i in range(len(name)):
        pos.append([getRADecForField(vis, i, usemstool=True, myms=myms)])
    myms.close()
    nfields = len(pos)
    if (nfields < 2):
        print "There is only one field in this dataset."
    else:
        print "Field =         Names (*=phasecal)           Separations"
    if doplot:
        if (type(plotintents) == str):
            plotintents = [plotintents]
        pb.clf()
        desc = pb.subplot(111)
        pb.xlabel('RA (hours)')
        pb.ylabel('Dec (deg)')
        plotfields = []
        for intent in plotintents:
            plotfields.append(list(mymsmd.fieldsforintent(intent)))
        colors = ['k','r','g','b','c','m']
    separations = []
    doneFields = []
    for i in range(nfields):
      if (name[i] not in doneFields) or allMosaicFields:
        if doplot:
            for col, plotfield in enumerate(plotfields):
                if i in plotfield:
                    hours = np.degrees(pos[i][0][0])/15.
                    if (np.mean(hours) < 0):
                        hours += 24
                    pb.plot(hours, 
                            np.degrees(pos[i][0][1]), 'o', color=colors[col])
                    break
        doneFields2 = []
        for j in range(i+1,len(pos)):
          if allMosaicFields or (name[j] not in doneFields2):
            if (fields == [] or fields == [''] or (i in fields or j in fields) or
                (name[i] in fields or name[j] in fields)):
                radians = angularSeparationRadiansTuples(pos[i][0], pos[j][0])
                degrees = radians*180/np.pi
                arcsec = 3600*degrees
                namei = name[i]
                namej = name[j]
                phasecalScience = ''
                if ('CALIBRATE_PHASE#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                    namei = '*'+namei
                    if ('OBSERVE_TARGET#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                        phasecalScience = '(phasecal-science)'
                        separations.append(degrees)
                    if ('OBSERVE_CHECK_SOURCE#ON_SOURCE' in mymsmd.intentsforfield(name[j]) or
                        'CALIBRATE_DELAY#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                        phasecalScience = '(phasecal-checksource)'
                    if ('CALIBRATE_BANDPASS#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                        phasecalScience = '(phasecal-bandpass)'
                    if ('CALIBRATE_FLUX#ON_SOURCE' in mymsmd.intentsforfield(name[j]) or
                        'CALIBRATE_AMPLI#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                        phasecalScience = '(phasecal-flux)'
                if ('CALIBRATE_PHASE#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                    namej = '*'+namej
                    if ('OBSERVE_TARGET#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                        separations.append(degrees)
                        phasecalScience = '(science-phasecal)'
                    if ('CALIBRATE_BANDPASS#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                        phasecalScience = '(bandpass-phasecal)'
                    if ('CALIBRATE_FLUX#ON_SOURCE' in mymsmd.intentsforfield(name[i]) or
                        'CALIBRATE_AMPLI#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                        phasecalScience = '(flux-phasecal)'
                    if ('OBSERVE_CHECK_SOURCE#ON_SOURCE' in mymsmd.intentsforfield(name[i]) or
                        'CALIBRATE_DELAY#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                        phasecalScience = '(checksource-phasecal)'
                if ('OBSERVE_CHECK_SOURCE#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                    namei = '*'+namei
                    if ('OBSERVE_TARGET#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                        phasecalScience = '(checksource-science)'
                if ('OBSERVE_TARGET#ON_SOURCE' in mymsmd.intentsforfield(name[j])):
                    if ('OBSERVE_CHECK_SOURCE#ON_SOURCE' in mymsmd.intentsforfield(name[i])):
                        phasecalScience = '(science-checksource)'
                print "%02d-%02d = %15s-%15s: %8g deg = %8g arcsec %s" % (i,j,namei,namej,degrees,arcsec,phasecalScience)
            doneFields2.append(name[j])
        doneFields.append(name[i])
    mymsmd.close()
    if doplot:
        desc.set_aspect(np.abs(np.cos(np.radians(np.mean(pb.ylim()))))/15.0)
        pb.title(os.path.basename(vis))
        pb.draw()
        png = vis+'.fieldlayout.png'
        pb.savefig(png)
        print "Plot left in ", png
    if (len(separations) > 0):
        return(np.max(separations))

def checksourceImage(vis, img, radius=15):
    """
    Accepts a measurement set and an image of a calibrator and
    reports the difference between the imfitted position (in the central 30 pixel
    diameter) and the catalog position.
    radius: in pixels
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    if not os.path.exists(img):
        print "Could not find image."
        return
    info = getFitsBeam(img)
    synthBeam = (info[0]*info[1])**0.5
    sourcename = imageSource(img)
    imsize = info[5]  # size in RA direction
    region = 'circle[[%dpix , %dpix], %dpix ]' % (imsize/2,imsize/2, radius)
    imagefit = imfit(imagename=img, region=region)
    fitresults = imfitparse(imagefit)

    # Compare the Positions
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    fields = mymsmd.fieldsforname(sourcename)
    phasepos = mymsmd.phasecenter(fields[0])
    phasepos_obs = direction2radec(phasepos)
    print "Using field %d = %s = %s" % (fields[0], sourcename, phasepos_obs)
    if len(fields) > 1:
        for f in fields[1:]:
            pc = mymsmd.phasecenter(f) 
            if pc != phasepos_obs:
                print "Multiple fields with different directions: ", direction2radec(pc)
    mymsmd.close()
    if fitresults is not None:
        phasepos_fit = ','.join(fitresults.split()[:2])
        phasepos_diff = angularSeparationOfStrings(phasepos_obs,phasepos_fit,verbose=False, returnComponents=True)
        separation, longsep, latsep, longsepcosdec, posangle = phasepos_diff
        separation *= 3600
        latsep *= 3600
        longsepcosdec *= 3600
        line = "%s: Position difference = %s arcsec = %s synth.beam: (%+.3f,%+.3f) PA=%.1fdeg"%(sourcename, roundFiguresToString(separation,3), roundFiguresToString(separation/synthBeam,3), longsepcosdec, latsep, posangle)
    else:
        line = "%s: imfit failed" % (phase)
    print line

def checksourceOffset(workingdir, vis='', plotfile='', imfitlog=False, spw=''):
    """
    Takes a pipeline working directory and find all images of the checksource 
    and produces a plot showing the relative directions of the first science 
    target, the phase calibrator, and the checksource, and a vector
    showing the offset of the checksource from its catalog position, and
    text showing the RAO and DECO offsets.
    workingdir: path to pipeline working directory
    vis: alternate location for a measurement set to consult (ignores *_target.ms)
    Looks first for *chk*iter2.image; if not found, then *chk*iter1.image
    plotfile: default = img+'_offset.png'
    imfitlog: if True, then tell imfit to generate log files (*.imfit')
    spw: int or comma-delimited string, if specified, limit to this or these spws
    """
    return checksource.offset(workingdir, vis, plotfile, imfitlog, spw)

def elevationSeparationPhaseScience(vis, mymsmd='', verbose=False, returnSeparation='signed'):
    """
    Determines the first phase calibrator and computes mean elevation separation
    to each science target using elevationSeparationOfFields.
    returnSeparation: 'signed' or 'unsigned'
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "vis does not exist = ", ms
        return
    needToClose = False
    if mymsmd == '':
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    scienceTargets = getScienceTargets(vis, mymsmd=mymsmd)
    scienceTargets = np.unique(scienceTargets)
    phasecal = getScienceTargets(vis, 'CALIBRATE_PHASE#ON_SOURCE', mymsmd)
    nscience = len(scienceTargets)
    if nscience < 1:
        print "No science targets"
        if needToClose: mymsmd.close()
        return
    nphase = len(phasecal)
    if nphase < 1:
        print "No phase calibrator"
        if needToClose: mymsmd.close()
        return
    elif nphase > 1:
        print "Using first of %d phase targets" % nphase
    for i,science in enumerate(scienceTargets):
        sep = elevationSeparationOfFields(vis, [science, phasecal[0]], mymsmd=mymsmd, 
                                          exclusive=True, verbose=verbose, returnSeparation=returnSeparation)
        if sep > 0: 
            sense = "science lower than phasecal"
        else:
            sense = "science higher than phasecal"
        print "phase (%s) - science %d (%s): %.2f deg (%s)" % (phasecal[0], i,science,sep, sense)
    if needToClose: mymsmd.close()
    return sep

def elevationSeparationOfFields(vis, fields=[], verbose=True, value='mean',
                                exclusive=False, mymsmd='', returnSeparation=''):
    """
    Reads an ms and computes the mean of the per-scan elevation separation 
    of all combinations of fields, or if the fields parameter is given, only 
    those field names or IDs specified in the fields parameter, which can be 
    either a list of IDs or names, or an individual ID or name.
    value: 'all' (for per-scan mean) or 'mean' (for global mean)
           'all' only works if there is an equal number of scans per field
    exclusive: if True, then only report the separation between the listed fields
    returnSeparation: '', 'signed', 'unsigned'
    Returns:
    The field ID of the field with minimum separation from the specified field.
    if returnSeparation != '', then instead return the (minimum) separation 
       in degrees.  The sense of the subtraction is field2 - field1.
    -- Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "vis does not exist = ", ms
        return
    fieldTable = vis+'/FIELD'
    if (not os.path.exists(fieldTable)):
        print "FIELD table does not exist = ", fieldTable
        return
    if (type(fields) != list):
        fields = [fields]
    mytb = createCasaTool(tbtool)
    mytb.open(fieldTable)
    name = mytb.getcol('NAME')
    if verbose: print "Field =              Names                 Separations"
    sid = mytb.getcol('SOURCE_ID')
    pos = mytb.getcol('PHASE_DIR')
    mytb.close()
    pos = np.transpose(pos)
    nfields = len(pos)
    needToClose = False
    if mymsmd == '':
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    minSeparation = 1e9
    minSeparationSigned = 1e9
    fieldWithMinimumSeparation = 0
    if exclusive:
        myfieldlist = fields
    else:
        myfieldlist = range(nfields)
    for ith,i in enumerate(myfieldlist):
        if exclusive:
            myfieldlist2 = myfieldlist[ith+1:]
        else:
            myfieldlist2 = range(i+1,len(pos))
        for j in myfieldlist2:
            if (fields == [] or fields == [''] or (i in fields or j in fields) or
                (name[i] in fields or name[j] in fields)):
                result = listazel(vis, mymsmd.scansforfield(i),verbose=False,
                                  value=value, mymsmd=mymsmd)
                if result is None:
                    return
                az, el = result
                azj, elj = listazel(vis, mymsmd.scansforfield(j),verbose=False,
                                    value=value, mymsmd=mymsmd)
                if value == 'all':
                    if (len(azj) != len(az)):
                        print "value='all' only works if there are equal number of scans on the fields"
                        return
                degrees = np.mean(np.abs(elj-el))
                if (degrees < minSeparation):
                    minSeparation = degrees
                    minSeparationSigned = np.mean(elj-el)
                    if (i in fields):
                        fieldWithMinimumSeparation = j
                    elif (j in fields):
                        fieldWithMinimumSeparation = i
                arcsec = 3600*degrees
                if verbose:
                    print "%02d-%02d = %15s-%15s: %8g deg = %8g arcsec" % (i,j,name[i],name[j],degrees,arcsec)
    if needToClose: mymsmd.close()
    if verbose: print "minimum separation = %f degrees" % (minSeparation)
    if returnSeparation == 'signed':
        return(minSeparationSigned)
    elif returnSeparation == 'unsigned':
        return(minSeparation)
    else:
        return(fieldWithMinimumSeparation)

def angularSeparationOfScans(vis, scans=[], skipConsecutive=True,
                             observatory='ALMA', verbose=False, forceVM=False):
    """
    Reads an ms and computes the angular separation of each transition between
    scans.  If only one pair of scans is given, then return the angle in 
    degrees.
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "ms does not exist = ", vis
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (type(scans) != list):
        print "The scans parameter must be a list."
        return
    if (len(scans) == 1):
        print "You must give at least two scans (or none, which means all)."
        return
    if (casadef.casa_version >= casaVersionWithMSMD and forceVM==False):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        if (scans == []):
            scans = mymsmd.scannumbers()
            if (verbose): print "scans = ", scans
        fieldsForScans = []
        timesForScans = []
        for j in scans:
            fieldsForScans.append(mymsmd.fieldsforscan(j)[0]) # assume first field
            timesForScans.append(mymsmd.timesforscans(j))
            if (verbose):
                print "type(j) = ", str(type(j))
                print "type(tfs) = ", str(type(timesForScans[-1]))
                print "timesForScans (scan=%d)" % (int(j))
                print list(timesForScans[-1])  # will crash unless you convert to list
        mymsmd.close()
    else:
        vm = ValueMapping(vis)
        if (scans == []):
            scans = vm.uniqueScans
        fieldNamesForScans = vm.getFieldsForScans(scans)
        fieldsForScans = []
        for fn in fieldNamesForScans:
            fieldsForScans.append(vm.getFieldIdsForFieldName(fn)[0]) # assume first field
        timesForScans = vm.getTimesForScans(scans)
    if (verbose):
        print "%d scans = " % (len(scans)), scans
        print "%d fieldsForScans = " % (len(fieldsForScans)), fieldsForScans
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FIELD')
    name = mytb.getcol('NAME')
    print "                                      Angular separations"
    print "Scan slew         Field Names      on-the-sky (deg)  (arcsec)  dAz(deg) dEl(deg)"
    pos = mytb.getcol('PHASE_DIR')
    mytb.close()
    pos = np.transpose(pos)
    linesShown = 0
    for i in range(len(scans)-1):
        field = []
        field.append(fieldsForScans[i])
        field.append(fieldsForScans[i+1])
        radians = angularSeparationRadiansTuples(pos[field[0]][0], pos[field[1]][0])
        degrees = radians*180/np.pi
        if (degrees == 0 and skipConsecutive): continue
        linesShown += 1
        arcsec = 3600*degrees
        mjd = []
        mjd.append(np.max(timesForScans[i])/86400.)
        mjd.append(np.min(timesForScans[i+1])/86400.)
        if (verbose):
            print "Computing separation of field %d-%d at %.5f-%.5f" % (field[0], field[1], mjd[0], mjd[1])
        azel = []
        for j in range(2):
            azel.append(computeAzElFromRADecMJD(pos[field[j]][0],mjd[j],observatory=observatory,verbose=False))
        deltaaz = (azel[1][0]-azel[0][0])*180/np.pi
        deltael = (azel[1][1]-azel[0][1])*180/np.pi
        outline = "%02d-%02d = %14s to %14s %8g = %8g %+8.3f %+8.3f" % (scans[i],scans[i+1],name[fieldsForScans[i]],name[fieldsForScans[i+1]]+' '*(15-len(name[fieldsForScans[i+1]])),degrees,arcsec,deltaaz,deltael)
        if (verbose):
            outline += "  %.5f %.5f" % (mjd[0],mjd[1])
        print outline
    if (linesShown == 0):
        print "*** Specified scans are all on the same field position. ***"
        print "Set skipConsecutive=False to show all transitions."
    if (len(scans) == 2):
        return(degrees)

def medianFrequencyOfIntent(vis, intent='OBSERVE_TARGET#ON_SOURCE', verbose=False,
                            ignoreChanAvgSpws=True):
    """
    Returns the median of the mean frequency (in Hz) of the spws observed with
    the specified intent (default = OBSERVE_TARGET#ON_SOURCE).
    ignoreChanAvgSpws: if True, then ignore single channel spws, unless they 
                       are the only ones present!
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (casadef.casa_version >= casaVersionWithMSMD):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        try:
            if intent == '':
                spws = getNonWvrSpws(mymsmd)
            else:
                spws = mymsmd.spwsforintent(intent)
            spws = list(set(spws).difference(set(mymsmd.wvrspws())))
            myspws = spws[:]
            if (ignoreChanAvgSpws):
                spws = list(set(spws).difference(set(mymsmd.almaspws(chavg=True))))
                if (len(spws) == 0):
                    spws = list(set(myspws).difference(set(mymsmd.wvrspws())))
        except:
            spws = []
        if (len(spws) < 1):
            print "medianFrequencyOfIntent(): No spws with intent = '%s'" % (intent)
            print "intents = ", mymsmd.intents()
            mymsmd.close()
            return None
        if verbose: print "spws = ", spws
        freq = []
        for spw in spws:
            freq.append(mymsmd.meanfreq(spw))
            if verbose: print "spws %d = %f GHz" % (spw,freq[-1]*1e-9)
    else:
        vm = ValueMapping(vis)
        spws = vm.getSpwsForIntent(intent)
        if (len(spws) < 1):
            print "medianFrequencyOfIntent(): No spws with intent = '%s'" % (intent)
            return None
        if verbose: print "spws = ", spws
        freq = []
        for spw in spws:
            if (spw in vm.spwInfo.keys()):
                if verbose: print "spw = %d, " % (spw), vm.spwInfo[spw]
                freq.append(vm.spwInfo[spw]['meanFreq'])
    return(np.median(freq))

def rotationEuler(Pl, rLong, rLat):
    Ps = [np.cos(rLong)*np.cos(rLat)*Pl[0] - np.sin(rLong)*Pl[1] - np.cos(rLong)*np.sin(rLat)*Pl[2],
          np.sin(rLong)*np.cos(rLat)*Pl[0] + np.cos(rLong)*Pl[1] - np.sin(rLong)*np.sin(rLat)*Pl[2],
          np.sin(rLat)*Pl[0]                                     + np.cos(rLat)*Pl[2]]
    return(Ps)

def radecOffsetFileToRadec(filename, origin, raColumn=0, decColumn=1, velocityColumn=None,
                           intensityColumn=None, delimiter=' ', output='', rao=0, deco=0):
    """
    Converts an ASCII file of RA/Dec offsets in arcseconds into absolute coordinates.
    Lines beginning with # are ignored.
    filename: ASCII file
    origin: absolute coordinate for the offset origin as RADec string, e.g. 'hh:mm:ss.ssss +dd:mm:ss.sss'
    delimiter: the string to use to delimit the RA and Dec strings output
    rao, deco: additional offset to apply (in arcseconds)
    """
    f = open(filename,'r')
    lines = f.readlines()
    f.close()
    if output == '':
        output = filename + '.j2000'
    o = open(output,'w')
    for line in lines:
        if line[0] == '#': continue
        token = line.split()
        myrao = float(token[raColumn]) + rao
        mydeco = float(token[decColumn]) + deco
        if velocityColumn is not None:
            velocity = ' %s' % (token[velocityColumn])
        else:
            velocity = ''
        if intensityColumn is not None:
            intensity = ' %s' % (token[intensityColumn])
        else:
            intensity = ''
        o.write(radecOffsetToRadec(origin, myrao, mydeco, verbose=False, delimiter=delimiter)+velocity+intensity+'\n')
    o.close()
    print "Wrote ", output

def radecOffsetToRadec(radec, rao, deco, replaceDecDotsWithColons=True,
                       mas=False, prec=5, useEulerAngles=True, verbose=True,
                       delimiter=', ',hms=False):
    """
    Converts an absolute J2000 position and offset into a new absolute position.
    radec: either a string ('hh:mm:ss.s dd:mm:ss') or a tuple of radians
    rao, deco: offset in arcseconds (floating point values)
    replaceDotsWithColons: change CASA's Dec string from xx.yy.zz to xx:yy:zz
    mas: if True, then treat rao and deco as milliarcsec
    prec: desired number of digits of precision after the seconds decimal point
    delimiter: string to use between RA and Dec
    useEulerAngles: if True, then use the expression of the control system;
      if False, then use the small-angle formula:   RAnew = RA + deltaRA/cos(Dec)
    hms: if True, then output HHhMMmSS.Ss +DDdMMmSS.Ss instead of using colons
    Returns: a sexagesimal string
    """
    if (type(radec) == str or type(radec) == np.string_):
        rarad, decrad = radec2rad(radec)
    elif (type(radec) == list):
        rarad, decrad = radec
    else:
        print "type(radec) = ", type(radec)
        print "radec must be either a string ('hh:mm:ss.s dd:mm:ss') or a list in radians [ra,dec]"
        return
    if (mas):
        rao *= 0.001
        deco *= 0.001
    rao = np.radians(rao/3600.)
    deco = np.radians(deco/3600.)
    if useEulerAngles:
        Pl = [np.cos(rao)*np.cos(deco), np.sin(rao)*np.cos(deco), np.sin(deco)]
        Ps = rotationEuler(Pl, rarad, decrad)
        newrarad = np.arctan2(Ps[1], Ps[0])
        if (newrarad < 0): newrarad += 2*np.pi
        newdecrad = np.arcsin(Ps[2])
    else:
        newrarad = rarad + rao/np.cos(decrad)
        newdecrad = decrad + deco
    mystring = rad2radec(newrarad, newdecrad, replaceDecDotsWithColons=replaceDecDotsWithColons,
                         prec=prec, verbose=verbose, delimiter=delimiter, hmsdms=hms)
    return(mystring)
           
def angularSeparationOfAllPlanetsFromSun(date='', observatory=JPL_HORIZONS_ID['ALMA'], 
                                         useJPL=True, verbose=False, extraobjects=['Pluto']):
    """
    Computes the current angular separation of the major planets from the Sun
    (in degrees) at 0 UT on the specified date.
    -Todd Hunter
    """
    separation = {}
    if date=='':
        date = getCurrentDate()
    for planet in ['Mercury','Venus','Mars','Jupiter','Saturn','Uranus','Neptune'] + extraobjects:
        separation[planet] = degrees(angularSeparationOfPlanets('Sun',planet,date,observatory,useJPL))
    return separation

def angularSeparationOfPlanets(planet1='', planet2='', date='',
             observatory=JPL_HORIZONS_ID['ALMA'], useJPL=True, target=None,
             returnComponents=False, verbose=False, vis='', bodyForScan='',
             frequency=None, diameter=None, returnLimbSeparation=False):
    """
    Computes the current angular separation of two planets at 0 UT on the 
    current date, or the exact specified date string.  Default viewing 
    location is ALMA.
    If 'target' is specified as a valid RA/Dec, then the separation between 
    it and planet1 will be computed.
    If 'vis' is specified, then it will use the time of the first scan on the
    target, or the start time of the ms if neither target is not found.
    'bodyForScan' is passed to both calls to planet() to pick time of first scan
    If 'frequency' and 'diameter' are specified, these are passed to
       primaryBeamArcsec() to compute the separation in beam diameters.
    If 'vis' is specified, it will use the median dish diameter and median
       of the mean frequencies of the OBSERVE_TARGET spws.
    Required format for target:  HH[:MM:SS.S]  [+]DD[:MM:SS.S]
    date: one possible format of the date string is: '2011-10-31 11:59:59'
          or simply '2011-10-31' for 0:00 UT. A list of allowed formats for date
          is at:   http://ssd.jpl.nasa.gov/?horizons_doc#time
          
    Returns: the separation value in radians.  If the primary beam is known, it
      also returns the value in primary beam units, and a Boolean value telling
      whether it is safe to use the object as amplitude calibrator (>2*beam+25'').
    returnComponents: if True, then compute angular separation in both
         coordinates and the position angle of the separation vector on the sky
    Todd Hunter
    """
    if (planet1 == '' or planet2 == ''):
        if (vis == ''):
            print "You must either specify planet1 and planet2, or vis (or all three)"
            return
        else:
            fields = getFields(vis)
            fieldsUpperCase = [x.upper() for x in fields]
            checkObjects = ['TITAN','CALLISTO','GANYMEDE','IO','EUROPA']
            for object in checkObjects:
                if (object in fieldsUpperCase):
                    planet1 = object
                    bodyForScan = object
                    break
            if (planet1 == ''):
                print "None of these satellites were observed: ", checkObjects
                return
            if (planet1 == 'TITAN'):
                planet2 = 'SATURN'
            else:
                planet2 = 'JUPITER'
    data1 = planet(planet1, date=date, observatory=observatory, useJPL=useJPL, verbose=verbose,vis=vis, bodyForScan=bodyForScan)
    if (data1 == None): return
    if (target == None):
        data2 = planet(planet2, date=date, observatory=observatory, useJPL=useJPL, verbose=verbose,vis=vis, bodyForScan=bodyForScan)
    else:
        results = target.split()
        if (len(results) != 2):
            print "Required format for target:  HH[:MM:SS.S]  [+]DD[:MM:SS.S]"
            return
        ra,dec = results
        if (ra.find(':') > 0):
            ratokens = ra.split(':')
            ra = float(ratokens[0])
            if (ratokens > 1):
                ra += float(ratokens[1])/60.
            if (ratokens > 2):
                ra += float(ratokens[2])/3600.
        else:
            print "Required format for target:  HH[:MM:SS.S]  [+]DD[:MM:SS.S]"
            return
        
        if (dec.find(':') > 0):
            dectokens = dec.split(':')
            dec = abs(float(dectokens[0]))
            if (dectokens > 1):
                dec += float(dectokens[1])/60.
            if (dectokens > 2):
                dec += float(dectokens[2])/3600.
            if (dectokens[0].find('-') >= 0):
                dec = -dec
        else:
            print "Required format for target:  HH[:MM:SS.S]  [+]DD[:MM:SS.S]"
            return
        data2 = {'directionRadians': [float(ra)*pi/12.0, float(dec)*pi/180]}
#    print data1['directionRadians'][0], data1['directionRadians'][1], data2['directionRadians'][0], data2['directionRadians'][1]
    result = angularSeparationRadians(data1['directionRadians'][0], data1['directionRadians'][1], 
                                      data2['directionRadians'][0], data2['directionRadians'][1], returnComponents)
    if (returnComponents):
        rad, raRadians, decRadians, raRadiansCosDec = result
        positionAngle = 90-np.degrees(math.atan2(decRadians, raRadiansCosDec))
        print "RA Separation: radian = %g, degrees = %f, arcsec = %f" % (raRadiansCosDec, 
                                                                         np.degrees(raRadiansCosDec),
                                                                         np.degrees(raRadiansCosDec)*3600)
        print "Dec Separation: radian = %g, degrees = %f, arcsec = %f" % (decRadians, 
                                                                          np.degrees(decRadians),
                                                                          np.degrees(decRadians)*3600)
        print "Position angle: %g deg E of N" % (positionAngle)
    else:
        rad = result
    print "Separation of centers = %g rad = %g deg = %g arcsec" % (rad, rad*180/math.pi, rad*3600*180/math.pi)
    print "RA separation of centers = %g hours" % (12*(data1['directionRadians'][0] - data2['directionRadians'][0])/math.pi)
    radLimbs = rad-np.radians(0.5*(data1['angularDiameter']+data2['angularDiameter'])/3600.)
    print "Separation of limbs = %g rad = %g deg = %g arcsec" % (radLimbs, radLimbs*180/math.pi, radLimbs*3600*180/math.pi)
    if (returnLimbSeparation):
        rad = radLimbs
    if (vis != '' or (frequency!=None and diameter!=None)):
        if (vis != ''):
            primaryBeam = primaryBeamArcsec(vis=vis, showEquation=False)
        else:
            primaryBeam = primaryBeamArcsec(frequency=frequency, diameter=diameter, showEquation=False)
        beams = rad*3600*180/math.pi / primaryBeam
        print "%.1f primary beams" % (beams)
        separationArcsec = rad*3600*180/math.pi
        if (separationArcsec > 2*primaryBeam + 25):  # 25 is the kludged value used by CSV for planet half-diameter
            safe = True
        else:
            safe = False
        return(result, beams, safe)
    else:
        return(result)
    
def angularSeparationOfDirections(dir1,dir2,returnComponents=False):
    """
    Accepts two direction dictionaries and returns the separation in radians.
    It computes great circle angle using the Vincenty formula.
    --Todd Hunter
    """
    rad = angularSeparationRadians(dir1['m0']['value'], dir1['m1']['value'], dir2['m0']['value'], dir2['m1']['value'],returnComponents)
    return(rad)

def angularSeparationOfDirectionsArcsec(dir1,dir2,returnComponents=False):
    """
    Accepts two direction dictionaries and returns the separation in arcsec.
    It computes great circle angle using the Vincenty formula.
    Todd Hunter
    """
    retval = angularSeparationOfDirections(dir1, dir2, returnComponents)
    if (returnComponents):
        retval = np.array(retval) * 180*3600 / np.pi
    else:
        retval *= 180*3600 / np.pi
    return(retval)

def angularSeparationRadiansTuples(pos0,pos1,returnComponents=False):
    """
    Computes the great circle angle between two celestial coordinates.
    using the Vincenty formula (from wikipedia) which is correct for all
    angles, as long as you use atan2() to handle a zero denominator.  
       See  http://en.wikipedia.org/wiki/Great_circle_distance
    Input and output are in radians.  The input must be in the form of
    tuples: [ra0,dec0], [ra1,dec1], such as read from the FIELD table.
    It also works for the az,el coordinate system.
    returnComponents=True will return: [separation, raSeparation, decSeparation, raSeparationCosDec]
    See also angularSeparation() and angularSeparationRadians().
    """
    return(angularSeparationRadians(pos0[0],pos0[1], pos1[0],pos1[1],returnComponents))
           
def angularSeparationRadians(ra0,dec0,ra1,dec1,returnComponents=False,returnPositionAngle=False):
  """
  Computes the great circle angle between two celestial coordinates.
  using the Vincenty formula (from wikipedia) which is correct for all
  angles, as long as you use atan2() to handle a zero denominator.  
     See  http://en.wikipedia.org/wiki/Great_circle_distance
  Input and output are in radians.  It also works for the az,el coordinate system.
  returnComponents=True will return: [separation, raSeparation, decSeparation, raSeparationCosDec]
     if returnPositionAngle is also True, it will return:
        [separation, raSeparation, decSeparation, raSeparationCosDec, positionAngleRadians]
  See also angularSeparation()
  -- Todd Hunter
  """
  result = angularSeparation(ra0*180/math.pi, dec0*180/math.pi, ra1*180/math.pi, dec1*180/math.pi,returnComponents,returnPositionAngle)
  if (returnComponents):
      return(np.radians(np.array(result)))
  else:
      return(np.radians(result))

def angularSeparationOfStringsFromFile(filename,verbose=True,arcsec=False,kpc=None):
    """
    Reads a text file and sends each line to angularSeparationOfStrings after
    stripping off the leading source name.  Required format:
        sourcename RA1 Dec1 RA2 Dec2 optional_comments
    where the sexagesimal components of RA/Dec can be either colon-delimited
    or space-delimited.
    Returns: an array of the separations in degrees, unless arcsec==True.
    if kpc is specified, then return the separation in AU
    - Todd Hunter
    """
    if (os.path.exists(filename) == False):
        print "File not found."
        return
    f = open(filename,'r')
    sep = []
    returnComponents = False  # True will return more than one value
    for line in f.readlines():
        tokens = line.split()
        line = ' '.join(tokens[1:]) # pull off the leading name
        line = line.replace(':',' ').replace('&',' ')
        tokens = line.split()
        sep.append(angularSeparationOfStrings(' '.join(tokens[:6]), ' '.join(tokens[6:12]),
                                              returnComponents,verbose))
    f.close()
    result = np.array(sep)
    if (arcsec):
        result *= 3600
    elif (kpc is not None):
        result *= 3600*kpc*1000
    return(result)

def pickRandomErrors(nvalues=1):
    """
    Picks a series of random values from a Gaussian distribution with mean 0 and standard 
    deviation = 1 and returns it as an array.
    -Todd Hunter
    """
    p = []
    for i in range(nvalues):
        p.append(pickRandomError())
    return(np.array(p))

def pickRandomError(seed=None):
    """
    Picks a random value from a Gaussian distribution with mean 0 and standard deviation = 1.
    seed: if specified, then first reseed with random.seed(seed)
    -Todd Hunter
    """
    w = 1.0
    if seed is not None:
        random.seed(seed)
    while ( w >= 1.0 ):
      x1 = 2.0 * random.random() - 1.0
      x2 = 2.0 * random.random() - 1.0
      w = x1 * x1 + x2 * x2

    w = np.sqrt( (-2.0 * np.log( w ) ) / w )
    y1 = x1 * w
    y2 = x2 * w
    return(y1)

def angularSeparationOfPB(vis, img, fieldname='', verbose=False):
    """
    Given a measurement set and a CASA image of the primary beam,
    computes the offset between the beam center and the phase center.
    vis: measurement set
    img: CASA image of the primary beam
    fieldname: field name or integer ID or string ID; if blank, try to read it from img header
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    if not os.path.exists(img):
        print "Could not find primary beam image."
        return
    if fieldname == '':
        fieldname = imhead(img, mode='get', hdkey='object')
        if fieldname == '':
            fieldname = getScienceTargets(vis)
            if len(fieldname) == 0:
                print "No object name in image header and no science target in dataset. Please set fieldname parameter"
                return
            fieldname = fieldname[0]
        if verbose:
            print "Got fieldname = ", fieldname
    iPeak = imagePeak(img, returnPosition='radec', verbose=verbose)[1]
    radec = getRADecForField(vis, fieldname, hms=True, verbose=verbose)
    separation, longsep, latsep, longsepcosdec, pa = angularSeparationOfStrings(iPeak, radec,
                                                                                returnComponents=True, verbose=verbose)
    result = getFitsBeam(img) #, omitBeam=True)
    print "   RA separation = %g deg = %g arcsec = %g pixels" % (longsepcosdec, longsepcosdec*3600, longsepcosdec*3600/abs(result[3]))
    print "  Dec separation = %g deg = %g arcsec = %g pixels" % (latsep, latsep*3600, latsep*3600/abs(result[4]))
    print "Total separation = %g deg = %g arcsec = %g pixels" % (separation, separation*3600, separation*3600/result[4])
                                         

def angularSeparationOfStrings(radec0,radec1='',returnComponents=False,verbose=True,
                               uncertainties=None,date=None,observatory='ALMA',
                               returnArcsec=False, searchFluxVerbose=False):
    """
    Accepts input of the form: '23:29:17.70000, -47:30:19.211595'
                            or '23:29:17.70000  -47:30:19.211595'
                            or '23:29:17.70000, -47.30.19.211595'
                            or '23:29:17.70000  -47.30.19.211595'
                            or '23 29 17.70000  -47 30 19.211595'
                            or '23h29m17.70000s -47d30m19.211595'
    and computes the angular separation.  Returns it in degrees.
    Leading spaces are removed from both coordinates.
    If radec1 is not specified, then radec0 must contain 4 values: 'ra0 dec0 ra1 dec1'
    If the first character is J/j/N/n/B/b or the second character is C/c, then it 
       calls searchFlux to translate the source name into an RA/Dec string.
    If a date is specified, it also converts the input
         coordinates to Az/El, then computes the deltaAz and deltaEl
    date: can be specified as a string, e.g. 2014-03-15T10:24:48.417
          or a float, which is interpreted as MJD
    If returnComponents==True, then it also returns the separation in 
       longitude and latitude, the longitude separation with cos(averageDec) applied,
       as well as the position angle (in degrees).
    If returnArcsec=True, return all separations in arcsec
    If uncertainties is a list of 4 numbers, then run a Monte-Carlo simulation 
      using these values as ra0unc, dec0unc, ra1unc, dec1unc
    """
    radec0 = radec0.replace('&',' ')  # allow pasting from Latex tables
    if radec1 == '':
        if len(radec0.split()) == 4:
            radec1 = ' '.join(radec0.split()[2:])
            radec0 = ' '.join(radec0.split()[:2])
        else:
            print "You must either specify radec1, or give 4 values in radec0."
            return
    radec0 = radec0.replace('?','-')  # openoffice cut&paste mangles -- into ?
    radec0 = radec0.replace(';',' ')  # allow pasting from VLA Obsprep tool import/export files
    radec0 = radec0.replace('h',':')  # allow NED output table format
    radec0 = radec0.replace('d',':')  # allow NED output table format
    radec0 = radec0.replace('m',':')  # allow NED output table format
    radec0 = radec0.replace('s',':')  # allow NED output table format
    radec1 = radec1.replace('&',' ')  # allow pasting from Latex tables
    radec1 = radec1.replace('?','-')  # openoffice cut&paste mangles -- into ?
    radec1 = radec1.replace(';',' ')  # allow pasting from VLA Obsprep tool import/export files
    radec1 = radec1.replace('h',':')  # allow NED output table format
    radec1 = radec1.replace('d',':')  # allow NED output table format
    radec1 = radec1.replace('m',':')  # allow NED output table format
    radec1 = radec1.replace('s',':')  # allow NED output table format
    radec0 = radec0.strip()
    radec1 = radec1.strip()
    if (radec0[0].upper() in ['J','B','N'] or radec0[1].upper() in ['C']):
        radec0 = searchFlux(radec0, returnPosition=True, verbose=searchFluxVerbose)
    if (radec1[0].upper() in ['J','B','N'] or radec1[1].upper() in ['C']):
        radec1 = searchFlux(radec1, returnPosition=True, verbose=searchFluxVerbose)
    if (radec0.find(',')>0):
        (ra,dec) = radec0.split(',')
    else:
        tokens = radec0.split()
        if (len(tokens) == 2):
            (ra,dec) = tokens
        elif (len(tokens) == 6):
            ra = tokens[0] + ':' + tokens[1] + ':' + tokens[2]
            dec = tokens[3] + ':' + tokens[4] + ':' + tokens[5]
        else:
            print "Confusing input for first position.  Need either 2 or 6 tokens"
            return
    (h,m,s) = ra.lstrip().split(':')
    hours = float(h)+float(m)/60. + float(s)/3600.
    ra0 = hours*15

    if (dec.find(':')>0):
        (d,m,s) = dec.lstrip().split(':')
    else:
        try:
            (d,m,s) = dec.lstrip().split('.')
        except:
            (d,m,s,sfraction) = dec.lstrip().split('.')
            s = s+'.'+sfraction
    dec0 = abs(float(d))+float(m)/60.+float(s)/3600.
    if (dec.lstrip().find('-') == 0):
        dec0 = -dec0

    if (radec1.find(',') > 0):
        (ra,dec) = radec1.split(',')
    else:
        tokens = radec1.split()
        if (len(tokens) == 2):
            (ra,dec) = tokens
        elif (len(tokens) == 6):
            ra = tokens[0] + ':' + tokens[1] + ':' + tokens[2]
            dec = tokens[3] + ':' + tokens[4] + ':' + tokens[5]
        else:
            print "Confusing input for second position.  Need either 2 or 6 tokens"
            return
    (h,m,s) = ra.lstrip().split(':')
    hours = float(h)+float(m)/60. + float(s)/3600.
    if (dec.find(':') > 0):
        (d,m,s) = dec.lstrip().split(':')
    else:
        try:
            (d,m,s) = dec.lstrip().split('.')
        except:
            (d,m,s,sfraction) = dec.lstrip().split('.')
            s = s + '.' + sfraction
    dec1 = abs(float(d))+float(m)/60.+float(s)/3600.
    if (dec.lstrip().find('-') == 0):
        dec1 = -dec1
    ra1 = hours*15
#    print ra0/15., dec0, ra1/15., dec1
    if (returnComponents):
        if (uncertainties is not None):
            if (len(uncertainties) != 4):
                print "uncertainties must be a list of 4 values in arcsec"
                return
            trials = 1000
        else:
            trials = 1
            dra0 = 0
            dra1 = 0
            ddec0 = 0
            ddec1 = 0
        degArray = []
        raArray = []
        decArray = []
        positionAngleArray = []
        for t in range(trials):
            if (uncertainties is not None):
                dra0 = uncertainties[0]*pickRandomError()/3600.
                dra1 = uncertainties[1]*pickRandomError()/3600.
                ddec0 = uncertainties[2]*pickRandomError()/3600.
                ddec1 = uncertainties[3]*pickRandomError()/3600.
            degrees, radegrees, decdegrees, radegreesCosDec = angularSeparation(ra0+dra0,dec0+ddec0,ra1+dra1,dec1+ddec1,returnComponents)
            positionAngle = 90-math.atan2(decdegrees*math.pi/180., radegreesCosDec*math.pi/180.)*180/math.pi
            if (positionAngle > 180):
                positionAngle -= 360
            if (positionAngle < -180):
                positionAngle += 360
            retval = degrees, radegrees, decdegrees, radegreesCosDec, positionAngle
            raArray.append(radegrees)
            decArray.append(decdegrees)
            degArray.append(degrees)
            positionAngleArray.append(positionAngle)
            if (verbose):
                print "RA Separation: radian = %g, degrees = %f, arcsec = %f" % (radegreesCosDec*math.pi/180., 
                                                                                 radegreesCosDec, radegreesCosDec*3600)
                print "Dec Separation: radian = %g, degrees = %f, arcsec = %f" % (decdegrees*math.pi/180., 
                                                                                  decdegrees, decdegrees*3600)
                print "Position angle: %g deg E of N" % (positionAngle)
        if (trials > 1):
            retval = np.median(degArray), np.median(raArray), np.median(decArray), np.median(positionAngleArray), np.std(degArray), np.std(positionAngleArray)
            print "separation = %f +- %f deg, position angle = %f +- %f deg" % (np.median(degArray), np.std(degArray), np.median(positionAngleArray), np.std(positionAngleArray))
            print "separation = %f +- %f arcsec, position angle = %f +- %f deg" % (3600*np.median(degArray), 3600*np.std(degArray), np.median(positionAngleArray), np.std(positionAngleArray))
            
    else:
        degrees = angularSeparation(ra0,dec0,ra1,dec1,returnComponents)
        retval = degrees
    if (verbose):
        print "Separation: radian = %g, degrees = %f, arcsec = %f" % (degrees*math.pi/180., 
                                                                      degrees, degrees*3600)
    if (date is not None):
        if (type(date) == str):
            mjd = dateStringToMJD(date)
        else:
            mjd = date
        # convert ra/decs to az/el, then recompute separation
        az0,el0 = computeAzElFromRADecMJD([ra0*np.pi/180.,dec0*np.pi/180.],mjd,observatory)
        az1,el1 = computeAzElFromRADecMJD([ra1*np.pi/180.,dec1*np.pi/180.],mjd,observatory)
        total = angularSeparationRadians(az0,el0,az1,el1)
        print "Initial az/el = %f, %f deg" % (az0*180/np.pi, el0*180/np.pi)
        print "Delta azimuth = %f deg,  Delta elevation = %f deg  (total = %f deg)" % ((az1-az0)*180/np.pi, (el1-el0)*180/np.pi, total*180/np.pi) 
    if returnArcsec:
        retval = np.array(retval)
        retval *= 3600
        if (returnComponents):
            # convert degrees*3600 back to degrees
            retval[-1] = retval[-1]/3600.
    return(retval)


def angularSeparation(ra0,dec0,ra1,dec1, returnComponents=False, 
                      returnPositionAngle=False, verbose=False):
  """
  Computes the great circle angle between two celestial coordinates.
  using the Vincenty formula (from wikipedia) which is correct for all
  angles, as long as you use atan2() to handle a zero denominator.  
     See  http://en.wikipedia.org/wiki/Great_circle_distance
  ra,dec must be given in degrees, either as floating point values or 
        sexagesimal strings.  Output will be in floating point degrees.
  It also works for the az,el coordinate system.
  Component separations are field_0 minus field_1.
  See also angularSeparationRadians()
  returnComponents: if True, then also compute angular separation in both
         coordinates, and if returnPositionAngle is True, then also return
         the position angle of the separation vector on the sky (in degrees)
  -- Todd Hunter
  """
  if type(ra0) == str:
      ra0 = dmsToDegrees(ra0)
      if verbose: print "ra0 = ", ra0
  if type(ra1) == str:
      ra1 = dmsToDegrees(ra1)
      if verbose: print "ra1 = ", ra1
  if type(dec0) == str:
      dec0 = dmsToDegrees(dec0)
      if verbose: print "dec0 = ", dec0
  if type(dec1) == str:
      dec1 = dmsToDegrees(dec1)
      if verbose: print "dec1 = ", dec1
  ra0 *= math.pi/180.
  dec0 *= math.pi/180.
  ra1 *= math.pi/180.
  dec1 *= math.pi/180.
  deltaLong = ra0-ra1
  argument1 = (((math.cos(dec1)*math.sin(deltaLong))**2) +
               ((math.cos(dec0)*math.sin(dec1)-math.sin(dec0)*math.cos(dec1)*math.cos(deltaLong))**2))**0.5
  argument2 = math.sin(dec0)*math.sin(dec1) + math.cos(dec0)*math.cos(dec1)*math.cos(deltaLong)
  angle = math.atan2(argument1, argument2) / (math.pi/180.)
  if (angle > 360):
      angle -= 360
  if (returnComponents):
      cosdec = math.cos((dec1+dec0)*0.5)
      radegreesCosDec = np.degrees(ra0-ra1)*cosdec
      radegrees = np.degrees(ra0-ra1)
      decdegrees = np.degrees(dec0-dec1)
      if (radegrees > 360):
          radegrees -= 360
      if (radegreesCosDec > 360):
          radegreesCosDec -= 360
      if (decdegrees > 360):
          decdegrees -= 360
      if (radegrees < -180):
          radegrees += 360
          radegreesCosDec = (np.degrees(ra0-ra1)+360)*cosdec
      if returnPositionAngle:
          positionAngle = np.degrees(-math.atan2(np.radians(decdegrees), np.radians(radegreesCosDec)))
          retval = angle,radegrees,decdegrees, radegreesCosDec, positionAngle
      else:
          retval = angle,radegrees,decdegrees, radegreesCosDec
  else:
      retval = angle
  return(retval)

def sun(observatory='' ,mjdsec='', mjd='', date=None, verbose=False):
    """
    Determines the az/el of the Sun for the specified observatory and specified
    time in MJD seconds (or MJD) or date/time string.  
       Any of these formats is valid: 2011/10/15 05:00:00
                                      2011/10/15-05:00:00
                                      2011-10-15 05:00:00
                                      2011-10-15T05:00:00
                                      2011-Oct-15T05:00:00
    If no information is given, it defaults to ALMA and 'now'.
    Returns az, el in degrees.
    Other observatories available:
      ARECIBO  ATCA  BIMA  CLRO  DRAO  DWL  GB  GBT  GMRT  IRAM PDB  IRAM_PDB
      JCMT  MOPRA  MOST  NRAO12M  NRAO_GBT  PKS  SAO SMA  SMA  VLA  VLBA  WSRT
      ATF  ATA  CARMA  ACA  OSF  OVRO_MMA  EVLA  ASKAP  APEX  SMT  NRO  ASTE
      LOFAR  MeerKAT  KAT-7  EVN  LWA1  PAPER_SA  PAPER_GB  e-MERLIN  MERLIN2

    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/Sun
    -- Todd Hunter
    """
    printCurrent = False
    if (mjdsec=='' and mjd=='' and date==None):
        printCurrent = True
        mjdsec = getCurrentMJDSec()
    elif (mjdsec=='' and date==None):
        mjdsec = double(mjd)*86400
    elif (mjd=='' and date==None):
        mjdsec = double(mjdsec)
    elif (mjd=='' and mjdsec==''):
        mjdsec = dateStringToMJDSec(date)
    else:
        print "Too many dates specified"
        return

    mjd = mjdsec/86400.
    datestring = mjdToUT(mjd)
    if (observatory==''):
        observatory = 'ALMA'
    try:
        [latitude,longitude,observatory] = getObservatoryLatLong(observatory)
        if (printCurrent):
            print "Found location for %s: %f, %f degrees" % (observatory,longitude,latitude)
    except:
        print "Did not find this observatory=%s, using ALMA instead." % (observatory)
        
    (az,el) = ComputeSolarAzElLatLong(mjdsec,latitude,longitude)
    if (printCurrent):
        print "At %s, the Sun is currently at azim=%.3f, elev=%.3f" % (observatory,az,el)
    if verbose:
        print "MJD = %f = %f seconds = %s" % (mjd, mjdsec, datestring)
    return(az,el)

def checkGeodetic():
    """
    Checks the final date in the geodetic tables of CASA.
    -Todd Hunter
    """
    tables=['IERSeop2000', 'IERSeop97', 'IERSpredict', 'TAI_UTC']
    mytb = createCasaTool(tbtool)
    print "Checking casa %s r%s = %s" % (casadef.casa_version, casadef.subversion_revision, casadef.__file__)
    mypath = os.getenv("CASAPATH").split()[0] + "/data/geodetic/" 
    print "Date of final entry in table in directory %s:" % (mypath)
    for t in tables:
        mytb.open(mypath + t)
        mjd = mytb.getcol('MJD')
        descriptor = ''
        if (t == 'TAI_UTC'):
            descriptor = '(most recent leap second)'
        elif (t == 'IERSpredict'):
            if (mjd[-1] < getMJD()):
                print "(out of date!!)"
        print "%12s:  %.2f = %s (Chilean time) %s" % (t, mjd[-1], mjdToChileTime(mjd[-1]), descriptor)
        mytb.close()

def listAvailableObservatories():
    """
    Lists the observatories known to CASA.
    Todd Hunter
    """
    repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
    try:
        mytb = createCasaTool(tbtool)
        mytb.open(repotable)
        Name = mytb.getcol('Name')
        ns = ''
        names = ''
        for N in Name:
            names += N + ","
            ns += N + ", "
            if (len(ns) > 70):
                print ns
                ns = ''
        mytb.close()
        return names.strip(',').split(',')
    except:
        print "Could not open table = %s" % (repotable)

def getObservatoryFromConfig(config):
    """
    Reads the observatory name from a CASA antenna configuration file.
    -Todd Hunter
    """
    config = findConfigurationFile(config)
    f = open(config,'r')
    lines = f.readlines()
    observatory = ''
    for line in lines:
        loc = line.find('observatory=')
        if loc > 0:
            observatory = line.split('observatory=')[1]
    observatory = observatory.rstrip('\n')
    return observatory

def getObservatoryLongitude(observatory='',verbose=False):
    """
    Opens the casa table of known observatories and returns the latitude and longitude
    in degrees for the specified observatory name string.
    observatory: string name, JPL integer, or integer string  (e.g. 'ALMA' == -7)
    -Todd Hunter
    """
    result = getObservatoryLatLong(observatory, verbose)
    if (len(result[0]) == 0):
        print "Invalid observatory name"
        listAvailableObservatories()
        return
    lat, longitude, name = result
    return(longitude[0])

def getObservatoryAltitude(observatory='ALMA'):
    """
    Opens the casa table of known observatories and returns the height above sea
    level in meters.  
    table path: os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories
    if Type = WGS84, then the Height column entry is used directly
    if Type = ITRF, then the X,Y,Z column entries are compared to ellipsoid
    """
    mytb = createCasaTool(tbtool)
    repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
    try:
        mytb.open(repotable)
    except:
        print "Could not open table, returning height of ALMA."
        mytb.close()
        return(5056.8)
    Name = mytb.getcol('Name')
    Height = mytb.getcol('Height')
    Type = mytb.getcol('Type')
    X = mytb.getcol('X')
    Y = mytb.getcol('Y')
    Z = mytb.getcol('Z')
    mytb.close()
    matches = np.where(np.array(Name)==observatory)
    if (len(matches[0]) < 1 and str(observatory).find('500') < 0):
        print "Names = ", Name
        print "Did not find observatory='%s', using ALMA value instead." % (observatory)
        return(5056.8)
    myType = Type[matches[0]][0]
    x = X[matches[0]][0]
    y = Y[matches[0]][0]
    z = Z[matches[0]][0]
    if myType == 'WGS84':
        height = Height[matches[0]][0]
        print "Reading from height column; fyi: geocentric position: ", x,y,z
    elif myType == 'ITRF':
        print "Computing from geocentric position: ",x,y,z
        height = geocentricXYZToEllipsoidalHeight(x,y,z)
        if (height > 6e3) and (observatory.find('SMA') >= 0):
            x = -5464555.493
            y = -2492927.989
            z =  2150797.176
            print "Illogical position for SMA.  Using mm VLBI position instead: ",x,y,z
            height = geocentricXYZToEllipsoidalHeight(x,y,z)
    else:
        height = 0
        print "Unrecognized coordinate type: ", myType
    return(height)

def getObservatoryLatLong(observatory='',verbose=False, radians=False):
     """
     Opens the casa table of known observatories and returns the latitude and longitude
     in degrees for the specified observatory name string.
     observatory: string name, JPL integer, or integer string  (e.g. 'ALMA' == -7)
     -- Todd Hunter
     """
     if (observatory == ''):
        listAvailableObservatories()
        return
     repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
     try:
        tb.open(repotable)
     except:
        print "Could not open table = %s, returning ALMA coordinates in au instead" % (repotable)
        longitude = ALMA_LONGITUDE
        latitude = ALMA_LATITUDE
        observatory = 'ALMA'
        if radians:
            latitude = np.radians(latitude)
            longitude = np.radians(longitude)
        return([latitude,longitude,observatory])
     if (type(observatory) == 'int' or str(observatory) in JPL_HORIZONS_ID.values()):
         if (str(observatory) in JPL_HORIZONS_ID.values()):
             observatory = JPL_HORIZONS_ID.keys()[JPL_HORIZONS_ID.values().index(str(observatory))]
             if (verbose):
                 print "Recognized observatory = %s" % observatory
             if (observatory == 'MAUNAKEA'): observatory = 'SMA'
             if (observatory == 'OVRO'): observatory = 'OVRO_MMA'
         else:
             print "Did not recognize observatory='%s' in %s, using ALMA instead." % (observatory,str(JPL_HORIZONS_ID.values()))
             observatory = 'ALMA'
#     else:
#         print "%s is not in %s" % (observatory, str(JPL_HORIZONS_ID.values()))
             
     Name = tb.getcol('Name')
     matches = np.where(np.array(Name)==observatory)
     if (len(matches) < 1 and str(observatory).find('500') < 0):
         print "Names = ", Name
         print "Did not find observatory='%s', using ALMA value in au instead." % (observatory)
         for n in Name:
             if (n.find(observatory) >= 0):
                 print "Partial match: ", n
         observatory = 'ALMA'
         longitude = ALMA_LONGITUDE
         latitude = ALMA_LATITUDE
     elif (str(observatory).find('500') >= 0 or
           str(observatory).lower().find('geocentric') >= 0):
         observatory = 'Geocentric'
         longitude = 0
         latitude = 0
     else:
         longitude = tb.getcol('Long')[matches[0]]
         latitude = tb.getcol('Lat')[matches[0]]
     tb.close()
     if radians:
         latitude = np.radians(latitude)
         longitude = np.radians(longitude)
     return([latitude,longitude,observatory])

def ComputeSolarAzEl(mjdsec=None, observatory='ALMA'):
  """
  Return the az and el of the Sun in degrees for the specified
  time (default=now).  Default observatory is ALMA. See also ComputeSolarRADec().
  Todd Hunter
  """
  if (mjdsec==None):
      mjdsec = getCurrentMJDSec()
  [latitude,longitude,obs] = getObservatoryLatLong(observatory) 
  return(ComputeSolarAzElLatLong(mjdsec,latitude,longitude))

def ComputeSolarAzElLatLong(mjdsec,latitude,longitude):
  """
  Computes the apparent Az,El of the Sun for a specified time and location
  on Earth.  Latitude and longitude must arrive in degrees, with positive
  longitude meaning east of Greenwich.
  -- Todd Hunter
  """
  DEG_TO_RAD = math.pi/180.
  RAD_TO_DEG = 180/math.pi
  HRS_TO_RAD = math.pi/12.
  [RA,Dec] = ComputeSolarRADec(mjdsec)
  LST = ComputeLST(mjdsec, longitude)

  phi = latitude*DEG_TO_RAD
  hourAngle = HRS_TO_RAD*(LST - RA)
  azimuth = RAD_TO_DEG*math.atan2(math.sin(hourAngle), (math.cos(hourAngle)*math.sin(phi) - math.tan(Dec*DEG_TO_RAD)*math.cos(phi)))

# the following is to convert from South=0 (which the French formula uses)
# to North=0, which is what the rest of the world uses */
  azimuth += 180.0;

  if (azimuth > 360.0):
    azimuth -= 360.0
  if (azimuth < 0.0):
    azimuth += 360.0

  argument = math.sin(phi)*math.sin(Dec*DEG_TO_RAD) + math.cos(phi)*math.cos(Dec*DEG_TO_RAD) * math.cos(hourAngle);
  elevation = RAD_TO_DEG*math.asin(argument);

  return([azimuth,elevation])

def sunrise(date=None, observatory='ALMA', intervalMinutes=30, 
            finestSearch=3.0, verbose=True):
    """
    Computes sunrise and sunset
    intervalMinutes: initial grid size to use in the search
    finestSearch: final grid to use (in minutes)
    """
    if (date == None):
        date = mjdsecToDate()
    mjd = dateStringToMJD(date,verbose=False)
    if (mjd == None): return None
    radec = rad2radec(ComputeSolarRADecRadians(mjd*86400), verbose=False)
    ut = computeUTForElevation(0, radec, date, mjd, observatory,
                               intervalMinutes, verbose=verbose,
                               finestSearch=finestSearch)
    return(ut)

def angleToSun(date=None, mjdsec=None, radec='', raRadian=None, decRadian=None,
               raDegrees=None, decDegrees=None, days=None, figfile=None,
               vis=None, field=None, body=None, verbose=False, useJPL=False,
               showTable=False, returnPositionAngle=False, approximate=False):
    """
    Compute the angular separation (in deg) between the Sun and another object.
    The accuracy is tens of arc seconds (due to the approximate method of computing 
    the solar position).  Use the CASA measures tool if you need higher accuracy.    

    Specify the date/time to use in one of the following two ways:
    date: UT in string format, e.g. '2011/10/16 05:00:00'
    mjdsec: the time to use (default = now)
    
    Specify the coordinates of the object in one of the three following ways:
    radec: a sexagesimal string, e.g. 03:49:10.99 +57:17:44.806, or J0228-0337
    raRadian and decRadian: in radians
    raDegrees and decDegrees: in degrees
    vis: measurement set: if specified, compute angle from Sun to all fields
    field: if vis specified, then return the angle between Sun and this field
           (ID or string name).  If None, then compute for all and showTable

    days: compute the angle for the next number of days (default=None) and
          also make a plot
    body: a planetary body (alternative to entering radec)
    showTable: if True, then print a table of results for all fields
    verbose: print separations to screen
    useJPL: if True and body is set, then use the JPL position for body,
            (otherwise use CASA position)
    returnPositionAngle: if True, then also return the position angle (in deg)
    - Todd Hunter
    """
    if (date is not None):
        myValidCharacterList = [' ','/','-',':'] + [str(m) for m in range(10)]
        if (len(date) == sum([m in myValidCharacterList for m in date])):
            mjdsec = dateStringToMJDSec(date)
        else:
            print "Invalid date string"
            return
    if (mjdsec==None and date==None):
        if (vis == None):
            mjdsec = getCurrentMJDSec()
        else:
            mjdsec = getObservationStart(vis)
        print "Computing for right now."
    if (days is not None):
        mjdsecStop = mjdsec + days*86400
        angle = []
    else:
        mjdsecStop = mjdsec+1
    seconds = np.array(np.arange(mjdsec, mjdsecStop, 86400))
    if (raRadian is not None and decRadian is not None):
        radec = rad2radec(raRadian,decRadian)
    elif (raDegrees is not None and decDegrees is not None):
        radec = rad2radec(raDegrees*np.pi/180,decDegrees)
    elif (vis is not None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        nfields = mymsmd.nfields()
        fieldnames = mymsmd.namesforfields(range(nfields))
        mymsmd.close()
        if (field == None):
            field = 0
            showTable = True
        if showTable:
            print "Field ID, Name     Angle to sun (deg) at %s" % (mjdsecToUT(mjdsec))
            for myfieldId in range(nfields):
                radec = rad2radec(getRADecForField(vis, myfieldId, usemstool=True, forcePositiveRA=False), verbose=verbose)
                ra, dec = ComputeSolarRADecRadians(seconds[0], approximate=approximate)
                solarString = rad2radec(ra, dec, verbose=verbose)
                separation = angularSeparationOfStrings(radec, solarString, verbose=verbose)
                print "%2d = %12s = %6.3f deg" % (myfieldId, fieldnames[myfieldId],separation)
        if (type(field) == str):
            if (field.isdigit() == False):
                if (field not in fieldnames):
                    print "%s is not in the dataset" % (field)
                    return
                field = fieldnames.index(field)
        radec = rad2radec(getRADecForField(vis, field, usemstool=True, forcePositiveRA=False), verbose=verbose)
    elif (body is not None):
        mymjd = [mjdsec/86400., mjdsecStop/86400.]
        if useJPL:
            result = planet(body, date=date, mjd=mymjd)
            ra = np.degrees(result['directionRadians'][0])
            dec = np.degrees(result['directionRadians'][1])
        else:
            result = planetFlux(body,showRADec=True,mjd=mymjd,dayIncrement=1.0)
            if (result == None):
                print "Try setting useJPL=True"
                return
            ra, dec = result 
        radec = deg2radec(ra,dec)
    elif (radec == ''):
        print "You must specify either: (1) radec, (2) raRadian and decRadian, (3) raDegrees, decDegrees"
        print "  where (1) is a sexagesimal string, e.g. 03:49:10.99 +57:17:44.806"
        return(-1)
    for i,second in enumerate(seconds):
        ra, dec = ComputeSolarRADecRadians(second, approximate=approximate)
        solarString = rad2radec(ra, dec, verbose=verbose)
        print "Sun is at: ", solarString
        if (type(radec) == list):
            myradec = radec[i]
        else:
            myradec = radec
        result=angularSeparationOfStrings(myradec, solarString, 
                                          verbose=verbose, searchFluxVerbose=verbose,
                                          returnComponents=returnPositionAngle)
        if (returnPositionAngle):
            separation, deltaLong, deltaLat, deltaLongCos, pa = result
        else:
            separation = result
        if (days is not None):
            angle.append(separation)
    if (days is not None):
        pb.clf()
        adesc = pb.subplot(111)
        pb.plot((seconds-seconds[0])/86400., angle, 'k-')
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        pb.ylabel('Angle (degrees)')
        pb.xlabel('Days since %s' % (mjdSecondsToMJDandUT(seconds[0])[1]))
        if (body == None):
            pb.title('Angle between the Sun and %s' % (radec))
        else:
            pb.title('Angle between the Sun and %s' % (body))
        pb.draw()
        if (figfile is not None):
            if (figfile == True):
                figfile = 'angleToSun.png'
            pb.savefig(figfile)
            print "Plot saved to %s" % (figfile)
    if (returnPositionAngle):
        return(separation, pa)
    else:
        return(separation)
    
def ComputeSolarRADec(mjdsec=None, vis=None, apparent=False, approximate=False):
    """
    Computes the RA,Dec of the Sun (in hours and degrees) for a specified time 
    (default=now), or for the mean time of a measurement set.  
    apparent: if True, then report apparent position rather than J2000
    approximate: if True, then do not use the CASA measures tool
    See also: au.planet('sun',useJPL=True)
    -- Todd Hunter
    """
    RAD_TO_DEG = 180/math.pi
    RAD_TO_HRS = (1.0/0.2617993877991509)
    ra,dec = ComputeSolarRADecRadians(mjdsec, vis, apparent, approximate)
    return(ra*RAD_TO_HRS, dec*RAD_TO_DEG)

def ComputeSolarRADecRadians(mjdsec=None, vis=None, apparent=False, approximate=False):
    """
    Computes the RA,Dec of the Sun (in radians) for a specified time 
    (default=now), or for the mean time of a measurement set.  
    apparent: if True, then report apparent position rather than J2000
    approximate: if True, then do not use the CASA measures tool
    See also: au.planet('sun',useJPL=True)
    -- Todd Hunter
    """
    if (mjdsec == None):
        if (vis is not None):
            mjdsec = np.mean(getObservationMJDSecRange(vis))
        else:
            mjdsec = getCurrentMJDSec()
    if not approximate:
        mydict = planet('sun',useJPL=False,mjd=mjdsec/86400.,apparent=apparent)
        return(mydict['directionRadians'])
    else:
        jd = mjdToJD(mjdsec/86400.)
        RAD_TO_DEG = 180/math.pi
        RAD_TO_HRS = (1.0/0.2617993877991509)
        DEG_TO_RAD = math.pi/180.
        T = (jd - 2451545.0) / 36525.0
        Lo = 280.46646 + 36000.76983*T + 0.0003032*T*T
        M = 357.52911 + 35999.05029*T - 0.0001537*T*T
        Mrad = M * DEG_TO_RAD
        e = 0.016708634 - 0.000042037*T - 0.0000001267*T*T
        C = (1.914602 - 0.004817*T - 0.000014*T*T) * math.sin(Mrad) +  (0.019993 - 0.000101*T) * math.sin(2*Mrad) + 0.000289*math.sin(3*Mrad)
        L = Lo + C
        nu = DEG_TO_RAD*(M + C)
        R = 1.000001018 * (1-e*e) / (1 + e*math.cos(nu))
        Omega = DEG_TO_RAD*(125.04 - 1934.136*T)
        mylambda = DEG_TO_RAD*(L - 0.00569 - 0.00478 * math.sin(Omega))  
        epsilon0 = (84381.448 - 46.8150*T - 0.00059*T*T + 0.001813*T*T*T) / 3600.
        epsilon = (epsilon0 + 0.00256 * math.cos(Omega)) * DEG_TO_RAD
        rightAscension = math.atan2(math.cos(epsilon)*math.sin(mylambda), math.cos(mylambda))
        if (rightAscension < 0):
            rightAscension += np.pi*2
        argument = math.sin(epsilon) * math.sin(mylambda)
        declination = math.asin(argument)
        return([rightAscension, declination])
    
def parseMonitorPowerLevels(filename,antenna,polarization=0,plot_type='sb_power') :
    if ((plot_type <> 'sb_power') and (plot_type <> 'bb_power') and (plot_type <> 'atten')) :
        return "You must select plot_type sb_power, bb_power or atten"
    if ((polarization <> 0) and (polarization <> 1)) :
        return 'Polarization needs to be 0 or 1.'
    polarization = str(polarization)
    table = fiop.fileToTable(filename)
    [rest,rows]  = fiop.getRestrictTable(table,1,antenna)
    [rest2,rows] = fiop.getRestrictTable(rest,2,polarization)
    rest2 = fiop.getInvertTable(rest2)
    times = rest2[0]
    times_ = convertTimeStamps(times)
    for i in range(len(times_[:-2000])) : print times_[i],i
    clf()
    if plot_type == 'sb_power' :
        plot(times_,rest2[3])
        plot(times_,rest2[4])
    elif plot_type == 'bb_power' :
        plot(times_,rest2[5])
        plot(times_,rest2[6])
        plot(times_,rest2[7])
        plot(times_,rest2[8])        
    elif plot_type == 'atten' :
        plot(times_,rest2[9],'.')
        plot(times_,rest2[10],'.')
        plot(times_,rest2[11],'.')
        plot(times_,rest2[12],'.')
        plot(times_,rest2[13],'.')
        plot(times_,rest2[14],'.')
    show()
        
def stuffPercentIntoAFdict(flag_dict, report='report0'):
    """
    Computes and inserts 'percent' keys into the specified flag dictionary
    returned by the af tool.
    -Todd Hunter
    """
    for key in flag_dict[report].keys():
        if (type(flag_dict[report][key]) == dict):
            for subkey in flag_dict[report][key].keys():
                flag_dict[report][key][subkey]['percent'] = flag_dict[report][key][subkey]['flagged']*100.0 / flag_dict[report][key][subkey]['total']
    flag_dict[report]['percent'] = flag_dict[report]['flagged']*100.0 / flag_dict[report]['total']
    return(flag_dict)

def stuffPercentIntoFlagdict(flag_dict):
    """
    Computes and inserts 'percent' keys into the specified flag dictionary
    returned by the fg tool.
    -Todd Hunter
    """
    for key in flag_dict.keys():
        if (key != 'total' and key != 'flagged'):
            for subkey in flag_dict[key].keys():
                flag_dict[key][subkey]['percent'] = flag_dict[key][subkey]['flagged']*100.0 / flag_dict[key][subkey]['total']
    flag_dict['percent'] = flag_dict['flagged']*100.0 / flag_dict['total']
    return(flag_dict)

def getFieldIDsForEphemerisID(vis, ephemID):
    """
    Returns a list of field IDs corresponding to an ephemeris ID of a
    measurement set.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return 
    if (not os.path.exists(vis+'/FIELD')):
        print "Could not find FIELD directory.  This does not appear to be an ms."
        return 
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FIELD')
    if ('EPHEMERIS_ID' not in mytb.colnames()):
        return []
    ephemIDs = mytb.getcol('EPHEMERIS_ID')
    mytb.close()
    idx = np.where(ephemID == ephemIDs)[0]
    return(list(idx))

def casaEphemeris(table='', body=''):
    """
    Finds the time sampling of an ephemeris table in the CASA repository
    in data/ephemerides/JPL-Horizons.
    -Todd Hunter
    """
    if (table == '' and body==''):
        print "You must specify a table name or a body name."
        return
    repotable = os.getenv("CASAPATH").split()[0]+"/data/ephemerides/JPL-Horizons"
    if (table == ''):
        table = repotable+'/%s*J2000.tab' % body
        tables = glob.glob(table)
        if (len(tables) < 1):
            table = repotable+'/%s%s*J2000.tab' % (body[0].upper(),body[1:].lower())
            tables = glob.glob(table)
            if (len(tables) < 1):
                print "No table found for %s*J2000.tab" %  (body)
                return
        table = tables[0]
        print "Checking table ", table
    if (not os.path.exists(table)):
        print "Table %s does not exist.  Use the 'body' parameter to request the table for a specific solar system body." % (table)
        return
    mytb = createCasaTool(tbtool)
    mytb.open(table)
    if 'MJD' not in mytb.colnames():
        print "MJD is not a column in this table. Are you sure it is an ephemeris table?"
        mytb.close()
        return
    mjd = mytb.getcol('MJD')
    mytb.close()
    print "interval = %f days, length = %f days" % (mjd[1]-mjd[0], mjd[-1]-mjd[0])

def getEphemerisFieldsFromASDM(asdm, keyBy='name', verbose=True):
    """
    Read the ephemeris table and return a dictionary keyed by name or ID with 
    values of their initial direction in sexagesimal format, and time in MJD.
    keyBy: 'name', 'fieldID', or 'ephemerisID'
    -Todd Hunter
    """
    if not os.path.exists(asdm):
        print "Could not find asdm"
        return
    if not os.path.exists(asdm+'/Ephemeris.xml'):
        if verbose:
            print "ASDM has no Ephemeris file."
        return
    xmlscans = minidom.parse(asdm+'/Ephemeris.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    ephemeris = {}
    for rownode in rowlist:
        myrow = rownode.getElementsByTagName("ephemerisId")
        ephemerisId = int(myrow[0].childNodes[0].nodeValue)
        if ephemerisId not in ephemeris:
            myrow = rownode.getElementsByTagName("dir")
            rad = [float(myrow[0].childNodes[0].nodeValue.split()[3]), float(myrow[0].childNodes[0].nodeValue.split()[4])]
            radec = rad2radec(rad, verbose=False)
            myrow = rownode.getElementsByTagName("timeInterval")
            mjd = float(myrow[0].childNodes[0].nodeValue.split()[0])*1e-9/86400.
            ephemeris[ephemerisId] = {'direction': radec, 'mjd': mjd}
    xmlscans = minidom.parse(asdm+'/Field.xml')
    rowlist = xmlscans.getElementsByTagName("row")
    ephemerisByName = {}
    ephemerisByFieldID = {}
    for rownode in rowlist:
        myrow = rownode.getElementsByTagName("ephemerisId")
        if len(myrow) > 0:
            ephemerisId = int(myrow[0].childNodes[0].nodeValue)
            myrow = rownode.getElementsByTagName("fieldName")
            fieldName = str(myrow[0].childNodes[0].nodeValue)
            ephemerisByName[fieldName] = ephemeris[ephemerisId]
            myrow = rownode.getElementsByTagName("fieldId")
            fieldId = int(str(myrow[0].childNodes[0].nodeValue).split('_')[1])
            ephemerisByFieldID[fieldId] = ephemeris[ephemerisId]
    if keyBy == 'name':
        return ephemerisByName
    elif keyBy == 'fieldID':
        return ephemerisByFieldID
    elif keyBy == 'ephemerisID':
        return ephemeris
    else:
        print "Unrecognized value for parameter: keyBy"

def getEphemerisFields(vis, keyByFieldName=True, verbose=False):
    """
    Gets a list of field names that have entries in the ephemeris table.
    -Todd Hunter
    """
    return getEphemeris(vis, keyByFieldName=keyByFieldName, verbose=verbose).keys()

def getEphemeris(vis, ephemerisId=-1, useASDM_Ephemeris=False, verbose=True,
                 keyByFieldName=False, radec=False, sourceid=''):
    """
    Reads the ephemeris information from a measurement set.
    Inputs:
    use_ASDM_EPHEMERIS: if True then use the ASDM_EPHEMERIS table
          if False, then search the FIELD subdirectory
          for files of the name format: EPHEMx_fieldname_MJDsec.tab.
    ephemerisId: if specified, then limit the return value to that ephemeris ID.
    radec: if True, then return sexagesimal strings for the RA and Dec
           and YYYY-MMM-DD HH:MM for the time
    sourceid: name of the source (e.g. 'Venus')
    Returns a dictionary keyed by ephemerisID with a value of a list of 3 lists:
    * {'0': [MJD seconds, RA_radian, Dec_radian]}
    """
    result = {}
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return result
    if (not os.path.exists(vis + '/FIELD')):
        print "Could not find FIELD directory.  This does not appear to be an ms."
        return result
    if (not os.path.exists(vis + '/ASDM_EPHEMERIS') or not useASDM_Ephemeris):
        if (not os.path.exists(vis + '/ASDM_EPHEMERIS') and useASDM_Ephemeris):
            print "Could not find ASDM_EPHEMERIS table in this ms."
        ephemerisTables = sorted(glob.glob(vis + '/FIELD/EPHEM*.tab'))
        if (len(ephemerisTables) < 1):
            if verbose: print "Could not find any EPHEMx*.tab files in the FIELD directory"
            return result
        mytb = createCasaTool(tbtool)
        nEphem = len(ephemerisTables)
        print "There are %d ephemeris tables in the FIELD directory: " % (nEphem), [os.path.basename(i) for i in
                                                                                    ephemerisTables]
        if (ephemerisId < 0 and sourceid == ''):
            if (nEphem == 1):
                ephemerisId = 0
            else:
                print "You must select an ephemeris using the ephemerisId or sourceid parameter."
                return result
        for i in range(nEphem):
            mytb.open(ephemerisTables[i])
            keywords = mytb.getkeywords()
            fieldname = keywords['NAME']
            if ephemerisId < 0 and sourceid != '':
                if sourceid == fieldname:
                    print "Selected ephemerisId: %d for %s" % (i, sourceid)
                    ephemerisId = i
            mjdsec = getFieldTime(vis, fieldname)
            print "The time in the FIELD table = %f = %s" % (mjdsec, mjdsecToDatestring(mjdsec))
            if verbose:
                print "Reading MJD column from ", ephemerisTables[i]
                print keywords
            if ('obsloc' in keywords):
                obsloc = keywords['obsloc']
            else:
                obsloc = ''
            mjd = mytb.getcol('MJD')
            raDeg = mytb.getcol('RA')
            decDeg = mytb.getcol('DEC')
            difference = (mjd[0] * 86400 - getObservationStart(vis)) / 60.
            if (obsloc != ''):
                obsloc = '(obsloc=%s)' % (obsloc)
            else:
                obsloc = ''
            totalMinutes = 1440 * (mjd[-1] - mjd[0])
            if verbose:
                if (difference < 0):
                    print "Ephemeris %d %s begins %.1f minutes before observation begins and has %d rows. Total length=%.1f minutes." % (
                    i, obsloc, abs(difference), len(mjd), totalMinutes)
                else:
                    print "Ephemeris %d %s begins %.1f minutes after observation begins and has %d rows. Total length=%.1f minutes." % (
                    i, obsloc, difference, len(mjd), totalMinutes)
            difference = (mjd[-1] * 86400 - getObservationStop(vis)) / 60.
            minutes = np.mean(1440 * np.diff(mjd))
            #            for i,mydiff in enumerate(np.diff(mjd)): print '%.12f %.12f' % (mjd[i],mydiff)
            mindiff = np.min(1440 * np.diff(mjd))
            maxdiff = np.max(1440 * np.diff(mjd))
            if verbose:
                if (difference < 0):
                    print "Ephemeris %d ends %f minutes before observation ends and mean row spacing is %.10f minutes (min=%.10f,max=%.10f)." % (
                    i, abs(difference), minutes, mindiff, maxdiff)
                else:
                    print "Ephemeris %d ends %f minutes after observation ends and mean row spacing is %.10f minutes (min=%.10f,max=%.10f)." % (
                    i, difference, minutes, mindiff, maxdiff)
            if (ephemerisId == i or ephemerisId < 0):
                mjdsec = mjd[:] * 86400
                ra = np.radians(raDeg[:])
                dec = np.radians(decDeg[:])
                if (keyByFieldName):
                    if radec:
                        radecString = rads2radec(ra, dec)
                        result[fieldname] = [mjdsecToDatestring(mjdsec), radecString]
                    else:
                        result[fieldname] = [mjdsec, ra, dec]
                else:
                    if radec:
                        radecString = rads2radec(ra, dec)
                        result[i] = [mjdsecToDatestring(mjdsec), radecString]
                    else:
                        result[i] = [mjdsec, ra, dec]

        mytb.close()
        return (result)

    if (not os.path.exists(vis + '/ASDM_EPHEMERIS')):
        print "Could not find ASDM_EPHEMERIS table in this ms."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis + '/ASDM_EPHEMERIS')
    print "Reading timeInterval column from ASDM_EPHEMERIS table"
    direction = mytb.getcol('dir')
    ephemerisIds = mytb.getcol('ephemerisId')
    if (len(direction) == 0):
        print "The ephemeris table is blank."
        mytb.close()
        return result
    timeInterval = mytb.getcol('timeInterval')
    nEphem = len(np.unique(ephemerisIds))
    print "There are %d ephemerides in the table and %d total rows." % (nEphem, len(ephemerisIds))
    mjdsec = timeInterval[0]
    raRadian = direction[0][0]
    decRadian = direction[0][1]
    if (ephemerisId >= 0):
        idx = np.where(ephemerisId == ephemerisIds)
        mjdsec = mjdsec[idx]
        raRadian = raRadian[idx]
        decRadian = decRadian[idx]
    mytb.close()
    difference = (mjdsec[0] - getObservationStart(vis)) / 60.
    if (difference < 0):
        if (ephemerisId < 0):
            ephemerisId = ephemerisIds[0]
        print "Ephemeris %d begins %f minutes before observation begins." % (ephemerisId, abs(difference))
    else:
        print "Ephemeris begins %f minutes after observation begins." % (difference)
    print "and it is %f minutes long" % ((mjdsec[-1] - mjdsec[0]) / 60.)
    if radec:
        result = {ephemerisId: [mjdsec, rads2radec(raRadian, decRadian)]}
    else:
        result = {ephemerisId: [mjdsec, raRadian, decRadian]}
    return (result)

class FixPosition:
  def __init__(self,inputMs=''):
    """
    Instantiation of this class calls this function, i.e.,
        fp = aU.FixPosition('myInputMS.ms').  
    The dataset name is the only allowed input.
    For further help, see https://safe.nrao.edu/wiki/bin/view/ALMA/FixPosition
    Todd Hunter (May 2011)
    """
    self.inputMs = inputMs

  def getDirectionFromProperMotion(self,field,years=0):
      """
      Find the first occurrence of the source name or source ID, 
      and then use its position and proper motion to compute a
      new direction, and return it.
      Letting years=0 means to start at J2000 and come forward.
      -Todd Hunter (May 2011)
      """
      tb.open('%s/SOURCE'%(self.inputMs),nomodify=True)
      if (isinstance(field,str)):
          source = tb.getcol('NAME')
      else:
          source = tb.getcol('SOURCE_ID')
      direction = tb.getcol('DIRECTION')
      properMotion = tb.getcol('PROPER_MOTION')
      tb.close()
#      print "len(direction[0]) = %d" % (len(direction[0]))
      if (years == 0):
          tb.open('%s/FIELD'%(self.inputMs),nomodify=True)
          if (isinstance(field,str)):
             mySource = tb.getcol('NAME')
          else:
             mySource = tb.getcol('SOURCE_ID')
          for i in range(len(mySource)):
              if (mySource[i] == field):
                  timestamp = tb.getcell('TIME',i)
                  j2000 = 4453401600
                  years = (timestamp - j2000)/31556925.0
                  seconds = (timestamp - j2000)
                  print "Applying %f years (%.1f seconds) of proper motion since J2000." % (years,seconds)
                  break
          tb.close()
      else:
          seconds = years*31556925.
      foundSource = 0
      for i in range(len(direction[0])):
          if (source[i] == field):
              new_dec = direction[1][i] + properMotion[1][i]*seconds
              new_ra = direction[0][i] + properMotion[0][i]*seconds/math.cos(new_dec)
              new_direction = np.array([[new_ra], [new_dec]])
              hr = (new_ra*180/np.pi)/15.
              h = int(floor(hr))
              m = int((hr-h)*60)
              s = 3600*(hr-h-m/60.)
              if (new_dec < 0):
                  mysign = '-'
              else:
                  mysign = '+'
              dec = abs(new_dec*180/np.pi)
              d = int(floor(dec))
              dm = int(60*(dec-d))
              ds = 3600*(dec-d-dm/60.)
              print "New direction = %.12f, %.12f = %02d:%02d:%07.4f, %c%02d:%02d:%07.4f" % (new_ra, new_dec, h,m,s,mysign,d,dm,ds)
              foundSource = 1
              break
      if (foundSource == 0):
          print "Did not find source = ", field
          return(0)
      else:
          return(new_direction)
      
  def setDirectionFromRADec(self,field,raString,decString):
      """
      Sets the direction of a field from a specified ra and dec
      string. 
      field: the field ID (integer or string) or field name.
      raString: should be in the form:  hh:mm:ss.sssss   
      decString: should be in the form:  +dd:mm:ss.ssss
      Todd Hunter
      """
      (hour,minute,second) = raString.split(':')
      (deg,dmin,dsec) = decString.split(':')
      rahour = (float(hour)+float(minute)/60.+float(second)/3600.) 
      ra = 15*rahour*np.pi/180.
      if (deg.find('-')>=0):
          sign = -1
      else:
          sign = +1
      deg = abs(float(deg))
      dec = sign*(deg+float(dmin)/60.+float(dsec)/3600.)*np.pi/180
      new_direction = np.array([[ra],[dec]])
      # now double check it by showing it to the user
      hr = (ra*180/np.pi)/15.
      h = int(floor(hr))
      m = int(floor((hr-h)*60))
      s = 3600*(hr-h-m/60.)
      if (dec < 0):
          mysign = -1
          mychar = '-'
      else:
          mysign = +1
          mychar = '+'
      decdeg = abs(dec*180/np.pi)
      d = int(floor(decdeg))
      dm = int(floor(60*(decdeg-d)))
      ds = 3600*(decdeg-d-dm/60.)
      print "New direction: %.11f,%.11fdeg = %02d:%02d:%06.3f,%c%02d:%02d:%07.4f" % (hr, mysign*decdeg, h,m,s,mychar,d,dm,ds)
      print "             = %.13f,%.13f radian" % (ra,dec)
      self.setDirectionFromValue(field,new_direction)
      return
      
  def setDirectionFromProperMotion(self,field,years=0):
      """
      Will set the PHASE, DELAY and REFERENCE directions of the field to the modified
      position as computed from the proper motion in the SOURCE table.
      Todd Hunter
      """
      new_direction = self.getDirectionFromProperMotion(field,years)
      if (isinstance(new_direction,int)):
          print "Did not find source"
          return
      self.setDirectionFromValue(field,new_direction)
      return
      
  def setDirectionFromValue(self,field,new_direction):
      """
      field: can be field ID (integer or string) or field name
      new_direction: a CASA direction in radians: [[ra],[dec]]
      """
      mytb = createCasaTool(tbtool)
      mytb.open('%s/FIELD'%(self.inputMs),nomodify=False)
      sourceName = mytb.getcol('NAME')
      if (isinstance(field,str)):
          if (field.isdigit()):
              field = int(field)
              source = mytb.getcol('SOURCE_ID')
          else:
              source = mytb.getcol('NAME')
      else:
          source = mytb.getcol('SOURCE_ID')
      changed = 0
      for j in range(len(source)):
          if (source[j] == field):
#              direction = mytb.getcell('PHASE_DIR',j)   
#              print "len(direction), direction = ", len(direction), direction
#              print "len(new_direction), new_direction = ", len(new_direction), new_direction
              mytb.putcell('PHASE_DIR',j,new_direction)   
              mytb.putcell('DELAY_DIR',j,new_direction)   
              mytb.putcell('REFERENCE_DIR',j,new_direction)   
              print "Changed field ", field
              changed += 1
      mytb.close()
      print "Changed %d positions in FIELD table." % (changed)
      return

  def getRADecJ2000FromAntennas(self,field,timestamp=0):
#      loop over antennas,  this needs improvement
    ant = range(0,9)
    self.doRADecJ2000FromAntenna(field,0,ant,timestamp=timestamp)

  def doRADecJ2000FromAntenna(self, field, observatory=JPL_HORIZONS_ID['ALMA'], set=0, ant=0, timestamp=0):
    """
    Computes the mean RA/Dec in J2000 coordinates for the specified 
    field string by using the azim/elev pointing of the specified 
    antenna and stuffs this into the FIELD tables. This is the 
    equivalent of something Dirk wrote independently and should be 
    superceded by the method: getRADecJ2000FromJPL().

    ant = antenna number index (0..n)
    timestamp = 0 means compute the mean position
      (otherwise, find the antenna position at the nearest time to this)
    Todd Hunter
    """ 
    me = createCasaTool(metool)
    vm = ValueMapping(self.inputMs)
    try:
        times = vm.getTimesForField(field)
    except:
        print "did not find %s in the ms" %(field)
        return
    tb.open('%s/POINTING'%(self.inputMs))
    tim=tb.getcol('TIME')
    dir=tb.getcol('DIRECTION')
    antenna=tb.getcol('ANTENNA_ID')
    tb.close()
    tb.open('%s/ANTENNA'%(self.inputMs))
    antpos=tb.getcol('POSITION')
    tb.close()

    if (isinstance(ant,int)):
        ants = [ant]
    else:
        ants = ant
    antCounter = -1
    for ant in ants:
      iant = ant
      me.doframe(me.position('ITRF','%.8fm'%(antpos[0][iant]), '%.8fm'%(antpos[1][iant]), '%.8fm'%(antpos[2][iant])))
      raRadian = []
      decRadian = []
      for k in range(len(tim)):
        if ((tim[k] > times[0]) and (tim[k] < times[-1])):
          if (antenna[k] == ant):
            me.doframe(me.epoch('UTC', qa.quantity(tim[k],'s')))
            dirJ2000=me.measure(me.direction('AZELGEO',
                                             qa.quantity(dir[0,0,k], 'rad'), 
                                             qa.quantity(dir[1,0,k],'rad')),
                               'J2000')
            raRadian.append(dirJ2000['m0']['value'])
            decRadian.append(dirJ2000['m1']['value'])
      if (timestamp == 0):
        meanRA = mean(raRadian)
        meanDEC = mean(decRadian)
      else:
        index = self.find_index_of_nearest(times, timestamp)
        if (ant == ants[0]):
          print "The nearest time to %.3f is %.3f, a difference of %.3f seconds" % (timestamp,times[index],timestamp-times[index])
        meanRA = raRadian[index]
        meanDEC = decRadian[index]
      if (meanRA < 0):
        meanRA = meanRA+2*math.pi
      hours = meanRA*12/math.pi
      deg = meanDEC*180/math.pi
      absdeg = abs(deg)
      if (len(ants) < 2):
        antstring = ''
        if (timestamp == 0):
          print 'mean RA, Dec:'
        else:
          print 'RA, Dec at closest time:'
      else:
        antstring = '%d'%(ant)

      xyz = "antpos = %.4fm, %.4fm, %.4fm" % (antpos[0][ant],antpos[1][ant],antpos[2][ant])
      print 'Antenna %s  %s  %02d:%02d:%07.4f, %c%02d:%02d:%06.3f  %s' % (antstring,
        vm.getAntennaNamesForAntennaId(ant),
        int(hours), 
        int(60*(hours-int(hours))), 3600*(hours-int(hours)-int(60*(hours-int(hours)))/60.),
        ('%+f'%(deg))[0], int(absdeg), int(60*(absdeg-int(absdeg))), 3600*(absdeg-int(absdeg)-int(60*(absdeg-int(absdeg)))/60.), 
        xyz)
    tb.open('%s/FIELD'%(self.inputMs),nomodify=False)
    name = tb.getcol('NAME')
    j = 0
    for i in range(len(name)):
        if (name[i] == field):
            reference_dir = tb.getcell('REFERENCE_DIR',j)   
            reference_dir = np.array([[meanRA],[meanDEC]])
            if (set):
                tb.putcell('REFERENCE_DIR',j,reference_dir)   
                tb.putcell('PHASE_DIR',j,reference_dir)   
                tb.putcell('DELAY_DIR',j,reference_dir)   
                print "Values updated"
#            else:
#                print "Values NOT updated"
        j = j+1
    tb.close()

  def setRADecJ2000FromAntenna(self,field,ant=0,timestamp=0):
      self.doRADecJ2000FromAntenna(field,set=1,ant=ant,timestamp=timestamp)

  def getRADecJ2000FromAntenna(self,field,ant=0,timestamp=0):
      self.doRADecJ2000FromAntenna(field,set=0,ant=ant,timestamp=timestamp)

  def find_nearest(self,array,value):
    idx = (np.abs(array-value)).argmin()
    return array[idx]

  def find_index_of_nearest(self,array,value):
    idx = (np.abs(array-value)).argmin()
    return idx

  def doRADecJ2000FromJPL(self, field, observatory=JPL_HORIZONS_ID['ALMA'], set=0, verbose=0, timeout=4):
    """
    Contacts JPL Horizons via the telnet interface, gets the position and derivative
    for the mean time of observation, and stuffs them into the FIELD table of the ms.
    At present, this function can only accept a single field, but could be modified to
    do more than one at once.  The apparent coordinates are for ALMA.
    It returns the polynomial for use in subsequent .ms.
    Todd Hunter
    """
    nPolyTerms = 2
    vm = ValueMapping(self.inputMs)
    try:
        times = vm.getTimesForField(field)
    except:
        print "did not find %s in the ms" %(field)
        return
    meanTime = mean(times)
    print "Will query JPL Horizons for position & derivative at mean time = %.1f " % (meanTime)
    s = mjdSecondsToMJDandUT(meanTime)
    print " = %.5f = %s" % (s[0],s[1])
    tb.open('%s/FIELD'%(self.inputMs),nomodify=False)
    sourceName = tb.getcol('NAME')
    if (isinstance(field,str)):
        source = tb.getcol('NAME')
    else:
        source = tb.getcol('SOURCE_ID')
    j = 0
    for i in range(len(source)):
        if (source[i] == field):
            [directionRadians,rateRadiansPerSecond,angularDiameter] = self.contactJPLHorizons(sourceName[i], meanTime, observatory, verbose, timeout=timeout)
            reference_dir = tb.getcell('REFERENCE_DIR',j)   
            print "original PHASE_DIR = ", reference_dir
# definitely works:
            reference_dir = np.array([[directionRadians[0], rateRadiansPerSecond[0]],
                                      [directionRadians[1], rateRadiansPerSecond[1]]])
# this does not
#            reference_dir = np.array([directionRadians[0], directionRadians[1], 
#                                      rateRadiansPerSecond[0], rateRadiansPerSecond[1]])

            print "new PHASE_DIR = ", reference_dir
            if (set):
                tb.putcell('REFERENCE_DIR',j,reference_dir)   
                tb.putcell('PHASE_DIR',j,reference_dir)   
                tb.putcell('DELAY_DIR',j,reference_dir)   
                tb.putcell('TIME',j,meanTime)
                tb.putcell('NUM_POLY',j,nPolyTerms)   
                print "Values updated"
            else:
                print "Values NOT updated"
        j = j+1
    if (set):
        tb.putcolkeyword('PHASE_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
        tb.putcolkeyword('DELAY_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
        tb.putcolkeyword('REFERENCE_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
    tb.close()
    return([reference_dir,meanTime])

  def setRADecJ2000FromPolynomial(self,field,polynomial,timestamp,set=True):
    """
    Sets the RA and Dec for the specified field using the specified
    polynomial and timestamp.
    Todd Hunter
    """
    nPolyTerms = len(polynomial) - 1 # Bryan Butler told me to add the "- 1" on March, 12 2012. - TRH
    tb.open('%s/FIELD'%(self.inputMs),nomodify=False)
    sourceName = tb.getcol('NAME')
    if (isinstance(field,str)):
        source = tb.getcol('NAME')
    else:
        source = tb.getcol('SOURCE_ID')
    j = 0
    for i in range(len(source)):
        if (source[i] == field):
            reference_dir = polynomial
            print "new PHASE_DIR = ", reference_dir
            if (set):
                tb.putcell('REFERENCE_DIR',j,reference_dir)   
                tb.putcell('PHASE_DIR',j,reference_dir)   
                tb.putcell('DELAY_DIR',j,reference_dir)   
                tb.putcell('TIME',j,timestamp)
                tb.putcell('NUM_POLY',j,nPolyTerms)   
                print "Values updated"
            else:
                print "Values NOT updated"
        j = j+1
    if (set):
        tb.putcolkeyword('PHASE_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
        tb.putcolkeyword('DELAY_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
        tb.putcolkeyword('REFERENCE_DIR','MEASINFO', {'Ref':'J2000', 'type':'direction'})
    tb.close()
    return

  def setRADecJ2000FromJPL(self,field,observatory=JPL_HORIZONS_ID['ALMA']):
    """
    Contacts JPL Horizons via the telnet interface, gets the position
    of a planetary body along with its derivative for the mean time of
    observation, and stuffs them into the FIELD table of the ms.
    Todd Hunter
    """
    polynomialData = self.doRADecJ2000FromJPL(field, observatory, set=1)
    return(polynomialData)

  def getRADecJ2000FromJPL(self,field, observatory=JPL_HORIZONS_ID['ALMA'], verbose=0):
    """
    Contacts JPL Horizons via the telnet interface, gets the position
    of a planetary body along with its derivative for the mean time of
    observation and returns it.
    Todd
    """
    polynomialData = self.doRADecJ2000FromJPL(field, observatory, set=0, verbose=verbose)
    return(polynomialData)

  def getRaDecSize(self, body, datestring, observatory=JPL_HORIZONS_ID['ALMA'], 
                   verbose=False, apparent=False, timeout=4):
    """
    timeout: value in seconds
    """
    if (len(datestring.split()) < 2):
        # append a UT time if not given
        datestring += ' 00:00'
        print "Assuming 0 hours UT"
    mjdsec = dateStringToMJDSec(datestring)
    returnValue = self.contactJPLHorizons(body, mjdsec, observatory, verbose, apparent, timeout)
    if (returnValue == None):
        return None
    if (len(returnValue) == 5):
        (directionRadians, rateRadiansPerSecond,angularDiameter,rangeRate,rangeAU) = returnValue
    else:
        if (len(returnValue) != 2):
            return
        directionRadians,rateRadiansPerSecond = returnValue
        rangeAU = 0
        rangeRate = 0
        angularDiameter = 0
        
    data = {}
    data['directionRadians'] = directionRadians
    data['rateRadiansPerSecond'] = rateRadiansPerSecond
    data['angularDiameter'] = angularDiameter
    data['rangeRateKms'] = rangeRate
    data['rangeAU'] = rangeAU
    return(data)      
  
  def contactJPLHorizons(self, body, mjdsec, observatory=JPL_HORIZONS_ID['ALMA'], 
                         verbose=False, apparent=False, timeout=4):
    """
    body: name of SSO
    mjdsec: value of MJD seconds
    observatory: needs to be an integer ID acceptable to JPL horizons
    timeout: value in seconds
    example interactive session:
    telnet://horizons.jpl.nasa.gov:6775
    606 # = Titan
    e  # for ephemeris
    o  # for observables
    -7 # for ALMA
    y  # confirm
    2011-Apr-23 00:00  #  UT
    2011-Apr-23 01:00  #  UT
    1h #  interval
    y  # default output
    1,3,13,20 # RA/DEC and rates (Rarcsec/hour), angular diameter, and range+rate
    space  # to get to next prompt
    q   # quit
    """

    if (body.lower() == 'juno'):
        print "Switching to 'Juno;' to force search of small body database."
        body = 'Juno;'
    OBSERVATORY_ID = observatory
    tstart = mjdSecondsToMJDandUT(mjdsec)[1][0:-3]
    if (verbose):
        print "tstart = ", tstart
    tstop = mjdSecondsToMJDandUT(mjdsec+3600)[1][0:-3]
    t = None
    while (t==None):
        if verbose: print "telnet horizons.jpl.nasa.gov 6775"
        try:
            t = telnetlib.Telnet('horizons.jpl.nasa.gov',6775)  # this can bomb with err=110, connection timed out
        except:
            print "Telnet connection to JPL time out. Trying again."
    t.set_option_negotiation_callback(self.optcallback)
    data = t.read_until('Horizons> ')
    if (verbose):
        print "0)data = ", data
        print "hex string ="
        print "%s\n\n" % binascii.hexlify(data)
    while (data.find('Horizons>') < 0):
        t.write('\n')
        data = t.read_until('Horizons> ')
        if (verbose):
            print "1)data = ", data
    t.write(body+'\n')
    data = t.read_until('Select ... [E]phemeris, [F]tp, [M]ail, [R]edisplay, ?, <cr>: ',timeout)
    if (verbose):
        print "2)data = ", data
    if (data.find('phemeris') < 0):
      # this happens if multiple bodies match:  Select ... [F]tp, [M]ail, [R]edisplay, ?, <cr>:  
      if (data.find('EXACT')>=0):
        t.write('\n')
        data = t.read_until('Select ... [E]phemeris, [F]tp, [M]ail, [R]edisplay, ?, <cr>: ', timeout)
        if (verbose):
            print "3)data = %s" % data
        useID = ''
        if (data.find("No matches found") > 0):
            print "Unrecognized body: ", body
            return
      else:
        # then we have a conflict in the name. 
        # e.g. Titan vs. Titania, or Mars vs. Mars Barycenter
        # Try to resolve by forcing an exact match.
        lines = data.split('\n')
        if (verbose):
            print "Multiple entries found, using exact match"
            print "nlines = %d" % (len(lines))
        firstline = -1
        lastvalidline = -1
        l = 0
        useID = -1
        for line in lines:
            if (verbose):
                print line
            if (line.find('-----') >= 0):
                if (firstline == -1):
                    firstline = l+1
            else:
              tokens = line.split()
              if (firstline>=0 and lastvalidline == -1):
                  if (len(tokens) < 2):
                      lastvalidline = l-1
                  elif (tokens[1] == body):
                      if (len(tokens) == 2 or (len(tokens)>2 and useID==-1)):
                          useID = int(tokens[0])
                          useBody = tokens[1]
                          if (verbose):
                              print "Use instead the id = %s = %d" % (tokens[0],useID)
            l = l+1
        if (useID == -1):
          # Try again with only the first letter capitalized
          body = string.upper(body[0]) + string.lower(body[1:])
          if (verbose):
              print "Try the exact match search again with body = ", body
          firstline = -1
          lastvalidline = -1
          l = 0
          for line in lines:
            if (verbose):
                print line
            if (line.find('-----') >= 0):
                if (firstline == -1):
                    firstline = l+1
            elif (firstline > 0):
              line = line.lstrip(' ')
              if (verbose):
                  print "Splitting this line = %s" % (line)
              tokens = line.split()
              if (verbose):
                  message = "length=%d,  %d tokens found: " % (len(line),len(tokens))
                  for tok in tokens:
                      message +=  "%s " % (tok)
                  print message
              if (firstline>=0 and lastvalidline == -1):
                  if (len(tokens) < 2):
                      # this is the final (i.e. blank) line in the list
                      lastvalidline = l-1
                  elif (tokens[1] == body):
                      if (len(tokens) == 2 or (len(tokens)>2 and useID==-1)):
                          useID = int(tokens[0])
                          useBody = tokens[1]
                          if (verbose):
                              print "Use instead the id = %s = %d" % (tokens[0],useID)
            l = l+1
        if (verbose):
            print "line with first possible source = ", firstline
            print "line with last possible source = ", lastvalidline
            print "first possible source = ", (lines[firstline].split())[1]
            print "last possible source = ", (lines[lastvalidline].split())[1]
            print "Writing ", useID
        else:
            if (str(useID) != body):
                print "Using body = %s" % (str(useID))
        if (useID == -1):
            return
        t.write(str(useID)+'\n')
        data = t.read_until('Select ... [E]phemeris, [F]tp, [M]ail, [R]edisplay, ?, <cr>: ', timeout)
        if (verbose):
            print data
    else:
        useID = ''
    t.write('e\n')
    data = t.read_until('Observe, Elements, Vectors  [o,e,v,?] : ', timeout)
    if (verbose):
        print data
    t.write('o\n')
    data = t.read_until('Coordinate center [ <id>,coord,geo  ] : ', timeout)
    if (verbose):
        print data
    t.write('%s\n' % OBSERVATORY_ID)
    data = t.read_until('[ y/n ] --> ', timeout)
    pointer = data.find('----------------')
    ending = data[pointer:]
    lines = ending.split('\n')
    try:
        if (verbose):
            print "Parsing line = %s" % (lines)
        tokens = lines[1].split()
    except:
        print "Telescope code or target name unrecognized by JPL."
        return([],[],[])
        
    if (verbose):
        print data
    obsname = ''
    for i in range(4,len(tokens)):
        obsname += tokens[i]
        if (i < len(tokens)+1): obsname += ' '
    # display LST date/time and Julian date/time
    [latitude,longitude,obs] = getObservatoryLatLong(OBSERVATORY_ID)
    if (verbose):
        print "latitude = %s, longitude = %s" % (str(latitude), str(longitude))
    ComputeLSTDay(mjdsec, longitude=longitude, verbose=False)
    if (verbose):
        print "Confirmed Observatory name = %s (= %s in CASA)" % (obsname, obs)
        if (useID != ''):
            print "Confirmed Target ID = %d = %s" % (useID, useBody)
    # Confirm selection station  [y/n] -->
    t.write('y\n')
    data = t.read_until('] : ',3)
    if (verbose):
        print data
    t.write(tstart+'\n')
    data = t.read_until('] : ',3)
    if (verbose):
        print data
    t.write(tstop+'\n')
    data = t.read_until(' ? ] : ',timeout)
    if (verbose):
        print data
    t.write('1h\n')
    data = t.read_until(', ?] : ',timeout)
    if (verbose):
        print data
    if (True):
        t.write('n\n') # accept default output?
        data = t.read_until('Select table quantities [ <#,#..>, ?] :',timeout)
        if (verbose):
            print data
        # Set the first '1' to '2' for apparent coordinates
        if (apparent):
            if (verbose):
                print "Querying for apparent coordinates......"
            t.write('2,3,13,20\nJ2000\n\n\n\nDEG\nYES\n\n\n\n\n\n\n\n\n\n\n\n')
        else:
            if (verbose):
                print "Querying for J2000 coordinates......"
            # Added a 12th '\n' on June 9, 2017 for "Spreadsheet CS format [Y,N]"
            t.write('1,3,13,20\nJ2000\n\n\n\nDEG\nYES\n\n\n\n\n\n\n\n\n\n\n\n')
    else:
        t.write('y\n') # accept default output?
        data = t.read_until(', ?] : ') #,timeout)
        if (verbose):
            print data
        t.write('1,3\n')
    t.read_until('$$SOE',timeout)  # This marks the line prior to the data we want
    data = t.read_until('$$EOE',timeout)  # This marks the line after the data we want
    if (verbose):
        print "data = ", data
    t.close()
    lines = data.split('\n')
    if (verbose):
        print "lines = ", lines
    if (len(lines[1].split()) == 9):
        (date, time, raDegrees, decDegrees, raRate, decRate, angularDiameter, rangeAU, rangeRate) = lines[1].split()
    else:
        (date, time, flag, raDegrees, decDegrees, raRate, decRate, angularDiameter, rangeAU, rangeRate) = lines[1].split()
    raRadian = float(raDegrees)*math.pi/180.0
    decRadian = float(decDegrees)*math.pi/180.0
    directionRadians = [raRadian,decRadian]
    directionDegrees = [float(raDegrees), float(decDegrees)]
    rate = [float(raRate), float(decRate)]
    rateRadiansPerSecond = [float(raRate)*math.pi/(180*3600.*3600.),float(decRate)*math.pi/(180*3600.*3600.)]
    rangeAU = float(rangeAU)
    rangeRate = float(rangeRate)
    if (verbose):
        print "Range rate = %+f km/sec" % (rangeRate)
        print "degrees: position = ", directionDegrees, "  rates (arcsec/hr) = ",rate
    if (apparent):
        coords = 'Apparent'
    else:
        coords = 'J2000'
    observatoryName = JPL_HORIZONS_ID.keys()[JPL_HORIZONS_ID.values().index(str(observatory))]
    if verbose:
        print "observatoryName = ", observatoryName
    azim, elev = computeAzElFromRADecMJD(directionRadians, mjdsec/86400., observatory=observatoryName)
    azim *= 180/np.pi
    elev *= 180/np.pi
    print '%s %s Position: %s, %s   Azim, Elev: %.3f, %.3f' % (body, coords,qa.formxxx('%.12fdeg'%directionDegrees[0],format='hms',prec=5),
                                   qa.formxxx('%.12fdeg'%directionDegrees[1],format='dms',prec=4).replace('.',':',2),azim,elev)
    pa = np.arctan2(rate[0],rate[1]) * 180/np.pi
    if (verbose):
        print "%s %s Rate: %+.4f, %+.4f arcsec/hour (position angle = %+.1fdeg)" % (body,coords, rate[0], rate[1], pa)    
        print '%s %s Rate: %+.6f, %+.6f arcsec/second  (position angle = %+.1fdeg)' % (body,coords, rate[0]/3600., rate[1]/3600., pa)
    if (angularDiameter.find('n.a.') >=0):
        return(directionRadians, rateRadiansPerSecond, [], rangeRate, rangeAU)
    else:
        return(directionRadians, rateRadiansPerSecond, float(angularDiameter), rangeRate, rangeAU)

  # Reject all telnet requests.  Vanilla all the way.
  def optcallback(self, socket, command, option):
        cnum = ord(command)
        onum = ord(option)
        if cnum == telnetlib.WILL: # and onum == ECHO:
                socket.write(telnetlib.IAC + telnetlib.DONT + onum)
        if cnum == telnetlib.DO and onum == telnetlib.TTYPE:
                socket.write(telnetlib.IAC + telnetlib.WONT + telnetlib.TTYPE)

def computeBaselineLength(pos1,pos2):
    """
    Simple function to compute the length of a baseline, given the X,Y,Z coordinates
    of two stations, in some arbitrary linear coordinate system.  See also
    au.getBaselineLength to compute it for specific antennas in an ms.
    - Todd Hunter
    """
    length = ((pos1[0]-pos2[0])**2+(pos1[1]-pos2[1])**2+(pos1[2]-pos2[2])**2)**0.5
    return(length)

def computeBaselineHeightDiff(pos1,pos2):
    """
    Simple function to compute the height difference, given the X,Y,Z coordinates
    of two stations, in some arbitrary linear coordinate system.Simply computed as the difference between the total distance from the center of the earth.  
    - 
    """
    r1 = ((pos1[0])**2+(pos1[1])**2+(pos1[2])**2)**0.5
    r2 = ((pos2[0])**2+(pos2[1])**2+(pos2[2])**2)**0.5
    diff = r1 - r2
    return(diff)

def getBaselineExtrema(msFile=None, verbose=True, config=None):
    """
    Will compute the shortest and longest baseline for the specified ms.
    Projection toward the sources in the ms is not accounted for.
    Returns:
      maxlength,minlength,maxbaseline,minbaseline
      e.g.  [500, 12, 'DV01-DV02', 'DV01-DA50']
      The latter two values are only returned if msFile is specified.
    Todd Hunter
    """
    if msFile is None and config is None:
        print "You must specify msFile or config"
        return
    if config is not None:
        result = getBaselineStats(config=config)
        return [result[2],result[1]]
    obsIDs = len(getObservationIDs(msFile))
    if (obsIDs > 1):
        baselines = getBaselinesInMainTable(msFile)
    mytb = createCasaTool(tbtool)
    mytb.open(msFile+'/ANTENNA')
    names = mytb.getcol('NAME')
    positions = np.transpose(mytb.getcol('POSITION'))
    maxlength = 0
    minlength = 1e20
    droppedBaselines = 0
    for i in range(len(positions)):
        for j in range(i+1,len(positions)):
            if (obsIDs > 1):
                if (i,j) not in baselines: 
                    droppedBaselines += 1
                    continue
            length = computeBaselineLength(positions[i],positions[j])
            if (length > maxlength):
                maxlength = length
                maxbaseline = '%s-%s' % (names[i],names[j])
                maxbaselineIDs = '%d-%d' % (i,j)
            if (length < minlength):
                minlength = length
                minbaseline = '%s-%s' % (names[i],names[j])
                minbaselineIDs = '%d-%d' % (i,j)
    mytb.close()
    if droppedBaselines > 0:
        print "Dropped %d baselines which do not appear in the main visibility table." % droppedBaselines
    if (verbose):
        print "Longest baseline = %.3f m:  %s (names) = %s (IDs)" % (maxlength,maxbaseline,maxbaselineIDs)
        print "Shortest baseline = %.3f m:  %s (names) = %s (IDs)" % (minlength,minbaseline,minbaselineIDs)
    return([maxlength,minlength,maxbaseline,minbaseline])

def surmiseCycle(vis):
    """
    Finds the date of an observation and determines which ALMA Cycle it is.
    Cycle 0: 2011-09-30 to 2013-01-20
    Cycle 1: 2013-01-21 to 2014-06-02
    Cycle 2: 2014-06-03 to 2015-09-30
    Cycle 3: 2015-10-01 to 2016-09-30
    Cycle 4: 2016-10-01 to 2017-09-30
    Cycle 5...: etc.
    Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    observatory = getObservatoryName(vis)
    if (observatory.find('ALMA') < 0):
        return -2
    yyyymmdd = getObservationStartDate(vis).split()[0]
    return almaCycles(yyyymmdd)

def imageDate(img, stripTime=False, delimiter='/', prec=6):
    """
    Reads the date-obs from the coordsys epoch from a CASA or FITS image
    prec: 6 is the nearest second, 7 is tenths of sec, etc.
    Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    mycs = myia.coordsys()
    mjd = mycs.epoch()['m0']['value']
    myia.close()
    mydate = mjdToUT(mjd,prec=prec)
    if stripTime:
        return mydate.split()[0].replace('-',delimiter)
    else:
        return mydate.replace('-',delimiter)

def surmiseCycleFromImage(img, method='ia', header='', observatory=''):
    """
    Attempts to surmise the Cycle number for an ALMA image based on the 
    observing date in the header.
    method: method for finding observatory name 'ia' or 'header' (ia = fastest)
    header: only used if method=='header'
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    cycle = -1
    if (observatory == ''):
        observatory = imageObservatory(img, method, header)
    if (observatory.lower().find('alma') < 0):
        print "Did not find ALMA in the header"
    if (method == 'header'):
        if (eader == ''):
            header = imhead(img, mode='list')
        if ('date-obs' not in header):
            print "Did not find 'date-obs' in the header."
        obsDate = header['date-obs']
    else:
        obsDate = imageDate(img)
    cycle = almaCycles(obsDate)
    return cycle

def almaCycles(yyyymmdd):
    """
    Converts date string ('yyyy-mm-dd' or 'yyyy/mm/dd' or 'yyyymmdd') to ALMA cycle.
    -Todd Hunter
    """
    if (len(yyyymmdd) == 8):
        yyyymmdd = yyyymmdd[:4] + '-' + yyyymmdd[4:6] + '-' + yyyymmdd[6:]
    elif (len(yyyymmdd) < 10):
        print "Invalid string"
        return
    else:
        yyyymmdd = yyyymmdd[:10].replace('/','-') # strip off the time, if it exists
    cycle = -2  # should never happen
    if (yyyymmdd < '2011-09-30'):
        cycle = -1
    if (yyyymmdd < '2013-01-21'):
        cycle = 0
    elif (yyyymmdd < '2014-06-03'):
        cycle = 1
    elif (yyyymmdd < '2015-10-01'):
        cycle = 2
    else:
        for year in range(2016,2038,1):
            if (yyyymmdd < str(year)+'-10-01'):
                cycle = year-2013
                break
    return cycle

def surmiseCycleFromASDM(asdm):
    """
    Finds the date of an observation and determines which ALMA Cycle it is.
    Cycle 0: 2011-09-30 to 2013-01-20
    Cycle 1: 2013-01-21 to 2014-06-02
    Cycle 2: 2014-06-03 to 2015-09-30
    Cycle 3: 2015-10-01 to 2016-09-30
    Cycle 4: 2016-10-01 to 2017-09-30
    Cycle 5: etc.
    Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    observatory = getObservatoryNameFromASDM(asdm)
    if (observatory.find('ALMA') < 0):
        return -2
    yyyymmdd = getObservationStartDateFromASDM(asdm)[0].split()[0]
    return almaCycles(yyyymmdd)

def surmiseConfigurationFromImage(img=''):
    """
    Reads the date, frequency and beamsize from an image and find the closest
    ALMA configuration that would have provided it.
    -Todd Hunter
    """
    if not os.path.exists(img):
        print "Could not find image"
        return
    cycle = surmiseCycleFromImage(img)
    print "Cycle = ", cycle
    date = imageDate(img)
    beam = getFitsBeam(img)
    beam = beam[0]*beam[1]
    freq = np.mean(imageChannelFrequency(img, -1))
    configurations = configs(cycle=cycle)
    beams = []
    for config in configurations:
        beams.append(estimateSynthesizedBeamForConfig(config, freq)**2)
    beams = np.array(beams)
    i = np.argmin(np.abs(beams - beam))
    return configurations[i]

def surmiseConfiguration(vis='', config='', cycle='auto', verbose=False, mymsmd=None):
    """
    Compares the baseline statistics of an ALMA measurement set to the official
    configurations for the Cycle in which it was observed, and reports the 
    closest matching configuration name.  Also works for other telescopes
    like the VLA, because it uses the configuration files in: 
    os.getenv("CASAPATH").split()[0]+"/data/alma/simmos"
    If it is not an ALMA measurement set, then all configurations of all
    known observatories are searched (so it will work with VLA data, etc.).
    vis, config: enter one or the other
    cycle: if 'auto', then determine Cycle by date then restrict to the 
           official configurations of that Cycle.
           otherwise, a comma-delimited string list of cycles from which to 
           use all configurations
    -Todd Hunter
    """
    if (vis != ''):
        alma = True
        if (not os.path.exists(vis)):
            print "Could not find measurement set."
            return
        if (not os.path.exists(vis+'/OBSERVATION')):
            print "Could not find measurement set's OBSERVATION table."
            return
        if (cycle == 'auto'):
            cycle = str(surmiseCycle(vis))
        cycles = cycle.split(',')
        if (int(cycles[0]) < -1):
            print "This is not an ALMA measurement set. Will search all telescope configurations."
            alma = False
        if (cycles[0] == '-1'):
            print "This measurement set pre-dates Cycle 0."
            return
        stats = getBaselineStats(msFile=vis, verbose=False, mymsmd=mymsmd)
        if alma and verbose:
            print "Restricting to cycle ", cycles
    elif (config != ''):
        cycles = ['']
        stats = getBaselineStats(config=config, verbose=False)
    else:
        print "Must specify either a measurement set or configuration file"
        return    
    repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    configs = []
    acaconfigs = []
    for cycle in cycles:
        configs += glob.glob(repotable+'alma.cycle%s*cfg'%cycle)
        acaconfigs += glob.glob(repotable+'aca.cycle%s*cfg'%cycle)
    configs = configs + acaconfigs
    if (vis != '' and not alma):
        configs = glob.glob(repotable+'*.cfg')
    if verbose:
        print "Checking configs = %s in directory %s" % (str([os.path.basename(c) for c in configs]), os.path.dirname(configs[0]))
    distance = []
    for config in configs:
        cstats = getBaselineStats(config=config, verbose=False)
        distance.append(scipy.spatial.distance.euclidean(cstats[1:],stats[1:]))
    idx = np.argsort(distance)
    config = os.path.basename(configs[idx[0]])
    return(config)
    
def surmiseConfigurationFromASDM(asdm, cycle='auto', verbose=False):
    """
    Compares the baseline statistics of an ALMA ASDM to the official
    configurations for the Cycle in which it was observed, and reports the 
    closest matching configuration.  Uses the configuration files in: 
    os.getenv("CASAPATH").split()[0]+"/data/alma/simmos"
    If it is not an ALMA measurement set, then all configurations of all
    known observatories are searched (so it will work with VLA data, etc.).
    asdm: name of ALMA or VLA dataset
    cycle: if 'auto', then determine Cycle by date then restrict to the 
           official configurations of that Cycle.
           otherwise, a comma-delimited string list of cycles from which to 
           use all configurations
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm+'/ExecBlock.xml')):
        print "Could not find the ASDM's ExecBlock.xml."
        return
    if (cycle == 'auto'):
        cycle = str(surmiseCycleFromASDM(asdm))
    cycles = cycle.split(',')
    if (int(cycles[0]) < -1):
        alma = False
        print "This is not an ALMA ASDM."
    else:
        alma = True
    if (cycles[0] == '-1' and alma):
        print "This ASDM pre-dates Cycle 0."
        return
    if alma:
        print "Restricting to cycle ", cycles
    stats = getBaselineStatsFromASDM(asdm)
    if (stats == None): return
    repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    configs = []
    acaconfigs = []
    for cycle in cycles:
        configs += glob.glob(repotable+'alma.cycle%s*cfg'%cycle)
        acaconfigs += glob.glob(repotable+'aca.cycle%s*cfg'%cycle)
    configs = configs + acaconfigs
    if (asdm != '' and not alma):
        configs = glob.glob(repotable+'*.cfg')
    if verbose:
        print "Checking configs = %s in directory %s" % (str([os.path.basename(c) for c in configs]), os.path.dirname(configs[0]))
    distance = []
    for config in configs:
        cstats = getBaselineStats(config=config, verbose=False)
        distance.append(scipy.spatial.distance.euclidean(cstats[1:],stats[1:]))
    idx = np.argsort(distance)
    config = os.path.basename(configs[idx[0]])
    return(config)

def estimateSynthesizedBeamForConfig(config, frequency):
    """
    Reads an antenna configuration file (by default from the directory:
         os.getenv('CASAPATH').split()[0]+'/data/alma/simmos
    and computes the expected beamsize in arcseconds based on the ALMA-accepted
    formula of 0.574*lambda/L80percentile.
    frequency: in Hz or GHz, or a string with units
    -Todd Hunter
    """
    frequencyHz = parseFrequencyArgumentToHz(frequency)
    L80 = getBaselineStats(config=config, percentile=80, verbose=False)[0]
    resolution = 3600*np.degrees(1)*0.574*c_mks/(frequencyHz*L80)
    return resolution

def estimateMRSForConfig(config, frequency):
    """
    Reads an antenna configuration file (by default from the directory:
         os.getenv('CASAPATH').split()[0]+'/data/alma/simmos
    and computes the expected maximum recoverable scale (a.k.a. LAS) in 
    arcseconds based on the ALMA-accepted formula of 0.983*lambda/L5percentile.
    -Todd Hunter
    """
    frequencyHz = parseFrequencyArgumentToHz(frequency)
    L5 = getBaselineStats(config=config, percentile=5, verbose=False)[0]
    resolution = 3600*np.degrees(1)*0.983*c_mks/(frequencyHz*L5)
    return resolution

def getBaselineStats(msFile='', length=None, percentile=None, field='',
                     azimuth=None, elevation=None, config=None,
                     angularSize=None, frequency=None, verbose=True, 
                     mymsmd=None, plot=False, units='m'):
    """
    Compute statistics on the baseline lengths of the specified ms.
    Returns: number, min, max, median, mean, st.dev, 20%ile, 25%ile, 30%ile,
             75%ile, 90%ile in meters.  For klambda, see getBaselineLengths(units='kl')
    msFile: the measurement set to examine (if config is not None)
    field: if not blank, then find the first integration on the specified
           field ID or name, get its az&el and compute the projected baseline
           lengths rather than the unprojected baseline lengths
    azimuth,elevation: if field=='', and these are both set (in degrees),
           then compute the projected baseline length toward this direction
           rather than the unprojected baseline lengths
    config: a configuration file to read, instead of a visibility file
    length: If not None, then it also finds the percentile for that length.
    percentile: If not None, then it finds the length for that percentile and
           returns it as an additional (first) value in the list.
    angularSize: If not None, then it find the percentage of baselines shorter
           than this angular scale (in arcseconds) and returns it as an
           additional (first) argument
    frequency: in GHz, used with the angularSize option.
    plot: create a histogram plot
    
    Todd Hunter
    """
    if (units not in ['m','kl']):
        print "length units must be either 'm' or 'kl'."
        return
    if (percentile is not None and angularSize is not None):
        print "percentile and angularSize are cannot both be specified."
        return
    if (angularSize is not None and frequency == None):
        print "A frequency must be specified if angular size is specified."
        return
    if (msFile == '' and config==None):
        print "Either an msFile or a config file must be specified."
        return
    bl1 = getBaselineLengths(msFile=msFile, field=field, azimuth=azimuth,
                             elevation=elevation, config=config, verbose=verbose, 
                             mymsmd=mymsmd, units=units)
    if (bl1 is None): return

    bl = []
    for i in range(len(bl1)):
        if len(bl1[i]) != 2: 
            print "Unexpected baseline length entry: ", bl1[i]
            return
        if type(bl1[i][1]) == np.ndarray:
            # VLA config files (extra indexing of array of length 1)
            bl.append(tuple([bl1[i][0], bl1[i][1][0]]))
        else:
            # ALMA config files
            bl.append(tuple([bl1[i][0], bl1[i][1]]))

    bl = np.array(bl)
    lengths = bl[:,1].astype(np.float)
    number = len(lengths)
    twenty = scoreatpercentile(lengths, 20)    
    twentyfive = scoreatpercentile(lengths, 25)    
    thirty = scoreatpercentile(lengths, 30)    
    seventyfive = scoreatpercentile(lengths, 75)
    ninety = scoreatpercentile(lengths, 90)
    if (verbose):
        print "number=%d, min=%.2f%s, max=%.2f%s, median=%.2f%s, mean=%.2f%s, std=%.2f%s" % (number, np.min(lengths), units, np.max(lengths), units, np.median(lengths), units, np.mean(lengths), units, np.std(lengths), units)
        print "20%%ile=%.1f%s 25%%ile=%.1f%s, 30%%ile=%.1f%s, 75%%ile=%.1f%s, 90%%ile=%.1f%s" % (twenty, units, twentyfive, units, thirty, units, seventyfive, units, ninety, units)
    if (length is not None):
        mypercentile = percentileofscore(lengths,length)
        if (verbose):
            print "%g m corresponds to %g percentile" % (length,mypercentile)
    if plot:
        import pylab as pl
        pl.ion()
        pl.clf()
        hh=pl.hist(lengths,bins=int(len(lengths)*0.025))
        med=np.median(lengths)
        z=pl.where(med>=hh[1])[0].max()
        pl.text(med,hh[0][z]*1.1,"median=%6.1f"%med,rotation="vertical",horizontalalignment="center",verticalalignment="bottom")
        rms=np.std(lengths)
        z=pl.where(rms>=hh[1])[0].max()
        pl.text(rms,hh[0][z]," rms=%6.1f"%rms,rotation="vertical",horizontalalignment="center",verticalalignment="bottom")
        eighty=scoreatpercentile(lengths, 80)
        z=pl.where(eighty>=hh[1])[0].max()
        pl.text(eighty,hh[0][z]," 80th pctl=%6.1f"%eighty,rotation="vertical",horizontalalignment="center",verticalalignment="bottom")
        yy=pl.ylim()
        pl.ylim(yy[0],yy[1]+30)
        pl.xlabel("baseline length [%s]" % (units))
        pl.ylabel("number")
    if (percentile is not None):
        mylength = scoreatpercentile(lengths,percentile)
        if (verbose):
            print "%g m corresponds to %g percentile" % (mylength,percentile)
        return(mylength, number, np.min(lengths), np.max(lengths), np.median(lengths),
               np.mean(lengths), np.std(lengths), twenty, twentyfive, thirty,
               seventyfive, ninety)
    elif (angularSize is not None):
        criticalBaseline = angularScaleBaseline(angularSize,frequency,units)
        mypercentage = percentileofscore(lengths, criticalBaseline)
        if (verbose):
            print "Percentage of baselines shorter than %.1f %s (%.3f arcsec): %.3f" % (criticalBaseline, units, angularSize,mypercentage)
        return(mypercentage, number,np.min(lengths),np.max(lengths),
               np.median(lengths),
               np.mean(lengths), np.std(lengths),twenty,twentyfive,thirty,
               seventyfive,ninety)
    else:
        return(number,np.min(lengths),np.max(lengths),np.median(lengths),
               np.mean(lengths), np.std(lengths),twenty,twentyfive,thirty,
               seventyfive,ninety)

def angularScaleBaseline(angularScale, frequency, units='m', coefficient=1.0):
    """
    Return the baseline length (in meters) corresponding to the specified
    angular scale at the specified frequency.  See also findNull().
    Uses formula: wavelength*ARCSEC_PER_RAD / angularScale
    angularScale: arcsec
    frequency: GHz
    coefficient: used to scale the ratio of lambda/arcsec, use 1.13 for equivalent single dish
    -- Todd Hunter
    """
    wavelengthMeters = c_mks*1e-9/float(frequency)
    lengthLambda = coefficient*ARCSEC_PER_RAD/angularScale
    lengthMeters = lengthLambda*wavelengthMeters
    if units == 'm':
        length = lengthMeters
    elif units in ['kl','klambda','kilolambda']:
        length = lengthMeters/wavelengthMeters
    else:
        print "Unrecognized units"
        length = 0
    return(length)

def roundFigures(value, digits):
    """
    This function rounds a floating point value to a number of significant figures.
    value: value to be rounded (between 1e-20 and 1e+20)
    digits: number of significant digits, both before or after decimal point
    -Todd Hunter
    """
    if (value != 0.0):
        if (np.log10(np.abs(value)) % 1 < np.log10(5)):
            digits -= 1
    for r in range(-20,20):
        if (round(value,r) != 0.0):
            value = round(value,r+digits)
            break
    return(value)

def roundFiguresToString(value, digits, zeroPad=True, value2=None, maxAfterDecimal=None, 
                         avoidZero=False):
    """
    Takes a floating point value and converts it to a string containing only
    the specified number of significant digits.
    value: value to be rounded (between 1e-20 and 1e+20)
    digits: number of significant digits to show
    zeroPad: if True, then return 72.9200 if digits=6; otherwise, return 72.92
    value2: if specified, then display this number in parentheses after the
       first number, using the same number of digits after the decimal point.
       This is useful for formatting the uncertainty of a measurement.
    maxAfterDecimal: after generating a string, then clip to this number of digits
       after the decimal.  Useful for when data is dynamic range limited.
    avoidZero: if True, then disallow 0.0 as the uncertainty, and force 0.1
    -Todd Hunter
    """
    originalValue = value
    value = roundFigures(value, digits)
    string = '%.16f' % value
    # The following converts 3.00499999999999999999 to 3.005
    if (string.find('.') >= 0):
        candidate = str(float(string.rstrip('0').strip('.')))
    else:
        candidate = str(float(string))
    if (candidate.find('e') > 0):
        # prevent sci. notation
        candidate = string.rstrip('0').strip('.')
    if zeroPad:
        if (abs(value) < 1):
            found = [candidate.index(dig) for dig in '123456789' if dig in candidate]
            lastZero = min(found) if found else len(candidate)
            leadingZeros = candidate[candidate.find('0.'):lastZero].count('0')
            addZeros = digits - (len(candidate) - leadingZeros - candidate.count('.') - candidate.count('-'))
            candidate += addZeros*'0'
        else:
            addZeros = digits - (len(candidate) - candidate.count('.') - candidate.count('-'))
#            print "candidate = ", candidate
#            print "addzeros = ", addZeros
            if (addZeros > 0):
                candidate += addZeros*'0'
            elif (addZeros < 0):
                candidate = candidate[:candidate.find('.')]
    value = candidate
    if maxAfterDecimal is not None:
        decimal = value.find('.')
        if (decimal >= 0):
            value = value[:decimal+maxAfterDecimal+1]
    if (value2 is not None):
        if (value.find('.') < 0):
            prec = 0
        else:
            prec = len(value[value.find('.'):]) - 1
        value += ' (%.*f)' % (prec,value2)
        if avoidZero:
            # prevent zero uncertainty
            if float('%.*f'%(prec,value2)) == 0.0:
                print "Avoiding zero uncertainty (%f +- %f)" % (originalValue, value2)
                value = value.replace('(%.*f)'%(prec,value2), '(%.*f)'%(prec,value2+10**-prec))
    return(value)

def nextValidImsize(imsize):
    """
    Calls the cleanhelper tool to find the next highest valid imsize
    for clean.
    -Todd Hunter
    """
    return(cleanhelper.cleanhelper.getOptimumSize(int(imsize)))

def pickCellSize(vis='', spw='', npix=5, intent='OBSERVE_TARGET#ON_SOURCE', 
                 imsize=False, maxBaselinePercentile=95,
                 cellstring=False, roundcell=2, compare=False,
                 pblevel=0.2, config='', frequency=0, verbose=True, diameter=12):
    """
    Computes the image cell size for a dataset using the 95%-ile baseline
    length, and the specified desired number of pixels per synthesized beam.
    This is faster than the im.advise method.  Uses the mean of all spws,
    unless an spw is specified. 
    vis: measurement set to use (if '', then use config instead)
    imsize: if True, then also return the imsize array (in pixels) to reach the 
         specified pblevel, *and* the central field ID. It uses 
         cleanhelper.cleanhelper.getOptimumSize to 
         round up to next highest acceptable image size.
    maxBaselinePercentile: 100 = longest baseline; for datasets with decent
           UV coverage, 95 works well to predict the natural weighting beam, 
           while 99 gives a result closer to uniform weighting
    cellstring: if True, then return cell size as a unit string: '0.23arcsec'
    roundcell: if >0, round the cellsize to the N significant figures
    compare: if True, then also run im.advise for comparison
    pblevel: in fraction 0..1 (used to set imsize)
    config: use the specified configuration instead of a measurement set
    frequency: used along with config if vis=''
    diameter: only used if imsize=True and vis=''
    -Todd Hunter
    """
    if (len(vis) < 1):
        if (frequency <= 0 or config==''):
            print "If vis is undefined, then you must specify frequency along with config."
            return
        baselineStats = getBaselineStats(config=config,verbose=False,percentile=maxBaselinePercentile)[0]
        meanfreq = parseFrequencyArgumentToHz(frequency)
    else:
        if (not os.path.exists(vis)):
            print "Could not find measurement set."
            return
        baselineStats = getBaselineStats(vis,verbose=False,percentile=maxBaselinePercentile)[0]
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        if (spw == ''):
            spw = mymsmd.spwsforintent('*'+intent+'*')
            if (len(spw) == 0):
                spw = ''
            meanfreq = getMeanFreqs(mymsmd,spw)
        else:
            meanfreq = mymsmd.meanfreq(int(spw))

        if (type(meanfreq) == np.ndarray):
            meanfreq = np.mean(meanfreq)
        if (verbose):
            print "mean frequency = ", meanfreq
        mymsmd.close()
    cellsize = printBaselineAngularScale(baselineStats,meanfreq*1e-9,verbose=verbose) / npix
    if (roundcell > 0):
        cellsize = roundFigures(cellsize,roundcell)
    if (imsize):
        if (vis == ''):
            # This was the logic before mosaics were supported
            mysize = int(np.ceil(2*gaussianBeamOffset(pblevel,primaryBeamArcsec(frequency=meanfreq, showEquation=False, diameter=diameter))/cellsize))
            fullsize = [mysize,mysize]
            centralField = 0
        else:
            centralField, raMax, raMin, decMax, decMin = plotmosaic(vis,doplot=False,pblevel=pblevel,intent=intent)
            # Use this method all the time
            fullsize = [int(np.ceil(abs(raMax-raMin)/cellsize)), 
                        int(np.ceil(abs(decMax-decMin)/cellsize))]
    if (cellstring):
        cellsize = roundFiguresToString(cellsize, roundcell)+'arcsec'
        print "cellsize = ", cellsize
    if compare:
        myim = createCasaTool(imtool)
        myim.open(vis)
        if (type(spw) == str):
            spw = int(spw)
        myim.selectvis(spw=spw, intent=intent)
        imInfo = myim.advise()
        imadviseCellsize = imInfo[2]['value']
        print "im.advise gives %f arcsec" % (imadviseCellsize)
        myim.close()
    if (imsize):
        # convert from int64 to int (due to CAS-6493 being still unresolved)
        optimumSize = [int(cleanhelper.cleanhelper.getOptimumSize(fullsize[0])),
                       int(cleanhelper.cleanhelper.getOptimumSize(fullsize[1]))]
        return([cellsize, optimumSize, centralField])
    else:
        return(cellsize)

def makeDirtyCube(vis, spw, imagename, field=-1, mode='channel', 
                  weighting='briggs', robust=1, imagermode='csclean', npix=5, useTclean=True, imsize=-1):
    """
    Automatically chooses cell size and imsize and makes a dirty cube for a
    specified measurement set and spw.
    vis: string or list, passed to tclean
    field: ID or name; if not specified, then use first OBSERVE_TARGET source
    useTclean: if True, use tclean, otherwise use clean
    imsize: if not -1, then pass this size to (t)clean
    -Todd Hunter
    """
    if type(vis) == str:
        firstvis = vis.split(',')[0]
    else:
        firstvis = vis[0]
    if type(spw) == list:
        firstspw = spw[0]
    elif type(spw) == str:
        firstspw = spw.split(',')[0]
    else:
        firstspw = spw
        spw = str(spw)
    if not os.path.exists(firstvis):
        print "Could not find first measurement set: ", firstvis
        return
    if field == -1:
        field = getScienceTargets(firstvis, returnNames=False)[0]
        print "Picked field = ", field
    cell, myimsize, centralField = pickCellSize(firstvis, firstspw, npix=npix, imsize=True, cellstring=True)
    if imsize == -1:
        imsize = myimsize
    if os.path.exists(imagename+'.image'):
        os.system('rm -rf %s.*' % (imagename))
    if useTclean:
        print "Running tclean('%s', imagename='%s', field='%s', spw='%s', niter=0, interactive=False, cell='%s', deconvolver='hogbom', imsize='%s', weighting='%s', robust=%f)" % (vis, imagename, str(field), str(spw), cell, imsize, weighting, robust)
        tclean(vis, imagename=imagename, field=str(field), spw=spw, 
              niter=0, interactive=False, cell=cell, deconvolver='hogbom',
              imsize=imsize, weighting=weighting, robust=1)
    else:
        print "Running clean('%s', imagename='%s', field='%s', spw='%s', mode='%s', niter=0, interactive=False, cell='%s', imsize='%s', weighting='%s', robust=%f, imagermode='%s')" % (vis, imagename, str(field), str(spw), mode, cell, imsize, weighting, robust, imagermode)
        clean(vis, imagename=imagename, field=str(field), spw=str(spw), mode=mode,
              niter=0, interactive=False, cell=cell, 
              imsize=imsize, weighting=weighting, robust=1, imagermode=imagermode)

def printBaselineAngularScale(length, frequency=[], verbose=True):
    """
    Converts a baseline length into angular scale on the sky either at the
    specified frequency(s), or at the four major ALMA bands (default), using
    the formula: ARCSEC_PER_RAD*(wavelength/baseline).
    frequency can be a single integer/float or a list thereof.
    Returns the value in arc seconds of the last one in the list.
    --Todd Hunter
    """
    if (frequency == []):
        frequency = [100, 230, 345, 690]
    elif (type(frequency) == int or type(frequency) == float or 
          type(frequency) == np.float64):
        frequency = [frequency]
    for freq in frequency:
        wavelengthMeters = 0.2998/np.float(freq)
        lengthLambda = length/wavelengthMeters
        arcsec = ARCSEC_PER_RAD/lengthLambda
        if verbose:
            print "%g m corresponds to %g kilolambda and %g arcsec at %d GHz" % (length,lengthLambda*0.001,arcsec,freq)
    return(arcsec)

def printBaselineUVDistance(length, frequency=[], verbose=True):
    """
    Converts a baseline length into UV Distance either at the
    specified frequency(s), or at the four major ALMA bands (default).
    frequency can be a single integer/float or a list thereof.
    Prints a message in stdout with the values used for calculations.
    Returns the value in [kilolambda] of the last one in the list.
    --
    """
    if (frequency == []):
        frequency = [100, 230, 345, 690]
    elif (type(frequency) == int or type(frequency) == float or
          type(frequency) == np.float64):
        frequency = [frequency]
    for freq in frequency:
        wavelengthMeters = 0.2998/np.float(freq)
        lengthLambda = length/wavelengthMeters
        arcsec = ARCSEC_PER_RAD/lengthLambda
        if verbose:
            print "%g m corresponds to %g kilolambda and %g arcsec at %d GHz" % (length,lengthLambda*0.001,arcsec,freq)
    return(lengthLambda*0.001)

def farfieldDistance(vis=None, field=None, frequency=None, maxbaseline=None, 
                     intent=None, ignoreChanAvgSpws=True):
    """
    Returns the distance in AU for:  2*B_max**2 / wavelength
    vis: a measurement set from which to read the max frequency and baseline
    field: the field toward which to compute the 90th%ile projected baseline
    frequency: in GHz, or a string with units
    maxbaseline: in meters
    """
    if (vis==None and (frequency==None or maxbaseline==None)):
        print "You must specify either a measurement set, or a frequency and maxbaseline"
        return
    if (vis == None):
        hz = parseFrequencyArgumentToHz(frequency)
    else:
        if (intent == None): 
            hz = medianFrequencyOfIntent(vis,ignoreChanAvgSpws=ignoreChanAvgSpws)
        else:
            hz = medianFrequencyOfIntent(vis,intent,ignoreChanAvgSpws=ignoreChanAvgSpws)
        if (hz == None and ignoreChanAvgSpws): 
            if (intent == None): 
                hz = medianFrequencyOfIntent(vis,ignoreChanAvgSpws=False)
            else:
                hz = medianFrequencyOfIntent(vis,intent,ignoreChanAvgSpws=False)
            if (hz == None): 
                return
        print "Found median frequency = %f GHz" % (hz*1e-9)
        if (field == None):
            maxbaseline = getBaselineStats(vis)[2] # max unprojected
        else:
            maxbaseline = getBaselineStats(vis,field=field)[-1] # 90%ile proj.
    distance = 2*100*maxbaseline**2/(c_mks/hz) / au2cgs
    return(distance)

def findConfigurationFile(config):
    """
    Locates the requested antenna configuration file in CASA simmos directory.
    -Todd Hunter
    """
    if (not os.path.exists(config)):
        repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
        config = repotable + config
    if (not os.path.exists(config)):
        if (os.path.exists(config+'.cfg') == False):
            print "Could not find configuration file: %s" % (config)
            return
        config = config + '.cfg'
    return config

def configurationNearestNeighbors(config, showtop=5, threshold=None):
    """
    Identify the nearest neighbor pad to each pad in a configuration file, and
    report those with the most distance nearest neigbhors.
    showtop: if specified, show this number of top values
    threshold: if specified, show all values larger than this value (in meters)
    Return: dictionary of format: {'A101': {'name': 'A102', 'separation': 113.3451}}
    """
    stations, positions, names, nAntennas, diameters = readPadConfigurationFile(config)
    neighbor = {}
    separations = []
    for i in range(nAntennas):
        minSeparation = 1e40
        for j in range(nAntennas):
            if i != j:
                separation = np.linalg.norm(np.array(positions[i]) - np.array(positions[j]))
                if separation < minSeparation:
                    minSeparation = separation
                    neighbor[names[i]] = {'name': names[j]}
        separations.append(minSeparation)
        neighbor[names[i]]['separation'] = minSeparation
    idx = np.argsort(separations)[::-1]
    separations = np.array(separations)
    names = np.array(names)
    if threshold is None:
        N = showtop
    else:
        idx2 = np.where(separations[idx] > threshold)[0]
        N = len(idx2)
    if N==0:
        print "No nearest neighbors beyond threshold of %f m" % (threshold)
    for i in range(N):
        if threshold is None:
            print "Antenna with most distant nearest neighbor: %s. Neighbor: %s at %fm" % (names[idx[i]], neighbor[names[idx[i]]]['name'], separations[idx[i]]) 
        else:
            print "Antenna with most distant nearest neighbor: %s. Neighbor: %s at %fm" % (names[idx][idx2][i], neighbor[names[idx][idx2][i]]['name'], separations[idx][idx2][i]) 
    return neighbor
 
def readPadConfigurationFile(config, verbose=False):
    """
    Reads a pad configuration file and returns 4 arrays and an integer:
        stations: ['1']
        positions:  [[X,Y,Z]]  in the LOC frame
        names:  ['padXXX']
        nAntennas: len(stations)
        diameters: ['25']
    Looks first in the current directory, then in the CASA repository.
    -Todd Hunter
    """
    config = findConfigurationFile(config)
    if config is None:
        return
    cfile = open(config, 'r')
    lines = cfile.readlines()
    stations = []
    positions = []
    diameters = []
    if (verbose): print "parsing file = ", config
    for line in lines:
        if (line[0] == '#'):
            if (verbose): print "parsing line = ", line
            if (line.find('observatory') >= 0):
                observatory = line.split('=')[1].strip()
            if (line.find('coordsys') >= 0):
                if (line.find('coordsys') >= 0):
                    coordsys = line.split('=')[1].strip()
                if coordsys == 'XYZ':
                    cx,cy,cz,clong,clat = getCOFAForObservatory(observatory)
        else:
            if (verbose):
                print "splitting line = ", line
            tokens = line.split()
            if (len(tokens) < 4): continue
            elif (len(tokens) < 5):
                a,b,c,d = tokens
                pad = '???'
            else:
                a,b,c,d,pad = tokens
            x = float(a)
            y = float(b)
            z = float(c)
            diameters.append(float(d))
            stations.append(pad)
            if coordsys == 'XYZ':
                # e.g. VLA config files;  convert to LOC to be like ALMA Cycle X files
                x,y,z = simutil.simutil().itrf2loc(x,y,z,cx,cy,cz)
            positions.append([x,y,z])
    nAntennas= len(stations)
    names = ['pad%03s'%(x) for x in stations]
    cfile.close()
    return stations, positions, names, nAntennas, diameters

def getPadsForConfig(config):
    """
    Returns a list of antenna pads from an ALMA configuration file
    config: use the specified configuration file
    -Todd Hunter
    """
    returnValue = readPadConfigurationFile(config, verbose=False)
    if (returnValue == None): return
    stations, positions, names, nAntennas, diameters = returnValue
    names = [pad.replace('pad','') for pad in names]
    return names

def padHeightRange(filename, binwidth=20):
    """
    Computes the range of pad heights in the local tangent plane.
    filename: use the specified configuration file or measurement set
    binwidth: in meters (20 is used by Telcal)
    """
    z = []
    if not os.path.exists(filename):
        print "Did not find file"
        return
    if os.path.isdir(filename):
        pads = getPadPositions(filename).keys()
    else:
        pads = getPadsForConfig(filename)
    if (pads == None): return
    for pad in pads:
        east, north, up = getPadLOC(pad)
        z.append(up)
    
    hist, bin_edges = np.histogram(z, bins=np.arange(np.min(z)-0.5*binwidth, np.max(z)+0.5*binwidth, binwidth))
    line =  "Height range: %.1fm (%.1f to %.1f). " % (np.max(z)-np.min(z), np.min(z), np.max(z))
    print line+" For bins of size %.1fm, there are %d populated bins." % (binwidth, len(np.where(hist > 0)[0]))

def getPadXYZ(pad=None, returnPads=False):
    """
    Returns the Earth centered ITRF coordinates of an arbitrary ALMA pad as converted from 
    its local tangent plane coordinates in AOS_Pads__XYZ_ENU.txt distributed with analysisUtils. 
    pad: string, or list of strings;  None -> return all pads
    if pad is single pad, then return a tuple (X,Y,Z,padname)
    otherwise return a tuple of arrays: (array(X), array(Y), array(Z), array(padnames))
    -Todd Hunter
    """
    result = getPadLOC(pad, returnPads=returnPads)
    if type(result) == list or type(result) == np.ndarray:
        x = result[0]
        y = result[1]
        z = result[2]
        if returnPads:
            names = result[3]
            name = names[0]
    else:
        x = [result[0]]
        y = [result[1]]
        z = [result[2]]
        if returnPads:
            name = result[3]
    u = simutil.simutil()
    X = []; Y = []; Z = []
    # The following values are the 0,0,0 position of MASTER from R. Hills' spreadsheet
    longitude, latitude, altitude = u.xyz2long(2225205.092, -5440307.774, -2481019.066, 'WGS84')
    for i in range(len(x)):
        # the following takes the difference between the entries for A001 in AOS_Pads_XYZ_ENU.txt and 
        # in R. Hills' spreadsheet to convert from LOC tangent plane in .txt file to LTP in spreadsheet
        xyz = u.locxyz2itrf(np.degrees(latitude), np.degrees(longitude), altitude, x[i]+5.606192499-33.89413, 
                            y[i]+7.646657746-712.7516, z[i]-2.087775605+2.3301)
        X.append(xyz[0])
        Y.append(xyz[1])
        Z.append(xyz[2])
    if returnPads:
        if len(X) == 1:
            return X[0], Y[0], Z[0], name
        else:
            return np.array(X), np.array(Y), np.array(Z), np.array(names)
    else:
        if len(X) == 1:
            return X[0], Y[0], Z[0]
        else:
            return np.array(X), np.array(Y), np.array(Z)

def findNearestPadToXYZ(xyz):
    """
    Computes the nearest ALMA pad to the specified ITRF coordinate
    xyz: a single array or tuple of [X,Y,Z] in ITRF coordinates
    -Todd Hunter
    """
    x, y, z, names = getPadXYZ(returnPads=True)
    separations = []
    for i in range(len(x)):
        separations.append(np.linalg.norm([xyz[0] - x[i], xyz[1] - y[i], xyz[2] - z[i]]))
    idx = np.argmin(separations)
    print "Nearest pad = %s (%.1f m away)" % (names[idx], separations[idx])
    return names[idx]

def getPadLOC(pad=None, neighbor=False, diameter=12, vis=None, antenna=None,
              returnPads=False):
    """
    Returns the local tangent plane coordinates of the specified
    ALMA pad from the file AOS_Pads_XYZ_ENU.txt distributed with
    analysisUtils.  This function is only strictly needed if
    (casadef.subversion_revision < '25324'), as
    later versions can use getCOFA along with simutil.itrf2loc, but
    this is still a convenient method.
    pad: if None is specified, it returns all pads
         if a list is specified, it returns a list of positions
         if a single name is specified, it returns a single position
    neighbor: if True, and if a single pad is specified, also return
         its nearest neighbor and its distance and relative azimuth.
         If an integer, return the nth closest neighbor.
    diameter: of antenna in meters, used to calculate maximum elevation
         for shadowing by neighboring pad (neglecting pad height difference)
    vis: if specified, get the date of observation, and possibly the pad from
         this measurement set
    antenna: if vis is specified, then get the pad for this antenna name
    returnPads: if True, then return pad name(s).  The default needs to 
         be False so that 4.1 data delivery scripts will still run.
    Returns:
    if a single pad is requested, then it returns a tuple of 3 or 4 entries: 
          (5.606192499, 7.646657746, -2.087775605, 'A001')
    if multiple pads are requested, then it returns a list:
          [[-7557.874468, 550.9615648, -445.2271435, 'W201'],
           [-6448.301275, 1849.946563, -339.2838017, 'W202']]
    -Todd Hunter
    """
    almafile = os.path.dirname(__file__) + '/AOS_Pads_XYZ_ENU.txt'
    if (os.path.exists(almafile) == False):
        print "Could not find file: ", almafile
        return
    f = open(almafile,'r')
    lines = f.readlines()
    X = []
    Y = []
    Z = []
    padList = []
    for line in lines:
        if  line.find('#')<0:
            tokens = line.split()
            X.append(float(tokens[0]))
            Y.append(float(tokens[1]))
            Z.append(float(tokens[2]))
            padList.append(tokens[4])
    if (pad is None and vis is None):
        if (returnPads):
            return [X,Y,Z,padList]
        else:
            return [X,Y,Z]
    else:
        if (type(pad) == list):
            mylist = []
            for p in pad:
                ind = find(array(padList) == p)
                if (len(ind) > 0):
                    if returnPads:
                        mylist.append([X[ind],Y[ind],Z[ind],p])
                    else:
                        mylist.append([X[ind],Y[ind],Z[ind]])
                else:
                    print "%s: No such pad at AOS!" % (p)
                    return(0,0,0)
            return mylist
        else:
            if (pad == None):
                result = getAntennaInfo(vis)
                if (result == None):
                    print "Could not find vis."
                    return
                x,y,d,pads,names = result
                pad = pads[names.index(antenna)]
                print "Antenna %s is on pad %s" % (antenna,pad)
            ind = find(array(padList) == pad)
            if (neighbor != False):
                if (len(ind) > 0):
                    mindistance = 1e10
                    distances = []
                    for i,n in enumerate(padList):
                        distances.append(((X[i]-X[ind])**2 + (Y[i]-Y[ind])**2 +
                                          (Z[i]-Z[ind])**2) ** 0.5)
                    idx = np.argsort(distances)
                    # first entry will be itself
                    if neighbor == True:
                        neighbor = 1
                    pad2 = padList[idx[neighbor]]
                    distance = distances[idx[neighbor]]
                    azimuth = np.degrees(np.arctan2(X[idx[neighbor]]-X[ind],
                                                    Y[idx[neighbor]]-Y[ind]))
                    if (azimuth < 0): azimuth += 360
                    print "nth nearest neighbor is %s at %.2f m away at azimuth %.0f deg." % (pad2, distance, azimuth)
                    if (diameter>=distance):
                        print "The nearest pad is closer than the antenna diameter!"
                    else:
                        print "Maximum elevation for shadowing = %.1f deg" % (np.degrees(np.arcsin(diameter/distance)))
                    return(X[ind],Y[ind],Z[ind], pad, pad2, distance, azimuth)
                else:
                    print "%s: No such pad!" % (pad)
                    return(0,0,0)
            else:
                if (len(ind) > 0):
                    if (returnPads):
                        return(X[ind],Y[ind],Z[ind], pad)
                    else:
                        return(X[ind],Y[ind],Z[ind])
                else:
                    print "%s: No such pad!" % (pad)
                    return(0,0,0)

def parseUvrange(uvrange, frequency=None):
    """
    Accepts a string specifying uvrange (in meters or klambkda)
    and converts it to minimum and maximum baseline lengths.
    If klambda is specified, then frequency must be specified
    uvrange:  e.g. '0~1000klambda' or '0~20m', or '50~200' (meters assumed)
    frequency: Hz, GHz, or string with units
    Returns: 2 values in meters
    """
    if (uvrange.find('kl') >= 0):
        if (frequency == None):
            print "If you use klambda, then you must specify the frequency."
            return
        tokens = uvrange.replace('klambda','').replace('kl','').split('~')
        klambda = True
    else:
        klambda = False
        tokens = uvrange.replace('m','').split('~')
    if (len(tokens) != 2):
        print "uvrange must be specified by two numbers, in the format: '5~40'"
        return
    uvmin = float(tokens[0])
    uvmax = float(tokens[1])
    if (klambda):
        uvmin *= 1000 * c_mks / parseFrequencyArgumentToHz(frequency)
        uvmax *= 1000 * c_mks / parseFrequencyArgumentToHz(frequency)
    return(uvmin,uvmax)

def effectiveAntennas(baselines):
    """
    Computes the effective number of antennas for a given number of baselines.
    -Todd Hunter
    """
    return((1+(8*baselines+1)**0.5) / 2.0)

def getBaselinesInMainTable(vis):
    """
    For datasets with multiple observation IDs, the antennas in each observation
    may differ, so there may not be visibility data for every possible baseline
    judged solely from the list in the antenna table.  This function looks for
    all baseline combinations in the main visibility table, and returns only
    those (as an array of 2-element integer tuples).
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    ant1 = mytb.getcol('ANTENNA1')
    ant2 = mytb.getcol('ANTENNA2')
    mytb.close()
    uniqueAnts = np.unique(list(np.unique(ant1)) + list(np.unique(ant2)))
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    n = mymsmd.nantennas()
    mymsmd.close()
#    mylist = [(ant1[i],ant2[i]) for i in range(len(ant1))]  # worked in CASA 4.7.2, but fails in 5.x due to bug in numpy
    mylist = np.array([(ant1[i],ant2[i]) for i in range(len(ant1))], dtype=[('foo','i4'), ('bar','i4')])
    baselines = [(i[0],i[1]) for i in np.unique(mylist)]
    print "Found %d baselines out of a potential %d" % (len(baselines),n*(n-1)/2)
    return baselines

def getBaselineLengths(msFile='', sort=True, length=None, rigorous=False,
                       subarraySize=0, percentile=None, field='', azimuth=None,
                       elevation=None, uvrange='', config=None, debug=False,
                       unflagged=False, flaggedFraction=0.9, flagStats=None,
                       antenna=[], histogram=False, nbins=None, linear=True,
                       plotfile=None, frequency=None, verbose=True, 
                       includeIDs=False, returnLengthsOnly=False, digits=2,
                       units='m', intent='OBSERVE_TARGET#ON_SOURCE', mymsmd=None):
    """
    Determines the baseline lengths for the specified ms and returns a
    list of tuples with the first value being the baseline string and the
    second value being the baseline length in meters. If the length parameter
    is given, it instead returns the maximum number of antennas in a
    subarray configuration where all baselines are less than this value,
    and the corresponding list of antenna names. If the percentile parameter
    is given, then it computes the baseline length corresponding to that
    percentile and proceeds to use it as the length parameter.

    length:  find the subarray with the most antennas for which the longest
             baseline is less than this value (in meters)
    percentile: compute and use the length corresponding to this percentile of
             the baseline lengths for the configuration.
    sort=True sorts by baseline length, sort=False sorts by antenna name
    rigorous=Performs a full analysis of all possible combinations of
           N-1 antennas, then N-2, etc. until it find one that meets the
           length criterion.  Fast for ACA, but slow for >=32 antennas!
    subarraySize: in the option rigorous, this number of antennas tells it
           where to start its checks (going downward), which greatly speeds
           the calculation; default=0 ==> start with all N antennas in dataset
    field: if not blank, then find the first integration on the specified
           field ID or name, get its az&el and compute the projected baseline length
    azimuth,elevation: if field=='', and these are both set (in degrees),
           then compute the projected baseline length toward this direction
    uvrange: a string range in meters: '5~40'.  If present, then compute the
       number of baselines within the specified range. Can also use kilolambda: '4~30kl'
    config: a configuration file to read, instead of a visibility file
    unflagged: if True, then only return baselines to antennas that are not flagged
               if False, return all baselines
    flaggedFraction: 0..1, used by the unflagged option
    flagStats: a 'report0' dictionary, previously returned by the af tool; if not
             specified, then it will be computed; used by the unflagged option
    antenna: restrict to a single antenna or list of antennas (names)
    histogram: if True, then produce a histogram
    nbins: number of bins in histogram, default = automatic
    linear: if True, use linear bins along x-axis, otherwise use log
    plotfile: name of plotfile to produce, or True for automatic naming
    frequency: used with uvrange parameter if klambda units are specified in uvrange string
    includeIDs: if True, then also include antenna IDs in the baseline name
    returnLengthsOnly: if True, then omit the baseline names and return a list 
            of lengths as floats rounded to number of digits specified
    units: length units to report (default='m' for meters), or 'kl' for kilolambda=klambda
    intent: only used if frequency is not given
    For further help and examples, see
       http://casaguides.nrao.edu/index.php?title=GetBaselineLengths
    Todd Hunter
    """
    if (units not in ['m','kl']):
        print "length units must be either 'm' or 'kl'."
        return
    if (config == None):
        if (os.path.exists(msFile+'/ANTENNA') == False):
            print "Could not find table = ", msFile+'/ANTENNA'
            return
        if (percentile is not None):
            tokens = getBaselineStats(msFile, percentile=percentile,field=field)
            length = tokens[0]
        mytb = createCasaTool(tbtool)
        try:
            mytb.open(msFile+'/ANTENNA')
        except:
            print "Could not open table = ", msFile+'/ANTENNA'
            return
        names = list(mytb.getcol('NAME'))
        nAntennas = len(names)
        if (nAntennas < 17 and rigorous==False and length is not None):
            print "getBaselineLengths(): Switching to rigorous mode for better accuracy"
            rigorous = True
        positions = np.transpose(mytb.getcol('POSITION'))
        stations = mytb.getcol('STATION')
        mytb.close()
    else:
        returnValue = readPadConfigurationFile(config, verbose=False)
        if (returnValue is None): return
        stations, positions, names, nAntennas, diameters = returnValue
        
    # Now figure out where it ranks in the array
    l = {} # holds a list of tuples of of format: ('DA45-DV13', 7222.22)
    uvl = {}
    mostNeighbors = 0
    neighborlist = []
    mylengths = [[0.0 for i in range(nAntennas)] for j in range(nAntennas)]
    if (uvrange != '' or units == 'kl'):
        if (frequency==None):
            frequency = medianFrequencyOfIntent(msFile,intent)
    if (uvrange != ''):
        uvrangeBaselines = 0
        uvmin, uvmax = parseUvrange(uvrange, frequency)
    if (field != ''):
        if (type(field) == str):
            # may need to convert to int
            if (field.isdigit()):
                field = int(field)
            elif field in getFields(msFile):
                field = list(getFields(msFile)).index(field)
            else:
                print "Field %s not in the ms. It has: %s" % (field,str(getFields(msFile)))
                return
        # field will now be an int
        nfields = len(getFields(msFile))
        if (field not in range(nfields)):
            print "Field %d not in the ms, only %s" % (field,str(range(nfields)))
            return
        # get the az,el of the observation, which amounts to getting the
        # UT time of the first integration and the observatory location.
        # open the ms, and look for first scan on field
        mydirectionRadians = getRADecForField(msFile, field, usemstool=True)
        if (casadef.casa_version >= casaVersionWithMSMD):
            needToClose = False
            if mymsmd is None:
                needToClose = True
                mymsmd = createCasaTool(msmdtool)
                mymsmd.open(msFile)
            myscans = mymsmd.scansforfield(field)
            if len(myscans) == 0:
                print "No scans for field %s in %s" % (str(field), msFile)
            scan = np.min(myscans)
            myscantime = np.mean(mymsmd.timesforscan(scan))
            telescopeName = mymsmd.observatorynames()[0]
            if needToClose:
                mymsmd.close()
        else:
            vm = ValueMapping(msFile)
            scan = np.min(vm.getScansForField(field))
            myscantime = np.mean(vm.getTimesForScans(scan))
            telescopeName = getObservatoryName(msFile)
        print "  Using scan %d to compute projected baseline lengths for %s" % (scan, rad2radec(mydirectionRadians))
        myazel = computeAzElFromRADecMJD(mydirectionRadians, myscantime/86400., telescopeName)
        source_el = myazel[1]*180/pi
        source_az = myazel[0]*180/pi
        projected = True
    elif (elevation is not None and azimuth is not None):
        source_el = elevation
        source_az = azimuth
        projected = True
        telescopeName = getObservatoryName(msFile)
    else:
        projected = False
    if (projected):
        if (telescopeName.find('ALMA') < 0 and telescopeName.find('ACA') < 0 and
            casadef.subversion_revision<'25324'):
            print "In casa revisions < 25324, computation of the projected baselines is only\n supported for ALMA, not %s." % (telescopeName)
            return
        u = simutil.simutil()
    if (type(antenna) == str):
        if (antenna == ''):
            antenna = []
        else:
            antenna = [antenna]
    uvrangeLengths = []
    if (len(msFile) > 0):
        obsIDs = len(getObservationIDs(msFile))
    else:
        obsIDs = 1
    if (obsIDs > 1):
        baselines = getBaselinesInMainTable(msFile)
    droppedBaselines = 0
    for i in range(nAntennas):
      if (names[i] in antenna or antenna==[]):
        neighborlist.append([names[i]])
        # For the ith antenna, we now measure each baseline, and if it is less
        # than half the specified criterion, we add it to the neighborlist for
        # the ith antenna.  This will yield a group of antennas within a circle
        # of diameter of length centered near the ith antenna.
        for j in range(nAntennas):
            if ((antenna==[] and j<i+1) or i==j): continue
            if (obsIDs > 1):
                if (i,j) not in baselines: 
                    droppedBaselines += 1
                    continue
            x = positions[i][0]-positions[j][0]
            y = positions[i][1]-positions[j][1]
            z = positions[i][2]-positions[j][2]
            mylengths[i][j] = (x**2 + y**2 + z**2)**0.5
            if (projected):
                # convert length to projected. the formula for azimuth and elevation
                # assumes that x,y,z are in local coordinates, not UTM, so until
                # itrf2loc returns all 3 coords, we have to read the pad coordinates
                # from AOS_Pads_XYZ_ENU.txt.
                if (casadef.subversion_revision < '25324'):
                    # The only telescope that will reach this point is ALMA or ACA.
                    x0,y0,z0 = getPadLOC(stations[i])
                    x1,y1,z1 = getPadLOC(stations[j])
                else:
                    cx,cy,cz,Long,Lat = getCOFA(msFile)
                    if (debug):
                        print "Calling u.itrf2loc(%f,%f,%f,%f,%f,%f)" % (positions[i][0],positions[i][1],positions[i][2],cx,cy,cz)
                    x0,y0,z0 = u.itrf2loc(positions[i][0],positions[i][1],positions[i][2],cx,cy,cz)
                    x1,y1,z1 = u.itrf2loc(positions[j][0],positions[j][1],positions[j][2],cx,cy,cz)
                x = x0-x1
                y = y0-y1
                z = z0-z1
                elevation = np.arcsin(z / mylengths[i][j]) * 45/np.arctan(1.0) 
                azimuth = 90 - (45/np.arctan(1.0))*np.arctan2(y,x)
                # formula from http://saj.matf.bg.ac.yu/177/pdf/115-124.pdf 
                cosTheta = np.cos(elevation*pi/180.)*np.cos(source_el*pi/180.)*np.cos((azimuth-source_az)*pi/180.) + \
                           np.sin(elevation*pi/180.)*np.sin(source_el*pi/180.)
                mylengths[i][j] *= np.sin(np.arccos(cosTheta))
                if (type(mylengths[i][j]) == np.ndarray):
                    # u.itrf2loc (above) returns arrays of length 1
                    mylengths[i][j] = mylengths[i][j][0]
            mykey = '%s-%s'%(names[i],names[j])
            if includeIDs:
                if (mykey != ''):
                    mykey += ' - '  # must be dash so that splitting will still work in 'if (sort)' option
                mykey += '%2d-%2d'%(i,j)
            if (uvrange != ''):
                if (mylengths[i][j] > uvmin and mylengths[i][j] < uvmax):
                    uvrangeLengths.append(mylengths[i][j])
                    uvrangeBaselines += 1
                    uvl[mykey] = mylengths[i][j]
            l[mykey] = mylengths[i][j]
            if (units == 'kl'):
                # convert from meters to kilolambda
                l[mykey] /= 1000*c_mks/parseFrequencyArgumentToHz(frequency)
            if (length is not None):
                if (mylengths[i][j] < length*0.5):
                    neighborlist[i].append(names[j])
        if (length is not None):
            if (len(neighborlist[i]) > mostNeighbors):
                mostNeighbors = len(neighborlist[i])
                bestAntenna = i
      # end 'if'
    # end 'for' loop over antennas
    if droppedBaselines > 0:
        print "Dropped %d baselines which do not appear in the main visibility table." % droppedBaselines
    if (uvrange != ''):
        maxlength = np.max(uvrangeLengths)
        minlength = np.min(uvrangeLengths)
        rmslength = np.sqrt(np.mean(np.array(uvrangeLengths)**2))
    else:
        flatlengths = np.array(mylengths).flatten()
        flatlengths = flatlengths[np.where(flatlengths > 0)[0]]
        maxlength = np.max(flatlengths)
        minlength = np.min(flatlengths)
        rmslength = np.sqrt(np.mean(flatlengths**2))
    if (units == 'kl'):
        # convert from meters to kilolambda
        maxlength /= 1000*c_mks/parseFrequencyArgumentToHz(frequency)
        minlength /= 1000*c_mks/parseFrequencyArgumentToHz(frequency)
        rmslength /= 1000*c_mks/parseFrequencyArgumentToHz(frequency)
        if (uvrange == ''):
            flatlengths /= 1000*c_mks/parseFrequencyArgumentToHz(frequency)

    if (length == None):
        if verbose:
            print "Found %d baselines (%d stations)" % (len(l),nAntennas)
            if (projected):
                print "Projected lengths toward the source:  min=%f, max=%f, rms=%f %s" % (minlength, maxlength, rmslength, units)
                # also print the values in klambda
            else:
                print "Unprojected lengths:  min=%f, max=%f, rms=%f %s" % (minlength, maxlength, rmslength, units)
        if (uvrange != ''):
            print "%d baselines are within the uvrange %.2f-%.2fm" % (uvrangeBaselines,uvmin,uvmax)
            print "Effective number of antennas = %.1f" % (effectiveAntennas(uvrangeBaselines))
        if (histogram):
            if (uvrange != ''):
                flatlengths = uvrangeLengths
            if (nbins==None):
                nbins = len(flatlengths)/10
            if linear:
                bins = np.linspace(0,np.max(flatlengths),nbins)
            else:
                bins = np.logspace(0,np.log10(np.max(flatlengths)),nbins)
                print "bins = ", bins
            pb.clf()
            pb.hist(flatlengths, bins=bins) 
            pb.ylabel('Number of baselines')
            pb.xlabel('Baseline length (%s)'%units)
            pb.title(msFile + ' (scan=%d)'%scan)
            if (plotfile is not None):
                if plotfile == True:
                    png = '%s_baseline_histogram.png'%msFile
                else:
                    png = plotfile
                pb.savefig(png)
                print "Left histogram in %s" % png
        if (sort):
            if (uvrange != ''):
                sortedBaselines= sorted(uvl.items(), key=operator.itemgetter(1))
            else:
                sortedBaselines = sorted(l.items(), key=operator.itemgetter(1))
            if (unflagged):
                unflaggedBaselines = []
                unflaggedAntennas, flaggedAntennas = getUnflaggedAntennas(msFile,flaggedFraction,flagStats)
                for sb in sortedBaselines:
                    ant1 = sb[0].split('-')[0].strip()
                    ant2 = sb[0].split('-')[1].strip()
                    if (ant1 in unflaggedAntennas and ant2 in unflaggedAntennas):
                        unflaggedBaselines.append(sb)
                if (len(unflaggedBaselines) != len(sortedBaselines)):
                    print "Found %d baselines to antennas that are unflagged" % (len(unflaggedBaselines))
                sortedBaselines = unflaggedBaselines
            if returnLengthsOnly:
                return(np.round(np.array(np.transpose(sortedBaselines)[1],dtype=float),digits))
            else:
                return(sortedBaselines)
        else:
            if (uvrange != ''):
                if returnLengthsOnly:
                    return(np.round(np.array(np.transpose(uvl)[1], dtype=float),digits))
                else:
                    return(uvl)
            else:
                if returnLengthsOnly:
                    return(np.round(np.array(np.transpose(l)[1], dtype=float), digits))
                else:
                    return(l)
    elif (rigorous == False):
        return(mostNeighbors,neighborlist[bestAntenna])

    # Now do the rigorous calculation
    maxlengthFullArray = maxlength
    foundSubarray = []
    if (subarraySize == 0):
        dropAntsStart = 1
    else:
        dropAntsStart = nAntennas-subarraySize
    for dropAnts in range(dropAntsStart, nAntennas-2):
        myiterator = itertools.combinations(names, nAntennas-dropAnts)
        ctr = 0
        for subarray in myiterator:
            ctr += 1
        trials = ctr
        notify = trials/100
        print "Testing %d configurations with %d antennas" % (ctr, nAntennas-dropAnts)
        myiterator = itertools.combinations(names, nAntennas-dropAnts)
        minimumMaxlength = maxlengthFullArray
        ctr = 0
        for subarray in myiterator:
            ctr += 1
            nAntennasInSubarray = len(subarray)
            maxlength = 0
            for i in range(nAntennasInSubarray):
                for j in range(i+1,nAntennasInSubarray):
                    ipos = names.index(subarray[i])
                    jpos = names.index(subarray[j])
                    mylength = ((positions[ipos][0]-positions[jpos][0])**2 +
                                (positions[ipos][1]-positions[jpos][1])**2 +
                                (positions[ipos][2]-positions[jpos][2])**2)**0.5
                    if (mylength > maxlength):
                        maxlength = mylength
            if (trials > 10000):
                if (ctr%notify == 0):
                    print "Done %d%%" % (ctr*100/trials)
            if (maxlength < length):
                foundSubarray = subarray
                print "Found a subarray that met the criterion on the %dth try (%.1f%%)" % (ctr,ctr*100.0/trials)
                break
            if (maxlength < minimumMaxlength):
                minimumMaxlength = maxlength
        if (maxlength > length):
            print "   smallest maximum baseline length = %.2f%s" % (minimumMaxlength,units)
        if (foundSubarray != []):
            break
    mostNeighbors = len(foundSubarray)
    return(mostNeighbors,foundSubarray)

def getBaselineLength(msFile='', ant1='', ant2='', help=False, verbose=True) :
    """
    Computes the specified baseline's length in meters.  The antennas
    can be specified by name string or ID number.
    Also compute its percentile length for the configuration.
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/GetBaselineLength
    Todd Hunter (June 2011)
    """
    if (help):
        print "Usage example: getBaselineLength(ms, 'DV01', 'DV02')"
        return
    try:
        tb.open(msFile+'/ANTENNA')
    except:
        print "Could not open table = ", msFile+'/ANTENNA'
        return
    if (type(ant1) == str):
        if (len(ant1) < 1):
            print "You must specify two separate antenna names or IDs"
            return
    if (type(ant2) == str):
        if (len(ant2) < 1):
            print "You must specify two separate antenna names or IDs"
            return
    names = tb.getcol('NAME')
    positions = np.transpose(tb.getcol('POSITION'))
    tb.close()
    position = []
    j = 0
    for i in range(len(names)):
        if (isinstance(ant1,str)):
            if (names[i] == ant1):
                position.append(positions[i])
                ant1 = i
                j += 1
        else:
            if (i == ant1):
                position.append(positions[i])
                j += 1
        if (isinstance(ant2,str)):
            if (names[i] == ant2):
                position.append(positions[i])
                ant2 = i
                j += 1
        else:
            if (i == ant2):
                position.append(positions[i])
                j += 1
        if (j==2):
            break
    if (j<2):
        print "Did not find both antennas: %s, %s" % (ant1,ant2)
        print "Found: ", names
        length = 0
        return length
    else:
        length = ((position[0][0]-position[1][0])**2+
                  (position[0][1]-position[1][1])**2+
                  (position[0][2]-position[1][2])**2
                  )**0.5
        if (verbose):
            print "Length of %s-%s (%d-%d) is %.3f m." % (names[ant1],names[ant2],ant1,ant2,length)
    # Now figure out where it ranks in the array
    l = []
    for i in range(len(names)):
      for j in range(i,len(names)):
          if (i != j):
             l.append(((positions[i][0]-positions[j][0])**2 +  (positions[i][1]-positions[j][1])**2 +
                  (positions[i][2]-positions[j][2])**2)**0.5)
    sortedBaselines = np.sort(l)
    nBaselines = len(sortedBaselines)
    for i in range(nBaselines):
#        print sortedBaselines[i]
        if (length <= sortedBaselines[i]):
            if (verbose):
                print "Of %d baselines, this baseline length is percentile %.0f, where 100=longest." % (nBaselines,i*100.0/(nBaselines-1))
            break
    return length,names[ant1],names[ant2]

def freqif(vis, freq) :
    """
    A Castro Carrizo (August 2011)
    Computes the frequency values corresponding to the different freq planes, which is particularly
    useful for the investigation of spurious signals generated in the system
    Sky (GHz)
    IF1 (4-8) or (5-10) depending on band (GHz)
    IF2 (2-4) (GHz)
    IF3 (0-2) (GHz) + channel numbering 
    entries: vis = ms file - if empty, it would read some defaults from script;
                           possible improvement could be that flo1 and flo2 would be given as inputs
             freq = input freq, which could be in sky, if1 or if2 units (always GHz). If empty, it 
                    will give all the details about LOs and spectral configuration.
    If LO4s are introduced in future ASDM datasets to define the position of the spectral unit within
    the IF3 window, this is to be read and included in the script to properly calculate the channel
    numbering
    """
    viss="no"+vis+"ne" 
    freqq="no"+freq+"ne"
    out_of_range=True
    if freqq == 'none' and viss != 'none':  
        tb.open("%s/SPECTRAL_WINDOW" % vis)
        bb = tb.getcol("BBC_NO")           # num unidad
        freq = tb.getcol("REF_FREQUENCY")  # freq cada unidad
        numchan = tb.getcol("NUM_CHAN")    # num channels
        tbw = tb.getcol("TOTAL_BANDWIDTH") # total bandwidth
        tb.close()
        try:
            tb.open("%s/ASDM_RECEIVER" % vis)
        except:
            print "Could not open ASDM_RECEIVER table:"
            print " ' asdm2MS --asis='*' ' may be needed "
            return([])
        numLO = tb.getcol('numLO')  # num of used spectral units
        freqLO = []
        band = []
        spws = []
        names = []
        for i in range(len(numLO)):
            freqLO.append(tb.getcell('freqLO',i))
            band.append(tb.getcell('frequencyBand',i))
            spws.append(int((tb.getcell('spectralWindowId',i).split('_')[1])))
            names.append(tb.getcell('name',i))
        tb.close() 
        print "SPECTRAL_WINDOW ...."
        print "basebands", bb
        print "Sky freqs (ghz)? ", freq/1e9
        print "num chan", numchan
        print "total bw (mhz)", tbw/1e6
        print ""
        print "ASDM_RECEIVER ...."
        print "numLO ", numLO
        for i in range(len(numLO)):
            print "freqLO (ghz)", freqLO[i]/1e9
        print "band", band
        print "spws", spws
        print "names", names
        return([])
 
    paras=float(freq)

    if paras > 12.:
        skyfreq=True
    else:
        skyfreq=False
    
      
    if viss != 'none':              # read spect config from ms file
        tb.open("%s/SPECTRAL_WINDOW" % vis)
        bb = tb.getcol("BBC_NO")           # num unidad
        freq = tb.getcol("REF_FREQUENCY")  # freq cada unidad
        numchan = tb.getcol("NUM_CHAN")    # num channels
        tbw = tb.getcol("TOTAL_BANDWIDTH") # total bandwidth
        tb.close()

        try:
            tb.open("%s/ASDM_RECEIVER" % vis)
        except:
            print " "
            print "Could not open ASDM_RECEIVER table:"
            print " ' asdm2MS --asis='*' ' may be needed "
            return([])
        numLO = tb.getcol('numLO')  # num of used spectral units
        freqLO = []
        band = []
        spws = []
        names = []
        for i in range(len(numLO)):
            freqLO.append(tb.getcell('freqLO',i))
            band.append(tb.getcell('frequencyBand',i))
            spws.append(int((tb.getcell('spectralWindowId',i).split('_')[1])))
            names.append(tb.getcell('name',i))
        tb.close() 
        numbb=(len(numLO)-1)/2
        flo1=freqLO[0]/1e9
        flo2=pb.zeros(numbb)
        flo3=pb.zeros(numbb)
        nchan=pb.zeros(numbb,int)
        c=0
        for i in range(1,len(numLO),2):  #BB_1,3,5,7...
            flo2[c]=freqLO[i][1]/1e9
            flo3[c]=freqLO[i][2]/1e9
            nchan[c]=numchan[i]
            c=c+1

        if1min = 4000.0/1e3          
        kk=band[1]   # a unique band is observed -- TO BE ADAPTED 
        if kk[9]=='6':
            if1min = 5000.0/1e3
        if1max = 8000.0/1e3 
        if kk[9]=='1' or kk[9]=='2' or kk[9]=='9' or kk[9]=='10':
            if1max = 12000.0/1e3
        elif kk[9]=='6':
            if1max = 10000.0/1e3
    else:                          # no ms file to read spect config 
        numbb = 4  # for general use it's worth to adapt this part to be read as input parameters(freq,lo1,lo2s)
        # 
        freq = [1.8342e11, 8.71848362499E10, 8.71848362499E10, 8.73020237499E10, 8.73020237499E10, 9.71848362501E10, 9.71848362501E10, 9.73020237501E10,  9.73020237501E10]
        flo1 = 92.21228               #
        flo1 = 104.26885              #
        flo2 = [9.0274437501,8.9102562501,8.9725562501,9.0897437501] #
        flo2 = [9.02744375,9.052256250,8.97255625,8.94774375]        #
        flo3 = [4.0,4.0,4.0,4.0]      #          
        nchan= [3840,3840,3840,3840]  #
        if1min = 4000.0/1e3           #
        if1max = 8000.0/1e3           #
        tbw = [1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9,1.875*1e9]  #
        tbw = [1.171875E8,1.171875E8,1.171875E8,1.171875E8,1.171875E8,1.171875E8,1.171875E8,1.171875E8,1.171875E8]   #

        
    if2min = (2000.+2000.*1/16/2)/1e3     # fix: start 2ghz band
    if2max = (4000.-2000.*1/16/2)/1e3     # fix: end 2ghz band
    if2cen = 3000./1e3
    bandif2 = 2.*15/16

    if3min = (2000.*1/16/2)/1e3           # fix: start 2ghz band  !DG output
    if3max = (2000.-2000.*1/16/2)/1e3     # fix: end 2ghz band    !
    if3cen = 1000./1e3                    #                       !
    
    if2par=pb.zeros(numbb)                #  if2 units (2-4)
    if3par=pb.zeros(numbb)                #  if3 units (0-2)
    # if3par_sbb=pb.zeros(numbb)          #  subbaseband filter number in if3 (?)
    chanpar = pb.zeros(numbb)             #  channel number

    
    for i in range(0,numbb):
        chanpar[i] = -1

    if skyfreq:
        parif1 = [False,False]              # lsb,usb 
        parif2 = [False,False,False,False,False,False,False,False] # should be limited to nunbb
        parif3 = [False,False,False,False,False,False,False,False] # should be limited to nunbb
        if1par=pb.zeros(2)                  # lsb,usb 
        if1par[0] = flo1 - paras            # if parasite in lsb
        if1par[1] = paras - flo1            # if parasite in usb
        # print if1par[0],if1par[1]

        for i in range(0,2):                # lsb,usb  
            if if1par[i] < if1max and if1par[i] > if1min:
                parif1[i] = True 
            # print " if1 = ",if1par[i],parif1[i]
                
        for i in range(0,numbb):
            if freq[(i+1)*2]/1e9 < flo1:    
                if2par[i] = flo2[i] - if1par[0]     # lsb
                #print i,' lsb',(freq[(i+1)*2]/1e9),if2par[i]
            if freq[(i+1)*2]/1e9 > flo1: 
                if2par[i] = flo2[i] - if1par[1]     # usb
                #print i,' usb',(freq[(i+1)*2]/1e9),if2par[i]
            if if2par[i] < if2max and if2par[i] > if2min:
                parif2[i] = True
                
            if3par[i] = flo3[i] - if2par[i]
            if if3par[i] < if3max and if3par[i] > if3min:
                parif3[i] = True
                # if3par_sbb[i] = ((if3par[i]-if3cen)*32./1.875)+(16.)  
                chanpar[i] = ((if3par[i]-if3cen)*nchan[i]/(tbw[(i+1)*2]/1e9)+(nchan[i]+1.)/2)  # valid if units are centered,
                                                                   # here LO4 is to be read once they're not centered anymore 
                # chanpar[i] = ((if3par[i]-if3cen)*nchan[i]/(tbw[(i+1)*2]/1e9)+(nchan[i])/2)   # valid if units are centered
                # print i,if3par[i],if3cen,(if3par[i]-if3cen),nchan[i],tbw[(i+1)*2]/1e9
            # print " if2 = ",i,if2par[i],flo2[i]
            # print " if3 = ",i,if3par[i],flo3[i]
            
    else:
        parif1 = False   
        parif2 = False  
        parif3 = False

        if (paras < 4.0) and (paras > 2.0):
            parif2 = True
        elif (paras > 4.0):
            parif1 = True

        if1par=pb.zeros(numbb)
        fsky_par=pb.zeros(numbb)
    
        if parif2:              # parasite in 2-4ghz bandwidth
            for i in range(0,numbb):
                if2par[i] = paras
                if1par[i] = flo2[i] - if2par[i]
                if3par[i] = flo3[i] - if2par[i]
                # print " parif2",if1par[i],if2par[i],if3par[i]

        if parif1:              # parasite in 4-12ghz bandwidth
            for i in range(0,numbb):
                if1par[i] = paras
                if2par[i] = flo2[i] - if1par[i]
                if3par[i] = flo3[i] - if2par[i]
                # print " parif1",if1par[i],if2par[i],if3par[i]
        
        for i in range(0,numbb):     # channel with parasite
            if if3par[i] > if3min and if3par[i] < if3max:
                # if3par_sbb[i] = ((if3par[i]-if3cen)*32./1.875)+(16.)  
                chanpar[i] = ((if3par[i]-if3cen)*nchan[i]/(tbw[(i+1)*2]/1e9)+(nchan[i]+1.)/2)  # valid if units are centered
                                                                   # here LO4 is to be read once they're not centered anymore 
                # chanpar[i] = ((if3par[i]-if3cen)*nchan[i]/(tbw[(i+1)*2]/1e9)+(nchan[i])/2)   # valid if units are centered
                # print if3par[i],if3cen,(if3par[i]-if3cen),nchan[i],tbw[(i+1)*2]/1e9
                
        for i in range(0,numbb):
            if freq[(i+1)*2]/1e9 < flo1: 
                fsky_par[i] = flo1 - 1*if1par[i]  #lsb
            if freq[(i+1)*2]/1e9 > flo1: 
                fsky_par[i] = flo1 + 1*if1par[i]  #usb
            
            
    # Present results
    # print " "
    # print " Input must be in GHz, either for Sky, LO1 or LO2 frequencies "
    print " "
    print " INPUT frequency at ...", paras, "GHz !!"
    print " "
    print " FLo1 (GHz)   =  %7.3f " %flo1
    print "        LSB=(","%5.3f" %(flo1-if1max),"-","%5.3f" %(flo1-if1min),")GHz  and  USB=(","%5.3f" %(flo1+if1min),"-","%5.3f" %(flo1+if1max),")GHz "
    print " IFLo1    LSB=(","%5.3f" %(if1max),"-","%5.3f" %(if1min),")GHz  and  USB=(","%5.3f" %(if1min),"-","%5.3f" %(if1max),")GHz "
    print " "
    # print "                   BB_1(L)    BB_2(L)    BB_3(U)    BB_4(U)" 
    print " FLo2 (GHz)   =  ", ["%7.3f" %flo2[i] for i in range(0,numbb)]
    print " IFLo2 BB_LSB=(","%5.3f" %(if2min),"-","%5.3f" %(if2max),")GHz  and BB_USB=(","%5.3f" %(if2max),"-","%5.3f" %(if2min),")GHz "
    print " "
    print " FLo3 (GHz)   =  ", ["%7.3f" %flo3[i] for i in range(0,numbb)]
    print " IFLo3 BB_LSB=(","%5.3f" %(if3max),"-","%5.3f" %(if3min),")GHz  and BB_USB=(","%5.3f" %(if3min),"-","%5.3f" %(if3max),")GHz "
    print " "
    print " N_channels   =  ", ["%i" %nchan[i] for i in range(0,numbb)]
    print "   channel width (KHz) = ", ["%7.5f" %((tbw[(i+1)*2]/1e3)/nchan[i]) for i in range(0,numbb)]
    print "     total width (MHz) = ", ["%7.3f" %((tbw[(i+1)*2]/1e6)) for i in range(0,numbb)]
    print " " 
    print " RESULTS:"

    if skyfreq:

        sb=["LSB","USB"]
        for i in range(0,2):
            if parif1[i]:
                print " Equivalent IF1 freq: %10.4f " %(if1par[i]*1000), "MHz in the IF_LO1",sb[i],",   of range (","%5.3f" %if1min,"-","%5.3f" %if1max,") GHz "
            #else:
                #print "         (deduced IF1 freq =%7.3f"  %if1par[i], sb[i],")"
                #  print parif1[i]
                out_of_range=False

        for i in range(0,numbb):
            if parif2[i]:
                print ""
                print " Equivalent IF2 freq: %10.4f " %(if2par[i]*1000), "MHz in the IF_LO2, BB_",(i+1)," of range (","%5.3f" %if2min,"-","%5.3f" %if2max,") GHz "
                out_of_range=False
                if parif3[i]:
                    print "         which is %10.6f " %(if3par[i]*1000), "MHz in the IF_LO3, BB_",(i+1)," of range (","%5.3f" %if3min,"-","%5.3f" %if3max,") GHz "
                    # print " IF_LO3 channel    = ", ["%i" %chanpar[i] for i in range(0,numbb)]
                    print " IF_LO3 channel    = ", ["%7.3f" %chanpar[i] for i in range(0,numbb)]
                    if chanpar[i] > nchan[i] or chanpar[i] < 0:
                        print "     which is out of range for the selected setup... "
                    # print " IF_LO3 SBB filter = ", ["%7.3f" %if3par_sbb[i] for i in range(0,numbb)]

        if out_of_range:
            print " The proposed frequency is out of range..."
            
    else:
        print " Sky freq (GHz) = ", ["%10.6f" %fsky_par[i] for i in range(0,numbb)]," from LSB=(","%5.3f" %(flo1-if1max),"-","%5.3f" %(flo1-if1min),") and USB=(","%5.3f" %(flo1+if1min),"-","%5.3f" %(flo1+if1max),")"
        print " IF_LO1 freq (MHz) = ", ["%10.4f" %(if1par[i]*1000) for i in range(0,numbb)]," of range (","%5.3f" %if1min,"-","%5.3f" %if1max,") GHz "
        print " IF_LO2 freq (MHz) = ", ["%10.4f" %(if2par[i]*1000) for i in range(0,numbb)]," of range (","%5.3f" %if2min,"-","%5.3f" %if2max,") GHz "
        print " IF_LO3 freq (MHz) = ", ["%10.7f" %(if3par[i]*1000) for i in range(0,numbb)]," of range (","%5.3f" %if3min,"-","%5.3f" %if3max,") GHz "

        # print " IF_LO3 channel    = ", ["%i" %chanpar[i] for i in range(0,numbb)]
        print " IF_LO3 channel    = ", ["%7.3f" %chanpar[i] for i in range(0,numbb)] # no integer, have more precision
        if chanpar[i] > nchan[i] or chanpar[i] < 0:
            print "     which is out of range for the selected setup... "
        # print " IF_LO3 SBB filter = ", ["%7.3f" %if3par_sbb[i] for i in range(0,numbb)]

    return

def ComputeDewPointCFromRHAndTempC(relativeHumidity, temperature):
    """
    inputs:  relativeHumidity in percentage, temperature in C
    output: in degrees C
    Uses formula from http://en.wikipedia.org/wiki/Dew_point#Calculating_the_dew_point
    Todd Hunter
    """
    temperature = np.array(temperature)            # protect against it being a list
    relativeHumidity = np.array(relativeHumidity)  # protect against it being a list
    es = 6.112*np.exp(17.67*temperature/(temperature+243.5))
    e = relativeHumidity*0.01*es
    if (len(np.where(e <= 0)[0]) == 0):
        dewPoint = 243.5*np.log(e/6.112)/(17.67-np.log(e/6.112))
    else:
        dewPoint = np.zeros(len(e))
    return(dewPoint)

def computeWVP(d):
    """
    This simply converts the specified temperature (in Celsius) to water vapor
    pressure, which can be used to estimate the relative humidity from the
    measured dew point.   It accepts a scalar or 1D array.
    -- Todd Hunter
    """
    # d is in Celsius, t is in Kelvin
    t = celsiusToKelvin(d)
#    print "Shape(t) = ", np.shape(t)
#    try:
#        print "log.__module__ = ", log.__module__
#    except:
#        print "log.types = ", log.types
    w = np.exp(-6096.9385/t +21.2409642-(2.711193e-2)*t +(1.673952e-5)*t**2 +2.433502*np.log(t))
    return(w)

def reweightFonts(adesc,weight='extra bold'):
    pb.setp(adesc.get_xticklabels(), weight=weight)
    pb.setp(adesc.get_yticklabels(), weight=weight)
    
def resizeFonts(adesc,fontsize):
    """
    Disable offset units and resize fonts.
    Todd Hunter
    """
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    adesc.xaxis.set_major_formatter(yFormat)
    pb.setp(adesc.get_xticklabels(), fontsize=fontsize)
    pb.setp(adesc.get_yticklabels(), fontsize=fontsize)

def resizeFontsOnly(adesc,fontsize):
    """
    Resize fonts, but do not disable offset units, as this breaks
    the xaxis labeling of plot_time().
    """
    pb.setp(adesc.get_xticklabels(), fontsize=fontsize)
    pb.setp(adesc.get_yticklabels(), fontsize=fontsize)

def estimateALMAOpacity(pwv,reffreq,airmass=1.0,h0=1.0,verbose=True,
                        P=563.0, H=20.0, T=273.0,
                        maxAltitude=48.0,   # i.e., top of atmosphere
                        dP=5.0,    # model step to use in mbar
                        dPm=1.1,   # pressure step factor (unitless)
                        ):
   """
   Estimate the zenith opacity at ALMA using J. Pardo's model in casa.
   This function is useful if the weather conditions for your specific
   observation are not available and the average weather conditions must
   be used. -- Todd Hunter
   maxAltitude: of the atmosphere, in km
   """
   altitude = 5059
   chansep=1
   numchan=1
   nb = 1
   myqa = createCasaTool(qatool)
   at.initAtmProfile(humidity=H,
                     temperature = create_casa_quantity(myqa, T, "K"),
                     altitude=create_casa_quantity(myqa, altitude,"m"),
                     pressure=create_casa_quantity(myqa, P,'mbar'),
                     atmType = TROPICAL,
                     h0 = create_casa_quantity(myqa, h0,"km"),
                     maxAltitude = create_casa_quantity(myqa, maxAltitude,"km"),
                     dP = create_casa_quantity(myqa, dP,"mbar"),
                     dPm=dPm
                     )
   fC = create_casa_quantity(myqa, reffreq,'GHz')
   fR = create_casa_quantity(myqa, chansep,'GHz')
   fW = create_casa_quantity(myqa, numchan*chansep,'GHz')
   at.initSpectralWindow(nb,fC,fW,fR)
   at.setUserWH2O(create_casa_quantity(myqa, pwv,'mm'))
   dry, wet, TebbSkyZenith, rf, cs = getAtmDetails(at)
   if (verbose):
       print "%5.1f GHz tau at zenith = %.3f (dry=%.3f, wet=%.3f)" % (reffreq,dry+wet, dry, wet)
   TebbSky = TebbSkyZenith*(1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))
   hvkT = h*reffreq*1e9/(k*TebbSky)
   J = hvkT / (np.expm1(hvkT))
   TebbSky_Planck = TebbSky*J
   return(airmass*(dry+wet), TebbSky_Planck, TebbSky)

def antennaEllipsoidalHeight(vis, antenna, mymsmd=''):
    """
    Returns the height above the Earth ellipsoid model in meters of the pad of an
    antenna in a specific dataset.
    antenna: integer string ID or string name
    -Todd Hunter
    """
    antennaIDlist = parseAntenna(vis, antenna, mymsmd)
    antennaID = antennaIDlist[0]
    return geocentricXYZToEllipsoidalHeight(getAntennaPadXYZ(vis, antennaID, mymsmd))

def almaPadnameToObservatoryName(padname):    
    """
    Checks for the test facitily pads "TF" and returns 'ALMAOSF' instead of 'ALMA'.  
    -Todd Hunter
    """
    prefix = padname[:2]
    if prefix == 'TF':
        observatory = 'ALMAOSF'
    else:
        observatory = 'ALMA'
    return observatory

def estimateOpacity(pwvmean=1.0,reffreq=230,conditions=None,verbose=True,
                    elevation=90, altitude=5059, P=563, H=20, T=273, Trx=0,
                    etaTelescope=0.75, telescope=None, airmass=0, dP=5.0, h0=1.0,
                    maxAltitude=48.0, dPm=1.1):
   """
   Estimate the opacity at a specified frequency and weather condition at an
   observatory using J. Pardo's ATM in casa.
   Return values:
     If Trx is not specified, then it returns:  [tauZenith, tau]
     If Trx is specified, then it returns:
       [[tauZenith, tau], [transZenith, trans], [TskyZenith, Tsky], [TsysZenith, Tsys]]
   Equation for Tsys:
     (Trx + etaTelescope*T*(1-etaSky) + T*(1-etaTelescope))/(etaTelescope*etaSky)
     where etaSky = atmospheric transmission (as a fraction)
       and etaTelescope = telescope efficiency (as a fraction)
   units: pwv(mm), reffreq(GHz), elevation(deg), altitude(m), P=pressure(mb), T=temp(K),
          H=relativeHumidity(percent)
   h0: scale height (in km)
   maxAltitude: of atmosphere (in km)
   dP: pressure step in the model, has units of pressure (mb)
   dPm: pressure step factor in the model (unitless) called PstepFact in TelCal
   The default values are nominal conditions at ALMA.  To change them, you may
   either specify the weather and location variables, or use the shortcuts:
    telescope: 'ALMA', 'SMA', 'EVLA'
    conditions: a dictionary containing keys and values for (at least):
                'pressure','temperature','humidity','elevation'
   For further help, see
   https://safe.nrao.edu/wiki/bin/view/ALMA/EstimateOpacity
   -- Todd Hunter
   """
   if (airmass >= 1.0):
       elevation = math.asin(1./airmass)*180/math.pi
   if (conditions is not None):
     if (conditions['pressure'] > 1e-10):
#       angle = conditions['solarangle'] # unused
       P = conditions['pressure']
       T = celsiusToKelvin(conditions['temperature'])
       H = conditions['humidity']
       elevation = conditions['elevation']
   elif (telescope is not None):
       # default P,H,T are set to ALMA typical, but should get this from observatory
       if (telescope == 'SMA'):
           P = 629.5
           altitude = 4072
           print "Using pressure=%.1fmb, temperature=%.1fK and humidity=%.0f%% at SMA." % (P,T,H)
       elif (telescope.find('VLA')>=0):
           P = 785
           altitude = 2124
           print "Using pressure=%.1fmb, temperature=%.1fK and humidity=%.0f%% at %s." % (P,T,H,telescope)
       elif (telescope != 'ALMA'):
           print "Unrecognized telescope.  Available choices: SMA, ALMA, (E)VLA"
           return
   else:
       if (verbose):
           print "Using pressure=%.1fmb, temperature=%.1fK, humidity=%.0f%%, etaTelescope=%.2f at ALMA." % (P,T,H,etaTelescope)
   chansep=1
   numchan=1
   nb = 1
   reffreq = double(reffreq)
   chansep = double(chansep)
   numchan = int(numchan)
   chansep = double(chansep)
   spwid = 0
   myqa = createCasaTool(qatool)
   at.initAtmProfile(humidity=H,
                     temperature=create_casa_quantity(myqa, T,"K"),
                     altitude=create_casa_quantity(myqa, altitude,"m"),
                     pressure=create_casa_quantity(myqa, P,'mbar'),
                     atmType = TROPICAL,
                     h0 = create_casa_quantity(myqa, h0,"km"),
                     maxAltitude = create_casa_quantity(myqa, maxAltitude,"km"),
                     dP = create_casa_quantity(myqa, dP,"mbar"),
                     dPm=dPm)
   fC = create_casa_quantity(myqa, reffreq,'GHz')
   fR = create_casa_quantity(myqa, chansep,'GHz')
   fW = create_casa_quantity(myqa, numchan*chansep,'GHz')
   at.initSpectralWindow(nb,fC,fW,fR)
   at.setUserWH2O(create_casa_quantity(myqa, pwvmean,'mm'))
   dry, wet, TebbSkyZenith, rf, cs = getAtmDetails(at)
   transZenith = math.exp(-dry-wet)*100
   if (verbose):
       print "%5.1f GHz tau at zenith= %.3f (dry=%.3f,wet=%.3f), trans=%.1f%%, Tsky=%.2f" % (reffreq,dry+wet, dry, wet,math.exp(-dry-wet)*100, TebbSkyZenith)
   airmass = 1/math.sin(elevation*math.pi/180.)
   TebbSky = TebbSkyZenith * (1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))
   trans = math.exp((-dry-wet)*airmass)*100
   if (verbose and elevation<90):
       print "%5.1f GHz tau toward source (elev=%.1f,airm=%.2f)=%.3f, trans=%.1f%%, Tsky=%.2f" % (reffreq,elevation,airmass,(dry+wet)*airmass,math.exp((-dry-wet)*airmass)*100, TebbSky)
   if (Trx > 0):
       # compute expected Tsys
       etaSkyZenith = math.exp(-(dry+wet))
       TsysZenith = (T*(1/etaSkyZenith-1) + Trx/etaSkyZenith) / etaTelescope
       etaSky = math.exp(-airmass*(dry+wet))
       Tsys = (T*(1/etaSky-1) + Trx/etaSky) / etaTelescope
       if (verbose):
           print "Expected Tsys at zenith = %.1fK,   toward source = %.1fK" % (TsysZenith,Tsys)
       return([[dry+wet, (dry+wet)*airmass], [transZenith,trans], [TebbSkyZenith,TebbSky],
               [TsysZenith,Tsys]])
   else:
       return([dry+wet, (dry+wet)*airmass])

def computeTskyForSpw(vis='', spw=0, pwv=None):
   """
   Returns arrays of frequency and Tsky at zenith computed for the ALMA
   observation using default weather values and the observed PWV.
   spw: the spw ID to use
   pwv: the PWV (in mm) to use.  If not specified, it uses getMedianPWV.
   - Todd Hunter
   """
   mytb = createCasaTool(tbtool)
   spw = int(spw)
   try:
       mytb.open(vis+'/SPECTRAL_WINDOW')
   except:
       print "Could not open ms = %s." % (vis)
       return
   T = 270
   altitude = 5056
   P = 563
   H = 20
   numchan = mytb.getcell("NUM_CHAN",spw)    # num channels
   chanfreq = mytb.getcell("CHAN_FREQ",spw)    # num channels
   mytb.close()
   if (numchan == 1):
       chansep = 1
   else:
       chansep = (chanfreq[-1] - chanfreq[0]) / (numchan-1)
   numberWindows = 1
   reffreq = chanfreq[0]
   chansep = double(chansep)
   spwid = 0
   myqa = createCasaTool(qatool)
   at.initAtmProfile(humidity=H, temperature=create_casa_quantity(myqa,T,"K"),
                     altitude=create_casa_quantity(myqa,altitude,"m"),
                     pressure=create_casa_quantity(myqa,P,'mbar'),
                     atmType=TROPICAL)
   fC = create_casa_quantity(myqa,reffreq,'Hz')
   fR = create_casa_quantity(myqa,chansep,'Hz')
   fW = create_casa_quantity(myqa,numchan*chansep,'Hz')
   at.initSpectralWindow(numberWindows, fC, fW, fR)
   if (pwv == None):
       pwv, pwv_mad = getMedianPWV(vis)
   at.setUserWH2O(create_casa_quantity(myqa,pwv, 'mm'))
   dry, wet, TebbSky, rf, cs = getAtmDetails(at)
   azim, elev = listazel(vis)
   airmass = elevationToAirmass(elev)
   TebbSky *= (1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))
   chanfreqGHz = 1e-9 * chanfreq
   return(chanfreqGHz, TebbSky)

def plotPWVHistogram(dataset, plotfile=''):
    """
    Plots a histogram of the antenna-based PWV measurements for an 
    ALMA dataset.
    dataset: either an ASDM or measurement set
    -Todd Hunter
    """
    if not os.path.exists(dataset):
        print "Could not find ms or asdm by that name."
        return
    if os.path.exists(dataset+'/ASDM.xml'):
        data = readpwv(dataset)
        result = getBaselineStatsFromASDM(dataset)
    else:
        data = readPWVFromMS(dataset)
        result = getBaselineStats(dataset)
    minBaseline = result[1]
    maxBaseline = result[2]
    times = np.unique(data[0])
    antennas = np.unique(data[2])
    nAntennas = len(antennas)
    medianPWVs = []
    data[1] = np.array(data[1])*1000 # convert to mm
    data[2] = np.array(data[2])
    pb.clf()
    desc = pb.subplot(211)
    pb.hist(data[1],bins=nAntennas)
    pb.xlabel('PWV (mm)')
    pb.ylabel('Number of occurrences')
    trans = matplotlib.transforms.blended_transform_factory(desc.transData, desc.transAxes)
    wt = 'bold'
    size = 8
    for antenna in antennas:
        idx = np.where(data[2] == antenna)
        pwv = nanmedian(data[1][idx])
        pb.text(pwv,0.95,antenna,size=size,transform=trans,
                rotation=90,weight=wt)
    suffix = ': %d antennas, median: %.2f' % (nAntennas,np.median(data[1]))
    pb.title(os.path.basename(dataset) + suffix)
    maxpwv = np.max(data[1])
    minpwv = np.min(data[1])
    binwidth = (maxpwv-minpwv)/nAntennas
    pb.xlim([minpwv-binwidth,maxpwv+binwidth])

    desc2 = pb.subplot(212)
    for t in times:
        idx = np.where(np.array(data[0]) == t)
        medianPWV = nanmedian(data[1][idx])
        data[1][idx] -= medianPWV
        medianPWVs.append(medianPWV)
    data[1] += np.median(medianPWVs)
    pb.hist(data[1],bins=nAntennas)
    pb.xlabel('PWV (mm) normalized to per-scan median')
    pb.ylabel('Number of occurrences')
    trans2 = matplotlib.transforms.blended_transform_factory(desc2.transData, desc2.transAxes)
    for antenna in antennas:
        idx = np.where(data[2] == antenna)
        pwv = nanmedian(data[1][idx])
        pb.text(pwv,0.95,antenna,size=size,transform=trans2,
                rotation=90,weight=wt)
    maxpwv = np.max(data[1])
    minpwv = np.min(data[1])
    binwidth = (maxpwv-minpwv)/nAntennas
    pb.xlim([minpwv-binwidth, maxpwv+binwidth])
    pb.title('baseline range: %.0f - %.0fm' % (minBaseline, maxBaseline))
    pb.draw()
    if plotfile != '':
        if plotfile == True:
            plotfile = dataset + '_wvr.png'
        pb.savefig(plotfile)
        print "Wrote ", plotfile

def readPWVFromMS(vis):
    """
    Reads all the PWV values from a measurement set, returning a list
    of lists:   [[mjdsec], [pwv], [antennaName]]
    - Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    if (os.path.exists("%s/ASDM_CALWVR" % vis)):
        mytb.open("%s/ASDM_CALWVR" % vis)
        time = mytb.getcol('startValidTime')  # mjdsec
        antenna = mytb.getcol('antennaName')
        pwv = mytb.getcol('water')
        mytb.close()
        if (len(pwv) < 1):
            print "The ASDM_CALWVR table is empty, switching to ASDM_CALATMOSPHERE"
            time, antenna, pwv = readPWVFromASDM_CALATMOSPHERE(vis)
    elif (os.path.exists("%s/ASDM_CALATMOSPHERE" % vis)):
        print "Did not find %s/ASDM_CALWVR, using ASDM_CALATMOSPHERE" % (vis)
        time, antenna, pwv = readPWVFromASDM_CALATMOSPHERE(vis)
    else:
        print "Did not find ASDM_CALWVR nor ASDM_CALATMOSPHERE."
        return[[0],[1],[0]]
    return[time,pwv,antenna]

def readPWVFromASDM_CALATMOSPHERE(vis):
    """
    Reads the PWV via the water column of the ASDM_CALATMOSPHERE table.
    - Todd Hunter
    """
    if (not os.path.exists(vis+'/ASDM_CALATMOSPHERE')):
        if (vis.find('.ms') < 0):
            vis += '.ms'
            if (not os.path.exists(vis)):
                print "Could not find measurement set = ", vis
                return
            elif (not os.path.exists(vis+'/ASDM_CALATMOSPHERE')):
                print "Could not find ASDM_CALATMOSPHERE in the measurement set"
                return
        else:
            print "Could not find measurement set"
            return
    mytb = createCasaTool(tbtool)
    mytb.open("%s/ASDM_CALATMOSPHERE" % vis)
    pwvtime = mytb.getcol('startValidTime')  # mjdsec
    antenna = mytb.getcol('antennaName')
    pwv = mytb.getcol('water')[0]  # There seem to be 2 identical entries per row, so take first one.
    mytb.close()
    return(pwvtime, antenna, pwv)

def snrToPhaseRmsDegrees(snr):
    """
    Implements equation 7-51 (for snr < 1.837) and 7-52 (for snr > 1.837)
    of Synthesis Imaging textbook volume 1.
    -Todd Hunter
    """
    if (type(snr) == list or type(snr) == np.ndarray):
        snr = np.array(snr)
        degrees = np.zeros(len(snr))
        idx51 = np.where(snr < 1.837)[0]
        idx52 = np.where(snr >= 1.837)[0]
        degrees[idx51] = np.degrees(np.pi*(1.0-snr[idx51]*(9/(2*np.pi**3))**0.5)/(3**0.5))
        degrees[idx52] = np.degrees(1.0/snr[idx52])
        return degrees
    else:
        if (snr < 1.837):  # Eq 7-51 (Moran 1976)
            return np.degrees(np.pi*(1.0-snr*(9/(2*np.pi**3))**0.5)/(3**0.5))
        else:
            return np.degrees(1.0/snr)  # Eq 7-52

def MADoutliers(mylist, c=0.6745, sigma=3):
    """
    Find the outlier values, and their indices, in a list by computing
    its median and median absolute deviation (scaled to the expected rms).
    Returns: 2 lists
    * list of outlier values
    * list of their indices
    -Todd Hunter
    """
    mylist = np.array(mylist)
    mad = MAD(mylist, c)
    idx = np.where(abs(mylist-np.median(mylist)) > mad*sigma)[0]
    outliers = mylist[idx]
    return(outliers, idx)
                
def MAD(a, c=0.6745, axis=0):
    """
    Median Absolute Deviation along given axis of an array:

    median(abs(a - median(a))) / c

    c = 0.6745 is the constant to convert from MAD to std; it is used by
    default

    """
    a = np.array(a)
    good = (a==a)
    a = np.asarray(a, np.float64)
    if a.ndim == 1:
        d = np.median(a[good])
        m = np.median(np.fabs(a[good] - d) / c)
#        print  "mad = %f" % (m)
    else:
        d = np.median(a[good], axis=axis)
        # I don't want the array to change so I have to copy it?
        if axis > 0:
            aswp = swapaxes(a[good],0,axis)
        else:
            aswp = a[good]
        m = np.median(np.fabs(aswp - d) / c, axis=0)

    return m

def octile(oct):
    """
    Returns the PWV defining the specified octile.
    oct: integer from 1..7
    """
    octiles = [0.472, 0.658, 0.913, 1.262, 1.796, 2.748, 5.186]
    if oct >= 1 and oct <= len(octiles):
        return octiles[oct-1]
    print "invalid octile: ", oct

def pwvRange(freq):
    """
    Rough approximation to the target PWV range for observing.  
    See plot on page 133 of the Cycle 5 Technical Handbook.
    """
    if freq < 140:
        oct = 7
    elif freq < 180:
        oct = 6
    elif freq < 186:
        oct = 1
    elif freq < 300:
        oct = 5
    elif freq < 320:
        oct = 4
    elif freq < 328:
        oct = 1
    elif freq < 450:
        oct = 4
    elif freq < 420:
        oct = 3
    else:
        oct = 2
    if oct == 7:
        print "> %.3f" % (octile(oct-1))
    elif oct == 1:
        print "< %.3f" % (octile(oct-1))
    else:
        print "%.3f - %.3f" % (octile(oct-2),octile(oct-1))
        
def plotPWV(ms, figfile='', plotrange=[0,0,0,0], clip=True, verbose=False, panels=1,
            plotrange2=[0,0,0,0]):
  """
  Read and plot the PWV values from the ms via the ASDM_CALWVR table.
  If that table is not found, it reads the ASDM_CALATMOSPHERE table.
  Different antennas are shown in different colored points.
  Arguments:
  * ms:  the measurement set
  * plotrange: the ranges for the X and Y axes (default=[0,0,0,0] which is autorange)
  * clip:  default=True,  True=do not plot outliers beyond 5*MAD from the median.
  * figfile: True, False, or a string
           If figfile is not a string, the file created will be <ms>.pwv.png.
  * panels: if 1, then PWV vs. time, if 2, then also plot PWV vs. height
  * plotrange2: used for the second panel only
  For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/PlotPWV
  -- Todd Hunter
  """
  if (os.path.exists(ms) == False):
      print "Could not find the ms = %s" % (ms)
      return
  if (os.path.exists(ms+'/ASDM_CALWVR') == False and os.path.exists(ms+'/ASDM_CALATMOSPHERE') == False):
      # Confirm that it is ALMA data
      observatory = getObservatoryName(ms)
      if (observatory.find('ALMA') < 0 and observatory.find('ACA')<0):
          print "Either this is not a measurement set, or this is not ALMA data and "
          print "this telescope (%s) does not appear to have WVR data." % (observatory)
      else:
          print "Could not find %s/ASDM_CALWVR nor ASDM_CALATMOSPHERE.  Did you importasdm(asis='*')?" % (ms)
          print "You could also try: plotPWVFromASDM(your_asdm)"
      return
  try:
      [watertime,water,antennaName] = readPWVFromMS(ms)
  except:
      if (not casaAvailable):
          print "Sorry, you cannot run this function outside of CASA."
      else:
          print "readPWVFromMS: Could not open %s/ASDM_CALWVR nor ASDM_CALATMOSPHERE.  Did you importasdm(asis='*')?" % (ms)
          print "You could also try: plotPWVFromASDM(your_asdm)"
      return
  pb.clf()
  adesc = subplot(panels,1,1)
  ms = ms.rstrip('/')
#  watertime = np.array(watertime)/86400.   
#  offset = int(floor(watertime[0]))
#  watertime -= offset
  water = np.array(water)*1000
  if (clip):
      mad = MAD(water)
      median = np.median(water)
      if (verbose):
          print "MAD = %e, median = %e" % (mad, median)
      if (mad <= 0):
          matches = range(len(water))
      else:
          matches = np.where(abs(water - median) < 5*mad)[0]
          nonmatches = np.where(abs(water - median) >= 5*mad)[0]
          if (len(nonmatches) > 0):
              mymedian = np.median(water[nonmatches])
              print "Dropped %d/%d points (with median=%fmm) because they appear to be 5sigma outliers" % (len(water)-len(matches), len(water), mymedian)
      water = water[matches]
      watertime = watertime[matches]
      antennaName = antennaName[matches]
  uniqueAntennas = np.unique(antennaName)
  padHeights = []
  padDict = getAntennaPads(ms,keyByAntennaName=True)
  for a in antennaName:
      padHeights.append(getPadHeight(ms,padDict[a]))
  padHeights = np.array(padHeights)
  padHeights -= np.max(padHeights)

  pb.hold(True)
  list_of_date_times = mjdSecondsListToDateTime(watertime)
  timeplot = pb.date2num(list_of_date_times)
  for a in range(len(uniqueAntennas)):
      matches = np.where(uniqueAntennas[a] == np.array(antennaName))[0]
      pb.plot_date(timeplot[matches], water[matches], '.', color=overlayColors[a], mec=overlayColors[a])
#      pb.plot(watertime[matches], water[matches], '.', color=overlayColors[a])
  if (verbose):
      print "len(matches) = %d" % (len(matches))
  # now sort to average duplicate timestamps to one value, then fit spline
  indices = np.argsort(watertime)
  watertime = watertime[indices]
  water = water[indices]
  padHeights = padHeights[indices]
  antennaName = antennaName[indices]
  newWater = []
  newtime = []
  for w in range(len(water)):
      if (watertime[w] not in newtime):
          matches = np.where(watertime[w] == watertime)[0]
          newWater.append(np.median(water[matches]))
          newtime.append(watertime[w])
  watertime = newtime

  regularTime = np.linspace(watertime[0], watertime[-1], len(watertime))
  order = 3
  if (len(newWater) <= 3):
      order = 1 # required for datasets with only 3 points (e.g. uid___A002_X95c8aa_X179)
  if (len(newWater) > 1):
      # if there is more than one data point, we can fit a spline to overlay on the plot
      # example dataset with only one point is uid___A002_X316307_X6f
      ius = splrep(watertime, newWater,s=len(watertime)-sqrt(2*len(watertime)),k=order)
      newWater = splev(regularTime, ius, der=0)
  list_of_date_times = mjdSecondsListToDateTime(regularTime)
  timeplot = pb.date2num(list_of_date_times)
  pb.plot_date(timeplot,newWater,'k-')
  print "Median value at zenith = %.3f mm" % (np.median(newWater))
  if (plotrange[0] != 0 or plotrange[1] != 0):
      pb.xlim([plotrange[0],plotrange[1]])
  if (plotrange[2] != 0 or plotrange[3] != 0):
      pb.ylim([plotrange[2],plotrange[3]])
  xlim = pb.xlim()
  ylim = pb.ylim()
  xrange = xlim[1]-xlim[0]
  yrange = ylim[1]-ylim[0]
  for a in range(len(uniqueAntennas)):
      pb.text(xlim[1]+0.01*xrange, ylim[1]-0.024*yrange*(a-2)*panels, 
              uniqueAntennas[a], color=overlayColors[a], size=8)
  pb.xlabel('Universal Time (%s)' % (plotbp3.utdatestring(watertime[0])))
  pb.ylabel('PWV (mm)')
  adesc.xaxis.grid(True,which='major')
  adesc.yaxis.grid(True,which='major')
  pb.title(ms+' (median = black line)')
  if (len(newWater) > 1):
      adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
      adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
      adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
      adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
      RescaleXAxisTimeTicks(pb.xlim(), adesc)
  autoFigureName = "%s.pwv.png" % (ms)
  if (panels == 2):
      pb.subplot(2,1,2)
      if (plotrange[:2] != [0,0]):
          pb.xlim(plotrange[:2])
      if (plotrange[2:] != [0,0]):
          pb.ylim(plotrange[2:])
      pb.xlabel('Relative pad height (m)')
      pb.ylabel('PWV (mm)')
      medianPWVs = []
      perPadHeights = []
      for a in uniqueAntennas:
          medianPWVs.append(np.median(water[np.where(antennaName == a)]))
          perPadHeights.append(padHeights[np.where(antennaName==a)[0][0]])
          if (perPadHeights[-1] < -50):
              pb.text(perPadHeights[-1], medianPWVs[-1], a, size=8)
      pb.plot(padHeights, water, 'k.', perPadHeights, medianPWVs, 'ro')
  pb.draw()
  if (figfile==True):
      pb.savefig(autoFigureName)
      print "Wrote file = %s" % (autoFigureName)
  elif (len(figfile)>0):
      pb.savefig(figfile)
      print "Wrote file = %s" % (figfile)
  else:
      print "To create a png file, rerun with either:"
      print "  plotPWV(%s,figfile=True) to produce the automatic name=%s" % (ms,autoFigureName)
      print "  plotPWV('%s',figfile='myname.png')" % (ms)

def getSB(vis):
    """
    Gets the UID of the schedule block for a measurement set
    """
    mytb = createCasaTool(tbtool)
    if (os.path.exists(vis+'/OBSERVATION') == False):
        print "Could not open OBSERVATION table for this ms"
        return
    sched = 'unknown'
    sbname = 'unknown'
    mytb.open(vis+'/OBSERVATION')
    if ('SCHEDULE' in mytb.colnames()):
        if (mytb.iscelldefined('SCHEDULE',0)):
            sched = mytb.getcol('SCHEDULE')
            sbname = '%s' % (sched[0][0].split()[1])  # This is the SB UID.
    mytb.close()
    return(sbname)
    
def getSBGainFromASDM(asdm=''):
    """
    This function reads the CalAtmosphere.xml table from the ASDM and returns a
    dictionary.
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "getSBGainFromASDM(): Could not find file = ", asdm
        return
    sdmfile = asdm
    xmlscans = minidom.parse(sdmfile+'/CalAtmosphere.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    for rownode in rowlist:
        myrow = rownode.getElementsByTagName("syscalType")
        mytype = myrow[0].childNodes[0].nodeValue
        if (mytype == 'SIDEBAND_RATIO'):
            rowSBGain = rownode.getElementsByTagName("sbGain")
            sbGain = []
            tokens = rowSBGain[0].childNodes[0].nodeValue.split()
            gains = []
            for i in range(int(tokens[1])):
                gains.append(float(tokens[i+2]))
            sbGain = gains
            scandict[fid] = {}

            # start and end times in mjd ns
            rowstart = rownode.getElementsByTagName("startValidTime")
            start = int(rowstart[0].childNodes[0].nodeValue)
            startmjd = float(start)*1.0E-9/86400.0
            t = qa.quantity(startmjd,'d')
            starttime = call_qa_time(t,form="ymd",prec=8)
            rowend = rownode.getElementsByTagName("endValidTime")
            end = int(rowend[0].childNodes[0].nodeValue)
            endmjd = float(end)*1.0E-9/86400.0
            t = qa.quantity(endmjd,'d')
            endtime = call_qa_time(t,form="ymd",prec=8)
            # antenna
            rowantenna = rownode.getElementsByTagName("antennaName")
            antenna = str(rowantenna[0].childNodes[0].nodeValue)
            # baseband
            rowbaseband = rownode.getElementsByTagName("basebandName")
            baseband = int(rowbaseband[0].childNodes[0].nodeValue.split('_')[1])
            # scan
            rowCalDataId = rownode.getElementsByTagName("calDataId")
            calDataId = str(rowCalDataId[0].childNodes[0].nodeValue)
            scan = int(calDataId.split('_')[1])
            rowCalDataId = rownode.getElementsByTagName("receiverBand")
            receiverBand = int(rowCalDataId[0].childNodes[0].nodeValue.split('_')[2])

            scandict[fid]['start'] = starttime
            scandict[fid]['end'] = endtime
            scandict[fid]['startmjd'] = startmjd
            scandict[fid]['endmjd'] = endmjd
            scandict[fid]['startmjdsec'] = startmjd*86400
            scandict[fid]['endmjdsec'] = endmjd*86400
            timestr = starttime+'~'+endtime
            scandict[fid]['timerange'] = timestr
            scandict[fid]['antenna'] = antenna
            scandict[fid]['baseband'] = baseband
            scandict[fid]['scan'] = scan
            scandict[fid]['sbGain'] = sbGain
            scandict[fid]['receiverBand'] = receiverBand
            scandict[fid]['duration'] = (endmjd-startmjd)*86400
            fid += 1

    print 'getSBGainFromASDM(): Found ',rowlist.length,' rows in CalAtmosphere.xml'
    if (rowlist.length == 0):
        print "This table is now in binary format. You need to importasdm(asis='CalAtmosphere') and run au.plotSBGain()"

    # return the dictionary for later use
    return scandict
    
    
def plotSBGainFromASDM(asdm='', pol='', figfile='', verbose=False,antenna='',
                       baseband='', doplot=True, threshold=None, 
                       SBR_THRESHOLD_2SB=0.80, SBR_THRESHOLD_DSB=0.25):
    """
    Plots the sideband gain ratio values from the SIDEBAND_RATIO entries in
    the CalAtmosphere.xml table for the specified ASDM.
    pol: 'X', 'Y', or ''=both,  only plot this polarization
    figfile: name of png file to save, default = asdm + '.sbgain.png'
    verbose: print all values of sbGain
       antenna: restrict the verbose printing to one specified antenna name
       baseband: restrict the verbose printing to one specified baseband number (1..4)
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find ASDM = ", asdm
        return
    scandict = getSBGainFromASDM(asdm)
    if (verbose):
        print "len(scandict) = %d" % (len(scandict))
    suspect = ''
    if (len(scandict) < 1):
        return('', suspect)
    sbGains = []
    sbGainsX = []
    sbGainsY = []
    scans = []
    antennas = []
    receiverBands = []
    basebands = []
    mjdsec = []
    for sd in scandict:
        s = scandict[sd]
        sbGainsX.append(s['sbGain'][0])
        if (len(s['sbGain']) > 1):
            sbGainsY.append(s['sbGain'][1])
        scans.append(s['scan'])
        antennas.append(s['antenna'])
        receiverBands.append(s['receiverBand'])
        basebands.append(s['baseband'])
#        mjdsec.append((s['startmjdsec']+s['endmjdsec'])*0.5)
#   The end time is often set to be way in the future (30 days).
        mjdsec.append(s['startmjdsec'])
        if (verbose):
            if (antenna == '' or antenna == s['antenna']):
                if (baseband == '' or baseband == s['baseband']):
                    print "ant=%s, scan=%d, rx=%d, baseband=%d, s['sbGain'] = " % (s['antenna'],
                           s['scan'], s['receiverBand'], s['baseband']), s['sbGain']
    sbGains = [sbGainsX]
    if (len(sbGainsY) > 0):               
        sbGains.append(sbGainsY)
    sbrscans=scans
    figfile, suspect, valuesAreDefault = plotSBGainFromData(asdm, sbGains, antennas, receiverBands, basebands, 
                                          mjdsec, scans, pol, figfile, verbose, antenna,
                                          baseband, doplot, threshold, sbrscans, SBR_THRESHOLD_2SB,
                                          SBR_THRESHOLD_DSB)    
    return(figfile, suspect, valuesAreDefault)

def getCalAtmosphereInfo(vis, pol='', antenna='', baseband='', scan='', receiverBand='',
                         debug=False, tol=10, altscan=None, calscandict=None, 
                         favorSBgain=False, mymsmd='', verbose=False):
    """
    Reads the sideband gain ratio and other useful values from the ASDM_CALATMOSPHERE
    file of a measurement set.  Returns 12 arrays:
       sideband gain, antenna name, receiver band number, baseband number,
       time (in MJD seconds), scan number, pwv, groundPressure, groundTemperature,
       groundRelHumidity, myIndex, sbrscans

    Returns either all of the rows, or only those rows which match the input parameters:
    antenna: must be the string name (e.g. 'DA41')
    scan: a single scan number (as string or integer)
    baseband: a single baseband number (as string or integer)
    receiverBand: a single receiver band number (as string or integer)
    pol: '0', 'X', '1', 'Y' or ''=both
    tol: tolerance in seconds to pass to buildCalDataIdDictionary (should not have to change this)
    calscandict: optional dictionary (to avoid having to call buildCalDataIdDictionary)
    -- Todd Hunter
    """
    startTime = timeUtilities.time()
    if not os.path.exists(vis):
        print "Could not find MS"
        return
    if not os.path.exists(vis+'/table.dat'):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (mymsmd == ''):
        closemymsmd = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    else:
        closemymsmd = False
    if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' in mymsmd.intents()):
        calscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
    elif ('CALIBRATE_ATMOSPHERE#HOT' in mymsmd.intents()):
        calscans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#HOT')
    else:
        calscans = []
    if ('CALIBRATE_SIDEBAND_RATIO#ON_SOURCE' in mymsmd.intents()):
        sbrscans = mymsmd.scansforintent('CALIBRATE_SIDEBAND_RATIO#ON_SOURCE')
    else:
        sbrscans = []
    if (debug): print "atmcal scans = %s,  sbrcal scans = %s" % (str(calscans), str(sbrscans))
    calscans = np.union1d(calscans,sbrscans)
    if (len(calscans) < 1):
        print "No atmcal or sideband ratio scans in this dataset"
        return
    if closemymsmd:
        mymsmd.close()
    mytable = vis+'/ASDM_CALATMOSPHERE'
    if (os.path.exists(mytable) == False):
        print "Could not find table = %s" % (mytable)
        print "Did you importasdm with asis='CalAtmosphere' ?"
        return(None)
    mytb = createCasaTool(tbtool)
    mytb.open(mytable)
    pwv = mytb.getcol('water') * 1000
    groundPressure = mytb.getcol('groundPressure') * 0.01  # convert Pascals to mbar
    groundTemperature = mytb.getcol('groundTemperature')
    groundRelHumidity = mytb.getcol('groundRelHumidity')
    antennas = mytb.getcol('antennaName')
    startValidTime = mytb.getcol('startValidTime')
    mjdsec = mytb.getcol('startValidTime')
    calDataId = np.array([int(c.split('_')[-1]) for c in mytb.getcol('calDataId')])
    basebands = np.array([int(c.split('_')[-1]) for c in mytb.getcol('basebandName')])
    receiverBands = np.array([int(c.split('_')[-1]) for c in mytb.getcol('receiverBand')])
    if (calscandict == None):
        if (debug):
            print "getCalAtmosphereInfo(): Calling buildCalDataIdDictionary"
        if (favorSBgain):
            calscandict = buildCalDataIdDictionary(vis, tol, debug=debug, atm=False, mymsmd=mymsmd)
        else:
            calscandict = buildCalDataIdDictionary(vis, tol, debug=debug, mymsmd=mymsmd)
    if (calscandict == {}):
        print "The dictionary returned by buildCalDataIdDictionary is blank!"
        return(None)
    if (antenna != '' and antenna is not None):
        if (antenna not in antennas):
            print "Antenna %s is not in this dataset (available antennas = %s)" % (antenna, str(np.unique(antennas)))
            return(None)
    if (scan != '' and scan is not None):
        if (int(scan) not in calscans):
            print "Scan %s is not a cal scan in this dataset (available scans = %s)" % (scan, str(np.unique(calscans)))
            return(None)
    if (baseband != '' and baseband is not None):
        if (int(baseband) not in basebands):
            print "Baseband %s is not in this dataset (available basebands= %s)" % (baseband, str(np.unique(basebands)))
            return(None)
    if (receiverBand != '' and receiverBand is not None):
        if (int(receiverBand) not in receiverBands):
            print "Band %s is not in this dataset (available bands= %s)" % (receiverBand, str(np.unique(receiverBands)))
            return(None)
        
    sbGains = mytb.getcol('sbGain')
    if (debug): print "getSBGain: initial shape sbGains = %s" % (str(np.shape(sbGains)))
    mytb.close()
    calDataIdIndex = range(len(calDataId))
    antennaIndex = range(len(antennas))
    basebandIndex = range(len(basebands))
    receiverBandIndex = range(len(receiverBands))
    scanIndex = []
    scans = []
    for row in range(len(calDataId)):
        cDI = calDataId[row]
        if (cDI not in calscandict.keys()):
#            print "calDataId_%d is not in the dictionary: %s" % (cDI, str(calscandict))
            scans.append(None)
            continue
        if (len(calscandict[cDI]) > 0):
            scans.append(calscandict[cDI][0])
            if (debug):
                print "scan=%s, calscandict[%d]=%s" % (str(scan), cDI, str(calscandict[cDI]))
            # Here I need to guard against more than one scan being associated with a calDataId
            # take the final one (usually ATMCal)
            if (favorSBgain):
                if ([calscandict[cDI][0]] == [scan] or scan=='' or scan==None or
                    [calscandict[cDI][0]] == [altscan]):
                    scanIndex.append(row)
            else:
                if ([calscandict[cDI][-1]] == [scan] or scan=='' or scan==None or
                    [calscandict[cDI][-1]] == [altscan]):
                    scanIndex.append(row)
        elif (debug):
            print "calscandict[%d] = %s" % (cDI, str(calscandict[cDI]))
            
    if (debug):
        print "calscandict=", calscandict
        print "scanIndex=", scanIndex
        print "len(scanIndex)=",len(scanIndex)
    scans = np.array(scans)   # has an entry for every row
    scanIndex = np.array(scanIndex)  # only has entries for each row that matches the selected scan
    if (antenna != '' and antenna is not None):
        antennaIndex = np.where(antennas == antenna)[0]
    if (baseband != '' and baseband is not None):
        basebandIndex = np.where(basebands == int(baseband))[0]
    if (receiverBand != '' and receiverBand is not None):
        receiverBandIndex = np.where(receiverBands == int(receiverBand))[0]
    myIndex = np.intersect1d(scanIndex, antennaIndex)
    myIndex = np.intersect1d(myIndex, basebandIndex)
    myIndex = np.intersect1d(myIndex, receiverBandIndex)
    if (len(myIndex) < 1):
        print "No rows found in the ASDM_CALATMOSPHERE table for this scan/antenna. Use altscan parameter."
        return(None)
    sbGains = sbGains[:,myIndex]
    xpol = ['X','x','0',0]
    ypol = ['Y','y','1',1]
    if (pol in xpol):
        if (debug): print "getSBGain: returning only X pol"
        sbGains = sbGains[0,:]
    elif (pol in ypol):
        if (debug): print "getSBGain: returning only Y pol"
        sbGains = sbGains[1,:]
    elif (pol not in ['X,Y','Y,X','x,y','y,x','','0,1','1,0']):
        print "Unrecognized polarization option: %s" % (pol)
        return(None)
    if (debug):
        print "getSBGain: final shape(sbGains) = ", np.shape(sbGains)
        print "lengths:  myindex=%d, mjdsec=%d, scans=%d, pwv=%d, groundPressure=%d" % (len(myIndex), len(mjdsec), len(scans), len(pwv[0]), len(groundPressure))
        print "lengths: antennas=%d, receiverBands=%d, basebands=%d, groundTemperature=%d, groundRelHumidity=%d" % (len(antennas),len(receiverBands),len(basebands),len(groundTemperature),len(groundRelHumidity))
    stopTime = timeUtilities.time()
    if verbose:
        if closemymsmd:
            mymsmdarg = None
        else:
            mymsmdarg = 'existing'
        print "getCalAtmosphereInfo(antenna='%s', mymsmd=%s) required %.1f seconds" % (antenna, mymsmdarg, stopTime-startTime)
    return(sbGains, antennas[myIndex], receiverBands[myIndex], basebands[myIndex],
           mjdsec[myIndex], scans[myIndex], pwv[0,myIndex], groundPressure[myIndex],
           groundTemperature[myIndex], groundRelHumidity[myIndex], myIndex, sbrscans)
    # end getCalAtmosphereInfo()

def plotSBGainForDatasets(vislist=[], pol='', figfile='', verbose=False,antenna='',
               baseband='', doplot=True, threshold=None, 
               SBR_THRESHOLD_2SB=0.80, SBR_THRESHOLD_DSB=0.25, scan=''):
    """
    Calls plotSBGain for a list of datasets.
    -Todd Hunter
    """
    if (type(vislist) == str):
        outfile = vislist+'.plotSBGainForDatasets.txt'
        vislist = getListOfFilesFromFile(vislist, appendms=True)
    else:
        outfile = 'plotSBGainForDatasets.txt'
    figfiles = []
    f = open(outfile,'w')
    for vis in vislist:
        figfile = ''
        figfile,suspect,suspectDict,valuesAreDefault = plotSBGain(vis,pol,figfile,verbose,antenna,
                                                                  baseband,doplot,threshold,
                                                                  SBR_THRESHOLD_2SB,
                                                                  SBR_THRESHOLD_DSB, scan)
        figfiles.append(figfile)
        f.write('%s   %s\nsuspect values = %s\nvaluesAreDefault=%s\n\n' % (vis,getObservationStartDate(vis),
                                                                           str(suspectDict),str(valuesAreDefault)))
    pdfname = outfile + '.pdf'
    f.close()
    print "Left results in %s" % (outfile)
    buildPdfFromPngs(figfiles, pdfname=pdfname)
    return(pdfname)

def plotSBGain(vis, pol='', figfile='', verbose=False,antenna='',
               baseband='', doplot=True, threshold=None, 
               SBR_THRESHOLD_2SB=0.80, SBR_THRESHOLD_DSB=0.25, scan='',
               perscan=False, interactive=False, tol=10):
    """
    Plots the sideband gain ratio values from the SIDEBAND_RATIO entries in
    the ASDM_CALATMOSPHERE table for the specified measurement set
    pol: 'X', 'Y', or ''=both,  only plot this polarization
    figfile: name of png file to save, default = vis + '.sbgain.png'
    verbose: print all values of sbGain
    antenna: restrict the verbose printing to one specified antenna name
    baseband: restrict the verbose printing to one specified baseband number (1..4)
    scan: restrict the plot and verbose printing to one specified scan number
    perscan: make an individual plot for scan (under development)
    
    Returns:
    1) the name of the png file produced
    2) an html string suitable for analyzemscal's pipeline result
    3) a dictionary of suspect values keyed by antenna name, baseband number (1-4), and polarization (0,1)
    4) a Boolean indicating if the values are simply the default values
    
    -Todd Hunter
    """
    if (scan != '' and type(scan) == str):
        scan = int(scan)
    favorSBgain = True
    result = getCalAtmosphereInfo(vis, scan=scan, antenna=antenna, baseband=baseband,
                                  debug=verbose, favorSBgain=favorSBgain, tol=tol)
    if (result == None):
        favorSBgain = False
        result = getCalAtmosphereInfo(vis, scan=scan, antenna=antenna, baseband=baseband,
                                      debug=verbose, favorSBgain=favorSBgain, tol=tol)
        if (result == None):
            print "Aborting plotSBGain"
            return
    sbGains, antennas, receiverBands, basebands, mjdsec, scans, pwv, groundPressure, groundTemperature, groundRelHumidity, index, sbrscans = result
    if (perscan):
        scansToPlot = sbrscans
    else:
        scansToPlot = [scan]
    if (verbose):
        print "plotSBGain: shape(sbGains) = ", np.shape(sbGains)
    lo1 = None
    lo2 = None
    figfiles = []
    for scan in scansToPlot:
      if (scan != ''):
          mymsmd = createCasaTool(msmdtool)
          mymsmd.open(vis)
          spws = mymsmd.spwsforscan(scan)
          spwsforbaseband = {}
          for bb in range(1,5):
              if (casadef.subversion_revision >= casaRevisionWithAlmaspws):
                  tdmspws = mymsmd.almaspws(tdm=True)
              else:
                  tdmspws = mymsmd.tdmspws()
              spwsforbaseband[bb] = np.intersect1d(spws,np.intersect1d(getSpwsForBaseband(mymsmd,bb),tdmspws))
          lo1info, lo2info = interpretLOs(vis,alsoReturnLO2=True,mymsmd=mymsmd)
          mymsmd.close()
          lo1 = 0
          lo2 = {}
          for bb in spwsforbaseband.keys():
              if (len(spwsforbaseband[bb]) > 0):
                  if (spwsforbaseband[bb][0] not in lo1info.keys()):
                      print "spw %d not in lo1info.keys() = %s" % (spwsforbaseband[bb][0], str(lo1info.keys()))
                      lo2[bb] = {'frequency':0, 'spw': spwsforbaseband[bb][0]}
                  else:
                      lo1 = lo1info[spwsforbaseband[bb][0]]
                      lo2[bb] = {'frequency':lo2info[spwsforbaseband[bb][0]], 'spw': spwsforbaseband[bb][0]}
                      print "Got LO1=%.3f,LO2=%.3f for bb=%d, spw=%d" % (lo1*1e-9,lo2[bb]['frequency']*1e-9, bb, spwsforbaseband[bb][0])
      result = getCalAtmosphereInfo(vis, scan=scan, antenna=antenna, baseband=baseband,
                                    debug=verbose, favorSBgain=favorSBgain)
      sbGains, antennas, receiverBands, basebands, mjdsec, scans, pwv, groundPressure, groundTemperature, groundRelHumidity, index, sbrscans = result
      sbrscans = []
      for i in range(len(scans)):
        if (antenna == '' or antenna == antennas[i]):
            if (baseband == '' or baseband == basebands[i]):
                if (scan == '' or scan == scans[i]):
                    sbrscans.append(scans[i])
                    if (verbose):
                        print "ant=%s, scan=%d, rx=%d, baseband=%d, sbGain[pol 0] = " % (antennas[i],
                                    scans[i], receiverBands[i], basebands[i]), sbGains[0][i]
      sbrscans = np.unique(sbrscans)
      if (favorSBgain):
          print "plotting sbrscans=", sbrscans
      else:
          print "WARNING: plotting scans=%s, which may not be sideband ratio scans" % (str(sbrscans))
      myfigfile = figfile
      if (perscan):
          if (figfile == '' or figfile == True):
              myfigfile = vis + '.scan%02d.sbgain.png' % (scan)
      myfigfile, suspect, suspectDict, valuesAreDefault = plotSBGainFromData(vis, sbGains, antennas,
                                                                           receiverBands, basebands, 
                                          mjdsec, scans, pol, myfigfile, verbose, antenna,
                                          baseband, doplot, threshold, sbrscans, SBR_THRESHOLD_2SB,
                                          SBR_THRESHOLD_DSB, lo1=lo1, lo2=lo2)
      figfiles.append(myfigfile)
      if (interactive):
          myinput = raw_input("Press return for next page (q to quit): ")
          if (myinput == 'q'): break
    if (len(figfiles) > 1 and doplot):
        if (figfile == '' or figfile==True):
            pdfname = vis + '.sbgain.pdf'
        else:
            pdfname = figfile+'.pdf'
        buildPdfFromPngs(figfiles, pdfname=pdfname)
    return(figfile, suspect, suspectDict, valuesAreDefault)

def plotSBGainFromData(sourceFile, sbGains, antennas, receiverBands, basebands, mjdsec, 
                       caldataids, pol, figfile, verbose, antenna, baseband, doplot, threshold, sbrscans,
                       SBR_THRESHOLD_2SB=0.80, SBR_THRESHOLD_DSB=0.25, lo1=None, lo2=None):
    """
    Returns four things:
    1) name of the png produced
    2) an html string suitable for analyzemscal's pipeline result
    3) a dictionary of suspect values keyed by antenna name, baseband number (1-4), and polarization (0,1)
    4) a Boolean indicating if the values are all the default
    """
    suspect = ''
    sbGainsX = sbGains[0]
#    print "plotSBGainFromData: type(sbGainsX)=%s, shape=%s" % (type(sbGainsX), np.shape(sbGainsX))
    sbGainsXdB = 10*np.log10(1-sbGainsX)
    if (len(sbGains) > 1):
        sbGainsY = np.array(sbGains[1])
        sbGainsYdB = 10*np.log10(1-sbGainsY)
    uniqueAntennaNames = list(np.unique(antennas))
    uniqueAntennaNumbers = range(len(uniqueAntennaNames))
    antennaNumbers = []
    for antennaName in antennas:
        antennaNumbers.append(uniqueAntennaNames.index(antennaName))
    if (verbose):
        print "len(sbGainsX) = %d" % (len(sbGainsX))
    matches = np.where(sbGainsX > 0.01)[0]  # avoid apparently bogus scans
    if (verbose):
        print "len(matches) = %d" % (len(matches))
    signal_gain, image_gain = defaultSBGainsForBand(receiverBands[0])
    valuesAreDefault = False
    if (pol in ['','X','x','0',0]):
        if (fabs(signal_gain-np.median(sbGainsX[matches]))<0.0001
            and fabs(signal_gain-np.min(sbGainsX[matches]))<0.0001
            and fabs(signal_gain-np.max(sbGainsX[matches]))<0.0001):
            valuesAreDefault = True
        print "Median  for Pol X = %f/%f = %f dB" % (np.median(sbGainsX[matches]),
                                                     1-np.median(sbGainsX[matches]),
                                        10*np.log10(1-np.median(sbGainsX[matches])))
        print "Minimum for Pol X = %f/%f = %f dB" % (np.min(sbGainsX[matches]),
                                                     1-np.min(sbGainsX[matches]),
                                             10*np.log10(1-np.min(sbGainsX[matches])))
        print "Maximum for Pol X = %f/%f = %f dB" % (np.max(sbGainsX[matches]),
                                                     1-np.max(sbGainsX[matches]),
                                                 10*np.log10(1-np.max(sbGainsX[matches])))
    if (pol in ['','Y','y','1',1]):
        if (signal_gain == np.median(sbGainsY[matches])):
            valuesAreDefault = True
        print "Median  for Pol Y = %f/%f = %f dB" % (np.median(sbGainsY[matches]),
                                                    1-np.median(sbGainsY[matches]),
                                             10*np.log10(1-np.median(sbGainsY[matches])))
        print "Minimum for Pol Y = %f/%f = %f dB" % (np.min(sbGainsY[matches]),
                                                     1-np.min(sbGainsY[matches]),
                                             10*np.log10(1-np.min(sbGainsY[matches])))
        print "Maximum for Pol Y = %f/%f = %f dB" % (np.max(sbGainsY[matches]),
                                                     1-np.max(sbGainsY[matches]),
                                            10*np.log10(1-np.max(sbGainsY[matches])))

    if (threshold == None):
        mythreshold = SBR_THRESHOLD_2SB
    else:
        mythreshold = threshold
    matches = np.where(sbGainsX < mythreshold)[0]
    if (len(matches) > 0):
        # Check if this is a DSB receiver
        if (receiverBands[0] >= 9 and threshold==None):
            mythreshold = 0.25
            matches = np.where(sbGainsX < mythreshold)[0]
    suspectDict = {}
    for i in matches:
        next_suspect = "Suspect value=%f for pol X, ant=%s, calDataId=%d, rx=%d, baseband=%d" % (sbGainsX[i], antennas[i],
                    caldataids[i], receiverBands[i], basebands[i])
        if (antennas[i] not in suspectDict.keys()):
            suspectDict[antennas[i]] = {}
        if (basebands[i] not in suspectDict[antennas[i]].keys()):
            suspectDict[antennas[i]][basebands[i]] = {}
        if (0 not in suspectDict[antennas[i]][basebands[i]].keys()):
            suspectDict[antennas[i]][basebands[i]][0] = sbGainsX[i]
        print next_suspect
        suspect += next_suspect + "<br>"
    matches = np.where(sbGainsY < mythreshold)[0]
    for i in matches:
        next_suspect = "Suspect value=%f for pol Y, ant=%s, calDataId=%d, rx=%d, baseband=%d" % (sbGainsY[i], antennas[i],
                    caldataids[i], receiverBands[i], basebands[i]) 
        if (antennas[i] not in suspectDict.keys()):
            suspectDict[antennas[i]] = {}
        if (basebands[i] not in suspectDict[antennas[i]].keys()):
            suspectDict[antennas[i]][basebands[i]] = {}
        if (1 not in suspectDict[antennas[i]][basebands[i]].keys()):
            suspectDict[antennas[i]][basebands[i]][1] = sbGainsY[i]
        print next_suspect
        suspect += next_suspect + "<br>"
    if (figfile==True):
        doplot = True
        figfile = ''
    if (doplot==False):
        figfile = ''
    else:
        pb.clf()
        list_of_date_times = mjdSecondsListToDateTime(mjdsec)
        timeplot = pb.date2num(list_of_date_times)
        adesc = pb.subplot(211)
        pb.hold(True)
        c = ['k','r','g','c']
        xpol = ['','X','x','X,Y','Y,X','x,y','y,x','0',0]
        ypol = ['','Y','y','X,Y','Y,X','x,y','y,x','1',1]
        for a in range(len(antennaNumbers)):
            if (pol in xpol):
                pb.plot(antennaNumbers[a], sbGainsX[a], 'o', color=c[basebands[a]-1])
            if (pol in ypol):
                pb.plot(antennaNumbers[a], sbGainsY[a], '+', color=c[basebands[a]-1], linewidth=2)
        x0,x1 = pb.xlim()
        y0,y1 = pb.ylim()
        yrange = y1-y0
        pb.xlim([-0.9,x1+0.9])
        pb.ylim([y0-0.2*yrange,y1+yrange*0.05])
        y0,y1 = pb.ylim()
        yrange = y1-y0
        pb.plot(pb.xlim(),[signal_gain,signal_gain],'k--')
        for a in range(len(uniqueAntennaNames)):
            pb.text(a, y0+0.09*yrange, uniqueAntennaNames[a], size=8, rotation='vertical')
        bbs = np.unique(basebands)
        pb.ylabel("Sideband gain ratio (sbGain)")
        uniqueScans = np.unique(sbrscans)
        scanstring = 'scans=%s' % (str(sbrscans))
        pb.title('Band %d %s %s (%d=%s)' % (receiverBands[0],os.path.basename(sourceFile),scanstring,uniqueScans[0],plotbp3.utstring(mjdsec[0],3)), size=12)
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        majorLocator = MultipleLocator(1)
        adesc.xaxis.set_major_locator(majorLocator)

        adesc = pb.subplot(212)
        for a in range(len(antennaNumbers)):
            if (pol in xpol):
                pb.plot(antennaNumbers[a], sbGainsXdB[a], 'o', color=c[basebands[a]-1])
            if (pol in ypol):
                pb.plot(antennaNumbers[a], sbGainsYdB[a], '+', color=c[basebands[a]-1], linewidth=2)
        pb.xlabel('Antenna')
        x0,x1 = pb.xlim()
        y0,y1 = pb.ylim()
        yrange = y1-y0
        pb.xlim([-0.9,x1+0.9])
        pb.ylim([y0-0.2*yrange,y1+1])
        y0,y1 = pb.ylim()
        yrange = y1-y0
        pb.plot(pb.xlim(),[10*np.log10(1-signal_gain),10*np.log10(1-signal_gain)],'k--')
        majorLocator = MultipleLocator(1)
        adesc.xaxis.set_major_locator(majorLocator)
        for a in range(len(uniqueAntennaNames)):
            pb.text(a, y0+0.09*yrange, uniqueAntennaNames[a], size=8, rotation='vertical')
        for a in range(len(bbs)):
            if (lo2 is not None):
                pb.text(0.0+a*0.2, 1.02, 'BB%d spw%d'%(bbs[a],lo2[bbs[a]]['spw']), color=c[bbs[a]-1], size=10, transform=adesc.transAxes)
            else:
                pb.text(0.0+a*0.2, 1.02, 'BB%d'%bbs[a], color=c[bbs[a]-1], size=10, transform=adesc.transAxes)
        pb.text(0.0+0.2*(len(bbs)), 1.02, 'XX=dots,YY=crosses', size=10, transform=adesc.transAxes)
        if (lo1 is not None):
            pb.text(0.0+0.2*(len(bbs)), 1.08, 'LO1=%.3f'%(lo1*1e-9), size=10, transform=adesc.transAxes)
        if (lo2 is not None):
            for a in range(len(bbs)):
                pb.text(0.0+0.2*a, 1.08, 'LO2=%.3f'%(lo2[bbs[a]]['frequency']*1e-9), size=10, transform=adesc.transAxes)
        pb.ylabel("10*log10(1-sbGain) (dB)")
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        if (figfile == ''):
            figfile = sourceFile + '.sbgain.png'
        if (os.path.exists(figfile)):
            if (os.access(figfile,os.W_OK) == False):
                figfile = '/tmp/' + figfile
        else:
            if (figfile.find('/') < 0):
                figfile = './'+figfile
            if (os.access(os.path.dirname(figfile),os.W_OK) == False):
                figfile = '/tmp/' + os.path.basename(figfile)
        pb.savefig(figfile)
        print "Wrote plot to %s" % (figfile)
    return(figfile, suspect, suspectDict, valuesAreDefault)

def RescaleXAxisTimeTicks(xlim, adesc):
    if (xlim[1] - xlim[0] < 10/1440.):
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,30)))
    elif (xlim[1] - xlim[0] < 0.5/24.):
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
    elif (xlim[1] - xlim[0] < 1/24.):
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,2)))
                
def setXaxisTimeTicks(adesc, t0, t1, verbose=False):
    """
    Sets sensible major and minor tick intervals for a plot_date plot
    based on the start and end times.
    Inputs: t0 (startTime in seconds)
        and t1 (endTime in seconds)
        Only the difference matters.
   -Todd Hunter
    """
    timeRange = t1-t0
    if (verbose):
        print "timeRange = %f sec" % (timeRange)
    if (timeRange > 20000):
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H'))
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,int(60*np.floor((t1-t0)/3600)),60)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,15)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H')
    elif (timeRange > 2000):
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,15)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    elif (timeRange > 600):
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,30)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    elif (timeRange > 200):
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,3)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,10)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    elif (timeRange > 40):
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M:%S'))
        adesc.xaxis.set_major_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,20)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,5)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M:%S')
    else:
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M:%S'))
        adesc.xaxis.set_major_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,10)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,1)))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M:%S')

def plotPWVFromASDM(asdm='',figfile=False,showMedianOnly=False,avgtime=30.0,
                    meanelev=-1, freq=-1, station=1, linetype='.-',
                    markersize=9, bandwidth=1.0, panels=1, plotrange=[0,0,0,0]):
  """
  Read and plot the PWV values from the ASDM via the CalWVR.xml table.
  avgtime is the time in secs over which to compute the median value from all
  antennas.  If meanelev is specified, it will compute the PWV toward that
  elevation. If freq is further specified (GHz), it will compute the
  transmission toward that elevation using the measured weather conditions.
  Inputs:
  * figfile: Boolean, or a string (default filename = 'asdm.pwv.png')
  * showMedianOnly: show median only (True), or with all antennas colorized (False)
  * avgtime: time window over which to bin the PWV data
  * meanelev: compute the PWV at this specified elevation by scaling from zenith
     * freq: compute the transmission at this frequency at meanelev (GHz or string with units)
     * station: the weather station to use to compute transmission
     * bandwidth: the bandwidth to use to compute transmission (GHz or string with units)
  * linetype: to use on the showMedianOnly=True plot
  * markersize: of plotted points
  * panels: if 1, then PWV vs. time, if 2, then also plot PWV vs. height
  * plotrange: used for the second panel only
   -- Todd Hunter
  """
  if (os.path.exists(asdm)):
    try:
      [watertime,water,antennaName] = readpwv(asdm)
    except:
      print "Could not open %s/CalWVR.xml" % (asdm)
      return
  else:
      print "Could not find file %s/CalWVR.xml" % (asdm)
      return
  pb.clf()
  adesc = pb.subplot(panels, 1, 1)
  asdm = asdm.rstrip('/')
  uniqueAntennaNames = np.unique(antennaName)
  print "Found WVR data from %d antennas" % (len(uniqueAntennaNames))
  roundedData = avgtime*(np.round(np.array(watertime)/avgtime))
  uniqueTimes = np.unique(roundedData)
  watertime = np.array(watertime)
  antennaNames = np.array(antennaName)
  pad_dict = getAntennaPadsFromASDM(asdm)
  padHeights = []
  for a in antennaNames:
      padHeights.append(getPadHeightFromASDM(asdm, pad_dict[a]))
  padHeights = np.array(padHeights)
  padHeights -= np.max(padHeights)
  mjdsec = watertime
  water = np.array(water)*1000
  print "Found %d times" % (len(uniqueTimes))
  timeMedian = []
  pwvMedian = []
  for t in uniqueTimes:
      matches = np.where(roundedData == t)[0]
      timeMedian.append(np.median(watertime[matches]))
      pwvMedian.append(np.median(water[matches]))
  pwvRange = np.max(pwvMedian) - np.min(pwvMedian)
  list_of_date_times = mjdSecondsListToDateTime(timeMedian)
  if (asdm == "." or asdm == "./"):
      asdmTitle = os.getenv('PWD').split('/')[-1]
  else:
      asdmTitle = asdm
  if (showMedianOnly==False):
      pwv = {}
      pwvtime = {}
      for ant in np.unique(antennaName):
          pwv[ant] = []
          pwvtime[ant] = []
      for i in range(size(antennaName)):
          pwv[antennaName[i]].append(water[i])
          pwvtime[antennaName[i]].append(watertime[i])
      for i,ant in enumerate(sort(pwv.keys())):
          timeplot = pb.date2num(mjdSecondsListToDateTime(pwvtime[ant]))
          pb.plot_date(timeplot, pwv[ant], 'o', color=overlayColors[i], markeredgecolor=overlayColors[i])
          pb.text(timeplot[-1]+0.02*(timeplot[-1]-timeplot[0]), pwv[ant][-1],
                  str(ant), size=7, ha='left',va='center')
      pb.legend(sort(pwv.keys()), prop={'size':11-panels*3}, ncol=2)
      x0,x1 = pb.xlim()
      pb.xlim([x0-0.05*(x1-x0), x1+0.55*(x1-x0)])
      timeplot = pb.date2num(list_of_date_times)
      pb.plot_date(timeplot, pwvMedian, 'k-',markersize=markersize,markeredgecolor='r')
      pb.ylabel('PWV (mm)')
      pb.title(asdmTitle + ' (median = black line)')
  else:
      timeplot = pb.date2num(list_of_date_times)
      pb.plot_date(timeplot, pwvMedian, 'r%s'%(linetype),markersize=markersize,markeredgecolor='r')
      pb.ylim([np.min(pwvMedian)-0.03*pwvRange, np.max(pwvMedian)+0.03*pwvRange])
      pb.ylabel('PWV (mm) (median of all antennas)')
      pb.title(asdmTitle)
  pb.xlabel('Universal Time (%s)' % plotbp3.utdatestring(watertime[0]))
      
  adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
  adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
  adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
  adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
  RescaleXAxisTimeTicks(pb.xlim(), adesc)
  adesc.xaxis.grid(True,which='major')
  adesc.yaxis.grid(True,which='major')
  (mjd, utstring) = mjdSecondsToMJDandUT(mjdsec[0])
  deltaTime = (np.max(watertime) - np.min(watertime))/3600.
  print " median PWV at zenith = %.3f mm over %.3f hours" % (np.median(water),deltaTime)
  if (meanelev > 0):
      airmass = 1.0/math.cos((90-meanelev)*math.pi/180.)
      print " median PWV at elev=%.0f = %.3f mm over %.3f hours" % (meanelev,airmass*np.median(water),deltaTime)
      if (freq > 0):
          freq = parseFrequencyArgumentToGHz(freq)
          [conditions,medianConditions,stationName] = getWeatherFromASDM(asdm,station=station)
          P = medianConditions['pressure']
          H = medianConditions['humidity']
          T = medianConditions['temperature']
          print "Median conditions: P,H,T = ", P, H, T
          altitude = 5059
          myqa = createCasaTool(qatool)
          at.initAtmProfile(humidity=H,
                            temperature=create_casa_quantity(myqa,T,"K"),
                            altitude=create_casa_quantity(myqa,altitude,"m"),
                            pressure=create_casa_quantity(myqa,P,'mbar'),
                            atmType=TROPICAL)
          fCenter = create_casa_quantity(myqa,freq,'GHz')
          bandwidth = parseFrequencyArgumentToGHz(bandwidth)
          fWidth = create_casa_quantity(myqa,bandwidth,'GHz')
          fResolution = fWidth
          at.initSpectralWindow(1, fCenter, fWidth, fResolution)
          at.setUserWH2O(create_casa_quantity(myqa,airmass*np.median(water), 'mm'))
          dry, wet, TebbSkyZenith, rf, cs = getAtmDetails(at)
          transmission = np.exp((-wet-dry)*airmass)* 100
          print " transmission at median PWV at %.1f GHz = %.1f percent" % (freq, transmission)
  if (panels == 2):
      pb.subplot(2,1,2)
      if (plotrange[:2] != [0,0]):
          pb.xlim(plotrange[:2])
      if (plotrange[2:] != [0,0]):
          pb.ylim(plotrange[2:])
      pb.xlabel('Relative pad height (m)')
      pb.ylabel('PWV (mm)')
      medianPWVs = []
      perPadHeights = []
      for a in uniqueAntennaNames:
          medianPWVs.append(np.median(water[np.where(antennaNames == a)]))
          perPadHeights.append(padHeights[np.where(antennaNames==a)[0][0]])
          if (perPadHeights[-1] < -50):
              pb.text(perPadHeights[-1], medianPWVs[-1], a, size=8)
      pb.plot(padHeights, water, 'k.', perPadHeights, medianPWVs, 'ro')
  pb.draw()
  if (figfile==True):
      myfig = asdm + '.pwv.png'
      pb.savefig(myfig, density=144)
      print "Figure saved to %s" % (myfig)
  elif (figfile != False):
      myfig = figfile
      pb.savefig(myfig, density=144)
      print "Figure saved to %s" % (myfig)
  else:
      print "To write a png file, re-run with figfile=True or a string"

def plotSunDuringTrack(ms='', asdm='', plotfile='', figfiledir='', elvstime=False):
    """
    Plots the solar az/el during a dataset, with one point per scan.  You
    can specify either the ms or the asdm.  It reads the observatory name
    from the ExecBlock.xml (ASDM) or the OBSERVATION table (ms).
    Returns the name of the plotfile.
    plotfile can be: True, False, or a string name
    elvstime: False=plot el vs. az;  True=plot el vs. time
          I have implemented lists to hold the times, but not plotted yet.
    -- Todd Hunter
    """
    if (ms == '' and asdm == ''):
        print "Need to specify either an ms or an asdm"
        return
    azimuth = []
    elevation = []
    pointingScans = []
    startmjd = []
    endmjd = []
    mjd = []
    if (asdm != ''):
        if (os.path.exists(asdm) == False):
            print "ASDM does not exist: %s" % (asdm)
            return
        track = os.path.basename(asdm)
        if (track == ''):
            track = os.path.basename(asdm[:-1])  # in case name ends in '/'
        observatory = getObservatoryNameFromASDM(asdm)
        scandict, sourcedict = readscans(asdm)
        for scan in scandict:
#            print "processing scan ", scan
            az,el = sun(observatory=observatory, mjd=dateStringToMJD(scandict[scan]['start'], verbose=False))
            azimuth.append(az)
            elevation.append(el)
            startmjd.append(scandict[scan]['startmjd']*86400)
            mjd.append(scandict[scan]['startmjd']*86400)
            az,el = sun(observatory=observatory, mjd=dateStringToMJD(scandict[scan]['end'], verbose=False))
            azimuth.append(az)
            elevation.append(el)
            endmjd.append(scandict[scan]['endmjd']*86400)
            mjd.append(scandict[scan]['endmjd']*86400)
            if (scandict[scan]['intent'].find('CALIBRATE_POINTING') >= 0):
                pointingScans.append(scan)
        firstScan = np.min(scandict.keys())
        lastScan = np.max(scandict.keys())
    else:
        track = os.path.basename(ms)
        if (casadef.casa_version >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms)
            scannumbers = mymsmd.scannumbers()
            t = []
            for snumber in scannumbers:
                mytimes = mymsmd.timesforscan(snumber)
                t.append([np.min(mytimes), np.max(mytimes)])
            firstScan = np.min(scannumbers)
            lastScan = np.max(scannumbers)
            if ('CALIBRATE_POINTING#ON_SOURCE' in mymsmd.intents()):
                pointingScans = mymsmd.scansforintent('CALIBRATE_POINTING#ON_SOURCE')
            else:
                pointingScans = []
        else:
            print "Running ValueMapping because this is a pre-4.1 version of casa"
            vm = ValueMapping(ms)
            t = vm.getTimesForScans(vm.uniqueScans)
            firstScan = np.min(vm.uniqueScans)
            lastScan = np.max(vm.uniqueScans)
            pointingScans = getScansForIntentFast(vm,vm.uniqueScans,'CALIBRATE_POINTING#ON_SOURCE')
        observatory = getObservatoryName(ms)
        for scantime in t:
            az,el = sun(observatory=observatory, mjdsec=np.min(scantime))
            azimuth.append(az)
            elevation.append(el)
            mjd.append(np.min(scantime))
            startmjd.append(np.min(scantime))
            az,el = sun(observatory=observatory, mjdsec=np.max(scantime))
            azimuth.append(az)
            elevation.append(el)
            endmjd.append(np.max(scantime))
            mjd.append(np.max(scantime))
    pb.clf()
    adesc = pb.subplot(111)
    twilight = False
    if (elevation[0]*elevation[-1] < 0):
        twilight = True
    if (twilight):
        color = 'r'
    elif (elevation[0] < 0): # nighttime
        color = 'k'
    else:  # daytime
        color = 'b'
    azimuthStart = np.array(azimuth)[range(0,len(azimuth),2)]
    elevationStart = np.array(elevation)[range(0,len(elevation),2)]
    azimuthEnd = np.array(azimuth)[range(1,len(azimuth),2)]
    elevationEnd = np.array(elevation)[range(1,len(elevation),2)]
    if (elvstime):
        list_of_date_times = mjdSecondsListToDateTime(mjd)
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, elevation, '%s-'%color)
        timeplot = pb.date2num(mjdSecondsListToDateTime(startmjd))
        pb.plot_date(timeplot, elevationStart, '%so'%color)
        timeplot = pb.date2num(mjdSecondsListToDateTime(endmjd))
        pb.plot_date(timeplot, elevationEnd, 'wo', markeredgecolor=color)
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, elevation, '%s.-'%color)
        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
        xlims = pb.xlim()
        xrange = xlims[1]-xlims[0]
        pb.xlim([xlims[0]-0.06*xrange, xlims[1]+0.06*xrange])
        RescaleXAxisTimeTicks(pb.xlim(), adesc)
        adesc.xaxis.grid(True,which='major')
    else:
        pb.plot(azimuth, elevation, '%s-'%color)
        pb.plot(azimuthStart, elevationStart, '%so'%color)
        pb.plot(azimuthEnd, elevationEnd, 'wo', markeredgecolor=color)
        pb.plot(azimuth, elevation, '%s.-'%color)
        
    xlims = pb.xlim()
    pb.ylim([-92,92])
    ylims = pb.ylim()
    azoff = (xlims[1]-xlims[0])*0.05
    for p in pointingScans:
        if (elvstime==False):
            pb.text(azimuth[p-1]-azoff*0.5, elevation[p-1]-8, 'Point')
        else:
            pb.text(timeplot[p-1]-azoff*0.5, elevation[p-1]-8, 'Point')
    if (elvstime==False):
        pb.text(azimuth[0]-azoff, elevation[0]+3, 'Scan %d' % (firstScan))
        pb.text(azimuth[-1]-azoff, elevation[-1]+3, 'Scan %d' % (lastScan))
    else:
        pb.text(timeplot[0]-azoff, elevation[0]+3, 'Scan %d' % (firstScan))
        pb.text(timeplot[-1]-azoff, elevation[-1]+3, 'Scan %d' % (lastScan))
    pb.axhline(0, ls='--', color='k')
    pb.ylabel('Elevation (deg)')
    if (elvstime):
        pb.xlabel('Time (UT on %s)' % (mjdsecToUT(mjd[0]).split()[0]))
    else:
        pb.xlabel('Azimuth (deg)')
    pb.yticks(range(-90,92,15))
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    pb.title('Solar position from %s during %s' % (observatory,track))
    if (plotfile != ''):
        if (plotfile == True):
            if (elvstime):
                plotfile = track + '.sun.elvstime.png'
            else:
                plotfile = track + '.sun.png'
        if (figfiledir != ''):
            if (os.path.exists(figfiledir) == False):
                os.makedirs(figfiledir)
            if (figfiledir[-1] != '/'):
                figfiledir += '/'
            plotfile = figfiledir + plotfile
        pb.savefig(plotfile)
        print "Wrote plot = ", plotfile
    pb.draw()
    print "Mean elevation = %f deg" % (np.mean(elevation))
    if (plotfile == ''):
        return(np.mean(elevation))
    else:
        return(plotfile)
    
def setTickLabelSize(desc, size):
    pb.setp(desc.get_xticklabels(), fontsize=size)
    pb.setp(desc.get_yticklabels(), fontsize=size)

def plotWeather(vis='', figfile='', station=[], asdm='', verbose=False, 
                colors='', doplot=True, pressureCorrection=False,
                referenceStation='MeteoTB2'):  
    """
    Compiles and plots the major weather parameters for the specified ms. 
    Station can be a single integer or integer string, or a list of two
    integers, and refers to the row number in the Station.xml file of the ASDM.
    The default empty list means to plot all data from up to N stations, where
    N is the number of colors provided by the colors parameter.
    Inputs:
    vis: the measurement set
    figfile: the default plot file name will be 'vis'.weather.png
    station: a single integer or list of integers corresponding to the row in the 
       Station.xml file.  If ASDM_STATION table is present, or the asdm is specified,
       it can also be a comma-delimited string of names, case insensitive,
       e.g. 'meteo130,METEO201'
    asdm: if you also specify the ASDM, it can look up the
            conversion from station number to station name.  This is not
            necessary if you imported with asis='*' or asis='Station'
    verbose: print the number of rows per station, and their median and max 
             temperatures
    colors: pylab colors to use for the stations
    pressureCorrection: if True, then adjust pressure measurements by height to
            the highest station using the formula from CALC in ICT-272.
    referenceStation: name of station to use for pressure reference
    doplot: if False, then simply return 2 dictionaries:
      * stations: station IDs, keyed by station name
      * data: keyed by 'mjdsec', 'pressure', 'temperature', 'windspeed', 
                     'winddirection', 'relativehumidity', 'dewpoint'
      * Thus: temperature_array = data['temperature'][stations['METEO201']]  
    doplot: if True, then returns a dictionary of the pressure differences
    -- Todd Hunter
    """
    if (colors == ''): colors = list(weatherStationColors)
    myfontsize = 9
    if (os.path.exists(vis) == False):
        if (os.path.exists(asdm)):
            return(plotWeatherFromASDM(asdm))
        else:
            print "Could not find measurement set = ", vis
            return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (os.path.exists("%s/WEATHER" % vis)):
        mytb = createCasaTool(tbtool)
        mytb.open("%s/WEATHER" % vis)
    elif (os.path.exists(asdm)):
        return(plotWeatherFromASDM(asdm))
    else:
        print "Could not open WEATHER table.  Did you importasdm with asis='*'?"
        return
    mjdsec = mytb.getcol('TIME')
    mjdsec1 = mjdsec
    vis = vis.rstrip('/')
    pressure = mytb.getcol('PRESSURE')
    relativeHumidity = mytb.getcol('REL_HUMIDITY') # this value is in percentage
    temperature = mytb.getcol('TEMPERATURE')
    dewPoint = mytb.getcol('DEW_POINT')
    stations = mytb.getcol('NS_WX_STATION_ID')
    windDirection = (180/math.pi)*mytb.getcol('WIND_DIRECTION')
    windSpeed = mytb.getcol('WIND_SPEED')
    mytb.close()
    uniqueStationIDs = np.unique(stations)
    print "uniqueStationIDs in dataset = ", uniqueStationIDs
    stationNames = []
    stationIDs = []
    if pressureCorrection:
        heightDict, highestStation = getWeatherStationPositions(vis, returnDeltaHeights=True)
    if (os.path.exists(vis+'/ASDM_STATION')):
        mydict = getWeatherStationNames(vis)
        for uniqueStation in uniqueStationIDs:
            if (uniqueStation in mydict.keys()):
                stationNames.append(mydict[uniqueStation])
            else: # concat does not concat ASDM_STATION tables, so just use the ID
                stationNames.append(str(uniqueStation))
    elif (asdm is not None and asdm != ''):
        if (os.path.exists(asdm)):
            for i in range(len(uniqueStationIDs)):
                stationName, stationPosition = readStationFromASDM(asdm, uniqueStationIDs[i])
                stationNames.append(stationName)
        else:
            print "Could not find asdm to translate to station names."

    # assume all stations are to be plotted until told otherwise
    uniqueStationIDsToPlot = uniqueStationIDs
    if (station != [] and station != ''):
        if (type(station) == int):
            if (station not in uniqueStationIDs):
                print "Station %d is not in the data.  Present are: "%station, uniqueStationIDs
                return
            uniqueStationIDsToPlot = [station]
        elif (type(station) == list):
            for s in station:
                if (s not in uniqueStationIDs):
                    print "Station %d is not in the data.  Present are: " % (s), uniqueStationIDs
                    return
            uniqueStationIDsToPlot = station
        elif (type(station) == str):
            if (station.isdigit()):
                if (int(station) not in uniqueStationIDs):
                    print "Station %s is not in the data.  Present are: "%station, uniqueStationIDs
                    return
                uniqueStationIDsToPlot = [int(station)]
            else:
                if (len(stationNames) == 0):
                    print "Invalid station ID, it must be an integer, or list of integers, unless you specify asdm or load with asis='Station'."
                    return
                station = station.split(',')
                # It must be a list of station names
                uniqueStationIDsToPlot = []
                for s in station:
                    if (s.upper() not in stationNames and s not in stationNames):
                        print "Invalid station name, %s not found in dataset" % (s.upper())
                        return
                    elif (s in stationNames):
                        uniqueStationIDsToPlot.append(uniqueStationIDs[stationNames.index(s)])
                    else:
                        uniqueStationIDsToPlot.append(uniqueStationIDs[stationNames.index(s.upper())])

    if (len(uniqueStationIDsToPlot) > len(colors)):
        print "Too many stations (%d>%d), limit them using the station parameter" % (len(uniqueStationIDs), len(colors))
        return
    print "stationNames = ", stationNames
    if verbose: print "uniqueStationIDs to plot = ", uniqueStationIDsToPlot
    stationRows = {}
    Pressure = {}
    PressureDiff = {}
    RelativeHumidity = {}
    Temperature = {}
    DewPoint = {}
    WindDirection = {}
    WindSpeed = {}
    Mjdsec = {}
    if (referenceStation == '' or referenceStation not in stationNames):
        if (referenceStation not in stationNames):
            if referenceStation == 'MeteoTB2':
                if 'WSTB2' not in stationNames:
                    print "Reference station %s (or %s) is not in the data, choosing %s instead" % (referenceStation, 'WSTB2', stationNames[0])
                    referenceStation = stationNames[0]
                else:
                    referenceStation = 'WSTB2'
            else:
                referenceStation = stationNames[0]

    # referenceStationID is the index number of the referenceStation in stationNames array
    referenceStationID = list(stationNames).index(referenceStation)
    stationNamesToPlot = []
    for u in uniqueStationIDsToPlot:
        stationNamesToPlot.append(stationNames[list(uniqueStationIDs).index(u)])
    # If referenceStation not in stationNamesToPlot, then add it.
    if (referenceStation not in stationNamesToPlot):
        uniqueStationIDsToPlot.append(uniqueStationIDs[stationNames.index(referenceStation)])
        if verbose: print "uniqueStationIDs to plot = ", uniqueStationIDsToPlot
        stationNamesToPlot = []
        for u in uniqueStationIDsToPlot:
            stationNamesToPlot.append(stationNames[list(uniqueStationIDs).index(u)])
    print "stationNamesToPlot = ", stationNamesToPlot
    for i in range(len(uniqueStationIDsToPlot)):
        if (len(stationNames) == 0):
            stationName = 'ID%d' % (i)
            stationText = 'Station %d (ID=%d)' % (i,uniqueStationIDsToPlot[i])
        else:
            stationName = stationNames[list(uniqueStationIDs).index(uniqueStationIDsToPlot[i])]
            stationText = 'Station %d (ID=%d) = %s' % (i,uniqueStationIDsToPlot[i], stationName)
        stationRows[i] = np.where(stations == uniqueStationIDsToPlot[i])[0]
        if verbose:
            print "%s has %d of the %d rows" % (stationText,len(stationRows[i]),len(stations))
        Pressure[i] = pressure[stationRows[i]]
        RelativeHumidity[i] = relativeHumidity[stationRows[i]]
        Temperature[i] = temperature[stationRows[i]]
        if (pressureCorrection and len(stationNames) > 0):
            heightDiff = -heightDict[stationName]
            if (np.mean(Temperature[i]) < 100):
                # Auto correct to Kelvin
                temperatureK = celsiusToKelvin(Temperature[i])
            else:
                temperatureK = Temperature[i]
            Pressure[i] *= pressureCorrectionFactor(heightDiff,temperatureK)
        DewPoint[i] = dewPoint[stationRows[i]]
        WindDirection[i] = windDirection[stationRows[i]]
        WindSpeed[i] = windSpeed[stationRows[i]]
        Mjdsec[i] = mjdsec[stationRows[i]]
        if (np.mean(Temperature[i]) > 100):
            # convert to Celsius, if necessary
            Temperature[i] = kelvinToCelsius(Temperature[i])
        if (np.mean(DewPoint[i]) > 100):
            # convert to Celsius, if necessary
            DewPoint[i] = kelvinToCelsius(DewPoint[i]) # there was a longstanding bug here: dewPoint
        if (np.mean(DewPoint[i]) == 0.0):
            # assume it is not measured and use NOAA formula to compute from humidity:
            DewPoint[i] = ComputeDewPointCFromRHAndTempC(RelativeHumidity[i], Temperature[i])
#            print "mean Dewpoint from RH and Temperature = %f" % (np.mean(DewPoint[i]))
        if (np.mean(RelativeHumidity[i]) <= 0.001):
            if np.count_nonzero(DewPoint[i]) == 0:
                print "Setting small (zero or negative) relative humidity measurement to 0.001%"
                RelativeHumidity[i] = 0.001*np.ones(len(DewPoint[i]))
            else:
                print "Replacing zeros in relative humidity from station %s with value computed from dew point and temperature." % (stationName)
                #        dewPointWVP = np.exp(17.271*dewPoint/(237.7+dewPoint))
                #        ambientWVP = np.exp(17.271*temperature/(237.7+temperature))
                dewPointWVP = computeWVP(DewPoint[i])
                ambientWVP = computeWVP(Temperature[i])
                RelativeHumidity[i] = 100*(dewPointWVP/ambientWVP)
                print "first value: dewPt=%f amb=%f dewWVP=%f, ambWVP=%f, RH=%f" % (DewPoint[i][0], Temperature[i][0], dewPointWVP[0],ambientWVP[0],RelativeHumidity[i][0])
        if verbose:
            print "Median temperature for %s = %f" % (stationText, np.median(Temperature[i]))
            print "Max temperature for %s = %f" % (stationText, np.max(Temperature[i]))

    for i, ID in enumerate(uniqueStationIDsToPlot):
        stationName = stationNames[list(uniqueStationIDs).index(ID)]
        PressureDiff[stationName] = np.median(Pressure[i]) - np.median(Pressure[referenceStationID])
        print "median pressure of %s = %f" % (stationName,  np.median(Pressure[i]))
    if (not doplot):
        stationDict = {}
        if (len(stationNames) > 0):
            for name in stationNames:
                stationDict[name] = stationNames.index(name)
        else:
            for s in uniqueStationIDsToPlot:
                stationDict[s] = uniqueStationsIDToPlot.index(s)
        values = {'pressure':Pressure, 'temperature':Temperature,
                  'windspeed': WindSpeed, 'winddirection':WindDirection, 
                  'relativehumidity':RelativeHumidity, 'dewpoint': DewPoint,
                  'mjdsec': Mjdsec}
        return(stationDict, values)
    mysize = myfontsize
    pb.clf()
    adesc = pb.subplot(321)
    myhspace = 0.22
    mywspace = 0.25
    markersize = 3
    pb.subplots_adjust(hspace=myhspace, wspace=mywspace)
    pb.title(os.path.basename(vis), size=12)
    timeplot = {}
    for i in range(len(uniqueStationIDsToPlot)):
        stationName = stationNames[list(uniqueStationIDs).index(uniqueStationIDsToPlot[i])]
        if (len(stationNames) == 0):
            stationText = 'Station %d (ID=%d)' % (i,uniqueStationIDsToPlot[i])
        else:
            stationText = 'Station %d (ID=%d) = %s' % (i,uniqueStationIDsToPlot[i], stationName)
        print "median time spacing of %s = %.2f sec" % (stationText, np.median(np.diff(Mjdsec[i])))
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[i])
        timeplot[i] = pb.date2num(list_of_date_times)
        pb.hold(True)
        pb.plot_date(timeplot[i], Pressure[i], markersize=markersize, color=colors[i], mec=colors[i])
    resizeFonts(adesc,myfontsize)
    if pressureCorrection:
        pb.ylabel('Pressure (mb, corr. to %s)'%highestStation,size=mysize)
    else:
        pb.ylabel('Pressure (mb)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc = pb.subplot(322)
    temperatures = []
    for i in range(len(uniqueStationIDsToPlot)):
        pb.plot_date(timeplot[i], Temperature[i], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
        if (np.nanmax(Temperature[i]) != np.nanmin(Temperature[i]) or abs(np.nanmax(Temperature[i])) < 0.0001):
            # Avoid bogus "inf" readings from Meteo129, but allow the showing of thermometers stuck at 0.0
            temperatures += list(Temperature[i])
        stationName = stationNames[list(uniqueStationIDs).index(uniqueStationIDsToPlot[i])]
        print "Temperatures for station %d=%s: max=%+.1f, mean=%+.1f, min=%+.1f" % (i,stationName,np.nanmax(Temperature[i]), np.mean(Temperature[i]), np.nanmin(Temperature[i]))
    resizeFonts(adesc,myfontsize)
    minTemp = np.nanmin(temperatures)
    maxTemp = np.nanmax(temperatures)
#    print "MaxTemp=%f, MinTemp=%f" % (maxTemp, minTemp)
    temperatureRange = maxTemp-minTemp
    minTemp -= 0.05*temperatureRange
    maxTemp += 0.05*temperatureRange
    pb.ylim([minTemp,maxTemp])
    pb.ylabel('Temperature (C)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    labsize = myfontsize
    labxstart = -0.2
    xinc = 0.2
    for i in range(len(uniqueStationIDsToPlot)):
        stationName = stationNames[list(uniqueStationIDs).index(uniqueStationIDsToPlot[i])]
        if (len(stationNames) == 0):
            if (i == 0):
                pb.text(labxstart, 1.05, 'station:', color='k',
                        transform=adesc.transAxes, size=labsize)
            pb.text(labxstart+(1+i)*xinc, 1.05, '%d, ' % (uniqueStationIDsToPlot[i]), 
                    color=colors[i], transform=adesc.transAxes, size=labsize)
        else:
            if (i>3):
                y0 = 1.14
            else:
                y0 = 1.05
            pb.text(labxstart+(1+i)*xinc, y0, stationName.replace('Meteo',''), 
                    color=colors[i], transform=adesc.transAxes, size=labsize)

    adesc = pb.subplot(323)
    for i in range(len(uniqueStationIDsToPlot)):
        pb.plot_date(timeplot[i], RelativeHumidity[i], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
    resizeFonts(adesc,myfontsize)
#    pb.xlabel('Universal Time (%s)'%plotbp3.utdatestring(mjdsec[0]),size=mysize)
    pb.ylabel('Relative Humidity (%)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc = pb.subplot(324)
    for i in range(len(uniqueStationIDsToPlot)):
        pb.plot_date(timeplot[i], DewPoint[i], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
    resizeFonts(adesc,myfontsize)
#    pb.xlabel('Universal Time (%s)'%plotbp3.utdatestring(mjdsec[0]),size=mysize)
    pb.ylabel('Dew point (C)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc = pb.subplot(325)
    for i in range(len(uniqueStationIDsToPlot)):
        pb.plot_date(timeplot[i], WindSpeed[i], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
    resizeFonts(adesc,myfontsize)
    pb.xlabel('Universal Time (%s)'%plotbp3.utdatestring(mjdsec[0]),size=mysize)
    pb.ylabel('Wind speed (m/s)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc= pb.subplot(326)
    pb.xlabel('Universal Time (%s)'%plotbp3.utdatestring(mjdsec[0]),size=mysize)
    pb.ylabel('Wind direction (deg)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    for i in range(len(uniqueStationIDsToPlot)):
        pb.plot_date(timeplot[i], WindDirection[i], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
    resizeFonts(adesc,myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.ylim([0,360])
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    if (len(figfile) < 1):
        if (station == [] or station == ''):
            weatherFile = vis+'.weather.allstations.png'
        else:
            weatherFile = vis+'.weather.%dstations.png' % (len(station))
    else:
        weatherFile = figfile
    pb.savefig(weatherFile)
    pb.draw()
    print "Wrote file = %s" % (weatherFile)
    return(PressureDiff)

def celsiusToKelvin(celsius):
    return celsius + 273.15

def kelvinToCelsius(kelvin):
    return kelvin - 273.15

def plotWeatherFromASDM(asdm, station='', plotfile='', titlefontsize=10,
                        pressureCorrection=False, referenceStation='MeteoTB2',
                        colors=''):
    """
    Calls getWeatherFromASDM() for the specified ASDM, then plots the results.
    station: name of a weather station
    -- Todd Hunter
    """
    if (colors == ''): colors = list(weatherStationColors)
    myfontsize = 8
    markersize = 3
    if (os.path.exists(asdm) == False):
        print "Could not find asdm = ", asdm
        return
    asdm = asdm.rstrip('/')
    stationNames = getWeatherStationNamesFromASDM(asdm).values()
    uniqueStations = stationNames
    if pressureCorrection:
        heightDict, highestStation = getWeatherStationPositionsFromASDM(asdm, returnDeltaHeights=True)
    pb.clf()
    adesc = pb.subplot(321)
    pb.title(asdm, size=titlefontsize)
    # assume all stations are to be plotted until told otherwise
    uniqueStationsToPlot = stationNames
    if (station != [] and station != ''):
        if (type(station) == int):
            if (station not in uniqueStations):
                print "Station %d is not in the data.  Present are: "%station, uniqueStations
                return
            uniqueStationsToPlot = [station]
        elif (type(station) == list):
            for s in station:
                if (s not in uniqueStations):
                    print "Station %d is not in the data.  Present are: " % (s), uniqueStations
                    return
            uniqueStationsToPlot = station
        elif (type(station) == str):
            if (station.isdigit()):
                if (int(station) not in uniqueStations):
                    print "Station %s is not in the data.  Present are: "%station, uniqueStations
                    return
                uniqueStationsToPlot = [int(station)]
            else:
                if (len(stationNames) == 0):
                    print "Invalid station ID, it must be an integer, or list of integers, unless you specify asdm or load with asis='Station'."
                    return
                station = station.split(',')
                uniqueStationsToPlot = []
                for s in station:
                    if (s.upper() not in stationNames and s not in stationNames):
                        print "Invalid station name, %s not found in dataset" % (s.upper())
                        return
                    elif (s in stationNames):
                        uniqueStationsToPlot.append(uniqueStations[stationNames.index(s)])
                    else:
                        uniqueStationsToPlot.append(uniqueStations[stationNames.index(s.upper())])

    Mjdsec = {}
    Pressure = {}
    PressureDiff = {}
    Temperature = {}
    RelativeHumidity = {}
    WindSpeed = {}
    WindDirection = {}
    DewPoint = {}
    removals = []
    if (referenceStation == '' or referenceStation not in stationNames):
        referenceStation = stationNames[0]
    for i,stationName in enumerate(uniqueStationsToPlot):
        result = getWeatherFromASDM(asdm, station=stationName, verbose=False)
        [conditions, medianConditions, stationName] = result
        Mjdsec[stationName] = np.array(conditions[0])
        if (len(Mjdsec[stationName]) == 1):
            mymedian = Mjdsec[stationName][0]
        else:
            mymedian = np.median(np.diff(Mjdsec[stationName]))
        print "Median time spacing of %d points from station %s = %.2f sec" % (len(Mjdsec[stationName]), stationName, mymedian)
        Pressure[stationName] = conditions[1]
        Temperature[stationName] = kelvinToCelsius(np.array(conditions[3]))
        if (pressureCorrection and len(stationNames) > 0):
            heightDiff = -heightDict[stationName]
            if (np.mean(Temperature[stationName]) < 100):
                temperatureK = celsiusToKelvin(Temperature[stationName])
            else:
                temperatureK = Temperature[stationName]
            Pressure[stationName] *= pressureCorrectionFactor(heightDiff, temperatureK)
        RelativeHumidity[stationName] = conditions[2]
        WindSpeed[stationName] = conditions[5]
        WindDirection[stationName] = conditions[4]
        DewPoint[stationName] = ComputeDewPointCFromRHAndTempC(RelativeHumidity[stationName], Temperature[stationName])
        try:
            list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
            if (len(list_of_date_times) < 2):
                removals.append(stationName)
                continue
        except:
            removals.append(stationName)
            continue
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, Pressure[stationName], markersize=markersize, color=colors[i], mec=colors[i])
        pb.hold(True)
    for r in removals:
        print "Removing station %s due to invalid times" % (r)
        colors.remove(colors[uniqueStationsToPlot.index(r)])
        uniqueStationsToPlot.remove(r)
    for i,stationName in enumerate(uniqueStationsToPlot):
        PressureDiff[stationName] = np.median(Pressure[stationName]) - np.median(Pressure[referenceStation])
        print "median pressure of %s = %f" % (stationName,  np.median(Pressure[stationName]))
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    setTickLabelSize(adesc, myfontsize)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    mysize = myfontsize
    if pressureCorrection:
        pb.ylabel('Pressure (mb, corr. to %s)'%highestStation,size=mysize)
    else:
        pb.ylabel('Pressure (mb)',size=mysize)

    adesc = pb.subplot(322)
    for i,stationName in enumerate(uniqueStationsToPlot):
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, Temperature[stationName], markersize=markersize, color=colors[i], mec=colors[i])
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.ylabel('Temperature (C)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    labxstart = -0.2
    if (len(uniqueStationsToPlot) > 8):
        labsize = 8
    else:
        labsize = 9
    xinc = 0.2
    for i,stationName in enumerate(uniqueStationsToPlot):
        if (i>3):
            y0 = 1.14
        else:
            y0 = 1.05
        pb.text(labxstart+(1+i)*xinc, y0, stationName.replace('Meteo',''), 
                color=colors[i], transform=adesc.transAxes, size=labsize)

    adesc = pb.subplot(323)
    for i,stationName in enumerate(uniqueStationsToPlot):
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, RelativeHumidity[stationName], markersize=markersize, 
                     color=colors[i], mec=colors[i])
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.ylabel('Relative Humidity (%)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc = pb.subplot(324)
    for i,stationName in enumerate(uniqueStationsToPlot):
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, DewPoint[stationName], markersize=markersize, 
                     color=colors[i], mec=colors[i])
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.ylabel('Dew point (C)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    windSpeed = conditions[5]
    adesc = pb.subplot(325)
    for i,stationName in enumerate(uniqueStationsToPlot):
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot,WindSpeed[stationName], markersize=markersize, 
                     color=colors[i], mec=colors[i])
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    pb.xlabel('Universal Time (%s)' % plotbp3.utdatestring(Mjdsec[stationName][0]),size=mysize)
    pb.ylabel('Wind speed (m/s)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')

    adesc= pb.subplot(326)
    for i,stationName in enumerate(uniqueStationsToPlot):
        list_of_date_times = mjdSecondsListToDateTime(Mjdsec[stationName])
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, WindDirection[stationName], markersize=markersize, 
                     color=colors[i], mec=colors[i])
    pb.xlabel('Universal Time (%s)'%plotbp3.utdatestring(Mjdsec[stationName][0]),size=mysize)
    pb.ylabel('Wind direction (deg)',size=mysize)
    setTickLabelSize(adesc, myfontsize)
    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormat)
    RescaleXAxisTimeTicks(pb.xlim(), adesc)
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    if (len(plotfile) < 1):
        if (station == [] or station == ''):
            weatherFile = asdm+'.weather.allstations.png'
        else:
            weatherFile = asdm+'.weather.%dstations.png' % (len(uniqueStationsToPlot))
    else:
        weatherFile = plotfile
    pb.subplots_adjust(hspace=0.25, wspace=0.30)
    pb.savefig(weatherFile)
    pb.draw()
    print "Wrote file = %s" % (weatherFile)
    return(PressureDiff)

def find_key(dic, val):
    """return the key of dictionary dic given the value"""
    return [k for k, v in dic.iteritems() if v == val][0]

def degfile2radec(filename):
    """
    Converts a list of RA and Dec from a file into sexagesimal
    """
    f = open(filename,'r')
    lines = f.readlines()
    outname = filename+'.radec'
    outfile = open(filename+'.radec','w')
    for line in lines:
        ra,dec = line.split()
        radec = deg2radec(float(ra),float(dec))
        radec = radec.replace(',',' ')+'\n'
        radec = radec.replace('+0','+')
        radec = radec.replace('-0','-')
        outfile.write(radec)
    f.close()
    outfile.close()
    print "Output file = ", outname
    
def hours2radec(ra, dec=0, prec=5, verbose=True, hmsdms=False):
    """
    Convert a position (or list of positions) in RA/Dec from hours/degrees 
    to sexagesimal string.  See also deg2radec.
    -Todd Hunter
    Inputs:
    ra: RA in hours, or a tuple of RA in hours and Dec in degrees, or an array
        of RAs in hours
    dec: Dec in degrees, or an array of Decs in degrees
    prec: number of digits after the secondsdecimal
    hmsdms: if True, then format is HHhMMmSS.SSSs, +DDdMMmSS.SSSs
    Output:
    default format is HH:MM:SS.SSSSS, +DD:MM:SS.SSSS
    """
    if (type(ra) == tuple):
        ra = ra[0]*15, ra[1]
    else:  # float or np.ndarray
        ra *= 15
    return(deg2radec(ra, dec, prec, verbose, hmsdms))
    
def deg2dms(dec):
    """
    Converts a declination value in degrees to sexagesimal string.
    Also works for values as a generic convertor for values outside 
    the normal declination range of -90 to +90.
    -Todd Hunter
    """
    integer = int(dec)
    ra,dec = deg2radec(0,abs(dec)%1,delimiter=' ',verbose=False).split()
    token = dec.split(':')
    dec = ':'.join(['%+d'%integer, token[1], token[2]])
    return dec

def deg2radec(ra=0, dec=0, prec=5, verbose=True, hmsdms=False, delimiter=', ',
              filename=''):
    """
    Convert a position (or list of positions) in RA/Dec from degrees 
    to sexagesimal string. See also hours2radec.
    -Todd Hunter
    Inputs:
    ra: RA in degrees (float or string), or a tuple of RA and Dec in degrees, 
        or an array of RAs in degrees. If a string, 'deg' will be stripped.
    dec: Dec in degrees (float or string), or an array of Decs in degrees
    prec: number of digits after the secondsdecimal
    hmsdms: if True, then output format is HHhMMmSS.SSSs, +DDdMMmSS.SSSs
    filename: if specified, then treat ra and dec as column numbers (starting 
       at zero) from which to read the ra and dec values.
    Output:
    default format is HH:MM:SS.SSSSS, +DD:MM:SS.SSSS
    """
    if (ra==0 and dec==0 and filename==''):
        print "You must specify either ra and dec, or a filename"
        return
    elif (filename != ''):
        f = open(filename)
        lines = f.readlines()
        if (ra==0 and dec==0):
            dec = 1
        ralist = []
        declist = []
        for line in lines:
            token = line.split()
            ralist.append(np.double(token[ra]))
            declist.append(np.double(token[dec]))
        ra = np.array(ralist)
        dec = np.array(declist)
    if (type(ra) == np.ndarray and type(dec) == np.ndarray):
        radec = []
        for i in range(len(ra)):
            radec.append(rad2radec(np.double(ra[i])*pi/180., np.double(dec[i])*pi/180., None, prec, 
                                 verbose, hmsdms=hmsdms, delimiter=delimiter))
    else:
        if (type(ra) == tuple or type(ra) == list):
            dec = ra[1]
            ra = ra[0]
        if type(ra) == str:
            ra = ra.strip('degree')
        if type(dec) == str:
            dec = dec.strip('degree')
        radec = rad2radec(np.double(ra)*pi/180., np.double(dec)*pi/180., None, prec, verbose, hmsdms=hmsdms, delimiter=delimiter)
    return(radec)

def radec2deg(radecstring):
    """
    Convert a position from a single RA/Dec sexagesimal string to RA and
    Dec in degrees. The string can be either comma or space delimited, or
    delimited by h,m,s/d,m,s.
    The Dec portion of the string can be either : or . delimited.
    See also deg2radec and radec2rad.
    -Todd Hunter
    """
    if (radecstring.find('h')>0 and radecstring.find('d')>0):
        radecstring = radecstring.replace('h',':').replace('m',':').replace('s',' ').replace('d',':')
    myrad = radec2rad(radecstring)
    return(list(np.array(myrad)*180/np.pi))

def radec2rad(radecstring, returnList=False):
    """
    Convert a position from a single RA/Dec sexagesimal string to RA and
    Dec in radians.
    The RA and Dec portions can be separated by a comma or a space.
    The RA portion of the string must be colon-delimited, space-delimited,
        or 'h/m/s' delimited.
    The Dec portion of the string can be either ":", "." or space-delimited.
    If it is "." delimited, then it must have degrees, minutes, *and* seconds.
    Returns: a tuple
    returnList: if True, then return a list of length 2
    See also rad2radec.
    -Todd Hunter
    """
    if (radecstring.find('h')>0 and radecstring.find('d')>0):
        radecstring = radecstring.replace('h',':').replace('m',':').replace('d',':').replace('s','')
    radec1 = radecstring.replace(',',' ')
    tokens = radec1.split()
    if (len(tokens) == 2):
        (ra,dec) = radec1.split()
    elif (len(tokens) == 6):
        h,m,s,d,dm,ds = radec1.split()
        ra = '%s:%s:%s' % (h,m,s)
        dec = '%+f:%s:%s' % (float(d), dm, ds)
    else:
        print "Invalid format for RA/Dec string"
        return
    tokens = ra.strip().split(':')
    hours = 0
    for i,t in enumerate(tokens):
        hours += float(t)/(60.**i)
    if (dec.find(':') > 0):
        tokens = dec.lstrip().split(':')
    elif (dec.find('.') > 0):
        try:
            (d,m,s) = dec.lstrip().split('.')
        except:
            (d,m,s,sfraction) = dec.lstrip().split('.')
            s = s + '.' + sfraction
        tokens = [d,m,s]
    else:  # just an integer
        tokens = [dec]
    dec1 = 0
    for i,t in enumerate(tokens):
        dec1 += abs(float(t)/(60.**i))
    if (dec.lstrip().find('-') == 0):
        dec1 = -dec1
    decrad = dec1*np.pi/180.
    ra1 = hours*15
    rarad = ra1*np.pi/180.
    if returnList:
        return [rarad,decrad]
    else:
        return(rarad,decrad)

def fluxscaleLogMean(logfile, field=None, spw=None, showMedians=True,
                     showMaxDeviations=False, dropWorstOutlier=True,
                     referenceField=None):
    """
    Reads a concatenation of fluxscale log messages and computes
    the statistics on the flux density derived for a specified source
    and spw.
    -Todd Hunter
    """
    if (not os.path.exists(logfile)):
        print "Could not find file"
        return
    f = open(logfile,'r')
    lines = f.readlines()
    fluxes = []
    fields = []
    fluxUncs = []
    myReferenceField = None
    referenceFields = []
    for line in lines:
        loc = line.find('Found reference')
        if (loc >= 0):
            tokens = line[loc:].split()
            myReferenceField = tokens[3]
            referenceFields.append(myReferenceField)
        loc = line.find('Flux density')
        if (loc >= 0):
            result = line[loc:].split()
            if (len(result) < 18): continue
            a,b,c,ifield,d,ispw,Hz,e,f,flux,g,fluxUnc,h,j,snr,k,l,n = result
            ispw = ispw.split('=')[1]
            flux = float(flux)
            fluxUnc = float(fluxUnc)
            if ((spw == None or str(spw) == ispw or spw=='') and
                (field==None or field==ifield or field=='') and
                (referenceField==None or referenceField=='' or
                 myReferenceField==referenceField)):
                fields.append(ifield)
                fluxes.append(flux)
                fluxUncs.append(fluxUnc)
    if (len(fluxes) < 1):
        print "No matching measurements found."
        return
    if (len(referenceFields)>0 and (referenceField==None or referenceField=='')):
        print "reference fields = ", np.unique(referenceFields)
    if (referenceField is not None and referenceField != ''):
        print "%d measurements for %s using %s" % (len(fluxes), np.unique(fields), referenceField)
    else:
        print "%d measurements for %s" % (len(fluxes), np.unique(fields))
    print "Mean+-std = %f+-%f (%f%%)" % (np.mean(fluxes),np.std(fluxes),
                                         np.std(fluxes)*100/np.mean(fluxes))
    if (showMedians):
        print "Median+-MAD/.6745 = %f+-%f (%f%%)" % (np.median(fluxes),MAD(fluxes),
                                         MAD(fluxes)*100/np.median(fluxes))
    if (dropWorstOutlier and len(fluxes)>1):
        worstOutlier = np.argmax(np.abs(fluxes-np.median(fluxes)))
        print "Dropping worst outlier: %f" % (fluxes[worstOutlier])
        fluxes = list(fluxes[:worstOutlier]) + list(fluxes[worstOutlier+1:])
        print "Mean+-std = %f+-%f (%f%%)" % (np.mean(fluxes),np.std(fluxes),
                                         np.std(fluxes)*100/np.mean(fluxes))
                    
    if (showMedians):
        print "Median+-MAD/.6745 = %f+-%f (%f%%)" % (np.median(fluxes),MAD(fluxes),
                                         MAD(fluxes)*100/np.median(fluxes))
    if (showMaxDeviations):
        maxdiff = np.max(flux)-np.mean(fluxes)
        mindiff = np.mean(flux)-np.min(fluxes)
        print "Max-mean = %f  (%f%%)" % (maxdiff, maxdiff*100/np.mean(flux))
        print "Mean-min = %f (%f%%)" % (mindiff, mindiff*100/np.mean(flux))
    
def fluxscaleParseLog(logfile, field=None):
    """
    Extract the spectral index fit parameters from the ASCII log file
    produced by the casa task fluxscale.  If only one spw is in the file
    then there is no fit, and so the only flux density is returned and
    the spectral index and uncertainty are set to zero.
    Optional parameters:
    field: can be given as a name string (e.g. '3c279')
    Returns a list of 4 items for the first (or specified) field found: 
         flux density list: [I,0,0,0]
         reference frequency as a string (e.g. '44.5507GHz')
         spectral index as a float
         spectral index Uncertainty as a float
    - T. Hunter
    """
    f = open(logfile,'r')
    lines = f.readlines()
    lastline = None
    for line in lines:
        if ((line.find('Fitted spectrum') > 0) and (field==None or line.find(field)>0)):
            lastline = line
            break
    f.close()
    if (lastline == None):
        if (field == None):
            print "Did not find fitted spectrum line"
        else:
            print "Did not find fitted spectrum line for %s" % (field)
        print "Using first spw with data"
        refFreqString = ''
        for line in lines:
            if ((line.find('Flux density for') > 0) and (field==None or line.find(field)>0) and line.find('INSUFFICIENT')<0):
                fluxDensity = float(line.split(' is: ')[1].split()[0])
                refFreqString = line.split('freq=')[1].split(')')[0].replace(' ','')
                spidx = 0
                spidxUncertainty = 0
                break
        if (refFreqString == ''):
            print "No flux densities found."
            return
    else:
        fluxDensity = float(lastline.split('Flux density = ')[1].split()[0])
        refFreqString = lastline.split('freq=')[1].split(')')[0].replace(' ','')
        spidx = float(lastline.split('spidx=')[1].split(' ')[0])
        spidxText = lastline.split('spidx=')[1].split(' ')
        if (len(spidxText) > 2):
            spidxUncertainty = float(spidxText[2])
        else:
            print "Warning from fluxscaleParseLog: spectral index uncertainty is indeterminate."
            spidxUncertainty = 0.0
    return([fluxDensity,0,0,0], refFreqString, spidx, spidxUncertainty)

def fluxscaleMean(fluxscaleDict=None, fieldID=None, fieldname=None, 
                  fluxd=None, fluxdUncertainty=None, verbose=True):
    """
    Computes the mean flux density for a field across all spws in a
    dictionary returned by fluxscale, or a list of input flux densities
    and uncertainties.  Nans are masked and ignored by using np.ma functions.
    fluxscaleDict: dictionary returned by CASA fluxscale
    fieldID: field ID (integer or integer string)
    fieldname: field name string
    fluxd: a list or numpy array of flux densities
    fluxdUncertainty: a list or numpy array of uncertainties
    Returns: weighted mean, and weighted uncertainty
    -Todd Hunter
    """
    if (fluxscaleDict == None):
        if (fluxd==None or fluxdUncertainty==None):
            print "Must specify either fluxscaleDict or fluxd with fluxdUncertainty"
            return
        spws = np.ones(len(fluxd))
    else:
        if (fieldID==None and fieldname==None):
            print "Must specify either fieldID or fieldname"
            return
        spws = []
        fluxd = []
        fluxdUncertainty = []
        for fieldkey in fluxscaleDict.keys():
            if (not fieldkey.isdigit()): continue
            if (fieldID == None):
                if (fieldname != fluxscaleDict[fieldkey]['fieldName']):
                    continue
            else:
                if (str(fieldID) not in fluxscaleDict.keys()):
                    print "Field %s is not in the dictionary" % (str(fieldID))
                    return
            keys = fluxscaleDict[fieldkey].keys()
            for key in keys:
                if (key.isdigit()):
                    spws.append(int(key))
                    fluxd.append(fluxscaleDict[fieldkey][key]['fluxd'][0])
                    fluxdUncertainty.append(fluxscaleDict[fieldkey][key]['fluxdErr'][0])
            break
    weights = 1/(np.array(fluxdUncertainty)**2)
    weights_nonan = np.ma.masked_array(weights, np.isnan(fluxd))
    fluxd_nonan = np.ma.masked_array(fluxd, np.isnan(fluxd))
#    print "Running np.ma.average(%s, weights=%s)" % (str(fluxd_nonan), str(weights_nonan))
    mymean = np.ma.average(fluxd_nonan, weights=weights_nonan)
    mystd = 1/(weights_nonan.sum())**0.5
    if verbose:
        print "Uncertainty-weighted mean flux density over %d measurements: %.4f +- %.4f Jy" % (len(sorted(spws)), mymean, mystd)
    return(mymean, mystd)

def imageImstats(images, region='', keyword='flux', index=0, verbose=False):
    """
    Runs imstat on a list of images and reports back the specified keyword value.
    region: region to examine (default = whole image)
    keyword: the dictionary key to extract and return (default='flux')
       options: rms, medabsdevmed, minpos, maxpos, minposf, maxposf
                flux, min, max, sum, sumsq, median, quartile, npts, 
                mean, sigma, blc, trc, blcf, trcf   
    index: the index of the array to choose
    verbose: if True, print the dictionary returned by imstat
    Returns:
    a list of values
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    fluxes = []
    for img in images:
        flux = imageImstat(img, region, keyword, index, verbose)
        if (flux == None): return
        fluxes.append(flux)
        print "%s:  %f" % (img, flux)
    return(fluxes)

def imageGaussianFilter(img, sigma=15/2.355, channel='', outfile='', 
                        overwrite=True):
    """
    Alternative to imsmooth for a 2D image or a single plane of a cube.
    Uses scipy.ndimage.filters.gaussian_filter
    sigma: standard deviation for Gaussian kernal (passed to gaussian_filter)
    channel: which channel of a cube to smooth
    outfile: default name = <img>.gaussianFilteres
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    myia = createCasaTool(iatool)
    if (outfile == ''):
        outfile = img + '.gaussianFiltered'
    if (os.path.exists(outfile)):
        if (overwrite):
            print "Removing existing outfile"
            shutil.rmtree(outfile)
            os.system('cp -r %s %s' % (img,outfile))
    else:
        os.system('cp -r %s %s' % (img,outfile))
    myia.open(img)
    pixels = myia.getregion()
    axis = findSpectralAxis(myia)
    myia.close()
    if (channel != ''):
        if (axis==2):
            result = gaussian_filter(pixels[:,:,channel,0], sigma=sigma)
            pixels[:,:,channel,0] = result
        elif (axis==3):
            result = gaussian_filter(pixels[:,:,0,channel], sigma=sigma)
            pixels[:,:,0,channel] = result
    else:
        if (len(pixels[axis]) == 1):
            pixels = gaussian_filter(pixels, sigma=gaussianSigma)
        else:
            print "Multi-channels not supported.  Use casa imsmooth."
            return
    myia.open(outfile)
    myia.putregion(pixels=pixels)
    myia.close()
    print "Wrote ", outfile

def imageImstat(img, region='', keyword='flux', index=0, verbose=False, pb='', pbInner=0.8, pbOuter=0.4):
    """
    Runs imstat on an image and reports back the value of a keyword.
    img: name of CASA image
    region: region to examine (default = whole image)
    keyword: the dictionary key to extract and return (default='flux')
       options: rms, medabsdevmed, minpos, maxpos, minposf, maxposf
                flux, min, max, sum, sumsq, median, quartile, npts, 
                mean, sigma, blc, trc, blcf, trcf   
    index: the index of the array to choose
    verbose: if True, print the dictionary returned by imstat
    pb: if not blank, then set mask based on pbInner and pbOuter
    """
    mask = ''
    if (pb != ''):
        if (pbInner != '' and pbOuter != ''):
            mask = '%s<%f&&%s>%f' % (pb,pbInner,pb,pbOuter)
        elif (pbInner != ''):
            mask = '%s<%f' % (pb,pbInner)
        elif (pbOuter != ''):
            mask = '%s>%f' % (pb,pbOuter)
    mydict = imstat(img, region=region, mask=mask)
    if (verbose):
        print mydict
    if (keyword not in mydict.keys()): 
        print "keyword %s not returned by imstat" % (keyword)
        return None
    if (len(mydict[keyword]) < index+1):
        print "Invalid index, length=%d" % (len(mydict[keyword]))
        return
    return(mydict[keyword][0])

def ratioImageStdPerChannel(img1, img2, region='', pbimg='', chans='', pbInner=0.3, 
                            pbOuter=0.2, statistic='std', plotmin=False, plotfile='', 
                            box='', listit=False, maskSigma=None, maskValue=False,
                            plotrange=[0,0,0,0], title=''):
    """
    Compute and plot the ratio of imageStdPerChannel of two cubes.
    -Todd Hunter
    """
    v1 = imageStdPerChannel(img1, region, pbimg, chans, pbInner, 
                            pbOuter, statistic+'array', plotmin, plotfile, 
                            box, listit, maskSigma, maskValue)
    v2 = imageStdPerChannel(img2, region, pbimg, chans, pbInner, 
                            pbOuter, statistic+'array', plotmin, plotfile, 
                            box, listit, maskSigma, maskValue)
    v1 = v1/v2
    pb.clf()
    pb.plot(range(len(v1)), v1, 'ko-')
    pb.plot(range(len(v1)), np.ones(len(v1)), 'k:')
    pb.xlabel('Channel')
    pb.ylabel('Ratio of %s' % (statistic))
    pb.title(title)
    if plotrange[:2] != [0,0]:
       pb.xlim(plotrange[:2])
    if plotrange[2:] != [0,0]:
       pb.ylim(plotrange[2:])
    pb.draw()
    if (plotfile != ''):
        if plotfile == True:
            plotfile = 'stdev_ratio.png'
        pb.savefig(plotfile)

def imageStdPerChannel(img, region='', pbimg='', chans='', pbInner=0.3, 
                       pbOuter=0.2, statistic='std', plotmin=False,plotfile='', 
                       box='', listit=False, maskSigma=None, maskValue=False,
                       plotrange=[0,0,0,0], doplot=True, verbose=True, 
                       xaxis='chan', markPeaks=False, percentile=10):
    """
    Computes the statistics of each plane of a CASA cube over a specified 
    region or annulus in the primary beam response and generates a profile 
    plot of max, sigma, rms, scaled MAD, and optionally, min.
    -Todd Hunter
    Inputs:
    img: CASA cube
    xaxis: 'chan' or 'freq'
    statistic: 'std', 'mad', 'rms', 'peak/std', 'peak/mad', 'peak/rms' 
         which array (or ratio) to compute stats upon
         append or prepend 'array' to return the array itself
         Note: the "peak/" options use the peak in the whole plane
    region: region to examine (default = whole image)
    box: box(es) to examine, either 'a,b,c,d' or 'a,b,c,d,e,f,g,h', etc.
    pbimg: if not blank, then set mask based this primary beam image, using the
           range of pixels between radii of pbInner and pbOuter
    chans: single channel, or range of channels to use (e.g. '4~50'),  blank --> all channels
    plotmin: if True, then also plot the min statistic
    listit: passed to imstat (default of False reduces clutter in casa log)
    maskSigma: if specified, then mask each channel of the image below this
          value times the statistic of that image.
    maskValue: the value to which to set the mask (use False for images)
    markPeaks: if True, draw a marker at the peak value of each curve
    percentile: percentile to compute for sigma==std (0=min, 100=max)
    Returns:
    list of four values [np.median(v), np.min(v), np.max(v), MAD(v)]
    or, if statistic contains 'array', the array v
    """
    mask = ''
    if (pbimg != ''):
        if (pbInner != '' and pbOuter != ''):
            mask = '"%s"<%f&&"%s">%f' % (pbimg,pbInner,pbimg,pbOuter)
        elif (pbInner != ''):
            mask = '"%s"<%f' % (pbimg,pbInner)
        elif (pbOuter != ''):
            mask = '"%s">%f' % (pbimg,pbOuter)
    if xaxis.find('chan') < 0 and xaxis.find('freq') < 0:
        print "xaxis must be either 'chan' or 'freq'."
        return
    mylist = imheadlist(img,omitBeam=True)
    bunit = mylist['bunit']
    myshape = mylist['shape']
    axes = range(len(myshape))
    axis = findSpectralAxis(img)
    axes.remove(axis)
    if (chans == ''):
        c0 = 0
        c1 = myshape[axis]-1
    elif (type(chans)==str):
        if (chans.find('~') > 0):
            c0,c1 = [int(i) for i in chans.split('~')]
        else:
            c0 = int(chans)
            c1 = int(chans)
    elif type(chans) != list: # single value passed
        c0 = int(chans)
        c1 = int(chans)
        chans = '%d~%d' % (c0,c1)
    chanlist = range(c0,c1+1)
    mydict = imstat(img, region=region, mask=mask, box=box, listit=listit, 
                    axes=axes)
    mini = mydict['min'][c0:c1+1]
    maxi = mydict['max'][c0:c1+1]
    if (statistic.find('peak') >= 0):
        maxWholePlane = imagePeakPerChannel(img, channels='%d~%d'%(c0,c1), axes=axes)
    rms = mydict['rms'][c0:c1+1]
    std = mydict['sigma'][c0:c1+1]
    mad = mydict['medabsdevmed'][c0:c1+1]

    whole = imstat(img, region=region, mask=mask, chans=chans, box=box)
    if verbose:
        print "rms: median=%f, min=%f, max=%f, mad=%f, allchans=%f" % (np.median(rms),np.min(rms),np.max(rms),MAD(rms),whole['rms'])
        print "std: median=%f, min=%f, max=%f, mad=%f, allchans=%f, %d%%ile=%f" % (np.median(std),np.min(std),np.max(std),MAD(std),whole['sigma'], percentile, scoreatpercentile(std,percentile))
        print "mad: median=%f, min=%f, max=%f, mad=%f, allchans=%f" % (np.median(mad),np.min(mad),np.max(mad),MAD(mad),whole['medabsdevmed'])
        print "max: median=%f, min=%f, max=%f, mad=%f, allchans=%f" % (np.median(maxi),np.min(maxi),np.max(maxi),MAD(maxi),whole['max'])
        print "min: median=%f, min=%f, max=%f, mad=%f, allchans=%f" % (np.median(mini),np.min(mini),np.max(mini),MAD(mini),whole['min'])
    if doplot:
        pb.clf()
        desc = pb.subplot(111)
        if xaxis.find('freq') >= 0:
            chanlist = imageChannelFrequency(img, channel=-1)
        pb.plot(chanlist, rms, 'r-', chanlist, mad, 'm-', chanlist, std, 'g-', 
                chanlist, maxi, 'k-')
        pb.plot(pb.xlim(), 2*[whole['rms']], 'r:', pb.xlim(), 2*[whole['medabsdevmed']], 
                'm:', pb.xlim(), 2*[whole['sigma']], 'g:', pb.xlim(), 2*[whole['max']], 'k:')
        if markPeaks:
            pb.plot([chanlist[np.where(maxi==whole['max'])[0][0]]], [whole['max']], 'ko')
            pb.plot([chanlist[np.where(rms==np.max(rms))[0][0]]], [np.max(rms)], 'ro', mec='r')
            pb.plot([chanlist[np.where(std==np.max(std))[0][0]]], [np.max(std)], 'go', mec='g')
            pb.plot([chanlist[np.where(mad==np.max(mad))[0][0]]], [np.max(mad)], 'mo', mec='m')
        # draw lines down to x-axis
        pb.plot(2*[chanlist[np.where(maxi==whole['max'])[0][0]]], [0,whole['max']], 'k:')
        pb.plot(2*[chanlist[np.where(rms==np.max(rms))[0][0]]], [0,np.max(rms)], 'r:')
        pb.plot(2*[chanlist[np.where(std==np.max(std))[0][0]]], [0,np.max(std)], 'g:')
        pb.plot(2*[chanlist[np.where(mad==np.max(mad))[0][0]]], [0,np.max(mad)], 'm:')
        if (plotmin):
            pb.plot(chanlist, mini, 'b-',  pb.xlim(), 2*[whole['min']], 'b:')
            pb.text(0.1, 0.75, 'min', color='b', transform=desc.transAxes)
    #    else:
    #        pb.ylim([0,pb.ylim()[1]])
        if xaxis.find('chan') >= 0:
            pb.xlabel('Channel')
        else:
            pb.xlabel('Frequency (GHz)')
            
        if statistic.find('peak/') >= 0:
            bunit = ''
        else:
            bunit = ' ('+bunit+')'
        if (pbimg != ''):
            pb.ylabel('imstat statistic (computed over pb=%.2f < r < %.2f) %s' % (pbOuter, pbInner, bunit))
        elif (box != ''):
            pb.ylabel('imstat statistic (computed over box)' + bunit)
        else:
            pb.ylabel('imstat statistic (computed over image)' + bunit)
        pb.title(os.path.basename(img),size=12)
        textsize = 10
        pb.text(0.1, 0.95, 'max = %g' % (whole['max']), color='k', transform=desc.transAxes, size=textsize)
        pb.text(0.1, 0.90, 'sigma = %g (max=%g, med=%g, min=%g)' % (whole['sigma'],np.max(std),np.median(std),np.min(std)), color='g', transform=desc.transAxes, size=textsize)
        pb.text(0.1, 0.85, 'rms = %g (max=%g, med=%g, min=%g)' % (whole['rms'],np.max(rms), np.median(rms), np.min(rms)), color='r', transform=desc.transAxes, size=textsize)
        pb.text(0.02, 0.80, 'unscaled MAD = %g (max=%g, med=%g, min=%g)' % (whole['medabsdevmed'], np.max(mad), np.median(mad), np.min(mad)), color='m', transform=desc.transAxes, size=textsize)
        pb.text(0.02, 0.75, 'scaled MAD = %g (max=%g, med=%g, min=%g)' % (whole['medabsdevmed']/.6745, np.max(mad)/.6745, np.median(mad)/.6745, np.min(mad)/.6745), color='m', transform=desc.transAxes, size=textsize)
        pb.text(0.7, 0.95, 'dotted = all channels', transform=desc.transAxes, size=textsize)
    if (statistic.find('peak/rms') >= 0):
        v = maxWholePlane/rms
        if verbose: print "Channel with min peak/rms = %d, max peak/rms = %d" % (np.argmin(v), np.argmax(v)) 
    elif (statistic.find('peak/std') >= 0):
        v = maxWholePlane/std
        if verbose: print "Channel with min peak/std = %d, max peak/std = %d" % (np.argmin(v), np.argmax(v)) 
    elif (statistic.find('peak/mad') >= 0):
        v = maxWholePlane/mad
        if verbose: print "Channel with min peak/mad = %d, max peak/mad = %d" % (np.argmin(v), np.argmax(v)) 
    elif (statistic.find('rms') >= 0):
        v = rms
        if verbose: print "Channel with min rms = %d, max rms = %d" % (np.argmin(v), np.argmax(v)) 
    elif (statistic.find('std') >= 0):
        v = std
        if verbose: print "Channel with min std = %d, max std = %d" % (np.argmin(v), np.argmax(v)) 
    elif (statistic.find('mad') >= 0):
        v = mad
        if verbose: print "Channel with min mad = %d, max mad = %d" % (np.argmin(v), np.argmax(v)) 
    if doplot:
        if statistic.find('peak/') >= 0:
            pb.plot(chanlist, v, 'b-')
            pb.text(0.1, 0.75, statistic, color='b', transform=desc.transAxes)
        if plotrange[:2] != [0,0]:
           pb.xlim(plotrange[:2])
        if plotrange[2:] != [0,0]:
           pb.ylim(plotrange[2:])
        pb.draw()
        if (plotfile != ''):
            if plotfile == True:
                plotfile = img + '_stdPerChannel.png'
            pb.savefig(plotfile)
    if maskSigma is not None:
        for i in range(len(v)):
            maskChannel(img, i+c0, belowValue=maskSigma*v[i], maskValue=maskValue)
    if statistic.find('array') >= 0:
        return v
    else:
        return [np.median(v), np.min(v), np.max(v), MAD(v)]
    
def imageSetCtype(img, ctype1='RA---SIN', ctype2='DEC--SIN'):
    imhead(img, mode='put', hdkey='ctype1', hdvalue=ctype1)
    imhead(img, mode='put', hdkey='ctype2', hdvalue=ctype2)

def imstat_cas6745(img, bunit='"1e15 cm^-2"'):
    """
    Workaround for CAS-6475.
    -Todd Hunter
    """
    if (imhead(img,mode='get',hdkey='bunit')==bunit):
        imgtemp = img+'.temp'
#        print "Copying image to ", imgtemp
        shutil.copytree(img, imgtemp)
        imhead(imgtemp,mode='put',hdkey='bunit',hdvalue='K')
        mystat = imstat(imgtemp)
#        print "Removing ", imgtemp
        shutil.rmtree(imgtemp)
    else:
        mystat = imstat(img)
    return(mystat)

def makeMovie(images, moviename='', convert=True, delay=50, 
              ffmpeg='/users/thunter/usr/local/ffmpeg/ffmpeg',verbose=False):
    """
    Runs convert or ffmpeg to assemble a list of png files in the current
    working directory into an animated gif or mpeg move.
    images: either a list of filenames, a comma-delimited string, or a single
            string with a wildcard character
    convert: if True, then use ImageMagick's convert command to build a gif
             (instead of ffmpeg to build an mpeg)
    delay: time gap between 
    moviename: name of output file (*.gif or *.mpeg)
    ffmpeg: full path to the ffmpeg executable
    The resulting *.mpg file can be played with mplayer or vlc.
    One can also use ImageMagick to generate a movie on-the-fly:
         animate -delay 50 *.png
    -Todd Hunter
    """
    if (moviename==''):
        if (type(images) == str):
            moviename = images.split(',')[0].split('*')[0]+'.mpg'
        else:
            moviename = images[0]+'.mpg'
    if (type(images) == str):
        if (images.find('*') >= 0):
            imglist = sorted(glob.glob(images))
            if not convert:
                images = imglist
        else: # assume comma-delimited string
            imglist = images.split(',')
            images = ' '.join(imglist)
        if not convert:
            for i,img in enumerate(images):
                shutil.copyfile(img, 'img%03d.png'%(i))
    else:
        imglist = images[:]
        images = ' '.join(imglist)
    if (os.path.exists(moviename)):
        os.remove(moviename)
    print "Assembling movie from %d images" % (len(imglist))
    if (convert):
        cmd = 'convert -delay %d %s %s' % (delay,images,moviename)
    else:
        cmd = ffmpeg + ' -qmax 8 -i img%%03d.png %s' % (moviename)
    if verbose:
        print "Running: ", cmd
    os.system(cmd)
    if (convert):
        print "Wrote movie: ", moviename
        print "To display movie on linux: animate %s" % (moviename)
        print "To change the frame rate: animate -delay 50 %s" % (moviename)
    
def imviewFields(imgs, radius=0, minIntensity=None, maxIntensity=None, 
                 maxIntensityFraction=None, maxIntensityMinFraction=None,
                 xcenter=None, ycenter=None, colorwedge=True, plotfile=None,
                 frequency=None, trim=True, colormap='Rainbow 2', scaling=0,
                 verbose=False, contourImage=None, levels=None, unit=1.0,
                 contourImage2=None, levels2=None, unit2=1.0, 
                 minIntensityFraction=None, dpi=300, contourColor='white',
                 contourColor2='yellow', base=0.0, base2=0.0, 
                 contourThickness=1, contourThickness2=1):
    """
    Calls imviewField on a list of images (or wildcard name) and puts the
    resulting pngs into a PDF.
    imgs: a list of images, or a single string containing a wildcard character(s)
       example: 'g??.??/tkin24*masked4*image'
    maxIntensity: None, value or 'median'
        if 'median', then use the median maximum value of all images
    For other arguments, see help(au.imviewField)
    -Todd Hunter
    """
    if plotfile==None:
        pdf = 'imviewFields.pdf'
    else:
        pdf = plotfile
    pngs = []
    if (type(imgs) == str):
        if (imgs.find('*') >= 0):
            imgs = sorted(glob.glob(imgs))
    if (maxIntensity == 'median'):
        maxs = []
        for img in imgs:
            maxs.append(np.float(imstat_cas6745(img)['max'][0]))
        maxIntensity = np.float(np.median(maxs))
        print "Using maxIntensity = ", maxIntensity
    for img in imgs:
        plotfile = img+'.imview.png'
        pngs.append(plotfile)
        imviewField(img, radius, minIntensity, maxIntensity, maxIntensityFraction,
                    maxIntensityMinFraction, xcenter, ycenter, colorwedge, plotfile,
                    frequency, trim, colormap, scaling, verbose, contourImage, levels,
                    unit, contourImage2, levels2, unit2,
                    minIntensityFraction, dpi, contourColor, contourColor2, base, base2,
                    contourThickness, contourThickness2)
    buildPdfFromPngs(pngs, pdf)

def imviewGaussianModels(img, models=[], color='yellow', thickness=2, plotfile=None,
                         colorwedge=True, minIntensity=None, maxIntensity=None,
                         maxIntensityFraction=None, minIntensityFraction=None,radius=0,
                         maxIntensityMinFraction=None, colormap='Rainbow 2', scaling=0,
                         xcenter=None, ycenter=None, trim=True, pathToConvert=''):
    """
    Overlays 1 or more images of Gaussian models (such as those created from imfitplot with
    the generateExtraModelAndResidual option enabled) as 50% contours overtop another image.
    img: base image
    models: list of model image names
    plotfile: default=<img>.modelOverlay.png
    -Todd Hunter
    """
    img = img.rstrip('/')
    if (plotfile == None):
        plotfile = img + '.modelOverlay.png'
    myrange = pickIntensityRange(img, maxIntensity, minIntensity, maxIntensityFraction, 
                                 minIntensityFraction, maxIntensityMinFraction)
    mydict = getFitsBeam(img) # , omitBeam=True)
    arcsecPerPixel = abs(mydict[3])
    naxis1 = mydict[5]
    naxis2 = mydict[6]
    if (xcenter == None):
        xcenter = (naxis1-1)/2.0
    if (ycenter == None):
        ycenter = (naxis2-1)/2.0
    if radius > 0:
        blcx = xcenter - radius/arcsecPerPixel
        blc = [float(xcenter - radius/arcsecPerPixel), float(ycenter - radius/arcsecPerPixel)]
        trc = [float(xcenter + radius/arcsecPerPixel), float(ycenter + radius/arcsecPerPixel)]
    else:
        blc = [0,0]
        trc = [int(naxis1-1), int(naxis2-1)]
    contour = []
    for model in models:
        contour.append({'file':model, 'levels':[0.5], 'color': color, 'thickness': float(thickness)})
    imview(raster=[{'file':img, 'colorwedge': colorwedge, 'range':myrange, 'colormap':colormap, 'scaling':scaling}],
           contour=contour, out=plotfile, zoom={'coord':'pixel', 'blc':blc, 'trc':trc})
    if (trim and plotfile is not None and plotfile != ''):
        if (len(pathToConvert) > 0):
            if (pathToConvert[-1] != '/'):
                pathToConvert += '/'
        cmd = '%sconvert -trim %s %s' % (pathToConvert,plotfile,plotfile)
        os.system(cmd)
    print "Wrote plotfile = ", plotfile

def pickIntensityRange(img, maxIntensity, minIntensity, maxIntensityFraction, 
                       minIntensityFraction, maxIntensityMinFraction):
    """
    Choose an intensity range for imview.
    minIntensity: the minimum intensity to display (if None, use min)
    maxIntensity: the maximum intensity to display (if None, use maxIntensityFraction)
    maxIntensityFraction: the fraction of the image maximum to display (if None, use max)
    maxIntensityMinFraction: the fraction of the image minimum to display as max (if None, use max)
    minIntensityFraction: the fraction of the image maximum to display (if None, use min)
    """
    if (maxIntensity == None or minIntensity == None):
        myimstat = imstat_cas6745(img)
        imax = float(myimstat['max'][0])
    if (minIntensity == None):
        if (minIntensityFraction is not None):
            imin = minIntensityFraction * float(myimstat['max'][0])
        else:
            imin = float(myimstat['min'][0])
    else:
        imin = minIntensity
    if (maxIntensity == None):
        if (maxIntensityFraction is not None):
            imax *= maxIntensityFraction
        elif (maxIntensityMinFraction is not None):
            imax = abs(imin)*maxIntensityMinFraction
    else:
        imax = maxIntensity
    return [imin,imax]

def imviewField(img, radius=0, minIntensity=None, maxIntensity=None,
                maxIntensityFraction=None, maxIntensityMinFraction=None,
                xcenter=None, ycenter=None, colorwedge=True, plotfile=None,
                frequency=None, trim=True, colormap='Rainbow 2', scaling=0,
                verbose=False, contourImage=None, levels=None, unit=1.0,
                contourImage2=None, levels2=None, unit2=1.0,
                minIntensityFraction=None, dpi=300, contourColor='white',
                contourColor2='yellow', base=0.0, base2=0.0, 
                contourThickness=1, contourThickness2=1, ellipse=[],
                pathToConvert='', channel=0, ellipseLevel=0.5, scale=2, 
                orientation='landscape', axes='auto'):
    """
    Plots a square portion of a CASA image using imview.
    channel: which channel of cube to view
    radius: radius of the square, floating point value in arcseconds, <=0 means whole image
    minIntensity: the minimum intensity to display (if None, use min)
    maxIntensity: the maximum intensity to display (if None, use maxIntensityFraction)
    maxIntensityFraction: the fraction of the image maximum to display (if None, use max)
    maxIntensityMinFraction: the fraction of the image minimum to display as max (if None, use max)
    minIntensityFraction: the fraction of the image maximum to display (if None, use min)
    xcenter, ycenter: central pixel, e.g. [128,160]; or set xcenter='ellipse' 
       to use the center of the requested ellipse;  or a sexagesimal string 
       of 'hh:mm:ss.ss' and 'dd:mm:ss.ss'
    colorwedge: Boolean to control the display of a colorwedge
    plotfile: the name of the png file to produce, set to '' to open viewer
    frequency: scale the requested radius by the ratio of this frequency
               (given in Hz or GHz) to the frequency in the image header
    trim: if True, run ImageMagick's "convert -trim" to remove blank borders
    colormap: string, see the available names in the viewer wrench tool
           such as "Hot Metal 1", "Greyscale 1"
    contourImage: overlay another image with contours (relative values)
    levels: numeric vector, e.g. [3,4,5]
    unit: of contours, i.e. sets the value of "one" in the relative levels
    base: of contours, i.e. sets the value of "zero" in the relative levels
    dpi: only relevant for .ps or .eps (see 'scale' for others)
    contourColor: available in CASA 4.6 > r35896
    ellipse: parameters of an ellipse to overlay [x,y,majoraxis,minoraxis,paDegrees] 
          using contourColor.  If the first 4 values are numeric, then are treated as
          pixels; if strings, then they are treated as RA/Dec sexagesimal and arcsec.
    ellipseLevel: in units of fraction of the peak
    pathToConvert: the path to ImageMagick convert (if necessary)
    scaling: use negative values to bring out faint features (-1, -2, etc.)
    orientation: only relevant for .ps/eps images, 'portrait' or 'landscape'
    scale: only relevant for non-.ps/eps images to set size/resolution of non-ps/eps images
           1 --> 72 dpi, 2 --> 144 dpi, etc.
    axes: 'auto' or a dictionary like:
          {'x':'Right Ascension', 'y':'Declination'}
          'auto' will set RA, Dec if both are present, or Frequency, Offset
                if both are present; otherwise will use first 2 axes.
    Returns:
    the name of the png file produced
    -Todd Hunter
    """
    img = img.rstrip('/')
    if (os.path.exists(img) == False):
        print "Could not find image = ", img
        return
    if scaling != 0 and casaVersionCompare('<','5.3.0-95'):
        print "Warning: the scaling parameter does not work in imview, see CAS-6081 and 6425."
    if (frequency is not None):
        if (frequency < 2000):
            frequencyGHz = frequency
        else:
            frequencyGHz = frequency*1e-9
    if verbose:
        print "Running pickIntensityRange('%s')" % (img) 
    myrange = pickIntensityRange(img, maxIntensity, minIntensity, 
                                 maxIntensityFraction, 
                                 minIntensityFraction, maxIntensityMinFraction)
    if levels is None and contourImage is not None:
        levels = np.array([0.2,0.4,0.6,0.8]) * imagePeak(contourImage)
    if levels2 is None and contourImage2 is not None:
        levels2 = np.array([0.2,0.4,0.6,0.8]) * imagePeak(contourImage2)
    if verbose: print "myrange = ", myrange
    mydict = getFitsBeam(img, warnNoBeam=False)
    arcsecPerPixel = abs(mydict[3])
    if verbose:
        print "arcsec per pixel = ", arcsecPerPixel
    if (frequency is not None):
        imgFrequencyGHz = mydict[7]
        scaleFactor = frequencyGHz / imgFrequencyGHz
        print "Scaling radius down by %f" % (scaleFactor)
        radius *= scaleFactor
    # find number of pixels in each of the requested axes
    if axes == 'auto':
        myia = iatool()
        myia.open(img)
        names = [name.lower() for name in myia.summary()['axisnames']]
        myia.close()
        if 'offset' in names and 'frequency' in names:
            axes = {'x': 'Frequency', 'y': 'Offset'}
        elif 'declination' in names and 'right ascension' in names:
            axes = {'x': 'Right Ascension', 'y': 'Declination'}
        else:
            axes = {'x': names[0], 'y': names[1]}
    if axes['x'].lower() in ['right ascension','declination','offset']:
        naxis1 = findOffsetAxis(img, axes['x'], returnLength=True)
    elif axes['x'].lower() in ['frequency']:
        naxis1 = findSpectralAxis(img, axes['x'], returnLength=True)
    else:
        print "Unrecognized x axis"
        return
    if axes['y'].lower() in ['right ascension','declination','offset']:
        naxis2 = findOffsetAxis(img, axes['y'], returnLength=True)
    elif axes['y'].lower() in ['frequency']:
        naxis2 = findSpectralAxis(img, axes['y'], returnLength=True)
    else:
        print "Unrecognized y axis"
        return
    contour = []
    if (len(ellipse) > 0):
        peak = 1.0
        x, y, major, minor, pa = ellipse
        if (type(x) == str):
            x, y = findRADec(img, radec=x+' '+y)
        if (type(major) == str or type(minor) == str):
            print "type(major) = ", type(major), major
            cdelt1 = imhead(img, mode='get', hdkey='cdelt1')
            print "x=%f, y=%f, cdelt1=%f %s" % (x,y,cdelt1['value'],cdelt1['unit'])
            cdelt1 = cdelt1['value']
            if (cdelt1['unit']=='rad'): 
                cdelt1 *= np.degrees(1)*3600
            elif (cdelt1['unit']=='deg'): 
                cdelt1 *= 3600
        if (type(major) == str):
            major = float(major)/cdelt1
            print "Setting major axis to %f pixels" % major
        if (type(minor) == str):
            minor = float(minor)/cdelt1
            print "Setting minor axis to %f pixels" % minor
        gimg = makeGaussianForImage(img, peak, x, y, major, minor, pa)
        if (contourImage is None):
            if (casadef.subversion_revision > '37134'):
                contour.append({'file':gimg, 'levels': [ellipseLevel], 'unit':1.0,
                            'color':contourColor, 'base':0.0, 
                            'thickness': float(contourThickness)})
            else:
                contour.append({'file':gimg, 'levels': [ellipseLevel], 'unit':1.0,
                            'color':contourColor, 'base':0.0})
        else:
            if (casadef.subversion_revision > '37134'):
                contour.append({'file':gimg, 'levels': [ellipseLevel], 'unit':1.0,
                                'color':contourColor2, 'base':0.0, 
                                'thickness': float(contourThickness2)})
            else:
                contour.append({'file':gimg, 'levels': [ellipseLevel], 'unit':1.0,
                                'color':contourColor2, 'base':0.0})
    if (xcenter == None):
        xcenter = (naxis1-1)/2.0
        if (ycenter == None):
            ycenter = (naxis2-1)/2.0
    elif (xcenter == 'ellipse'):
        if len(ellipse)>0:
            xcenter = x
            ycenter = y
        else:
            print "No ellipse center specified"
            return
    elif (type(xcenter) == str and type(ycenter)==str):
        xcenter, ycenter = findRADec(img, ','.join([xcenter,ycenter]))
        print "Converted RA/Dec to pixel=%f,%f" % (xcenter,ycenter)
    if radius > 0:
        blcx = xcenter - radius/arcsecPerPixel
        blc = [float(xcenter - radius/arcsecPerPixel), float(ycenter - radius/arcsecPerPixel)]
        trc = [float(xcenter + radius/arcsecPerPixel), float(ycenter + radius/arcsecPerPixel)]
    else:
        blc = [0,0]
        trc = [int(naxis1-1), int(naxis2-1)]
    if (plotfile is None or plotfile == True):
        plotfile = img + '.imview.png'
    colormap = colormap.replace('Gray','Grey') # allow alternate spelling
    if (casadef.subversion_revision > '37134'):
        if (contourImage is not None and contourImage != '' and contourImage != False):
            contour.append({'file':contourImage, 'levels': levels, 'unit':unit,
                            'color':contourColor, 'base':base, 'thickness': float(contourThickness)})
    else:
        if (contourImage is not None and contourImage != '' and contourImage != False):
            contour.append({'file':contourImage, 'levels': levels, 'unit':unit,
                                'color':contourColor, 'base':base})
    if (casadef.subversion_revision > '37134'):
        if (contourImage2 is not None and contourImage2 != '' and contourImage2 != False):
            contour.append({'file':contourImage2, 'levels': levels2, 'unit':unit2,
                            'color':contourColor2, 'base':base2, 'thickness': float(contourThickness)})
    else:
        if (contourImage2 is not None and contourImage2 != '' and contourImage2 != False):
            contour.append({'file':contourImage2, 'levels': levels2, 'unit':unit2,
                            'color':contourColor2, 'base':base2})
    if casaVersionCompare('>=','5.3.0-94'):
        if verbose:
            print "Running imview(raster=[{'file':'%s', 'colorwedge': %s, 'range': %s, 'colormap':'%s', 'scaling':%f}], contour=%s, zoom={'coord':'pixel', 'blc':%s,'trc':%s, 'channel':%d}, axes=%s, out={file:'%s', 'dpi':%d, 'scale':%f, 'orient':%s})" % (img, colorwedge, str(myrange), colormap, scaling, contour, str(blc), str(trc), channel, axes, plotfile, dpi, scale, orientation)
        imview(raster=[{'file':img,'colorwedge':colorwedge, 'range':myrange, 'colormap':colormap, 'scaling':scaling}],
               contour=contour, axes=axes,
               zoom={'coord':'pixel','blc':blc,'trc':trc, 'channel': channel},
               out={'file':plotfile, 'dpi':dpi, 'scale':scale, 'orient':orientation})  # now works since CAS-6521
    else:
        if verbose:
            print "Running imview(raster=[{'file':'%s', 'colorwedge': %s, 'range': %s, 'colormap':'%s', 'scaling':%f}], contour=%s, zoom={'coord':'pixel', 'blc':%s,'trc':%s, 'channel':%d}, axes=%s, out='%s')" % (img, colorwedge, str(myrange), colormap, scaling, contour, str(blc), str(trc), channel, axes, plotfile)
        if scale != 1:
            print "The scale parameter (only relevant for non-ps/eps files) does not work in this old of a version of CASA."
        if orientation != 'landscape':
            print "The orientation parameter (only relevant for ps/eps files) does not work in this old of a version of CASA."
        if dpi != 300:
            print "The dpi parameter (only relevant for ps/eps files) does not work in this old of a version of CASA."
        imview(raster=[{'file':img,'colorwedge':colorwedge, 'range':myrange, 'colormap':colormap, 'scaling':scaling}],
               contour=contour, axes=axes,
               zoom={'coord':'pixel','blc':blc,'trc':trc, 'channel': channel},
               out=plotfile)
    if (trim and plotfile is not None and plotfile != ''):
        if (len(pathToConvert) > 0):
            if (pathToConvert[-1] != '/'):
                pathToConvert += '/'
        cmd = '%sconvert -trim %s %s' % (pathToConvert,plotfile,plotfile)
        if verbose:
            print "Running: ", cmd
        os.system(cmd)
    return(plotfile)
 
def setBeam(img, major='', minor='', pa='0.0deg', fromimg='', setBunit=False):
    """
    Sets the restoring beam in a CASA image using the ia tool.
    major: string with units, e.g. '4.5arcsec', or a floating point value in arcsec
    minor: string with units, e.g. '4.5arcsec', or a floating point value in arcsec
    pa:    string with units, e.g. '32.1deg', or a floating point value in degree
    setBunit: if True and fromimg specified, then also copy the bunit from FITS or CASA image
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image = ", img
        return
    if (major == '' and minor == '' and fromimg == ''):
        print "Must set either fromimg or major,minor,pa"
        return
    if type(pa) != str:
        pa = str(pa) + 'deg'
    if (major == '' and minor == ''):
        result = getFitsBeam(fromimg)
        major = '%farcsec' % (result[0])
        minor = '%farcsec' % (result[1])
        pa = '%fdeg' % (result[2])
        print "Setting beam to %s x %s at %s" % (major, minor, pa)
    if (major != '' and minor == ''):
        minor = major
    if type(major) != str:
        major = str(major) + 'arcsec'
    if type(minor) != str:
        minor = str(minor) + 'arcsec'
    myia = createCasaTool(iatool)
    myia.open(img)
    myia.setrestoringbeam(major=major, minor=minor, pa=pa)
    myia.close()
    if setBunit and fromimg != '':
        bunit = imhead(fromimg, mode='get', hdkey='bunit')
        imhead(img, mode='put', hdkey='bunit', hdvalue=bunit)

def summarizeImfitResults(myImfitResults, mydict, img, replaceUncertaintiesWithMAD=True):
    """
    Takes a dictionary of accumulated imfit results, and the most recent imfit result,
    computes the median and MAD of each of the 6 parameters for each component, and  places
    them into the dictionary of the most recent imfit result so that it can be displayed
    elsewhere.
    returns: nothing
    -Todd Hunter
    """
    ncomponents = mydict['results']['nelements']
    token = getFitsBeam(img) #, omitBeam=True)
    bmaj, bmin, bpa, cdelt1, cdelt2, naxis1, naxis2, frequency = getFitsBeam(img)
    for comp in range(ncomponents):
#        print "Computing over %d values: %s, median=%f MAD=%g" % (len(myImfitResults[comp]['f']), 
#                                                                  str(myImfitResults[comp]['f']),
#                                                                  np.median(myImfitResults[comp]['f']), 
#                                                                  MAD(myImfitResults[comp]['f']))
        mydict['results']['component%d'%comp]['peak']['value'] = np.median(myImfitResults[comp]['f'])
        mydict['results']['component%d'%comp]['shape']['majoraxis']['value'] = np.median(myImfitResults[comp]['a'])
        mydict['results']['component%d'%comp]['shape']['minoraxis']['value'] = np.median(myImfitResults[comp]['b'])
        mydict['results']['component%d'%comp]['shape']['positionangle']['value'] = np.median(myImfitResults[comp]['p'])
        mydict['results']['component%d'%comp]['flux']['value'] = [np.median(myImfitResults[comp]['flux']),0,0,0]
        ra,dec = findPixel(img,pixel=[np.median(myImfitResults[comp]['x']), np.median(myImfitResults[comp]['y'])], 
                           format='radians', verbose=False) 
        mydict['results']['component%d'%comp]['shape']['direction']['m0']['value'] = ra
        mydict['results']['component%d'%comp]['shape']['direction']['m1']['value'] = dec
        if replaceUncertaintiesWithMAD:
            mydict['results']['component%d'%comp]['peak']['error'] = MAD(myImfitResults[comp]['f'])
            mydict['results']['component%d'%comp]['shape']['majoraxiserror']['value'] = MAD(myImfitResults[comp]['a'])
            mydict['results']['component%d'%comp]['shape']['minoraxiserror']['value'] = MAD(myImfitResults[comp]['b'])
            mydict['results']['component%d'%comp]['shape']['positionangleerror']['value'] = MAD(myImfitResults[comp]['p'])
            mydict['results']['component%d'%comp]['flux']['error'] = [MAD(myImfitResults[comp]['flux']),0,0,0]
            mydict['results']['component%d'%comp]['shape']['direction']['error']['latitude']['value'] = MAD(myImfitResults[comp]['x'])*abs(cdelt1)
            mydict['results']['component%d'%comp]['shape']['direction']['error']['longitude']['value'] = MAD(myImfitResults[comp]['y'])*cdelt2
    # end 'for' loop over components
    if (len(myImfitResults['percentageFluxRecovered']) > 0):
        mydict['percentageFluxRecovered'] = np.median(myImfitResults['percentageFluxRecovered'])
        mydict['percentageFluxRecoveredMAD'] = MAD(myImfitResults['percentageFluxRecovered'])
        print "Percentage flux recovered: median=%f  MAD=%f" % (mydict['percentageFluxRecovered'], mydict['percentageFluxRecoveredMAD'])
    mydict['iterationsCompleted'] = len(myImfitResults[0]['f'])

def accumulateImfitResults(myImfitResults, mydict, img):
    """
    Takes an imfit multi-component fit result dictionary and appends the parameters and 
    uncertainties into a larger dictionary keyed by the component number for eventual
    statistical analysis (in summarizeImfitResults).
    -Todd Hunter
    """
    ncomponents = mydict['results']['nelements']
    for comp in range(ncomponents):
        if (comp not in myImfitResults.keys()):
            # initialize
            myImfitResults[comp] = {}
            myImfitResults['percentageFluxRecovered'] = []
        for parameter in ['f','x','y','a','b','p','flux']:
            if parameter not in myImfitResults[comp].keys():
                myImfitResults[comp][parameter] = []
        pixel = findRADec(img,[mydict['results']['component%d'%comp]['shape']['direction']['m0']['value'],
                               mydict['results']['component%d'%comp]['shape']['direction']['m1']['value']])
        if pixel == None: return None
        myImfitResults[comp]['f'].append(mydict['results']['component%d'%comp]['peak']['value'])
        myImfitResults[comp]['x'].append(pixel[0])
        myImfitResults[comp]['y'].append(pixel[1])
        myImfitResults[comp]['a'].append(mydict['results']['component%d'%comp]['shape']['majoraxis']['value'])
        myImfitResults[comp]['b'].append(mydict['results']['component%d'%comp]['shape']['minoraxis']['value'])
        myImfitResults[comp]['p'].append(mydict['results']['component%d'%comp]['shape']['positionangle']['value'])
        myImfitResults[comp]['flux'].append(mydict['results']['component%d'%comp]['flux']['value'][0])
    if ('percentageFluxRecovered' in mydict.keys()):
        myImfitResults['percentageFluxRecovered'].append(mydict['percentageFluxRecovered'])
    return myImfitResults

def getImfitEstimatesFixedString(estimates):
    """
    Reads an imfit estimates file, and returns a list of strings containing the fixed 
    parameter setting (i.e. the indicator at the end of the line)
    -Todd Hunter
    """
    f = open(estimates,'r')
    lines = f.readlines()
    f.close()
    values = []
    for line in lines:
        if (line[0] == '#'): continue
        token = line.split(',')
        if (len(token) > 6):
            values.append(token[6].rstrip('\n'))
        else:
            values.append('')
    return(values)

def getImfitEstimatesString(estimates):
    """
    Reads an imfit estimates file, and returns a list of strings, one per line, ignoring
    lines starting with a comment character.
    -Todd Hunter
    """
    f = open(estimates,'r')
    lines = f.readlines()
    f.close()
    values = []
    for line in lines:
        if (line[0] == '#'): continue
        values.append(line)
    return(values)

def updateImfitEstimates(estimates, logfile, new_estimates='', allParameters=False):
    """
    Modifies an existing text file containing imfit estimates with the values from
    the specified imfit-produced logfile for peak, x, and y.
    estimates: filename containing imfit estimates; to create one, use 'create'
    logfile: written by the CASA imfit task
    new_estimates: new filename to produce (default=overwrite existing file)
    allParameters: if True, update all parameters
    """
    if (not os.path.exists(estimates)):
        if estimates == 'create':
            estimates = 'estimates.txt'
            f = open(estimates,'w')
            f.write('1 10 10 1 1 90\n')
            f.close()
        else:
            print "Could not find estimates file = ", estimates
            return
    allLines = getImfitEstimatesString(estimates)
    newValues = parseImfitLogfile(logfile)
    if len(allLines) != len(newValues):
        print "Number of components differ: estimatesFile=%d vs. logfile=%d" % (len(allLines), len(newValues))
        return
    if new_estimates == '':
        new_estimates = estimates + '.new'
    o = open(new_estimates,'w')
    for i,line in enumerate(allLines):
        token = line.split()
        print "len(token) = ", len(token)
        token[0] = str(newValues[i][0])
        token[1] = str(newValues[i][1])
        token[2] = str(newValues[i][2])
        if allParameters:
            token[3] = str(newValues[i][3])+'arcsec'
            token[4] = str(newValues[i][4])+'arcsec'
            token[5] = str(newValues[i][5])+'deg'
        newline = ', '.join(token)
        o.write(newline)
    o.close()
    print "Wrote ", new_estimates

def modifyImfitEstimates(estimates, sourceNumber=1, fixed=None, xy=[], new_estimates='', 
                         ab=[], pa=None, sigma=None, pixelsPerArcsec=1, 
                         writePercentageFile=False, keepfixed=''):
    """
    Modifies an existing text file containing imfit estimates with new specified values.
    estimates: filename
    new_estimates: new filename to produce (default=overwrite existing file)
    sourceNumber: the source number to modify (first = 1); -1 means all
    fixed: if not None, then replace the fixed parameter with this string
    xy: if not empty list, then replace the peak pixel with this pixel
    ab: if not empty list, then replace the major,minor axis with this value (arcsec)
    pa: if not None, then replace the position angle with this value (degrees)
    sigma: if not None, then apply random variations to each parameter of each source
    writePercentageFile: if True, and sigma is set, then write a second file indicating
       the percentage change of each parameter, called <new_estimates>.percentage
    keepfixed: if set to a file, and fixed==None, then copy the fixed string for the
       specified component (or all if sourceNumber==-1) from that file to the output file
    -Todd Hunter
    """
    if (not os.path.exists(estimates)):
        print "Could not find estimates file = ", estimates
        return
    if sourceNumber < 1 and sourceNumber != -1:
        print "Source numbers must start at 1."
        return
    if (keepfixed != ''):
        keepFixedStrings = getImfitEstimatesFixedString(keepfixed)
    f = open(estimates,'r')
    lines = f.readlines()
    f.close()
    if (new_estimates == ''):
        new_estimates = estimates
        print "modifyImfitEstimates(): Overwriting existing file: ", new_estimates
    o = open(new_estimates,'w')
    if (writePercentageFile):
        pf = open(new_estimates+'.percentage','w')
    i = 0
    for line in lines:
        if (line[0] == '#'):
            o.write(line)
        else:
            i += 1
            if (sigma is not None):
                token = line.rstrip('\n').split(',')
                peak = float(token[0]); x=float(token[1]); y=float(token[2])
                a = float(token[3].replace('arcsec','')); b=float(token[4].replace('arcsec','')) 
                pa = float(token[5].replace('deg',''))
                # perturbed value:  peak + randomValue*sigma*peak = peak * (1+randomValue*sigma)
                finished = False
                while (not finished):
                    newpeak = peak*(1+pickRandomError()*sigma)
                    finished = newpeak > 0
                finished = False
                while (not finished):
                    newmajor = a * (1+pickRandomError()*sigma)
                    newminor = b * (1+pickRandomError()*sigma)
                    finished = newmajor >= newminor and newmajor>0 and newminor>0
                newpa = pa+180*sigma*pickRandomError()
                newpa = newpa % 360.0
                newx = x+pickRandomError()*a*pixelsPerArcsec
                newy = y+pickRandomError()*a*pixelsPerArcsec
                newline = '%f, %f, %f, %farcsec, %farcsec, %fdeg' % (newpeak,
                          newx, newy, newmajor, newminor, newpa)
                if (len(token) > 6):
                    newline += ', ' + token[6]
                o.write(newline+'\n')
                if writePercentageFile:
                    newline = '%.2f, %.2f, %.2f, %.2f, %.2f, %.2f' % (100*(newpeak-peak)/peak,
                          100*(newx-x)/x, 100*(newy-y)/y, 100*(newmajor-a)/a, 100*(newminor-b)/b, ((newpa-pa)%360)/180.)
                    pf.write(newline+'\n')
            elif (sourceNumber == i or sourceNumber < 0):
                token = line.rstrip('\n').split(',')
                if (len(xy) > 0):
                    o.write('%s, %f, %f,' % (token[0],xy[0],xy[1]))
                else:
                    o.write('%s, %s, %s,' % (token[0],token[1],token[2]))
                if (len(ab) > 0):
                    o.write(' %farcsec, %farcsec,' % (ab[0],ab[1]))
                else:
                    o.write(' %s, %s,' % (token[3],token[4]))
                if (pa is not None):
                    o.write(' %fdeg' % (pa))
                else:
                    o.write(' %s' % (token[5]))
                if (fixed == None):
                    if (keepfixed != ''):
                        o.write(', %s' % keepFixedStrings[i-1])
                    elif (len(token) > 6):
                        # Keep the previous fixed string
                        o.write(', %s' % token[6])
                else:
                    o.write(', %s' % fixed)
                o.write('\n')
            else:
                o.write(line)
    o.close()
    if (writePercentageFile):
        pf.close()
    return

def recoverImfitEstimates(timestamp='2017-10-25 20:15:33', casalogfile='', 
                          outfile='estimates.txt'):
    """
    Recovers the imfit estimates file used at a specified timestamp in the
    CASA log.
    Todd Hunter
    """
    if casalogfile == '':
        casalogfile = casalog.logfile()
        print "Using current casa log file: ", casalogfile
    f = open(casalogfile,'r')
    lines = f.readlines()
    f.close()
    o = open(outfile,'w')
    readingEstimates = False
    estimates = []
    for line in lines:
        if line.find(timestamp) >= 0 or readingEstimates:
            if line.find('initial estimates') > 0:
                print "Found start of initial estimates"
                readingEstimates = True
                continue
            if readingEstimates:
                if line.find('iterations') > 0:
                    break
                estimates.append(' '.join(line.split()[4:]) + '\n')
                o.write(estimates[-1])
    o.close()
    print "Wrote %d estimates to %s" % (len(estimates),outfile)

def imfitplot(img, region='', residual=None, model=None, logfile=None,
              colorwedge=True, pngname=None, rms=None, startSigma=3.0,
              subimage=None, includepix=[], excludepix=[], box='',
              verbose=False, estimates='', pixrange = None, sidebyside=True,
              chans='', vis='', field='', dooff=False, newestimates='', 
              levels='', base=0, unit=1, compareCoordinates=['dummy'],
              generateExtraModelAndResidual=[], clipThreshold=None,
              geometry=None, backgroundImage='', contourColor='yellow',
              contourThickness=2, extraSuffix='', niter=1,
              sigma=0.25, allowNegativeFlux=False, deconvolved=False,
              contourColorDeconvolved='cyan', drawModelOnDataSubimage=True,
              fix={}, cleanup=True, writeEstimatesFile=False, writeCLB=True,
              output='', addLabel=False, pointsize=9):
    """
    Calls the casa task imfit, then plots the subimage, model, and residual 
    images on a 2x2 grid on the same color scale.
       subimage(sameScale)   model(sameScale)
       residual(sameScale)   residual(autoScale)
    Inputs:
    img: The image to fit
    region: 'auto' or any other string is passed to imfit
       e.g. 'box [[17:20:56.67557, -035.45.10.5642],[17:20:56.59472, -035.45.09.0259]] coord=J2000'
            'auto' will define a circle at the image peak of radius 5*beamsize
    box: passed to imfit   e.g. '100, 120, 200, 220'
    residual: The name to call the residual image; default=<img>.residual
    model: The name to call the model image; default=<img>.model
    logfile: The name to call the log file (passed to imfit).
    colorwedge: whether to include a color wedge in the plot
    pngname: The name to call the 3-panel png; default=<img>.imfit.png
    rms: The rms value to use in contouring the residual image (default=10% of peak)
    startSigma: where to start the +- contour levels on the residual
    subimage: The name to call the data subimage.
    includepix, excludepix, box, estimates: passed to imfit
    verbose: if True, then print the commands as they are executed
    pixrange: the intensity range to display in image brightness units, e.g. [0,10.0]
    chans: channel number string passed to imfit and imsubimage
    vis: if specified, compare fitted peak pos with field pos in this ms
    field: use with the 'vis' parameter
    dooff: passed to imfit
    estimates, newestimates: passed to imfit
    writeEstimatesFile: after doing the fit, create an estimates file for future use
    levels: contour levels passed to imview for the residual image
    base, unit: passed to imview
    compareCoordinates: list of RA/Dec values to compare to.  The first entry must
       be a dummy value in order that a source A is the second entry in list, i.e. [1].
    generateExtraModelAndResidual: True, or a list of components; if specified, then also generate a second model
       and residual optionally using only the numbered model components, e.g. [1,3,4].  This
       allows you to see if the remaining residual is point-like or double, etc.
       Values start at 1, not zero.
    extraSuffix: used to name the extra produces when generateExtraModelAndResidual is set
    geometry: passed to montagePngs
    backgroundImage: if specified, add this image to the model and img and create
       a second pair of 3-panel pngs (this image must be same geometry as img)
    contourColor: for the single component contours on the extra plot
       (Note: must use full names like 'black', not matplotlib shortform 'k')
    contourThickness: for the single component contours on the extra plot
    deconvolved: if True, then also overlay the deconvolved size in contours
    contourColorDeconvolved: for the deconvolved size of the component
    niter: number of fit iterations to run, adding random errors to each parameter
    sigma: used for niter>1 as the 1-sigma perturbation applied to each parameter
    allowNegativeFlux: used only when niter>1; declares fit as failure if any component<0
    fix: if estimates=='', then fix this parameter ('x','y','major','minor','pa','peak')
           units are pixels, pixels, arcsec, arcsec, deg, Jy
    cleanup: if True, then remove the images after montagePngs completes
    writeCLB: if True, then write a text file using imfitparseCLB with the same
              base name as the model image. One line version of the file written
              by writeImfitDictToFile
    output: name of text file for writeCLB to generate
    addLabel: if True, and writeCLB=True, then print fit result text at top of image
    pointsize: used for addLabel
    Returns:
    a dictionary of the imfit results; if niter>1, this contains the median and MAD (as
       the uncertainty) of the fitted parameters
    -Todd Hunter
    """
    img = img.rstrip('/')
    if (residual == None or residual == ''):
        residual = os.path.basename(img) + '.residual'
    if (model == None or model == ''):
        model = os.path.basename(img) + '.model'
    if (subimage == None or subimage == ''):
        subimage = os.path.basename(img) + '.subimage'
        removeImageIfPresent(subimage)
    if (logfile == None):
        logfile = os.path.basename(img) + '.imfit.log'
    removeImageIfPresent(residual)
    removeImageIfPresent(model)
    removeImageIfPresent(logfile)
    if (useImsubimage == False):
        print "This version of CASA is too old to have imsubimage."
        return
    if type(generateExtraModelAndResidual) == list:
        if (len(generateExtraModelAndResidual) > 0):
            if (0 in generateExtraModelAndResidual):
                print "generateExtraModelAndResidual should not have 0 as a value.  Components start at 1."
                return
    result = getFitsBeam(img)
    pixelsPerArcsec = 1.0/result[4]
    if (region=='auto'):
        if verbose:
            print "Running imagePeak('%s', returnPosition='radec_hms', delimiter=',')" % (img)
        peak, position = imagePeak(img, returnPosition='radec_hms', delimiter=',')
        radius = 5*result[0]
        region = 'circle [[%s], %farcsec]' % (position, radius)
        print "Using region = ", region
    if (not os.path.exists(subimage)):
        if (verbose):
            print "Running imsubimage('%s',region='%s',outfile='%s',box='%s')" % (img,region,subimage,box)
        imsubimage(img, region=region, outfile=subimage, box=box, chans=chans)
    if (clipThreshold is not None):
        imageClipAndRemove(subimage, threshold, subimage+'.clippedAndRemoved')
        removeImageIfPresent(subimage)
        os.rename(subimage+'.clippedAndRemoved', subimage)
    if (estimates != ''):
        if (not os.path.exists(estimates)):
            print "estimates file does not exist."
            return
    elif (niter > 1):
        print "You cannot use niter>1 without providing an estimates file"
        return
    else:
        if len(fix.keys()) > 0:
            # write an estimates file
            estimates = img + '.estimates'
            # peak intensity, peak x-pixel value, peak y-pixel value, major axis, minor axis, position angle, fixed
            f = open(estimates,'w')
            fixed = ''
            mybox = [int(i) for i in box.split(',')]
            if 'peak' in fix.keys():
                fixed += 'f'
                peak = fix['peak']
            else:
                peak = 1
            if 'x' in fix.keys():
                fixed += 'x'
                x = fix['x']
            else:
                x = (mybox[0]+mybox[2])/2
            if 'y' in fix.keys():
                fixed += 'y'
                y = fix['y']
            else:
                y = (mybox[1]+mybox[3])/2
            if 'major' in fix.keys():
                fixed += 'a'
                major = fix['major']
            else:
                major = 3/pixelsPerArcsec
            if 'minor' in fix.keys():
                fixed += 'b'
                minor = fix['minor']
                if major < minor:
                    major = minor
            else:
                minor = 3/pixelsPerArcsec
            if 'pa' in fix.keys():
                fixed += 'p'
                pa = fix['pa']
            else:
                pa = 0
            f.write('# file auto-generated by au.imfitplot(fix=%s)\n' % (str(fix)))
            f.write('%f, %d, %d, %.4farcsec, %.4farcsec, %.2fdeg, %s\n' % (peak,x,y,major,minor,pa,fixed))
            f.close()
    if (verbose or True):
        print "Running imfit('%s',region='%s',estimates='%s',box='%s', residual='%s', dooff=%s)" % (img,region,estimates,box,residual,dooff)
    my_estimates = estimates
    myImfitResults = {}
    failures = 0
    i = 0
    lowestRmsResidual = 1e10
    while (i < niter):
        mydict = imfit(img, region=region, residual=residual, logfile=logfile, 
                       model=model, excludepix=excludepix, includepix=includepix, 
                       box=box, estimates=my_estimates, chans=chans, dooff=dooff,
                       newestimates=newestimates)
        i += 1
        if (niter > 1):
            failure = False
            if (mydict == None):
                i -= 1
                failures += 1
                failure = True
            elif (mydict['results']['nelements'] == 0):
                i -= 1
                failures += 1
                failure = True
            else:
                tentativeResult = writeImfitDictToFile(mydict, img, estimates, verbose=False, append= i>1, 
                                     outfile=img+'_'+estimates+'.random', niter=i, deconvolved=deconvolved,
                                     returnInfoOnResidual=residual, box=box, region=region,
                                     compareCoordinates=compareCoordinates, my_estimates=my_estimates,
                                     model=model)
                if tentativeResult == None:
                    # This failure is from imfitparse() "RA coordinate is not within image"
                    i -= 1
                    failures += 1
                    failure = True
                else:
                    components,negativeComponents,percentageFluxRecovered,rmsResidual = tentativeResult
                    if ((not allowNegativeFlux) and (negativeComponents > 0)):
                        print "Declaring failure due to %d negative components" % (negativeComponents)
                        i -= 1
                        failures += 1
                        failure = True
                    else:
                        mydict['percentageFluxRecovered'] = percentageFluxRecovered
                        tentativeResult = accumulateImfitResults(myImfitResults, mydict, img)
                        if tentativeResult == None:
                            # This is a failure of findRADec
                            i -= 1
                            failures += 1
                            failure = True
                        else:
                            myImfitResults = tentativeResult
                            if (rmsResidual < lowestRmsResidual):
                                print "Found new best residual: %f (negativeComponents=%d)" % (rmsResidual,negativeComponents)
                                writeImfitDictToFile(mydict, img, estimates, verbose=False, append=False, 
                                         outfile=img+'_'+estimates+'.lowestRmsResidual', niter=i, deconvolved=deconvolved,
                                         returnInfoOnResidual=residual, box=box, region=region,
                                                     compareCoordinates=compareCoordinates, my_estimates=my_estimates,
                                                     model=model)
                            
            print "Completed %d/%d iterations with %d failures" % (i,niter,failures)
            if (i > 1):
                if (not failure):
                    print "Taking median of %d results" % (len(myImfitResults[0]['f']))
                    runningDict = copy.deepcopy(mydict)
                    summarizeImfitResults(myImfitResults, runningDict, img)  
                    components, negativeComponents, percentageFluxRecovered, rmsResidual = \
                        writeImfitDictToFile(runningDict, img, estimates, verbose=True, deconvolved=deconvolved,
                                             returnInfoOnResidual=residual, box=box,region=region,
                                             compareCoordinates=compareCoordinates,model=model)
                else:
                    if (not os.path.exists('failures')):
                        os.mkdir('failures')
                    shutil.copyfile(my_estimates, 'failures/'+my_estimates+'.failure%03d' % failures)
            if i<niter:
                # Setup for next iteration
                my_estimates = estimates+'.random'
                modifyImfitEstimates(estimates, sigma=sigma, new_estimates=my_estimates, 
                                     pixelsPerArcsec=pixelsPerArcsec, writePercentageFile=True)
                shutil.copyfile(my_estimates, my_estimates+str(i))
                shutil.copyfile(my_estimates+'.percentage', my_estimates+'.percentage.'+str(i))
        # end 'if' niter>1
    # end 'while' loop over iterations
    if (niter > 1):
        print "Taking median of %d results" % (len(myImfitResults[0]['f']))
        summarizeImfitResults(myImfitResults, mydict, img)  
    residualSubimage = residual + '.subimage' + chans
    modelSubimage = model + '.subimage' + chans
    removeImageIfPresent(residualSubimage)
    if (verbose):
        print "Running residual imsubimage('%s', outfile='%s')" % (residual,residualSubimage)
    imsubimage(residual, region=region, outfile=residualSubimage, box=box, chans=chans)
    removeImageIfPresent(modelSubimage)
    if (verbose):
        print "Running model imsubimage(%s,outfile='%s')" % (model,modelSubimage)
    imsubimage(model, region=region, outfile=modelSubimage, box=box, chans=chans)
    if (verbose):
        print "Running model imstat(%s)" % img
    myimstat = imstat(img, region=region, chans=chans, box=box)
    pixrangeSpecified = True
    if (pixrange == None):
        pixrangeSpecified = False
        pixrange = [float(myimstat['min'][0]), float(myimstat['max'][0])]
        if (pixrange[0] > 0):
            pixrange[0] = 0
    if (verbose):
        print "Running residual imstat('%s')" % (residual)
    stats = imstat(residual)
    if (verbose):
        print stats
    mymax = float(stats['max'][0])
    mymin = float(stats['min'][0])
    levelsSpecified = True
    if (levels == ''):
        levelsSpecified = False
        if (rms == None):
            rms = imageStd(img)
        levels = np.arange(startSigma*rms, mymax, startSigma*rms, dtype=float)
        nlevels = np.arange(-startSigma*rms, mymin, -rms*startSigma, dtype=float)
        if (verbose):
            print "levels=%s, nlevels=%s" % (str(levels), str(nlevels))
        levels = list(levels) + list(nlevels)
        levels = [float(a) for a in levels]
    else:
        # prevent tiny negative contour from being dashed
        levels = [round(a,10) for a in levels]
    if levelsSpecified:
        contourModel = [{'file':modelSubimage, 'levels': list(levels), 'color':'black', 'base':base, 'unit':unit}]
        contourSubimage = [{'file':subimage, 'levels': list(levels), 'color':'black', 'base':base, 'unit':unit}]
        contourSubimageWithModel = contourSubimage
    else:
        contourModel = []
        contourSubimage = []
        contourSubimageWithModel = []

    if (verbose):
        print "running imview(raster={'file':'%s', 'colorwedge':%s}, zoom=1, out='%s.png', contour=%s)" % (subimage,colorwedge,model,contourSubimage)
    imview(raster={'file':subimage, 'range':pixrange, 'colorwedge':colorwedge}, contour=contourSubimage,
           zoom=1, out=subimage+'.png')
    if (not mydict['converged'][0]):
        return(mydict)

    if (verbose):
        print "running imview(raster={'file':'%s', 'colorwedge':%s}, zoom=1, out='%s.png', contour=%s)" % (modelSubimage,colorwedge,model,contourModel)
    imview(raster = {'file':modelSubimage, 'range':pixrange, 'colorwedge':colorwedge}, contour=contourModel,
           zoom=1, out=modelSubimage+'.png')
    if (verbose):
        print "running imview(raster={'file':'%s', 'range':%s, 'colorwedge':%s}, zoom=1,out='%s.png', contour={'levels':%s})" % (residualSubimage,pixrange,colorwedge,residualSubimage,str(levels))
    pixrangeResidual = [imageMin(residualSubimage),pixrange[1]]
    imview(raster = {'file':residualSubimage, 'range':pixrangeResidual, 'colorwedge':colorwedge},
           zoom = 1, out = residualSubimage + '.png', contour={'file':residual, 'levels': levels, 'base':base, 'unit':unit})
    imview(raster = {'file':residualSubimage, 'colorwedge':colorwedge},
           zoom = 1, out = residualSubimage + '_autoscale.png')
    if (verbose):
        print "Running montagePngs"
    if (pngname == None or pngname == ''):
        pngname = os.path.basename(img)+'.imfit.png'
    if writeCLB:
        if output == '':
            output = model + '.imfitparseCLB'
        imfitparseCLB(mydict, output=output)
        print "Wrote ", output
        if addLabel == True: # it could also be False, or some other text string
            addLabel = output
    montagePngs(png2=modelSubimage+'.png', png3=residualSubimage+'.png', 
                outname=pngname, sidebyside=sidebyside, png1=subimage+'.png',
                trim=True, geometry=geometry, 
                png4=residualSubimage+'_autoscale.png', 
                addLabel=addLabel, pointsize=pointsize)
    print "0)Wrote montaged image = ", pngname
    if backgroundImage != '':
        backgroundSubimage = backgroundImage + '.subimage'
        removeImageIfPresent(backgroundSubimage)
        imsubimage(backgroundImage, region=region, outfile=backgroundSubimage, box=box, chans=chans)
        subimageBGA = subimage + '.backgroundAdded'
        modelSubimageBGA = modelSubimage + '.backgroundAdded'
        contourSubimageBGA = {'file':subimageBGA, 'levels': list(levels), 'color':'black', 'base':base, 'unit':unit}
        contourModelBGA = {'file':modelSubimageBGA, 'levels': list(levels), 'color':'black', 'base':base, 'unit':unit}
        removeImageIfPresent(subimageBGA)
        immath(imagename=[subimage,backgroundSubimage], mode='evalexpr',outfile=subimageBGA, expr='IM0+IM1')
        removeImageIfPresent(modelSubimageBGA)
        immath(imagename=[modelSubimage,backgroundSubimage], mode='evalexpr',outfile=modelSubimageBGA, expr='IM0+IM1')
        pixrangeBGA = pixrange
        if not pixrangeSpecified:
            myimstat = imstat(subimageBGA)
            pixrangeBGA = [float(myimstat['min'][0]), float(myimstat['max'][0])]
        if (verbose):
            print "running imview(raster={'file':'%s', 'colorwedge':%s}, zoom=1, out='%s.png', contour=%s)" % (subimageBGA,colorwedge,model,contourSubimage)
        imview(raster={'file':subimageBGA, 'range':pixrangeBGA, 'colorwedge':colorwedge}, contour=contourSubimageBGA,
               zoom=1, out=subimageBGA+'.png')
        if (verbose):
            print "running imview(raster={'file':'%s', 'colorwedge':%s}, zoom=1, out='%s.png', contour=%s)" % (modelSubimageBGA,colorwedge,model,contourModel)
        imview(raster = {'file':modelSubimageBGA, 'range':pixrangeBGA, 'colorwedge':colorwedge}, contour=contourModel,
               zoom=1, out=modelSubimageBGA+'.png')
        residualSubimageBGA = residualSubimage + '.backgroundAdded'
        if (verbose):
            print "running imview(raster={'file':'%s', 'range':%s, 'colorwedge':%s}, zoom=1,out='%s.png', contour={'levels':%s})" % (residualSubimage,pixrange,colorwedge,residualSubimageBGA,str(levels))
        # Just use the same residualSubimage since it would be identical; only the name is needed to distinguish the pngs
        imview(raster = {'file':residualSubimage, 'range':pixrangeBGA, 'colorwedge':colorwedge},
               zoom = 1, out = residualSubimageBGA + '.png', contour={'file':residual, 'levels': levels, 'base':base, 'unit':unit})
        pngname = img+'.imfitPlusBackground.png'
        if (verbose):
            print "Running montagePngs"
        montagePngs(png2=modelSubimageBGA+'.png', png3=residualSubimageBGA+'.png', 
                    outname=pngname, sidebyside=sidebyside, png1=subimageBGA+'.png',
                    trim=True, geometry=geometry)
        print "1)Wrote montaged image = ", pngname
        if cleanup:
            os.remove(residualSubimageBGA+'.png')
            os.remove(modelSubimageBGA+'.png')
            os.remove(subimageBGA+'.png')
    if (vis != '' and field != ''):
        ids, names = parseFieldArgument(vis,field)
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        mydir = mymsmd.phasecenter(fieldid=ids[0])
        mymsmd.close()
        sep = angularSeparationOfDirections(mydir, mydict['results']['component0']['shape']['direction'], verbose=False)
        print "Separation from catalog position = %f arcsec" % (np.degrees(sep)*3600)
    # This file contains several lines: the imfitparse line followed by 5 lines
    # of the flux density of data and model in box, and recovered in box, total
    results = writeImfitDictToFile(mydict, img, estimates, verbose=True, 
                                   returnInfoOnResidual=residual, box=box, 
                                   deconvolved=deconvolved, 
                                   compareCoordinates=compareCoordinates, 
                                   region=region, model=model)
    if results is not None:
        components, negativeComponents, percentageFluxRecovered, rmsResidual = results
        mydict['percentageFluxRecovered'] = percentageFluxRecovered
    else:
        mydict['percentageFluxRecovered'] = 0

    if generateExtraModelAndResidual == True:
        generateExtraModelAndResidual = 1+np.arange(components)

    if (len(generateExtraModelAndResidual) > 0):
        print "Generating extra model and residual images using %d out of %d components." % (len(generateExtraModelAndResidual),components)
        extraModel = os.path.basename(img) + extraSuffix + '_imfitplot_extra.model'
        extraResidual = os.path.basename(img) + extraSuffix + '_imfitplot_extra.residual'
        myresults = getFitsBeam(img) # ,omitBeam=True)
        arcsecPerXpixel = abs(myresults[3])
        arcsecPerYpixel = myresults[4]
#        contourModel = [contourModel]
#        contourSubimageWithModel = [contourSubimage]
        if backgroundImage != '':
            contourSubimageBGAWithModel = [contourSubimageBGA]
        for i,c in enumerate(generateExtraModelAndResidual):
            comp = c-1
            print "Working on component %d (%d of %d)" % (c, i+1, len(generateExtraModelAndResidual))
            if (i==0):
                rIOR = subimage
            else:
                rIOR = ''
            # print "Running imfitparse(component=%d,img='%s')" % (comp,img)
            myresult = imfitparse(mydict,component=comp,returnFittedPeak=True,
                                  returnPeakPixel=True,
                                  img=img,returnInfoOnResidual=rIOR)
            token = myresult.split()
            token[2:] = [float(f) for f in myresult.split()[2:]]
            cimg = 'c%d.' % c +extraSuffix+'.img'
            #                             peak,       xpeak,     ypeak,    major,                      minor,     pa
            makeGaussianForImage(img, token[13], token[11], token[12], token[5]/arcsecPerXpixel, token[7]/arcsecPerYpixel, 
                                 token[9], newimage=cimg, verbose=False)
            if (i == 0):
                if (os.path.exists(extraModel)):
                    shutil.rmtree(extraModel)
                # this is effectively an imcopy
                immath(imagename=[cimg], mode='evalexpr',outfile=extraModel, expr='IM0*1.0')
            else:
                immath(imagename=[extraModel,cimg], mode='evalexpr',outfile=extraModel+'.new', expr='IM0+IM1')
                shutil.rmtree(extraModel)
                os.rename(extraModel+'.new', extraModel)
            mysubimage = 'c%d.'%c + extraSuffix+'.subimage'
            removeImageIfPresent(mysubimage)
            print "Running imsubimage('%s',region='%s',outfile='%s',box='%s')" % (cimg,region,mysubimage,box)
            imsubimage(cimg, region=region, outfile=mysubimage, box=box, chans=chans)
            # Draw half-power ellipse for this model component
            contourModel.append({'file':mysubimage, 'levels':[0.5], 'color':contourColor, 
                                 'thickness':float(contourThickness)})
            if drawModelOnDataSubimage:
                contourSubimageWithModel.append({'file':mysubimage, 'levels':[0.5], 'color':contourColor, 
                                                 'thickness':float(contourThickness)})
                if backgroundImage != '':
                    contourSubimageBGAWithModel.append({'file':mysubimage, 'levels':[0.5], 'color':contourColor, 
                                                        'thickness':float(contourThickness)})
            if deconvolved:
                # now for the deconvolved size
                cimg = 'c%d.deconvolved.' % c +extraSuffix+'.img'
                tokenDeconvolved = parseImfitShape(mydict['deconvolved']['component'+str(comp)]['shape'])
                if (tokenDeconvolved[0] > 0 and tokenDeconvolved[1] > 0):
                    makeGaussianForImage(img, token[13], token[11], token[12], tokenDeconvolved[0]/arcsecPerXpixel, 
                                         tokenDeconvolved[1]/arcsecPerYpixel, tokenDeconvolved[2], newimage=cimg, verbose=False)
                    mysubimage = 'c%d.deconvolved.'%c + extraSuffix+'.subimage'
                    removeImageIfPresent(mysubimage)
                    print "Running imsubimage('%s',region='%s',outfile='%s',box='%s')" % (cimg,region,mysubimage,box)
                    imsubimage(cimg, region=region, outfile=mysubimage, box=box, chans=chans)
                    print "Done"
                    # Draw half-power ellipse for this model component (which will be inside the convolved one)
                    contourModel.append({'file':mysubimage, 'levels':[0.5], 'color':contourColorDeconvolved, 
                                         'thickness':float(contourThickness)})
                elif (tokenDeconvolved[0] + tokenDeconvolved[1] > 0):
                    print "Component %d is unresolved in one direction" % (c)
                else:
                    print "Component %d is unresolved" % (c)
        # end 'for' loop over components
        print "Draw contours for each component on one image: ", contourSubimageWithModel
        print "Running imview(raster={'file':'%s', 'range':%s, 'colorwedge':%s}, contour=%s, zoom=1, out='%s.png')" % (subimage, pixrange, colorwedge, contourSubimageWithModel, subimage)
        imview(raster = {'file':subimage, 'range':pixrange, 'colorwedge':colorwedge}, contour=contourSubimageWithModel,
               zoom=1, out=subimage+'.png')
        print "E"
        removeImageIfPresent(extraResidual)
        immath(imagename=[img,extraModel], mode='evalexpr', outfile=extraResidual, expr='IM0-IM1')
        extraModelSubimage = extraModel+'.subimage'
        removeImageIfPresent(extraModelSubimage)
        imsubimage(extraModel, region=region, outfile=extraModelSubimage, box=box, chans=chans)
        extraResidualSubimage = extraResidual+'.subimage'
        removeImageIfPresent(extraResidualSubimage)
        imsubimage(extraResidual, region=region, outfile=extraResidualSubimage, box=box, chans=chans)
        if verbose:
            print "Running imview(raster = {'file':'%s', 'range':%s, 'colorwedge':%s}, contour=%s, zoom=1, out='%s.png')" % (extraModelSubimage, str(list(pixrange)), str(colorwedge), str(contourModel), extraModelSubimage)
        imview(raster = {'file':extraModelSubimage, 'range':pixrange, 'colorwedge':colorwedge}, contour=contourModel,
               zoom=1, out=extraModelSubimage+'.png')
        contourResidual = {'file':extraResidual, 'levels': levels, 'base':base, 'unit':unit}
        if verbose:
            print "Running imview(raster = {'file':'%s', 'range':pixrange, 'colorwedge':colorwedge}, contour=%s, zoom=1, out='%s.png')" % (extraResidualSubimage, str(contourResidual), extraResidualSubimage)
        imview(raster = {'file':extraResidualSubimage, 'range':pixrange, 'colorwedge':colorwedge},
               zoom = 1, out = extraResidualSubimage + '.png', contour=contourResidual)
        extraPngname = pngname.replace('.png','.extra.png')
        imview(raster = {'file':extraResidualSubimage, 'colorwedge':colorwedge},
               zoom = 1, out = extraResidualSubimage + '_autoscale.png')
        if writeCLB:
            if output == '':
                output = model + '.imfitparseCLB'
            if addLabel == True: # it could also be False, or some other text string
                addLabel = output
        montagePngs(png2=extraModelSubimage+'.png', png3=extraResidualSubimage+'.png', 
                    outname=extraPngname, sidebyside=sidebyside, png1=subimage+'.png', 
                    trim=True, geometry=geometry, 
                    png4=extraResidualSubimage+'_autoscale.png', 
                    addLabel=addLabel, pointsize=pointsize)
        if cleanup:
            os.remove(extraResidualSubimage+'.png')
            os.remove(extraModelSubimage+'.png')
            os.remove(subimage+'.png')
        if backgroundImage != '':
            extraModelSubimageBGA = extraModelSubimage + '.backgroundAdded'
            removeImageIfPresent(extraModelSubimageBGA)
            immath(imagename=[extraModelSubimage,backgroundSubimage], mode='evalexpr',outfile=extraModelSubimageBGA, expr='IM0+IM1')
            if (verbose):
                print "running imview(raster={'file':'%s', 'colorwedge':%s}, zoom=1, out='%s.png', contour=%s)" % (extraModelSubimageBGA,colorwedge,model,contourModel)
            imview(raster = {'file':extraModelSubimageBGA, 'range':pixrangeBGA, 'colorwedge':colorwedge}, contour=contourModel,
                   zoom=1, out=extraModelSubimageBGA+'.png')
            # Just use the same residualSubimage since it would be identical; only the name is needed to distinguish the pngs
            extraResidualSubimageBGA = extraResidualSubimage + '.backgroundAdded'
            if (verbose):
                print "Running imview(raster = {'file':'%s', 'range':pixrangeBGA, 'colorwedge':colorwedge}, contour=%s, zoom=1, out='%s.png')" % (extraResidualSubimage, str(contourResidual), extraResidualSubimageBGA)
            imview(raster = {'file':extraResidualSubimage, 'range':pixrangeBGA, 'colorwedge':colorwedge},
                   zoom = 1, out = extraResidualSubimageBGA + '.png', contour=contourResidual)
            imview(raster={'file':subimageBGA, 'range':pixrangeBGA, 'colorwedge':colorwedge}, 
                   contour=contourSubimageBGAWithModel, zoom=1, out=subimageBGA+'.png')
            extraPngname = img+'.imfitPlusBackground.extra.png'
            montagePngs(png2=extraModelSubimageBGA+'.png', png3=extraResidualSubimageBGA+'.png', 
                        outname=extraPngname, sidebyside=sidebyside, png1=subimageBGA+'.png', 
                        trim=True, geometry=geometry) 
            if cleanup:
                os.remove(extraResidualSubimageBGA+'.png')
                os.remove(extraModelSubimageBGA+'.png')
                os.remove(subimageBGA+'.png')
        # endif backgroundImage
    # endif generateExtraModelAndResidual
    if writeEstimatesFile:
        writeImfitDictToEstimatesFile(mydict)
    return(mydict)
    # end of imfitplot

def addLabelToPng(png, label, pointsize=30, background='white', textcolor='black', 
                  gravity='North', outfile='', convert='convert', font=''):
    """
    Uses ImageMagick convert to add a bar with text to a png.
    png: name of png
    label: string to write at top of image
    outfile: name of output image (default is to overwrite)
    gravity: North=top edge, South=bottom edge, etc.
    -Todd Hunter
    """
    if outfile == '':
        newpng = png.replace('.png','_label.png')
    else:
        newpng = outfile
    if len(font) > 0:
        font = '-font ' + font
    cmd = "%s %s %s -gravity %s -pointsize %d -background %s -fill %s -splice 0x%d -annotate +0+2 '%s' %s" % (convert, png, font, gravity, pointsize, background, textcolor, pointsize, label, newpng)
    print "Calling ", cmd
    mystatus = os.system(cmd)
    if mystatus not in [0,256]:
        convert = '/opt/local/bin/convert'
        mystatus = os.system("%s %s -gravity %s -pointsize %d -background %s -fill %s -splice 0x%d -annotate +0+2 '%s' %s" % (convert, png, gravity, pointsize, background, textcolor, pointsize, label, newpng))
    if outfile == '':
        os.system('mv %s %s' % (newpng, png))
    
def printPngListFromCSVFile(csv, delimiter=',', lpr='lpr -Pcv-erlobby-ricohmpc4503',
                            wget='/opt/local/bin/wget', title=True, pointSize=16, background='white',
                            textcolor='black', gravity='North', addProjectCode=True, dryrun=True,
                            projectCodePointSize=24, verbose=False):
    """
    Print all the png file names that appear in a CSV file.  They are assumed to exist in
    the current working directory.
    lpr: print command, include the queue, such as cv-er333-ricohmpc3503
    title: if True, then print the name of the file at the top of the plot
    addProjectCode: if True, then print the ALMA project code at the bottom of the plot
    dryrun: if True, then don't print them, just modify them with titles
    """
    pnglist = extractPngListFromCSVFile(csv, delimiter)
    for png in pnglist:
        if (png.find('http://')>=0 or png.find('https://')>=0 or png[:3] == 'uid'):
            if not os.path.exists(os.path.basename(png)):
                # -r means overwrite, don't append a ".1"
                os.system(wget + ' -r ' + png)
            png = os.path.basename(png)
        if title:
            newpng = png.replace('.png','_label.png')
            addLabelToPng(png, png, pointSize, background, textcolor, gravity, newpng)
            if (addProjectCode and png.find('uid') >= 0):
                newpng2 = newpng.replace('_label.png','_label2.png')
                dataset = newpng.split('.ms')[0]
                projectCodeInfo = projectCodeFromDataset(dataset, verbose=verbose)
                projectCode = projectCodeInfo[0]
                mous = projectCodeInfo[2]
                addLabelToPng(newpng, projectCode+"  MOUS="+mous, projectCodePointSize, 
                              background, textcolor, 'South', newpng2)
                newpng = newpng2
            png = newpng
        if not dryrun:
            cmd = lpr + ' ' + png
            print cmd
            os.system(cmd)

def extractPngListFromCSVFile(csv, delimiter=','):
    """
    Finds all the png filenames in a comma-separated value ASCII file.
    -Todd Hunter
    """
    f = open(csv,'r')
    lines = f.readlines()
    f.close()
    pnglist = []
    for line in lines:
        token = line.split(delimiter)
        for t in token:
            t = t.rstrip('\n')
            if (len(t) > 4):
                if (t[-4:] == '.png'):
                    pnglist.append(t)
    return pnglist

def imageModelResidual(img, model, pngname='', box='', region='', pixrange=None,
                       geometry=None, sidebyside=True, colorwedge=True):
    """
    Given an image and a model image, compute the residual, then show all 3 on the
    same scale side-by-side on a plot (using imview).
    pngname: name of output plot file to produce
    box,region: passed to imsubimage
    pixrange: the intensity range to display in image brightness units, e.g. [0,10.0]
    sidebyside: if False, then stack them vertically
    -Todd Hunter
    """
    if (pngname == ''):
        pngname = img + '.imageModelResidual.png'
    residual = img+'.imageModelResidual.residual'
    if (removeImageIfPresent(residual) == None): return
    immath([img,model], mode='evalexpr',expr='IM0-IM1',outfile=residual)
    imgSubimage = img+'.imageModelResidual.subimage'
    modelSubimage = model+'.imageModelResidual.subimage'
    residualSubimage = residual+'.subimage'
    imsubimage(img, box=box, region=region, overwrite=True, outfile=imgSubimage)
    imsubimage(model, box=box, region=region, overwrite=True, outfile=modelSubimage)
    imsubimage(residual, box=box, region=region, overwrite=True, outfile=residualSubimage)
    print "Wrote residual: ", residualSubimage
    myimstat = imstat(imgSubimage)
    pixrangeSpecified = True
    if (pixrange == None):
        pixrangeSpecified = False
        pixrange = [float(myimstat['min'][0]), float(myimstat['max'][0])]
        if (pixrange[0] > 0):
            pixrange[0] = 0
    for f in [imgSubimage, modelSubimage, residualSubimage]:
        imview(raster={'file':f, 'range':pixrange, 'colorwedge':colorwedge}, 
               zoom=1, out=f+'.png')
    montagePngs(png1=imgSubimage+'.png', png2=modelSubimage+'.png', png3=residualSubimage+'.png', 
                outname=pngname, sidebyside=sidebyside, trim=True, geometry=geometry)
    print "wrote png = ", pngname

def writeImfitDictToEstimatesFile(mydict, img, estimates=''):
    if estimates == '':
        estimates = 'estimates.txt'
    for comp in [0]:
        myshape = mydict['results']['component%d'%comp]['shape']
    print "Not yet implemented."
    
def writeImfitDictToFile(mydict, img, estimates='', verbose=False, append=False, outfile='',
                         returnInfoOnResidual='', box='', compareCoordinates=[], region='',
                         my_estimates='', niter=-1, deconvolved=False, fluxprec=4, model=None):
    """
    Given an imfit results dictionary, write a select list of values to a text file for the
    purpose of recording the result (from multiple trials) of multi-component Gaussians.
    Optional inputs:
    * estimates: name of original estimates file (to be included in the automatic name of the outfile)
    * my_estimates: name of the estimates file for this iteration (to be included as label in output file)
    * append: if True, then append to the file if it exists
    * outfile: default name is <img>_<estimates>.results
    * returnInfoOnResidual: if not '', then take this filename as the residual image
          and find the min/maximum values and return them as the final values
    * box, region: box or region to use in assessing the max in returnInfoOnResidual
    * niter: simply used to label the result in the output file (along with my_estimates)
    Returns: 4 numbers
    * the number of components in the dictionary
    * the number of components with negative flux density
    * percentFluxRecovered in the box/region
    * rms of the residual in the box/region
    * deconvolved: if True, then also write the deconvolved size
    -Todd Hunter
    """
    components = mydict['results']['nelements'] # len(grep(img+'.imfit.log','Fit on')[0].split('\n')) - 1
    result = ''
    if ((components > 0) and ('iterationsCompleted' in mydict.keys())):
        result = 'After %d iterations:  (%s)\n' % (mydict['iterationsCompleted'], estimates)
    elif (niter>=0):
        result = 'Result for ' + estimates + '.%03d\n' % (niter)
    else:
        result = 'Result for ' + estimates + '\n'
    #               0              1            2      3     4     5      6      7      8       9      10     11      12    13 14
    result += "Right Ascension  Declination  FluxDens  Unc   SNR  Major   Unc    Minor   Unc     PA     Unc   Xpixel   Ypixel Peak   Unc  Residual:Min  Max  Mean  RMS"
    if deconvolved:
        result += "  DeMaj   Unc    DeMin   Unc     DePA  Unc"
    result += '\n'
    totalFlux = 0
    offset = []
    negativeComponents = 0
    residualInfo  = ''
    for component in range(components):
        if (component == 0):
            # This only needs to be run for one component, since result is independent of component
            rIOR = returnInfoOnResidual
        else:
            rIOR = ''
        myresult = imfitparse(mydict,component=component,returnFittedPeak=True,returnPeakPixel=True,
                              img=img, returnInfoOnResidual=rIOR, box=box, region=region,
                              fluxprec=fluxprec)
        if myresult == None: return None
        if (rIOR != ''):
            residualInfo = ' ' + ' '.join(myresult.split()[-4:])
        else:
            myresult += residualInfo
        if deconvolved:
            a,b,c,d,e,f = parseImfitShape(mydict['deconvolved']['component'+str(component)]['shape'])
            myresult += ' %.*f %.*f %.*f %.*f %+.2f %.2f' % (fluxprec,a,fluxprec,d,fluxprec,b,fluxprec,e,c,f)
        componentFlux = float(myresult.split()[2])
        if (componentFlux < 0):
            negativeComponents += 1
        totalFlux += componentFlux
        result += myresult + '\n'
        if (len(compareCoordinates) > component+1):
            if (len(compareCoordinates[component+1]) > 0):
                coords = ' '.join(myresult.split()[:2])
                offset = angularSeparationOfStrings(compareCoordinates[component+1], coords, verbose=False)*3600
                result += " Offset = %f arcsec\n" % (offset)
    result += "       Total Flux density of model = %f\n" % (totalFlux)
    boxTotalFlux = imstat(img, box=box, region=region)['flux'][0]
    result += "Flux density of data in parent box = %f\n" % (boxTotalFlux)
    if model is not None:
        boxModelFlux = imstat(model, box=box, region=region)['flux'][0]
        result += "Flux density of model in parent box = %f\n" % (boxModelFlux)
        percentageFluxRecoveredInBox = 100*boxModelFlux/boxTotalFlux
        result += "    Recovered flux density in box = %.2f%%\n" % (percentageFluxRecoveredInBox)
    percentageFluxRecovered = 100*totalFlux/boxTotalFlux
    result += "    Recovered flux density = %.2f%%\n" % (percentageFluxRecovered)
    rmsResidual = float(myresult.split()[-1])
    if verbose:
        print result[:-1]
    if (outfile == ''):
        if (estimates != ''):
            outfile = img + '_' + estimates + '.results'
        else:
            outfile = img + '.imfit.results'
    if append:
        mode = 'a'
    else:
        mode = 'w'
    f = open(outfile, mode)
    f.write(result)
    f.close()
    return(components, negativeComponents, percentageFluxRecovered, rmsResidual)

def imfitparseDict(imfitdict, raprec=4, decprec=3, fluxprec=6, sizeprec=4,
                   paprec=2, stokes=0, refpos='', separationprec=2, snrprec=0, 
                   component=0, fluxunit='Jy', logfile=None, showpixels=False,
                   meanpixel=None, img=None, deconvolved=False, 
                   returnPeakPixel=False, returnPositionUncertainties=False, kpc=0,
                   returnFittedPeak=True, returnInfoOnResidual='', box='', region=''):
    """
    Simplifies an imfit dictionary for a specified component to have only 6 entries:
    {'ra','dec','peak','major','minor','pa'}
    peak is a floating point value in Jy; the rest are strings, with units when applicable
    -Todd Hunter
    """
    d = imfitparse(imfitdict, raprec, decprec, fluxprec, sizeprec, paprec, stokes, refpos, 
                   separationprec, snrprec, component, fluxunit, logfile, showpixels,
                   meanpixel, img, deconvolved, returnPeakPixel, returnPositionUncertainties, 
                   kpc, returnFittedPeak, returnInfoOnResidual, box, region)
    token = d.split()
    mydict = {}
    mydict['ra'] = token[0]
    mydict['dec'] = token[1]
    mydict['peak'] = float(token[11])
    mydict['major'] = token[5] + 'arcsec'
    mydict['minor'] = token[7] + 'arcsec'
    mydict['pa'] = token[9] + 'deg'
    return(mydict)

def imfitparse(imfitdict, raprec=4, decprec=3, fluxprec=4, sizeprec=4,
               paprec=2, stokes=0, refpos='', separationprec=2, snrprec=0, 
               component=0, fluxunit='Jy', logfile=None, showpixels=False,
               meanpixel=None, img=None, deconvolved=False, 
               returnPeakPixel=False, returnPositionUncertainties=False, kpc=0,
               returnFittedPeak=False, returnInfoOnResidual='', box='', region=''):
    """
    This function accepts a dictionary result from imfit, and returns a string
    containing the position of component 0 in RA/Dec.   See also imfitparseCLB.
    sexagesimal, followed by its flux, fitted size, and uncertainties.
    Returns:
    * a string containing: ra, dec, flux, fluxerr, snr=(flux/fluxerr), majorarcsec, 
      majorarcsecerr, minorarcsec, minorarcsecerr, posangle, posangleerr
    * if returnPeakPixel, then also return the peak xpixel and ypixel
    * if returnPositionUncertainties==True, then also return the RA and Dec
      uncertainties on the fitted peak (in native dictionary units, usually arcsec)
    Optional inputs:
    * The various "prec" parameters set the precision (number of points to the
      right of the decimal) to show for the various corresponding quantities.
      e.g. fluxprec=6 will show to the nearest microJansky
    * stokes: which Stokes parameter to return (default = 0 = "I")
    * component: the component number of the imfitdict to parse
    * fluxunit:  set to 'mJy' to multiply values by 1000
    * refpos: a sexagesimal string  (e.g.  HH:MM:SS.SSS +DD:MM:SS.SSSS)
      * If specified, also compute the separation from this position, and
        insert it after the fluxerr field.
      * The RA & Dec part of the string can be either comma or space delimited.
      * The Dec portion of the string can be either : or . delimited.
    * logfile: alternate logfile to use for showpixels and deconvolved options,
               (default=the current log file)
    * showpixels: if True, then put the pixel values as 2 final columns, as
                  read from the current logfile. If not Boolean, then
                  also normalize the pixel value by this number
    * meanpixel: if specified as [x,y], then remove x,y from fitted pixel value
              before normalizing by showpixels
    * img: if specified, and showpixels=True, then the peak pixel is returned
           using findRADec (rather than parsing the logfile)
    * deconvolved: if True, then the size will be the size deconvolved from
                   the beam, rather than the (larger) fitted size.
    * kpc: give major/minor values in AU based on this distance in kpc
    * returnInfoOnResidual: if not '', then take this filename as the residual image
          and find the min/max/mean values and append them to the returned string
    * box, region: box or region to use in assessing the max in returnInfoOnResidual
    -- Todd Hunter
    """
    if ((showpixels != False or deconvolved) and logfile == None):
        # use the default log file
        logfile = casalog.logfile()
    if (imfitdict == None):
        return "no result"
    comp = 'component%d' % (component)
    if (comp not in imfitdict['results'].keys()):
        return(None)
    ra  = imfitdict['results'][comp]['shape']['direction']['m0']['value']
    dec = imfitdict['results'][comp]['shape']['direction']['m1']['value']
    raUnc = imfitdict['results'][comp]['shape']['direction']['error']['longitude']['value']
    raUncUnit = imfitdict['results'][comp]['shape']['direction']['error']['longitude']['unit']
    decUnc = imfitdict['results'][comp]['shape']['direction']['error']['latitude']['value']
    decUncUnit = imfitdict['results'][comp]['shape']['direction']['error']['latitude']['unit']
    flux = imfitdict['results'][comp]['flux']['value'][stokes]
    fluxerr = imfitdict['results'][comp]['flux']['error'][stokes]
    myfluxunit = imfitdict['results'][comp]['flux']['unit']
    if (fluxunit != myfluxunit):
        if (fluxunit == 'mJy' and myfluxunit=='Jy'):
            flux *= 1000
            fluxerr *= 1000
    # This major/minor is the fitted size, not deconvolved from the beam.
    majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr = parseImfitShape(imfitdict['results'][comp]['shape'])
    peakValue = imfitdict['results'][comp]['peak']['value']
    peakError = imfitdict['results'][comp]['peak']['error']

    if (refpos != ''):
        rarad,decrad = radec2rad(refpos)
        separationArcsec = angularSeparationRadians(rarad,decrad, ra, dec) * 180*3600/np.pi
        
    ra = qa.formxxx('%.12frad'%(ra),format='hms',prec=raprec)
    dec = qa.formxxx('%.12frad'%(dec),format='dms',prec=decprec-1).replace('.',':',2).replace('-0',' -',1)
    snr = flux/fluxerr
    if (img is not None):
#        print "Running au.findRADec('%s','%s')" % (img,str(ra)+' '+str(dec))
        tentativeResult = findRADec(img,str(ra)+' '+str(dec))
        if (tentativeResult == None): return None
        xpixel, ypixel = tentativeResult
    elif (deconvolved or showpixels):
        # For the showpixels case, this is obsoleted by the option to use
        # au.findRADec (above) except for the case of ia.rotate-d images,
        # for which findRADec does not work.
        if (casadef.subversion_revision >= '29326'): # CAS-6149
            if deconvolved:
                majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr = parseImfitShape(imfitdict['deconvolved'][comp]['shape'])
            if (os.path.exists(logfile) == False):
                print "Logfile not found"
                return
            lf = open(logfile,'r')
            lines = lf.readlines()
            lf.close()
            for i,line in enumerate(lines):
                if (line.find("Position ---")>=0 and showpixels != False):
                    if (lines[i+3].find('ra') >= 0 and lines[i+3].find('pixels') >= 0 ):
                        xpixel = float(lines[i+3].split('ra:')[1].split()[0])
                        if (meanpixel is not None):
                            xpixel -= meanpixel[0]
                        if (showpixels != False and showpixels != True):
                            xpixel /= showpixels
                    else:
                        print "Failed to parse the log file for pixel positions"
                        return
                    if (lines[i+4].find('dec') >= 0 and lines[i+4].find('pixels') >= 0 ):
                        ypixel = float(lines[i+4].split('dec:')[1].split()[0])
                        if (meanpixel is not None):
                            ypixel -= meanpixel[1]
                        if (showpixels != False and showpixels != True):
                            ypixel /= showpixels
                    else:
                        print "Failed to parse the log file for pixel positions"
                        return
        else:
            if (os.path.exists(logfile) == False):
                print "Logfile not found"
                return
            lf = open(logfile,'r')
            lines = lf.readlines()
            lf.close()
            for i,line in enumerate(lines):
                if (line.find("Position ---")>=0 and showpixels != False):
                    if (lines[i+3].find('ra') >= 0 and lines[i+3].find('pixels') >= 0 ):
                        xpixel = float(lines[i+3].split('ra:')[1].split()[0])
                        if (meanpixel is not None):
                            xpixel -= meanpixel[0]
                        if (showpixels != False and showpixels != True):
                            xpixel /= showpixels
                    else:
                        print "Failed to parse the log file for pixel positions"
                        return
                    if (lines[i+4].find('dec') >= 0 and lines[i+4].find('pixels') >= 0 ):
                        ypixel = float(lines[i+4].split('dec:')[1].split()[0])
                        if (meanpixel is not None):
                            ypixel -= meanpixel[1]
                        if (showpixels != False and showpixels != True):
                            ypixel /= showpixels
                    else:
                        print "Failed to parse the log file for pixel positions"
                        return
                if (line.find("Image component size (deconvolved from beam)")>=0 and deconvolved):
                    minorarcsec = 0
                    minorarcsecerr = 0
                    majorarcsec = 0
                    majorarcsecerr = 0
                    posangle = 0
                    posangleerr = 0
                    if (lines[i+1].find('major axis FWHM:') >= 0):
                        fitresult = lines[i+1].split('FWHM:')[1].strip() # 2.041 +/- 0.078 arcsec
                        majorarcsec = float(fitresult.split()[0])
                        majorarcsecerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if (myunit == 'marcsec'):
                            majorarcsec *= 0.001
                            majorarcsecerr *= 0.001
                        elif (myunit == 'uarcsec'):
                            minorarcsec *= 0.000001
                            minorarcsecerr *= 0.000001
                        elif ('arcsec' != myunit):
                            print "major axis: imfit returned %s instead of arcsec" % (myunit)
                    if (lines[i+2].find('minor axis FWHM:') >= 0):
                        fitresult = lines[i+2].split('FWHM:')[1].strip()
                        minorarcsec = float(fitresult.split()[0])
                        minorarcsecerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if (myunit == 'marcsec'):
                            minorarcsec *= 0.001
                            minorarcsecerr *= 0.001
                        elif (myunit == 'uarcsec'):
                            minorarcsec *= 0.000001
                            minorarcsecerr *= 0.000001
                        elif ('arcsec' != myunit):
                            print "minor axis: imfit returned %s instead of arcsec" % (myunit)
                    if (lines[i+3].find('position angle:') >= 0):
                        fitresult = lines[i+3].split('angle:')[1].strip()
                        posangle = float(fitresult.split()[0])
                        posangleerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if ('deg' != myunit):
                            print "position angle: imfit returned %s instead of deg" % (myunit)
    if (kpc > 0):
        majorarcsec *= kpc*1000
        majorarcsecerr *= kpc*1000
        minorarcsec *= kpc*1000
        minorarcsecerr *= kpc*1000
    if (refpos != ''):
        result = '%s %s %*.*f % .*f %.*f %*.*f  %.*f %.*f % .*f %.*f %+*.*f %*.*f' % (ra,dec,
             separationprec+6, separationprec, separationArcsec, fluxprec,flux,
             fluxprec, fluxerr, snrprec+4, snrprec, snr, sizeprec, majorarcsec, sizeprec,
             majorarcsecerr,
             sizeprec, minorarcsec, sizeprec, minorarcsecerr, 5+paprec, paprec,
             posangle, 3+paprec, paprec, posangleerr)
    else:
        result = '%s %s % .*f %.*f %*.*f  %.*f %.*f % .*f %.*f %+*.*f %*.*f' % (ra,dec,fluxprec,flux,
             fluxprec, fluxerr, snrprec+4, snrprec, snr, sizeprec, majorarcsec, sizeprec, majorarcsecerr,
             sizeprec, minorarcsec, sizeprec, minorarcsecerr, 5+paprec, paprec,
             posangle, 3+paprec, paprec, posangleerr)
    if (showpixels or returnPeakPixel):
        result += ' %8.3f %8.3f' % (xpixel, ypixel)
    if (returnPositionUncertainties):
        result += ' %8.3f %8.3f' % (raUnc, decUnc)
    if (returnFittedPeak):
        result += ' %.*f %.*f' % (fluxprec, peakValue, fluxprec, peakError)
    if (returnInfoOnResidual != '' and returnInfoOnResidual is not None):
        print "imfitparse: Running imstat('%s', box='%s')" % (returnInfoOnResidual, box)
        myresult = imstat(returnInfoOnResidual, box=box, region=region)
        minResidual = myresult['min'][0]
        maxResidual = myresult['max'][0]
        meanResidual = myresult['mean'][0]
        rmsResidual = myresult['rms'][0]
        result += ' %.*f %.*f %.*f %.*f' % (fluxprec, minResidual, fluxprec, maxResidual, 
                                            fluxprec, meanResidual, fluxprec, rmsResidual)
    return(result)

def parseImfitLogfile(logfile):
    """
    Reads a logfile generated by imfit and returns a list of components, each
    member of which is [peak, x, y]  where x and y are in units of pixels
    """
    f = open(logfile,'r')
    lines = f.readlines()
    components=[]
    pa = None
    for line in lines:
        if line.find('imagename') > 0:
            img = line.split()[2]
            print "img = ", img
            arcsecPerPixel = getFitsBeam(img)[4]
        if line.find('ra:') > 0 and line.find('pixels') > 0:
            print "parsing line: ", line
            x = float(line.split()[2])
        if line.find('dec:') > 0 and line.find('pixels') > 0:
            y = float(line.split()[2])
        if line.find('Peak:') > 0 and line.find('beam') > 0:
            peak = float(line.split()[2])
            if line.find('mJy') > 0:
                peak *= 0.001
            components.append([peak,x,y,major,minor,pa])
            break
        if line.find('major axis FWHM:') > 0:
            major = float(line.split()[4])
            #convert arcsec to pixels
            major /= arcsecPerPixel
            if line.find('marcsec') > 0:
                major *= 0.001
        if line.find('minor axis FWHM:') > 0:
            minor = float(line.split()[4])
            minor /= arcsecPerPixel
            if line.find('marcsec') > 0:
                minor *= 0.001
        if line.find('position angle:') > 0 and pa is None:
            # the first one is the one convolved with beam
            pa = float(line.split()[3])
    return components

def parseImfitShape(imfitShapeDict):
    """
    Parses the values from the 'shape' keyword of an imfit dictionary.
    Returns:  6 values
      majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr
    -Todd Hunter
    """
    if (imfitShapeDict['type'] == 'Gaussian'):
        majorarcsec = imfitShapeDict['majoraxis']['value']
        myunit      = imfitShapeDict['majoraxis']['unit']
        if ('arcsec' != myunit): print "imfit returned %s instead of arcsec" % (myunit)

        minorarcsec = imfitShapeDict['minoraxis']['value']
        myunit      = imfitShapeDict['minoraxis']['unit']
        if ('arcsec' != myunit): print "imfit returned %s instead of arcsec" % (myunit)

        majorarcsecerr = imfitShapeDict['majoraxiserror']['value']
        myunit         = imfitShapeDict['majoraxiserror']['unit']
        if ('arcsec' != myunit): print "imfit returned %s instead of arcsec" % (myunit)

        minorarcsecerr = imfitShapeDict['minoraxiserror']['value']
        myunit        = imfitShapeDict['minoraxiserror']['unit']
        if ('arcsec' != myunit): print "imfit returned %s instead of arcsec" % (myunit)

        posangle = imfitShapeDict['positionangle']['value']
        myunit   = imfitShapeDict['positionangle']['unit']
        if ('deg' != myunit): print "imfit returned %s instead of deg" % (myunit)

        posangleerr = imfitShapeDict['positionangleerror']['value']
        myunit      = imfitShapeDict['positionangleerror']['unit']
        if ('deg' != myunit): print "imfit returned %s instead of deg" % (myunit)
    else:
        majorarcsec = 0; minorarcsec = 0; posangle = 0; majorarcsecerr = 0; minorarcsecerr = 0; posangleerr = 0
    return(majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr)

def imfitparseCLBs(imfitdict, raprec=4, decprec=3, fluxprec=4, sizeprec=4,
                   paprec=2, stokes=0, refpos='', separationprec=2, snrprec=1, 
                   fluxunit='mJy', logfile=None, meanpixel=None, kpc=0):
    """ 
    Runs imfitparseCLB on all components in succession.
    """
    for i in range(imfitdict['results']['nelements']):
        header = i==0
        print imfitparseCLB(imfitdict,raprec, decprec, fluxprec, sizeprec,
                            paprec, stokes, refpos, separationprec, snrprec, 
                            i,  fluxunit, logfile,  meanpixel, kpc, header)

def imfitparseCLB(imfitdict, raprec=4, decprec=3, fluxprec=4, sizeprec=4,
                  paprec=2, stokes=0, refpos='', separationprec=2, snrprec=1, 
                  component=-1, fluxunit='mJy', logfile=None, 
                  meanpixel=None, kpc=0, header=True, output='', prepend='',
                  prependComponent=False, offsetComponentNumber=0, append=False):
    """
    This function accepts a dictionary result from imfit, and returns a
    string containing the results for component 0.  See also imfitparse.
    Returns:
    * a string containing: ra, dec, raerr, decerr 
         intensity intensityerror   peaksnr flux fluxerr 
         major minor posangle major_err minor_err posangle_err
         dc_major dc_minor dc_posangle dc_major_err dc_minor_err dc_posangle_err
       where "dc" stands for deconvolved
       The uncertainties on the fitted peak position are given in native 
       dictionary units, which is usually arcsec.
    Optional inputs:
    * output: write the string to a new file of this name
    * prepend: write this string to the beginning of each output line
    * prependComponent: prepend component number to output line
    * The various "prec" parameters set the precision (number of points to the
      right of the decimal) to show for the various corresponding quantities.
      e.g. fluxprec=6 will show to the nearest microJansky
    * stokes: which Stokes parameter to return (default = 0 = "I")
    * component: the component number of the imfitdict to parse, if not set, then all
    * fluxunit: set to 'mJy' in order to multiply Jy values by 1000
    * logfile: only relevant for older CASA (<rev.29326)
    * refpos: a sexagesimal string  (e.g.  HH:MM:SS.SSS +DD:MM:SS.SSSS)
      * If specified, also compute the separation from this position, and
        insert it after the fluxerr field.
      * The RA & Dec part of the string can be either comma or space delimited.
      * The Dec portion of the string can be either : or . delimited.
    * meanpixel: if specified as [x,y], then remove x,y from fitted pixel value
              before normalizing by showpixels
    * kpc: if >0, then give major/minor values in AU based on this distance (kpc)
    * header: if True, then print a title line that labels each quantity
    -- Todd Hunter
    """
    if (logfile == None):
        # use the default log file
        logfile = casalog.logfile()
    if (imfitdict == None):
        return "no result"
    if (type(imfitdict) != dict):
        # then it may be a return from imfitIterate, which is a tuple of length 2
        imfitdict = imfitdict[0]
    if (component >= 0):
        comp = 'component%d' % (component)
        if (comp not in imfitdict['results'].keys()):
            return(None)
        components = [comp]
    else:
        components = ['component%d' % (component) for component in range(imfitdict['results']['nelements'])]
#    headerLine = "Right Ascension  Declination   RAUnc    DecUnc    Peak    PeakUncer   PeakS/N   FluxDens   FluxDensUnc  Major Minor  PAngle MajorUnc MinorUnc PAunc DeMaj DeMin DePAngle DeMajUnc DeMinUnc DePAunc"
    headerLine = "Right Ascension  Declination   RAUnc    DecUnc    Peak  PeakUncer PeakS/N  FluxDens FluxDensUnc Major Minor PAngle MajorUnc MinorUnc PAunc DeMajor DeMinor DePAngle DeMajUnc DeMinUnc DePAunc"
    result = None
    if output != '':
        if append:
            if not os.path.exists(output):
                print "WARNING: append=True, but file did not exist.  Opening a new file."
            o = open(output, 'a')
        else:
            o = open(output, 'w')
        if prependComponent: 
            headerLine = 'Comp ' + headerLine
        if not append:
            o.write('#'+headerLine+'\n')
#    print "Will print %d components" % len(components)
    for icomp,comp in enumerate(components):
        ra  = imfitdict['results'][comp]['shape']['direction']['m0']['value']
        dec = imfitdict['results'][comp]['shape']['direction']['m1']['value']
        raUnc = imfitdict['results'][comp]['shape']['direction']['error']['longitude']['value']
        raUncUnit = imfitdict['results'][comp]['shape']['direction']['error']['longitude']['unit']
        decUnc = imfitdict['results'][comp]['shape']['direction']['error']['latitude']['value']
        decUncUnit = imfitdict['results'][comp]['shape']['direction']['error']['latitude']['unit']
        flux = imfitdict['results'][comp]['flux']['value'][stokes]
        fluxerr = imfitdict['results'][comp]['flux']['error'][stokes]
        myfluxunit = imfitdict['results'][comp]['flux']['unit']
        if (fluxunit != myfluxunit):
            if (fluxunit == 'mJy' and myfluxunit=='Jy'):
                flux *= 1000
                fluxerr *= 1000
            else:
                print "unknown flux unit combination (have %s, want %s)" % (fluxunit, myfluxunit)
                return
        # This major/minor is the fitted size, not deconvolved from the beam.
        majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr = parseImfitShape(imfitdict['results'][comp]['shape'])
        peakValue = imfitdict['results'][comp]['peak']['value']
        peakError = imfitdict['results'][comp]['peak']['error']
        myfluxunit = imfitdict['results'][comp]['peak']['unit']
        if (fluxunit != myfluxunit.split('/')[0]):
            if (fluxunit == 'mJy' and myfluxunit=='Jy/beam'):
                peakValue *= 1000
                peakError *= 1000
            else:
                print "unknown intensity unit combination (have %s, want %s)" % (fluxunit, myfluxunit)
                return

        if (refpos != ''):
            rarad,decrad = radec2rad(refpos)
            separationArcsec = angularSeparationRadians(rarad,decrad, ra, dec) * 180*3600/np.pi
            
        ra = qa.formxxx('%.12frad'%(ra),format='hms',prec=raprec)
        dec = qa.formxxx('%.12frad'%(dec),format='dms',prec=decprec-1).replace('.',':',2).replace('-0',' -',1)
        if peakError > 0:
            snr = peakValue/peakError
        else:
            snr = 0
        if (casadef.subversion_revision >= '29326'):  # CAS-6149
            result = parseImfitShape(imfitdict['deconvolved'][comp]['shape'])
            dc_majorarcsec, dc_minorarcsec, dc_posangle, dc_majorarcsecerr, dc_minorarcsecerr, dc_posangleerr = result
        else:
            if (os.path.exists(logfile) == False):
                print "Logfile not found"
                return
            lf = open(logfile,'r')
            lines = lf.readlines()
            lf.close()
            for i,line in enumerate(lines):
                if (line.find("Image component size (deconvolved from beam)") >= 0):
                    dc_minorarcsec = 0
                    dc_minorarcsecerr = 0
                    dc_majorarcsec = 0
                    dc_majorarcsecerr = 0
                    dc_posangle = 0
                    dc_posangleerr = 0
                    if (lines[i+1].find('major axis FWHM:') >= 0):
                        fitresult = lines[i+1].split('FWHM:')[1].strip() # 2.041 +/- 0.078 arcsec
                        dc_majorarcsec = float(fitresult.split()[0])
                        dc_majorarcsecerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if (myunit == 'marcsec'):
                            dc_majorarcsec *= 0.001
                            dc_majorarcsecerr *= 0.001
                        elif (myunit == 'uarcsec'):
                            dc_minorarcsec *= 0.000001
                            dc_minorarcsecerr *= 0.000001
                        elif ('arcsec' != myunit):
                            print "dc major axis: imfit returned %s instead of arcsec" % (myunit)
                    if (lines[i+2].find('minor axis FWHM:') >= 0):
                        fitresult = lines[i+2].split('FWHM:')[1].strip()
                        dc_minorarcsec = float(fitresult.split()[0])
                        dc_minorarcsecerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if (myunit == 'marcsec'):
                            dc_minorarcsec *= 0.001
                            dc_minorarcsecerr *= 0.001
                        elif (myunit == 'uarcsec'):
                            dc_minorarcsec *= 0.000001
                            dc_minorarcsecerr *= 0.000001
                        elif ('arcsec' != myunit):
                            print "dc minor axis: imfit returned %s instead of arcsec" % (myunit)
                    if (lines[i+3].find('position angle:') >= 0):
                        fitresult = lines[i+3].split('angle:')[1].strip()
                        dc_posangle = float(fitresult.split()[0])
                        dc_posangleerr = float(fitresult.split()[2])
                        myunit = fitresult.split()[3]
                        if ('deg' != myunit):
                            print "dc position angle: imfit returned %s instead of deg" % (myunit)
        if (kpc > 0):
            majorarcsec *= kpc*1000
            majorarcsecerr *= kpc*1000
            minorarcsec *= kpc*1000
            minorarcsecerr *= kpc*1000
            dc_majorarcsec *= kpc*1000
            dc_majorarcsecerr *= kpc*1000
            dc_minorarcsec *= kpc*1000
            dc_minorarcsecerr *= kpc*1000
        #         ra de raunc decunc peakV peakE snr     flux  fluxe  majo mino posang  maje   mine poser  demaj demin depos demaxunc deminunc depaunc
        result = '%s %s %8.3f %8.3f  %*.*f %*.*f  %*.*f  %*.*f %*.*f  %.*f %.*f %+*.*f  %.*f   %.*f %*.*f   %.*f %.*f %+*.*f    %.*f   %.*f   %*.*f' % (ra,dec,raUnc, decUnc, 4+fluxprec, fluxprec, peakValue, 4+fluxprec, fluxprec, peakError,
                                snrprec+5, snrprec, snr,  fluxprec+4, fluxprec,flux,  fluxprec+4, fluxprec, fluxerr, 
             sizeprec, majorarcsec,    sizeprec, minorarcsec,    5+paprec, paprec, posangle, 
             sizeprec, majorarcsecerr, sizeprec, minorarcsecerr, 3+paprec, paprec, posangleerr,
             sizeprec, dc_majorarcsec,    sizeprec, dc_minorarcsec,    5+paprec, paprec, dc_posangle, 
             sizeprec, dc_majorarcsecerr, sizeprec, dc_minorarcsecerr, 3+paprec, paprec, dc_posangleerr)
        if (header and comp==components[0]):
            print headerLine
        if prependComponent: 
            print str(icomp+offsetComponentNumber) + ' ' + result
        else:
            print result
        if output:
            if prependComponent: 
                prependComponent = str(icomp+offsetComponentNumber)
            else:
                prependComponent = ''
            line = ' '.join([prepend,prependComponent])+' '+result+'\n'
            o.write(line.lstrip())
    # end 'for' loop over comp
    if output:
        o.close()
    return(result)

def imheadlist(vis, omitBeam=False, verbose=True):
    """
    Emulates imhead(mode='list') but leaves off the min/max/minpos/maxpos
    keywords, the filling of which makes it take so long to run on large cubes.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find image."
        return
    header = {}
    if (not casaAvailable):
        print "Since you are running outside of CASA, you cannot run this function on a CASA image.  Converting it to a FITS image should work."
        return header
    keys = ['bunit','date-obs','equinox','imtype','masks',
            'object','observer','projection','reffreqtype',
            'restfreq','shape','telescope']
    if not omitBeam:
        header = imhead(vis, mode='list')
        if header == None:
            print "No beam found.  Re-run with omitBeam=True. Or set one with au.setBeam."
            return -1
        if 'beammajor' in header:
            singleBeam = imhead(vis, mode='get', hdkey='beammajor')
            keys += ['beammajor','beamminor','beampa']
        else:
            singleBeam = False
            print "Computing median of perplanebeams"
            if ('perplanebeams' not in header.keys()):
                print "No beam found.  Re-run with omitBeam=True. Or set one with au.setBeam."
                return -1
            beammajor = []
            beamminor = []
            beampa = []
            for beamchan in range(header['perplanebeams']['nChannels']):
                beamdict = header['perplanebeams']['*'+str(beamchan)]
                beammajor.append(beamdict['major']['value'])
                beamminor.append(beamdict['minor']['value'])
                beampa.append(beamdict['positionangle']['value'])
            bmaj = np.median(beammajor)
            bmin = np.median(beamminor)
            sinbpa = np.sin(np.radians(np.array(beampa)))
            cosbpa = np.cos(np.radians(np.array(beampa)))
            bpa = degrees(np.median(np.arctan2(np.median(sinbpa), np.median(cosbpa))))
            header['beammajor'] = bmaj
            header['beamminor'] = bmin
            header['beampa'] = bpa
            if verbose: print "Computing median beam shape from perplanebeams."
    for key in keys:
        try:
            header[key] = imhead(vis, mode='get', hdkey=key)
        except:
            pass
    for axis in range(len(header['shape'])):
        for key in ['cdelt','crval']:
            mykey = key+str(axis+1)
            try:
                result = imhead(vis, mode='get', hdkey=mykey)
                if type(result) == dict:
                    header[mykey] = result['value']
                else:  # Stokes axis
                    header[mykey] = result[0]
            except:
                pass
        for key in ['crpix','ctype','cunit']:
            mykey = key+str(axis+1)
            try:
                header[mykey] = imhead(vis, mode='get', hdkey=mykey)
            except:
                pass
    return(header)

def roundRadec(radec, prec=3):
    """
    Round an RA/Dec string to specified precision
    prec: 3 = 3 digits after decimal for Dec, and 4 digits after RA
    """
    return(rad2radec(radec2rad(radec),prec=prec))

def rads2radec(ras, decs, prec=5, hmsdms=False, delimiter=', ', hmdm=False,
               prependEquinox=False, verbose=False):
    """
    Calls rad2radec for a list of RA's and Dec's
    ras: list of radians
    decs: list of values in radians
    hmdm: produce output of format: '20h10m49.01, +057d17m44.806' (for simobserve)
    hmsdms: produce output of format: '20h10m49.01s, +057d17m44.806s'
    delimiter: the character to use to delimit the RA and Dec strings output
    prependEquinox: if True, insert "J2000" before coordinates (i.e. for clean or simobserve)
    Returns: list of strings ['HH:MM:SS.SSSS, +DD:MM:SS.SSS', ...]
    -Todd Hunter
    """
    values = []
    for i in range(len(ras)):
        values.append(rad2radec(ras[i], decs[i], prec=prec, hmsdms=hmsdms, 
                                delimiter=delimiter, hmdm=hmdm,
                                prependEquinox=prependEquinox, verbose=verbose))
    return values
        
def rad2radec(ra=0,dec=0,imfitdict=None, prec=5, verbose=True, component=0,
              replaceDecDotsWithColons=True, hmsdms=False, delimiter=', ',
              prependEquinox=False, hmdm=False):
    """
    Convert a position in RA/Dec from radians to sexagesimal string which
    is comma-delimited, e.g. '20:10:49.01, +057:17:44.806'.
    The position can either be entered as scalars via the 'ra' and 'dec' 
    parameters, as a tuple via the 'ra' parameter, as an array of shape (2,1)
    via the 'ra' parameter, or
    as an imfit dictionary can be passed via the 'imfitdict' argument, and the
    position of component 0 will be displayed in RA/Dec sexagesimal.
    replaceDecDotsWithColons: replace dots with colons as the Declination d/m/s delimiter
    hmsdms: produce output of format: '20h10m49.01s, +057d17m44.806s'
    hmdm: produce output of format: '20h10m49.01, +057d17m44.806' (for simobserve)
    delimiter: the character to use to delimit the RA and Dec strings output
    prependEquinox: if True, insert "J2000" before coordinates (i.e. for clean or simobserve)
    Todd Hunter
    """
#    print "rad2radec: type(ra) = ", type(ra)
    if (type(imfitdict) == dict):
        comp = 'component%d' % (component)
        ra  = imfitdict['results'][comp]['shape']['direction']['m0']['value']
        dec = imfitdict['results'][comp]['shape']['direction']['m1']['value']
    if (type(ra) == tuple or type(ra) == list or type(ra) == np.ndarray):
        if (len(ra) == 2):
            dec = ra[1] # must come first before ra is redefined
            ra = ra[0]
        else:
            ra = ra[0]
            dec = dec[0]
    if (np.shape(ra) == (2,1)):
        dec = ra[1][0]
        ra = ra[0][0]
    if (not casaAvailable):
        if (ra<0): ra += 2*pi
        rahr = ra*12/np.pi
        decdeg = dec*180/np.pi
        hr = int(rahr)
        min = int((rahr-hr)*60)
        sec = (rahr-hr-min/60.)*3600
        if (decdeg < 0):
            mysign = '-'
        else:
            mysign = '+'
        decdeg = abs(decdeg)
        d = int(decdeg)
        dm = int((decdeg-d)*60)
        ds = (decdeg-d-dm/60.)*3600
        mystring = '%02d:%02d:%08.5f, %c%02d:%02d:%08.5f' % (hr,min,sec,mysign,d,dm,ds)
    else:
        myqa = createCasaTool(qatool)
        myra = myqa.formxxx('%.12frad'%ra,format='hms',prec=prec+1)
        mydec = myqa.formxxx('%.12frad'%dec,format='dms',prec=prec-1)
        if replaceDecDotsWithColons:
            mydec = mydec.replace('.',':',2)
        if (len(mydec.split(':')[0]) > 3):
            mydec = mydec[0] + mydec[2:]
        mystring = '%s, %s' % (myra, mydec)
        myqa.done()
    if (hmsdms):
        mystring = convertColonDelimitersToHMSDMS(mystring)
        if (prependEquinox):
            mystring = "J2000 " + mystring
    elif (hmdm):
        mystring = convertColonDelimitersToHMSDMS(mystring, s=False)
        if (prependEquinox):
            mystring = "J2000 " + mystring
    if (delimiter != ', '):
        mystring = mystring.replace(', ', delimiter)
    if (verbose):
        print mystring
    return(mystring)

def convertColonDelimitersToHMSDMS(mystring, s=True, usePeriodsForDeclination=False):
    """
    Converts HH:MM:SS.SSS, +DD:MM:SS.SSS  to  HHhMMmSS.SSSs, +DDdMMmSS.SSSs
          or HH:MM:SS.SSS +DD:MM:SS.SSS   to  HHhMMmSS.SSSs +DDdMMmSS.SSSs
          or HH:MM:SS.SSS, +DD:MM:SS.SSS  to  HHhMMmSS.SSSs, +DD.MM.SS.SSS
          or HH:MM:SS.SSS +DD:MM:SS.SSS   to  HHhMMmSS.SSSs +DD.MM.SS.SSS
    s: whether or not to include the trailing 's' in both axes
    -Todd Hunter
    """
    colons = len(mystring.split(':'))
    if (colons < 5 and (mystring.strip().find(' ')>0 or mystring.find(',')>0)):
        print "Insufficient number of colons (%d) to proceed (need 4)" % (colons-1)
        return
    if (usePeriodsForDeclination):
        decdeg = '.'
        decmin = '.'
        decsec = ''
    else:
        decdeg = 'd'
        decmin = 'm'
        decsec = 's'
    if (s):
        outstring = mystring.strip(' ').replace(':','h',1).replace(':','m',1).replace(',','s,',1).replace(':',decdeg,1).replace(':',decmin,1) + decsec
        if (',' not in mystring):
            outstring = outstring.replace(' ', 's ',1)
    else:
        outstring = mystring.strip(' ').replace(':','h',1).replace(':','m',1).replace(':',decdeg,1).replace(':',decmin,1)
    return(outstring)

def rad2direction(rad):
    """
    Convert a 2-element list of RA,Dec in radians into a direction dictionary suitable
    to substitute for the result of a call to me.direction().
    Todd Hunter
    """
    rarad, decrad = rad
    direction = {'m0':{'unit':'rad', 'value': rarad}, 
                 'm1':{'unit':'rad', 'value': decrad}, 
                 'refer':'J2000', 
                 'type': 'direction'}
    return(direction)
    
def radec2direction(radecstring):
    """
    Convert a sexagesimal string into a direction dictionary suitable
    to substitute for the result of a call to me.direction().
    The string can be either comma or space delimited.
    The dec portion of the string can be either : or . delimited.
    Todd Hunter
    """
    rarad, decrad = radec2rad(radecstring)
    direction = {'m0':{'unit':'rad', 'value': rarad}, 
                 'm1':{'unit':'rad', 'value': decrad}, 
                 'refer':'J2000', 
                 'type': 'direction'}
    return(direction)

def directionList2radecDegrees(directionList):
    """
    Converts a list of CASA direction dictionaries into a list of ra,dec values in degrees.
    Todd Hunter
    """
    ra = []
    dec = []
    for d in directionList:
        radeg, decdeg = radec2deg(direction2radec(d))
        ra.append(radeg)
        dec.append(decdeg)
    return(ra,dec)
    
def direction2radec(direction=None, prec=5, hmsdms=False):
    """
    Convert a direction dictionary to a sexagesimal string of format:
    HH:MM:SS.SSSSS, +DDD:MM:SS.SSSSSS
    hmsdms: if True, then output format is HHhMMmSS.SSSs, +DDDdMMmSS.SSSs
    Todd Hunter
    """
    ra  = direction['m0']['value']
    dec = direction['m1']['value']
    mystring = '%s, %s' % (qa.formxxx('%.12frad'%ra,format='hms',prec=prec),
                           qa.formxxx('%.12frad'%dec,format='dms',prec=prec).replace('.',':',2))
    if (hmsdms):
        mystring = convertColonDelimitersToHMSDMS(mystring)
    return(mystring)
    
def direction2rad(direction):
    """
    Convert a direction dictionary to a 2-element list in radians.
    Todd Hunter
    """
    ra  = direction['m0']['value']
    dec = direction['m1']['value']
    return([ra,dec])
    
def direction2radecForSimobserve(direction=None, prec=5):
    """
    Convert a direction dictionary to a sexagesimal string that simobserve expects.
    Todd Hunter
    """
    ra  = direction['m0']['value']
    dec = direction['m1']['value']
    epoch = direction['refer']
    rastring = qa.formxxx('%.12frad'%ra,format='hms',prec=prec)
    rastring = '%sh%sm%ss' % (rastring[0:2], rastring[3:5], rastring[6:])
    decstring = qa.formxxx('%.12frad'%dec,format='dms',prec=prec).replace('.',':',2)
    decstring = '%sd%sm%ss' % (decstring[0:4], decstring[5:7], decstring[8:])
    mystring = '%s %s %s' % (epoch, rastring, decstring)
    return(mystring)

def parseSSSerror(s, body):
    if (s == 0):
        return('success')
    elif (s==1):
        return ('Error: unsupported body (%s)'%body)
    elif (s==2):
        return ('Error: unsupported frequency or time for body (%s)'%(body))
    elif (s==3):
        return ('Error: Tb model file not found (%s)'%(body))
    elif (s==4):
        return ('Error: ephemeris table not found (%s), or time out of range (note - the case where the MJD times span two ephemeris files is not supported' % (body))
    else:
        return('Error: unknown error code')
    

def call_solar_system_fd(body, MJDs, frequencies, observatory='ALMA', verbose=False):
    """
    This is a wrapper to call Bryan Butler's function, which requires a
    different number of parameters depending on whether you are using
    casa version <4.0 or  4.0 or 4.1.
    -Todd Hunter
    """
    if (casadef.casa_version >= '4.1.0'):
        sss2 = sss.solar_system_setjy()
        if (verbose):
            print "Calling sss.solar_system_setjy.solar_system_fd(sss2, '%s', %s, %s, '%s', casalog)" % (body, MJDs, frequencies, observatory)
        if (len(frequencies) == 3):
            freqs = []
            freqGHz = []
            fluxdensity = []
            for f in np.arange(frequencies[0], frequencies[1], frequencies[2]):
                freqs.append([f,f+frequencies[2]])
                freqGHz.append(np.mean(freqs[-1])*1e-9)
            print "Calling sss.solar_system_setjy.solar_system_fd with %d frequency bins of width=%gMHz" % (len(freqs),frequencies[2]*1e-6)
            print "This will take about %d seconds on a decent machine. Use bandwidth parameter to adjust." % (len(freqs)/100)
            result = sss.solar_system_setjy.solar_system_fd(sss2, body, MJDs, freqs,
                                                            observatory, casalog)
            (status,flux,uncertainty,size,direction) = result
            for fl in flux[0]:
                fluxdensity.append(fl)
            return(freqGHz, fluxdensity)
        else:
            result = sss.solar_system_setjy.solar_system_fd(sss2, body, MJDs, frequencies,
                                                            observatory, casalog)
        if (verbose):
            print "Done"
    elif (casadef.casa_version >= '4.0.0'):
        if (verbose):
            print "Calling sss.solar_system_fd('%s', %s, %s, '%s', casalog)" % (body, MJDs, frequencies, observatory)
        result = sss.solar_system_fd(body, MJDs, frequencies,
                                     observatory, casalog)
        if (verbose):
            print "Done"
    else:
        if (verbose):
            print "Calling sss.solar_system_fd('%s', %s, %s)" % (body, MJDs, frequencies)
        result = sss.solar_system_fd(body, MJDs, frequencies)
        if (verbose):
            print "Done"
    (status,flux,uncertainty,size,direction) = result        
    return(status,flux,uncertainty,size,direction)

def diskCouplingFromDiameters(diskDiameter, beamDiameter):
    return(diskCoupling(diskDiameter**2, beamDiameter**2))

def diskCoupling(diskArea, beamArea):
    """
    Equation C.20 of NRAO 12m user manual
    Can use this to estimate apparent brightness temperature from planet temperature,
    planet size, and beam size.
    """
    return(1-np.exp(-(diskArea/beamArea)*np.log(2.0)))

def getModelPlanetFromVis(vis):
    """
    Finds the first planet with a CASA model in a measurement set.
    """
    fields = getFields(vis)
    fieldsUpperCase = [x.upper() for x in fields]
    checkObjects = predictCompBodies
    body = None
    for object in checkObjects:
        if (object in fieldsUpperCase):
            body = object
            break
    return(body)

def diffPlanetModels(body, newmodel, frequnit='wavenumber', k='linear'):
    """
    Plots the difference between two planetary body brightness temperature models.
    body: name of body to search for in existing CASA repository
    newmodel: filename containing a new model
    frequnit: units for first column in newmodel ('GHz' or 'wavenumber')
              (second column should be K)
    k: interpolation type to use when resampling the curves
    -Todd Hunter
    """
    if (not os.path.exists(newmodel)):
        print "Could not find ", newmodel
        return
    repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/SolarSystemModels/*"
    files = glob.glob(repotable)
    bodyfile = ''
    for f in files:
        if (f.lower().find(body.lower())>=0):
            bodyfile = f
            break
    if (len(bodyfile) < 1):
        print "Could not find file for %s in SolarSystemModels" % (body)
        return
    f = open(bodyfile,'r')
    freq = []
    temp = []
    for line in f.readlines():
        tokens = line.split()
        if (len(tokens) < 2): continue
        freq.append(float(tokens[0]))
        temp.append(float(tokens[1]))
    f.close()
    newfreq = []
    newtemp = []
    f = open(newmodel,'r')
    for line in f.readlines():
        tokens = line.split()
        if (len(tokens) < 2): continue
        newfreq.append(float(tokens[0]))
        if (frequnit.lower() == 'wavenumber'):
            newfreq[-1] *= c_mks/10000000.
        elif (frequnit.lower() != 'ghz'):
            print "Unrecognized freq unit (must be GHz or wavenumber)"
            return
        newtemp.append(float(tokens[1]))
    f.close()
    xaxis, f1, f2 = alignFunctions(freq, temp, newfreq, newtemp, k=k)
    pb.clf()
    ax = pb.subplot(211)
    pb.loglog(freq, temp, 'k.', mec='k', ms=7)
    pb.hold(True)
    pb.loglog(newfreq, newtemp,'r.', mec='r', ms=7)
    pb.ylabel('Temperature (K)')
    pb.xlim([np.min(freq),np.max(freq)])
    pb.ylim([np.min([np.min(temp),np.min(newtemp)]), np.max([np.max(temp),np.max(newtemp)])])
    pb.xticks([100,200,300,500,700,1000], [100,200,300,500,700,1000])
    pb.yticks([60,80,100,120,140], [60,80,100,120,140])
    ax.xaxis.grid(True,which='major')
    ax.yaxis.grid(True,which='major')
    pb.legend((os.path.basename(bodyfile), os.path.basename(newmodel)), numpoints=1, prop={'size':10})
    pb.title('old:%s vs. new:%s' % (os.path.basename(bodyfile),os.path.basename(newmodel)))

    ax2 = pb.subplot(212)
    diff = np.abs(100*(f1-f2)/f1)
    pb.loglog(xaxis, diff, 'k.-')
    pb.xlim([np.min(xaxis),np.max(xaxis)])
    majorFormatter = matplotlib.ticker.FormatStrFormatter('%g')
    pb.xticks([100,200,300,500,700,1000], [100,200,300,500,700,1000])
    ax.xaxis.set_major_formatter(majorFormatter)
    ax.yaxis.set_major_formatter(majorFormatter)
    ax2.xaxis.set_major_formatter(majorFormatter)
    ax2.yaxis.set_major_formatter(majorFormatter)
    ax2.xaxis.grid(True,which='major')
    ax2.yaxis.grid(True,which='major')
    pb.xlabel('Frequency (GHz)')
    pb.ylabel(r'$\Delta$T (old-new)/old (%)')
    png = 'diffPlanetModels.%s.png'%body
    pb.savefig(png)
    print "plot left in ", png

def planetTemperature(body='', frequency=None, angularDiameter=None, vis=None,
                      date='', intent='OBSERVE_TARGET#ON_SOURCE',
                      efficiency=None, spw=None, beamFwhm=None,
                      beamFwhmFactor=1.13, telescopeDiameter=12,
                      useJPL=True, surfaceRms=25, temperature=None):
    """
    Estimates the expected antenna temperature of a planet based on its model
    radiative temperature in CASA, the observed frequency and angular diameter
    at a specific date of observation.
    planet: one of /usr/lib64/casapy/data/alma/SolarSystemModels/*_Tb.dat
    frequency: observed frequency (Hz, GHz, or a string with units)
    angularDiameter: of body in arcsec (if not specified, get it from JPL)
    vis: measurement set to consult for planet name and date
    date: date of observation
    intent: the observing intent to use to search for spws to use if vis is specified but spw is not
    efficiency: antenna efficiency (on a scale from 0 to 1.0),
                 if None: then use au.antennaEfficiency() with surfaceRms
    spw: the spw to use if vis is specified
    beamFwhm: the beamsize to use instead of 1.13 lambda/D
    beamFwhmFactor: the coefficient (C) to use in C*lambda/D
    telescopeDiameter: telescope diameter (meters)
    surfaceRms: in microns, only used if efficiency==None
    temperature: use the specified temperature, rather than CASA table
    """
    if (vis == None):
        if (frequency==None):
            print "Must give either vis or frequency"
            return
        if (body==''):
            print "Must give either vis or frequency"
            return
    elif (os.path.exists(vis) == False):
        print "Cannot find measurement set = ", vis
        return
    if (frequency==None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        if (spw == None):
            spws = np.intersect1d(mymsmd.spwsforintent(intent), getNonWvrSpws(mymsmd))
            if (len(spws) < 1):
                print "planetTemperature(): No spws with %s intent" % (intent)
                return
            spw = spws[0]
        frequency = mymsmd.meanfreq(int(spw))
        mymsmd.close()
    if (body==''):
        body = getModelPlanetFromVis(vis)
        if (body==''):
            print "No valid bodies with models found in measurement set."
            return
    if (type(frequency)==str):
        frequency = parseFrequencyArgument(frequency)
    elif (frequency < 10000):
        frequency *= 1e9
    frequencyGHz = frequency * 1e-9
    if (temperature == None):
        planetDir = os.getenv("CASAPATH").split()[0]+"/data/alma/SolarSystemModels"
        filelist = glob.glob(planetDir+"/*_Tb.dat")
        myfile = None
        for f in filelist:
            if (f.upper().find(body.upper()) >= 0):
                myfile = f
        if (myfile == None):
            print "There is no model for this object in CASA."
            return
        f = open(myfile,'r')
        ghz = []
        kelvin = []
        for i,line in enumerate(f.readlines()):
            if (body.lower() == 'mars'):
                if (i==0):
                    marsFreqsGHz = [float(j) for j in line.split()]
                else:
                    tokens = line.split()
                    ghz = np.array(marsFreqsGHz)
                    lowerindex = np.where(ghz<=frequencyGHz)[0][-1]
                    upperindex = np.where(ghz>=frequencyGHz)[0][0]
                    kelvin = []
                    for t in tokens[5:]:
                        kelvin.append(float(t))
                    lineDate = tokens[0]+'-'+tokens[1]+'-'+tokens[2]
                    if (lineDate > date):
                        print "Using Mars model for %s, and interpolating between %f and %f GHz" % (lineDate, ghz[lowerindex],ghz[upperindex])
                        break
            else:
                a,b = line.strip().split()
                ghz.append(float(a))
                kelvin.append(float(b))
        f.close()
        if (body.lower() != 'mars'):
            # simply find the closest entry (for now)
            fdiff = list(abs(np.array(ghz) - frequencyGHz) )
            index = fdiff.index(min(fdiff))
            Tplanet = kelvin[index]
        else:
            Tplanet = (kelvin[upperindex]*(frequencyGHz-ghz[lowerindex]) + kelvin[lowerindex]*(ghz[upperindex]-frequencyGHz))/(ghz[upperindex]-ghz[lowerindex])
    else:
        Tplanet = temperature
    if (angularDiameter == None):
        if (vis is not None):
            data1 = planet(vis=vis, useJPL=useJPL)
            angularDiameter = data1['angularDiameter']
        elif (date != ''):
            data1 = planet(body, date=date, useJPL=useJPL)
            angularDiameter = data1['angularDiameter']
        else:
            print "No angularDiameter (or date) defined for the body."
            return
        print "Angular diameter of %s = %.3f arcsec" % (body,angularDiameter)
    planetArea = np.pi*(angularDiameter*0.5)**2
    if (beamFwhm==None):
        beam = primaryBeamArcsec(frequency=frequencyGHz,
                                 diameter=telescopeDiameter,
                                 fwhmfactor=beamFwhmFactor)
        if (beam == None): return
    else:
        beam = beamFwhm
    print "telescope Gaussian beam FWHM at %.1f GHz = %.3f arcsec" % (frequencyGHz, beam)
    beamArea = np.pi*(beam*0.5)**2 
    coupling = diskCoupling(planetArea,beamArea)
    print "coupling factor between %.3f arcsec disk and Gaussian beam = %f" % (angularDiameter, coupling)
    if (efficiency == None):
        efficiency = antennaEfficiency(frequency, surfaceRms)
    print "antenna efficiency assumed = %f" % (efficiency)
    Tb = Tplanet * coupling * efficiency
    print "%s model temperature = %.3f K" % (body,Tplanet)
    print "expected single-dish brightness temperature = %.3f K" % (Tb)
    if (date != ''):
        fluxDensity = planetFlux(body,date=date,frequency=frequency,vis=vis,
                                 spw=spw)['fluxDensity']
        print "total planet flux = %f Jy" % (fluxDensity)
        print "total flux / expected Tb = %f Jy/K (assuming no image regridding)" % (fluxDensity/Tb)
    else:
        print "To get flux density, provide the date parameter"
    return(Tb)

def bandwidthsForField(vis, field):
    """
    Uses the msmd tool to find the bandwidths for the spws used to observe the
    specified field name.
    field: integer ID or string ID or string name of a single field
    Returns: a list of bandwidths (in Hz)
    """
    spws = spwsforfield(vis, field)
    if (spws == None): return
    print "spws = ", spws
    if (len(spws) == 0): return(spws)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    bws = mymsmd.bandwidths(spws)
    mymsmd.close()
    return(bws)

def planetFlux(body='', date=None, mjd=None, frequency=345e9, bandwidth=1e6, 
               dayIncrement=1.0,plotfile=None,verbose=False, observatory='ALMA',
               timeUnits='MJD', rotation=60, fontsize=8, hspace=0.4, bottom=0.2,
               vis=None, spw=None, separation=False, secondFrequency=None,
               showRADec=False, decrange=0, rarange=0):
    """
    A wrapper for testing Bryan Butler's solar_system_fd() function.
    Makes a plot of flux density vs. time,  or vs. frequency if a range of dates
    or frequencies is requested.

    Parameters:
    body: To see the list of supported planets, type help(au.sss.solar_system_fd)
    mjd: default=now; otherwise, a single value or a list of 1 or 2 MJDs (2 = a range)
    date: string of format: 2011/10/15, 2011/10/15 05:00:00, or 2011/10/15-05:00:00
    frequency: a single value or string with units, or a list of 1 or 2 frequencies in Hz
              (a list of 2 is interpreted as a range)
    bandwidth: define the bandwidth at a single frequency or the increment for
               the range (in Hz): floating point, or string with units
    dayIncrement: define the MJD increment for the plot
    plotfile: specify the output png name, None=use default name
    timeUnits: when x-axis is time, set the units: 'MJD' (default) or 'YMD'
    rotation: the angle of the x-axis tick labels (for timeUnits='YMD')
    fontsize: the font size of the x-axis tick labels (for timeUnits='YMD')
    hspace: the hspace value for pylab.subplots_adjust (for timeUnits='YMD')
    wspace: the wspace value for pylab.subplots_adjust (for timeUnits='YMD')
    vis: the name of an ms from which to grab the start time and body name
    spw: the spw for which to use the mean frequency instead of the frequency parameter
    separation: if True, then for Jovian moons or Titan, compute separations
    secondFrequency: if specified, then a plot of flux vs. time will be a flux1/flux2 ratio
    showRADec: if True, make a second plot of the RA and Dec vs. time
    decrange: half of the y-axis range to use when plotting Dec
    rarange: half of the y-axis range to use when plotting RA
    
    Return value:
        if a plot is computed: nothing, unless showRADec is True, in which case
              RA and Dec are returned as separate arrays in degrees
        if single value computed:  a dictionary containing the following keys and units:
          {'fluxDensity': Jy, 'direction', 'majorAxis': arcsec, 'minorAxis': arcsec,
          'positionAngle': deg, 'frequency': [Hz,Hz], 'bandwidth': Hz, 'body': name,
          'meanFrequency': Hz}

    Example: plot Neptune's flux density in ALMA Band 7:
      au.planetFlux('Neptune',mjd=55600, frequency=[275e9,373e9], bandwidth=1e9)

    - Todd Hunter
    """
    if (body[-3:] == '.ms'):
        print "If you want to specify an ms, use the vis parameter."
        return
    timeUnitsAllowed = ['MJD','YMD']
    data1 = None
    if (mjd==None and date==None):
        if (vis==None):
            # use current MJD
            mjd = getMJD()
            date = mjdToUT(float(mjd))
            print "No MJD or date specified, assuming right now=%s." % (date)
        else:
            date = getObservationStartDate(vis).split(' UT')[0]
    if (useSolarSystemSetjy == False):
        print "This version of CASA does not contain the solar_system_setjy module."
        return
    bandwidth = parseFrequencyArgumentToHz(bandwidth)
    if (type(frequency) != list):
        if (type(frequency) == str):
            frequency = [[parseFrequencyArgumentToHz(frequency)-0.5*bandwidth,
                          parseFrequencyArgumentToHz(frequency)+0.5*bandwidth]]
        else: # it's an int or float
            frequency = [[parseFrequencyArgumentToHz(frequency)-0.5*parseFrequencyArgumentToHz(bandwidth),
                          parseFrequencyArgumentToHz(frequency)+0.5*parseFrequencyArgumentToHz(bandwidth)]]
    elif (type(frequency[0]) != list):
        if (len(frequency) == 1):
            frequency = [[frequency[0]-0.5*bandwidth, frequency[0]+0.5*bandwidth]]
        else:
            frequency = [frequency]
    elif (len(frequency[0]) == 1):
        frequency = [[frequency[0][0]-0.5*bandwidth,frequency[0][0]+0.5*bandwidth]]
    if (secondFrequency is not None):
        if (type(secondFrequency) != list):
            if (type(secondFrequency) == str):
                secondFrequency = [[parseFrequencyArgumentToHz(secondFrequency)-0.5*bandwidth,
                              parseFrequencyArgumentToHz(secondFrequency)+0.5*bandwidth]]
            else: # it's an int or float
                secondFrequency = [[parseFrequencyArgumentToHz(secondFrequency)-0.5*parseFrequencyArgumentToHz(bandwidth),
                              parseFrequencyArgumentToHz(secondFrequency)+0.5*parseFrequencyArgumentToHz(bandwidth)]]
        elif (type(secondFrequency[0]) != list):
            if (len(secondFrequency) == 1):
                secondFrequency = [[secondFrequency[0]-0.5*bandwidth, secondFrequency[0]+0.5*bandwidth]]
            else:
                secondFrequency = [secondFrequency]
        elif (len(secondFrequency[0]) == 1):
            secondFrequency = [[secondFrequency[0][0]-0.5*bandwidth,secondFrequency[0][0]+0.5*bandwidth]]


    if (vis is not None and spw is not None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        if (spw >= mymsmd.nspw()):
            print "spw not in ms.  Available = ", range(mymsmd.nspw())
            return
        try:
            bandwidth = mymsmd.bandwidths(int(spw))  # This is a fairly new function
        except:
            bandwidth = mymsmd.chanwidths(int(spw))[0] * mymsmd.nchan(int(spw))
        frequency = [[mymsmd.meanfreq(int(spw))-0.5*bandwidth, mymsmd.meanfreq(int(spw))+0.5*bandwidth]]
        mymsmd.close()
    if (verbose):
        print "frequency = ", frequency
    if (date is not None):
        if (type(date) == list):
            mjd1 = dateStringToMJD(date[0],verbose=False)
            if (mjd1 == None):
                return
            if (len(date) > 1):
                mjd2 = dateStringToMJD(date[1],verbose=False)
                if (mjd2 == None):
                    return
                mjd = [mjd1,mjd2]
            else:
                mjd = [mjd1]
        else:
            if (len(date.split('-')) > 3):
                # This is needed to accept 2010-01-01-12:00:00'
                # by making it look like 2010-01-01 12:00:00'
                date = date[0:10] + ' ' + date[11:]
            mjd = dateStringToMJD(date,verbose=False)
            if (mjd == None):
                return
    if (body==''):
        if (vis == None):
            print "Must specify either a body or a vis"
            return
        if (os.path.exists(vis) == False):
            print "Could not find measurement set"
            return
        body = getModelPlanetFromVis(vis)
        if (body==None):
            print "No valid bodies with models found in measurement set."
            return
    if (type(mjd) != list):
        mjd = [float(mjd)]
    if ((frequency[0][1]-frequency[0][0]) <= bandwidth):
        if (len(mjd) == 1):
            if (verbose):
                print "Calling call_solar_system_fd(%s, MJDs=%s, frequencies=%s, observatory='%s')" % (body,str(mjd),str(frequency),observatory)
            (status,flux,uncertainty,size,direction) = call_solar_system_fd(body, MJDs=mjd, frequencies = frequency, observatory=observatory)
            if (verbose):
                print "Done"
            if (status[0][0] == 0):
                # Just print the flux density
                if (verbose):
                    print "Flux density at %.3f GHz averaged over a %.3f GHz bandwidth is %f Jy." % (np.mean(frequency[0])*1e-9, (frequency[0][1]-frequency[0][0])*1e-9, flux[0][0])
                    print "J2000 Position = %s" % (direction2radec(direction[0]))
                    print "size = ", size
                mydict = {'fluxDensity': flux[0][0], 'direction': direction[0], 'majorAxis': size[0][0],
                          'minorAxis': size[0][1], 'positionAngle': size[0][2], 'frequency': frequency[0],
                          'bandwidth': bandwidth, 'body': body, 'meanFrequency': np.mean(frequency[0])}
            else:
                print parseSSSerror(status[0][0],body)
                return
        else:
            # Make a plot of flux and major axis vs. time
            if (timeUnits not in timeUnitsAllowed):
                print "timeUnits must be one of: %s" % (str(timeUnitsAllowed))
                return
            if (mjd[0] >= mjd[1]):
                print "The start MJD must be earlier than the end MJD."
                return
            mjd = np.arange(mjd[0], mjd[1], float(dayIncrement))
            if (body.lower()=='mars'):
                timeEstimate = len(mjd)*3/2
                if (secondFrequency is not None): timeEstimate = len(mjd)*3
                print "On a decent machine, this will take about %d seconds" % (timeEstimate)
            (status,flux,uncertainty,size,direction) = call_solar_system_fd(body, MJDs=mjd, frequencies = frequency, observatory=observatory, verbose=verbose)
            if (secondFrequency is not None):
                (status,fluxdensitySecond,uncertaintySecond,size,direction) = \
                    call_solar_system_fd(body, MJDs=mjd, frequencies=secondFrequency, observatory=observatory)
                flux = np.array(flux)/np.array(fluxdensitySecond)
            if (status[0][0] != 0):
                print parseSSSerror(status[0][0],body)
                return
            pb.clf()
            adesc = pb.subplot(211)
            flux = [item for sublist in flux for item in sublist]
            # should have option to use pb.plot_date
            if (timeUnits == 'MJD'):
                pb.plot(mjd, flux, 'b-')
                pb.xlabel('Date (MJD)')
                adesc.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))
            else:
                pb.subplots_adjust(hspace=hspace, bottom=bottom)
                pb.plot_date(pb.date2num(mjdListToDateTime(mjd)),flux,'b-')
                pb.xlabel('Date')
                pb.setp(pb.xticks()[1], rotation=rotation, fontsize=fontsize)
            adesc.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))
            if (secondFrequency is not None):
                pb.ylabel('Flux density ratio')
                pb.title(body+' at %.3f/%.3f GHz (BW=%.3fGHz)'%(np.mean(frequency[0])*1e-9, 
                                                                np.mean(secondFrequency[0])*1e-9, 
                                                                bandwidth*1e-9))
            else:
                pb.ylabel('Flux density (Jy)')
                pb.title(body+' at %.3f GHz (BW=%.3fGHz)'%(np.mean(frequency[0])*1e-9, bandwidth*1e-9))
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')

            adesc = pb.subplot(212)
            majoraxis = np.transpose(size)[0]
            if (timeUnits == 'MJD'):
                pb.plot(mjd, majoraxis, 'b-')
                pb.xlabel('Date (MJD)')
                adesc.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))
            else:
                pb.plot_date(pb.date2num(mjdListToDateTime(mjd)),majoraxis,'b-')
                pb.xlabel('Date')
                pb.setp(pb.xticks()[1], rotation=rotation, fontsize=fontsize)
            pb.ylabel('Major axis (arcsec)')
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            if (plotfile == None):
                if (secondFrequency == None):
                    plotfile = body+'.fluxvstime.%gGHz.%d-%d.png'%(np.mean(frequency[0])*1e-9,mjd[0],mjd[-1])
                else:
                    plotfile = body+'.fluxratiovstime.%gGHz.%gGHz.%d-%d.png'%(np.mean(frequency[0])*1e-9,np.mean(secondFrequency[0])*1e-9,mjd[0],mjd[-1])
            pb.savefig(plotfile)
            print "Plot left in ", plotfile
            pb.draw()
            if (showRADec):
                pb.clf()
                adesc = pb.subplot(211)
                ra, dec = directionList2radecDegrees(direction)
                pb.plot(mjd, ra, 'b.-')
                yFormatter = ScalarFormatter(useOffset=False)
                adesc.yaxis.set_major_formatter(yFormatter)
                adesc.xaxis.set_major_formatter(yFormatter)
                adesc.xaxis.grid(True,which='major')
                adesc.yaxis.grid(True,which='major')
                pb.ylabel('Right Ascension (degrees)')
                if (rarange > 0):
                    pb.ylim([np.mean(ra)-rarange, np.mean(ra)+rarange])
                pb.title(body + ' (%s to %s)'%(mjdToUT(mjd[0]),mjdToUT(mjd[-1])))
                
                adesc = pb.subplot(212)
                pb.plot(mjd, dec, 'b.-')
                adesc.yaxis.set_major_formatter(yFormatter)
                adesc.xaxis.set_major_formatter(yFormatter)
                adesc.xaxis.grid(True,which='major')
                adesc.yaxis.grid(True,which='major')
                pb.ylabel('Declination (degrees)')
                pb.xlabel('Date (MJD)')
                if (decrange > 0):
                    pb.ylim([np.mean(dec)-decrange, np.mean(dec)+decrange])
                plotfile = plotfile.replace('.fluxvstime','.radec')
                print "RA,Dec plot left in ", plotfile
                pb.savefig(plotfile)
                return(np.array(ra),np.array(dec))
            else:
                return
    elif (len(mjd) < 7):
        # Make a plot of flux vs. frequency
        mjdstring = ''
        colors = ['k','b','r','g','c','m']
        pb.clf()
        adesc = pb.subplot(111)
        for i in range(len(mjd)):
            mymjd = mjd[i]
            if (mjdstring != ''): mjdstring += ', '
            if ((frequency[0][1]-frequency[0][0])/bandwidth > 10000):
                print "You are asking for over 10000 channels of width %f Hz.  Aborting" % (bandwidth)
                return
            (freqGHz, fluxdensity) = call_solar_system_fd(body, MJDs=[mymjd], 
                                                          frequencies=[frequency[0][0], frequency[0][1], bandwidth], 
                                                          observatory=observatory)
            pb.plot(freqGHz, fluxdensity, '%s-'%(colors[i]))
            mjdstring += '%.1f' % (mymjd)
            if (len(mjd) > 1):
                pb.text(0.04,0.94-0.04*i, '%.1f = %s'%(mymjd,mjdToUT(mymjd).split()[0]),color=colors[i],transform=adesc.transAxes,size=10)
            pb.hold(True)
        pb.xlabel('Frequency (GHz) (channel width = %g MHz)'%(bandwidth*1e-6))
        pb.ylabel('Flux density (Jy)')
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        pb.title(body+' at MJD=%s'%(mjdstring))
        if (plotfile == None):
            plotfile = body+'.fluxvsfreq.%d-%dGHz.png'%(int(freqGHz[0]),int(freqGHz[-1]))
        pb.savefig(plotfile)
        print "Plot left in ", plotfile
        pb.draw()
        return
    else:
        print "More than 6 MJDs and multiple frequencies are not supported."
        return
    if (separation):
        jovianMoons = ['ganymede','callisto','io','europa']
        if (body.lower() == 'titan'):
            if (data1 == None):
                data1 = planet(body, date=date, observatory=observatory, useJPL=True, 
                               verbose=verbose, vis=vis, mjd=mjd)
            data2 = planet('Saturn', date=date, observatory=observatory, useJPL=True, 
                           verbose=verbose,vis=vis,mjd=mjd)
            rad = angularSeparationRadians(data1['directionRadians'][0], 
                                           data1['directionRadians'][1], 
                                           data2['directionRadians'][0], 
                                           data2['directionRadians'][1])
            print "Separation with Saturn = %g rad = %g deg = %g arcsec" % (rad, rad*180/math.pi, rad*3600*180/math.pi)
        elif (body.lower() in jovianMoons):
            if (data1 == None):
                data1 = planet(body, date=date, observatory=observatory, useJPL=True, 
                               verbose=verbose, vis=vis, mjd=mjd)
            jovianMoons.remove(body.lower())
            for otherBody in ['Jupiter']+jovianMoons:
                data2 = planet(otherBody, date=date,observatory=observatory,useJPL=True, 
                               verbose=verbose,vis=vis,mjd=mjd)
                rad = angularSeparationRadians(data1['directionRadians'][0], 
                                               data1['directionRadians'][1], 
                                               data2['directionRadians'][0], 
                                               data2['directionRadians'][1])
                print "Separation with %s = %g rad = %g deg = %g arcsec" % (otherBody, rad, rad*180/math.pi, rad*3600*180/math.pi)
    return(mydict)

def jplVsCasa(body='',date=''):
   jpl_pos = planet(body,date,useJPL=True)['directionRadians']
   casa_pos = planet(body,date,useJPL=False)['directionRadians']
   separation = angularSeparationRadiansTuples(jpl_pos,casa_pos)
   print "difference = %f radian = %f arcsec" % (separation, separation*180*3600/np.pi)
   return(separation)

def planet(body='',date='',observatory=JPL_HORIZONS_ID['ALMA'],
           verbose=False, help=False, mjd=None,
           beam='',useJPL=True, standard=defaultEphemeris, subroutine=False,
           apparent=False, vis='', bodyForScan='', scan='',
           savefig='', showplot=False, antennalist='',frequency=345.0, 
           symb=',', timeout=4, asdm=''):
    """
    This function returns the position and angular size of any Solar System
    body. If useJPL=True (default), it queries the JPL Horizons telnet server
    for exact positions as viewed from the specified observatory.
    If useJPL=False, it will first try to use the casa ephemerides
    (default='Butler-JPL-Horizons 2012').  Note that the casa tables are 
    quantized to one day. If the casa tables fail
    for any reason, it will automatically revert to using JPL's server.
    The dictionory returned is:
      data['directionRadians']
      data['angularDiameter']  (in arcsec)
      data['rateRadiansPerSecond'] (only present if useJPL=True)
      data['rangeRateKms'] (only present if useJPL=True)
      data['rangeAU'] (only present if useJPL=True)
    body: string name of Solar system body
    date: one possible format of the date string is: '2011-10-31 11:59:59'
    mjd: floating point MJD (alternative to specifying a date string)
    observatory: string name or JPL integer ID (run planet(help=True) for a list)
    beam: FWHM of the observing beam in arcsecs
    standard: the name of the ephemeris table to use (if useJPL=False)
    apparent: get the apparent coordinates rather than J2000
    vis: the name of an ms from which to grab the start time as the date
    asdm: the name of an ASDM from which to grab the start time as the date
    bodyForScan: the fieldname in vis to pick the date/time of the first scan
    scan: if not '', then use this scan number, if it is a scan on the body
    savefig: if a filename is given, then use antennalist to generate a visibility plot
    showplot: if True, then use antennalist to generate a visibility plot
    antennalist: if an antenna configuration file is given, then use this one,
          otherwise build a temporary one from the specified measurement set
    frequency: the frequency to use in predictcomp
    symb: marker symbol passed to predictcomp
    timeout: value in seconds to wait for JPL Horizons
   
    For further help and examples, run au.planet(help=True).
    -- Todd Hunter
    """
    if (help):
        print "This function returns the position and angular size of any "
        print "Solar System body for the specified date from the specified observatory."
        print "Usage: planet(solarSystemBody, date, observatory='%s', verbose=False," % (JPL_HORIZONS_ID['ALMA'])
        print "              beam='', useJPL=True, standard='%s', apparent=False)"%(defaultEphemeris)
        print "  body: string name of Solar system body"
        print "  date: one possible format of the date string is: '2011-10-31 11:59:59'"
        print "    or simply '2011-10-31' for 0:00 UT. A list of allowed formats for date"
        print "    is at:   http://ssd.jpl.nasa.gov/?horizons_doc#time"
        print "    An alternative is to specify the name of an ms."
        print "  mjd: floating point MJD (alternative to specifying a date string)"
        print "  useJPL: if False, first try the casa ephemerides.  Note that the casa tables"
        print "    are quantized to one day, and can be in error by many arcminutes. If the "
        print "    casa tables fail for any reason, it will automatically revert to using "
        print "    JPL's server.  It may require a few seconds to reach the JPL server."
        print "  observatory: Observatories can be specifed by JPL ID string, or by the "
        print "    following names:"
        for n in JPL_HORIZONS_ID:
            print "     '%s' (which will be converted to = '%s')" % (n, JPL_HORIZONS_ID[n])
        print "     '500' (which will be converted to = 'Geocentric')"
        print "  beam:  If a beam size is included (in arcsec), the expected FWHM will be"
        print "    computed using scipy.signal.convolve() of a Gaussian with a uniform disk."
        print "  apparent: False = the return values are J2000 values as seen from the specified observatory"
        print "  apparent: True = the return values are apparent values as seen from the specified observatory"
        print "  vis: the name of an ms from which to grab the start time as the date"
        print "The dictionary returned is:"
        print "  data['directionRadians']"
        print "  data['angularDiameter']"
        print "  data['rateRadiansPerSecond'] (only present if useJPL=True)"
        print "  data['rangeRateKms'] (only present if useJPL=True)"
        print "  data['rangeAU'] (only present if useJPL=True)"
        return
#    if (apparent and useJPL==False):
#        print "You cannot request apparent=True with useJPL=False. CASA contains only one coordinate set."
#        return
    if (useJPL == False and (body.lower() == 'io' or body.lower()=='europa')):
        print "WARNING: the casa ephemerides are too coarsely sampled for this rapidly moving moon!"
    if (antennalist == '' and vis=='' and asdm=='' and (showplot==True or savefig!='')):
        print "To generate a uv plot, you must either specify the name of vis or asdm or an antennalist file."
        return
    if ((showplot==True or savefig!='') and useJPL):
        print "To generate a uv plot, you must set useJPL=False."
        return
    if (antennalist != ''):
        if (os.path.exists(antennalist) == False):
            repotable=os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
            if (antennalist[-4:] != '.cfg'):
                antennalist += '.cfg'
            if (os.path.exists(repotable+antennalist) == False):
                print "Could not find antennalist file: %s" % (antennalist)
                return
    foundObservatory  = False
    if (type(frequency) == str):
        frequency = float(frequency)
    if (type(observatory) == int):
        observatory = str(observatory)
    elif (type(observatory) == str):
        if (len(observatory) < 1):
            observatory = 'ALMA'
        if (observatory.upper() == 'SMA'):
            observatory = 'MAUNAKEA'
    for n in JPL_HORIZONS_ID:
        if (n.find(observatory) >= 0 or (len(observatory)>2 and observatory.find(n) >= 0)):
            observatory = JPL_HORIZONS_ID[n]
            if (verbose):
                print "Using observatory: %s = %s" % (n, JPL_HORIZONS_ID[n])
            foundObservatory  = True
            break
    if (body[-3:] == '.ms'):
        print "If you want to specify an ms, use the vis parameter."
        return
    if (foundObservatory == False):
        if (observatory.lower().find('geocentric') >= 0):
            observatory = 500
        try:
            o = int(observatory)
            key = []
            try:
                key = find_key(JPL_HORIZONS_ID,observatory)
            except:
                if (key == []):
                    print "Using observatory: %s" % (observatory)
                else:
                    print "Using observatory: %s = %s" % (observatory,key)
                
        except:
            print "Unrecognized observatory = %s" % (observatory)
            print "For a list of codes, see http://ssd.jpl.nasa.gov/horizons.cgi#top"
            return
    if (len(date) < 1 and (vis is None or vis=='') and (asdm is None or asdm=='')):
        if (mjd == None):
            mjd = getMJD()
            date = mjdToUT(float(mjd))
            print "No date/time or visibility.ms specified, assuming right now=%s" % (date)
        else:
            date = mjdToUT(float(mjd))
    if (len(date) < 1 and asdm is not None and asdm != ''):
        mjd = getObservationStartDateFromASDM(asdm)[1]/86400.
        date = mjdToUT(mjd)
    if (vis is not None and vis != ''):
        if (os.path.exists(vis)):
            if (bodyForScan == ''):
                bodyForScan = body
            elif (body == ''):
                body = bodyForScan
            if (bodyForScan == ''):
                # then look for planet names
                fields = getFields(vis)
                fieldsUpperCase = [x.upper() for x in fields]
                checkObjects = ['MERCURY','VENUS','MARS','CERES','PALLAS','VESTA','JUPITER','SATURN',
                                'TITAN','CALLISTO','GANYMEDE','IO','EUROPA','URANUS','NEPTUNE','PLUTO']
                for object in checkObjects:
                    if (object in fieldsUpperCase):
                        bodyForScan = object
                        body = bodyForScan
                        break
                if (bodyForScan == ''):
                    print "No common planets found in the ms. You must specify the body as the first argument."
                    return
            fields = getFields(vis)
            fieldsUpperCase = [x.upper() for x in fields]
            if (bodyForScan.upper() in fieldsUpperCase):
                bodyForScan = fields[fieldsUpperCase.index(bodyForScan.upper())]
                try:
                    mymsmd = createCasaTool(msmdtool)
                    mymsmd.open(vis)
                    scans = mymsmd.scansforfield(bodyForScan)
                    usescan = scans[0]
                    if (scan != ''):
                        scan = int(scan)
                        if (scan in scans):
                            usescan = scan
                            print "Got date from scan %d on %s using msmd" % (usescan, bodyForScan)
                        else:
                            print "Scan %d is not a scan on %s" % (scan, bodyForScan)
                            print "Got date from the first scan on %s (scan %d) using msmd" % (bodyForScan, usescan)
                    else:
                        print "Got date from the first scan on %s (scan %d) using msmd" % (bodyForScan, usescan)
                    mytime = mymsmd.timesforscan(usescan)[0]
                except:
                    print "Getting date from the scan on %s using ValueMapping" % (bodyForScan)
                    vm = ValueMapping(vis)
                    scans = vm.getScansForField(bodyForScan)
                    usescan = scans[0]
                    if (scan != ''):
                        scan = int(scan)
                        if (scan in scans):
                            usescan = scan
                            print "Got date from scan %d on %s" % (usscan, bodyForScan)
                        else:
                            print "Scan %d is not a scan on %s" % (scan, bodyForScan)
                            print "Got date from the first scan on %s (scan %d)" % (bodyForScan, usescan)
                    else:
                        print "Got date from the first scan on %s (scan %d)" % (bodyForScan, usescan)
                    mytime = vm.getTimesForScan(usescan)[0]
                scan = ' from scan %d' % (usescan)
            else:
                scan = ''
                print "Did not find %s in %s" % (bodyForScan.upper(), fieldsUpperCase)
                print "Getting date from the start time of ms"
                mytime = getObservationStart(vis)
            obsdateString = mjdsecToUT(mytime)
            date = obsdateString[:-3]
            print "Got date%s: %s" % (scan,date)
            mjd = mytime/86400.
            epoch = mjdToPredictcomp(mjd)
        else:
            print "Could not open vis = %s" % (vis)
            return
    if (len(body) > 0):
        while (body[-1] == ' ' and len(body) > 0):
            body = body[0:-1]
    else:
        print "You must specify body, or vis and bodyForScan"
        return
    data = None
    try:
        if (not useJPL and body.upper() not in predictCompBodies):
            myme = createCasaTool(metool)
            myme.doframe(myme.epoch('mjd', qa.quantity(mjd,'d')))
            phasedir = myme.direction(body.upper())
            myme.doframe(phasedir)
            if apparent:
                mydir = myme.measure(phasedir,'APP')
                radec = direction2radec(mydir)
            else:
                mydir = myme.measure(phasedir,'J2000')
                radec = direction2radec(mydir)
            myme.done()
            mydict = {'directionRadians': direction2rad(mydir)}
            return mydict
        elif (useJPL==False and usePredictComp 
            and (observatory in JPL_HORIZONS_ID.keys() or
             observatory in JPL_HORIZONS_ID.values())):
            if (mjd == None):
              if (vis == ''):
                # Need to convert date string to be acceptable to predictcomp
                if (len(date.split()) == 1 and len(date.split()[0])<=10):
                    # only the date was specified, add 0h UT
                    if (verbose): print "Appending 0h"
                    epoch = date + '-00:00:00'
                elif (len(date.split()) > 1):
                    if (verbose): print "Forcing delimiter to be a -"
                    epoch = date.split()[0] + '-' + date.split()[1]
                else:
                    if (date[10] != '-' and date[10] != '/'):
                        if (verbose): print "Changing delimiter to -"
                        epoch = date[0:10] + '-' + date[11:]
                    else:
                        if (verbose): print "Format okay"
                        epoch = date
                mjd = dateStringToMJD(epoch,verbose=False)
            else:
                # convert MJD from command-line, or ms, into a date
                # string for predictcomp
                if (verbose): print "Calling mjdToPredictcomp(%f)" % (mjd)
                epoch = mjdToPredictcomp(mjd)
            if (verbose): print "Using epoch = ", epoch
            
            data = {}
            if (type(imtool) == type):   # casa 4.0.0
                print "Using casa's ephemerides for %s. These are in J2000 coordinates in this casa version (>=4.0.0)" % (body)
                myme = metool()
            else:  # casa 3.x
                print "Using casa's ephemerides for %s. Note these are in apparent coordinates in this casa version (<=3.4)." % (body)
                myme = metool.create()
            if (verbose): print "metool created"
            mepoch = myme.epoch('UTC',epoch) # This ignores the hours portion.
            result =  epoch.split()
            if (len(result) > 1):
                result = result[1].split(':')
                hours = 0
                if (len(result) > 0):
                    hours += int(result[0])
                if (len(result) > 1):
                    hours += int(result[1]) / 60.
                if (len(result) > 2):
                    hours += int(result[2]) / 3600.
                if (verbose):
                    print "Adding %f days" % (hours/24.)
                mepoch['m0']['value'] = mepoch['m0']['value'] + hours/24.
            if (antennalist == '' and (showplot or savefig!='')):
                # create a configuration file from the ms
                antennalist = '/tmp/%s.cfg'%(os.path.basename(vis))
                buildConfigurationFile(vis=vis, output=antennalist)
            if (antennalist != '' and savefig == ''):
                if (vis != ''):
                    savefig = os.path.basename(vis) + '.%s.predictcomp.png' % (body)
                else:
                    savefig = body + '.predictcomp.png'
            if (verbose):
                print "Running predictcomp('%s',standard='%s',epoch='%s', minfreq='345e9Hz', prefix='/tmp/', nfreqs=1, showplot=%s, savefig='%s', antennalist='%s')" % (body,standard,epoch,showplot,savefig,antennalist)
            dirlist = os.listdir('.')
            d = predictcomp(objname=body, standard=standard,
                            epoch=epoch, minfreq='%fGHz'%(frequency),
                            prefix='/tmp/',nfreqs=1,showplot=showplot,savefig=savefig,
                            antennalist=antennalist, symb=symb)
            if (d == None):
                print "Cannot run predictcomp if you don't have write permission in the working directory."
            if (antennalist != ''):
                print "Figure saved in %s" % (savefig)
            dirlist2 = os.listdir('.')
            # remove the .cl file created by predictcomp
            for myfile in dirlist2:
                if (myfile not in dirlist and myfile[-3:] == '.cl'):
                    os.system('rm -rf %s' % myfile)
            data['angularDiameter'] = d['shape']['majoraxis']['value']
            if (d['shape']['majoraxis']['unit'] == 'arcmin'):
                data['angularDiameter'] *= 60
            if (antennalist != ''):
                percentage = getBaselineStats(config=antennalist,
                                       angularSize=data['angularDiameter'],
                                       frequency=frequency,verbose=False)[0]
                print "Percentage of baselines shorter than this angular scale at %.1f GHz = %.3f" % (frequency,percentage)
            data['directionRadians'] = [d['shape']['direction']['m0']['value'],
                                        d['shape']['direction']['m1']['value']]
            directionDegrees = [data['directionRadians'][0]*180/math.pi,
                                data['directionRadians'][1]*180/math.pi
                                ]
            directionRadians = [d['shape']['direction']['m0']['value'],
                                d['shape']['direction']['m1']['value']]
            if (apparent):
                coords = 'Apparent Position'
            else:
                coords = 'J2000 Position'
            if (verbose): print "computeAzElFromRADecMJD is using mjd = ", mjd
            azim, elev = computeAzElFromRADecMJD(directionRadians, mjd, observatory=observatory,verbose=False)
            azim *= 180/np.pi
            elev *= 180/np.pi
            print '%s: %s, %s   Azim, Elev: %.3f, %.3f' % (coords,qa.formxxx('%.12fdeg'%directionDegrees[0],format='hms',prec=5),
                                  qa.formxxx('%.12fdeg'%directionDegrees[1],format='dms',prec=4).replace('.',':',2), azim, elev)
        else:
            if (useJPL==False and (observatory in JPL_HORIZONS_ID.keys() or observatory in JPL_HORIZONS_ID.values())
                and usePredictComp==False):
                print "Will not use casa because predictcomp module is missing."
            if (useJPL==False and usePredictComp):
                print "Will not use casa for observatory=", observatory
            raise
    except:
        fp = FixPosition()
        if (verbose or True):
            print "Contacting JPL Horizons for %s" % (body)
        data = fp.getRaDecSize(body, date, observatory, verbose, apparent, timeout)
    if (data is not None):
        if (data['angularDiameter'] != []):
            if (verbose):
                print "Angular diameter (major axis) = %f arcsec" % (data['angularDiameter'])
            if (beam != ''):
                expectedFWHM = computeExpectedFWHM(float(beam),data['angularDiameter'])
                print 'The expected FWHM with a %.2f" beam is %.2f".' % (float(beam),expectedFWHM)
            if (antennalist != ''):
                percentage = getBaselineStats(config=antennalist,
                                              angularSize=data['angularDiameter'],
                                              frequency=frequency,verbose=False)[0]
                print "Percentage of baselines shorter than this angular scale at %.1f GHz = %.3f" % (frequency,percentage)
        else:
            print "Angular diameter is not available."
    return(data)

def columnStatistics(filename, column, startline=0, delimiter=None):
    """
    Compute basic statistics on one column of an ASCII file.
    column: column number, starting at zero
    startline: starting line, starting from zero
    delimiter: the character(s) that separate columns (default is
               whitespace)
    Returns: mean, median, min, max, std, MAD*.6745, 25%ile, 75%ile
    -- Todd Hunter
    """
    f=open(filename,'r')
    x = []
    for i,line in enumerate(f.readlines()):
        if (i >= startline):
            tokens = line.split(delimiter)
            x.append(float(tokens[column]))
    percentile25 = scoreatpercentile(x, 25)
    percentile75 = scoreatpercentile(x, 75)
    print "Mean=%f, Median=%f, Min=%f, Max=%f, St.Dev=%f\nMAD*0.6745=%f, 25%%ile=%f, 75%%ile=%f" % (np.mean(x),np.median(x),np.min(x),np.max(x),np.std(x),MAD(x),percentile25,percentile75)
    return(np.mean(x),np.median(x),np.min(x),np.max(x),np.std(x),MAD(x),
           percentile25,percentile75)
    
def getxyFromFile(filename,xcol,ycol,delimiter=None,maxLines=None,
                  startAfter=None,stopAt=None,yhms=False,ydms=False,
                  returnType=False, verbose=False, degrees=False, xhms=False):
    """
    Gets two columns of numeric (or string) data from an ASCII file, as numpy arrays.
    xcol: the column number from which to read x-axis data (starting at zero)
    ycol: the column number from which to read y-axis data (starting at zero)
    If a colon is seen in the xcol & ycol data, and xcol!=ycol, then assume both
      columns are a sky position in sexagesimal format & convert them to radians,
      unless degrees==True, in which case convert them to degrees
    delimiter: the string that delimits columns within a row
               (default = None which means whitespace)
    startAfter: if defined, then skip all rows up to and including the first
        one containing this string
    stopAt: if defined, then skip all remaining rows when this string is seen
    xhms: if True, then read 3 columns starting at xcol as HH MM SS and convert to deg
    yhms: if True, then read 3 columns starting at ycol as HH MM SS and convert to deg
    ydms: if True, then read 3 columns starting at ycol as DD MM SS and convert to deg
    Returns:
    Two lists of values.
    if returnType==True, then also return Boolean value telling whether the
      values were found to be skyCoordinates (i.e. colon-delimited)
    -Todd Hunter
    """
    if yhms and ydms:
        print "You can only set yhms or ydms."
        return
    if xhms and yhms:
        print "You can only set xhms or yhms."
        return
    skyCoordinates = False
    f = open(filename,'r')
    x = []
    y = []
    lines = f.readlines()
    skipping = False
    for i,line in enumerate(lines):
        if (startAfter is not None):
            if (line.find(startAfter) >= 0):
                startAfter = None
                print "Starting at line ", i+1
#            print "Skipping line ", i
            continue
        if (stopAt is not None and startAfter is None):
            if (line.find(stopAt) >= 0):
                print "Stopping at line ", i
                break
        if (len(line.strip()) == 0): continue
        firstChar = line.strip()[0]
        if (firstChar in ['#','/']): continue
        if (firstChar == ':'):
            if skipping:
                skipping = False
            else:
                skipping = True
            continue
        if skipping:
            # Skip lines between lines that being with a colon (i.e. txt output from plotms)
            continue
        if (line.find('Source') >= 0): continue
        tokens = line.strip().split(delimiter)
        if (len(tokens) <= xcol or len(tokens) <= ycol):
            print "getxyFromFile(%s): Skipping row %d because there are only %d columns." % (filename,i,len(tokens))
            continue
        if False:
            # support either 0-based or 1-based column specification
            if (len(tokens) == xcol):
                xcol -= 1
            if (len(tokens) == ycol):
                ycol -= 1
        # clip off the trailing uncertainty if it is in parenthesis
        tokens[xcol] = tokens[xcol].split('(')[0]
        tokens[ycol] = tokens[ycol].split('(')[0]
        if yhms:
            # First read x column as per normal
            if (tokens[xcol].find(':') > 0):
                x.append(hmsToHours(tokens[xcol]))
            else:
                try:
                    x.append(float(tokens[xcol]))
                except:
                    x.append(tokens[xcol])  # allow strings
            # Now read 3 columns for y
            if verbose:
                print "Running hmsToHours(%s)" % (tokens[ycol]+':'+tokens[ycol+1]+':'+tokens[ycol+2])
            y.append(15*hmsToHours(tokens[ycol]+':'+tokens[ycol+1]+':'+tokens[ycol+2]))
        elif ydms:
            # First read x column as per normal
            if xhms:
                x.append(15*hmsToHours(tokens[xcol]+':'+tokens[xcol+1]+':'+tokens[xcol+2]))
            elif (tokens[xcol].find(':') > 0):
                x.append(hmsToHours(tokens[xcol]))
            else:
                try:
                    x.append(float(tokens[xcol]))
                except:
                    x.append(tokens[xcol])  # allow strings
            # Now read 3 columns for y
            y.append(hmsToHours(tokens[ycol]+':'+tokens[ycol+1]+':'+tokens[ycol+2]))
        else:
          if (tokens[xcol].find(':') > 0 and tokens[ycol].find(':') > 0 and xcol != ycol):
              if verbose:
                  print "Running radec2rad('%s %s')" % (tokens[xcol], tokens[ycol])
              rarad,decrad = radec2rad(tokens[xcol]+' '+tokens[ycol])
              skyCoordinates = True
              if degrees:
                  rarad *= 180/np.pi
                  decrad *= 180/np.pi
              x.append(rarad)
              y.append(decrad)
          else:
            if xhms:
                x.append(15*hmsToHours(tokens[xcol]+':'+tokens[xcol+1]+':'+tokens[xcol+2]))
            elif (tokens[xcol].find(':') > 0):
                x.append(hmsToHours(tokens[xcol]))
            else:
                try:
                    x.append(float(tokens[xcol]))
                except:
                    x.append(tokens[xcol])  # allow strings
            if (tokens[ycol].find(':') > 0):
                y.append(hmsToHours(tokens[ycol]))
            else:
                try:
                    y.append(float(tokens[ycol]))
                except:
                    y.append(tokens[ycol])  # allow strings
        if (len(x) == maxLines):
            print "Stopping after reading %d data lines from %d file lines" % (maxLines,i+1)
            break
    f.close()
    if returnType:
        return np.array(x),np.array(y),skyCoordinates
    else:
        return np.array(x),np.array(y)

def interpolateTable(filename, xcol, ycol, xvalue, delimiter=None, k=3,
                     startAfter=None, stopAt=None, xvaluecol=None, maxLines=None, 
                     xhms=False, yhms=False, ydms=False):
    """
    Perform a spline (or other type of) interpolation on a table of data
    read in from an ASCII file.
    filename: an ascii file with 2 or more columns that are space-delimited
    xcol: the column number to use for x
    ycol: the column number to use for y
    xvalue: the value of x for which you want to determine y
        if it is a string, then assume it is a filename and read values
        from xvaluecol (up to maxLines)
    xvaluecol: the column number to use from file=xvalue for new xvalues
    delimiter: the string that delimits columns within a row (default = None
               which means whitespace)
    k: if an integer, then use scipy.interpolate.UnivariateSpline
    k: if a string, then use scipy.interpolate.interp1d
       options: 'linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic'
    startAfter: if defined, then skip all rows up to and including the first
        one containing this string
    stopAt: if defined, then skip all remaining rows when this string is seen
    xhms: if True, then read 3 columns starting at xcol as HH MM SS and convert to deg
    yhms: if True, then read 3 columns starting at ycol as HH MM SS and convert to deg
    ydms: if True, then read 3 columns starting at ycol as DD MM SS and convert to deg
    Returns:
    a single value or array of values, depending on the input
    -Todd Hunter
    """
    if (os.path.exists(filename) == False):
        print "File not found"
        return
    result = getxyFromFile(filename,xcol,ycol,delimiter,maxLines,startAfter,stopAt,yhms,ydms,xhms=xhms)
    if result is None: return
    x,y = result
    if (len(x) < 2):
        print "Not enough data found"
        return
    if (type(xvalue) == str):
        print "Reading new xvalues from file = ", xvalue
        xvalue,junk = getxyFromFile(xvalue,xvaluecol,xvaluecol,delimiter,
                                    maxLines,startAfter,stopAt)
        print "Read %d values" % (len(xvalue))
    if (type(k) == str):
        result = interpolateSpectrum(x, y, xvalue, k=k)
    else:
        spline = scipy.interpolate.UnivariateSpline(x, y, s=0)
        result = spline(xvalue)
    if (type(xvalue) == list or type(xvalue) == np.ndarray):
        return(result)
    else:
        return(float(result))
    
def findZeroCrossing(x,y):
    spline = scipy.interpolate.UnivariateSpline(x, y, s=0)
    x0 = spline.roots()
    if (len(x0) > 0):
        return(x0)
    else:
        return([])
    
def findFWHM(x,y,level=0.5, s=0):
    """
    Measures the FWHM of the specified profile.  This works
    well in a noise-free environment.  The data are assumed to
    be sorted by the x variable.
    x: the position variable
    y: the intensity variable
    level: the signal level for which to find the full width
    s: see help scipy.interpolate.UnivariateSpline
    -Todd Hunter
    """
#    idx = np.argsort(x)
#    x = np.array(x)[idx]
#    y = np.array(y)[idx]
    halfmax = np.max(y)*level
    print "halfmax = ", halfmax
    spline = scipy.interpolate.UnivariateSpline(x, y-halfmax, s=s)
    result = spline.roots()
    if (len(result) == 2):
        x0,x1 = result
        return(abs(x1-x0))
    elif (len(result) == 1):
        return(2*result[0])
    else:
#        print "Warning: reducing %d roots into one (%s -> %f)" % (len(result),str(result),np.median(result))
#        result = 2*np.median(result)
        print "More than two crossings (%d), fitting slope to points near that power level." % (len(result))
#        result = 2*findMedianZeroCrossing(x, y-halfmax)
        result = 2*findZeroCrossingBySlope(x, y-halfmax)
        return(result)

def findMedianZeroCrossing(x, y):
    """
    Finds the x-value for the median zero crossing in y.
    -Todd Hunter
    """
    crossings = []
    for i in range(1,len(x)):
        if (y[i]*y[i-1] < 0):
            separation = abs(y[i]) + abs(y[i-1])
            wt1 = abs(y[i-1])/separation
            wt0 = abs(y[i])/separation
            crossings.append(x[i]*wt1 + x[i-1]*wt0)
    return(np.median(crossings))

def findZeroCrossingBySlope(x, y):
    """
    Finds the x-value for the zero crossing in y.
    -Todd Hunter
    """
    crossings = []
    amplitude = np.max(y)
    xdata = []
    ydata = []
    threshold = 0.1
    while (len(xdata) == 0 and threshold < 0.4):
        threshold += 0.1
        for i in range(1,len(x)):
            if (abs(y[i]) < threshold*amplitude):
                xdata.append(x[i])
                ydata.append(y[i])
#    print "Fitting ydata: ", sorted(np.array(ydata)+0.5)
    if (len(xdata) == 0):
        print "No data found between +-0.4 of half power point."
    slope, intercept = linfit().linfit(xdata,ydata,np.array(ydata)*0.01)
    return(-intercept/slope)

def deconvolveDiskFromBeam(fittedBeam, diskDiameter, tolerance=1e-5):
    """
    Deconvolve a disk from a Gaussian using a series of trial convolutions
    while adjusting the guess accordingly.  This is the inverse of 
    au.computeExpectedFWHM.
    Inputs:
    fittedBeam: this is the geometric mean of the size as fitted in the image
    diskDiameter: this is the expected diameter of the planet (or other 
                  disk-like object), in the same angular units as fittedBeam
    tolerance: the stopping criterion in units of the measured beam size 
    Todd Hunter
    """
    beamGuess = (fittedBeam**2 - diskDiameter**2)**0.5
    error = 1e9
    while (abs(error) > tolerance*fittedBeam):
        fwhm = computeExpectedFWHM(beamGuess, diskDiameter)
        error = fittedBeam-fwhm
        beamGuess += error*0.1
    return(beamGuess)

def computeExpectedFWHM(beam_fwhm, disk_diameter_arcsec, 
                        disk_diameter_arcsec2=None):
    """
    Performs a convolution of one (or two) top-hat functions with a Gaussian, 
    and reports the FWHM of the result.  This is the inverse of 
    au.deconvolveDiskFromBeam.  If a minor axis is given, then it returns the
    geometric mean of the two results.
    -Todd Hunter
    """
    if (disk_diameter_arcsec <= 0):
        return(beam_fwhm)
    p = 1
    M = 500  # minimum number of points in the profile
    disk_radius_arcsec = disk_diameter_arcsec*0.5
    image_size_arcsec = np.max([3*disk_diameter_arcsec,3*beam_fwhm])
    scale_size = image_size_arcsec/np.float(M)  # arcsec/pixel

    # now insure that the disk_radius is an integer number of pixels
    pixelsPerDiskRadius = np.ceil(disk_radius_arcsec/scale_size)
    image_size_arcsec= pixelsPerDiskRadius*image_size_arcsec/disk_radius_arcsec
    M = pixelsPerDiskRadius * image_size_arcsec / disk_radius_arcsec
    scale_size = image_size_arcsec/np.float(M)  # arcsec/pixel

    sig = beam_fwhm*0.5 / ((2*math.log(2))**0.5) / scale_size
    gaussian = spsig.general_gaussian(M,p,sig)
    r = scale_size*(np.arange(0, M) - (M - 1.0) / 2.0)
    disk = np.zeros(len(r))
    for i in range(len(r)):
        if (np.abs(r[i]) < disk_radius_arcsec):
            disk[i] = 1
        elif (np.abs(r[i]) == disk_radius_arcsec):
            disk[i] = 0.5
            
    beam = spsig.convolve(gaussian,disk,mode='same')
    beam_fwhm1 = findFWHM(r,beam)
    if (disk_diameter_arcsec2 is not None):
        disk_radius_arcsec = disk_diameter_arcsec2*0.5
        sig = beam_fwhm*0.5 / ((2*math.log(2))**0.5) / scale_size
        gaussian = spsig.general_gaussian(M,p,sig)
        r = scale_size*(np.arange(M) - (M - 1.0) / 2.0)
        disk = np.zeros(len(r))
        for i in range(len(r)):
            if (np.abs(r[i]) < disk_radius_arcsec):
                disk[i] = 1
        beam = spsig.convolve(beam,disk,mode='same')
        beam_fwhm2 = findFWHM(r,beam)
        return((beam_fwhm1*beam_fwhm2)**0.5)
    return(beam_fwhm1)

def convertSMAAntennaPositionsToPads(x, y, simmospath=''):
    """
    Converts arrays of SMA antenna local coordinates into SMA pad number names.
    -Todd Hunter
    """
    if (simmospath is None or simmospath == ''):
        repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    else:
        repotable = simmospath
        if (repotable[-1] != '/'): 
            repotable += '/'
    configs = ['sma.subcompact.cfg',
               'sma.compact.cfg',
               'sma.compact.n.cfg',
               'sma.extended.cfg',
               'sma.vextended.cfg']
    configuration = ['']*len(x)
    nearestPad = ['']*len(x)
    nearestDistance = np.ones(len(x))*10000
    for config in configs:
        px = []
        py = []
        pads = []
        f = open(repotable+'/'+config,'r')
        lines = f.readlines()
        for line in lines:
            if (line[0] == '#'):
                continue
            tokens = line.split()
            if (len(tokens) < 5):
                continue
            px.append(float(tokens[0]))
            py.append(float(tokens[1]))
            pads.append(int(tokens[4]))
        for pad in range(len(pads)):
            for ant in range(len(x)):
                dist = np.linalg.norm(x[ant]-px[pad], y[ant]-py[pad])
                if (dist <= nearestDistance[ant]):
                    nearestDistance[ant] = dist
                    nearestPad[ant] = str(pads[pad])
                    configuration[ant] = config
    
    print "Configuration identified = ", collections.Counter(configuration).most_common()[0][0]
    return(nearestPad)

def renameAntennas(vis, newnames, oldnames=''):
    """
    newnames: a list of strings, for example from au.getAntennaNames()
    oldnames: a list of strings, if blank then it assumes 'A01', 'A02', etc.
           which is used by simobserve when reading a config file
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ANTENNA', nomodify=False)
    names = mytb.getcol('NAME')
    if oldnames == '':
        oldnames = ['A%02d' % i for i in range(len(names))]
    for i,name in enumerate(names):
        if name in oldnames:
            names[i] = newnames[oldnames.index(name)]
            print "Setting %s to %s" % (name, names[i])
    mytb.putcol('NAME',names)
    mytb.close()

def buildConfigurationFile(vis='', simmospath=None, field='', dropTPpads=False,
                           output='', debug=False, extraPads=[], extraNames=[],
                           includeAntennaNames=False):
    """
    Reads the list of antenna stations in an .ms and creates a .cfg file based
    on the antenna locations in the files in /usr/lib64/casapy/data/alma/simmos.
    For ALMA, the file AOS_Pads_XYZ_ENU.txt is used. The resulting file is
    useful for running simulations on previously-obtained datasets.
    vis: an ms
    simmospath: alternative place to search for observatory .cfg files
    field: if specified, then report the date/time of the first observation of this
           field (ID or name), e.g. for usage in predictcomp
    dropTPpads: if set to True, will exclude pads starting with 'T70', as their
                files do not have the same coordinate system as the others.
    output: the name of the outputfile to write
    extraPads: insert additional pads into the list
    extraNames: the antenna names corresponding to the extraPads
    Returns:
      two integers: number of antennas written to the file, and total number of
                    stations in the STATION column.
    
    - Todd Hunter
    """
    if (vis == ''):
        print "Usage: buildConfigurationFile(vis=myvis)"
        return
    if (simmospath is None or simmospath == ''):
        repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    else:
        repotable = simmospath
        if (repotable[-1] != '/'): 
            repotable += '/'
    observatory = getObservatoryName(vis)
    startdate = mjdsecToUT(getObservationStart(vis))
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ANTENNA')
    stations = mytb.getcol('STATION')
    if (includeAntennaNames):
        names = mytb.getcol('NAME')
    mytb.close()
    for e in range(len(extraPads)):
        extraPad = extraPads[e]
        if (extraPad not in stations):
            stations = np.append(stations,extraPad)
            if (includeAntennaNames):
                if (len(extraNames) > e):
                    extraName = extraNames[e]
                    if (extraName in names):
                        print "One of the antennas in extraNames (%s) is already in the ms!  Stopping." % (extraName)
                        return
                else:
                    extraName = '????'
                names = np.append(names,extraName)
        else:
            print "One of the pads in extraPads (%s) is already in the ms!  Stopping."  % (extraPad)
            return
    if (output == ''):
        output = vis+'.cfg'
        
    if (os.path.exists(output)):
        if (os.access(output,os.W_OK) == False):
            fileWriteMessage = "Cannot write to the existing file, therefore will write to /tmp"
            output = '/tmp/' + os.path.basename(output)
        else:
            fileWriteMessage = "Overwriting the existing file"
    else:
        # The file does not exist
        if (os.path.basename(output) != output):
            # then a directory tree was given
            if (os.access(os.path.dirname(output),os.W_OK) == False):
                fileWriteMessage = "Cannot write to specified location, therefore will write to /tmp"
                output = '/tmp/' + os.path.basename(output)
            else:
                fileWriteMessage = "Creating new file in specified location"
        elif (os.access('./',os.W_OK) == False):
            fileWriteMessage = "Cannot write to current directory, therefore will write to /tmp"
        else:
            fileWriteMessage = "Creating new file in current directory"
    if not os.access(os.path.dirname(output), os.W_OK):
        print "No permission to write to this directory.  Use the output parameter to specify a different path to the requested file."
        return
    cfg = open(output, 'w')
    if (observatory.find('VLA')>=0):
        coordsys = '# coordsys=XYZ\n'
        observatory = 'VLA'
        print "Recognized observatory = VLA"
        # Remove "VLA:" and "_" from "VLA:_W8"
        for i,s in enumerate(stations):
            tokens = s.split(':')
            if (len(tokens) > 1):
                stations[i] = tokens[1].strip('_')
                if (len(stations[i]) == 2):
                    stations[i] = stations[i][0] + '0' + stations[i][1]

    elif (observatory.find('SMA')>=0):
        coordsys = '# coordsys=LOC (local tangent plane)\n'
        # need to read the antenna positions and match to pad number in CASA repository
        x,y,a,b = getAntennaPositionXY(vis)
        stations = convertSMAAntennaPositionsToPads(x,y)
    elif (observatory.find('ALMA')>=0):
        coordsys = '# coordsys=LOC (local tangent plane)\n'
    else:
        coordsys = '# coordsys=LOC (local tangent plane)\n'
    cfg.write(coordsys)
    cfg.write('# observatory=%s\n' % observatory)
    cfg.write('# x y z diam pad#\n')
    cfg.write('# %s\n' % os.path.basename(vis))
    found = np.zeros(len(stations))
    configs = 6  # number of Cycle 1 configs
    wrote = 0
    dirlist = os.listdir(repotable)
    configs = []
    almafile = os.path.dirname(__file__) + '/AOS_Pads_XYZ_ENU.txt'
    if (debug):
        print "alma file = ", almafile
    configs.append(almafile)
    configs.append('vla.a.cfg')
    configs.append('vla.b.cfg')
    configs.append('vla.c.cfg')
    configs.append('vla.d.cfg')
    configs.append('vla.bna.cfg')
    configs.append('vla.cnb.cfg')
    configs.append('vla.dnc.cfg')
    configs.append('sma.subcompact.cfg')
    configs.append('sma.compact.cfg')
    configs.append('sma.compact.n.cfg')
    configs.append('sma.extended.cfg')
    configs.append('sma.vextended.cfg')
    for c in range(len(configs)):
      cstation = 0
      if (configs[c][0] != '/'):
          cfilename = '%s%s' % (repotable,configs[c])
      else:
          cfilename = configs[c]
      if (os.path.exists(cfilename)):
#        print "Opening ", cfilename
        cfile = open(cfilename, 'r')
        lines = cfile.readlines()
        if (observatory == 'VLA' and cfilename.find('vla')>=0):
            # check if pads names are present yet
            vlapads = False
            for line in lines:
                if (line.find('W') > 0):
                    vlapads = True
            if (vlapads == False):
                print "The VLA configuration files in this version of casa do not include pad names."
                print "You can download the files from here: "
                print "   https://safe.nrao.edu/wiki/bin/view/Main/EVLAConfigFilesForSimmos"
                print "and then use the simmospath parameter to point to them."
                return

        for s in range(len(stations)):
            if (found[s] == 0):
                for line in lines:
                    if (line.find('#') < 0):
                        cstation += 1
                        if (line.strip().split()[-1] == stations[s] or
                            # The following line can be removed once ACA
                            # files have pad names.
                            (c==configs and cstation==int(stations[s][-1]) and stations[s].find('T70')>=0)):
                            found[s] = 1
                            if (debug):
                                print "Found %s in file: %s" % (stations[s],cfilename)
                            if (dropTPpads and stations[s].find('T70')>=0):
                                print "Not writing total power pads to the file."
                            else:
                                if (includeAntennaNames):
                                    line = line.strip('\n') + ' %s\n' % (names[s])
                                    # Could also change 12m to 7m here if a CM antenna is seen
                                    if (float(line.split()[3]) == 12.):
                                        line = line.replace(' 12. ',' 7. ')
                                cfg.write(line)
                                wrote += 1
                            break
        cfile.close()
    cfg.close()
    print fileWriteMessage
    print "Wrote %d of %d antenna stations to: %s" % (wrote,len(stations),output)
    for s in range(len(stations)):
        if (found[s] == 0):
            print "Did not find %s." % (stations[s])
    if (field == ''):
        print "Start of observation = %s" % (startdate)
    else:
        try:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            usemsmd = True
        except:
            usemsmd = False
        if (usemsmd):
            if (type(field) == str):
                if (field.isdigit()):
                    fieldID = int(field)
                    if (fieldID >= mymsmd.nfields()):
                        print "Field ID is too large for this ms."
                        return
                    fieldname = mymsmd.namesforfield(fieldID)
                else:
                    fieldname = field
                    fieldID = mymsmd.fieldsforname(fieldname)
            else:
                fieldID = int(field)
                if (fieldID >= mymsmd.nfields()):
                    print "Field ID (%d) is too large for this ms." % (fieldID)
                    return
                fieldname = mymsmd.namesforfields(fieldID)
            starttime = mymsmd.timesforfield(fieldID)
            mymsmd.done()
        else:
            vm = ValueMapping(vis)
            if (type(field) == str):
                if (field.isdigit()):
                    fieldID = int(field)
                    fieldname = vm.getFieldNamesForFieldId(fieldID)
                else:
                    fieldname = field
                    fieldID = vm.getFieldIdsForFieldName(fieldname)
            else:
                fieldID = int(field)
                fieldname = vm.getFieldNamesForFieldId(fieldID)
            starttime = vm.fieldsForTimes[fieldname]
        starttime = np.sort(np.unique(starttime))[0]
        starttimeString = mjdsecToUT(starttime).split()
        print "First observation of field %s = %s was at %s = %s-%s UT" % (fieldID,fieldname,starttime,starttimeString[0],starttimeString[1])
    return(wrote,len(stations))

def planetPlots(objects='Venus,Mars,Ceres,Vesta,Pallas,Juno,Jupiter,Callisto,Europa,Ganymede,Io,Titan,Uranus,Neptune',
                date='2012-12-20', freqs = [100,230,345,690],  pixels=800,
                standard = 'Butler-JPL-Horizons 2012', alma_cycle=1, longitude=ALMA_LONGITUDE,
                configs = None, showbl0flux=True, keepcl=False, keeppngs=False, verbose=False, gs='gs',pdftk='pdftk'):
    """
    This function will create a grid of amplitude vs. uvdistance visibility
    plots for the specified objects, date, frequencies and configurations.
    The output is a multipage collection of a grid of plots, one
    per object, where rows are configurations and columns are frequencies.

    objects: comma-delimited string of planetary bodies 
    longitude: in degrees east of Greenwich (default = ALMA at -67.7549)
    date: observing date, all plots are a 1-second snapshot at transit 
    freqs: a list of frequencies, in GHz, or a comma-delimited string
    standard: the model in casa to use
    showbl0flux: True/False, list the zero-baseline flux density in the legend
    keepcl: True/False, keep/remove the component lists generated by predictcomp
    keeppngs: True/False, keep/remove individual pngs (leaving only the PDFs)
    alma_cycle: 0 or 1 (will automatically fill in the configs offered) or None
    configs: alternative to alma_cycle, specify one or a list of configurations,
           such as: ['alma_cycle1_1.cfg','alma_cycle1_2.cfg'], or 'alma_cycle1_1.cfg'

    Pre-defined lists of configurations:
    alma_cycle=0:  configs=['alma.cycle0.compact.cfg',
                            'alma.cycle0.extended.cfg',
                            './alma.cycle0.hybrid.cfg',
                            ]
    alma_cycle=1:  configs=['aca_cycle1.cfg','alma_cycle1_1.cfg',
                            'alma_cycle1_2.cfg','alma_cycle1_3.cfg',
                            'alma_cycle1_4.cfg','alma_cycle1_5.cfg',
                            'alma_cycle1_6.cfg']
    alma_cycle=2:  configs=['aca.cycle2.i.cfg','aca.cycle2.ns.cfg','alma_cycle2.1.cfg',
                            'alma.cycle2.2.cfg','alma_cycle2.3.cfg',
                            'alma.cycle2.4.cfg','alma_cycle2.5.cfg',
                            'alma.cycle2.6.cfg','alma_cycle2.7.cfg']

    -Todd Hunter
    """
    if (usePredictComp == False):
        print "This function is not supported in this casa version because predictcomp is missing."
        return
    if (configs is None):
        if (alma_cycle==0):
            configs = ['alma.cycle0.compact.cfg',
                       'alma.cycle0.extended.cfg',
                       './alma.cycle0.hybrid.cfg'
                       ]
        elif (alma_cycle==1):
            configs = ['aca_cycle1.cfg','alma_cycle1_1.cfg','alma_cycle1_2.cfg',
                       'alma_cycle1_3.cfg','alma_cycle1_4.cfg','alma_cycle1_5.cfg',
                       'alma_cycle1_6.cfg']
        elif (alma_cycle is not None):
            print "Unrecognized alma_cycle.  Must be either 0 or 1."
            return
    elif (type(configs) == str):
        configs = configs.split(',')
    if (date[0:4].isdigit()==False or date[5:7].isdigit()==False or date[8:].isdigit()==False):
        print "Invalid date format.  Must be integers:  'YYYY-MM-DD'"
        return
    if (type(objects) == str):
        # convert to a list
        if (objects.find(',')>0):
            objects = objects.split(',')  
        else:
            objects = objects.split()
    if (type(freqs) == str):
        # convert to a list
        if (freqs.find(',')>0):
            freqs = [int(y) for y in freqs.split(',')]
        else:
            freqs = [int(y) for y in freqs.split()]
    pdfs = ''
    leftColumnFig = []
    leftColumnFigs = 0
    initial_dirlist = os.listdir('.')
    foundconfigs = []
    repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    for config in configs:
        if (os.path.exists(config) or os.path.exists(repotable+config)):
            foundconfigs.append(config)
        else:
            print "Could not find configuration file = %s" % (config)
    configs = foundconfigs
    if (len(configs) < 1):
        print "Could not find any configuration files."
        return
    for obj in objects:
        figs = ''
        for config in configs:
          for freq in freqs:
            config_nopath = config.split('/')[-1]
            savefig = '%s.%s.%s.%dGHz.png' % (obj,config_nopath,date,freq)
            if (verbose): print "Running au.planet('%s', '%s', useJPL=False, standard='%s')"%(obj,date,standard)
            ra,dec = planet(obj,date,useJPL=False,standard=standard,verbose=verbose)['directionRadians']
            if (ra < 0):
                ra += 2*pi
            radecString = rad2radec(ra,dec)
            # Convert the RA (i.e. the LST of transit) into UT for this date
            mjd = lst2mjd(ra, date, longitude)
            print "MJD=%f, LST=%f" % (mjd,ra*12/np.pi)
            ut = mjdToUT(mjd).split()[1]
            epoch = date + '/' + ut
            if (verbose):
                print "Running: predictcomp(objname='%s', epoch='%s', standard='%s', minfreq='%de9Hz', symb='o', antennalist='%s', savefig='%s', nfreqs=1)" % (obj, epoch,standard,freq, config,savefig)
            if (keepcl==False):
                dirlist = os.listdir('.')
            mydict = predictcomp(objname=obj, epoch=epoch,
                                 showbl0flux=showbl0flux,
                                 standard='Butler-JPL-Horizons 2012',
                                 minfreq='%de9'%freq, symb='o', antennalist=config,
                                 savefig=savefig, nfreqs=1)
            if (keepcl==False):
                # remove the .cl file created by predictcomp
                dirlist2 = os.listdir('.')
                for myfile in dirlist2:
                    if (myfile not in dirlist and myfile[-3:] == '.cl'):
#                        print "--------- Removing %s" % myfile
                        os.system('rm -rf %s' % myfile)
            if (freq == freqs[0]):
                # only need to compute this once per object
                maunit = mydict['shape']['majoraxis']['unit']
                mavalue = mydict['shape']['majoraxis']['value']
                if (maunit == 'arcmin'):
                    maunit = '"'
                    mavalue *= 60
                if (mavalue < 1):
                    majoraxisLabel = '%.2f%s' % (mavalue,maunit)
                else:
                    majoraxisLabel = '%.1f%s' % (mavalue,maunit)
                radecStringLabel = direction2radec(mydict['shape']['direction'], prec=0)[:-2] # strip off the decimal part of the declination
                # remove extraneous leading zero from dec
                loc = radecStringLabel.find('+')
                if (loc > 0):
                    radecStringLabel = radecStringLabel[:loc+1] + radecStringLabel[loc+2:]
                else:
                    loc = radecStringLabel.find('-')
                    if (loc > 0):
                        radecStringLabel = radecStringLabel[:loc+1] + radecStringLabel[loc+2:]
            labelSize = 96
            if (config == configs[0]):
                label = str(freq) + ' GHz'
                originalfig = savefig
                savefig = savefig[:-4] + '.labeled.png'
                os.system('rm -f %s' % savefig)
                os.system("convert %s -font Utopia-Regular -pointsize %d label:'%s' -gravity Center +swap -append %s" % (originalfig,labelSize,label,savefig))
            if (freq == freqs[0]):
                # need to insert an additional figure prior to this one
                leftColumnFig.append('left_column_fig%d.png'%leftColumnFigs)
                figs += leftColumnFig[-1] + ' '
                leftColumnFigs += 1
                if (config_nopath[:4] == 'alma'):
                    leftlabel = config_nopath[5:-4]
                else:
                    leftlabel = config_nopath[:-4]
                leftLabelSize = (90*pixels)/800
                os.system("convert -size %dx%d xc:white -pointsize %d -gravity Center -annotate 0 %s %s" % (pixels,pixels, leftLabelSize, leftlabel, leftColumnFig[-1]))
            figs += savefig + ' '
          # end 'for' loop over freqs
        # end 'for' loop over configs
        # Assemble the plots for this object into a single large png
        rows = len(configs)
        cols = len(freqs) + 1  # +1 is for the left column fig
        fname = '%s.%s' % (obj,date)
        cmd = 'montage -tile %dX%d -geometry %dx%d %s %s.png'%(cols,rows,pixels,pixels,figs,fname)
        print "Running %s" % (cmd)
        os.system(cmd)
        # add a global label
        fname2 = '%s.%s.labeled' % (obj,date)
        biglabel = '%s   %s   %s   RA,Dec=%s' % (obj,date,majoraxisLabel,radecStringLabel)
        toplabelSize = 128*pixels/800.
        cmd = "convert %s.png -font Utopia-Regular -pointsize %d label:'%s' -gravity Center +swap -append %s.png" % (fname,toplabelSize,biglabel,fname2)
        print "Running %s" % (cmd)
        os.system(cmd)
        # convert to PDF
        cmd = 'convert %s.png %s.pdf' % (fname2,fname2)
        print "Running %s" % (cmd)
        os.system(cmd)
        pdfs += '%s.pdf ' % (fname2)
        # end 'for' loop over objects
        
    # concatenate PDFs
    final = '%s.pdf' % (date)
    concatenatePDFs(pdfs,final,pdftk=pdftk,gs=gs)
    print "Multipage PDF result left in %s" % (final)
    os.system('rm -rf left_column_fig*.png')
    final_dirlist = os.listdir('.')
    if (keeppngs == False):
        print "Cleaning up pngs." 
        for f in final_dirlist:
            if (f not in initial_dirlist):
                if (f.find('.png') > 0):
                    os.system('rm -f %s' % f)

    # end of planetPlots()

def lstToUT(lst, date, longitude=ALMA_LONGITUDE):
    """
    lst is a string in the format: hh:mm:ss, or a floating point hours
    Date is a string in the format: YYYY-MM-DD
    longitude is degrees East of Greenwich
    Returns a string of the format:  '2012-09-20 00:02:51 UT'
          and floating point UT hours
    """
    if (type(lst) == str):
        h,m,s = lst.split(lst[2])
        lstRadians = (int(h)+int(m)/60.+float(s)/3600.)*np.pi/12.
    else:
        lstRadians = lst*np.pi/12.
    mjd = lst2mjd(lstRadians,date,longitude)
    dateTimeString = mjdToUT(mjd)
    h,m,s = dateTimeString.split()[1].split(':')
    ut = int(h)+int(m)/60.+int(s)/3600.
    return(dateTimeString, ut)

def lst2mjd(lst, date, longitudeDegrees, verbose=False):
    """
    Converts LST, date and longitude to MJD.
    Date is a string in the format: YYYY-MM-DD where '-' is any common delimiter
    The input longitude is in degrees, where east of Greenwich is positive.
    Returns the mjd in floating point days
    - Todd Hunter
    """
    if (type(lst) == str):
        lstRadians = lst.split(':')
        hours = 0
        for i,l in enumerate(lstRadians):
            hours += int(l)/(60.0**i)
        lstRadians = hours*np.pi/12.
    else:
        lstRadians = lst
    SOLAR_TO_SIDEREAL = 1.002737909350795;
    mjd = strDate2MJD(date)
    if verbose: print "mjd = ", mjd
    lstHours = lstRadians*12/np.pi
    lstAtMidnight = ComputeLST(mjd*86400, longitudeDegrees)
    delay = (lstHours - lstAtMidnight) / 24.0
    if (delay < 0.0):
        delay += 1.0
    return(mjd + delay/SOLAR_TO_SIDEREAL);

def buildMinorPlanetPlot(bodies='Venus,Mars,Ceres,Vesta,Pallas,Juno,Jupiter,Saturn,Uranus,Neptune',date='',help=False,cals=[],observatory='ALMA',useJPL=False,standard=defaultEphemeris):
    """
    Takes a list of solar system bodies and a date, and creates a Gildas astro
    script that will plot their elevation vs. time at ALMA.  If useJPL=False
    (default), it will first try to use the casa ephemerides to get the positions
    of the non-major planets in the body list.  If this fails, or if useJPL=True,
    it queries the JPL Horizons telnet server to get the positions.
    Usage: au.buildMinorPlanetPlot(bodies='Venus,Mars,Ceres,Vesta,Pallas,Juno,
        Jupiter,Saturn,Uranus,Neptune',date='',help=False,cals=[],
        observatory='ALMA',useJPL=False,standard='Butler-JPL-Horizons 2010')
    The date format required by Astro is: DD-MMM-YYYY, i.e. 01-apr-2012
    Additional fixed sources can be added as strings, e.g.:
        cals=['3C279 12:56:11.16 -05:47:21.5', '3C273 12:29:06.7 +02:03:08.6']
    For further help and examples, see
    https://safe.nrao.edu/wiki/bin/view/ALMA/BuildMinorPlanetPlot
    -- Todd Hunter
    """
    if (help):
        print "Takes a list of solar system bodies and a date, and creates a Gildas astro"
        print "script that will plot their elev. vs. time at ALMA.  If useJPL=False (default),"
        print "it will first try to use the casa ephemerides to get the positions of the"
        print "non-major planets in the body list.  If this fails, or if useJPL=True,"
        print "then it queries the JPL Horizons telnet server to get the positions."
        print ""
        print "Usage: buildMinorPlanetPlot(bodies='Venus,Mars,Ceres,Vesta,Pallas,Juno,Jupiter,Saturn,Uranus,Neptune',date='',help=False,cals=[],observatory='ALMA',useJPL=False,standard='%s')"%(defaultEphemeris)
        print "  The date format required by Astro is: DD-MMM-YYYY, i.e. 01-apr-2012"
        print "  Additional fixed sources can be added as strings, e.g.:"
        print "   cals=['3C279 12:56:11.166 -05:47:21.52', '3C273 12:29:06.699 +02:03:08.598']"
        print "Observatories can be specifed by JPL ID string, or by the following names:"
        for n in JPL_HORIZONS_ID:
            print "   '%s' (which will be converted to = '%s')" % (n, JPL_HORIZONS_ID[n])
        return
    if (len(date) < 1):
        mydate = datetime.date.today().strftime('%d-%b-%Y')
        print "No date/time specified, assuming today=%s at UT 0:00" % (date)
    else:
        try:
            mydate = datetime.datetime.strptime(date,'%d-%b-%Y')
            # it will bomb here if the format is not correct
            mydate = date
        except:
            print "You need to specify a date like so:  date='01-apr-2012'"
            return

    fname = 'minorplanets.%s'%(mydate)
    f = open(fname, 'w')
    sname = "%s.astro" % mydate
    scriptname = open(sname,'w')
    if (type(cals) != list):
        cals = [cals]
    calnames = []
    for cal in cals:
        tokens = cal.split()
        if (len(tokens)<3):
            print "1)Invalid calibrator string format: ", cal
            return
#        print "tokens = ", tokens
        # remove any spaces in the source name
        myname = ''
        for t in range(len(tokens)-2):
            myname += tokens[t]
        calnames.append(myname.upper())
        if ((tokens[-2].find(':') < 1) or (tokens[-2].find(':') < 1)):
            print "2)Invalid calibrator string format: ", cal
            return
        f.write('%s %s %s LS 0\n'%(calnames[-1],tokens[-2],tokens[-1]))
    bodyList = bodies.split(',')
    for body in bodyList:
        if (body.upper() not in majorPlanets):
            planetData = planet(body,date=mydate,observatory=observatory,
                                verbose=False,useJPL=useJPL,
                                standard=standard,subroutine=True)
            dRad = planetData['directionRadians']
            f.write("%s %s %s LS 0\n"%(str(body).upper(), qa.formxxx('%frad'%(dRad[0]),format='hms',prec=3),
                                      qa.formxxx('%frad'%(dRad[1]),format='dms',prec=2).replace('.',':',2)))
    f.close()
    f = open(sname,"w")
    f.write("set plot landscape\n")
    f.write("pen /weight 2\n")
    f.write("catalog %s\n"%(fname))
    if (observatory == 'OVRO'):
        f.write("observatory -118:16:54.00 +37:13:54.12\n")
    elif (observatory == 'GBT'):
        f.write("observatory -79:50:24.00 +38:25:58.58 0.822 50\n")
    else:
        f.write("observatory %s\n"%(observatory))

    f.write("time 00:00 %s\n"%(mydate))
    f.write("frame horizontal\n")
    f.write("horizon 20 30 40 50 60 70 /source ")
    for body in bodyList:
        if (body.upper() not in majorPlanets):
            f.write(body.upper() + ' ')
    for calname in calnames:
        f.write('%s '%calname)
    f.write('/planet SUN ')
    planetsToWrite = []
    for body in bodyList:
        if (body.upper() in majorPlanets):
            planetsToWrite.append(body.upper())
    for p in majorPlanets:
        if (p in planetsToWrite):
            f.write(p + ' ')
    f.write('/night\n')
    f.write("$rm -f %s.eps\n"%(fname))
    f.write("hard %s.eps /dev eps f\n"%(fname))
    f.write("$convert -rotate 90 -density 108 %s.eps %s.png\n"%(fname,fname))
    f.write("say wrote plot files: %s.ps and %s.png"%(fname,fname))
    print "Wrote %s and %s to be used by gildas astro to create plots." % (fname,sname)
    try:
        shell = os.getenv('SHELL')
    except:
        shell = '/bin/tcsh'
    if (shell.find('csh')>=0):
        print "In Charlottesville, do the following (1-3 can be put in your .cshrc):"
        print "1) setenv GAG_EXEC_SYSTEM x86_64-redhatClient-g95"
        print "2) setenv GAG_ROOT_DIR /opt/local/stow/gildas-exe-dec10c/"
    else:
        print "In Charlottesville, do the following (1-3 can be put in your .bashrc):"
        print '1) export GAG_EXEC_SYSTEM="x86_64-redhatClient-g95"'
        print '2) export GAG_ROOT_DIR="/opt/local/stow/gildas-exe-dec10c/"'
    print "3) source $GAG_ROOT_DIR/etc/login"
    print "4) astro (which runs $GAG_ROOT_DIR/$GAG_EXEC_SYSTEM/bin/astro)"
    print "5) @%s" % (sname)
    return
# end of buildMinorPlanetPlot()

def plotPhaseSolutions(caltables=[], sort='value', threshold=0.0, phasecal=[],
                       drop=1):
    """
    Calls listPhaseSolutions for a series of files and prints summary tables of
    the number of solutions larger than the specified threshhold for each 
    antenna and the angle between the targets and the phase calibrator.  If 
    threshold=0, it also generates a plot of median absolute phase vs. angle 
    between the target and the phase calibrator.

    au.plotPhaseSolutions(caltables=[], sort='value', threshold=0.0, 
                          phasecal=[], drop=1)
       caltables: list of self-calibration gain tables 
       phasecal: The phase-calibrator(s) matching the sequence of caltables.  
                 It can be field ID(s) or field name(s),  scalar or list.
                 If a list, then it must be the same length as caltables. 
       threshold: only use phases with an absolute value larger than this (deg)
       drop: number of highest x-values to drop when fitting the line
    -- Todd Hunter
    """
    if (type(phasecal) == list):
        if (len(caltables) != len(phasecal)):
            print "phasecal must be a scalar or have a length equal to caltables (%d)" % (len(caltables))
            return
    results = {}
    antennas = []
    for c in range(len(caltables)):
        if (type(phasecal) == list):
            phaseCalibrator = phasecal[c]
        else:
            phaseCalibrator = phasecal
        results[caltables[c]] = listPhaseSolutions(caltables[c], sort=sort, threshold=threshold, phasecal=phaseCalibrator)
        antennas += results[caltables[c]]['timestamps'][0]['antennas']
    mjdsec = results[caltables[0]]['timestamps'][0]['mjdsec']
    obsdateString = mjdToUT(mjdsec/86400.)
    print "Observation Time = %f = %s" % (mjdsec,obsdateString)
    print "Antenna  Discrepancies  MostRecentMove"
    Y,M,D = obsdateString.split()[0].split('-')
    obsdate = datetime.date.today().replace(int(Y),int(M),int(D))
    now = "this observation"
    for ant in np.unique(antennas):
        move = getMostRecentMove(ant, before=obsdateString.split()[0])
        y,m,d = move.split('T')[0].split('-')
        movedate = datetime.date.today().replace(int(y),int(m),int(d))
        diff = obsdate - movedate
        if (diff.days < 0):
            print " %s: %2d  (%5d days after %s)" % (ant, antennas.count(ant), abs(diff.days), now)
        else:
            print " %s: %2d  (%5d days before %s)" % (ant, antennas.count(ant), diff.days, now)
    separation = []
    phasecalName = []
    medianphase = []
    meanphase = []
    maxphase = []
    stdphase = []
    madphase = []
    percentile = []
    MSName = results[results.keys()[0]]['MSName']
    [medianPWV, stdPWV] = getMedianPWV(MSName)
    dateString = mjdsecToUT(getObservationStart(MSName)).split()[0]
    print "\nTarget  Angle_to_phase_calibrator"
    for r in range(len(results.keys())):
        caltable = results.keys()[r]
        mjdsec = results[caltable].keys()[0]
        separation.append(results[caltable]['separation'])
        print "%s  %.2f deg" % (results[caltable]['target'], separation[-1])
        phasecalName.append(results[caltable]['phasecal'])
        medianphase.append(results[caltable]['timestamps'][0]['medianphase'])
        meanphase.append(results[caltable]['timestamps'][0]['meanphase'])
        stdphase.append(results[caltable]['timestamps'][0]['stdphase'])
        madphase.append(results[caltable]['timestamps'][0]['madphase'])
        maxphase.append(results[caltable]['timestamps'][0]['maxphase'])
        percentile.append(results[caltable]['timestamps'][0]['percentile'])
    if (threshold > 0):
        print "To generate the plot, set threshold to zero."
    else:
      pb.clf()
      desc = pb.subplot(111)
      separation = np.array(separation)
      medianphase = np.array(medianphase)
      percentile = np.array(percentile)
      if (type(phasecal) == list):
        phasecals = np.unique(phasecal)
      else:
        phasecals = [phasecal]
      pb.hold(True)
      for p in range(len(phasecals)):
        indices = np.where(phasecal == phasecals[p])
        pb.errorbar(separation[indices], medianphase[indices], 
                    fmt='o', color=overlayColors[p], yerr=percentile[indices])
      pb.xlabel('Angular separation between targets and phase calibrator (deg)')
      pb.ylabel('Median absolute self-calibrated phase solution (deg)')
      pb.title('%s  (%s)  median_PWV=%.3f mm' % (MSName,dateString,medianPWV), size=12)
      if (drop>0):
        separation = separation[0:-drop]
        medianphase = medianphase[0:-drop]
        percentile = percentile[0:-drop]
      for p in range(len(percentile)):
        if (percentile[p] <= 0):
            # prevent crash in linfit due to nan
            percentile[p] = 1e-6
      lf = linfit()
      p = lf.linfit(separation, medianphase, percentile)
      pb.plot(pb.xlim(), p[0]*np.array(pb.xlim())+p[1], 'k-')
      pb.ylim([0,pb.ylim()[1]])
      pb.text(0.15, 0.95, 'Y=%.3f+%.3fX'%(p[1],p[0]), transform=desc.transAxes)
      for p in range(len(phasecals)):
        pb.text(0.15, 0.90-0.05*p, '%s'%phasecalName[p], color=overlayColors[p], transform=desc.transAxes)

      desc.xaxis.grid(True,which='major')
      desc.yaxis.grid(True,which='major')
      pngname = '%s.selfcal_phase_vs_separation.png'%(MSName)
      pb.savefig(pngname)
      print "\nplot left in %s" %pngname
      pb.draw()

def differencePhaseSolutions(caltable1, caltable2, antennaName, plotfile=''):
    """
    Computes and plots the phase differences between two selfcal gain tables.
    If there are failed solutions, then things will likely start to go haywire.
    Returns: dictionary
    -Todd Hunter
    """
    sn1 = listPhaseSolutions(caltable1)
    sn2 = listPhaseSolutions(caltable2)
    pb.clf()
    if antennaName == '':
        antennaNames = getAntennaNamesFromCaltable(caltable1)
    else:
        antennaNames = antennaName.split(',')
    medianPhaseDiff = {}
    for idx,antennaName in enumerate(antennaNames):
        phase = []
        x = []
        for t in sn1['timestamps']:
            if antennaName not in t['antennas']:
                continue
            a = t['antennas'].index(antennaName)
            x.append(hmsToHours(mjdsecToUTHMS(t['mjdsec'])))
            phase.append(t['phases'][a])
        i = 0
        phase2 = []
        x2 = []
        phaseDiff = []
        for t in sn2['timestamps']:
            if antennaName not in t['antennas']:
                continue
            a = t['antennas'].index(antennaName)
            x2.append(hmsToHours(mjdsecToUTHMS(t['mjdsec'])))
            phase2.append(t['phases'][a])
            if i >= len(x):
                if False:
                    print "Stopping difference calculation early to avoid exceeding array length"
            else:
                if abs(x[i] - x2[-1]) > 10/3600.:
                    print "%s: Time mismatch at %s" % (antennaName,mjdsecToUTHMS(t['mjdsec']))
                diff = phase[i] - phase2[i]
                if diff > 180: diff -= 360
                if diff < -180: diff += 360
                phaseDiff.append(diff)
            i += 1
        if len(x) == 0: 
            print "No solutions found for antenna ", antennaName
            continue
        if (len(antennaNames) == 1):
            pb.subplot(211)
            pb.plot(x,phase,'ko', x2,phase2,'ro') #, x,phaseDiff,'go')
            pb.xlabel('UT (hours)')
            pb.ylabel('phase (deg)')
            pb.subplot(212)
        else:
            pb.subplot(111)
        pb.plot(x,phaseDiff,'o',color=overlayColors[idx],mec=overlayColors[idx])
        medianPhaseDiff[antennaName] = np.median(phaseDiff)
        pb.hold(True)
    pb.xlabel('UT (hours)')
    pb.ylabel('phase difference (deg)')
    pb.draw()
    if plotfile != '':
        if plotfile==True: plotfile = caltable1 + '_' + caltable2 + '_' + antennaName+'.png'
        pb.savefig(plotfile)
    for antennaName in sorted(medianPhaseDiff.keys()):
        print "%s: %+6.1f deg" % (antennaName,medianPhaseDiff[antennaName])
    return(medianPhaseDiff)

def listPhaseSolutions(caltable='', sort='value', threshold=0.0, phasecal=None, verbose=False):
    """
    This function is useful for examining the phase solutions of a
    self-cal table to identify antennas with the largest phase
    discrepancies from zero.  Only works for casa >= 3.4.
    au.listPhaseSolutions(caltable='', sort='value', threshold=0.0)
      sort: 'value', 'name', or 'id'
         'value': sort by absolute magnitude of the phase
         'name': sort by antenna name
         'id': sort by antenna ID (often the same as name)
      threshold: only show phases with an absolute value larger than this (deg)
      phasecal: the field ID or name of the phase calibrator (scalar or list)
    Returns a dictionary of the format:
        {'separation':value, 'MSName': ms, 'phasecal': phase_calibrator_name,
         'target': target_name,
         'timestamps': [{'mjdsec': value, 'antennas':['DA45',...],
                         'phases':[10.3,...], 'medianphase':3.2,
                         'meanphase':2.4, 'maxphase':8.0, 'stdphase':1.3},
                         ...]
                         } 
        where antennas are string names, phases are in degrees, and separation is in degrees

    - Todd Hunter
    """
    fulldictionary = {}
    if (os.path.exists(caltable) == False):
        print "Could not find caltable = %s" % (caltable)
        return(fulldictionary)
    tb.open(caltable)
    names = tb.colnames()
    if ('SPECTRAL_WINDOW_ID' not in names):
        print "This appears to be an old-format cal table from casa 3.3.  Not supported."
        return(fulldictionary)
    VisCal = tb.getkeyword('VisCal')      
    MSName = tb.getkeyword('MSName')      
    if (VisCal != 'T Jones'):
        print "This is not a T Jones solution."
        return(fulldictionary)
    AntennaTable = tb.getkeyword('ANTENNA')
    fieldIds = tb.getcol('FIELD_ID')
    fieldId = fieldIds[0]  # Assume all solutions are for the same field
    print "fieldID = %d" % fieldId
    times = tb.getcol('TIME')
    gains = tb.getcol('CPARAM')
#    print "shape(gains) = ", np.shape(gains)
    if (len(gains) == 1):
        gains = gains[0]
    if (len(gains) == 1):
        gains = gains[0]
#    print "len(gains) = ", len(gains)
    antennas = tb.getcol('ANTENNA1')
    phases = np.arctan2(np.imag(gains),np.real(gains))*180.0/math.pi
    uniqueTimes = np.unique(times)
    tb.close()
    tb.open(caltable+'/ANTENNA')
    antennaNames = tb.getcol('NAME')
    tb.close()
    tb.open(caltable+'/FIELD')
    fieldNames = tb.getcol('NAME')
    phaseDirs = tb.getcol('PHASE_DIR').transpose()
    targetDir = [phaseDirs[fieldId][0][0], phaseDirs[fieldId][0][1]]
    # targetDir is now [RA,Dec] in radians
    print "target = %s" % (rad2radec(targetDir[0], targetDir[1], verbose=False))
    if (phasecal is not None):
        if (str(phasecal).isdigit()):
            phasecal = int(phasecal)
        elif (phasecal in fieldNames):
            phasecal = fieldNames.index(phasecal)
        else:
            print "Unrecognized field name = ", phasecal
        # phasecal is now a valid FIELD ID
        phasecalDir = [phaseDirs[phasecal][0][0], phaseDirs[phasecal][0][1]]
        # phasecalDir is now [RA,Dec] in radians
        print "phase cal = %s" % (rad2radec(phasecalDir[0], phasecalDir[1], verbose=False))
        separationRadians = angularSeparationRadians(phasecalDir[0], phasecalDir[1], targetDir[0], targetDir[1])
        fulldictionary['separation'] = separationRadians*180/math.pi
        fulldictionary['phasecal'] = fieldNames[phasecal]
    fulldictionary['target'] = fieldNames[fieldId]
    tb.close()
    fulldictionary['timestamps'] = []
    fulldictionary['MSName'] = MSName
    for t in uniqueTimes:
        tdict = {'antennas':[], 'phases':[]}
        indices = np.where(t == times)[0]
        thisTime = times[indices]
        if verbose:
            print "Time = %f = %s" % (thisTime[0],mjdToUT(thisTime[0]/86400.))
        thisPhase = phases[indices]
        thisAntenna = antennas[indices]
        if (sort == 'value'):
            indices = np.argsort(np.abs(thisPhase))
        elif (sort == 'name'):
            indices = np.argsort(antennaNames)
        elif (sort == 'id'):
            indices = range(len(thisTime))
        else:
            print "Unrecognized sort type.  Must be 'value', 'name' or 'id'."
            return(fulldictionary)
        for g in range(len(thisTime)):
          if (abs(thisPhase[indices[g]]) > threshold):
            if verbose:
              print "%2d %s %+8.3f " % (thisAntenna[indices[g]], 
                                      antennaNames[thisAntenna[indices[g]]], 
                                      thisPhase[indices[g]])
            tdict['antennas'].append(antennaNames[thisAntenna[indices[g]]])
            tdict['phases'].append(thisPhase[indices[g]])
        if (len(tdict['phases']) > 0):
            tdict['medianphase'] = np.median(np.abs(tdict['phases']))
            tdict['meanphase'] = np.mean(np.abs(tdict['phases']))
            tdict['maxphase'] = np.max(np.abs(tdict['phases']))
            tdict['stdphase'] = np.std(np.abs(tdict['phases']))
            tdict['madphase'] = MAD(np.abs(tdict['phases']))
            tdict['percentile25'] = scoreatpercentile(np.abs(tdict['phases']), 25)
            tdict['percentile75'] = scoreatpercentile(np.abs(tdict['phases']), 75)
            tdict['percentile'] = 0.5*(tdict['percentile75']-tdict['percentile25'])
        else:
            tdict['medianphase'] = tdict['meanphase'] = tdict['maxphase'] = 0
            tdict['stdphase'] = tdict['madphase'] = tdict['percentile'] = 0
            tdict['percentile25'] = tdict['percentile75'] = 0
        tdict['mjdsec'] = thisTime[0]
        fulldictionary['timestamps'].append(tdict)
    return(fulldictionary)

def plotbandpassOverlayTime(caltable, showatm=True, debug=False):
    """
    Produces the standard overlay='time' plot from the manual script generator.
    """
    plotbandpass(caltable, xaxis='freq', figfile=caltable+'.png', buildpdf=True,
                 overlay='time', interactive=False, showatm=showatm,
                 showfdm=True,
                 showBasebandNumber=True, chanrange='90%', debug=debug)

def plotbandpassStats(caltable='', chanavg=[], channeldiff=5, title='',usetask=False,
                      resample=True, edge=0):
    """
    Calls plotbandpass on a list of caltables with the following naming scheme:
        caltable+'_smoothXch'
    with the channeldiff option (to compute derivative statistics) and plots
    the resulting MADs vs. the level of channel averaging.
    chanavg: an integer list -- if not specified, then it will search for
             the caltables and build it automatically
    usetask: if True, use the casa task plotbandpass rather than analysisUtils version
    """
    return(plotbp3.plotbandpassStats(caltable, chanavg, channeldiff, title, usetask, resample, edge))
                      
def plotbandpass(caltable='', antenna='', field='', spw='', yaxis='amp',
                 xaxis='chan', figfile='', plotrange=[0,0,0,0], help=False,
                 caltable2='',overlay='', showflagged=False, timeranges='',
                 buildpdf=False, caltable3='',markersize=3, density=108,
                 interactive=True, showpoints='auto', showlines='auto',
                 subplot='22', zoom='', poln='', showatm=False, pwv='auto',
                 gs='gs', convert='convert', chanrange='',
                 solutionTimeThresholdSeconds=30.0, debug=False, vm='',
                 phase='', ms='', showtsky=False, showfdm=False,showatmfield='',
                 lo1=None, showimage=False, showatmPoints=False,parentms='',
                 pdftk='pdftk', channeldiff=False, edge=8, resample=1, vis='',
                 platformingThreshold=10, platformingSigma=5, basebands=None,
                 showBasebandNumber=False, scans='',figfileSequential=False,
                 groupByBaseband=False, cleanup=False, caltable2amplitudeOffset=0,
                 xcolor='b', ycolor='g', chanrangeSetXrange=False, 
                 overlaySpwDistinguish='', asciiFile=False, maxAtmChannels=512,
                 maxAltitude=60.0, firstPlot=0, Feff=0.99, SBGain=0.99, Trx='auto', 
                 showtsys=False):
  """
  This is a tool to plot bandpass solutions faster than plotcal.  It is 
  designed to work on both the old cal table format and the new format of 3.4.
  The source code is in plotbandpass3.py.
  For more detailed help, run au.plotbandpass(help=True).
  -- Todd Hunter
  """
  retval = plotbp3.plotbandpass3(caltable, antenna, field, spw, yaxis,
                                 xaxis, figfile, plotrange, help,
                                 caltable2, overlay, showflagged, timeranges,
                                 buildpdf, caltable3, markersize, density,
                                 interactive, showpoints, showlines,
                                 subplot, zoom, poln, showatm, pwv,
                                 gs, convert, chanrange,
                                 solutionTimeThresholdSeconds, debug, vm,
                                 phase, ms, showtsky, showfdm, showatmfield,
                                 lo1, showimage, showatmPoints, parentms,pdftk,
                                 channeldiff, edge, resample, vis,
                                 platformingThreshold, platformingSigma,
                                 basebands, showBasebandNumber, scans,
                                 figfileSequential, groupByBaseband, cleanup,
                                 caltable2amplitudeOffset, xcolor, ycolor,
                                 chanrangeSetXrange, overlaySpwDistinguish, 
                                 asciiFile, maxAtmChannels, maxAltitude, firstPlot,
                                 Feff, SBGain, Trx, showtsys)
  return(retval)

def getCOFAForASDM(asdm):
    """
    Looks up the observatory name from the ASDM, then looks up
    the COFA in the CASA data repository.
    Returns: X, Y, Z, latitude, longitude
    """
    return(getCOFAForObservatory(getObservatoryNameFromASDM(asdm)))

def getCOFA(ms):
    """
    Return the ITRF coordinates, Longitude and Latitude of the center of the 
    array of the observatory (from the CASA Observatories table) for the 
    specified ms.  - Todd Hunter
    """
    try:
        antTable = ms+'/ANTENNA'
        tb.open(antTable)
    except:
        print "Could not open ANTENNA table: %s" % (antTable)
        return([],[])
    position = tb.getcol('POSITION')
    station = tb.getcol('STATION')
    name = tb.getcol('NAME')
    tb.close()
    try:
        antTable = ms+'/OBSERVATION'
        tb.open(antTable)
        myName = tb.getcell('TELESCOPE_NAME')
        tb.close()
    except:
        print "Could not open OBSERVATION table to get the telescope name: %s" % (antTable)
        myName = ''
        return
    return(getCOFAForObservatory(myName))

def getCOFAForObservatory(observatory):
    """
    Return the ITRF coordinates (meters), Longitude and Latitude (degrees of the 
    center of the array of the specified observatory (from the CASA Observatories table).
    For a list of observatories, run: au.listAvailableObservatories()
    - Todd Hunter
    """
    u = simutil.simutil()
    if (casadef.python_library_directory.find('telcalsa') < 0):
        repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
    else: # casapy-telcal does not have CASAPATH defined on sciops
        repotable = casadef.python_library_directory.split('/lib')[0] + "/data/geodetic/Observatories"
    tb.open(repotable)
    Name = tb.getcol('Name')
    myType = ''
    cx = None
    for i in range(len(Name)):
        if (Name[i] == observatory):
            Long = tb.getcell('Long',i)
            Lat = tb.getcell('Lat',i)
            Height = tb.getcell('Height',i)
            myType = tb.getcell('Type',i)
            if (myType == 'ITRF'):
                cx = tb.getcell('X',i)
                cy = tb.getcell('Y',i)
                cz = tb.getcell('Z',i)
            else:
                # WGS84
                output = u.long2xyz(Long*math.pi/180.,Lat*math.pi/180.,Height,myType)
                (cx,cy,cz) = output
            break
    if cx is None:
        print "Observatory not found: ", observatory
    else:
        return(cx,cy,cz,Long,Lat)

def pickNonWvrSpwsFromOneBaseband(mymsmd):
    """
    Takes an instance of msmd and returns a list of spws
    from the first non-WVR baseband.
    """
    basebands = list(np.unique(getBasebands(mymsmd)))
    wvrspws = mymsmd.wvrspws()
    nonwvrbasebands = basebands
    if (len(wvrspws) > 0):
        wvrbaseband = mymsmd.baseband(wvrspws[0])
        nonwvrbasebands = []
        for baseband in basebands:
            if (baseband != wvrbaseband):
                nonwvrbasebands.append(baseband)
    spws = mymsmd.spwsforbaseband(nonwvrbasebands[0])
    return(list(spws))

def plotmsTwoColumnsVsTime(vis, spw='23,25,27,29',field='J0437-7148',ydatacolumn='corrected',xaxis='time',
                           avgchannel='9000', coloraxis='corr',plotfile='',antenna='DV03', yaxis='phase',
                           avgtime='', plotrange=[0,0,-180,180], intent='', title='',ignoreAntenna='DV07'):
    """
    Plots cross-correlations from all antennas except the specified one in first column, 
    and just the specified one in second column.  Rows are spws (one or more).
    antenna: which antenna to exclude from the second column
    ignoreAntenna: which antenna(s) to exclude from both columns
    spw: comma-delimited list of spw IDs
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    spwlist = spw.split(',')
    clearplots = [True] + [False]*(len(spwlist)-1)
    gridcols = 2
    gridrows = len(spwlist)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if ignoreAntenna != '':
        ignoreAntennas = ';!'+';!'.join(ignoreAntenna.split(','))
    for i,spw in enumerate(spwlist):
        baseband = mymsmd.baseband(int(spw))
        myant = '*&*;!'+antenna+ignoreAntennas
        print "myant = ", myant
        plotms(vis, field=field, spw=spw, yaxis=yaxis, xaxis=xaxis, avgchannel=avgchannel, coloraxis='corr', 
               ydatacolumn=ydatacolumn, gridcols=gridcols, gridrows=gridrows, plotfile=plotfile,
               avgtime=avgtime, title=title+', all antennas except %s, spw %s, BB%d'%(antenna,spw,baseband), plotindex=2*i, 
               rowindex=i, colindex=0, plotrange=plotrange, clearplots=clearplots[i], overwrite=True,
               antenna=myant, intent=intent)
        myant = antenna+'&*'+ignoreAntennas
        print "myant = ", myant
        plotms(vis, field=field, spw=spw, yaxis=yaxis, xaxis=xaxis,avgchannel=avgchannel, coloraxis='corr', 
               ydatacolumn=ydatacolumn, gridcols=gridcols, gridrows=gridrows, plotfile=plotfile, intent=intent,
               avgtime=avgtime, title=title+', %s, spw %s, BB%d'%(antenna,spw,baseband), plotindex=2*i+1, overwrite=True,
               rowindex=i, colindex=1, plotrange=plotrange, clearplots=False, antenna=myant)
    mymsmd.close()

def computeAvgchannel(vis, spw='', extraSmoothingFactor=1.0, stringlist=True, blankInsteadOfOne=True):
    """
    Computes the channel averaging factor that brings the selected spws to
    a common sensitivity level.  Example: TDM, 3840FDM:  ['1','32']
    extraSmoothingFactor: smooth the widest channel width by this factor
    stringlist: if True, the return ['1','32'];  else return [1,32]
    blankInsteadOfOne: if True, then return ['','32'], suitable to avoid warning in plotms
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    widest = widestChanwidth(vis, spw, mymsmd) * extraSmoothingFactor
    spws = parseSpw(vis, spw, mymsmd)
    avg = []
    for spw in spws:
        chanwidth = np.abs(np.mean(mymsmd.chanwidths(spw)))
        avgchannel = int(np.round(widest/chanwidth))
        avg.append(avgchannel)
    mymsmd.close()
    if stringlist:
        avg = [str(i) for i in avg]
        if blankInsteadOfOne:
            avg = np.array(avg)
            avg[np.where(avg=='1')] = ''
            avg = list(avg)
    return avg

def widestChanwidth(vis, spw='', mymsmd=None):
    """
    Returns the widest channel width for the specified spws in a measurement set.
    -Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        needToClose=True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    spws = parseSpw(vis, spw, mymsmd)
    maxWidth = -1
    for spw in spws:
        width = np.mean(np.abs(mymsmd.chanwidths(spw)))
        if width > maxWidth:
            maxWidth = width
    if needToClose:
        mymsmd.close()
    return maxWidth

def plotmsSpwOverlay(vis, spw, antenna='', xaxis='freq', yaxis='amp', avgchannel='auto', coloraxis='corr', 
                     avgbaseline=True, field='', ydatacolumn='corrected', plotfile='',
                     avgtime='1e9', intent='', correlation='', title='', avgscan=True, 
                     includeModel=False, extraSmoothingFactor=1, showgui=True):
    """
    Calls plotms repeatedly to overlay spws, which allows different levels of averaging to be used,
    since the ability to use frequency unit average (CAS-5066) is not being worked on.
    avgchannel: 'auto' will smooth each spw to the one with the widest physical channel width 
         There is no attempt to account for the effective bandwidth of the channels.
    plotfile: default=vis+'_plotCalibratedData.png'
              if ends in '/' then write the default png name into this directory
    title: string, where 'vis+src' is translated to name of measurement set
           and the calibrator name(s)
    includeModel: if specified, then also plot the model column
    -Todd Hunter
    """
    colindex = 0
    rowindex = 0
    if spw == '':
        spws = getScienceSpws(vis, returnString=False)
    else:
        spws = parseSpw(vis,spw)
    clearplots = [True] + [False]*(len(spws)-1)
    if avgchannel == 'auto':
        avgchannel = computeAvgchannel(vis, spws, extraSmoothingFactor)
    elif avgchannel == '':
        avgchannel = ['' for i in spws]
    if len(avgchannel) != len(spws):
        print "avgchannel must have the same number of entries (%d) as the spws requested (%d)" % (len(avgchannel), len(spws))
        return
    if plotfile == True:
        plotfile = vis.replace('.ms','') + '_plotCalibratedData_%s.png' % (intent.replace('*',''))
    elif len(plotfile) > 0:
        if plotfile[-1] == '/':
            plotfile = plotfile + os.path.basename(vis).replace('.ms','') + '_plotCalibratedData_%s.png' % (intent.replace('*',''))
    if title == '':
        title = os.path.basename(vis)
    elif title.find('vis+src') >= 0:
        if intent.find('TARGET') >= 0:
            bandpass = getScienceTargets(vis)[0]
        else:
            bandpass = str(getCalibrators(vis, intent)).replace('[','').replace(']','').replace("'",'')
        if title.find('vis+src+intent') >= 0:
            title = title.replace('vis+src+intent','') + ' ' + os.path.basename(vis).replace('.ms','') + ', ' + bandpass + ', ' + intent
        else:
            title = title.replace('vis+src','') + ' ' + os.path.basename(vis).replace('.ms','') + ', ' + bandpass
    if intent != '':
        if intent.find('*') < 0:
            intent = '*' + intent + '*'
    for i,spw in enumerate(spws):
        if i == len(spws)-1 and not includeModel:
            myplotfile = plotfile
            ylabel = 'Amp:'+ydatacolumn
        else:
            myplotfile = ''
            ylabel = ''
        print "Calling plotms(spw='%s', avgchannel='%s', plotfile='%s')" % (str(spw), avgchannel[i], myplotfile)
        plotms(vis, field=field, yaxis=yaxis, xaxis=xaxis, avgchannel=avgchannel[i], spw=str(spw),
               ydatacolumn=ydatacolumn, gridrows=1, gridcols=1, plotindex=i, antenna=antenna,
               clearplots=clearplots[i], rowindex=0, colindex=0, avgbaseline=avgbaseline,
               plotfile=myplotfile, overwrite=True, avgscan=avgscan, avgtime=avgtime, 
               coloraxis=coloraxis, intent=intent, correlation=correlation,
               title=title, showgui=showgui, ylabel=ylabel)
    if includeModel:
        for i,spw in enumerate(spws):
            if i == len(spws)-1:
                myplotfile = plotfile
                ylabel = 'Amp:model,'+ydatacolumn
            else:
                ylabel = ''
                myplotfile = ''
            print "Calling plotms(spw='%s', avgchannel='%s', plotfile='%s', ydatacolumn='model')" % (str(spw), avgchannel[i], myplotfile)
            plotms(vis, field=field, yaxis=yaxis, xaxis=xaxis, avgchannel=avgchannel[i], spw=str(spw),
                   ydatacolumn='model', gridrows=1, gridcols=1, plotindex=i+len(spws), antenna=antenna,
                   clearplots=False, rowindex=0, colindex=0, avgbaseline=avgbaseline,
                   plotfile=myplotfile, overwrite=True, avgscan=avgscan, avgtime=avgtime, 
                   coloraxis=coloraxis, intent=intent, correlation=correlation,
                   title=title, ylabel='Amp: model,'+ydatacolumn, showgui=showgui)

def plotmsGrid(vis, spw, antenna='', xaxis='time', yaxis='amp', avgchannel='10000', coloraxis='corr', 
               avgantenna=True, field='', ydatacolumn='data', gridcols=3, gridrows=3, plotfile='',
               avgtime='', intent='', correlation='', title='', avgscan=False):
    """
    Plot values on a per-antenna basis in a single grid, i.e. plotms(avgantenna=True).
    antenna: specify any antennas to avoid in the grid, e.g. '!CM01;!CM10'
    -Todd Hunter
    """ 
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    antennas = list(getAntennaNames(vis))
    if antenna != '':
        removeAntennas = antenna.replace('!','').split(';')
        for i in removeAntennas:
            antennas.remove(i)
        antenna = ';'+antenna
    clearplots = [True] + [False]*(len(antennas)-1)
    colindex = -1
    rowindex = 0
    for i,antennaName in enumerate(antennas):
        colindex += 1
        if colindex >= gridcols:
            colindex = 0
            rowindex += 1
        plotms(vis, field=field, yaxis=yaxis, xaxis=xaxis, avgchannel=avgchannel, spw=spw,
               ydatacolumn=ydatacolumn, gridrows=gridrows, gridcols=gridcols, plotindex=i, 
               clearplots=clearplots[i], rowindex=rowindex, colindex=colindex,
               plotfile=plotfile, overwrite=True, avgscan=avgscan, avgtime=avgtime, 
               antenna=antennaName+'&*'+antenna, coloraxis=coloraxis, intent=intent, correlation=correlation,
               title=antennaName+'&* '+title, avgantenna=avgantenna)

def plotmsPhaseAmplitude(vis, field='', avgchannel='', spw='', ydatacolumn='data',
                         gridrows=2, gridcols=1, xaxis='time', yaxes='amp,phase', plotfile='',
                         avgscan=False, avgtime='', antenna='', coloraxis='', intent='', 
                         correlation='',flaggedsymbolshape='nosymbol', title=''):
    """
    Uses plotms to make a 2-panel plot (e.g. of phase and amplitude vs. time)
    -Todd Hunter
    """
    yAxes = yaxes.split(',')
    rowindex = [0,0]
    colindex = [0,0]
    clearplots = [True,False]
    if gridrows > 1:
        rowindex = [0,1]
    else:
        colindex = [0,1]
    customflaggedsymbol = (flaggedsymbolshape != 'nosymbol') and (flaggedsymbolshape != '')
    for i in [0,1]:
        if i == 1:
            title = ''
        plotms(vis, field=field, yaxis=yAxes[i], xaxis=xaxis, avgchannel=avgchannel, spw=spw,
               ydatacolumn=ydatacolumn, gridrows=gridrows, gridcols=gridcols, plotindex=i, 
               clearplots=clearplots[i], rowindex=rowindex[i], colindex=colindex[i],
               plotfile=plotfile, overwrite=True, avgscan=avgscan, avgtime=avgtime, 
               antenna=antenna, coloraxis=coloraxis, intent=intent, correlation=correlation,
               customflaggedsymbol=customflaggedsymbol, flaggedsymbolshape=flaggedsymbolshape,
               title=title)

def plotElevationSummary(vis, plotfile='', vs_azim=False, overwrite=False, antenna='0',
                         allBasebands=False, showgui=True, vs_lst=False, iteraxis='',
                         vs_hourangle=False, plotindex=0, gridrows=1, gridcols=1,
                         clearplots=True, rowindex=0, colindex=0, plotrange=[]):
    """
    Plots a summary of elevation vs time for a dataset, color-coded by field. Plots only
    the middle channel of each non-wvr spw.
    vs_azim: if True, make the xaxis be azimuth
    vs_lst: if True, make the xaxis be LST (instead of UT)
    vs_hourangle: if True, make the xaxis be hourangle (instead of UT)
    allBasebands: if True, then show all spws from all basebands, not just
                  all spws from the first (non-WVR) baseband.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find ms."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    nfields = mymsmd.nfields()
    if allBasebands:
        spw = ''
        maxChannels = '9000'
    else:
        spws = pickNonWvrSpwsFromOneBaseband(mymsmd)
        nchan = []
        spw = ''
        for i in spws:
            nchan = mymsmd.nchan(i)
            if (i != spws[0]):
                spw += ','
            spw += '%d:%d' % (i,nchan/2)
        maxChannels = '' # no need to average if only showing first channel
        print "Using spws = ", spw
    for field in range(nfields):
        ra,dec = getRADecForField(vis, field, usemstool=True, mymsmd=mymsmd)
        if (ra==0 and dec==0):
            print "WARNING: Field %d has zero coordinates.  You probably need to first run fixplanets to get an accurate plot." % (field)
    mymsmd.close()
    if (vs_azim):
        xaxis = 'azimuth'
    elif (vs_lst):
        xaxis = 'lst'
        print "plotms does not yet support lst"
        return
    elif (vs_hourangle):
        xaxis = 'hourangle'
    else:
        xaxis = 'time'
    if (plotfile == True):
        plotfile = os.path.basename(vis) + '.elevationSummary_vs_%s.png' % (xaxis)
#    print "Running plotms('%s', xaxis='time', yaxis='elevation', coloraxis='field, avgchannel='%s', avgtime='10s', antenna='%s', plotfile='%s')" % (vis,maxChannels, antenna, plotfile)
    avgtime=''
    plotms(vis=vis, plotfile=plotfile, xaxis=xaxis, yaxis='elevation',
           coloraxis='field', avgchannel=maxChannels, avgtime=avgtime,
           antenna=antenna, title=os.path.basename(vis), overwrite=overwrite,
           spw=spw, showgui=showgui, gridrows=gridrows, gridcols=gridcols, 
           plotindex=plotindex, clearplots=clearplots, rowindex=rowindex, 
           colindex=colindex, plotrange=plotrange, iteraxis=iteraxis)
    print "If plotms window does not appear, you may need to restart casa."
    return plotfile

def plotManyCalibratedSpectra(mydir,intent='BANDPASS,FLUX,TARGET',plotdir='',
                              title='vis+src+intent',showgui=False):
    buf = mydir+'/*/S*/G*/M*/working/uid*.ms'
    print "running glob.glob('%s')" % (buf)
    vislist = glob.glob(buf)
    intents = intent.split(',')
    viss = len(vislist)
    if viss==0: print "No ms found."
    if len(plotdir) > 2:
        if plotdir[-1] != '/':
            plotdir += '/'
    for i,vis in enumerate(vislist):
        if vis.find('_target') > 0: 
            continue
        print "Working on %d/%d: %s" % (i+1,viss,os.path.basename(vis))
        project = vis.split('/SOUS')[0].split('/')[-1].split('T')[0]
        mytitle = project + ', ' + title
        for intent in intents:
            if intent == 'BANDPASS':
                cals = np.unique(getCalibrators(vis,intent='FLUX,BANDPASS'))
                if len(cals) == 1: continue
            if intent == 'FLUX':
                includeModel = True
            else:
                includeModel = False
            plotCalibratedSpectrum(vis, plotfile=plotdir+os.path.basename(vis)+'_'+intent+'.png',
                                   intent=intent, includeModel=includeModel,
                                   title=mytitle, showgui=showgui)

def plotCalibratedSpectrum(vis, plotfile=True, intent='BANDPASS', spw='',
                           xaxis='freq', yaxis='amp', title='vis+src+intent',
                           avgbaseline=True, avgscan=True, avgchannel='auto', 
                           includeModel=False, extraSmoothingFactor=1.0,
                           showgui=True):
    """
    Plots the scan-averaged, baseline-averaged calibrated spectrum of the specified intent.
    vis: calibrated measurement set
    plotfile: True, or an output filename
    spw: comma-delimited list (default: all science spws)
    title: string, where 'vis+src' is translated to name of measurement set
           and the calibrator name(s)
    options for avgchannel='auto':
    * extraSmoothingFactor: smooth the widest channel width by this factor
    * includeModel: if specified, then also plot the model column
    """
    if avgchannel == 'auto':
        plotmsSpwOverlay(vis, spw, xaxis=xaxis, yaxis=yaxis, avgchannel='auto', coloraxis='corr',
                         avgbaseline=avgbaseline, plotfile=plotfile, avgtime='1e9', intent=intent,
                         title=title, avgscan=avgscan, includeModel=includeModel, 
                         extraSmoothingFactor=extraSmoothingFactor, showgui=showgui)
    else:
        if includeModel:
            print "includeModel requires the avgchannel='auto' option"
            return
        if extraSmoothingFactor:
            print "extraSmoothingFactor requires the avgchannel='auto' option"
            return
        plotCalibratedData(vis,iteraxis='',coloraxis='corr',avgchannel='',spw=spw,
                           avgtime='1e9',plotfile=plotfile,gridrows=1,gridcols=1,
                           intent=intent, xaxis=xaxis, yaxis=yaxis,
                           title=title, avgbaseline=avgbaseline, avgscan=avgscan)

def plotWeightsPerAntenna(vis, xaxis='time', yaxis='wt', avgchannel='10000', 
                          coloraxis='spw', antenna='', avgbaseline=False):
    """
    Plots data weights, one page per antenna, and builds a PDF.
    antenna: list of antenna IDs or names; default='' will plot all antenna IDs; 
        to exclude 2 antennas: antenna='!ea01,!ea08'
    avgbaseline: this option is not supported for the 'wt' quantity in CASA
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antenna = parseAntenna(vis, antenna, mymsmd)
    names = mymsmd.antennanames()
    pads = mymsmd.antennastations()
    mymsmd.close()
    pngs = []
    overwrite = True
    for a in antenna:
        plotfile = vis + '_%s_%s_vs_%s.png' % (names[a],yaxis,xaxis)
        title = 'antenna %d = %s = %s' % (a, names[a], pads[a])
        print "Running plotms('%s',antenna='%s', xaxis='%s', yaxis='%s', avgchannel='%s', coloraxis='%s', plotfile='%s', title='%s', overwrite=%s, avgbaseline=%s)" % (vis, str(a), xaxis, yaxis, str(avgchannel), coloraxis, plotfile, title, overwrite, avgbaseline)
        plotms(vis, antenna=str(a), xaxis=xaxis, yaxis=yaxis, avgchannel=str(avgchannel), 
               coloraxis=coloraxis, plotfile=plotfile, title=title, overwrite=overwrite, 
               avgbaseline=avgbaseline)
        print "Wrote ", plotfile
        pngs.append(plotfile)
    pdfname = pdfname=vis+'_%s_vs_%s.pdf' % (yaxis,xaxis)
    if avgbaseline:
        pdfname = pdfname.replace('.pdf','_avgbaseline.pdf')
    buildPdfFromPngs(pngs, pdfname=pdfname)

def plotCalibratedData(vis, spw='', iteraxis='spw', coloraxis='field',
                       xaxis='time', yaxis='amp', ydatacolumn='corrected',
                       avgchannel='8192', avgtime='', plotfile='', title='',
                       avgscan=False, scan='', field='', avgantenna=False, 
                       antenna='', intent='', plotrange=[0,0,0,0], gridrows=2,
                       gridcols=2, correlation='',avgbaseline=False,
                       overwrite=True, flaggedsymbolshape='nosymbol',
                       symbolshape='autoscaling', showgui=True):
    """
    Wrapper for CASA plotms that is useful to inspect calibrated data.  All parameters are 
    passed to the plotms task.
    spw: if not specified, use the science spws. Note that default for gridrows and gridcolx
           ix 2x2 which means a 4-spw ms with iteraxis='spw' will appear as a 4-panel plot.
    intent: e.g. 'CALIBRATION*'
    plotfile: default=vis+'_plotCalibratedData.png'
              if ends in '/' then write the default png name into this directory
    title: string, where 'vis+src' is translated to basename of measurement set
           and the calibrator name(s); and 'vis+src+intent' will append intent
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Cannot find measurement set."
        return
    if plotfile == True:
        plotfile = vis.replace('.ms','') + '_plotCalibratedData_%s.png' % (intent.replace('*',''))
    elif len(plotfile) > 0:
        if plotfile[-1] == '/':
            plotfile = plotfile + os.path.basename(vis).replace('.ms','') + '_plotCalibratedData_%s.png' % (intent.replace('*',''))
    if spw == '':
        spw = getScienceSpws(vis)
    if type(spw) == str:
        if len(spw.split(',')) == 1 and iteraxis=='spw':
            gridrows = 1
            gridcols = 1
    elif type(spw) == list:
        if len(spw) == 1 and iteraxis=='spw':
            gridrows = 1
            gridcols = 1
        spw = ','.join([str(i) for i in spw])
    elif type(spw) == int or type(spw) == np.int32 or type(spw) == np.int64:
        spw = str(spw)
        if iteraxis=='spw':
            gridrows = 1
            gridcols = 1
    if title == '':
        title = os.path.basename(vis)
    elif title.find('vis+src') >= 0:
        if intent.find('TARGET') >= 0:
            bandpass = getScienceTargets(vis)[0]
        else:
            bandpass = str(getCalibrators(vis, intent)).replace('[','').replace(']','').replace("'",'')
        title = title.replace('vis+src','') + ' ' + os.path.basename(vis).replace('.ms','') + ', ' + bandpass
        if title.find('intent') >= 0:
            title += title + ', ' + intent.split('#')[0]
    if intent != '':
        if intent.find('*') < 0:
            intent = '*' + intent + '*'
    if symbolshape != 'autoscaling':
        customsymbol = True
    else:
        customsymbol = False
    if flaggedsymbolshape != 'nosymbol':
        customflaggedsymbol = True
    else:
        customflaggedsymbol = False
    plotms(vis, spw=spw, iteraxis=iteraxis, coloraxis=coloraxis,
           xaxis=xaxis, yaxis=yaxis, ydatacolumn=ydatacolumn, 
           avgchannel=avgchannel, avgtime=avgtime, plotfile=plotfile,
           avgscan=avgscan, scan=scan, field=field, avgantenna=avgantenna,
           antenna=antenna, intent=intent, plotrange=plotrange,
           gridcols=gridcols, gridrows=gridrows, correlation=correlation,
           title=title, overwrite=overwrite, avgbaseline=avgbaseline,
           flaggedsymbolshape=flaggedsymbolshape, customflaggedsymbol=customflaggedsymbol,
           symbolshape=symbolshape, customsymbol=customsymbol, showgui=showgui)
    if plotfile != '':
        if os.path.exists(plotfile):
            print "Wrote ", plotfile
        elif iteraxis=='':
            print "Failed to write expected name of plotfile: %s.  Permissions issue?" % (plotfile)
        else:
            if iteraxis=='spw':
                plotfile = plotfile.replace('.png','_Spw0.png')
                if os.path.exists(plotfile):
                    print "Wrote ", plotfile
                else:
                    print "Failed to write expected name of plotfile: %s.  Permissions issue?" % (plotfile)

def convertPadLOCToLucas(coords):
    """
    Converts ALMA pad coordinates to Robert Lucas' frame.
    -Todd Hunter
    """
    return([coords[0]+(1749.07-1730.5), coords[1]-(3372.8-2671.9)])

def everOccupied(pad):
    """
    Returns True if the pad name appears anywhere in antennaMoves.txt
    -Todd Hunter
    """
    antfile = os.path.dirname(__file__) + '/../PadData/antennaMoves.txt'
    response = os.popen("grep %s %s" % (pad,antfile)).read()
    if (response.find(pad) >= 0):
        return True
    else:
        return False

def imageHistory(img, search=''):
    """
    Print the history information from a FITS or CASA image.  For a CASA image, it
    retrieves lines from the logtable, which should be equivalent to imhistory(mode='list').
    search: if specified, only print  lines containing this string
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Image not found"
        return
    if (img.lower().find('.fits') > 0 or not os.path.exists(img+'/logtable')):
        f = pyfits.open(img)
        hdr = f[0].header
        history = hdr.get_history()
        for i in range(len(history)):
            if (search == '' or str(history[i]).find(search)>=0):
                print "%s" % (history[i])
        f.close()
    else:
        mytb = createCasaTool(tbtool)
        mytb.open(img+'/logtable')
        messages = mytb.getcol('MESSAGE')
        mytb.close()
        msg = []
        for i in range(len(messages)):
            msg += messages[i].split('\n')
        for i in range(len(msg)):
            if (search == '' or msg[i].find(search)>=0):
                print msg[i]
        print "Searched %d messages" % (len(msg))

VLA_NORTH_SOUTH_OFFSET = -19792  
def plotantsLogarithmic(vis, label='antennas', plotfile='', showAzimuthLabels=True, verbose=False,
                        useMSMDAntennaOffset=True, includeWeatherStations=False, prefix=''):
    """
    Plots the antennas of a measurement set in a radially-logarithmic
    fashion.  See also plotantsFromASDM(logarithmicOnly=True), which can plot the locations
    and names of all pads.
    label: 'antennas', 'pads' or 'both'
    includeWeatherStations: if True, then also show the weather stations
    prefix: limit weather stations to those matching this string, or list of strings (default=all)
    useMSMDAntennaOffset: if True, then plot the values from msmd.antennaoffset
            instead of reading msmd.antennaposition and converting to ITRF then
            local.  For both VLA and ALMA, offsets are applied to bring the
            center of the Y to the middle of the polar plot.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    stationNames = mymsmd.antennastations()
    antennaNames = mymsmd.antennanames()
    if (label == 'antennas'):
        names = antennaNames
    elif (label == 'pads'):
        names = stationNames
    elif (label == 'both'):
        names = [antennaNames[i]+'_'+stationNames[i] for i in range(len(antennaNames))]
    else:
        print "label must be 'antennas', 'pads', or 'both'"
        return
    xpositions = []
    ypositions = []
    zpositions = []
    obsname = mymsmd.observatorynames()[0]
    if useMSMDAntennaOffset:
        for i in range(len(stationNames)):
            mydict = mymsmd.antennaoffset(i)
            ypositions.append(mydict['latitude offset']['value'])
            xpositions.append(mydict['longitude offset']['value'])
    else:
        mydict = mymsmd.observatoryposition()
        cx = mydict['m0']['value']
        cy = mydict['m1']['value']
        cz = mydict['m2']['value']
        u = simutil.simutil()
        cx,cy,cz,longitude,latitude = getCOFAForObservatory(obsname) 
        if verbose:
            print "COFA = ",    cx,cy,cz,longitude,latitude
    #    cx,cy,cz = u.long2xyz(cx,cy,cz-radiusEarthMeters,datum='WGS84')
        for i in range(len(stationNames)):
            itrf = mymsmd.antennaposition(i)
            x,y,z = u.long2xyz(itrf['m0']['value'], itrf['m1']['value'], itrf['m2']['value']-radiusEarthMeters, datum='WGS84')
            x0,y0,z0 = u.itrf2loc(x,y,z,cx,cy,cz)
            xpositions.append(x0[0])
            ypositions.append(y0[0])
            zpositions.append(z0[0])
            if verbose: print antennaNames[i], stationNames[i], x0[0], y0[0], z0[0]
    mymsmd.close()
    date = getObservationStartDate(vis)
    title = os.path.basename(vis) + ' (' + date + ') %d antennas' % (len(antennaNames))
    if useMSMDAntennaOffset:
        if obsname.find('ALMA') >= 0:
            xcenter = 15
            ycenter = -630
        elif obsname.find('VLA') >= 0:
            if antennaNames[0][0] == 'A':
                xcenter = 0 # simobserve
            else:
                xcenter = -32  # real data from the correlator
            ycenter = 0
        else:
            xcenter = 0
            ycenter = 0
    else:
        if obsname.find('VLA') < 0:
            xcenter = np.mean(xpositions)
            ycenter = np.mean(ypositions)
        else:
            xcenter = 0
            ycenter = VLA_NORTH_SOUTH_OFFSET
    includeAntennas=True 
    markMountains = False
    labelWeatherStations={}
    meteoColor = 'r'
    print "xcenter = ", xcenter, " min/max = ", np.min(xpositions), np.max(xpositions)
    print "ycenter = ", ycenter, " min/max = ", np.min(ypositions), np.max(ypositions)
    if includeWeatherStations:
        mydict = getWeatherStationPositions(vis, prefix)
        if useMSMDAntennaOffset:
            u = simutil.simutil()
            cx,cy,cz,longitude,latitude = getCOFAForObservatory(obsname) 
        for i in mydict:
            names.append(i)
            x0,y0,z0 = u.itrf2loc(mydict[i][0],mydict[i][1],mydict[i][2],cx,cy,cz)
            xpositions.append(x0)
            ypositions.append(y0)
    if plotfile == True:
        plotfile = vis + '.plotants_log.png'
    plotPositionsLogarithmic(names, xpositions, ypositions, xcenter, ycenter, title,
                             plotfile, includeAntennas, labelWeatherStations, meteoColor,
                             showAzimuthLabels, markMountains=markMountains, obsname=obsname, debug=verbose)
    return

def plotPositionsLogarithmic(stationNames, xpositions, ypositions, xcenter=0,
                             ycenter=0,
                             title='', plotfile='', includeAntennas=True,
                             labelWeatherStations={}, meteoColor='r',
                             showAzimuthLabels=False, windspeed={},
                             winddirection={}, antennas={}, shade='',
                             deltaHeights={}, label2='', label3='',
                             pixels=800, unoccupiedPads={}, occupiedPads=[],
                             markMountains=True, neverOccupied=True, obsname='',debug=False):
    """
    stationNames: list of station names (can be antennas and weather stations)
    xpositions, ypositions: meters in local tangent plane
    xcenter, ycenter: remove this value of meters from positions before plotting
    title: string to write a the top of the plot
    plotfile: png file to create
    includeAntennas: if False, then only show weather stations
    labelWeatherStations: dictionary of delta pressure values to write next to station point
            e.g. {'MeteoCentral': -45.0}
    meteoColor: text color for station name and delta height
    showAzimuthLabels: on the outside of the polar plot
    windspeed, winddirection, deltaHeights: dictionaries keyed by station name
    antennas: dictionary keyed by station name containing name of adjacent antenna
    shade: a color to set the background of the plot
    pixels: width of plot image in pixels
    markMountains: if true, then draw contour outline of major mountains
    neverOccupied: if True, then label never-occupied pads in green
    """
    xpositions = np.array(xpositions)
    ypositions = np.array(ypositions)
    theta = np.arctan2(xpositions-xcenter, ypositions-ycenter)
    r = ((xpositions-xcenter)**2 + (ypositions-ycenter)**2)**0.5
    rmax = np.log(1.5*np.max(r))
    # ignore station at center, if there is one there
    # Automatic determination
    rmin = 0.8*np.min(r[np.where(r>0)])
    # prevent min from being too large
    rmin = np.min([rmin,350])
    # prevent min from being too small
    #    rmin = np.max([rmin,7])

    # Should probably really use half the antenna diameter
    if (obsname.find('VLA') >= 0):
        rmin = np.max([rmin,12.5])
    else:
        rmin = np.max([rmin,3])
        
    # prevent points from being below the min (and thus causing a NaN crash)
    r[np.where(r<=rmin)] = rmin
    rmin = np.log(rmin)
    if debug:
        print "rmin = %f = %fm, rmax = %f = %fm" % (rmin,e**rmin, rmax, e**rmax)
    pb.clf()
    ax = pb.subplot(111, polar=True, projection='polar')
    cartesian = None
    if ((len(windspeed.keys()) > 0) or
        (len(np.intersect1d(stationNames,deltaHeights.keys()))>0)):
        # build a second coordinate system for wind sock plot
        pb.gcf().add_axes(rect=ax.get_position(), frameon=False)
        cartesian = pb.gca()
    ax.set_theta_zero_location('N')
    ax.set_theta_direction(-1)
    if (markMountains):
        mountains = np.array([[635000., 7455000.],[629000.,7457500.],[632800.,7446300.]])
        mountainRadii = np.array([1000., 1000., 800.])
        S301EN = [629490.2, 7450388.2] # from topo map in OSF control room
        S301Lucas = convertPadLOCToLucas(getPadLOC('S301'))
        mountains -= np.array(S301EN)
        mountains += np.array(S301Lucas)
        for i,mountain in enumerate(mountains):
            mtheta = np.arctan2(mountain[0]-xcenter, mountain[1]-ycenter)
            mr = ((mountain[0]-xcenter)**2 + (mountain[1]-ycenter)**2)**0.5
            ax.plot(mtheta,np.log(mr),'k+',ms=10,color='grey',mew=3)
            thetaCircle = np.arange(0,2*np.pi,0.01)
            radCircle = mountainRadii[i]
            mx = mountain[0]+radCircle*np.cos(thetaCircle)
            my = mountain[1]+radCircle*np.sin(thetaCircle)
            mtheta = np.arctan2(mx-xcenter, my-ycenter)
            mr = ((mx-xcenter)**2 + (my-ycenter)**2)**0.5
            ax.plot(mtheta,np.log(mr),'-',color='grey',lw=3)
    for i,stationName in enumerate(stationNames):
        if (stationName.find('Meteo') >= 0):
            mycolor = meteoColor
            if (includeAntennas):
                ha = 'right'
            else:
                if (stationName.find('410')>=0):
                    ha = 'right'
                elif (stationName.find('ASTE')>=0):
                    ha = 'left'
                else:
                    ha = 'center'
            va = 'top'
            if (stationName.find('ASTE')>=0):
                va2 = 'top'
            else:
                va2 = 'bottom'
        else:
            mycolor = 'k'
            ha = 'left' # default=left
            va = 'bottom'
            va2 = 'top'
        if (includeAntennas or stationName.find('Meteo')>=0):
            ax.plot(theta[i],np.log(r[i]),'ko',ms=5,mfc='k')
            stationLabel = stationName.replace('Meteo','Met').replace('MetASTE','ASTE').replace('MetAPEX','APEX')
            if stationLabel in antennas.keys():
                # append name of antenna close to this station
                stationLabel += '(%s)' % (antennas[stationName])
            if (stationLabel.find('Met') >= 0):
                stationLabel += '  ' # does not seem to help
            else:
                stationLabel = ' ' + stationLabel
            x0 = 0.5*(1+np.sin(theta[i])*(np.log(r[i])-rmin)/(rmax-rmin))
            y0 = 0.5*(1+np.cos(theta[i])*(np.log(r[i])-rmin)/(rmax-rmin))
            if (cartesian is not None):
                cartesian.text(x0, y0-0.02, stationLabel, size=8,
                               color=mycolor, va=va, ha=ha, weight='bold',
                               transform=cartesian.transAxes)
            else:
                ax.text(theta[i],np.log(r[i]),stationLabel,size=8,
                        color=mycolor,va=va,ha=ha,weight='bold')
                # draw a key for finding the antennas
                xm = rmax # rmax is the log of 1.5*rmax(m)
                ym = xm - i*2.01*xm/50.
                phi = np.arctan2(ym,xm)-np.pi/2.
                if (theta[i] < 0):
                    theta[i] += 2*np.pi
                rad = (xm**2+abs(ym)**1.5)**0.5 # it's bizarre why this must be ~1.5
                if (stationLabel.find('D')>=0 or stationLabel.find('P')>=0 or 
                    stationLabel.find('W')>=0 or stationLabel.find('S')>=0 or
                    stationLabel.find('A')>=0 or stationLabel.find('E')>=0 or
                    stationLabel.find('N')>=0 or stationLabel.find('ea')>=0 ):
                    if (r[i] > 2000):
                        weight = 'bold'
                    else:
                        weight = 'normal'
                    mylabel = '%s: %.1f km, %3.0f$^\circ$'%(stationLabel,0.001*r[i],np.degrees(theta[i]))
#                    pb.text(phi,rad,mylabel, size=8,weight=weight,ha='right')
                    ax.annotate(mylabel, xy=(0.5,0.5), xytext=(0.02,0.925-0.90*i/len(stationNames)),
                                xycoords='figure fraction', textcoords='figure fraction', weight=weight,
                                arrowprops=None, color='black', ha='left', va='center', size=8)
            if (stationName in deltaHeights.keys()):
                cartesian.text(x0, y0-0.04,
                               r'$\Delta$h %+.0fm'%deltaHeights[stationName],
                               size=8, color=mycolor, va=va, ha=ha,
                               transform=cartesian.transAxes, weight='bold')
                
            if (stationName in windspeed.keys()):
                # Neither of these built-in transformations work
#                point = ax.transData.transform((theta[i], r[i]))
#                point = ax.transProjection.transform(np.array([theta[i]],[np.log(r[i])]))
                windSock = 0.04 # length of wind sock
                dx = windSock*np.sin(winddirection[stationName]['median'])
                dy = windSock*np.cos(winddirection[stationName]['median'])
                x1 = x0+dx
                y1 = y0+dy
                windSockLineThickness = 2
                cartesian.plot([x0,x1],[y0,y1],'k-',transform=cartesian.transAxes,lw=windSockLineThickness)
                # Draw markers every 5 and 10 knots
                j = 0
                marked = 0
                knots = 1.9 * windspeed[stationName]['median']
                for inc in [10,5]:
                    for wind in np.arange(marked+inc, knots, inc):
                        xa = x0+(windSock*(1.0-j*0.2))*np.sin(winddirection[stationName]['median'])
                        ya = y0+(windSock*(1.0-j*0.2))*np.cos(winddirection[stationName]['median'])
                        xb = xa+0.0025*inc*np.sin(winddirection[stationName]['median']+0.8*np.pi/2)
                        yb = ya+0.0025*inc*np.cos(winddirection[stationName]['median']+0.8*np.pi/2)
                        cartesian.plot([xa,xb],[ya,yb],'k-',transform=cartesian.transAxes,lw=windSockLineThickness)
                        marked = wind
                        j += 1

            if (stationName in labelWeatherStations.keys()):
                if (abs(labelWeatherStations[stationName]) < 10):
                    ax.text(theta[i],np.log(r[i]),' %+.2f'%(labelWeatherStations[stationName]),
                            size=10,color='k',va=va2,weight='bold')
    angles = np.arange(0,2.01*pi,0.01*pi)
    rfirst = -1
    # Label the dotted circles
    for cr in [30,100,300,1000,3000,10000]:
        if (cr > np.min(r)):
            if (rfirst < 0):
                rfirst = cr
            radius = np.ones(len(angles))*np.log(cr)
            ax.plot(angles, radius, 'k:')
            # tick marks at 1 km intervals
            inc = 0.1*10000/cr
            if (cr > 100):
                for angle in np.arange(inc/2.,2*pi+0.05,inc):
                    ax.plot([angle,angle],[np.log(0.95*cr),np.log(1.05*cr)],'k-') 
            va = 'top'
            if (cr >= 1000):
                if (np.log(cr) < rmax):
                    ax.text(0.0, np.log(cr), (6+len(stationNames[0]))*' '+'%d km'%(cr/1000), size=8,va=va)
            else:
                ax.text(0.0, np.log(cr), (6+len(stationNames[0]))*' '+'%dm'%(cr), size=8,va=va)
    if (unoccupiedPads != {}):
        xpositionsUnoccupied = np.array(unoccupiedPads['x'])
        ypositionsUnoccupied = np.array(unoccupiedPads['y'])
        theta = np.arctan2(xpositionsUnoccupied-xcenter,
                           ypositionsUnoccupied-ycenter)
        r = ((xpositionsUnoccupied-xcenter)**2 + (ypositionsUnoccupied-ycenter)**2)**0.5
        idx = np.where(r > rfirst)[0]
        padsNeverOccupied = []
        for i in idx:
            if (unoccupiedPads['pad'][i] not in occupiedPads):
                ax.plot(theta[i],np.log(r[i]),'ko',ms=5,mfc='w')
            if (everOccupied(unoccupiedPads['pad'][i]) or neverOccupied==False):
                mycolor = 'k'
            else:
                mycolor = 'g'
            ax.text(theta[i],np.log(r[i]),unoccupiedPads['pad'][i],size=7,
                    color=mycolor,va='top',ha='right')
        for i in range(len(r)):
            if (not everOccupied(unoccupiedPads['pad'][i])):
                padsNeverOccupied.append(unoccupiedPads['pad'][i])
            
        if (neverOccupied):
            print "%d pads have never been occupied: %s" % (len(padsNeverOccupied), padsNeverOccupied)
    if (not showAzimuthLabels):
        pb.setp(ax.set_xticklabels([]))
    pb.setp(ax.set_yticklabels([]))
    ax.set_rmax(rmax)
    ax.set_rmin(rmin)
    ax.grid(False)
    if (shade != ''):
        ax.set_axis_bgcolor(shade)
    elif (ax.get_axis_bgcolor() != 'w'):
        ax.set_axis_bgcolor('w')
    if (title != ''):
        pb.title(title)
    if (label2 != ''):
        pb.text(-0.1, 1.0, label2, transform=ax.transAxes)
    if (label3 != ''):
        pb.text(+1.1, 1.0, label3, transform=ax.transAxes,ha='right')
    mng = pb.get_current_fig_manager()
    mng.resize(pixels,pixels)
    #mng.window.showMaximized()  # does not work
    #mng.full_screen_toggle() # does not work
    #mng.window.state('zoomed') # does not work
    if (plotfile != '' and plotfile != False):
        pb.draw()
        print 'saving antenna plot in %s' % (plotfile)
        pb.savefig(plotfile,format='png')
    else:
        pb.draw()

def plotantsFromASDM(asdm=None, plotfile='', plotAntennasActualSize=True, 
                     includeWeatherStations=True, includePadNames=False,
                     buildPDF=True, dropWeatherStations=['MeteoItinerant'],
                     logarithmicOnly=False, includeAntennas=True, title='',
                     labelWeatherStations={}, pads=False, almaReference=True,
                     allpads=False, pixels=900, neverOccupied=True, 
                     markMountains=True, verbose=False, valueDictionary=None,
                     valueDictionaryPrecision=0, config=None, showAntennaId=True):
    """
    Reads the antenna positions from the ASDM and makes a plot, similar to
    the plotants function in casa.  To operate on a measurement set, see also plotantsLogarithmic.
    Input parameters:
    * asdm: the name of the ASDM
    * plotfile: name of png to produce,  if plotfile==True, then generate a default name 
                from:  asdm.plotants.png
    * plotAntennasActualSize: if True, then the markers will be scaled to match antenna 
              diameter.  If the configuration is larger than 400m, and 
              plotAntennasActualSize==True, then a second plot will be made zoomed into 
              the inner array.  If larger than 2km, then three plots will be made.
    * includeWeatherStations: if True, then also show the location of the weather stations
    * labelWeatherStations: dictionary of delta pressure values to write next to station point
            e.g. {'MeteoCentral': -45.0}
    * includePadNames: does not apply to the logarithmic plot
    * pads: if True, then show pad names instead of antenna names
    * allpads: if True, then also show unoccupied pads in smaller font and set logarithmicOnly
    * logarithmicOnly: if True, then only produce the logarithmic plot
    * includeAntennas: only pertains to the logarithmic=True option
    * almaReference: if True, use Robert's reference position as the center of the
          logarithmic plot; otherwise use the mean of all antennas
    * neverOccupied: if True, then label never-occupied pads in green
    * valueDictionary: if present, then plot these values instead of the antenna name
    * valueDictionaryPrecision: precision to use on the floating point values
    * showAntennaId: show antenna ID in label (only applied to the linear scale plots)
    -Todd Hunter
    """
    if (allpads):
        logarithmicOnly = True
    if asdm is not None:
        if config is not None:
            print "You must specify either asdm or config file."
            return
        asdm = asdm.rstrip('/')
        if (not os.path.exists(asdm)):
            print "Could not find ASDM."
            return
        observatory = getObservatoryNameFromASDM(asdm)
        if markMountains:
            if (observatory.find('ACA') < 0 and observatory.find('ALMA') < 0):
                markMountains = False
        diameters = []
        originalPlotfile = plotfile
        mydict = readStationFromASDM(asdm) # returns {0:{'name':'A050', 'position':[x,y,z], 'type':'ANTENNA_PAD'}}, includes weather stations
        antennas, stationIds, diameters = readAntennasFromASDM(asdm,stations=True,diameters=True) # does not include weather stations
    else:
        if config is None:
            print "You must specify either asdm or config file."
            return
        stations, positions, names, nAntennas, diameters = readPadConfigurationFile(config)
        if includePadNames:
            print "Turning off includePadNames since you have specified a config file."
        includePadNames = False
        types = 'ANTENNA_PAD' * len(stations)
        # need to convert these positions from LOC to XYZ
        u = simutil.simutil()
        itrf = []
        observatory = getObservatoryFromConfig(config)
        lat, longitude, observatory_ignore = getObservatoryLatLong(observatory)
        alt = getObservatoryAltitude(observatory) 
        for loc in positions:
            itrf.append(u.locxyz2itrf(lat, longitude, alt, loc[0], loc[1], loc[2]))
        positions = itrf
        types = types
        antennas = names
        stationIds = stations
        nAntennas = len(names)
        diameters = 12*np.ones(nAntennas)  # need to fix this
        mydict = {}
        for i in range(nAntennas):
            mydict[stations[i]] = {'name': names[i], 'position': positions[i], 'type': types[i]}
    if almaReference:
        if (observatory.find('ACA') < 0 and observatory.find('ALMA') < 0):
            almaReference = False
            markMountains = False
    if valueDictionary is None:
        antennaNames = antennas[:]
    else:
        antennaNames = []
        for i in range(len(antennas)):
            if antennas[i] not in valueDictionary.keys():
                antennaNames.append(antennas[i])
            else:
                antennaNames.append(' %.*f' % (valueDictionaryPrecision, valueDictionary[antennas[i]]))
        print "Redefined antennaNames = ", antennaNames
    if (includeWeatherStations):
        print "number of antennas = %d, total stations = %d" % (len(antennas),len(mydict.keys()))
        for station in mydict.keys():
            if (station not in stationIds):
                if (mydict[station]['name'] not in dropWeatherStations):
                    # Add this weather station to the list of stations to display
                    radius = np.linalg.norm(mydict[station]['position'])
                    if (radius > 1.0):
                        # unless it is at the center of the Earth! (VLA)
                        if verbose: print "Adding weather station ", mydict[station]['name']
                        antennas.append(mydict[station]['name'])
                        stationIds.append(station)
                        diameters.append(1.0)
        antennaNames = antennas[:]
    u = simutil.simutil()
    stationNames = []
    stationNamesWithAntennas = []
    if asdm is None:
        cx,cy,cz,Long,Lat = getCOFAForObservatory(observatory)
        date = getCurrentDate()
    else:
        cx,cy,cz,Long,Lat = getCOFAForASDM(asdm)
        date = getObservationStartDateFromASDM(asdm)[0]
    if verbose:
        print "COFA = ", cx,cy,cz,Long,Lat
    xpositions = []
    ypositions = []
    zpositions = []
    for antennaStation in stationIds:
        stationNames.append(mydict[antennaStation]['name'])
        if mydict[antennaStation]['type'] == 'ANTENNA_PAD':
            stationNamesWithAntennas.append(mydict[antennaStation]['name'])
        if (casadef.casa_version < '5.0.0' and casadef.subversion_revision < '25324'):
            xpositions.append([getPadLOC(mydict[antennaStation]['name'])[0]])
            ypositions.append([getPadLOC(mydict[antennaStation]['name'])[1]])
            zpositions.append([getPadLOC(mydict[antennaStation]['name'])[2]])
        else:
            x0,y0,z0 = u.itrf2loc(mydict[antennaStation]['position'][0],
                                  mydict[antennaStation]['position'][1],
                                  mydict[antennaStation]['position'][2],
                                  cx,cy,cz)
            if verbose:
                print "%s: Running itrf2loc(%s=%s=%s) --> " % (antennaStation,mydict[antennaStation]['name'],mydict[antennaStation]['type'],str(mydict[antennaStation]['position'])), x0[0], y0[0], z0[0]
            xpositions.append(x0[0])
            ypositions.append(y0[0])
            zpositions.append(z0[0])
    xpositions = np.array(xpositions)
    ypositions = np.array(ypositions)
    zpositions = np.array(zpositions)
    maxBaseline = 0
    for i in range(len(xpositions)):
        for j in range(i+1,len(xpositions)):
            baseline = pow(pow(xpositions[i]-xpositions[j],2)+pow(ypositions[i]-ypositions[j],2),0.5)
            if (baseline > maxBaseline):
                maxBaseline = baseline
    if not includePadNames:
        stationNames = None
    if (almaReference):
        if (casadef.subversion_revision >= '25324'):
            xlim0,ylim0,zlim0 = u.itrf2loc(almaReferencePosition[0],
                                           almaReferencePosition[1],
                                           almaReferencePosition[2],
                                           cx,cy,cz)
        else:
            xlim0,ylim0,zlim0 = [ 18.57345066,-701.01137959, 18.04712612]
        print "Using center of local coordinates as: ", xlim0, ylim0
    elif (observatory.find('VLA') >= 0):
        if asdm is not None:
            xlim0 = 0  # real data does not need an offset
            ylim0 = 0
        else: # it is a config file in ITRF, so it needs to be translated
            xlim0 = 0
            ylim0 = VLA_NORTH_SOUTH_OFFSET
        print "Using center of local coordinates as: ", xlim0, ylim0
    else:
        print "observatory = ", observatory
        xlim0 = np.median(xpositions)
        ylim0 = np.median(ypositions)
        print "Using center of local coordinates as station median position: ", xlim0, ylim0
    if asdm is None:
        title = config + ' (%s)' % (date)
    else:
        title = os.path.basename(asdm) + ' (%s)' % (date)
    xcenter = xlim0
    ycenter = ylim0
    if (not pads):
        title += ' %d antennas' % (len(antennaNames))
    if plotfile == True:
        if (pads):
            if (allpads):
                plotfile = asdm + '.plotallpads_log.png'
            else:
                plotfile = asdm + '.plotpads_log.png'
        elif (allpads):
            plotfile = asdm + '.plotantspads_log.png'
        else:
            plotfile = asdm + '.plotants_log.png'
    occupiedPads = []
    if asdm is not None:
        mydict = getAntennaPadsFromASDM(asdm)
        for a in antennas:
            if a in mydict.keys():
                occupiedPads.append(mydict[a])
            else: # its a weather station
                occupiedPads.append(a)
    else:
        for a in antennas:
            occupiedPads.append(a.replace('pad',''))
        
    if pads:
        names = occupiedPads
    else:
        names = antennaNames
    unoccupiedPads = {}
    if (allpads):
        X,Y,Z,padname = getPadLOC(returnPads=True)
        print "Checking %d pads" % (len(padname))
#        print "len(X)=%d" % (len(X))
#        print "len(xpositions)=%d" % (len(xpositions))
#        print "xpositions[0] = ", xpositions[0]
        unoccupiedPads['x'] = []
        unoccupiedPads['y'] = []
        unoccupiedPads['pad'] = []
        if len(occupiedPads) > 0:
            for i,pad in enumerate(padname):
                if (pad == occupiedPads[0]):
                    referencePad = pad
#                    print "i=%d" % (i)
                    deltaX = X[i]-xpositions[0] #[0]
                    deltaY = Y[i]-ypositions[0] #[0]
                    print "coordinate system offset = ", deltaX, deltaY
                    break
            for i,pad in enumerate(padname):
                if (pad not in occupiedPads or not pads):
                    unoccupiedPads['x'].append(X[i]-deltaX)
                    unoccupiedPads['y'].append(Y[i]-deltaY)
                    unoccupiedPads['pad'].append(pad)
    if (casadef.casa_version < '4.2'):
        print "This version of CASA is too old for this plot. Missing set_rmin, set_theta_direction, etc."
        return
    if verbose:
        print "%d xpositions = " % (len(xpositions)), xpositions
        print "xcenter = ", xcenter, " min/max = ", np.min(xpositions), np.max(xpositions)
        print "ycenter = ", ycenter, " min/max = ", np.min(ypositions), np.max(ypositions)
    if includePadNames:
        namelist = [names[i]+':'+stationNamesWithAntennas[i] for i in range(len(names))]
    else:
        namelist = names
    if verbose:
        print "len(names)=", len(names)
    plotPositionsLogarithmic(namelist, xpositions, ypositions, xcenter, ycenter,
                             title, plotfile, includeAntennas,
                             labelWeatherStations, pixels=pixels,
                             unoccupiedPads=unoccupiedPads,
                             occupiedPads=occupiedPads, neverOccupied=neverOccupied,
                             markMountains=markMountains, debug=verbose)
    if (logarithmicOnly):
        return
    pngs = []
    pngs.append(plotfile[:])
    if (plotfile == ''):
        myinput = raw_input("Done logarithmic plot.  Press return for next plot (linear scale)")
    else:
        plotfile = plotfile.replace('_log.png','') + '.largeZoom.png'
#    passing antennaNames crashes
#    plotfile = plotAntennaPositionList(xpositions, ypositions, antennaNames, diameters, asdm,
    if asdm is None:
        asdm = config
    plotfile = plotAntennaPositionList(xpositions, ypositions, antennas, diameters, asdm,
                                       plotfile, plotAntennasActualSize, stations=stationNames,
                                       date=date, showAntennaId=showAntennaId, zpositions=zpositions, 
                                       debug=verbose)
    pngs.append(plotfile)
    if (maxBaseline > 10000 and plotAntennasActualSize):
        xlim = [-3000+xlim0,3000+xlim0]
        ylim = [-3000+ylim0,3000+ylim0]
        if (plotfile == ''):
            myinput = raw_input("Press return for next plot (zoom of large array)")
        else:
            plotfile = plotfile.replace('.png','') + '.largeZoom.png'
        plotfile = plotAntennaPositionList(xpositions, ypositions, antennas, diameters, asdm,
                                           plotfile, plotAntennasActualSize, xlim, ylim,
                                           stations=stationNames, date=date, showAntennaId=showAntennaId, 
                                           zpositions=zpositions, debug=verbose)
        pngs.append(plotfile)
    if (maxBaseline > 2000 and plotAntennasActualSize):
        xlim = [-750+xlim0,750+xlim0]
        ylim = [-750+ylim0,750+ylim0]
        if (plotfile == '' or plotfile==None):
            myinput = raw_input("Press return for next plot (zoom of intermediate array)")
        else:
            plotfile = plotfile.replace('.largeZoom','').replace('.png','') + '.intermediateZoom.png'
        plotfile = plotAntennaPositionList(xpositions, ypositions, antennas, diameters, asdm,
                                           plotfile, plotAntennasActualSize, xlim, ylim,
                                           stations=stationNames, date=date, showAntennaId=showAntennaId,
                                           zpositions=zpositions, debug=verbose)
        pngs.append(plotfile)

    if (maxBaseline > 400 and plotAntennasActualSize):
        xlim = [-190+xlim0,190+xlim0]
        ylim = [-150+ylim0,150+ylim0]
        if (plotfile == '' or plotfile==None):
            myinput = raw_input("Press return for next plot (zoom of inner array)")
        else:
            plotfile = plotfile.replace('.intermediateZoom','').replace('.png','') + '.fullZoom.png'
        plotfile = plotAntennaPositionList(xpositions, ypositions, antennas, diameters, asdm,
                                           plotfile, plotAntennasActualSize, xlim, ylim,
                                           stations=stationNames, date=date, showAntennaId=showAntennaId, 
                                           zpositions=zpositions, debug=verbose)
        if (plotfile is not None): pngs.append(plotfile)
    if (plotfile != '' and plotfile is not None):
        if (originalPlotfile == True):
            pdf = asdm + '.plotants.pdf'
        else:
            pdf = originalPlotfile.rstrip('.png')+'.plotants.pdf'
        print "Calling buildPdfFromPngs(%s,%s)" % (pngs,pdf)
        buildPdfFromPngs(pngs, pdf)
        print "Wrote %d-page PDF: %s" % (len(pngs),pdf)
    # end of plotantsFromASDM

def getAntennaInfo(vis):
    """
    Gets antenna info for a measurement set, with coordinates in a local 
    tangent plane.
    Returns five lists:  xpos(m), ypos(m), diameter(m), padname, names
    """
    if (not os.path.exists(vis)):
        print "Could not find vis"
        return(None)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    pads = mymsmd.antennastations()
    names = mymsmd.antennanames()
    mymsmd.close()
    xpositions = []
    ypositions = []
    for pad in pads:
        x,y,z,name = getPadLOC(pad, returnPads=True)
        xpositions.append(x)
        ypositions.append(y)
    diameters = almaAntennaDiameters(names)
    return(xpositions, ypositions, diameters, pads, names)
    
def plotantsTwoPanel(vis, plotfile='', plotAntennasActualSize=True, xlim=None,
                     ylim=None, showAntennaId=False, mfc='#999999', units='m',
                     title='', zoom=0.8, vis2=None, vis3=None, title2='',
                     title3='', hspace=0.2, wspace=0.25, dpi=400):
    """
    Creates a 2-panel plot of the antenna configuration (for the 2014 LBC
    overview paper).
    mfc: marker face color (default = black)
    vis2: creates a 4-panel plot if a second dataset is given
    vis3: creates a 6-panel plot if a third dataset is given
    -Todd Hunter
    """
    date = ''
    stations = None
    antennas = None
    pb.ion()
    if (vis3 is not None):
        s = 231
        ncols = 3
    elif (vis2 is not None):
        s = 221
        ncols = 2
    else:
        s = 211
        ncols = 1
    vises = [vis]
    if (vis2 is not None): vises.append(vis2)
    if (vis3 is not None): vises.append(vis3)
    xpositions = {}
    ypositions = {}
    diameters = {}
    pads = {}
    names = {}
    ylabel = {0:True, 1:False, 2:False}
    titles = {0:title, 1:title2, 2:title3}
    size = 9
    pb.clf()
    fig = pb.gcf()
    pb.subplots_adjust(wspace=wspace,hspace=hspace)
    for i,vis in enumerate(vises):
        if (vis is not None):
            adesc = fig.add_subplot(s+i, aspect='equal')
            xpositions[i], ypositions[i], diameters[i], pads[i], names[i] = getAntennaInfo(vis)
            print "Plotting %d antennas" % (len(xpositions[i]))
            plotAntennaPositionList(xpositions[i], ypositions[i], antennas, diameters[i], titles[i],
                                    plotfile, plotAntennasActualSize, xlim, ylim,
                                    stations, date, showAntennaId, mfc, units,
                                    standalone=False, ylabel=ylabel[i])
            pb.hold(True)
            pb.gca().add_patch(Rectangle((-zoom*0.5,-zoom*0.5),zoom,zoom,facecolor='w',alpha=0.5))
            pb.setp(adesc.get_xticklabels(), fontsize=size)
            pb.setp(adesc.get_yticklabels(), fontsize=size)

    if (units.find('km') == 0):
        zoom *= 1000
        units = 'm'
    xlim = [-zoom/2.,zoom/2.]
    ylim = [-zoom/2.,zoom/2.]
    print "Set second panel xlim,ylim = ", xlim,ylim
    title = ''
    for i,vis in enumerate(vises):
        if (vis is not None):
            adesc = fig.add_subplot(s+ncols+i, aspect='equal')
            plotAntennaPositionList(xpositions[i], ypositions[i], antennas, diameters[i], title,
                                    plotfile, plotAntennasActualSize, xlim, ylim,
                                    stations, date, showAntennaId, mfc, units,
                                    standalone=False, ylabel=ylabel[i])
            pb.setp(adesc.get_xticklabels(), fontsize=size)
            pb.setp(adesc.get_yticklabels(), fontsize=size)
            adesc.xaxis.set_major_locator(MultipleLocator(200))
            adesc.yaxis.set_major_locator(MultipleLocator(200))
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = vises[0] + '.plotants.png'
        pb.draw()
        pb.savefig(plotfile,format='png',density=dpi)
        print 'saved antenna plot in %s' % (plotfile)
        eps = plotfile.replace('.png','.eps')
        os.system('convert %s %s' % (plotfile,eps))
        print 'saved antenna plot in %s' % (eps)

def almaAntennaDiameter(antenna):
    """
    Returns the diameter of an antenna (in meters) as a function of name.  - Todd Hunter
    """
    if (antenna.find('CM') == 0):
        return 7.0
    else:
        return 12.0
    
def almaAntennaDiameters(antennas):
    """
    Runs almaAntennaDiameter for a list of antenna names. Returns a list of floats
    (in meters).
    - Todd Hunter
    """
    diameters = []
    for antenna in antennas:
        diameters.append(almaAntennaDiameter(antenna))
    return diameters
                         
def plotAntennaPositionList(plotx, ploty, antenna, diam, dataset, plotfile='',
                            plotAntennasActualSize=True, xlim=None, ylim=None,
                            stations=None, date=None, showAntennaId=True,
                            mfc='#FFB6C1', units='m', standalone=True, 
                            ylabel=True, zpositions=None, debug=False):
    """
    Called by plotantsFromASDM and es.listobs2. 
    The label drawn is [antennaID+'='] + antennaName + ':' + station
    Input parameters:
    plotx, ploty: list of X and Y components of geocentric position
    antenna: list of antenna names (or other string label to write)
    diam: list of antenna diameters (meters)
    dataset: the string to put in the title of the plot
    plotfile: if specified, then produce a plot of this name.  if 'True' then
         the plotfile name will be  <dataset>.plotants.png
    mfc: marker face color (default = pink)
    units: the units to use (default = 'm')
    standalone: if True, then clear the figure and save a plot
    -Todd Hunter
    """
    if (standalone):
        pb.clf()
    if debug and antenna is not None:
        print "len(antenna)=%d  len(zpositions)=%d, len(diameters)=%d" % (len(antenna),len(zpositions),len(diam))
    if (zpositions is None):
        zpositions = np.zeros(len(plotx))
    else:
        zpositions = np.array(zpositions)
    zoomed = False
    exaggerated = False
    plotx = np.array(plotx)
    ploty = np.array(ploty)
    diam = np.array(diam)
    if (antenna is not None):
        antenna = np.array(antenna)
    if (units.find('km') == 0):
        plotx *= 0.001
        ploty *= 0.001
    if (xlim is not None):
        index = np.where(plotx < xlim[1])[0]
        plotx = plotx[index]
        ploty = ploty[index]
        if (type(antenna) != type(None)):
            antenna = antenna[index]
        diam = diam[index]
        zpositions = zpositions[index]
        index = np.where(plotx > xlim[0])[0]
        if (len(index) < 1):
            print "no antennas in xrange"
            return
        plotx = plotx[index]
        ploty = ploty[index]
        if (type(antenna) != type(None)):
            antenna = antenna[index]
        diam = diam[index]
        zpositions = zpositions[index]
    if (ylim is not None):
        index = np.where(ploty < ylim[1])[0]
        plotx = plotx[index]
        ploty = ploty[index]
        if (type(antenna) != type(None)):
            antenna = antenna[index]
        diam = diam[index]
        zpositions = zpositions[index]
        index = np.where(ploty > ylim[0])[0]
        if (len(index) < 1):
            print "no antennas in yrange"
            return
        plotx = plotx[index]
        ploty = ploty[index]
        if (antenna is not None):
            antenna = antenna[index]
        diam = diam[index]
        zpositions = zpositions[index]
    index = np.where(zpositions > -5500)
    # Ignore stations below sea level, which happens when there are bad positions
    # for weather stations in the TMCDB 
    plotx = plotx[index]
    ploty = ploty[index]
    if (antenna is not None):
        antenna = antenna[index]
    diam = diam[index]
    zpositions = zpositions[index]

    if (plotAntennasActualSize):
        maxlength = 0
        antennaSizePercent = 0.5  # minimum size to draw in large configurations

        # Find the longest baseline to be shown in this view
        if (xlim is None):
            x0 = -1e5
            x1 = 1e5
        else:
            x0 = xlim[0]
            x1 = xlim[1]
        if (ylim is None):
            y0 = -1e5
            y1 = 1e5
        else:
            y0 = ylim[0]
            y1 = ylim[1]

        for a in range(len(plotx)-1):
            if (plotx[a] < x1 and plotx[a] > x0 and ploty[a] < y1 and ploty[a] > x0):
                for b in range(1,len(plotx)):
                    if (plotx[b] < x1 and plotx[b] > x0 and ploty[b] < y1 and ploty[b] > x0):
                        length = ((plotx[a]-plotx[b])**2 + (ploty[a]-ploty[b])**2)**0.5
                        if (length > maxlength):
                            maxlength = length
        # the following is necessary to support python 2.6's max function
        if (type(maxlength) == np.ndarray): maxlength = maxlength[0]
        for a in range(len(plotx)):
            length1 = maxlength*antennaSizePercent*0.01
            length2 = diam[a]*0.5
            if (units.find('km') == 0):
                length2 *= 0.001
            radius = np.max([length1,length2])
            if (radius > diam[a]*0.5):
                exaggerated = True
            circ = pb.Circle((plotx[a],ploty[a]), radius=radius,
                             facecolor=mfc, edgecolor='k')
            pb.gca().add_patch(circ)
        if standalone:
            pb.axis('equal')
        if (xlim is not None):
            print "A) Setting xlim  to ", xlim
            pb.xlim(xlim)
            zoomed = True
        if (ylim is not None):
            pb.ylim(ylim)
            zoomed = True
        xlim = pb.xlim() 
        ylim = pb.ylim()  # actual value may vary due to axis('equal')
    else:
        #  Find size of plot
        pxmin = np.min(plotx)
        pymin = np.min(ploty)
        pxmax = np.max(plotx)
        pymax = np.max(ploty)
        psize = np.sqrt((pxmax-pxmin)**2 + (pymax+pymin)**2)
        # set marker size
        mssize = 15.0/300.0*psize
        pb.plot(plotx,ploty,'go',ms=mssize,mfc=mfc)
        print "B) Setting xlim  to ", [pxmin-2*mssize, pxmax+2*mssize]
        pb.xlim([pxmin-2*mssize, pxmax+2*mssize])
        pb.ylim([pymin-2*mssize, pymax+2*mssize])
    labelsize = 10
    labelsizeMin = 2
    labelsizeMax = 12
    xmean = np.mean(plotx)
    ymean = np.mean(ploty)
    for i in range(0,len(plotx)):
        withinFrame = True
        if (plotAntennasActualSize):
            radiusFromCenter = ((plotx[i]-xmean)**2 + (ploty[i]-ymean)**2)**0.5
            cornerRadius = (((xlim[1]-xlim[0])*0.5)**2 + ((ylim[1]-ylim[0])*0.5)**2)**0.5
            labelsize = np.int(np.round(labelsizeMin + (labelsizeMax-labelsizeMin)*radiusFromCenter/cornerRadius))
            labelsize = labelsizeMin + (labelsizeMax-labelsizeMin)*(radiusFromCenter/cornerRadius)**0.33
            if (xlim is not None):
                if (plotx[i] < xlim[0] or plotx[i] > xlim[1]): withinFrame = False
            if (ylim is not None):
                if (ploty[i] < ylim[0] or ploty[i] > ylim[1]): withinFrame = False
        if (withinFrame):
            mytext = ''
            if (showAntennaId):
                mytext += str(i)+'='
            if (antenna is not None):
                mytext += antenna[i]
            if (stations is not None):
                mytext += ':'+stations[i]
            if (mytext.find('Meteo') >= 0):
                mycolor = 'r'
            else:
                mycolor = 'k'
            pb.text(plotx[i]-3.0,ploty[i]-5.0,mytext,size=labelsize,color=mycolor)
    if dataset is not None:
        mytitle = os.path.basename(dataset)
    if (zoomed and standalone):
        mytitle += ' (zoomed)'
    if (date is not None):
        mytitle += '  ' + date
    if (exaggerated and mytitle != ''):
        mytitle += ' (antenna size exaggerated)'
    pb.title(mytitle,fontsize=12)
    pb.xlabel('East/West (%s)'%units)
    if (ylabel):
        pb.ylabel('North/South (%s)'%units)
    if (standalone):
        if (plotfile != ''):
            if (plotfile == True):
                plotfile = dataset + '.plotants.png'
            pb.savefig(plotfile,format='png',density=108)
            print 'saved antenna plot in %s' % (plotfile)
        return(plotfile)
    else:
        return

def obslist(ms,cofa=''):
    """
    Parses the telescope name from the OBSERVATION table, then finds the
    coordinates of the center of the array (COFA), then converts each station
    coordinates into local offsets in meters from the COFA and prints the
    information. You can optionally define the COFA as an antenna ID or name
    via the cofa parameter.  For further help and examples, see:
    http://casaguides.nrao.edu/index.php?title=Obslist
    Todd Hunter
    """
    try:
        antTable = ms+'/ANTENNA'
        tb.open(antTable)
    except:
        print "Could not open ANTENNA table: %s" % (antTable)
        return([],[])
    position = tb.getcol('POSITION')
    station = tb.getcol('STATION')
    name = tb.getcol('NAME')
    tb.close()
    try:
        antTable = ms+'/OBSERVATION'
        tb.open(antTable)
        myName = tb.getcell('TELESCOPE_NAME')
        tb.close()
    except:
        print "Could not open OBSERVATION table to get the telescope name: %s" % (antTable)
        myName = ''
        
    u = simutil.simutil()
    repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
    tb.open(repotable)
    Name = tb.getcol('Name')
    cx = position[0][0]
    cy = position[1][0]
    cz = position[2][0]
    myType = ''
    if (cofa == ''):
        for i in range(len(Name)):
            if (Name[i] == myName or Name[i] == myName.upper()):
                Long = tb.getcell('Long',i)
                Lat = tb.getcell('Lat',i)
                Height = tb.getcell('Height',i)
                myType = tb.getcell('Type',i)
                if (myType == 'ITRF'):
                    cx = tb.getcell('X',i)
                    cy = tb.getcell('Y',i)
                    cz = tb.getcell('Z',i)
                else:
                    # WGS84
                    output = u.long2xyz(Long*math.pi/180.,Lat*math.pi/180.,Height,myType)
                    (cx,cy,cz) = output
                break
    else:
        if (str(cofa).isdigit()):
            if (int(cofa) < 0 or int(cofa) >= len(name)):
                print "Invalid antenna ID. (Valid range = 0..%d)" % (len(name)-1)
                return
        else:
            matches = np.where(name == cofa)[0]
            if (len(matches) < 1):
                print "cofa must be either an integer, a blank string, or a valid antenna name"
                return
            else:
                print "Antenna %s has ID %d" % (cofa,matches[0])
                cofa = matches[0]
            cx = position[0][int(cofa)]
            cy = position[1][int(cofa)]
            cz = position[2][int(cofa)]
        myType = 'user'
    if (len(myType) < 1):
        print "Did not find telescope data for %s, using first station as center of array." % (myName)
    tb.close()
    try:
        output = u.irtf2loc(position[0,:],position[1,:],position[2,:],cx,cy,cz)
    except:
        output = u.itrf2loc(position[0,:],position[1,:],position[2,:],cx,cy,cz) # the newer name
    if (len(output) == 2):
        (x,y) = output
    else:
        (x,y,z) = output
    for i in range(len(x)):
        print "Antenna %2d = %s on pad %s, lat/long offset (m) = %+10.4f/%+10.4f" % (i,name[i],station[i],x[i],y[i])
    getBaselineExtrema(ms)
    return

def xyz2long(x, y, z, datum='WGS84', verbose=True, dms=False):
    """
    A convenient wrapper for simutil.xyz2long to convert a geocentric X,Y,Z
    position to degrees of latitude, longitude.
    dms: if True, then return a sexagesimal string 'ddd:mm:ss.ss, +dd:mm:ss.ss'
    - Todd Hunter
    """
    u = simutil.simutil()
    result = np.array(u.xyz2long(x,y,z,datum))
    if (len(result) == 2):
        longitude, latitude = result * 180.0 / np.pi
        if verbose:
            print "latitude = %+f, longitude = %+f degrees" % (latitude,longitude)
        result = [latitude, longitude]
    else:
        longitude, latitude, height = result
        longitude *= 180.0 / np.pi
        latitude *= 180.0 / np.pi
        if verbose:
            print "latitude = %+f, longitude = %+f degrees, height = %fm" % (latitude,longitude,height)
        result = [latitude, longitude, height]
    if dms:
        result = ','.join([deg2dms(longitude),deg2dms(latitude)])
    return (result)

def longs2xyz(longLatElevList, datum='WGS84', verbose=False):
    """
    A convenient wrapper for simutil.long2xyz to convert a list of geodetic 
    positions (longitude, latitude and elevation) to a list of ITRF 
    coordinates (X,Y,Z).
    longLatElevList: [[longitude(degrees), latitude(degrees), elevation(m)],...]
    -Todd Hunter
    """
    mysimutil = simutil.simutil()
    xyz = []
    for pos in longLatElevList:
        xyz.append(long2xyz(pos[0],pos[1],pos[2],datum,mysimutil,verbose))
    return xyz
    
def long2xyz(longitude, latitude, elevation, datum='WGS84', mysimutil=None,
             verbose=True):
    """
    A convenient wrapper for simutil.long2xyz to convert a geodetic longitude,
    latitude and elevation to ITRF coordinates (X,Y,Z)
    longitude: in degrees
    latitude: in degrees
    elevation: in meters
    - Todd Hunter
    """
    if mysimutil is None:
        mysimutil = simutil.simutil()
    result = np.array(mysimutil.long2xyz(np.radians(longitude),
                                         np.radians(latitude),
                                         elevation,datum))
    if verbose:
        X,Y,Z = result
        print "X,Y,Z = ", X, Y, Z
    return (result)

def itrf2loc(x, y, z, cx, cy, cz):
    """
    A convenient wrapper for simutil.itrf2loc to convert an ITRF position x,y,z 
    and an array center position cx,cy,cz to LOC.
    - Todd Hunter
    """
    mysimutil = simutil.simutil()
    result = np.array(mysimutil.itrf2loc(x,y,z,cx,cy,cz))
    return(result)

def getPadPositionsFromASDM(asdm):
    """
    Reads the pad positions in geocentric XYZ coordinates from an ASDM.
    Returns a dictionary keyed by pad name, with value = its XYZ position.
    - Todd Hunter
    """
    pads = getAntennaPadsFromASDM(asdm).values()
    newdict = {}
    for pad in pads:
        newdict[pad] = getPadXYZFromASDM(asdm, pad)
    return(newdict)

def antennaPosition(vis, vis2=None, ant='', verbose=True):
    """
    This utility prints the XYZ positions from the ANTENNA table for 1 or 
    2 measurement sets.
    If vis2 is specified, the difference in positions is also computed.
    This is meant to help understand antenna position correction algorithms.
    Returns: a dictionary of positions, keyed by antenna name in vis
    Todd Hunter  (May 2012)
    """
    try:
        antTable = vis+'/ANTENNA'
        tb.open(antTable)
    except:
        print "Could not open ANTENNA table: %s" % (antTable)
        return([],[])
    position = tb.getcol('POSITION')
    station = tb.getcol('STATION')
    names = tb.getcol('NAME')
    tb.close()

    if (vis2 is not None):
      try:
          antTable2 = vis2+'/ANTENNA'
          tb.open(antTable2)
      except:
          print "Could not open ANTENNA table: %s" % (antTable2)
          return([],[])
      position2 = tb.getcol('POSITION')
      station2 = tb.getcol('STATION')
      names2 = tb.getcol('NAME')
      tb.close()

    antennas = len(station)
    axis = ['X','Y','Z']
    if (vis2 is not None):
        print "           vis1              vis2        Difference (m)"
    mydict = {}
    for antenna in range(len(names)):
      if (ant == '' or names[antenna] == ant):
        if verbose:
            print "Antenna %02d = %4s on %s: " % (antenna,names[antenna],station[antenna])
        for component in range(3):
          comp = position[component][antenna]
          if (verbose or vis2 is not None):
            if (vis2 is None):
                print "  %s: %+.6f" % (axis[component],comp)
            elif (names[antenna] in names2):
                index2 = list(names2).index(names[antenna])
                comp2 = position2[component][index2]
                if (component == 0):
                    print "  %s: %+.6f   %+.6f    %.6f  (%s on %s)" % (axis[component],comp,comp2,comp-comp2,names2[index2],station2[index2])
                else:
                    print "  %s: %+.6f   %+.6f    %.6f" % (axis[component],comp,comp2,comp-comp2)
            else:
                print "  %s: %+.6f" % (axis[component],comp)
        mydict[names[antenna]] = [position[0][antenna], position[1][antenna], position[2][antenna]]
    if (vis2 is not None):
        for antenna in range(len(names2)):
          if (ant == '' or names2[antenna] == ant):
            if (names2[antenna] not in names):
                print     "                        Antenna %02d = %4s on %s: " % (antenna,names2[antenna],station2[antenna])
                for component in range(3):
                    comp2 = position2[component][antenna]
                    print "  %s: ----------------  %+.6f" % (axis[component],comp2)
    return(mydict)
            
def antennaPositionASDM(vis, vis2=None, ant='', itrf=False, verbose=False):
    """
    This utility prints the antenna positions in ENU coordinates from the 
    ASDM_ANTENNA table for 1 or 2 measurement sets.
    If vis2 is specified, the difference in positions is also computed.
    This is meant to help understand antenna position correction algorithms.
    Specifying ant will limit the display to one antenna.
    If itrf=True, then convert positions from relative ENU to absolute ECEF.
    Todd Hunter  (May 2012)
    """
    antTable = vis+'/ASDM_ANTENNA'
    if (not os.path.exists(antTable)):
        print "Could not find ASDM_ANTENNA table for this measurement set."
        return([],[])
    try:
        tb.open(antTable)
    except:
        print "Could not open ASDM_ANTENNA table: %s" % (antTable)
        return([],[])
    position = tb.getcol('position')
    stationId = tb.getcol('stationId')
    names = tb.getcol('name')
    tb.close()
    try:
        antTable = vis+'/ASDM_STATION'
        tb.open(antTable)
    except:
        print "Could not open ASDM_STATION table: %s" % (antTable)
        return([],[])
    station = tb.getcol('name')
    padPosition = tb.getcol('position')
    padStationId = tb.getcol('stationId')
    tb.close()

    if (vis2 is not None):
      try:
          antTable2 = vis2+'/ASDM_ANTENNA'
          tb.open(antTable2)
      except:
          print "Could not open ASDM_ANTENNA table: %s" % (antTable2)
          return([],[])
      position2 = tb.getcol('position')
      stationId2 = tb.getcol('stationId')
      names2 = tb.getcol('name')
      tb.close()
      try:
          antTable2 = vis2+'/ASDM_STATION'
          tb.open(antTable2)
      except:
          print "Could not open ASDM_STATION table: %s" % (antTable2)
          return([],[])
      station2 = tb.getcol('name')
      padPosition2 = tb.getcol('position')
      padStationId2 = tb.getcol('stationId')

    antennas = len(station)
    if (itrf):
        axis = ['    X','    Y','    Z']
        cx,cy,cz,long,lat = getCOFA(vis)
        if (vis2 is None):
            if verbose:
                print "           vis1"
        else:
            print "     '      vis1            vis2            Difference (m)  (vis1-vis2)"
    else:
        axis = ['East ','North','Up   ']
        if (vis2 is None):
            if verbose:
                print "       vis1"
        else:
            print "       vis1        vis2        Difference (m)  (vis1-vis2)"
    mydict = {}
    for antenna in range(len(names)):
      antindex = list(padStationId).index(stationId[antenna])
      if (itrf):
          # compute antenna XYZ from pad XYZ and ENU correction
          # http://en.wikipedia.org/wiki/Geodetic_system   (ENU to ECEF)
          if (verbose):
              print "antenna%d=%s in vis1 is on %s=%s" % (antenna,names[antenna],
                                                          stationId[antenna],station[antindex])
          phi = lat*math.pi/180.
          lam = math.atan2(padPosition[1][antindex], padPosition[0][antindex])
          itrf_correction = []
          itrf_correction.append(-np.sin(lam)*position[0][antenna] \
                                 -np.sin(phi)*np.cos(lam)*position[1][antenna] + \
                                  np.cos(phi)*np.cos(lam)*position[2][antenna] + \
                                 padPosition[0][antindex])
          itrf_correction.append(+np.cos(lam)*position[0][antenna] \
                                 -np.sin(phi)*np.sin(lam)*position[1][antenna] + \
                                  np.cos(phi)*np.sin(lam)*position[2][antenna] + \
                                 padPosition[1][antindex])
          itrf_correction.append(+np.cos(phi)*position[1][antenna] + \
                                  np.sin(phi)*position[2][antenna] + padPosition[2][antindex])
          if (vis2 is not None):
            if (names[antenna] in names2):
              antenna2 = list(names2).index(names[antenna])
              vis2stationId = stationId2[antenna2]
              ant2index = list(padStationId2).index(vis2stationId)
              if (verbose):
                  print "antenna%d=%s in vis2 is on %s=%s (ant2index=%d)" % (antenna2,
                         names2[antenna2],stationId2[antenna2],station2[ant2index], ant2index)
              itrf_correction2 = []
              phi = lat*math.pi/180.
              lam = math.atan2(padPosition2[1][ant2index], padPosition2[0][ant2index])
              itrf_correction2.append(-np.sin(lam)*position2[0][antenna2] \
                                     -np.sin(phi)*np.cos(lam)*position2[1][antenna2] + \
                                     np.cos(phi)*np.cos(lam)*position2[2][antenna2] + \
                                     padPosition2[0][ant2index])
              itrf_correction2.append(+np.cos(lam)*position2[0][antenna2] \
                                     -np.sin(phi)*np.sin(lam)*position2[1][antenna2] + \
                                     np.cos(phi)*np.sin(lam)*position2[2][antenna2] + \
                                     padPosition2[1][ant2index])
              itrf_correction2.append(+np.cos(phi)*position2[1][antenna2] + \
                                   np.sin(phi)*position2[2][antenna2]+ padPosition2[2][ant2index])
      if (ant == '' or names[antenna] == ant):
        if verbose:
            print "Antenna %02d = %4s on %s: " % (antenna,names[antenna],station[antindex])
        mydict[names[antenna]] = []
        for component in range(3):
            if (itrf):
                comp = itrf_correction[component]
            else:
                comp = position[component][antenna]
            if (vis2 is None):
                mydict[names[antenna]].append(comp)
                if verbose:
                    print "%s: %+.6f" % (axis[component], comp)
            elif (names[antenna] in names2):
                if (itrf):
                    comp2 = itrf_correction2[component]
                else:
                    index2 = list(names2).index(names[antenna])
                    antenna2 = list(names2).index(names[antenna])
                    vis2stationId = stationId2[antenna2]
                    ant2index = list(padStationId2).index(vis2stationId)
                    comp2 = position2[component][index2] 
                if verbose:
                    if (component == 0):
                        print "%s: %+.6f   %+.6f    %+.6f  (%s on %s)" % (axis[component],comp,comp2,comp-comp2,names2[antenna2],station2[ant2index])
                    else:
                        print "%s: %+.6f   %+.6f    %+.6f" % (axis[component],comp,comp2,comp-comp2)
            else:
                if verbose:
                    print "%s: %+.6f" % (axis[component],comp)
                mydict[names[antenna]].append(comp)
    if (vis2 is not None):
        for antenna in range(len(names2)):
          if (itrf):
              # compute antenna XYZ from pad XYZ and ENU correction
              # http://en.wikipedia.org/wiki/Geodetic_system   (ENU to ECEF)
              antindex = list(padStationId2).index(stationId2[antenna])
              itrf_correction2 = []
              phi = lat*math.pi/180.
              lam = math.atan2(padPosition2[1][antindex],padPosition2[0][antindex])
              itrf_correction2.append(-np.sin(lam)*position2[0][antenna] \
                                     -np.sin(phi)*np.cos(lam)*position2[1][antenna] + \
                                     np.cos(phi)*np.cos(lam)*position2[2][antenna] + \
                                     padPosition2[0][antindex])
              itrf_correction2.append(+np.cos(lam)*position2[0][antenna] \
                                     -np.sin(phi)*np.sin(lam)*position2[1][antenna] + \
                                     np.cos(phi)*np.sin(lam)*position2[2][antenna] + \
                                     padPosition2[1][antindex])
              itrf_correction2.append(+np.cos(phi)*position2[1][antenna] + \
                                     np.sin(phi)*position2[2][antenna]+ padPosition2[2][antindex])
          
          if (ant == '' or names2[antenna] == ant):
            if (names2[antenna] not in names):
                print     "                  Antenna %02d = %4s on %s: " % (antenna,names2[antenna],station2[antenna])
                for component in range(3):
                    if (itrf):
                        comp2 = itrf_correction2[component]
                        print "%s: ----------------  %+.6f" % (axis[component],comp2)
                    else:
                        comp2 = position2[component][antenna]
                        print "%s: ----------  %+.6f" % (axis[component],comp2)
    return(mydict)
            
def getWeatherStationPositions(vis, prefix=['WSTB','Meteo','OSF'], 
                               returnDeltaHeights=False,
                               returnClosestPads=False,
                               returnNearbyPads=False, radius=100,
                               referenceStation=None):
    """
    Returns a dictionary keyed by ALMA weather station name, with the value
    equal to the [X,Y,Z] position.
    prefix: restrict stations to those that start with the specified list of strings
            set to None or '' or [''] to not restrict
    returnDeltaHeights: if True, then return height (in m) relative to highest one
           in a dictionary keyed by station name, and the name of the highest station
    referenceStation: the station name with which to base the zero point of deltaHeights
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if prefix is not None and prefix != '':
        if (type(prefix) != list):
            prefix = [prefix]
    else:
        prefix = ['']
    asdmStation = vis + '/ASDM_STATION'
    if (not os.path.exists(asdmStation)):
        print "This measurement set does not have an ASDM_STATION table."
        return
    antennaPads = getPadPositions(vis)
    mytb = createCasaTool(tbtool)
    mytb.open(asdmStation)
    names = mytb.getcol('name')
    positions = mytb.getcol('position')
    types = mytb.getcol('type')
    mydict = {}
    closestPads = {}
    nearbyPads = {}
    for i,name in enumerate(names):
        for p in prefix:
            if (name.lower().find(p.lower()) >= 0 and p != '') or (types[i] == 'WEATHER_STATION' and p == ''):
                mydict[name] = positions[:,i]
                minDistance = 1e9
                nearbyPadlist = []
                nearbyAntennas = []
                for pad in antennaPads:
                    distance = np.linalg.norm(np.array(antennaPads[pad])-mydict[name])
                    if (distance < minDistance):
                        minDistance = distance
                        closestPad = pad
#                        Geocentric height difference                        
#                        deltaHeight = np.linalg.norm(np.array(antennaPads[pad])) - \
#                                      np.linalg.norm(mydict[name])
                        deltaHeight = geocentricXYZToEllipsoidalHeight(np.array(antennaPads[pad]))-\
                                      geocentricXYZToEllipsoidalHeight(mydict[name])
                    if (distance < radius):
                        nearbyPadlist.append(pad)
                        nearbyAntennas.append(getAntennaPads(vis,keyByPadName=True)[pad])
                closestPads[name] = {'closestOccupiedPad': closestPad, 
                                     'distance': minDistance, 
                                     'deltaHeight': deltaHeight,
                                     'closestAntenna': getAntennaPads(vis,keyByPadName=True)[closestPad]}
                nearbyPads[name] = {'nearbyPads': nearbyPadlist,
                                    'nearbyAntennas': nearbyAntennas}
    mytb.close()
    if (returnDeltaHeights):
        return(computeDeltaGeocentricHeights(mydict, referenceStation,
                                             returnHighestStation=True))
    elif (returnClosestPads):
        return(closestPads)
    elif (returnNearbyPads):
        return(nearbyPads)
    else:
        return(mydict)

def geocentricXYZToGeocentricHeight(x, y=None, z=None):
    if (type(x) == list or type(x) == np.ndarray):
        if (len(x) == 3):
            x,y,z = x
        else:
            print "First parameter must be either a scalar or a list of [X,Y,Z] coordinates"
            return
    return np.linalg.norm([x,y,z])

def geocentricXYZToEllipsoidalHeight(x, y=None, z=None):
    """
    Uses formulas from OGP Publication 373-7-2 Geomatics Guidance Note
    number 7, part 2, September 2016 (page 97)
    Returns: height above ellipsoid in meters
    Example: 3771793.968, 140253.342, 5124304.349 yields 72.99992 m
    """
    if (type(x) == list or type(x) == np.ndarray):
        if (len(x) == 3):
            x,y,z = x
        else:
            print "First parameter must be either a scalar or a list of [X,Y,Z] coordinates"
            return
    # WGS84 ellipsoid parameters
    a = 6378137.000
    f = 1/298.2572236
    # derived parameters
    e = (2*f-f**2)**0.5
    b = a*(1-f)
    p = (x**2 + y**2)**0.5
    q = np.arctan(z*a/(p*b))
    epsilon = e**2/(1-e**2)
    phi = np.arctan((z+epsilon*b*sin(q)**3)/(p-e**2*a*cos(q)**3))
    nu = a/(1-e**2*np.sin(phi)**2)**0.5
    h = (p/np.cos(phi)) - nu
    return(h)

def getStandardTemperature(height):
    """
    Computes the 1976 U.S. Standard Atmosphere temperature.
    Uses a temperature lapse rate of -6.5 K/km, and a standard
    temperature of 288.15 K at sea level.
    height: value in meters
    """
    return 288.15 - (6.5*height*0.001)

def getStandardPressure(height, temperature=288.15, temperatureLapseRate=-6.5):
    """
    Computes the 1976 U.S. Standard Atmosphere pressure, with sea level
    pressure of 1013.25 mb, a temperature lapse rate of -6.5 K/km, and a 
    standard temperature of 288.15 K at sea level.
    height: value in meters
    temperature: standard temperature at sea level (288.15 in 1976 US Standard)
    temperatureLapseRate: in units of Kelvin/km (-6.5 in 1976 US Standard)
    """
    standardTemperature = getStandardTemperature(height)
    print "Using standard temperature at this height: %.2f K" % (standardTemperature)
    Lb = temperatureLapseRate * 0.001 # K/m
    R = 8.3144598 # J/mol/K
    g0 = 9.80665  # m/s^2
    M = 0.0289644 # kg/mol
    exponent = g0*M/R/Lb
    return 1013.25*pow(temperature/standardTemperature, exponent)
    
def getNominalObservatoryPressure(observatory='ALMA', temperature=288.15, 
                                  temperatureLapseRate=-6.5):
    """
    Finds the height above the WGS84 ellipsoid, then computes the
    expected pressure there (in mb), using the temperature lapse
    rate of -6.5 K/km.
    temperature: standard temperature at sea level (288.15 in 1976 US Standard)
    temperatureLapseRate: in units of Kelvin/km (-6.5 in 1976 US Standard)
    -Todd Hunter
    """
    height = getObservatoryAltitude(observatory)
    print "Using height = %.1f m" % (height)
    P = getStandardPressure(height)
    return P

def computeDeltaEllipsoidalHeights(mydict, referenceStation=None,
                                   returnHighestStation=False):
    """
    Takes a dictionary keyed by a station name, with values being the position as an
    XYZ array.
    Returns: a list of delta WGS84 ellipsoidal heights compared to the highest station,
       and (optionally) the name of the highest station.  If referenceStation is
       supplied, compute deltaHeights w.r.t. to it.
    -Todd Hunter
    """
    heights = []
    deltaHeights = {}
    sortedStations = sorted(mydict.keys())
    for name in sortedStations:
        height = geocentricXYZToEllipsoidalHeight(mydict[name])
        heights.append(height)
    highestStation = sortedStations[np.argmax(heights)]
    highestHeight = np.max(heights)
    for i in sortedStations:
        if (referenceStation is None):
            deltaHeights[i] = geocentricXYZToEllipsoidalHeight(mydict[i])-highestHeight
        else:
            deltaHeights[i] = geocentricXYZToEllipsoidalHeight(mydict[i])-geocentricXYZToEllipsoidalHeight(mydict[referenceStation])
    if returnHighestStation:
        return(deltaHeights, highestStation)
    else:
        return(deltaHeights)

def computeDeltaGeocentricHeights(mydict, referenceStation=None,
                                  returnHighestStation=False):
    """
    Takes a dictionary keyed by a station name, with values being the position
    as an XYZ array.
    Returns: a list of delta geocentric heights compared to the highest station,
       and (optionally) the name of the highest station.  If referenceStation
       is supplied, compute deltaHeights w.r.t. to it.
    -Todd Hunter
    """
    radii = []
    deltaHeights = {}
    sortedStations = sorted(mydict.keys())
    for name in sortedStations:
        radii.append(np.linalg.norm(mydict[name]))
    highestStation = sortedStations[np.argmax(radii)]
    highestHeight = np.max(radii)
    for i in sortedStations:
        if (referenceStation is None):
            deltaHeights[i] = np.linalg.norm(mydict[i])-highestHeight
        else:
            deltaHeights[i] = np.linalg.norm(mydict[i])-np.linalg.norm(mydict[referenceStation])
    if returnHighestStation:
        return(deltaHeights, highestStation)
    else:
        return(deltaHeights)

def computeDeltaHeights(mydict, referenceStation=None):
    """
    Computes the difference between geocentric height differences between a
    list of stations (with geocentric XYZ positions) and the ellipsoidal
    height differences between them.
    -Todd Hunter
    """
    geo = computeDeltaGeocentricHeights(mydict, referenceStation)
    ell = computeDeltaEllipsoidalHeights(mydict, referenceStation)
    delta = {}
    for s in geo.keys():
        delta[s] = geo[s]-ell[s]
    return delta

def getWeatherStationNames(vis, prefix=['WSTB','Meteo','OSF'], 
                           returnNearestAntennas=False):
    """
    Returns a dictionary keyed by ALMA weather station ID, with the value
    equal to the station name (e.g. 'WSTBn').
    vis: single measurement set, list, or wildcard string
    returnNearestAntennas: if True, then return a dictionary with keys being the 
        weather station names and their values being dictionaries keyed by 'antenna' 
        name, 'distance' in meters, and 'pad'.
    If multiple measurement sets are specified, then return a dictionary of 
    dictionaries keyed by the ms name.
    -Todd Hunter
    """
    if (type(vis) == str):
        if (vis.find('*') >= 0):
            vislist = sorted(glob.glob(vis))
        else: # assume comma-delimited string
            vislist = vis.split(',')
    else:
        vislist = vis
    mydicts = {}
    for vis in vislist:
        if (not os.path.exists(vis)):
            print "Could not find measurement set"
            return
        if (type(prefix) != list):
            prefix = [prefix]
        asdmStation = vis + '/ASDM_STATION'
        if (not os.path.exists(asdmStation)):
            print "This measurement set does not have an ASDM_STATION table."
            return
        mytb = createCasaTool(tbtool)
        mytb.open(asdmStation)
        names = mytb.getcol('name')
        mydict = {}
        for i,name in enumerate(names):
            for p in prefix:
    #            print "Checking if %s contains %s" % (name.lower(),p.lower())
                if (name.lower().find(p.lower()) >= 0):
                    mydict[i] = name
        mytb.close()
        if (returnNearestAntennas):
            stations = getWeatherStationPositions(vis)
            posdict = antennaPosition(vis, verbose=False)
            mydict = {}
            pads = getAntennaPads(vis, keyByAntennaName=True)
            for station in stations:
                mindistance = 1e12
                for antenna in posdict.keys():
                    distance = np.linalg.norm([posdict[antenna][0] - stations[station][0],
                                               posdict[antenna][1] - stations[station][1],
                                               posdict[antenna][2] - stations[station][2]])
    #                print "Distance from %s to %s = %f" % (station, antenna, distance)
                    if (mindistance > distance):
                        mindistance = distance
                        closestAntenna = antenna
                pad = pads[closestAntenna]
                mydict[station] = {'antenna': closestAntenna, 'distance': round(mindistance,1), 'pad': pad}
        mydicts[vis] = mydict
    if len(mydicts) == 1:
        return(mydict)
    else:
        return(mydicts)
        
def padPositionFromMS(vis, vis2=None, ant='', verbose=False):
    """
    This utility reads the pad positions from the ASDM_STATION table for 1 
    or 2 measurement sets.
    If vis2 is specified, the difference in positions is also computed.
    This is meant to help understand antenna position correction algorithms.
    Specifying ant will limit the display to one antenna.
    Returns a dictionary keyed by antenna name, containing padname, X, Y and Z.
    verbose: if True, print the information as readable text.
    Todd Hunter  (May 2012)
    """
    mydict = {}
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    try:
        antTable = vis+'/ASDM_ANTENNA'
        tb.open(antTable)
    except:
        print "Could not open ASDM_ANTENNA table: %s" % (antTable)
        return([],[])
#    position = tb.getcol('position')
    names = tb.getcol('name')
    tb.close()
    try:
        antTable = vis+'/ASDM_STATION'
        tb.open(antTable)
    except:
        print "Could not open ASDM_STATION table: %s" % (antTable)
        return([],[])
    station = tb.getcol('name')
    position = tb.getcol('position')
    tb.close()

    if (vis2 is not None):
      try:
          antTable2 = vis2+'/ASDM_ANTENNA'
          tb.open(antTable2)
      except:
          print "Could not open ASDM_ANTENNA table: %s" % (antTable2)
          return([],[])
#      position2 = tb.getcol('position')
      names2 = tb.getcol('name')
      tb.close()
      try:
          antTable2 = vis2+'/ASDM_STATION'
          tb.open(antTable2)
      except:
          print "Could not open ASDM_STATION table: %s" % (antTable2)
          return([],[])
      station2 = tb.getcol('name')
      position2 = tb.getcol('position')

    antennas = len(station)
    axis = ['X','Y','Z']
    if (vis2 is None):
        print "       vis1"
    else:
        print "       vis1        vis2        Difference (m)  (vis1-vis2)"
    for antenna in range(len(names)):
      if (ant == '' or names[antenna] == ant):
        mydict[names[antenna]] = {}
        mydict[names[antenna]]['pad'] = station[antenna]
        if verbose:
            print "Antenna %02d = %4s on %s: " % (antenna,names[antenna],station[antenna])
        for component in range(3):
            comp = position[component][antenna] 
            if (vis2 is None):
                mydict[names[antenna]][axis[component]] = comp
                if verbose:
                    print "  %s: %+.6f" % (axis[component],comp)
            elif (names[antenna] in names2):
                index2 = list(names2).index(names[antenna])
                comp2 = position2[component][index2]
                if verbose:
                    if (component == 0):
                        print "  %s: %+.6f   %+.6f    %+.6f  (%s on %s)" % (axis[component],comp,comp2,comp-comp2,names2[index2],station2[index2])
                    else:
                        print "  %s: %+.6f   %+.6f    %+.6f" % (axis[component],comp,comp2,comp-comp2)
            else:
                if verbose:
                    print "  %s: %+.6f" % (axis[component],comp)
    if (vis2 is not None):
        for antenna in range(len(names2)):
          if (ant == '' or names2[antenna] == ant):
            if (names2[antenna] not in names):
                if (verbose):
                    print     "                  Antenna %02d = %4s on %s: " % (antenna,names2[antenna],station2[antenna])
                for component in range(3):
                    comp2 = position2[component][antenna] 
                    if verbose:
                        print "  %s: ----------  %+.6f" % (axis[component],comp2)
    return(mydict)

def getScienceChannelsInSameBaseband(vis, spw, mymsmd=''):
    """
    Gets the total number of channels contained in science spws that have 
    the same baseband as the one specified.  For multi-tuning SBs, it will 
    restrict the result to those spws that share the same scan as the 
    specified spw.
    - Todd Hunter
    """
    spws = getScienceSpwsInSameBaseband(vis, spw, mymsmd)
    channels = 0
    closeTool = False
    if mymsmd == '' or mymsmd==None:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        closeTool = True
    for spw in spws:
        channels += mymsmd.nchan(spw)
    if closeTool:
        mymsmd.close()
    return channels

def getChannelAveragedScienceSpws(vis, mymsmd=None):
    """
    Return a list of the channel-averaged spws that correspond to the science
    spws of an ALMA dataset.  These are correlator products, not the SQLDs.
    -Todd Hunter
    """
    closeMymsmd = False
    if mymsmd is None or mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        closeMymsmd = True
    scienceSpws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False)
    print "science spws = ", scienceSpws
    chavgspws = []
    for spw in scienceSpws:
        chavgspw = getChannelAveragedSpw(vis, spw, mymsmd)
        chavgspws.append(chavgspw)
    if closeMymsmd:
        mymsmd.close()
    return chavgspws

def getChannelAveragedSpw(vis, spw, mymsmd=None):
    """
    Finds the channel-averaged spw corresponding to a full-resolution spw
    in an ALMA dataset.
    -Todd Hunter
    """
    closeMymsmd = False
    if mymsmd is None or mymsmd=='':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        closeMymsmd = True
    baseband = mymsmd.baseband(spw)
    spwlist = np.intersect1d(mymsmd.spwsforbaseband(baseband), mymsmd.almaspws(chavg=True))
    chavgspw = spwlist[np.argmin(np.abs(spwlist-spw))]
    if closeMymsmd: mymsmd.close()
    return chavgspw

def getScienceSpwsInSameBaseband(vis, spw, mymsmd=None, verbose=False, scanMatch=True):
    """
    Gets a list of science spws that have the same baseband as the one
    specified.  For multi-tuning SBs, it will restrict the result to those
    spws that share the same scan as the specified spw.
    scanMatch: if True, then only return spws that are also observed in the specified spw
    - Todd Hunter
    """
    needToClose = False
    if (mymsmd is None or mymsmd==''):
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    baseband = mymsmd.baseband(spw)
    if verbose: print "Identified baseband ", baseband
    scan = mymsmd.scansforspw(spw)[0]
    scienceSpws = getScienceSpws(vis,returnString=False,mymsmd=mymsmd)
    if verbose: print "Identified science spws: ", scienceSpws
    spws = np.intersect1d(scienceSpws, 
                          mymsmd.spwsforbaseband(baseband))
    if verbose: print "Identified matching spws: ", spws
    if scanMatch:
        spws = np.intersect1d(spws, mymsmd.spwsforscan(scan))
        if verbose: print "After apply scan match: ", spws
    if needToClose:
        mymsmd.close()
    return spws

def getBasebandNumberFromASDM(asdm, spw):
    """
    Gets the baseband number for an spw in an ASDM.  The spw number
    is the one it will have upon loading into a measurement set.
    -Todd Hunter
    """
    mydict = getSpwsFromASDM(asdm)
    return(mydict[spw]['basebandNumber'])
    
def getScienceSpwsInSameBasebandFromASDM(asdm, spw):
    """
    Gets a list of science spws that have the same baseband as the one
    specified.  For multi-tuning SBs, it will restrict the result to those
    spws that share the same scan as the specified spw.
    - Todd Hunter
    """
    scienceSpws = getScienceSpwsFromASDM(asdm)
    mydict = getSpwsFromASDM(asdm)
    baseband = getBasebandNumberFromASDM(asdm,spw)
#    scan = scansforspw(spw)[0]
    spws = np.intersect1d(scienceSpws, getSpwsForBasebandFromASDM(asdm,baseband))
#    spws = np.intersect1d(spws, spwsforscan(scan))
    return spws

def surmiseEffectiveResolution(vis, spw, window='hanning', kms=False):
    """
    Determines the effective resolution of a channel in an ALMA spw
    for pre-Cycle 3 data.
    Returns: value in Hz, unless kms=True
    -Todd Hunter
    """
    cycle = surmiseCycle(vis)
    if (cycle > 2):
        print "Since this is Cycle %d data, you should instead use au.effectiveResolution. But hopefully the result will be the same." % (cycle)
        N = onlineChannelAveraging(vis, spw)
    else:
        N = surmiseOnlineChannelAveraging(vis, spw)
    factor = windowFunction(window, N, ratio=True)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    chanwidth = abs(getChanWidths(mymsmd, spw)[0])
    meanfreq = getMeanFreqs(mymsmd, spw)[0]
    mymsmd.close()
    if kms:
        return (0.001*c_mks*chanwidth*factor/meanfreq)
    else:
        return (chanwidth*factor)

def surmiseOnlineChannelAveragingFromInfo(nchan, bw, npol, nspw, 
                                          totalCorrelatorChannels,
                                          channelsInBaseband, baseband, rounding=True):
    """
    Infer the level of online-channel averaging used in an ALMA baseband based on the spw 
    information.
    nchan: number of channels in spw
    bw: bandwidth in Hz
    npol: number of polarizations recorded
    nspw: number of spws in the baseband being considered
    totalCorrelatorChannels: available channels (typically 7680, 8160, or 8192), but does
         not need to be exactly right if rounding==True
    channelsInBaseband: number of channels in all spws of the baseband
    baseband: number of the baseband
    rounding: if True, then use floating point divisions and round the final value of N
    Returns: an integer: the level of online-channel averaging inferred
    -Todd Hunter
    """
    if nspw >= 2:
        nspwTwoOrMore = 2
    else:
        nspwTwoOrMore = 1
    if (nchan < 240):
        N = 1
    elif bw >= 1875e6:
        # There is no ambiguity because OT does not allow fraction correlator
        if rounding:
            N = int(round(totalCorrelatorChannels/float(nchan*npol)))
        else:
            N = totalCorrelatorChannels/(nchan*npol)
    elif bw >= 937.5e6:
        # There is still no ambiguity because only 1/2 and 2/2 of correlator 
        # are allowed for a 937.5 window.
        if rounding:
            N = int(round(totalCorrelatorChannels/float(nchan*npol*nspwTwoOrMore)))
        else:
            N = totalCorrelatorChannels/(nchan*npol*nspwTwoOrMore)
    else:
        # now it can be ambiguous, because 1/4 of correlator is also allowed
        # If there is only 1 spw, then assume whole correlator used
        # If there are 2 spws, then assume 1/2 of correlator used
        # If there are 3 spws, then assume 1/4 of correlator used
        # If there are 4 spws, then we know that 1/4 of correlator was used
        if (nspw == 1):
            if rounding:
                N = int(round(totalCorrelatorChannels/float(nchan*npol*nspw)))
            else:
                N = totalCorrelatorChannels/(nchan*npol*nspw)
            if (channelsInBaseband*npol < totalCorrelatorChannels):
                print "The result is ambiguous because we don't know if (in baseband %d) the whole correlator (or 1/2 or 1/4) was used for this one spw." % (baseband)
        elif (nspw == 4):
            # Not ambiguous because we know that 1/4 of correlator was used
            if rounding:
                totalCorrelatorChannelsPerSpw = totalCorrelatorChannels/float(npol*nspw)
                N = int(round(totalCorrelatorChannelsPerSpw / nchan))
            else:
                totalCorrelatorChannelsPerSpw = totalCorrelatorChannels/(npol*nspw)
                N = totalCorrelatorChannelsPerSpw / nchan
        elif (nspw == 2):
            if rounding:
                N = int(round(totalCorrelatorChannels/float(nchan*npol*nspw)))
            else:
                N = totalCorrelatorChannels/(nchan*npol*nspw)
            if (channelsInBaseband*npol < totalCorrelatorChannels):
                print "The result is ambiguous, because we don't know if (in baseband %d) 1/2 the correlator was used for one of the spws, or if 1/4 was used for both. We assume the former." % (baseband)
        elif (nspw == 3):
            if (channelsInBaseband*npol == totalCorrelatorChannels):
                # then we've used all the channels, so N must be 1 for all spws
                N = 1
            elif (channelsInBaseband*npol == totalCorrelatorChannels*3/4):
                # then we've either used exactly 3/4 of the correlator, so N=1
                # or we have used all of it, with N=2 on two spws, etc.
                if rounding:
                    if (nchan == int(round(totalCorrelatorChannels/float(4*npol)))):
                        N = 1
                    elif (nchan == int(round(totalCorrelatorChannels/float(2*npol)))):
                        N = 1
                    else:
                        N = 2
                else:
                    if (nchan == totalCorrelatorChannels/(4*npol)):
                        N = 1
                    elif (nchan == totalCorrelatorChannels/(2*npol)):
                        N = 1
                    else:
                        N = 2
            else:
                if rounding:
                    N = int(round(totalCorrelatorChannels/float(nchan*npol*4)))
                else:
                    N = totalCorrelatorChannels/(nchan*npol*4)
                print "The result is ambiguous, because we don't know if (in baseband %d) 1/4 of the correlator was used for all 3 spws, or if 1/2 was used for one of them. We assume the former." % (baseband)
    return(N)

def surmiseOnlineChannelAveraging(vis, spw='', mymsmd='', rounding=True):
    """
    For pre-Cycle 3 data, tries to determine the channel averaging factor for
    an spw from the number of channels it has and the number of spws in the 
    same baseband.
    spw: either a single integer, string integer, or comma-delimited list
         blank string --> use all science spws
    mymsmd: an existing instance of the msmd tool
    rounding: if True, then perform floating point divisions and round the final result
            (required for ALMA 12m Total Power observations on the ACA correlator)
    Returns: N (if a single spw is specified) or a dictionary if a list of 
             spws is requested)
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (surmiseCycle(vis) > 2):
        print "This is post-Cycle 2 data. Please use au.onlineChannelAveraging instead."
        return
    if mymsmd == '' or mymsmd is None:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        closeTool = True
    if (spw == ''):
        spws = getScienceSpws(vis, returnString=False, mymsmd=mymsmd)
    elif (type(spw) == str):
        spws = [int(i) for i in spw.split(',')]
    elif (type(spw) != list):
        spws = [spw]
    else:
        spws = spw
    N = []
    mydict = {}
    closeTool = False
    for myspw in spws:
        baseband = mymsmd.baseband(myspw)
        nspw = len(getScienceSpwsInSameBaseband(vis, myspw, mymsmd))
        channelsInBaseband = getScienceChannelsInSameBaseband(vis, myspw, mymsmd)
        nchan = mymsmd.nchan(myspw)
        bw = mymsmd.bandwidths(myspw)
        npol = mymsmd.ncorrforpol(mymsmd.polidfordatadesc(myspw))
        if (sevenMeterAntennasMajority(vis, mymsmd)):
            totalCorrelatorChannels = 8192
        else:
            totalCorrelatorChannels = 7680
        myN = surmiseOnlineChannelAveragingFromInfo(nchan, bw, npol, nspw, 
                                                    totalCorrelatorChannels,
                                                    channelsInBaseband, baseband, rounding)
        N.append(myN)
        mydict[myspw] = myN
    if closeTool:
        mymsmd.close()
    if (len(spws) == 1):
        N = N[0]
    else:
        N = mydict
    return N

def onlineChannelAveraging(vis, spw=None, mymsmd=''):
    """
    For Cycle 3-onward data, determines the channel averaging factor from
    the ratio of the effective channel bandwidth to the channel width.
    spw: a single value, or a list; if Nonne, then uses science spws
    Returns:
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (surmiseCycle(vis) < 3):
        print "This is pre-Cycle 3 data, thus the averaging is not definitely known. I will instead use au.surmiseOnlineChannelAveraging."
        return surmiseOnlineChannelAveraging(vis, spw, mymsmd)
    effBW = windowFunction('hanning', returnValue='dictionary')['EffectiveBW']
    closeTool = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        closeTool = True
    if spw is None:
        spw = getScienceSpws(vis, mymsmd=mymsmd, returnString=False)
        print "Using science spws: ", spw
    if type(spw) != list:
        spws = [spw]
    else:
        spws = spw
    Nvalues = []
    for spw in spws:
        chanwidths = mymsmd.chanwidths(spw)
        nchan = len(chanwidths)
        if (nchan < 5):
            return 1
        chanwidth = abs(chanwidths[0])
        if (casadef.casa_version >= '4.6'):
            chaneffwidth = mymsmd.chaneffbws(spw)[0]
        else:
            chaneffwidth = effectiveBandwidth(vis, spw)
        Ns = []
        ratios = []
        for N in effBW.keys():
            ratios.append(effBW[N] / N)
            Ns.append(N)
        ratio = chaneffwidth/chanwidth
        ratios = np.array(ratios)
        # Find the closest match
        Nvalues.append(Ns[np.argmin(abs(ratios - ratio))])
    if closeTool:
        mymsmd.close()
    if (len(spws) == 1):
        return Nvalues[0]
    else:
        return Nvalues

def sensitivityImprovement(vis, spw, newchanwidth, useCAS8534=True, 
                           window='hanning', cubechanwidth=None):
    """
    Computes the expected factor of improvement in sensitivity expected when 
    making images of ALMA data with channel widths wider than the observed 
    width.
    vis: name of measurement set
    spw: single spw index (integer)
    newchanwidth: width of image channel in units of the uvdata channel width, 
        or a string with any common frequency units ('MHz' etc.) or 'km/s'
    useCAS8534: if True, use the approximate formula developed for the imaging 
                  pipeline;
         if False, use a spline fit to the integral table of values (1,2,4,8,16)
    cubechanwidth: if specified, then compute the improvement with respect to
         this chanwidth (which might be larger than the observed chanwidth).
         Units: Width of image channel in units of the uvdata channel width, 
         or a string with any common frequency units ('MHz' etc.) or 'km/s'
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    N = onlineChannelAveraging(vis, spw, mymsmd)
    chanwidth = np.abs(mymsmd.chanwidths(spw)[0])  # Hz
    print  "online channel averaging: %d, chanwidth = %g" % (N,chanwidth)
    spwchan = mymsmd.nchan(spw)
    meanfreq = mymsmd.meanfreq(spw)
    mymsmd.close()
    if type(newchanwidth) == str:
        if (newchanwidth.lower().find('km/s') > 0):
            velocity = float(newchanwidth.lower().replace('km/s',''))
            newchanwidth = 1000*velocity*meanfreq/c_mks
        else:  # frequency units
            newchanwidth = parseFrequencyArgumentToHz(newchanwidth)
    else:
        newchanwidth *= chanwidth  # convert to Hz
    if newchanwidth < chanwidth:
        print "You are requesting a narrower channel width (%f MHz) than the original data have (%f MHz)." % (newchanwidth*1e-6, chanwidth*1e-6)
        return
    PI_request_channels = newchanwidth / chanwidth
    print "requested channel averaging = ", PI_request_channels
    if cubechanwidth is None:
        channelAveraging = N
        originalEffBW = windowFunction(window, channelAveraging=channelAveraging, returnValue='EffectiveBW', useCAS8534=False)
    else:
        if type(cubechanwidth) == str:
            if (cubechanwidth.lower().find('km/s') > 0):
                velocity = float(cubechanwidth.lower().replace('km/s',''))
                cubechanwidth = 1000*velocity*meanfreq/c_mks
            else:  # frequency units
                cubechanwidth = parseFrequencyArgumentToHz(cubechanwidth)
        else:
            cubechanwidth *= chanwidth  # convert to Hz
        if cubechanwidth < chanwidth:
            print "You are using a cube with a narrower channel width (%f MHz) than the original data have (%f MHz)." % (cubechanwidth*1e-6, chanwidth*1e-6)
            return
        channelAveraging = N*float(cubechanwidth)/chanwidth
        originalEffBW = windowFunction(window, channelAveraging=channelAveraging, returnValue='EffectiveBW',useCAS8534=False)
    if useCAS8534:
        newEffBW = windowFunction(window, channelAveraging=N, returnValue='EffectiveBW',useCAS8534=useCAS8534,spwchan=spwchan, nchan=PI_request_channels)
    else:
        newEffBW = windowFunction(window, channelAveraging=N*PI_request_channels, returnValue='EffectiveBW')
    improvement = sqrt(newEffBW  / originalEffBW) 
    return improvement
    
    
def sensitivityAdjustment(N=2, nchan=1, spwchan=128, window='hanning'):
    """
    Implements the equation in Todd's 13/Jul/2016 comment in CAS-8534 which corrects the 
    value returned by im.apparentsens upward to account for the fact that this tool is 
    ignoring the non-independence of the individual channels when multiple adjacent 
    channels are requested.
    N: level of online channel-averaging (1,2,4,8,16)
    nchan: number of contiguous channels being combined
    spwchan: total number of channels in the spw
    window: the window function used by the correlator
    -Todd Hunter
    """
    R = windowFunction(window, N, 'EffectiveBW', ratio=True, useCAS8534=False)
    optimisticBW = R*nchan
    approximateEffectiveBW = windowFunction(window, N, 'EffectiveBW',
                                            useCAS8534=True, nchan=nchan, ratio=True, spwchan=spwchan)
    return (optimisticBW/approximateEffectiveBW)**0.5
            
def windowFunction(window='', channelAveraging=1, returnValue='FWHM', 
                   splineDegree=3, splineSmoothing=None, ratio=False, 
                   useCAS8534=False, nchan=1, spwchan=128):
    """
    Print the FWHM and Effective sensitivity bandwidth of each of the ALMA correlator
    window functions, or return the value for a specific choice. The values are taken
    from the tables in Richard Hills' note of April 8, 2012.
    window: one of ['', 'uniform','hanning','welch','cosine','hamming','bartlett',
                    'blackmann','blackmann-harris']  ''=prints the whole table
    channelAveraging: 1, 2, 4, 8, or 16;  >16 will return channelAveraging, other values
                      will be spline interpolated
    returnValue: 'FWHM' or 'EffectiveBW' or 'dictionary'
    splineDegree: passed as the k parameter to scipy.interpolate.UnivariateSpline
    splineSmoothing: passed as the s parameter to scipy.interpolate.UnivariateSpline
    ratio: if True, then divide by the channelAveraging factor
    useCAS8534: uses the approximate formula developed for the pipeline rather than a spline
    spwchan: number of channels in spw (only used if useCAS8534=True)
    nchan: number of channels being combined (only used if useCAS8534=True)
    Returns:
    The effective number of native channels supplied by a single channel.
    Note: if you want to compute the sensitivity adjustment factor implemented
    by the pipeline to correct values returned by imtool.apparentsens, just
    run au.sensitivityAdjustment.
    -Todd Hunter
    """
    mydict = {'uniform': {'FWHM': {1: 1.207, 2: 1.639, 4: 4.063, 8: 8.033, 16: 16.017},
                          'EffectiveBW': {1: 1.0, 2: 2.0, 4: 4.0, 8: 8.0, 16: 16.0}},
              'hanning': {'FWHM': {1: 2.000, 2: 2.312, 4: 3.970, 8: 7.996, 16: 15.999},
                          'EffectiveBW':{1: 2.667, 2: 3.200, 4: 4.923, 8: 8.828, 16: 16.787}},
              'welch': {'FWHM': {1: 1.590, 2: 1.952, 4: 4.007, 8: 8.001, 16: 16.0},
                        'EffectiveBW':{1: 1.875, 2: 2.565, 4: 4.499, 8: 8.470, 16: 16.457}},
              'cosine': {'FWHM': {1: 1.639, 2: 2.000, 4: 4.000, 8: 8.000, 16: 16.0},
                         'EffectiveBW':{1: 2.000, 2: 2.667, 4: 4.571, 8: 8.533, 16: 16.561}},
              'hamming': {'FWHM': {1: 1.815}, 'EffectiveBW': {1: 2.516}},
              'bartlett': {'FWHM': {1: 1.772}, 'EffectiveBW': {1: 3.000}},
              'blackmann': {'FWHM': {1: 2.299}, 'EffectiveBW': {1: 3.283}},
              'blackmann-harris': {'FWHM': {1: 2.666}, 'EffectiveBW': {1: 3.877}}
              }
    window = window.lower()
    if (window in mydict.keys()):
        if (returnValue == 'dictionary'):
            return mydict[window]
        if (channelAveraging not in mydict[window]['FWHM'].keys() or useCAS8534):
            if (channelAveraging < 1 or window not in ['uniform','hanning','welch','cosine']):
                print "Invalid choice of channelAveraging"
                return
            if useCAS8534:
                approximateEffectiveBW = nchan + 1.12*(spwchan-nchan)/float(spwchan)/channelAveraging
                approximateEffectiveBW *= channelAveraging
                if ratio:
                    return approximateEffectiveBW/channelAveraging
                else:
                    return approximateEffectiveBW
            elif channelAveraging < 17:
                print "Using spline fit (set useCAS8534=True to use the formula in CAS-8534)"
                if channelAveraging > 8:
                    a = 8; b = 16
                elif channelAveraging > 4:
                    a = 4; b = 8
                elif channelAveraging > 2:
                    a = 2; b = 4
                elif channelAveraging > 1:
                    a = 1; b = 2
                myspline = scipy.interpolate.UnivariateSpline(mydict[window][returnValue].keys(),
                                                              mydict[window][returnValue].values(), 
                                                              k=splineDegree, 
                                                              s=splineSmoothing)
                factor = float(myspline(channelAveraging))
                if abs(channelAveraging - np.round(channelAveraging)) >= 0.1:
                    print "Warning: spline-interpolating computed table between %d and %d (for %.1f channels)" % (a,b,channelAveraging)
                if ratio:
                    return factor/channelAveraging
                else:
                    return factor
            else:
                return channelAveraging
        if (returnValue not in mydict[window].keys()):
            print "Invalid choice of returnValue"
            return
        if ratio:
            return(mydict[window][returnValue][channelAveraging]/channelAveraging)
        else:
            return(mydict[window][returnValue][channelAveraging])
    else:
        if (returnValue == 'dictionary'):
            return mydict
        print "No window function specified.  All will be displayed"
        print "                           in input channels   in output channels"
        print "%16s  ChanAvg  FWHM  EffectiveBW   FWHM  EffectiveBW" % ('Window type')
        for key in ['uniform','hanning','welch','cosine','hamming','bartlett',
                    'blackmann','blackmann-harris']:
            for chanAvg in sorted(mydict[key]['FWHM'].keys()):
                print "%16s     %d    %.3f   %.3f       %.3f    %.3f" % (key, chanAvg, mydict[key]['FWHM'][chanAvg],
                     mydict[key]['EffectiveBW'][chanAvg], mydict[key]['FWHM'][chanAvg]/chanAvg,
                     mydict[key]['EffectiveBW'][chanAvg]/chanAvg) 

def smoothTsys(caltable, channels=0, window='flat', window_len=0,
               decimate=True, avoidflags=True, outputname=None, overwrite=True):
    """
    Smooths the Tsys solutions for all spws in a caltable for purposes of 
    comparison with lower resolution measurements.
    Inputs:
    window:
         'flat', 'hanning', 'hamming', 'bartlett', 'blackman' (use np.convolve)
      or 'decimate'  (uses scipy.signal.decimate, warning: causes phase shift!)
    Specify either channels or window_len
    channels: number of channels desired in output
    window_len: smoothing level in channels 
    decimate: if True, then after running np.convolve (i.e. au.smooth), then 
       take the mean of every window_len channels to emulate native Tsys at 
       new resolution.  Note: SNR simply set to 1 and PARAMERR set to 0.1.
    outputname: default is <caltable>_smooth_<window>_XXXchan
                where 'XX'=number of output channels
    -Todd Hunter
    """
    spws = getSpwsFromCaltable(caltable)
    if (outputname is None):
        # This is necessary in case some spws do not need any smoothing to reach specified channels
        outputname = caltable+'_smooth_%s_%dchan' % (window,channels)
        if (decimate):
            outputname += '_decimated'
    for spw in spws:
        outputname = smoothTsysSpw(caltable, spw, channels, window_len, window, 
                                   decimate, avoidflags, outputname, overwrite)
        if outputname is None: return
        caltable = outputname
        overwrite = False

def smoothTsysSpw(caltable, spw, channels=0, window_len=0, window='flat', 
                  decimate=True, avoidflags=True, outputname=None, 
                  overwrite=True, verbose=False):
    """
    Smoothes the Tsys solutions for a single spw for purposes of comparison 
    with lower resolution measurements. 
    spw: a single spw (integer or integer string)
    window: 'flat', 'hanning', 'hamming', 'bartlett', 'blackman' (uses np.convolve)
        or 'decimate'  (uses scipy.signal.decimate with fir filter, causes phase-shift!)
    Specify either channels or window_len
    channels: number of channels desired in output
    window_len: smoothing level in channels (2,4, etc.) 
    decimate: if True, then after running np.convolve (i.e. au.smooth), then take the
           mean of every window_len channels to emulate native Tsys at new resolution
    outputname: default is <caltable>_smooth_<window>_XXXchan_[decimated]
                where 'XX'=number of output channels
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "Could not find caltable."
        return
    spw = int(spw)
    spws = getSpwsFromCaltable(caltable)
    if (spw not in spws):
        print "This spw is not in the caltable. Try: ", spws
        return
    if (channels <= 0 and window_len <= 0):
        print "Must specify either channels or window_len."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    # The following 2 names are not compatible with tables made before casa 3.4.
    gainColumnName = 'FPARAM'
    spwColumnName = 'SPECTRAL_WINDOW_ID'
    myt = mytb.query(spwColumnName+' == %d'%spw)
    gsm = myt.getcol(gainColumnName)
    flags = myt.getcol('FLAG')
    antennas = myt.getcol('ANTENNA1')
    cal_desc_id = myt.getcol(spwColumnName)
    myt.close()
    mytb.close()
    p = gsm.shape
    npol = p[0] 
    nant = p[2]  # spw+antenna combinations (size=nspw*nant=nant), i.e. nrows in queried table
    nchan = p[1]
    if (channels > 0):
        window_len = nchan / channels
        if (window_len <= 1):
            print "No smoothing necessary on spw %d since %d/%d=%d" % (spw,nchan,channels,window_len)
            if (outputname is not None):
                if (not os.path.exists(outputname)):
                    print "Copying %s to %s" % (caltable, outputname)
                    os.system('cp -r %s %s'%(caltable,outputname))
                return(outputname)
            return caltable
        print "Setting window_len=%d for spw %d.  " % (window_len,spw),
    channels = nchan / window_len
    if (decimate or window=='decimate'):
        print "Output will have %d channels." % (channels)
    if (window == 'decimate'):
        output = gsm[:,::window_len,:]
    chan = range(nchan)
    for i in range(npol):
        #   essentially smooth each pol/spw
        for j in range(nant):
            dreal = gsm[i,:,j]
            flag = flags[i,:,j]
            if (avoidflags):
                # Now replace each flagged channel's value with nearest unflagged value in this spw
                channelsToReplace = np.where(flag == 1)[0]
                goodChannels = np.where(flag == 0)[0]
                channelsReplaced = 0
                if (len(goodChannels) > 0 and len(channelsToReplace)>0):
                    # only examine spws that are not completely flagged and not completely unflagged
                    for mychan in range(len(channelsToReplace)):
                        # find the closest unflagged channel
                        closestDistance = 1000000
                        for good in range(len(goodChannels)):
                            distance = abs(channelsToReplace[mychan]-goodChannels[good])
                            if (distance < closestDistance):
                                closestGoodChannel = good
                                closestDistance = distance
                        dreal[channelsToReplace[mychan]] = dreal[goodChannels[closestGoodChannel]]
                        if (verbose):
                            print "row=%d, pol=%d, spw=%d, Ant%d: avoiding flagged channel %d with good channel %d" % (j,i,
                                   cal_desc_id[j],antennas[j],channelsToReplace[mychan],goodChannels[closestGoodChannel])
                        channelsReplaced += 1
                if (channelsReplaced > 0 and verbose):
                    print "Avoided %d flagged channels on pol=%d, spw=%d, antenna=%d" % (channelsReplaced,i,cal_desc_id[j],antennas[j])
            #   window type and window_len will be options
            if (window == 'decimate'):
                newXaxis, output[i,:,j] = filterAndDecimate(range(len(dreal)),
                                                            dreal, window_len)
#                output[i,:,j] = scipy.signal.decimate(dreal, 2, 2*window_len)
            else:
                gsm[i,:,j] = smooth(dreal, window_len, window)

    #  Overwrite smoothed table into already defined output.
    if (outputname is None):
        smooth_table = caltable+'_smooth_%s_%dchan' % (window,channels)
        if (decimate):
            smooth_table += '_decimated'
    else:
        smooth_table = outputname
    if (not os.path.exists(smooth_table)):
        print "Copying %s to %s" % (caltable, smooth_table)
        os.system('cp -r %s %s'%(caltable,smooth_table))
    elif (overwrite):
        print "Removing %s" % (smooth_table)
        shutil.rmtree(smooth_table)
        print "Copying %s to %s" % (caltable, smooth_table)
        os.system('cp -r %s %s'%(caltable,smooth_table))

    mytb.open(smooth_table, nomodify=False)
    myt = mytb.query(spwColumnName+' == %d'%spw)
    if (window == 'decimate'):
        myt.putcol(gainColumnName, output)
        myt.putcol('SNR', output/output)
        myt.putcol('PARAMERR', 0.1*output/output)
        myt.putcol('FLAG', 0*output)
    elif (decimate):
        output = decimate3DArrayByMean(gsm,1,window_len)
        flags = decimate3DArrayByMean(flags,1,window_len)
        myt.putcol(gainColumnName, output)
        myt.putcol('FLAG', flags)
        # SNR is currently always 1 in Tsys caltables
        myt.putcol('SNR', output/output)
        # PARAMERR is currently always 0.1 in Tsys caltables
        myt.putcol('PARAMERR', 0.1*output/output)
    else:
        myt.putcol(gainColumnName, gsm)
    myt.close()
    mytb.close()
    if (window == 'decimate' or decimate):
        smoothSpectralWindowTable(smooth_table+'/SPECTRAL_WINDOW', spw, window_len)
    print "Smoothed solution written to: %s" % (smooth_table)
    return(smooth_table)

def filterAndDecimate(freq, intensity, window_len=8, order=8):
    """
    Uses scipy Butterworth filter and filtfilt to low pass and decimate a 
    signal.  Pads the data by 1/3 of the length to avoid edge effects.
    freq: x-axis of the signal
    intensity: y-axis of the signal
    window_len: decimation factor
    order: the order (N) of the Butterworth filter to use
    Returns: two arrays: new x-axis and new y-axis
    -Todd Hunter
    """
    if window_len < 2:
        print "window_len must be >= 2"
        return
    b, a = scipy.signal.butter(order, 1./window_len, btype='lowpass')
    y = scipy.signal.filtfilt(b, a, intensity, padlen=len(freq)/3)
    # now decimate
    decimated = []
    newfreq = []
    for i in range(0,len(y),window_len):
        decimated.append(np.mean(y[i:i+window_len]))
        newfreq.append(np.mean(freq[i:i+window_len]))
    decimated = np.array(decimated)
    newfreq = np.array(newfreq)
    return newfreq, decimated
        
def filterAndDecimateFromFile(filename='sky_hot_ambient.txt', window_len=8, 
                              order=8, plotfile=''):
    """
    Uses scipy Butterworth filter and filtfilt to low pass and decimate a 
    signal.  Pads the data by 1/3 of the length to avoid edge effects.
    filename: ascii file containing two columns: freq, intensity
    npts: number of points in decimated spectrum
    window_len: decimation factor
    order: the order (N) of the Butterworth filter to use
    plotfile: if True, then overlay the original signal with the filtered signal
    Returns: two low-pass filtered and decimated arrays: freq, intensity
    -Todd Hunter
    """
    if not os.path.exists(filename):
        print "Could not find file: ", filename
        return
    f = open(filename,'r')
    lines = f.readlines()
    f.close()
    freq = []
    yaxis = []
    for line in lines:
        x, y = line.split()
        freq.append(float(x))
        yaxis.append(float(y))
    freq = np.array(freq)
    yaxis = np.array(yaxis)
    newfreq, decimated = filterAndDecimate(freq, yaxis, window_len, order)
    if plotfile != '':
        if plotfile == True:
            plotfile = filename + '.png'
        pb.clf()
        pb.plot(freq, yaxis, 'k-', newfreq, decimated, 'r-')
        pb.xlabel('Frequency (GHz)')
        pb.draw()
        pb.savefig(plotfile)
    return newfreq, decimated
    
def decimate3DArrayByMean(v, axis, window_len):
    """
    Resamples one axis of a 3D array by taking mean of every window_len values.
    Assumes the values have already been low-pass filtered (e.g. by au.smooth).
    v: the 3D array to draw from
    axis: which axis to decimate (0,1,2)
    window_len: the decimation factor (2,3,etc.)
         Note: only tested for array size that is evenly divisible by window_len.
    Returns: a new 3D array
    -Todd Hunter
    """
    newv = v[:,::window_len,:]
    if (axis==0):
        for i in range(np.shape(v)[0]/window_len):
            for j in range(np.shape(v)[1]):
                for k in range(np.shape(v)[2]):
                    newv[i,j,k] = np.mean(v[i*window_len:(i+1)*window_len,j,k])
    elif (axis==1):
        for i in range(np.shape(v)[0]):
            for j in range(np.shape(v)[1]/window_len):
                for k in range(np.shape(v)[2]):
                    newv[i,j,k] = np.mean(v[i,j*window_len:(j+1)*window_len,k])
    else:
        for i in range(np.shape(v)[0]):
            for j in range(np.shape(v)[1]):
                for k in range(np.shape(v)[2]/window_len):
                    newv[i,j,k] = np.mean(v[i,j,k*window_len:(k+1)*window_len])
    return newv

def smoothSpectralWindowTable(mytable, spw, window_len):
    """
    Decimates the vector columns of a spectral window table by taking the 
    mean of every window_len channels.
    -Todd Hunter
    """
    if (not os.path.exists(mytable)):
        print "Table does not exist."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(mytable, nomodify=False)
    for column in ['CHAN_FREQ', 'CHAN_WIDTH', 'EFFECTIVE_BW', 'RESOLUTION']:
        value = mytb.getcell(column,spw)
        newvalue = []
        for i in range(0,len(value),window_len):
            newvalue.append(np.mean(value[i:i+window_len]))
        mytb.putcell(column, spw, newvalue)
    mytb.putcell('NUM_CHAN', spw, len(newvalue))
    mytb.close()

def smoothbandpass(caltable='',window_len=20, window='flat', method='ri' ,
                   avoidflags=True, verbose=False, fullVerbose=False,
                   log='', outputname=None):
  """
  Note: This function is obsolete and should not be used.  Instead, set
        the frequency solint in the CASA bandpass task.
  Unless the outputname is specified, the output table will have
  '_smoothXXwindow_method' appended to the name,
  where 'XX'=window_len and 'window' is the window type.  The window 
  type options are: 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'.
  Method types are 'ri' = real & imaginary or 'ap' = amp & phase.
  -- Ed Fomalont & Todd Hunter, Sep 2011/2013
  """
#  Set some defaults
  ggr = 0
  ggr = 0
  mytb = createCasaTool(tbtool)
  mytb.open(caltable)
  if (outputname is None):
      smooth_table = caltable+'_smooth%d%s_%s' % (window_len,window,method)
  else:
      smooth_table = outputname
  gainColumnName = 'GAIN'
  spwColumnName = 'CAL_DESC_ID'
  if ('GAIN' not in mytb.colnames()):
      if (caltable.find('tsys')<0):
          print "This is a new-style caltable.  You should not use smoothbandpass, but instead use"
          print "the new on-the-fly channel averaging of the casa 3.4 command bandpass()."
          return
      if (method == 'ri' or method == 'ap'):
          gainColumnName = 'CPARAM'
      elif (method == 'float'):
          gainColumnName = 'FPARAM'
      spwColumnName = 'SPECTRAL_WINDOW_ID'
  if (gainColumnName not in mytb.colnames()):
      print "Mismatch between method parameter and cal table type."
      return
  g=mytb.getcol(gainColumnName)
  flags=mytb.getcol('FLAG')
  antennas=mytb.getcol('ANTENNA1')
  cal_desc_id=mytb.getcol(spwColumnName)
  gsm=g
  p=g.shape
  l1 = p[0]  # polarizations
  l2 = p[2]  # spw+antenna combinations   (size=nspw * nant), i.e. nrows in table
  ld = p[1]  # channels
  chan = range(0,ld)
  if (log != ''):
      f = open(log,'w')
  for i in range (0,l1):
    #   essentially smooth each pol/spw
    for j in range (0,l2):
        if (method == 'float'):
            dreal = g[i,:,j]
        else:
            dcompl = g[i,:,j]
            dreal = np.real(dcompl)
        flag = flags[i,:,j]
        if (method != 'float'):
            dimag = np.imag(dcompl)
        if (avoidflags):
          # Now replace each flagged channel's value with nearest unflagged value in this spw
          channelsToReplace = np.where(flag == 1)[0]
          goodChannels = np.where(flag == 0)[0]
          channelsReplaced = 0
          if (len(goodChannels) > 0 and len(channelsToReplace)>0):
            # only examine spws that are not completely flagged and not completely unflagged
            for mychan in range(len(channelsToReplace)):
               # find the closest unflagged channel
               closestDistance = 1000000
               for good in range(len(goodChannels)):
                   distance = abs(channelsToReplace[mychan]-goodChannels[good])
                   if (distance < closestDistance):
                       closestGoodChannel = good
                       closestDistance = distance
               dreal[channelsToReplace[mychan]] = dreal[goodChannels[closestGoodChannel]]
               if (method != 'float'):
                   dimag[channelsToReplace[mychan]] = dimag[goodChannels[closestGoodChannel]]
               if (fullVerbose):
                   print "row=%d, pol=%d, spw=%d, Ant%d: avoiding flagged channel %d with good channel %d" % (j,i,
                          cal_desc_id[j],antennas[j],channelsToReplace[mychan],goodChannels[closestGoodChannel])
               if (log != ''):
                   f.write("row=%d, pol=%d, spw=%d, Ant%d: avoiding flagged channel %d with good channel %d\n" % (j,i,
                            cal_desc_id[j],antennas[j],channelsToReplace[mychan],goodChannels[closestGoodChannel]))
               channelsReplaced += 1
          if (channelsReplaced > 0 and (verbose or fullVerbose)):
              print "Avoided %d flagged channels on pol=%d, spw=%d, antenna=%d" % (channelsReplaced,i,cal_desc_id[j],antennas[j])
        #   window type and window_len will be options
        if (method == 'ri'):
            ggr = smooth(dreal, window_len, window)
            ggi = smooth(dimag, window_len, window)
            for k in chan:
                gsm[i,k,j] = np.complex(ggr[k],ggi[k])
        elif (method == 'ap'):
            phase = np.arctan2(dimag, dreal)
            amp = np.abs(dcompl)
            ampSmooth = smooth(amp, window_len, window)
            phaseSmooth = smooth(phase, window_len, window)
            dreal = ampSmooth * np.cos(phaseSmooth)
            dimag = ampSmooth * np.sin(phaseSmooth)
            for k in chan:
                gsm[i,k,j] = np.complex(dreal[k],dimag[k])
        elif (method == 'float'):
            gsm[i,:,j] = smooth(dreal, window_len, window)
        else:
            print "Unrecognized method = ", method
            return

  if (log != ''):
      f.close()
  mytb.close()
#   Overwrite smoothed bandpass into already defined output.
  os.system('cp -r %s %s'%(caltable,smooth_table))
  mytb.open(smooth_table, nomodify=False)
  mytb.putcol(gainColumnName, gsm)
  mytb.close()
  print "Smooth solution written to: %s" % (smooth_table)
  return

def getScansForIntentFast(vm,uniqueScans,intent):
  """
  Given a ValueMapping structure and a list of scans, return those
  that have the specified intent.
  This is a faster version of the function in ValueMapping.
  - Todd Hunter
  """
  onsourceScans = []
  for s in uniqueScans:
    scanIntents = vm.getIntentsForScan(s)
    if (intent in scanIntents):
        onsourceScans.append(s)
  return(onsourceScans)

def lstRange(vis, verbose=True, vm='',intent='OBSERVE_TARGET#ON_SOURCE'):
  """
  Compute the LST of start and end of the specified ms.
  For further help and examples, see http://casaguides.nrao.edu/index.php?title=Lstrange
  -- Todd Hunter
  """
  return(lstrange(vis,verbose=verbose,vm=vm,intent=intent))
    
def lstrange(vis, verbose=True, vm='', intent='OBSERVE_TARGET#ON_SOURCE', fieldID=-1, mymsmd=None):
  """
  Compute the LST of start and end of the specified ms.
  intent: use only the scans observed with the specified intent
  fieldID: for computing the hour angle, use this field ID rather than the first with the
           specified intent
  -- Todd Hunter
  """
  if (os.path.exists('%s/table.dat'%vis)==False):
      print "Could not find %s/table.dat, are you sure this is an ms?" % (vis)
      return
  observatory = getObservatoryName(vis)
  if (observatory == ''):
      observatory = 'ALMA'
      print "Assuming ", observatory

  if (casadef.casa_version >= casaVersionWithMSMD):
      if mymsmd is None:
          needToClose = True
          mymsmd = createCasaTool(msmdtool)
          mymsmd.open(vis)
      else:
          needToClose = False
      uniqueScans = mymsmd.scannumbers()
  else:
      if (vm == ''):
          print "Running ValueMapping... (this may take a minute)"
          vm = ValueMapping(vis)
      uniqueScans = np.unique(vm.scans)

# This way is really slow:
#  onsourceScans = np.unique(vm.getScansForIntent(intent))
  if (verbose):
      print "Checking intents for each scan..."
  if (casadef.casa_version >= casaVersionWithMSMD):
      intents = mymsmd.intents()
      foundIntent = False
      for i in intents:
          if (i.find(intent) >= 0):
              foundIntent = True
              break
      if (foundIntent):
          onsourceScans = mymsmd.scansforintent(intent)
      else:
          onsourceScans = []
  else:
      onsourceScans = getScansForIntentFast(vm,uniqueScans,intent)
  if (len(onsourceScans) < 1):
      # try the "old school" format
      intent = intent.replace('#','.')
      if (casadef.casa_version >= casaVersionWithMSMD):
          intents = mymsmd.intents()
          foundIntent = False
          for i in intents:
              if (i.find(intent) >= 0):
                  foundIntent = True
                  break
          if (foundIntent):
              onsourceScans = mymsmd.scansforintent(intent)
          else:
              onsourceScans = []
      else:
          onsourceScans = getScansForIntentFast(vm,uniqueScans,intent)
  if (verbose):
        print "%s scans = " % (intent), onsourceScans
  i = 0
  wikiline = ''
  wikiline2 = ''
  wikiline3 = 'no onsource time | '
  # First, examine the list of all scans (where i will be 0), then 
  # the list of the on-target scans (where i will be 1).
  for scans in [uniqueScans,onsourceScans]:
      if (len(scans) > 0):
          [latitude, longitude, obs] = getObservatoryLatLong(observatory)
          if (casadef.casa_version >= casaVersionWithMSMD):
              times = mymsmd.timesforscans(scans)
              mjdsecmin = np.min(times)
              mjdsecmax = np.max(times)
              mjds = times/86400.
              intMjds = np.int32(mjds)
              uniqueMjds = np.unique(intMjds)
              LSTs = []
              for mjd in uniqueMjds:
                  idx = np.where(mjd == intMjds)[0]
                  mjdsecmin = np.min(times[idx])
                  mjdsecmax = np.max(times[idx])
                  LSTs.append(ComputeLST(mjdsecmin, longitude))
                  LSTs.append(ComputeLST(mjdsecmax, longitude))
          else:
              times = vm.getTimesForScans(scans)
              mjdsecmin = 1e12
              mjdsecmax = 0
              mjds = []
              LSTs = []
              for t in times:
    #  #  #  This is too slow:
    #  #  #        mjdsecmin = np.amin([np.amin(t),mjdsecmin])
    #  #  #        mjdsecmax = np.amax([np.amax(t),mjdsecmax])
    #  #  #  Assume the times are in ascending order:
                  mjdsecmin = np.amin([t[0],mjdsecmin])
                  mjdsecmax = np.amax([t[-1],mjdsecmax])
                  mjds += np.unique(np.int32(t/86400.))
                  LSTs.append(ComputeLST(mjdsecmin, longitude))
                  LSTs.append(ComputeLST(mjdsecmax, longitude))
              uniqueMjds = np.unique(mjds)
#          print "unique MJDs = ", uniqueMjds
          LST = np.zeros(2)
          LST[0] = np.min(LSTs)
          LST[1] = np.max(LSTs)
          if (i == 1):
              style = "on source"
          else:
              style = "of whole SB"
          duration = LST[1]-LST[0]
          duration2 = LST[1]+24-LST[0]
          if (duration2 < duration):
              duration = duration2
          if (verbose):
              print "LST range %s = %.2f to %.2f = %02d:%02d to %02d:%02d (%.1f minutes)" % (style,LST[0],LST[1],
                  np.floor(LST[0]),np.floor(60*(LST[0]-np.floor(LST[0]))), np.floor(LST[1]),
                  np.floor(60*(LST[1]-np.floor(LST[1]))), duration*60)
              if (i==1):
                  # get RA of science field
                  if (fieldID == -1):
                      if (casadef.casa_version >= casaVersionWithMSMD):
                          fieldID = mymsmd.fieldsforintent(intent)[0]
                      else:
                          fieldname = getFieldsForTime(vm.fieldsForTimes,times[0][0])
                          fieldID = vm.getFieldIdsForFieldName(fieldname)
                  RA, DEC = getRADecForField(vis, fieldID, forcePositiveRA=True, usemstool=True)
                  RA = RA*12/np.pi
                  HA = np.zeros(2)
                  HA[0] = LST[0]-RA
                  HA[1] = LST[1]-RA
                  HA0sign = ("%+f" % HA[0])[:1]
                  HA1sign = ("%+f" % HA[1])[:1]
                  aHA = np.zeros(2)
                  aHA[0] = abs(HA[0])
                  aHA[1] = abs(HA[1])
                  print "Field %d RA = %fh" % (fieldID, RA)
                  print " HA range %s = %+.2f to %+.2f = %c%02d:%02d to %c%02d:%02d" % (style,HA[0],HA[1],
                      HA0sign, np.floor(aHA[0]), np.floor(60*(aHA[0]-np.floor(aHA[0]))),
                      HA1sign, np.floor(aHA[1]), np.floor(60*(aHA[1]-np.floor(aHA[1]))))
          [mjdmin,utmin] = mjdSecondsToMJDandUT(mjdsecmin)
          [mjdmax,utmax] = mjdSecondsToMJDandUT(mjdsecmax)
          if (i==0):
              if (casadef.casa_version >= casaVersionWithMSMD):
                  alltimes = times
              else:
                  alltimes = np.array([val for subl in times for val in subl])
              deltaT = 0.5*(abs(np.min(alltimes[np.where(alltimes > mjdsecmin)]) - mjdsecmin) + 
                            abs(np.max(alltimes[np.where(alltimes < mjdsecmax)]) - mjdsecmax))
              clockTimeMinutes = (mjdmax - mjdmin + deltaT/86400.)*1440.
          if (verbose):
              print "MJD range %s = %.4f to %.4f" % (style, mjdmin, mjdmax)
              meanJD = mjdToJD(0.5*(mjdmin+mjdmax))
              print "Mean JD %s = %f" % (style, meanJD)
              print " UT range %s = %s to %s" % (style, utmin, utmax)
          tb.open(vis+'/OBSERVATION')
          sbname = 'unknown'
          exec_uid = 'unknown'
          if ('SCHEDULE' in tb.colnames()):
              if (tb.iscelldefined('SCHEDULE',0)):
                  sched = tb.getcol('SCHEDULE')
                  sbname = '%s' % (sched[0][0].split()[1])  # This is the SB UID.
                  exec_uid = '%s' % (sched[1][0].split()[1])
          tb.close()
          if (i==0):
              wikiline2 += "| %s | %s | %s | %s-%s | %02d:%02d-%02d:%02d | %.1f | " % (utmin[0:10],sbname,exec_uid,utmin[10:-6],utmax[11:-6],np.floor(LST[0]),np.floor(60*(LST[0]-np.floor(LST[0]))), np.floor(LST[1]), np.floor(60*(LST[1]-np.floor(LST[1]))), clockTimeMinutes)
              csvline = "%s,%s,%.2f" % (sbname, exec_uid, clockTimeMinutes)
              wikiline += "%s-%s | %02d:%02d-%02d:%02d | %.1f |" % (utmin[0:-6],utmax[11:-6],np.floor(LST[0]),np.floor(60*(LST[0]-np.floor(LST[0]))), np.floor(LST[1]), np.floor(60*(LST[1]-np.floor(LST[1]))),clockTimeMinutes)
          else:
              # print out elevation range for mjdsecmin to mjdsecmax
              # could use TsysExplorer(vis) but it fails at line 1144
              tb.open("%s/POINTING" % vis)
              azel = 1
              try:
                  elevation = np.transpose(tb.getcol("DIRECTION")[azel])
                  elevTime  = tb.getcol("TIME")
                  tb.close()
                  if (casadef.casa_version >= casaVersionWithMSMD):
                      t = mymsmd.timesforscan(scans[0])[0]
                  else:
                      t = vm.getTimesForScans(scans[0])[0]
                  matches1 = np.where(elevTime > np.min(t[0]))[0]
                  matches2 = np.where(elevTime < np.max(t[-1]))[0]
                  matches = np.intersect1d(matches1,matches2)
                  startElev = elevation[matches[0]]*180/math.pi
                  if (casadef.casa_version >= casaVersionWithMSMD):
                      t = mymsmd.timesforscan(scans[0])[0]
                  else:
                      t = vm.getTimesForScans(scans[-1])[0]
                  matches1 = np.where(elevTime > np.min(t[0]))[0]
                  matches2 = np.where(elevTime < np.max(t[-1]))[0]
                  matches = np.intersect1d(matches1,matches2)
                  stopElev = elevation[matches[-1]]*180/math.pi
                  if (verbose):
                      print "Elevation range on %s scans = %.1f-%.1f" % (intent, startElev,stopElev)
                  wikiline += "%02d:%02d-%02d:%02d | %.0f-%.0f | " % (np.floor(LST[0]),np.floor(60*(LST[0]-np.floor(LST[0]))), np.floor(LST[1]), np.floor(60*(LST[1]-np.floor(LST[1]))), startElev, stopElev)
                  wikiline3 = "%.0f-%.0f | " % (startElev,stopElev)
              except:
                  wikiline3 = "pointing table empty | "
                  if (verbose):
                      print "The pointing table appears to be empty.  Was it deleted because this is a mosaic?"
                  wikiline += "%02d:%02d-%02d:%02d | " % (np.floor(LST[0]),np.floor(60*(LST[0]-np.floor(LST[0]))), np.floor(LST[1]), np.floor(60*(LST[1]-np.floor(LST[1]))))
          i += 1
  if (verbose):
      print "wikiline = %s" % (wikiline)
  csvline = 'csvline = %s' % (csvline)
  if (casadef.casa_version >= casaVersionWithMSMD):
      if needToClose:
          mymsmd.close()
  return (wikiline2, wikiline3,clockTimeMinutes,csvline)
  # end of lstrange()

def findNearestFieldInVis(vis, radec, returnSeparation=False):
    """
    Returns nearest field in a measurement set to a specified absolute position
    radec: sexagesimal string
    Returns: field ID (and separation in degrees, if returnSeparation==True)
    -Todd Hunter
    """
    ra, dec = radec2deg(radec)
    mylist = getRADecForFields(vis, blendByName=False)
    ralist = np.degrees(mylist[0][0])
    declist = np.degrees(mylist[1][0])
    nearestField, smallestSeparation = findNearestField(ralist, declist, ra, dec)
    if returnSeparation:
        return nearestField, smallestSeparation
    else:
        return nearestField

def findNearestField(ra,dec,raAverageDegrees, decAverageDegrees):
    """
    Finds the field in a list that is nearest to the specified average position.
    ra and dec must be equal-sized lists, adn in degrees.
    raAvergeDegrees and decAverageDegrees must be scalar values.
    -- Todd Hunter
    """
    nearestField = -1
    smallestSeparation = 1e15
    for i in range(len(ra)):
        separation = angularSeparation(ra[i],dec[i],raAverageDegrees,decAverageDegrees)
        if (separation < smallestSeparation):
            smallestSeparation = separation
            nearestField = i
    return([nearestField,smallestSeparation])

def blcTrcToLineSegments(blc, trc):
    """
    Convert a BLC and TRC points to 4 line segments (i.e. 5 pairs of x,y points).
    -Todd Hunter
    """
    x = [blc[0],trc[0],trc[0],blc[0],blc[0]]
    y = [blc[1],blc[1],trc[1],trc[1],blc[1]]
    return(x,y)

def mosaicSensitivity(spacing=0.5774, beam=1.13, points=7, 
                      spacingInBeams=False):
    """
    Computes the sensitivity at the center of a hexagonal
    mosaic relative to a single pointing.
    -Todd Hunter
    Inputs:
    spacing: spacing between adjacent pointings
    beam: FWHM of primary beam
    Note: spacing and beam should be given in units of lambda/D
       unless spacingInBeams=True, then spacing will be multiplied by beam
    points: number of hexagonal pointings: 7, 19, or 37
    """
    allowedPoints = [7,19,37]
    if points not in allowedPoints:
        print "points must be in ", allowedPoints
        return
    if spacingInBeams:
        spacing *= beam
    sigma = beam/2.3548
    fractionalFlux = []
    fractionalFlux.append(exp(-pow(spacing/sigma,2)*0.5))
    fractionalFlux.append(exp(-pow(pow(3,0.5)*spacing/sigma,2)*0.5))
    fractionalFlux.append(exp(-pow(2*spacing/sigma,2)*0.5))
    fractionalFlux.append(exp(-pow(pow(7,0.5)*spacing/sigma,2)*0.5))
    fractionalFlux.append(exp(-pow(3*spacing/sigma,2)*0.5))
    timeOnSource = 1
    print "Spacing = %.4f lambda/D with FWHM beam = %.4f lambda/D:"%(spacing,beam)
    print "        = %.4f FWHM"%(spacing/beam)
    if (points >= 7):
        timeOnSource += 6*(pow(fractionalFlux[0],2))
    if (points >= 19):
        timeOnSource += 6*pow(fractionalFlux[1],2);
        timeOnSource += 6*pow(fractionalFlux[2],2);
    if (points >= 37):
        timeOnSource += 12*pow(fractionalFlux[3],2);
        timeOnSource += 6*pow(fractionalFlux[4],2);
    sensitivity = pow(timeOnSource,0.5)
    print "%d-pt Sensitivity = %f times better than single pointing"%(points,sensitivity)
    return(sensitivity)

def mosaicOverlapFactor(vis, source='', spw='', fwhmfactor=1.13, verbose=False,
                        intent='OBSERVE_TARGET#ON_SOURCE'):
    """
    Computes the maximum sensitivity increase factor for an ALMA mosaic.
    It is similar to au.mosaicSensitivity, but designed to handle an arbitrary 
    mosaic pattern rather than simply a hexagonal pattern.  Does not account
    for flagging or different observing depths at different pointings.
    Inputs:
    source: ID or name of the source (blank = automatic by intent)
    spw: determine the frequency based on this spw or list of spws, 
           default: all with the specified intent
    fwhmfactor: parameter to pass to gaussianBeamResponse and primaryBeamArcsec
    Returns:
    * A single floating point value for the maximum sensitivity increase factor, 
      which is typically the center of the mosaic but not necessarily so.  It is
      meant to be applied to a theoretical rms computed based on the total time 
      spent on only one of the pointings of the mosaic.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    scienceFields = mymsmd.fieldsforintent(intent)
    if (source == ''):
        fields = scienceFields
    elif (source.isdigit()):
        fields = mymsmd.fieldsforsource(source)
    else:
        fields = mymsmd.fieldsforname(source)
    if (source != ''):
        # Limit to science fields, as long as at least one of them is science.
        myfields = np.intersect1d(scienceFields,fields)
        if (len(myfields) > 0):
            fields = myfields
    frequency = np.mean(getScienceFrequencies(vis,spw=spw,intent=intent,verbose=verbose))
    if verbose:
        print "Using mean frequency = %f GHz" %(frequency*1e-9)
    if sevenMeterAntennasMajority(mymsmd=mymsmd):
        diameter = 7
    else:
        diameter = 12
    mymsmd.close()
    timeOnSource = np.zeros(len(fields))
    if verbose:
        print "Processing %d fields: " % (len(fields)), fields
    separations = []
    separationDict = {}
    primaryBeam = primaryBeamArcsec(frequency=frequency,diameter=diameter,
                                    fwhmfactor=fwhmfactor,showEquation=False)
    radiusFirstNull = primaryBeam # approximately correct for Bessel function
    mymsmd.open(vis)
    for i,f in enumerate(fields):
        for field in fields:
            if (f != field):
                # Fill the upper half of a matrix to hold separations in order
                # to avoid calculating each field separation twice.
                smallerField = np.min([f,field])
                largerField = np.max([f,field])
                if (smallerField not in separationDict.keys()):
                    separationDict[smallerField] = {}
                if (largerField not in separationDict[smallerField]):
                    separation = angularSeparationOfTwoFields(vis,f,field,mymsmd)*3600.
                    separationDict[smallerField][largerField] = separation
                else:
                    separation = separationDict[smallerField][largerField]
                separations.append(separation)
            else:
                separation = 0
            if (separation < radiusFirstNull):
                # Truncate the Gaussian at the first null of the Bessel function
                fractionalFlux = gaussianBeamResponse(separation, frequency, diameter=diameter, fwhmfactor=fwhmfactor)
                timeOnSource[i] += fractionalFlux ** 2
    mymsmd.close()
    response = np.median(timeOnSource) ** 0.5
    maxresponse = np.max(timeOnSource) ** 0.5
    if (len(separations) > 0):
        minsep = np.min(separations)
        beams = minsep/primaryBeam
    else:
        minsep = 0
        beams = 0
    if verbose:
        print "min separation = %f arcsec = %.4f FWHM" % (minsep,beams)
        print "response factor: median = %f, max = %f" % (response, maxresponse)
    return maxresponse

def plotmosaics(vislist):
    """
    Runs plotmosaic on a list of measurement sets.
    vislist: python list of strings, comma-delimited string, or string with wildcard
    sets figfile=True to produce default png name
    """
    val = []
    if type(vislist) == str:
        if vislist.find('*') >= 0:
            vislist = sorted(glob.glob(vislist))
        else:
            vislist = vislist.split(',')
    for vis in vislist:
        val.append(plotmosaic(vis, figfile=True))
    return val

def plotmosaic(vis, sourceid='', figfile='', coord='relative', skipsource=-1,
               doplot=True, help=False, sciencespws=False, vm='', debug=False,
               intent='OBSERVE_TARGET#ON_SOURCE', plotrange=[], bw=False,
               pblevel=0.05, showImageBorder=False,
               centerOnSourceDirection=False, firstAppearance=True,
               writeDS9regionFile=False, color='green',
               writeCRTF=False, markerType='symbol', symbolType='+',
               linewidth=1, symsize=2, maxPointingsToLabel=500):
    """
    Produce a plot of the pointings with the primary beam FWHM and field names.
    For further help and examples, see http://casaguides.nrao.edu/index.php?title=Plotmosaic
    Required parameters:
    vis: the measurement set

    Optional parameters:
    sourceid: int or string (name or ID)
    figfile: name of the png to produce, or True for default name
    coord: 'relative' (arcsec) or 'absolute' (deg)
    skipsource: source ID to avoid
    doplot: if False, then the central field ID is returned as an integer.
            if True, the a list of values is returned:
               [central field,  maxRA, minRA, minDec, maxDec]
       where the latter 4 values are in units of arcsec relative to the center.
    sciencespws: if True, then only use the science spws
    vm: a ValueMapping structure (obsolete, only for CASA < 4.1)
    debug: if True, print extra messages
    intent: determine the source IDs to use from this intent (if sourceid='')
    plotrange: for the 'relative' option only: [x0,x1,y0,y1]
    bw: produce a black/white version with bold field labels no grid lines
    pblevel: controls the size of the image mosaic that is returned
    centerOnSourceDirection: if False, center the plot on the mean RA/Dec of
         all the fields.  If True, center on the SOURCE table position.
    writeDS9regionFile: if True, then write an ASCII DS9 region file
           of all the pointings; name = <vis> + '_ds9.reg'
           Note: DS9 region output is not fully working yet. Please use CRTF.
    writeCRTF: if True, then write a CASA Region Text Format file.
           of all the pointings; name = <vis> + '_' + markerType + '.crtf'
    color: to use in the DS9 or CASA region file
    markerType: to use in the DS9 or CASA region file
           DS9: 'ellipse' (semi-major/minor axes will be of primary beam)
           CASA: 'symbol' or 'ellipse' (radius will be of primary beam)
              note: 'text' and 'circle' are not supported by CASA viewer
    symbol: . , o v ^ < > 1 2 3 4 s p * h H + x D d | _
    symsize: size of symbol in CASA region file
    linewidth: linewidth in CASA region file
    Returns:
    * coord='rel':  central field ID, maxRA, minRA, maxDec, minDec (arcsec)
    -- Todd Hunter
    """
    vis = vis.rstrip('/')
    # open the ms table
    if (coord.find('abs') < 0 and coord.find('rel') < 0):
        print "Invalid option for coord, must be either 'rel'ative or 'abs'olute."
        return
    mytb = createCasaTool(tbtool)
    try:
        fieldTable = vis + '/FIELD'
        mytb.open(fieldTable)
    except:
        print "Could not open table = %s" % fieldTable
        return
    delayDir = mytb.getcol('DELAY_DIR')
    ra = delayDir[0, :][0] * 12 / math.pi
    dec = np.degrees(delayDir[1, :][0])
    # will be 0,0 for planets in datasets with ephemeris tables and loaded in casa>=4.5
    # (except for mosaics where it holds the offset)

    # Use ms.getfielddirmeas if it's an ephemeris object
    ephemDict = getEphemeris(vis, verbose=False, sourceid=sourceid)
    if (len(ephemDict.keys()) > 0):
        absoluteDir = getRADecForFields(vis, usemstool=True)
        ephemIDs = ephemDict.keys()
        print "Ephemeris IDs found = ", ephemIDs
        for ephemID in ephemIDs:
            fieldIDs = getFieldIDsForEphemerisID(vis, ephemID)
            for fieldID in fieldIDs:
                delayDir[0][0][fieldID] = absoluteDir[0][0][fieldID]
                delayDir[1][0][fieldID] = absoluteDir[1][0][fieldID]

    sourceID = mytb.getcol('SOURCE_ID')
    name = mytb.getcol('NAME')
    if (type(sourceid) == str):
        try:
            sourceid = int(sourceid)
        except:
            # Source was specified by name, so we
            # need to convert the name to an id.
            matches = np.where(name == sourceid)[0]
            srcs = np.unique(sourceID[matches])
            nsrcs = len(srcs)
            if (nsrcs > 1):
                print "More than one source ID matches this name: ", sourceID
                print "Try again using one of these."
                return
            elif (nsrcs == 0):
                if (sourceid != ''):
                    print "No sources match this name = %s" % sourceid
                    print "Available sources = ", np.unique(name)
                    return
                else:
                    if (casadef.casa_version >= casaVersionWithMSMD):
                        print "plotmosaic(): No source specified, so using the intent %s." % (intent)
                    else:
                        print "plotmosaic(): No source specified, so using the first source."
                        sourceid = 0
                        return
            else:
                sourceid = srcs[0]
    #  sourcename = name[sourceid]  # original method, replaced by the line after the 'if' block
    fields = np.array(range(len(sourceID)))
    if (sourceid != ''):
        matches = np.where(sourceID == int(sourceid))[0]
        fields = fields[matches]
        matches = np.where(fields != skipsource)[0]
        fields = fields[matches]
        if (len(fields) < 1):
            print "No fields contain source ID = ", sourceid
            return
        print "Field IDs with matching source ID = ", fields
        sourcename = name[list(sourceID).index(sourceid)]  # protects against the case of non-consecutive source IDs
    else:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        fields = []
        if (intent in mymsmd.intents()):
            fields = mymsmd.fieldsforintent(intent)
        else:
            print "intent %s not found in dataset. Adding wildcards..." % (intent)
        if (len(fields) == 0):
            try:
                intentsToSearch = '*' + intent + '*'
                fields = mymsmd.fieldsforintent(intentsToSearch)
            except:
                fields = []
            if (len(fields) == 0):
                print "intent %s not found in dataset. Replacing '#' with '.' ..." % (intent)
                intent = intent.replace('#', '.').replace('*', '')
                if (intent in mymsmd.intents()):
                    fields = mymsmd.fieldsforintent(intent)
                    print "Found %d fields with intent = %s" % (len(fields), intent)
                if (len(fields) == 0):
                    print "intent %s not found in dataset. Replacing '.ON_SOURCE' with '#UNSPECIFIED' ..." % (intent)
                    intent = intent.replace('.ON_SOURCE', '#UNSPECIFIED')
                    if (intent in mymsmd.intents()):
                        fields = mymsmd.fieldsforintent(intent)
                        print "Found %d fields with intent = %s" % (len(fields), intent)
                    if (len(fields) == 0):
                        print "No fields have intent = %s. Using first field instead." % (intent)
                        fields = [0]
        sourcename = mymsmd.namesforfields(fields[0])[0]
        mymsmd.close()
        srcID = sourceID[list(name).index(sourcename)]
        print "Found %d fields for source ID=%d: %s: %s" % (len(fields), srcID, sourcename, str(fields))
    name = mytb.getcol('NAME')
    mytb.close()
    mytb.open(vis)
    antennasWithData = np.sort(np.unique(mytb.getcol('ANTENNA1')))
    mytb.close()
    try:
        antennaTable = vis + '/ANTENNA'
        if debug: print "Trying to open ", antennaTable
        mytb.open(antennaTable)
    except:
        print "Could not open table = %s" % antennaTable
        return
    dishDiameter = np.unique(mytb.getcol('DISH_DIAMETER')[antennasWithData])
    mytb.close()
    if (debug): print "dishDiameter = ", dishDiameter
    try:
        spwTable = vis + '/SPECTRAL_WINDOW'
        if debug: print "Trying to open ", spwTable
        mytb.open(spwTable)
        num_chan = mytb.getcol('NUM_CHAN')
        if debug: print "num_chan"
        refFreqs = mytb.getcol('REF_FREQUENCY')
        if debug: print "refFreqs"
        spwNames = mytb.getcol('NAME')
        if debug: print "spwNames = ", spwNames
        bandNames = []
        for i, spwName in enumerate(spwNames):
            if debug: print "spwName", spwName
            tokens = spwName.split('#')
            if (tokens[0].find('ALMA_RB') == 0 or tokens[0].find('WVR') == 0):
                bandNames.append(tokens[0])
            elif (len(tokens) > 1):
                # ICT-5291
                bandNames.append(tokens[1])
            else:
                myband = freqToBand(refFreqs[i])
                if myband[0] is None:
                    bandNames.append('unknown')
                else:
                    bandNames.append('ALMA_RB_%02d' % (myband[0]))
        bandNames = np.unique(bandNames)
        if (debug):
            print "bandNames = ", bandNames
        mytb.close()
    except:
        print "Could not open table = %s" % spwTable
        print "Will not print primary beam circles"
        titleString = vis.split('/')[-1]
        dishDiameter = [0]
    #    [latitude,longitude,obs] = getObservatoryLatLong(getObservatoryName(vis)) # ('ALMA')
    #    if (debug): print "Got observatory longitude = %.3f deg" % (longitude)
    tsysOnlyFields = []
    if (sciencespws):
        if (casadef.casa_version >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            spws = mymsmd.spwsforintent(intent)
            print "spws with intent = %s: " % (intent), spws
            wvrspws = mymsmd.almaspws(wvr=True, sqld=True)
            spws = [x for x in spws if x not in wvrspws]
            print "non-WVR, non-SQLD = ", spws
            meanRefFreq = []
            for spw in spws:
                meanRefFreq.append(mymsmd.meanfreq(spw))
            meanRefFreq = np.median(meanRefFreq)
            myband = freqToBand(meanRefFreq)[0]
            print "Median frequency = %f GHz (band = %s)" % (meanRefFreq * 1e-9, str(myband))
            if 'EVLA' not in mymsmd.observatorynames():
                for i,f in enumerate(fields):
                    if (i+1 % 100 == 0): print "Working field %d/%d" % (i+1, len(fields))
                    tsysOnly = True
                    scans = mymsmd.scansforfield(f)
                    spwsforfield = mymsmd.spwsforfield(f)
                    extraspws = 0
                    for sc in scans:
                        scanIntents = mymsmd.intentsforscan(sc)
                        scanSpws = mymsmd.spwsforscan(sc)
                        scanFieldSpws = np.intersect1d(scanSpws, spwsforfield)
                        fieldsforscan = mymsmd.fieldsforscan(sc)
                        commonSpws = mymsmd.spwsforfield(fieldsforscan[0])
                        for ffs in fieldsforscan[1:]:
                            commonSpws = np.intersect1d(commonSpws, mymsmd.spwsforfield(ffs))
                        extraspws += len(list(set(scanFieldSpws) - set(commonSpws)))
                        if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in scanIntents and 'CALIBRATE_ATMOSPHERE#HOT' not in scanIntents):
                            tsysOnly = False
                    if (extraspws > 0):  # Needed for ICT-6896
                        tsysOnly = True
                    if (tsysOnly):
                        tsysOnlyFields.append(f)
                print "fields with Tsys only = ", tsysOnlyFields
            mymsmd.close()
        else:
            if (vm == ''):
                vm = ValueMapping(vis)
            spws = vm.getSpwsForIntent('OBSERVE_TARGET#ON_SOURCE')
            for f in fields:
                tsysOnly = True
                scans = vm.getScansForField(f)
                for sc in scans:
                    scanIntents = vm.getIntentsForScan(sc)
                    if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in scanIntents):
                        tsysOnly = False
                if (tsysOnly): tsysOnlyFields.append(f)
            print "spws with observe_target = ", spws
            print "fields with Tsys only = ", tsysOnlyFields
            matchedNames = np.array(bandNames)[spws]
            matchedRefFreqs = np.array(refFreqs)[spws]
            matches = np.where(matchedNames != 'WVR')
            print "non-WVR = ", matchedNames[matches]
            meanRefFreq = np.median(matchedRefFreqs[matches])
            myband = freqToBand(meanRefFreq)[0]
            print "Median frequency = %f GHz (band = %s)" % (meanRefFreq * 1e-9, str(myband))
    else:
        # sciencespws == False
        if (3840 in num_chan):
            matches = np.where(num_chan == 3840)[0]
        else:
            matches = np.where(num_chan > 4)[0]  # this kills the WVR and channel averaged data
            if (len(matches) == 0):
                if debug: print "Using single-channel spws"
                matches = np.where(num_chan == 1)[0]  # this allows it to work with simdata
        if (debug):
            print "num_chan=%s (type=%s), matches = " % (str(num_chan), type(num_chan)), matches
            print "refFreqs = ", refFreqs[matches]
        meanRefFreq = np.median(refFreqs[matches])
        if (debug):
            print "medianRefFreq = ", meanRefFreq
        myband = freqToBand(meanRefFreq)[0]
        print "Median frequency = %f GHz (band = %s)" % (meanRefFreq * 1e-9, str(myband))
        # If median freq is not within one of the observed bands, then recalculate
        if myband is None:
            mybandString = ''
        else:
            mybandString = 'ALMA_RB_%02d' % myband
        if (mybandString not in bandNames and len(bandNames) > 1): # old data do not have band names in spw names
            print "Median frequency is not in any observed band. Recalculating over higher frequencies."
            newFreqs = refFreqs[matches]
            newmatches = np.where(newFreqs > meanRefFreq)[0]
            meanRefFreq = np.median(newFreqs[newmatches])
            print "Median frequency = %f GHz" % (meanRefFreq * 1e-9)
    lambdaMeters = c_mks / meanRefFreq
    ra = delayDir[0, :][0] * 12 / math.pi
    for i in range(len(ra)):
        if (ra[i] < 0): ra[i] += 24
    dec = delayDir[1, :][0] * 180 / math.pi
    ra *= 15
    if (centerOnSourceDirection):
#        print "Running au.getRADecForSource('%s', '%s', firstAppearance=%s)" % (vis, sourcename, firstAppearance)
        mydeg = getRADecForSource(vis, sourcename, firstAppearance=firstAppearance)
        raAverageDegrees, decAverageDegrees = radec2deg(mydeg)
    else:
        raAverageDegrees = np.mean(ra[fields])
        decAverageDegrees = np.mean(dec[fields])
    cosdec = 1.0 / cos(decAverageDegrees * np.pi / 180)

    # Here we scale by cos(dec) to make then pointing pattern in angle on sky
    raRelativeArcsec = 3600 * (ra - raAverageDegrees) * cos(decAverageDegrees * math.pi / 180.)
    decRelativeArcsec = 3600 * (dec - decAverageDegrees)

    markersize = 4
    print "Found %d pointings in this ms" % (shape(ra)[0])
    [centralField, smallestSeparation] = findNearestField(ra[fields], dec[fields],
                                                          raAverageDegrees, decAverageDegrees)
    # This next step is crucial, as it converts from the field number
    # determined from a subset list back to the full list.
    centralField = fields[centralField]

    print "Field %d is closest to the center of the area covered (%.1f arcsec away)." % (centralField,smallestSeparation*3600)
    maxradius = 0
    arcsec = 0
    if doplot:
        pb.clf()
        desc = pb.subplot(111)
    if (coord.find('abs') >= 0):
        if not doplot: return centralField
        raunit = 'deg'  # nothing else is supported (yet)
        desc = pb.subplot(111, aspect=cosdec)
        # SHOW ABSOLUTE COORDINATES
        pb.plot(ra[fields], dec[fields], "k+", markersize=markersize)
        for j in dishDiameter:
            for i in range(len(ra)):
                if (i in fields):
                    if (j > 0):
                        arcsec = 0.5 * primaryBeamArcsec(wavelength=lambdaMeters * 1000, diameter=j, showEquation=False)
                        radius = arcsec / 3600.0
                        if (radius > maxradius):
                            maxradius = radius
                        if (i in tsysOnlyFields):
                            myedgecolor = 'r'
                        else:
                            myedgecolor = 'b'
                            if (len(dishDiameter) > 1 and j < 12):
                                # Draw ACA in black
                                myedgecolor = 'k'
                        #                        print "Plotting ellipse with radius = ", radius
                        cir = matplotlib.patches.Ellipse((ra[i], dec[i]), width=2 * radius * cosdec,
                                                         height=2 * radius, facecolor='none', edgecolor=myedgecolor,
                                                         linestyle='dotted')
                        pb.gca().add_patch(cir)
        #                    cir = pb.Circle((ra[i], dec[i]), radius=radius, facecolor='none', edgecolor='b', linestyle='dotted')
        titleString = vis.split('/')[-1]+', %s, average freq. = %.1f GHz, beam = %s"'%(sourcename,meanRefFreq*1e-9, roundFiguresToString(2*arcsec,3))
        resizeFonts(desc, 10)
        if (raunit.find('deg') >= 0):
            pb.xlabel('Right Ascension (deg)')
        else:
            pb.xlabel('Right Ascension (hour)')
        pb.ylabel('Declination (deg)')
        raRange = np.max(ra[fields]) - np.min(ra[fields])
        decRange = np.max(dec[fields]) - np.min(dec[fields])
        x0 = np.max(ra[fields]) + 1.2 * maxradius * cosdec
        x1 = np.min(ra[fields]) - 1.2 * maxradius * cosdec
        y1 = np.max(dec[fields]) + 1.2 * maxradius
        y0 = np.min(dec[fields]) - 1.2 * maxradius
        pb.xlim([x0, x1])
        pb.ylim([y0, y1])
        pb.title(titleString, size=10)
        if len(ra) < maxPointingsToLabel:
            for i in range(len(ra)):
                if (i in fields):
                    pb.text(ra[i] - 0.02 * raRange, dec[i] + 0.02 * decRange, str(i), fontsize=12, color='k')
    elif (coord.find('rel') >= 0):
        if doplot:
            # SHOW RELATIVE COORDINATES in arcsec
            pb.plot(raRelativeArcsec[fields], decRelativeArcsec[fields], 'k+', markersize=markersize)
        for j in dishDiameter:
            for i in range(len(ra)):
                if (i in fields):
                    if (j > 0):
                        arcsec = 0.5 * primaryBeamArcsec(wavelength=lambdaMeters * 1000, diameter=j, showEquation=False)
                        radius = arcsec
                        if (radius > maxradius):
                            maxradius = radius
                        if (bw):
                            myedgecolor = 'k'
                        else:
                            if (i in tsysOnlyFields):
                                myedgecolor = 'r'
                            else:
                                myedgecolor = 'b'
                                if (len(dishDiameter) > 1 and j < 12):
                                    # Draw ACA in black
                                    myedgecolor = 'k'
                        if doplot:
                            cir = pb.Circle((raRelativeArcsec[i], decRelativeArcsec[i]),
                                            radius=radius, facecolor='none', edgecolor=myedgecolor,
                                            linestyle='dotted')
                            pb.gca().add_patch(cir)
        if doplot:
            titleString = vis.split('/')[-1]+', %s, average freq. = %.1f GHz, beam = %s"'%(sourcename,meanRefFreq*1e-9, roundFiguresToString(2*arcsec,3))
            resizeFonts(desc, 10)
            raString = qa.formxxx('%fdeg' % (raAverageDegrees), format='hms', prec=3)
            decString = qa.formxxx('%fdeg' % (decAverageDegrees), format='dms', prec=0).replace('.', ':', 2)
            if (centerOnSourceDirection):
                raString += ' (SOURCE table)'
                decString += ' (SOURCE table)'
            pb.xlabel('Right ascension offset (arcsec) from %s' % (raString))
            pb.ylabel('Declination offset (arcsec) from %s' % (decString))
            pb.title(titleString,size=10-int(len(titleString)/100))
            raRange = np.max(raRelativeArcsec[fields]) - np.min(raRelativeArcsec[fields])
            decRange = np.max(decRelativeArcsec[fields]) - np.min(decRelativeArcsec[fields])
            if (bw):
                mystyle = 'bold'
            else:
                mystyle = 'normal'
            if len(ra) < maxPointingsToLabel:
                for i in range(len(ra)):
                    if (i in fields):
                        if (i in tsysOnlyFields):
                            pb.text(0.05, 0.93, 'Tsys-only fields: %s' % (str(tsysOnlyFields)), transform=desc.transAxes, color='r')
                            mycolor = 'r'
                        else:
                            mycolor = 'k'
                        pb.text(raRelativeArcsec[i] - 0.02 * raRange, decRelativeArcsec[i] + 0.02 * decRange,
                                str(i), fontsize=12, color=mycolor, weight=mystyle)
            setPlotRange = False
            if (type(plotrange) == list):
                if (len(plotrange) == 4):
                    x0, x1, y0, y1 = plotrange
                    if (plotrange != [0, 0, 0, 0]):
                        setPlotRange = True
            if (not setPlotRange):
                x0 = np.max(raRelativeArcsec[fields]) + 1.2 * maxradius  # 0.25*raRange
                x1 = np.min(raRelativeArcsec[fields]) - 1.2 * maxradius  # - 0.25*raRange
                y1 = np.max(decRelativeArcsec[fields]) + 1.2 * maxradius  # 0.25*decRange
                y0 = np.min(decRelativeArcsec[fields]) - 1.2 * maxradius  # 0.25*decRange
            pb.xlim(x0, x1)
            pb.ylim(y0, y1)
            pb.axis('equal')
            if (setPlotRange):
                pb.gca().set_aspect('equal', adjustable='box')
                pb.axis(plotrange)
        mosaicInfo = []
        mosaicInfo.append(centralField)
        border = 2 * maxradius * gaussianBeamOffset(pblevel)
        mosaicInfo.append(np.max(raRelativeArcsec[fields]) + border)
        mosaicInfo.append(np.min(raRelativeArcsec[fields]) - border)
        mosaicInfo.append(np.max(decRelativeArcsec[fields]) + border)
        mosaicInfo.append(np.min(decRelativeArcsec[fields]) - border)
        if not doplot:
            return mosaicInfo
        if showImageBorder:
            x, y = blcTrcToLineSegments([mosaicInfo[1], mosaicInfo[4]],
                                        [mosaicInfo[2], mosaicInfo[3]])
            pb.plot(x, y, 'k--')
    else:
        print "Invalid option for coord, must be either 'rel'ative or 'abs'olute."
        return

    yFormatter = ScalarFormatter(useOffset=False)
    desc.yaxis.set_major_formatter(yFormatter)
    desc.xaxis.set_major_formatter(yFormatter)
    if (not bw):
        desc.xaxis.grid(True, which='major')
        desc.yaxis.grid(True, which='major')
    if (len(dishDiameter) > 1):
        pb.text(0.04, 0.03, '12m', color='b', transform=desc.transAxes)
        pb.text(0.04, 0.08, '7m', color='k', transform=desc.transAxes)
    pb.draw()
    if sourceid == '':
        autoFigureName = "%s.pointings.%s.png" % (vis, coord)
    else:
        autoFigureName = "%s.pointings.%s.src%s.png" % (vis, coord, str(sourceid))
    if (figfile == True):
        try:
            pb.savefig(autoFigureName)
            print "Wrote file = %s" % (autoFigureName)
        except:
            print "WARNING:  Could not save plot file.  Do you have write permission here?"
    elif (len(figfile) > 0):
        try:
            pb.savefig(figfile)
            print "Wrote file = %s" % (figfile)
        except:
            print "WARNING:  Could not save plot file.  Do you have write permission here?"
    else:
        print "To save a plot, re-run with either:"
        print "  plotmosaic('%s',figfile=True) to produce the automatic name=%s" % (vis, autoFigureName)
        print "  plotmosaic('%s',figfile='myname.png')" % (vis)
    if writeDS9regionFile:
        ds9file = '%s_ds9.reg' % vis
        f = open(ds9file, 'w')
        f.write('# Region file format: DS9 version 4.1\n')
        f.write('global color=%s\n' % color)
        f.write('fk5\n')
        for i in range(len(ra)):
            if (i in fields):
                #                radec = deg2radec(ra[i],dec[i],delimiter=',',verbose=False)
                #                f.write('ellipse(%s,%f",%f",0) # color=%s\n' % (radec,arcsec,arcsec,color))
                #                f.write('ellipse(%f,%f,%f",%f",0) # color=%s\n' % (ra[i],dec[i],arcsec,arcsec,color))
                f.write('ellipse %f %f %f" %f" 0\n' % (ra[i], dec[i], arcsec, arcsec))
        #                f.write('point(%f,%f) # color=%s\n' % (ra[i],dec[i],color))
        f.close()
        print "Wrote ", ds9file
    if writeCRTF:
        ds9file = '%s_%s.crtf' % (vis, markerType)
        f = open(ds9file, 'w')
        f.write('#CRTF0\n')
        f.write('global coord=J2000\n')
        shapes = ['symbol', 'ellipse']
        if markerType not in shapes:
            print "Shape must be one of: %s" % shapes
            return
        for i in range(len(ra)):
            if (i in fields):
                radec = deg2radec(ra[i], dec[i], delimiter=',', hmsdms=True, verbose=False)
                if markerType == 'symbol':
                    f.write('symbol[[%s], %s], linewidth=%d, symsize=%d, color=%s\n' % (radec, symbolType, linewidth, symsize, color))
                #                elif markerType == 'circle':  # not yet supported in CASA viewer
                #                    f.write('circle[[%s], %farcsec], color=%s\n' % (radec,arcsec,color))
                elif markerType == 'ellipse':
                    f.write('ellipse[[%s], [%farcsec,%farcsec], 0deg], color=%s\n' % (radec, arcsec, arcsec/np.cos(np.radians(dec[i])), color))
        #                elif markerType == 'text':  # not yet supported in CASA viewer
        #                    f.write("text[[%s], '%s']\n" % (radec,str(i)))
        f.close()
        print "Wrote ", ds9file
    if (coord.find('rel') >= 0):
        return mosaicInfo
    else:
        return

def runPredictcomp(objname, minfreq, maxfreq='', standard='Butler-JPL-Horizons 2012',
                epoch='', nfreqs=1, antennalist='alma.cycle2.7.cfg', mjd=None,
                savefig=''):
    """
    A convenient wrapper for running the casa task predictcomp.
    minfreq: either a string with units, or a value in GHz or Hz
    Specify either epoch or mjd, or else it assumes the current time.
    format for epoch = 2011-12-31-5:34:12
    -Todd Hunter
    """
    if (epoch == ''):
        epoch = mjdToPredictcomp(mjd)  # uses current time if None
    if (type(minfreq) != str):
        minfreq = str(parseFrequencyArgumentToGHz(minfreq)) + 'GHz'
    if (type(maxfreq) != str):
        maxfreq = str(parseFrequencyArgumentToGHz(maxfreq)) + 'GHz'
    if (savefig == True):
        savefig = objname+'_'+epoch.replace(':','_')+'_'+antennalist+'.png'
    return(predictcomp(objname, standard, epoch, minfreq, maxfreq, 
                       nfreqs, antennalist=antennalist,savefig=savefig))

def plotConfigHelp(telescope=''):
    print "Telescope and configuration available to plot:"
    if telescope in ['','aca']:
        print "aca: i, ns, tp,  i.loc, nc.loc, tp.loc"
    if telescope in ['','alma']:
        print "alma: 1..28, cycle0.compact, cycle0.extended, cycle1.1..6, cycle2.1..7, cycle3.1..8, cycle4.1..9, cycle5.1..10"
    if telescope in ['','carma']:
        print "carma: a, b, c, d, e"
    if telescope in ['','meerkat']:
        print "meerkat"
    if telescope in ['','pdbi']:
        print "pdbi: a, b, c, d"
    if telescope in ['','sma']:
        print "sma: subcompact, compact, compact.n, extended, vextended"
    if telescope in ['','vla']:
        print "vla: a, bna, b, cnb, c, dnc, d"
    if telescope in ['']:
        print "WSRT"
        print "file: specify any filename as config='myfilename'"
    
DEFAULT_TELESCOPE='alma'
def plotconfig(telescope=DEFAULT_TELESCOPE, config='', figfile='', list=False, limits=None,
               gridlines=True, listconfig=False, cofa=[], title='',
               repotable='', antennaSizePercent=0.5, units='m',
               tickSpacing=None, fontsize=12, showPadNames=False,
               extraStationLocations=[], extraStationNames=[], 
               returnLengths=False, config2=''):
    """
    Plots pad layout for specified telescope and configuration name. It also returns an
    array containing the baseline lengths, sorted from shortest to longest.
    If you want to see the antennas and/or pads labelled for a specific configuration,
    then use plotantsFromASDM(config='alma.cycle4.9.cfg').
    -- Todd Hunter
    Telescopes and configurations available to plot (there may be more):"
    * aca: i, ns, tp
    * alma: alma.cycle0.compact, alma.cycle0.extended, alma.cycle1.1..6
          alma.cycle2.1..7, alma.cycle3.1..8, alma.cycle4.1..9, alma.cycle5.1..10
    * carma: a, b, c, d, e
    * meerkat
    * pdbi: a, b, c, d
    * sma: subcompact, compact, compact.n, extended, vextended
    * vla: a, bna, b, cnb, c, dnc, d
    * WSRT
    telescope='file' option: specify any user filename as config='myfilename'
          will be ignored if config2 is specified
    config: name of configuration for specified telescope, or use this to
           specify the configuration filename directly (without telescope)
    config2: add a second configuration worth of antennas (e.g. Kitchen Sink)
    figfile: True (for automatic name generation) or a specific filename for the png
    limits: optional parameter for plot range: [x0,x1,y0,y1]
    list: optional Boolean parameter to print the list of baseline lengths
    listconfig: optional Boolean parameter to print the .cfg file
    cofa: center-of-array coordinates [x,y,z]; if [], then use the value in CASA
    title:  title for plot (default is "telescope config")
    repotable: default is the CASA simmos area
    antennaSizePercent: size of antennas to draw in large configurations
    units: 'm' or 'km'
    tickSpacing: change the X & Y axis major tick spacing (in specified units)
    fontsize: for axis labels and tick labels
    extraStationLocations: list of additional stations to plot (in geocentric ITRF X,Y,Z coords)
    extraStationNames: list of additional station names to plot
    returnLengths: if True, then return a sorted array of baseline lengths (shortest first)
    """
    z = None
    if config2 != '':
        telescope = ''
    if (telescope == 'wsrt'):
        telescope = telescope.upper()
    else:
        telescope = telescope.lower()
        
    if (len(str(config)) < 1 and telescope.find('meerkat')<0 and telescope.find('WSRT')<0):
        if telescope == DEFAULT_TELESCOPE:
            telescope = ''
        plotConfigHelp(telescope)
        return
    configString = str(config)
    if (len(str(config)) > 0):
      if (telescope != ''):
        if (telescope.find('alma')<0):
            if (telescope.find('pdbi')<0):
                configString = '.'+str(config.lower())  # e.g. convert 'A' to 'a'
            else:
                # PdBI 
                configString = '-'+str(config)
        else:  # ALMA
            if (str(config).find('cycle1')>=0):
                configString = '.' + config
            elif (not str(config).isdigit() and config.find('alma.out')<0 # cycle 0
                  and config.find('alma.cycle')<0 and config.find('alma.all')<0): # file with all pads
                configString = '.' + config
    # add support for '.cycle4.9' as well as 'cycle4.9'
    configString = configString.replace('..','.')
    if (repotable == ''):
        repotable = os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
    if (telescope == 'alma' and str(config).isdigit()):
        #  1
        myfile = repotable+telescope+'.out%02d'%int(config)+".cfg"
    elif (config.find('.cfg')<0): 
        if (configString.find(telescope) >= 0):
            # alma.out01
            myfile = repotable+configString+".cfg"
        else:
            # out01
            myfile = repotable+telescope+configString+".cfg"
    else:  # alma.out01.cfg
        if (configString.find(telescope) >= 0):
            # alma.out01.cfg
            if (configString[0] != '/' and configString[0:2] != './'):
                myfile = repotable+configString
            else:
                myfile = configString
        else:
            # out01.cfg
            if (configString[0] != '/' and configString[0:2] != './'):
                myfile = repotable+telescope+configString
            else:
                myfile = configString
    if (telescope == 'file'):
        myfile = config
    if (os.path.exists(myfile) == False):
        print "Could not locate file = ", myfile
        print "Checking current directory..."
        myfile = './' + config
        if (os.path.exists(myfile) == False):
            print "*Could not locate file = ", myfile
            if telescope != 'file':
                plotConfigHelp(telescope)
            return
    myfiles = [myfile]
    if config2 != '':
        if not os.path.exists(config2):
            config2 = os.path.join(repotable,config2)
            if not os.path.exists(config2):
                print "Could not find config2"
                return
        myfiles.append(config2)
        # Set up blank lists to hold the combined list of pad information
        allx = []
        ally = []
        allz = []
        allpadnames = []
        alldiameter = []
    for myfile in myfiles:
        try:
            fd = open(myfile,'r')
        except:
            print "Could not open file = ", myfile
            return
        columns = []
        line = fd.readline()
        telescopeCOFA = telescope
        # Read through the configuration file
        while (len(line) > 0):
            if (listconfig):
                print line[:-1]
            if (line.find('#')>=0):
                mystr = line.split('=')
                if (len(mystr) > 1):
                    mystr = mystr[1].split('\n')[0]
                    if (line.find('observatory')>=0):
                        if (telescope.upper() == 'ACA'):
                            telescopeCOFA = 'ALMA'
                        if (telescope == ''):
                            telescope = line.split('=')[1].strip('\n')
                    elif (line.find('coordsys')>=0):
                        coordsys = mystr
                    elif (line.find('datum')>=0):
                        datum = mystr
                    elif (line.find('zone')>=0):
                        zone = int(mystr)
                    elif (line.find('hemisphere')>=0):
                        nors = mystr
            else:
                newcolumns = line.split()
                if (len(newcolumns) > 2):
                    if (str.isdigit(newcolumns[-1].replace(".","",1)) or showPadNames):
                        columns.append(newcolumns)
                    else:
                        columns.append(newcolumns[0:len(newcolumns)-1])
            line = fd.readline()
        print "Read %d pads for observatory=%s in coordsys=%s (from %s)" % (len(columns), telescope,coordsys, myfile)
        if ((coordsys.find('LOC')<0 or extraStationLocations != []) and cofa==[]):
            # Then it is UTM-based file, such as alma.out01.cfg
            # Read COFA from CASA, which will be either IRTF (e.g. VLA) or WGS84 (ALMA,ACA)
            u = simutil.simutil()
            repotable = os.getenv("CASAPATH").split()[0]+"/data/geodetic/Observatories"
            mytb = createCasaTool(tbtool)
            mytb.open(repotable)
            Name = mytb.getcol('Name')
            for i in range(len(Name)):
                if (Name[i] == telescopeCOFA or Name[i] == telescopeCOFA.upper()):
                    # We have found the telescope name, now reads it's location
                    Long = mytb.getcell('Long',i)
                    Lat = mytb.getcell('Lat',i)
                    Height = mytb.getcell('Height',i)
                    myType = mytb.getcell('Type',i)
                    if (myType == 'ITRF'):
                        cx = mytb.getcell('X',i)
                        cy = mytb.getcell('Y',i)
                        cz = mytb.getcell('Z',i)
                    else:
                        # WGS84
                        print "COFA in long/lat/height = ", Long, Lat, Height
                        output = u.long2xyz(Long*math.pi/180.,Lat*math.pi/180.,Height,myType)
                        (cx,cy,cz) = output # This is the COFA in ITRF/XYZ coords
    #                    if (coordsys.find('UTM')>=0):
    #                        (position[0],position[1],position[2]) = u.utm2xyz(position[0,:], position[1,:],position[2,:],zone,datum,nors)
                    print "COFA in x/y/z = ", cx,cy,cz
                    break
            if (len(myType) < 1):
                print "Did not find telescope data for %s, using first station as center of array." % (telescopeCOFA)
            mytb.close()
        
        if (coordsys.find('LOC') >= 0):
            # No conversion is necessary
            x = np.array(columns).transpose()[0].astype('float')
            y = np.array(columns).transpose()[1].astype('float')
            z = np.array(columns).transpose()[2].astype('float')
            diameter = np.array(columns).transpose()[3].astype('float')
            if (showPadNames):
                padnames = np.array(columns).transpose()[4].astype('str')
            if (config == 'i.loc' or config == 'ns.loc' or config == 'nc.loc'):
                diameter = 7*(diameter/diameter)
            print "Maximum height difference = %f m" % (np.max(z)-np.min(z))
        else:
            # Convert UTM station coords to xyz, then to LOC
            position = np.array(columns).transpose().astype('float')
            diameter = np.array(columns).transpose()[3].astype('float')
            u = simutil.simutil()
            if (coordsys.find('UTM') >= 0):
                (position[0],position[1],position[2]) = u.utm2xyz(position[0,:], position[1,:],position[2,:],zone,datum,nors)
            print "Using COFA = ", cx, cy, cz
            try:
                output = u.irtf2loc(position[0,:],position[1,:],position[2,:],cx,cy,cz)
            except:
                output = u.itrf2loc(position[0,:],position[1,:],position[2,:],cx,cy,cz)
            if (len(output) == 2):
                (x,y) = output
            else:
                (x,y,z) = output
        if myfile == myfiles[0]:
            for i,extraStation in enumerate(extraStationLocations):
                # in case someone entered the values as integers, it would otherwise crash
                extraStation = [float(a) for a in extraStation]
                try:
                    output = u.irtf2loc(extraStation[0],extraStation[1],extraStation[2],cx,cy,cz)
                except:
                    output = u.itrf2loc(extraStation[0],extraStation[1],extraStation[2],cx,cy,cz)
                print "extraStation %s = " % (extraStationNames[i]), output
                x = np.append(x, output[0])
                y = np.append(y, output[1])
                z = np.append(z, output[2])
                padnames= np.append(padnames, extraStationNames[i])
                diameter = np.append(diameter, np.median(diameter))
        if config2 != '':
            allx = np.concatenate((allx, x))
            ally = np.concatenate((ally, y))
            allz = np.concatenate((allz, z))
            if showPadNames:
                allpadnames = np.concatenate((allpadnames, padnames))
            alldiameter = np.concatenate((alldiameter, diameter))
    if config2 != '':
        x = allx
        y = ally
        z = allz
        padnames = allpadnames
        diameter = alldiameter
    lengths = []
    print "Processing %d antennas" % (len(x))
    for i in range(len(x)):
        for j in range(i,len(x)):
            if (i != j):
                if (z is None):
                    lengths.append(((x[i]-x[j])**2+(y[i]-y[j])**2)**0.5)
                else:
                    lengths.append(((x[i]-x[j])**2+(y[i]-y[j])**2+(z[i]-z[j])**2)**0.5)
    lengths = np.sort(lengths)
    if (limits is None):
        maxlength = np.max(lengths) # in meters
    else:
        xsize = (limits[1]-limits[0])
        ysize = (limits[3]-limits[2])
        maxlength = 0.5*(ysize+xsize)  # meters or km
        if (units == 'km'):
            maxlength *= 1000
    pb.clf()
    uniqueDiameters = np.unique(diameter)
    print "diameters = ", uniqueDiameters
    adesc = pb.subplot(111)
    pb.subplots_adjust(bottom=np.max([0.1,fontsize/100.])) # make room for baseline stats
    pb.hold(True)
    dcolor = ['b','r']
    axes = pb.axes()
    exaggerated = False
    for d in range(len(uniqueDiameters)):
        diam = uniqueDiameters[d]
        matches = np.where(diam == diameter)[0]
        for m in matches:
            myx = x[m]
            myy = y[m]
            radius= np.max([maxlength*antennaSizePercent*0.01,diameter[m]*0.5])
            if (radius > diameter[m]*0.5):
                exaggerated = True
            if (units == 'km'):
               myx *= 0.001
               myy *= 0.001
               radius *= 0.001
            circ = pb.Circle((myx, myy),radius=radius, color=dcolor[d])
            axes.add_patch(circ)
            if (showPadNames):
                if (limits==None or (myx <= limits[1] and myx >=limits[0] and 
                                     myy <= limits[3] and myy >= limits[2])):
                    pb.text(myx, myy, padnames[m], size=10)
    pb.hold(False)
    if (title == ''):
        if config2 == '':
            configString = os.path.basename(config)
        else:
            configString = os.path.basename(config) + ' plus ' + os.path.basename(config2)
        limit = 70-len(telescope)
        if (exaggerated):
            limit -= 27
            if (len(configString) > limit):
                configString = '...' + configString[-limit:]
            if config2 == '':
                titleString = '%s: %s (antenna size exaggerated)' % (telescope,configString)
            else:
                titleString = '%s (antenna size exaggerated)' % (configString)
        else:
            if (len(configString) > limit):
                configString = '...' + configString[-limit:]
            if config2 == '':
                titleString = '%s: %s' % (telescope,configString)
            else:
                titleString = configString
        pb.title(titleString,size=14)
    else:
        pb.title(title,size=14)
    pb.text(-0.1,-fontsize/100.,"baselines: min/median/rms/max = %.1f / %.1f / %.1f / %.1f m" % (np.min(lengths),np.median(lengths),np.sqrt(np.mean(lengths**2)),np.max(lengths)),transform=adesc.transAxes)
    if (units == 'km'):
       xlabel = 'X (km)'
       ylabel = 'Y (km)'
    else:
       xlabel = 'X (m)'
       ylabel = 'Y (m)'
    pb.xlabel(xlabel, size=fontsize)
    pb.ylabel(ylabel, size=fontsize)
    if (list):
        for i in range(len(lengths)):
            print "%.1f m" % (lengths[i])
    if (limits is not None):
        pb.gcf().set_size_inches(6.0, 6.0*ysize/xsize)
        pb.gca().set_autoscale_on(False)
        pb.xlim([limits[0],limits[1]])
        pb.ylim([limits[2],limits[3]])
    else:
        pb.axis('equal')
    if (True):
        yFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
        adesc.yaxis.set_major_formatter(yFormatter)
        xFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
        adesc.xaxis.set_major_formatter(xFormatter)
        if (gridlines):
            adesc.yaxis.grid(True,which='major')
            adesc.xaxis.grid(True,which='major')
        if (tickSpacing is None):
            majorTicks = pb.gca().get_xticks()
#            print "majorTicks = ", majorTicks
            xmajorTickSpacing = abs(majorTicks[1] - majorTicks[0])
            majorTicks = pb.gca().get_yticks()
            ymajorTickSpacing = abs(majorTicks[1] - majorTicks[0])
#            print "xmajor tick spacing = %f, y=%f" % (xmajorTickSpacing, ymajorTickSpacing)
            tickSpacing = np.max([xmajorTickSpacing,ymajorTickSpacing])
        adesc.xaxis.set_major_locator(MultipleLocator(tickSpacing))
        adesc.yaxis.set_major_locator(MultipleLocator(tickSpacing))
    resizeFonts(adesc,fontsize)
    pb.draw()
    if (limits is not None):
        # This seems to be necessary in order for the first plot to be square.
        # Subsequent plots become square without these lines present.
        pb.gcf().set_size_inches(6.0, 6.0*ysize/xsize)
        pb.draw()
    if config2 == '':
        if (telescope == 'ALMA' and str(config).isdigit()):
            autoFigureName = "%s.%02d.png" % (telescope,int(str(config)))
        else:
            autoFigureName = "%s.%s.png" % (telescope,os.path.basename(config))
    else:
        autoFigureName = "%s_plus_%s.png" % (os.path.basename(config), os.path.basename(config2))
    if (figfile == True):
        pb.savefig(autoFigureName)
        print "Wrote file = %s" % (autoFigureName)
    elif (len(figfile) > 0):
        pb.savefig(figfile)
        print "Wrote file = %s" % (figfile)
    else:
        print "To save a plot, re-run with either:"
        print "  plotconfig('%s','%s',figfile=True) to produce the automatic name=%s" % (telescope,config,autoFigureName)
        print "  plotconfig('%s','%s',figfile='myname.png')" % (telescope,config)
    print "min/nextmin/median/mean/rms/max = %.2f / %.2f / %.2f / %.2f / %.2f / %.2f m" % (np.min(lengths),lengths[1],np.median(lengths),np.mean(lengths),np.sqrt(np.mean(lengths**2)),np.max(lengths))
    if returnLengths:
        return(lengths)
    else:
        return

def filterDictionary(completeDict, partialDict):
    """
    Filters a dictionary so that it only has keys that are present in a second dictionary.
    -Todd Hunter
    """
    # dictionary comprehension works in newer python, but causes import failure in older python
    # newDict = { your_key: completeDict[your_key] for your_key in partialdict }        
    # older python is uglier:
    newDict = dict((your_key, completeDict[your_key]) for your_key in partialDict)
    return(newDict)

def getUnflaggedScans(vis, spw, field, maxFractionFlagged=0.20, verbose=False):
    """
    Uses the af tool to find a list of scans which are not completely flagged for
    the specified field and spw.
    spw: spw ID (integer or string)
    field: either field ID (integer or string) or name
    maxFractionFlagged: note that 0.125 is normal for TDM edge-channel flagging
    Returns:
    an integer list of scan numbers
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set = ", vis
        return
    field = str(field)
    spw = str(spw)
    myaf = createCasaTool(aftool)
    myaf.open(vis)
    myaf.selectdata(spw=spw, field=field)
    myaf.parsesummaryparameters()
    myaf.init()
    stats2 = myaf.run()
    myaf.done()
    flagStats = stats2['report0']['scan']
    scans = []
    allscans = sorted([int(i) for i in flagStats.keys()])
    for scan in allscans:
        frac = flagStats[str(scan)]['flagged'] / (1.0*(flagStats[str(scan)]['total']))
        if verbose:
            print "scan %d: fraction = %f" % (scan, frac)
        if (frac <= maxFractionFlagged):
            scans.append(scan)
    return(scans)

def getUnflaggedAntennas(vis, flaggedFraction=0.9, flagStats=None):
    """
    Uses the af tool to determine the list of antenna names in a measurement set whose
    data are not flagged more than the specified fraction.  Return this list and
    the complementary list of antennas (i.e. those that *are* flagged).
    flaggedFraction: 0..1.0, where 1 means completely flagged
    flagStats: a 'report0' dictionary, previously returned by the af tool
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set = ", vis
        return
    if (flagStats is None):
        print "Running the af tool, this can take a few minutes."
        myaf = createCasaTool(aftool)
        myaf.open(vis)
        myaf.selectdata()
        myaf.parsesummaryparameters()
        myaf.init()
        stats2 = myaf.run()
        myaf.done()
        flagStats = stats2['report0']
    antennas = flagStats['antenna'].keys()
    unflaggedAntennas = []
    flaggedAntennas = []
    flagged = 0
    for antenna in sorted(antennas):
        points = flagStats['antenna'][antenna]
        fraction = points['flagged']/points['total']
        if (fraction >= flaggedFraction):
            print "%s total=%.0f  flagged=%.0f  fraction=%.9f" % (antenna, points['total'], points['flagged'], fraction)
            flagged += 1
        if (fraction < flaggedFraction):
            unflaggedAntennas.append(antenna)
        else:
            flaggedAntennas.append(antenna)
    print "%d antennas are flagged by at least %f%% of their data" % (flagged,flaggedFraction*100)
    return(unflaggedAntennas, flaggedAntennas)

class stuffForScienceDataReduction:
    def locatePath(self, pathEnding):
        # This method will locate any file in the active analysisUtils
        # "science" subdirectory tree. You need to call it with the
        # trailing part of the path beyond the ~/AIV/science/ directory.
        # e.g. 'PadData/almaAntPos.txt'
        #
#        print "Looking for %s in the analysisUtils area" % (pathEnding)
        tokens = __file__.split('/')
        mypath = ''
        for i in range(len(tokens)-len(pathEnding.split('/'))):
            mypath += tokens[i] + '/'
        mypath += pathEnding
        return(mypath)

    def correctMyAntennaPositions(self, msNames, obsTime='', verbose=True, checkForAntennaMoves=True, lbc=False, search='both_latest', maxSearchDays=30, minPosDiff=50e-6, thresh=5, useTMCDB=False):

        if type(msNames).__name__ == 'str': msNames = [msNames]

        if search not in ['backward', 'forward', 'both_closest', 'both_next', 'both_latest']: sys.exit('ERROR: unexpected value for search parameter.')

        if lbc == True:
            search = 'both_latest'
            maxSearchDays = 30

        f = open('antennapos.csv', 'w')
        print >> f, 'name,antenna,xoff,yoff,zoff,comment'
        f.close()

        #casaCmd = 'print "# Correcting for antenna position errors."\n\n'
        casaCmd = ''

        for msName in msNames:

            if len(msNames) > 1: obsTime = ''

            tb.open(msName)
            if 'ASDM_ANTENNA' not in tb.keywordnames() or 'ASDM_STATION' not in tb.keywordnames():
                sys.exit('ERROR: The ANTENNA and/or STATION tables from the ASDM were not transferred to the MS.')
            tb.close()
            try:
                f=open(os.path.expanduser('~/AIV/science/PadData/almaAntPos.txt'), 'r')
            except:
                try:
                    mypath = self.locatePath('PadData/almaAntPos.txt')
                    f=open(mypath)
                except:
                    print "Failed to find path=%s" % (mypath)

            almaAntPos=XmlObjectifier.XmlObject(f.read())
            f.close()

            try:
                g=open(os.path.expanduser('~/AIV/science/PadData/antennaMoves.txt'), 'r')
            except:
                try:
                    mypath = self.locatePath('PadData/antennaMoves.txt')
                    g=open(mypath)
                except:
                    print "Failed to find path=%s" % (mypath)

            gc=g.read().splitlines()
            g.close()

            gc=sorted(gc)

            ij=-1
            antMoves={}
            for line in gc:
                line=line.strip()
                if (len(line) < 1): continue  # added by T. Hunter
                if line[0] == '#': continue
                ele=line.split()
                ij=ij+1
                antMoves[ij]={}
                antMoves[ij]['Date']=datetime.datetime.strptime(ele[0], '%Y-%m-%dT%H:%M')
                antMoves[ij]['Antenna']=ele[1]
                antMoves[ij]['From']=ele[2]
                antMoves[ij]['To']=ele[3]

            baseRunObj = almaAntPos.AntennaPositions.BaselineRun
            if not isinstance(baseRunObj, types.ListType): baseRunObj = [baseRunObj]

            measTime=[]
            for i in range(len(baseRunObj)):
                baseRunObj1 = baseRunObj[i]
                measTime.append(datetime.datetime.strptime(baseRunObj1.getAttribute('measTime'), '%Y-%m-%dT%H:%M:%S'))

            measTime = sorted(enumerate(measTime), key=operator.itemgetter(1), reverse=True)

            sort1 = []
            for i in range(len(measTime)):
                sort1.append(measTime[i][0])

            if obsTime == '':
                tb.open(msName+'/OBSERVATION')
                obsTimeRange = tb.getcol('TIME_RANGE')
                obsTime = (obsTimeRange[0]+obsTimeRange[1])/2.0
                obsTime = ((obsTime/86400.0)+2400000.5-2440587.5)*86400.0
                obsTime = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTime))
                obsTime = datetime.datetime.strptime(obsTime, '%Y-%m-%dT%H:%M:%S')
                tb.close()
            else:
                obsTime = datetime.datetime.strptime(obsTime, '%Y-%m-%dT%H:%M:%S')
#            print "%s obsTime = " % (msName), obsTime
            tb.open(msName+'/ANTENNA')
            antNames = tb.getcol('NAME')
            padNames = tb.getcol('STATION')
            tb.close()

            msAntPos = {}
            for i in range(len(antNames)):
                msAntPos[antNames[i]] = {}
                msAntPos[antNames[i]]['pad'] = padNames[i]

            tb.open(msName+'/ASDM_ANTENNA')
            asdmAntNames = tb.getcol('name')
            asdmAntPositions = tb.getcol('position')
            tb.close()

            for i in range(len(antNames)):
                if antNames[i] not in asdmAntNames: sys.exit('ERROR: Antenna not found.')
                for j in range(len(asdmAntNames)):
                    if asdmAntNames[j] == antNames[i]:
                        msAntPos[antNames[i]]['antPos'] = [asdmAntPositions[0][j], asdmAntPositions[1][j], asdmAntPositions[2][j]]
                        break

            tb.open(msName+'/ASDM_STATION')
            asdmPadNames = tb.getcol('name')
            asdmPadPositions = tb.getcol('position')
            tb.close()

            for i in range(len(antNames)):
                if padNames[i] not in asdmPadNames: sys.exit('ERROR: Pad not found.')
                for j in range(len(asdmPadNames)):
                    if asdmPadNames[j] == padNames[i]:
                        msAntPos[antNames[i]]['padPos'] = [asdmPadPositions[0][j], asdmPadPositions[1][j], asdmPadPositions[2][j]]
                        break

            for i in range(len(antNames)):

                ij = -1
                antMoves1 = {}
                for j in range(len(antMoves)):
                    if antMoves[j]['Antenna'] == antNames[i]:
                        ij = ij+1
                        antMoves1[ij] = antMoves[j]

                if len(antMoves1) == 0:
                    sys.exit("ERROR: No antenna move information available for "+str(antNames[i]))
                if obsTime < antMoves1[0]['Date']:
                    sys.exit("ERROR: No antenna move information available for "+str(antNames[i]))

                for j in range(len(antMoves1)-1, -1, -1):
#                    print "%s Checking " % (antNames[i]), antMoves1[j]['Date']
                    if antMoves1[j]['Date'] <= obsTime: break

                if antMoves1[j]['To'] != padNames[i]:
                    if checkForAntennaMoves == True:
                        sys.exit("ERROR: Current data file has antenna "+str(antNames[i])+" on pad "+str(padNames[i])+" while latest move recorded is on pad "+str(antMoves1[j]['To']))
                    else:
                        print "ERROR: Current data file has antenna "+str(antNames[i])+" on pad "+str(padNames[i])+" while latest move recorded is on pad "+str(antMoves1[j]['To'])
                        msAntPos.pop(antNames[i])
                        continue

                msAntPos[antNames[i]]['putInTime'] = antMoves1[j]['Date']

                if j+1 in antMoves1.keys():
                    msAntPos[antNames[i]]['putOutTime'] = antMoves1[j+1]['Date']
                else:
                    msAntPos[antNames[i]]['putOutTime'] = datetime.datetime.strptime('9999-01-01T00:00:00', '%Y-%m-%dT%H:%M:%S')

            if useTMCDB == True:
                from suds.client import Client
                client = Client('http://asa.alma.cl/axis2/services/TMCDBAntennaPadService?wsdl')
                TMCDBoutput = client.service.getAntennaPositions("CURRENT.AOS", ' '.join(sorted(msAntPos.keys())), datetime.datetime.strftime(obsTime, '%Y-%m-%dT%H:%M:%S'))

            msAntCorr = {}
            gcAntParam1 = []
            missingAntennas = []

            for i in msAntPos:

                found = 0

                if useTMCDB == False:

                    ij = []

                    for j in range(len(baseRunObj)):

                        baseRunObj1 = baseRunObj[sort1[j]]
                        measTime1 = datetime.datetime.strptime(baseRunObj1.getAttribute('measTime'), '%Y-%m-%dT%H:%M:%S')

                        if measTime1 >= msAntPos[i]['putInTime'] and measTime1 <= msAntPos[i]['putOutTime']:

                            wsTime1 = datetime.datetime.strptime('2017-09-15T02:00:00', '%Y-%m-%dT%H:%M:%S') # this is about the time when the weather stations were enabled
                            wsTime2 = datetime.datetime.strptime('2017-09-15T19:00:00', '%Y-%m-%dT%H:%M:%S') # this is about the time when the tmcdb was updated with the new antenna positions
                            if obsTime > wsTime1 and obsTime < wsTime2: continue
                            if obsTime < wsTime1 and measTime1 > wsTime1: continue
                            if obsTime > wsTime2 and measTime1 < wsTime1: continue

                            delta1 = measTime1-obsTime
                            delta1 = delta1.days*86400 + delta1.seconds

                            if maxSearchDays != '':
                                if abs(delta1) > maxSearchDays*86400: continue

                            if search == 'backward':
                                if delta1 <= 0:
                                    ij.append(tuple([j, abs(delta1)]))

                            if search == 'forward':
                                if delta1 >= 0:
                                    ij.append(tuple([j, delta1]))

                            if search == 'both_closest':
                                ij.append(tuple([j, abs(delta1)]))

                            if search == 'both_next':
                                ij.append(tuple([j, 1./delta1]))

                            if search == 'both_latest':
                                ij.append(tuple([j, delta1]))

                    if len(ij) > 0:

                        ij = sorted(ij, key=lambda x:x[1])

                        if search == 'both_next' and ij[-1][1] > 0:
                            ij = sorted(ij, key=lambda x:x[1], reverse=True)

                        if search == 'both_latest':
                            ij = sorted(ij, key=lambda x:x[1], reverse=True)

                        for j in range(len(ij)):

                            baseRunObj1 = baseRunObj[sort1[ij[j][0]]]
                            measTime1 = datetime.datetime.strptime(baseRunObj1.getAttribute('measTime'), '%Y-%m-%dT%H:%M:%S')

                            antObj = baseRunObj1.Antenna

                            if type(antObj) == type([]):
                                lenAntObj = len(antObj)
                            else:
                                lenAntObj = 1

                            for k in range(lenAntObj):

                                if type(antObj) == type([]):
                                    antObj1 = antObj[k]
                                else:
                                    antObj1 = antObj

                                if antObj1.getAttribute('name') == i and antObj1.getAttribute('pad') == msAntPos[i]['pad']:
                                    found = 1
                                    padPosObj = antObj1.PadPosition
                                    brPadPos = [padPosObj.getAttribute('X'), padPosObj.getAttribute('Y'), padPosObj.getAttribute('Z')]
                                    antVecObj = antObj1.AntennaVector
                                    brAntVec = [antVecObj.getAttribute('X'), antVecObj.getAttribute('Y'), antVecObj.getAttribute('Z')]
                                    posErrObj = antObj1.PositionError
                                    brPosErr = [posErrObj.getAttribute('X'), posErrObj.getAttribute('Y'), posErrObj.getAttribute('Z')]
                                    break

                            if found == 1: break # modified

                else:

                    for j in range(len(TMCDBoutput['antennaPositionList'])):
                        if TMCDBoutput['antennaPositionList'][j]['name'] == i:
                            if TMCDBoutput['antennaPositionList'][j]['completion']['status'] == 'true':
                                found = 1
                                measTime1 = 'from TMCDB'
                                brPadPos = [float(TMCDBoutput['antennaPositionList'][j]['pad']['position']['x']), float(TMCDBoutput['antennaPositionList'][j]['pad']['position']['y']), float(TMCDBoutput['antennaPositionList'][j]['pad']['position']['z'])]
                                brAntVec = [float(TMCDBoutput['antennaPositionList'][j]['position']['x']), float(TMCDBoutput['antennaPositionList'][j]['position']['y']), float(TMCDBoutput['antennaPositionList'][j]['position']['z'])]
                                brPosErr = [1e-10, 1e-10, 1e-10]
                            break

                if found != 1:

#                     casaCmd = casaCmd + '# Note: no baseline run found for antenna '+i+'.\n\n'

                    missingAntennas.append(i)

                else:

                    if brPadPos[0] == msAntPos[i]['padPos'][0] and brPadPos[1] == msAntPos[i]['padPos'][1] and brPadPos[2] == msAntPos[i]['padPos'][2]:

                        if brAntVec[0] != msAntPos[i]['antPos'][0] or brAntVec[1] != msAntPos[i]['antPos'][1] or brAntVec[2] != msAntPos[i]['antPos'][2]:

                            posDiff = []
                            for j in range(3):
                                posDiff.append(brAntVec[j] - msAntPos[i]['antPos'][j])

                            if brPosErr[0] == 0 or brPosErr[1] == 0 or brPosErr[2] == 0:
                        
                                print "ERROR: Some baseline observing run position errors are null."

                            else:

                                if sqrt((posDiff[0]/brPosErr[0])**2 + (posDiff[1]/brPosErr[1])**2 + (posDiff[2]/brPosErr[2])**2) >= thresh:

                                    brLat = math.asin(brPadPos[2]/sqrt(brPadPos[0]**2+brPadPos[1]**2+brPadPos[2]**2))
                                    brLon = math.atan2(brPadPos[1], brPadPos[0])

                                    posDiff1 = []
                                    posDiff1.append(-math.sin(brLon)*posDiff[0]-math.cos(brLon)*math.sin(brLat)*posDiff[1]+math.cos(brLon)*math.cos(brLat)*posDiff[2])
                                    posDiff1.append(math.cos(brLon)*posDiff[0]-math.sin(brLon)*math.sin(brLat)*posDiff[1]+math.sin(brLon)*math.cos(brLat)*posDiff[2])
                                    posDiff1.append(math.cos(brLat)*posDiff[1]+math.sin(brLat)*posDiff[2])

                                    if np.linalg.norm(posDiff1) > 2e-3: casaCmd = casaCmd + '# Note: the correction for antenna '+i+' is larger than 2mm.\n\n'

                                    if np.linalg.norm(posDiff1) >= minPosDiff:

                                        msAntCorr[i] = {}
                                        msAntCorr[i]['posDiff'] = posDiff1
                                        if verbose == True: casaCmd = casaCmd + '# Position for antenna '+i+' is derived from baseline run made on '+str(measTime1)+'.\n\n' # modified
                                        gcAntParam1.append(tuple(['# '+i+' %15.5e%15.5e%15.5e%15.5e%25s' % (posDiff1[0], posDiff1[1], posDiff1[2], np.linalg.norm(posDiff1), measTime1), np.linalg.norm(posDiff1)]))

                    else:

                        brLat = math.asin(brPadPos[2]/sqrt(brPadPos[0]**2+brPadPos[1]**2+brPadPos[2]**2))
                        brLon = math.atan2(brPadPos[1], brPadPos[0])

                        brPosTot = []
                        brPosTot.append(brAntVec[0] + -math.sin(-brLon)*brPadPos[0]-math.cos(-brLon)*math.sin(-brLat)*brPadPos[1]+math.cos(-brLon)*math.cos(-brLat)*brPadPos[2])
                        brPosTot.append(brAntVec[1] + math.cos(-brLon)*brPadPos[0]-math.sin(-brLon)*math.sin(-brLat)*brPadPos[1]+math.sin(-brLon)*math.cos(-brLat)*brPadPos[2])
                        brPosTot.append(brAntVec[2] + cos(-brLat)*brPadPos[1]+sin(-brLat)*brPadPos[2])

                        msLat = math.asin(msAntPos[i]['padPos'][2]/sqrt(msAntPos[i]['padPos'][0]**2+msAntPos[i]['padPos'][1]**2+msAntPos[i]['padPos'][2]**2))
                        msLon = math.atan2(msAntPos[i]['padPos'][1], msAntPos[i]['padPos'][0])

                        msPosTot = []
                        msPosTot.append(msAntPos[i]['antPos'][0] + -math.sin(-msLon)*msAntPos[i]['padPos'][0]-math.cos(-msLon)*math.sin(-msLat)*msAntPos[i]['padPos'][1]+math.cos(-msLon)*math.cos(-msLat)*msAntPos[i]['padPos'][2])
                        msPosTot.append(msAntPos[i]['antPos'][1] + math.cos(-msLon)*msAntPos[i]['padPos'][0]-math.sin(-msLon)*math.sin(-msLat)*msAntPos[i]['padPos'][1]+math.sin(-msLon)*math.cos(-msLat)*msAntPos[i]['padPos'][2])
                        msPosTot.append(msAntPos[i]['antPos'][2] + math.cos(-msLat)*msAntPos[i]['padPos'][1]+math.sin(-msLat)*msAntPos[i]['padPos'][2])

                        posDiff = []
                        for j in range(3):
                            posDiff.append(brPosTot[j] - msPosTot[j])

                        if brPosErr[0] == 0 or brPosErr[1] == 0 or brPosErr[2] == 0:
                    
                            print "Note: some errors are null."

                        else:

                            if sqrt((posDiff[0]/brPosErr[0])**2 + (posDiff[1]/brPosErr[1])**2 + (posDiff[2]/brPosErr[2])**2) >= thresh:

                                brPosTot1 = []
                                brPosTot1.append(brPadPos[0] + -math.sin(brLon)*brAntVec[0]-math.cos(brLon)*math.sin(brLat)*brAntVec[1]+math.cos(brLon)*math.cos(brLat)*brAntVec[2])
                                brPosTot1.append(brPadPos[1] + math.cos(brLon)*brAntVec[0]-math.sin(brLon)*math.sin(brLat)*brAntVec[1]+math.sin(brLon)*math.cos(brLat)*brAntVec[2])
                                brPosTot1.append(brPadPos[2] + math.cos(brLat)*brAntVec[1]+math.sin(brLat)*brAntVec[2])

                                msPosTot1 = []
                                msPosTot1.append(msAntPos[i]['padPos'][0] + -math.sin(msLon)*msAntPos[i]['antPos'][0]-math.cos(msLon)*math.sin(msLat)*msAntPos[i]['antPos'][1]+math.cos(msLon)*math.cos(msLat)*msAntPos[i]['antPos'][2])
                                msPosTot1.append(msAntPos[i]['padPos'][1] + math.cos(msLon)*msAntPos[i]['antPos'][0]-math.sin(msLon)*math.sin(msLat)*msAntPos[i]['antPos'][1]+math.sin(msLon)*math.cos(msLat)*msAntPos[i]['antPos'][2])
                                msPosTot1.append(msAntPos[i]['padPos'][2] + math.cos(msLat)*msAntPos[i]['antPos'][1]+math.sin(msLat)*msAntPos[i]['antPos'][2])

                                posDiff1 = []
                                for j in range(3):
                                    posDiff1.append(brPosTot1[j] - msPosTot1[j])

                                if np.linalg.norm(posDiff1) > 2e-3: casaCmd = casaCmd + '# Note: the correction for antenna '+i+' is larger than 2mm.\n\n'

                                if np.linalg.norm(posDiff1) >= minPosDiff:

                                    msAntCorr[i] = {}
                                    msAntCorr[i]['posDiff'] = posDiff1
                                    if verbose == True: casaCmd = casaCmd + '# Position for antenna '+i+' is derived from baseline run made on '+str(measTime1)+'.\n\n' # modified
                                    gcAntParam1.append(tuple(['# '+i+' %15.5e%15.5e%15.5e%15.5e%25s' % (posDiff1[0], posDiff1[1], posDiff1[2], np.linalg.norm(posDiff1), measTime1), np.linalg.norm(posDiff1)]))

            gcAntList = []
            for i in sorted(msAntCorr.keys()): gcAntList.append(i)
            gcAntList = ','.join(gcAntList)

            gcAntParam = []
            gcAntParam0 = []
            for i in sorted(msAntCorr.keys()):
                for j in range(3):
    #                 gcAntParam.append(str(msAntCorr[i]['posDiff'][j]))
                    gcAntParam.append('%.5e' % msAntCorr[i]['posDiff'][j])
                    gcAntParam0.append('0')
            gcAntParam = ','.join(gcAntParam)
            gcAntParam0 = ','.join(gcAntParam0)

            f = open('antennapos.csv', 'a')

#             print >> f, 'name,antenna,xoff,yoff,zoff,comment'

            if gcAntList != '':

                for i in sorted(msAntCorr.keys()):
#                     print >> f, msName+','+i+','+str(msAntCorr[i]['posDiff'][0])+','+str(msAntCorr[i]['posDiff'][1])+','+str(msAntCorr[i]['posDiff'][2])+','
                    print >> f, '%s,%s,%.5e,%.5e,%.5e,' % (msName, i, msAntCorr[i]['posDiff'][0], msAntCorr[i]['posDiff'][1], msAntCorr[i]['posDiff'][2])
        
            f.close()

            if gcAntList != '' or lbc == True or len(missingAntennas) != 0:

                casaCmd = casaCmd + "os.system('rm -rf %s.antpos') \n"%(msName)  # Added by CLB
                casaCmd = casaCmd + "gencal(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  caltable = '"+msName+".antpos',\n"
                casaCmd = casaCmd + "  caltype = 'antpos',\n"

                if gcAntList == '':
                    casaCmd = casaCmd + "  antenna = '"+antNames[0]+"',\n"
                else:
                    casaCmd = casaCmd + "  antenna = '"+gcAntList+"',\n"

                obsTime1 = datetime.datetime.strftime(obsTime, '%Y-%m-%dT%H:%M:%S')

                if (obsTime1 >= '2015-05-12T00:00:00' and obsTime1 <= '2015-06-01T00:00:00') or lbc == True:

                    if gcAntList == '' and lbc == True:
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "  parameter = [0,0,0])\n"
                    else:
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "  parameter = ["+gcAntParam+"])\n"

                elif datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') >= '2017-09-11 00:00:00':

                    if gcAntList == '':
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "  parameter = [0,0,0])\n"
                    else:
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "  parameter = ["+gcAntParam+"])\n"

                else:

                    if gcAntList == '':
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "  parameter = [0,0,0])\n"
                    else:
                        casaCmd = casaCmd + "  parameter = ["+gcAntParam0+"])\n"
                        casaCmd = casaCmd + "#  parameter = ["+gcAntParam+"])\n"

                casaCmd += '\n\n# antenna x_offset y_offset z_offset total_offset baseline_date\n'
                for ij in sorted(gcAntParam1, key=lambda x:x[1], reverse=True):
                    casaCmd += ij[0]+'\n'

                if len(missingAntennas) != 0: casaCmd = '# Warning: no baseline run found for following antenna(s): '+str(missingAntennas)+'.\n\n' + casaCmd

                if len(msNames) == 1:
                    return casaCmd

            else:

                print "Note: I could not find any offset between the antenna positions in the ASDM and in the database, so I am not including any gencal call."

    def getSpwInfo(self, msName, intent='OBSERVE_TARGET'):

        tb.open(msName+'/STATE')
        obsModes = tb.getcol('OBS_MODE')
        tb.close()

        obsModes1 = []
        for i in range(len(obsModes)):
            if re.search(intent, obsModes[i]) is not None:
                obsModes1.append(i)

        if len(obsModes1) == 0:
            if 'OBSERVE_TARGET' in intent: # this is mainly for the cal survey reduction
                print 'WARNING: There seems to be no OBSERVE_TARGET intent in the data.'
                print 'WARNING: I will try with the intent CALIBRATE_PHASE. THIS MAY BE WRONG!!'
                obsModes1 = []
                for i in range(len(obsModes)):
                    if re.search('CALIBRATE_PHASE', obsModes[i]) is not None:
                        obsModes1.append(i)
                if len(obsModes1) == 0:
                    print 'WARNING: There seems to be no CALIBRATE_PHASE intent in the data.'
                    print 'WARNING: I will try with the intents CALIBRATE_AMPLI and CALIBRATE_FLUX. THIS MAY BE WRONG!!'
                    obsModes1 = []
                    for i in range(len(obsModes)):
                        if re.search('CALIBRATE_AMPLI|CALIBRATE_FLUX', obsModes[i]) is not None:
                            obsModes1.append(i)
                    if len(obsModes1) == 0: sys.exit('ERROR: Intent not found.')
            else:
                #sys.exit('ERROR: Intent not found.')
                print 'WARNING: Intent not found.'
                return {}

        tb.open(msName+'/PROCESSOR')
        tb1 = tb.query("SUB_TYPE == 'ALMA_CORRELATOR_MODE'")
        procIds = tb1.rownumbers()

        if (type(procIds) == int):
            # Added by T. Hunter to prevent crash at 'for' loop when only one value is returned.
            procIds = [procIds]
        tb1.close()
        tb.close()

        tb.open(msName+'/DATA_DESCRIPTION')
        spwIds = tb.getcol('SPECTRAL_WINDOW_ID')
        tb.close()

#         tb.open(msName+'/SPECTRAL_WINDOW')
#         numChans = tb.getcol('NUM_CHAN')
#         refFreq = tb.getcol('REF_FREQUENCY')
#         tb.close()

        tb.open(msName)

        dataDescIds = []
        for i in procIds:
            for j in obsModes1:
                tb1 = tb.query('PROCESSOR_ID == '+str(i)+' AND STATE_ID == '+str(j))
                dataDescIds1 = sorted(dict.fromkeys(tb1.getcol('DATA_DESC_ID')).keys())
                dataDescIds.extend(dataDescIds1)
                tb1.close()
        tb.close()

        dataDescIds = sorted(dict.fromkeys(dataDescIds).keys())
        if intent in ['OBSERVE_TARGET', 'OBSERVE_TARGET|CALIBRATE_BANDPASS']:

            tb.open(msName)

            integTime = []
            for i in dataDescIds:
                tb1 = tb.query('DATA_DESC_ID == '+str(i))
                integTime1 = dict.fromkeys(tb1.getcol('EXPOSURE')).keys()
                if len(integTime1) != 1:
                    print "WARNING: DATA ASSOCIATED TO DATA_DESC_ID="+str(i)+" IN "+msName+" HAVE MORE THAN ONE INTEGRATION TIME."
                integTime.append(integTime1[0])
                tb1.close()
            tb.close()

        tb.open(msName+'/SPECTRAL_WINDOW')
        numChans = tb.getcol('NUM_CHAN')
        spwName = tb.getcol('NAME')

        spwInfo = {}
        for i in range(len(dataDescIds)):
            if numChans[spwIds[dataDescIds[i]]] != 1 and 'CH_AVG' not in spwName[spwIds[dataDescIds[i]]]:
                spwInfo[spwIds[dataDescIds[i]]] = {}
                spwInfo[spwIds[dataDescIds[i]]]['numChans'] = numChans[spwIds[dataDescIds[i]]]
                spwInfo[spwIds[dataDescIds[i]]]['refFreq'] = tb.getcell('REF_FREQUENCY', spwIds[dataDescIds[i]]) # refFreq[spwIds[dataDescIds[i]]]
                spwInfo[spwIds[dataDescIds[i]]]['basebandNum'] = tb.getcell('BBC_NO', spwIds[dataDescIds[i]])
                spwInfo[spwIds[dataDescIds[i]]]['meanFreq'] = np.mean(tb.getcell('CHAN_FREQ', spwIds[dataDescIds[i]]))
                if intent in ['OBSERVE_TARGET', 'OBSERVE_TARGET|CALIBRATE_BANDPASS']: spwInfo[spwIds[dataDescIds[i]]]['integTime'] = integTime[i]

        tb.close()

        return spwInfo

    def generateTsysCalTable(self, msName, calTableName=[], doplot=True):

        #casaCmd = 'print "# Generation of the Tsys cal table."\n\n'
        casaCmd = ''

        sciSpwInfo = self.getSpwInfo(msName)

        if re.search('^3.3', getCasaVersion()) is not None:
            sciNumChans = []
#             sciSpwInfo = self.getSpwInfo(msName)
            for i in sciSpwInfo: sciNumChans.append(sciSpwInfo[i]['numChans'])
            sciNumChans = sorted(dict.fromkeys(sciNumChans).keys())
            if len(sciNumChans) != 1: sys.exit('ERROR: Configuration not supported.')

        tsysNumChans = []
        tsysSpwInfo = self.getSpwInfo(msName, intent='CALIBRATE_ATMOSPHERE')
        for i in tsysSpwInfo: tsysNumChans.append(tsysSpwInfo[i]['numChans'])
        tsysNumChans = sorted(dict.fromkeys(tsysNumChans).keys())
# The following check is no longer needed since tsysNumChans is not used
# in casa versions >= 4.0.   
#        if len(tsysNumChans) != 1:
#            print "tsysNumChans = ", tsysNumChans
#            sys.exit('ERROR: Tsys channel configuration not supported.')
        tsysNumChans = tsysNumChans[0]

        casaCmd = casaCmd + "os.system('rm -rf %s.tsys') \n"%(msName)  # Added by CLB
        if re.search('^3.3', getCasaVersion()) is not None:
            casaCmd = casaCmd + "os.system('rm -rf %s.tsys.fdm') \n\n"%(msName)  # Added by CLB
        casaCmd = casaCmd + "gencal(vis = '"+msName+"',\n"
        casaCmd = casaCmd + "  caltable = '"+msName+".tsys',\n"
        casaCmd = casaCmd + "  caltype = 'tsys')\n\n"

        if re.search('^3.3', getCasaVersion()) is not None:
            casaCmd = casaCmd + "interTsys = aU.InterpolateTsys('"+msName+".tsys')\n"
            casaCmd = casaCmd + "interTsys.correctBadTimes(force=True)\n"
            casaCmd = casaCmd + "interTsys.assignFieldAndScanToSolution()\n"

        calTableName1 = msName+'.tsys'

        if re.search('^3.3', getCasaVersion()) is not None:
            if tsysNumChans < sciNumChans:
                casaCmd = casaCmd + "interTsys.getTdmFdmSpw()\n"
                casaCmd = casaCmd + "interTsys.interpolateTsys()\n"
                calTableName1 = msName+'.tsys' # CLB removed .fdm temporarily for Tsys plotting below

            casaCmd = casaCmd + "clearstat()\n\n"

        if getCasaVersion() >= '4.2.2':

            chanEdge = 0.03125 # this is for 128ch/2GHz

            spwSpec = ''
            for i in sorted(tsysSpwInfo.keys()):
                if tsysSpwInfo[i]['numChans'] <= 256:
                    if spwSpec != '': spwSpec = spwSpec+','
                    chanEdge1 = chanEdge * tsysSpwInfo[i]['numChans'] / 128.
                    spwSpec = spwSpec+str(i)+':0~'+str(long(tsysSpwInfo[i]['numChans']*chanEdge1-1))+';'+str(long(tsysSpwInfo[i]['numChans']-tsysSpwInfo[i]['numChans']*chanEdge1))+'~'+str(tsysSpwInfo[i]['numChans']-1)

            if spwSpec != '':
                casaCmd = casaCmd + "# Flagging edge channels\n\n"
                casaCmd = casaCmd + "flagdata(vis = '"+calTableName1+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        if doplot == True:
            if False:
                # old method, before plotbandpass accepted percentages
                chanEdge = 0.0390625
                startChan = int(tsysNumChans * chanEdge)
                endChan = int(tsysNumChans * (1-chanEdge))
                chanrange = str(startChan)+'~'+str(endChan)
            else:
                chanrange = '92.1875%'

    # CLB Added additional Tsys plot:  TDM with overlay='time', atmospheric transmission,
    # a slightly restricted chanrange (to exclude wild edge values), and showing the
    # location of the FDM spws (if present)

            showimage = False
            for i in sorted(sciSpwInfo.keys()):
                if sciSpwInfo[i]['refFreq'] > 550e9: showimage = True

            casaCmd = casaCmd + "if applyonly != True: aU.plotbandpass(caltable='%s', overlay='time', \n" %(calTableName1)
            casaCmd = casaCmd + "  xaxis='freq', yaxis='amp', subplot=22, buildpdf=False, interactive=False,\n"
            casaCmd = casaCmd + "  showatm=True,pwv='auto',chanrange='"+chanrange+"',showfdm=True, showBasebandNumber=True, showimage="+str(showimage)+", \n"
            casaCmd = casaCmd + "  field='', figfile='%s') \n\n" %(calTableName1+'.plots.overlayTime/'+calTableName1.split('/')[-1])

        if re.search('^3.3', getCasaVersion()) is not None:
            if tsysNumChans < sciNumChans:   # CLB added
                calTableName1 += '.fdm'      # CLB added .fdm for following plot
        calTableName.append(calTableName1)
        if doplot == True:
            casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+"', msName='"+msName+"', interactive=False) \n"

        return casaCmd

    def getCalWeightStats(self, msName):

        sciSpwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
#         mytb = createCasaTool(tbtool)
#         mytb.open(msName+'/DATA_DESCRIPTION')
#         spwIds = mytb.getcol('SPECTRAL_WINDOW_ID')
#         mytb.close()
# 
#         output = "# Spw Pol Min Mean Max\n"
# 
#         mytb.open(msName)
# 
#         for i in sciSpwInfo:
#             dataDescId = np.where(np.array(spwIds) == i)[0]
#             if len(dataDescId) != 1: sys.exit('ERROR: Too many data desc ids')
#             dataDescId = dataDescId[0]
#             tb1 = mytb.query('DATA_DESC_ID == '+str(dataDescId)+' AND FLAG_ROW != True')
#             calWeightStats = tb1.statistics(column='WEIGHT')
#             for j in calWeightStats.keys():
#                 output = output + '%d %s %.2f %.2f %.2f' %(i, j.split('_')[1], calWeightStats[j]['min'], calWeightStats[j]['mean'], calWeightStats[j]['max'])
#                 if calWeightStats[j]['max'] < 10:
#                     output = output + ' -> OK\n'
#                 else:
#                     output = output + ' -> NOT OK\n'
#             tb1.close()
#         mytb.close()
#         print output
# 
#         f = open(msName+'.calweights', 'w')
#         print >> f, output
#         f.close()

        for i in sciSpwInfo:
            plotms(vis = msName, xaxis = 'time', yaxis = 'weight', spw = str(i), xselfscale = True, yselfscale = True,
                coloraxis = 'field', plotfile = msName + '_weights_spw'+str(i)+'.png', overwrite = True)

    def getFlagStats(self, msName):

        import flag

        flagStats = flag.flag_calc(msName)

        print 'Overall -> %.2f' %(100.0*flagStats['flagged']/flagStats['total'])
        print ''
        print 'Per spw (over total of dataset):'
        for i in flagStats['spw']:
            print i+' -> %.2f' %(100.0*flagStats['spw'][i]['flagged']/flagStats['total'])
        print ''
        print 'Per antenna (over total of dataset):'
        for i in flagStats['antenna']:
            print i+' -> %.2f' %(100.0*flagStats['antenna'][i]['flagged']/flagStats['total'])

    def getImageStats(self, imgName):

        import image

        imgStats = image.image_calc(imgName)

        nChans = len(imgStats['frequency'][0])

        print '# frequency max_in rms_out dynrange'
        for i in range(nChans):
            print str(i) + " %.2f" %(imgStats['frequency'][0][i]/1.0e9) + " %.2g" %(imgStats['max_in'][0][i]) + " %.2g" %(imgStats['rms_out'][0][i]) + " %.2f" %(imgStats['dynrange'][0][i])

    def getPsfStats(self, psfName):

        import psf

        psfStats = psf.psf_calc(psfName)

        nChans = len(psfStats['all_fits']['keyword']['frequency'])

        print '# frequency major_axis error unit minor_axis error unit position_angle error unit'
        for i in range(nChans):
            if psfStats['all_fits']['converged'][0][i] == True:
                print str(i) + " %.2f %.4g %.4g %s %.4g %.4g %s %.4g %.4g %s" %((psfStats['all_fits']['keyword']['frequency'][i]/1.0e9), \
                    psfStats['all_fits']['major_axis'][0][i],psfStats['all_fits']['major_axis_err'][0][i],psfStats['all_fits']['keyword']['major_axis_unit'], \
                    psfStats['all_fits']['minor_axis'][0][i],psfStats['all_fits']['minor_axis_err'][0][i],psfStats['all_fits']['keyword']['minor_axis_unit'], \
                    psfStats['all_fits']['position_angle'][0][i],psfStats['all_fits']['position_angle_err'][0][i],psfStats['all_fits']['keyword']['position_angle_unit'])
            else:
                print str(i) + " %.2f PSF fit did not converge." %(psfStats['all_fits']['keyword']['frequency'][i]/1.0e9)

    def plotAntennas(self, vis, plotfile=''):
        """
        Plot antenna/pad positions in ANTENNA table.
        vis: measurement set
        plotfile: default name is <vis>.plotAntennas.png
        """
        (sitelon, sitelat) = (pb.radians(-67.75), pb.radians(-23.02))
        tb.open(vis+'/ANTENNA')
        ant_pos = tb.getcol('POSITION')
        ant_name = tb.getcol('NAME')
        ant_station = tb.getcol('STATION')
        tb.close()

        config_antennas = {}
        for (i, ant) in enumerate(ant_name):
            config_antennas[ant] = ant_station[i]

        pads = {}
        for (i, pad) in enumerate(ant_station):
            pads[pad] = pb.array(self.shiftAlmaCoord(geoToAlma(sitelon, sitelat, \
                (ant_pos[0][i], ant_pos[1][i], ant_pos[2][i]))))
   # map: with pad names
        plf1 = pb.figure(1)
        pb.clf()
        subpl1 = plf1.add_subplot(1, 1, 1, aspect='equal')
        self.draw_pad_map_in_subplot(subpl1, pads, config_antennas)
        mytitle = vis
        if (len(mytitle) > 55):
            mytitle = '...'+vis[-55:]
        pb.title(mytitle)
        if (plotfile == ''):
            myfigfile = vis + '.plotAntennas.png'
        else:
            myfigfile = plotfile
        pb.savefig(myfigfile,format='png',density=108)
        print "Figure output to %s" % (myfigfile)
        plf1.show()

        ## map: without pad names
        #plf2 = pb.figure(2)
        ##plf2.clf()
        #subpl2 = plf2.add_subplot(1, 1, 1, aspect='equal')
        #self.draw_pad_map_in_subplot(subpl2, pads, config_antennas, showemptypads=False)
        #plf2.show()

    def shiftAlmaCoord(self, pos):
        """
        Arbitrarily shift ALMA coord so that central cluster comes around (0, 0).
        """
        return (pos[0]+480., pos[1]-14380., pos[2])

    #def geoToAlma(self, lon, lat, geo):
    #    """
    #    Convert the geocentric coordinates into the local (horizontal) ones.
    #    """
    #    alma = [0, 0, 0]
    #    alma[0] = - geo[0]*pb.sin(lon) + \
    #                geo[1]*pb.cos(lon)
    #    alma[1] = - geo[0]*pb.cos(lon)*pb.sin(lat) - \
    #                geo[1]*pb.sin(lon)*pb.sin(lat) + \
    #                geo[2]*pb.cos(lat)
    #    alma[2] =   geo[0]*pb.cos(lon)*pb.cos(lat) + \
    #                geo[1]*pb.sin(lon)*pb.cos(lat) + \
    #                geo[2]*pb.sin(lat)
    #    return alma

    def draw_pad_map_in_subplot(self, subpl, pads, antennas, xlimit=None, ylimit=None,
        showemptypads=True):
        """
        Draw a map of pads and antennas on them.

        subpl: a pylab.subplot instance
        pads: a dictionary of antennas {"Name": (X, Y, Z), ...}
        antennas: a dictionary of antennas {"AntennaName": "PadName", ...}
        xlimit, ylimit: lists (or tuples, arrays) for the x and y axis limits.
                        if not given, automatically adjusted.
        showemptypads: set False not to draw pads and their names
        showbaselinelength: set True to display baseline length
        """
        subpl.clear()
        if showemptypads:
            for pad in pads.keys():
                padpos = pads[pad]
                if pad[:1] in ['J', 'N']:
                    radius = 3.5
                else:
                    radius = 6.0
                circ = pb.Circle(padpos[:2], radius)
                subpl.add_artist(circ)
                circ.set_alpha(0.5)
                circ.set_facecolor([1.0, 1.0, 1.0])
                tt = subpl.text(padpos[0]+8., padpos[1]-5., pad)
                pb.setp(tt, size='small', alpha=0.5)

        (xmin, xmax, ymin, ymax) = (9e9, -9e9, 9e9, -9e9)
        for ant in antennas.keys():
            if ant[:2] == 'CM':
                radius = 3.5
            else:
                radius = 6.
            padpos = pads[antennas[ant]]
            circ = pb.Circle(padpos[:2], radius=radius)
            subpl.add_artist(circ)
            circ.set_alpha(1.0)
            circ.set_facecolor([0.8, 0.8, 0.8])
            subpl.text(padpos[0], padpos[1]+2, ant)
            if padpos[0] < xmin: xmin = padpos[0]
            if padpos[0] > xmax: xmax = padpos[0]
            if padpos[1] < ymin: ymin = padpos[1]
            if padpos[1] > ymax: ymax = padpos[1]

        subpl.set_xlabel('X [m]')
        subpl.set_ylabel('Y [m]')
        plotwidth = max(xmax-xmin, ymax-ymin) * 6./10. # extra 1/10 is the margin
        (xcenter, ycenter) = ((xmin+xmax)/2., (ymin+ymax)/2.)
        if xlimit is None:
            subpl.set_xlim(xcenter-plotwidth, xcenter+plotwidth)
        else:
            subpl.set_xlim(xlimit[0], xlimit[1])
        if ylimit is None:
            subpl.set_ylim(ycenter-plotwidth, ycenter+plotwidth)
        else:
            subpl.set_ylim(ylimit[0], ylimit[1])

        ants = antennas.keys()
        ants.sort()

        return None

    def getAntennasForFluxscale2(self, msName, fluxCalId='', refant='', thresh=0.15):

        spwInfo = self.getSpwInfo(msName, intent='CALIBRATE_AMPLI|CALIBRATE_FLUX')
        mymsmd = msmdtool()
        mymsmd.open(msName)
        ampSpwIds1 = mymsmd.spwsforfield(int(fluxCalId))
        mymsmd.close()

        for i in spwInfo.keys():
            if i not in ampSpwIds1:
                spwInfo.pop(i)

        msSplit = 0

        tb.open(msName)
        colNames = tb.colnames()
        tb.close()

        if 'MODEL_DATA' not in colNames:

            sciSpwIds = sorted(spwInfo.keys())
            sciSpwIds1 = ','.join(['%s' %i for i in sciSpwIds])

            split(vis = msName, outputvis = msName+'.temp', datacolumn = 'data', field = fluxCalId, spw = sciSpwIds1)

            msName = msName+'.temp'

#             fixplanets(vis = msName, field = '0', fixuvw = True)

            fieldIds = self.getFieldsForFixPlanets(msName)
            if len(fieldIds) != 0:
                fieldIds = ['%s' %i for i in fieldIds]
                fieldIds = ','.join(fieldIds)
                fixplanets(vis = msName, field = fieldIds, fixuvw = True)

            if re.search('^3.', getCasaVersion()) == None:
                setjy(vis = msName, field = '0', standard = 'Butler-JPL-Horizons 2012', usescratch = True)
            else:
                if re.search('^3.3', getCasaVersion()) == None:
                    setjy(vis = msName, field = '0', standard = 'Butler-JPL-Horizons 2010', usescratch = True)
                else:
                    setjy(vis = msName, field = '0', standard = 'Butler-JPL-Horizons 2010')

            for i in sciSpwIds:
                spwInfo[str(sciSpwIds.index(i))] = spwInfo[i]
                spwInfo.pop(i)

            fluxCalId = '0'

            msSplit = 1

        tb.open(msName+'/DATA_DESCRIPTION')
        spwIds = tb.getcol('SPECTRAL_WINDOW_ID').tolist()
        tb.close()

        uvDist1 = []

        tb.open(msName)

        for i in spwInfo:

            dataDescId = spwIds.index(int(i))
            tb1 = tb.query('FIELD_ID == '+fluxCalId+' AND DATA_DESC_ID == '+str(dataDescId))
            uvw = tb1.getcol('UVW')
            modelData = tb1.getcol('MODEL_DATA')

            uvDist = []
            modelData1 = []
            for j in range(len(uvw[0])):
                uvDist.append(sqrt(uvw[0][j]**2+uvw[1][j]**2))
                modelData1.append(abs(modelData[0][int(spwInfo[i]['numChans'])/2][j]))

            uvDist = np.array(uvDist)
            modelData1 = np.array(modelData1)
            ij = np.where(modelData1 < thresh*max(modelData1))
            if len(ij[0]) != 0: uvDist1.append(min(uvDist[ij]))

        tb.close()

        tb.open(msName+'/ANTENNA')
        antList = tb.getcol('NAME')
        tb.close()

        if len(uvDist1) == 0:

            if msSplit == 1: os.system('rm -Rf '+msName)
            return antList.tolist()

        else:

            uvDist1 = min(np.array(uvDist1))

            baselineLen = getBaselineLengths(msName)

            antList1 = []
            for i in antList:
                for j in baselineLen:
                    if i in j[0] and refant in j[0] and j[1] <= uvDist1:
                        antList1.append(i)
                        break

            while len(antList1) > 1:

                maxBaselineLen = 0.0
                for i in baselineLen:
                    ii = i[0].split('-')
                    if ii[0] in antList1 and ii[1] in antList1 and i[1] > maxBaselineLen: maxBaselineLen = i[1]
                if maxBaselineLen <= uvDist1: break

                avgBaselineLen = []
                for i in antList1:
                    count1 = 0
                    sum1 = 0.0
                    for j in baselineLen:
                        if i in j[0] and re.sub('-?'+i+'-?', '', j[0]) in antList1:
                            count1 = count1+1
                            sum1 = sum1+j[1]
                    avgBaselineLen.append(sum1 / count1)

                j = avgBaselineLen.index(max(avgBaselineLen))
                antList1.pop(j)

            if msSplit == 1: os.system('rm -Rf '+msName)
            return antList1

    def computeMaxGainIgnoring1(self, cparam):
        cparam = np.abs(cparam.flatten())
        indices = np.where(np.round(cparam*1000000.)/1000000. != 1.0)[0]
        cparam = cparam[indices]
        if (len(cparam) == 0):
            return(1.0)  # in case all values are 1.0
        else:
            return(np.max(cparam))

    def checkCalTable(self, calTableName, msName='', interactive=True, 
                      subplot=411, fontsize=10.0):
        """
        msName: this parameter is required in all recent CASA versions
        """
        subplotRows = int(subplot/100)
        if (subplotRows < 1 or subplotRows > 9 or subplot-subplotRows*100 != 11):
            print "subplot must be x11 where x=1..9 (and it only applies to G and T solutions)"
            return

        if (calTableName[-1] == '/'):
            print "checkCalTable(): stripping off the trailing slash from the name"
            calTableName = calTableName[:-1]  # strip off trailing slash if present
        calTableNameNoPath = calTableName.split('/')[-1]
        
        if os.path.isdir(calTableName+'.plots') == True:
            if (interactive == True):
                raw_input("Directory for plots already exists. It will be removed. Press Enter to continue...")
            os.system('rm -Rf '+calTableName+'.plots')

        supportedCalTypes = ['B Jones', 'G Jones', 'B TSYS', 'T Jones', 'SDSKY_PS', 'SDSKY_RASTER']
        mytb = createCasaTool(tbtool)
        if msName == '':
            # CASA caltables no longer have this table name
            mytb.open(calTableName+'/CAL_DESC')
            msName = dict.fromkeys(mytb.getcol('MS_NAME')).keys()
            if len(msName) != 1: sys.exit('ERROR: Too many names.')
            msName = msName[0]
            mytb.close()

        mytb.open(calTableName)
        calType = (mytb.info())['subType']
        if calType not in supportedCalTypes: sys.exit('ERROR: Cal type not supported.')

        if calType in ['B TSYS', 'SDSKY_PS', 'SDSKY_RASTER']:
            mytb.close()
            spwInfo = self.getSpwInfo(msName)
            mytb.open(calTableName)
            showimage = False
            for i in sorted(spwInfo.keys()):
                if spwInfo[i]['refFreq'] > 550e9: showimage = True

            fieldIds = sorted(dict.fromkeys(mytb.getcol('FIELD_ID')).keys())
            mytb.close()
            if getCasaVersion() >= '4.3.1':
                vm = ''
            else:
                vm = ValueMapping(msName)
            for i in fieldIds:
                plotbandpass(caltable=calTableName, overlay='antenna', xaxis='freq', yaxis='amp', subplot=22, buildpdf=False, interactive=interactive, field=str(i), showimage=showimage, vm=vm, showBasebandNumber=True, figfile=calTableName+'.plots/'+calTableNameNoPath+'.field'+str(i))
            casaCmd  = "# This is what checkCalTable executed:\n"  # Added by CLB
            casaCmd += "#for i in %s:\n" % list(fieldIds)   # Added by CLB
            casaCmd += "#   plotbandpass(caltable='%s', overlay='antenna', xaxis='freq', yaxis='amp', subplot=22, buildpdf=False, interactive=False, field=str(i), showimage=%s, showBasebandNumber=True, figfile='%s.plots/%s.field'+str(i))\n\n" % (calTableName,showimage,calTableName,calTableNameNoPath)   # Added by CLB
            print casaCmd  # Added by CLB

        if calType == 'B Jones':
            mytb.close()
            if getCasaVersion() >= '4.3.1':
                vm = ''
            else:
                vm = ValueMapping(msName)
            casaCmd  = "# This is what checkCalTable executed:\n"  # Added by CLB
            if os.path.isdir(calTableName+'_smooth20flat_ri') == True:
                casaCmd += "#aU.plotbandpass(caltable='%s', caltable2='%s_smooth20flat_ri', xaxis='freq', yaxis='both', showatm=True, pwv='auto', subplot=22, buildpdf=False, interactive=False, vm=vm, showBasebandNumber=True, figfile='%s.plots/%s)\n" % (calTableName,calTableName,calTableName,calTableNameNoPath)   # Added by CLB
                print casaCmd 
                plotbandpass(caltable=calTableName, caltable2=calTableName+'_smooth20flat_ri', xaxis='freq', yaxis='both', showatm=True, pwv='auto', subplot=22, buildpdf=False, interactive=interactive, vm=vm, showBasebandNumber=True, figfile=calTableName+'.plots/'+calTableNameNoPath)
            else:
                casaCmd += "#aU.plotbandpass(caltable='%s', xaxis='freq', yaxis='both', showatm=True, pwv='auto', subplot=22, buildpdf=False, interactive=False, vm=vm, showBasebandNumber=True, figfile='%s.plots/%s')\n" % (calTableName,calTableName,calTableNameNoPath)  # Added by CLB
                print casaCmd 
                plotbandpass(caltable=calTableName, xaxis='freq', yaxis='both', showatm=True, pwv='auto', subplot=22, buildpdf=False, interactive=interactive, vm=vm, showBasebandNumber=True, figfile=calTableName+'.plots/'+calTableNameNoPath)

        if calType in ['G Jones', 'T Jones']:
            # Check the number of spws in the caltable. If greater than 4, need 
            # to run plotcal multiple times for multiple pages.
            
            calStats = {}
            if re.search('^3.3', getCasaVersion()) is not None:
                calStats['GAIN_amp'] = (mytb.statistics(column='GAIN', complex_value='amp'))['GAIN']
                calStats['GAIN_phase'] = (mytb.statistics(column='GAIN', complex_value='phase'))['GAIN']
                spwsInSolution = np.unique(mytb.getcol('CAL_DESC_ID'))
            else:
                names = mytb.colnames()
                if ('SPECTRAL_WINDOW_ID' in names):  # this is a table from >= 3.4
                    calStats['GAIN_amp'] = (mytb.statistics(column='CPARAM', complex_value='amp'))['CPARAM']
                    calStats['GAIN_phase'] = (mytb.statistics(column='CPARAM', complex_value='phase'))['CPARAM']
                    # Added by Todd to make the maximum value not be forced to be 1.0
                    calStats['GAIN_amp']['max'] = self.computeMaxGainIgnoring1(mytb.getcol('CPARAM'))
                    spwsInSolution = np.unique(mytb.getcol('SPECTRAL_WINDOW_ID'))
                else:
                    # This is needed in case the user is running casa 3.4 and wants to examine a 3.3 table
                    calStats['GAIN_amp'] = (mytb.statistics(column='GAIN', complex_value='amp'))['GAIN']
                    calStats['GAIN_phase'] = (mytb.statistics(column='GAIN', complex_value='phase'))['GAIN']
                    spwsInSolution = np.unique(mytb.getcol('CAL_DESC_ID'))
            mytb.close()


            mytb.open(msName+'/ANTENNA')
            antList = mytb.getcol('NAME')
            mytb.close()

            os.system('mkdir '+calTableName+'.plots')

            if interactive:
                showgui=True
            else:
                showgui=False

            #if calStats['GAIN_amp']['medabsdevmed'] != 0:
            print "GAIN_amp_min, max = ", calStats['GAIN_amp']['min'], calStats['GAIN_amp']['max']
            if abs(calStats['GAIN_amp']['min']-1) > 0.001 or abs(calStats['GAIN_amp']['max']-1) > 0.001:
                minAmp = calStats['GAIN_amp']['min']
                maxAmp = calStats['GAIN_amp']['max']
                casaCmd  = "# This is what checkCalTable executed:\n"
                casaCmd += "#for i in %s:\n" % list(antList)   
                for i in antList:
                  quitloop = False
                  for startSpw in range(0,len(spwsInSolution),subplotRows):
                    if (len(spwsInSolution) <= subplotRows):
                        plotspw = ''
                        spwnames = ''
                    else:
                        plotspw = range(startSpw,np.min([startSpw+subplotRows,len(spwsInSolution)]))
                        plotspw = list(np.array(spwsInSolution)[plotspw])
                        plotspw = str(plotspw).replace(' ','').strip('[]')
                        spwnames = '.spw' + plotspw[0] + '-' + plotspw[-1]
                    plotcal(caltable=calTableName, xaxis='time', yaxis='amp', antenna=i, iteration='antenna,spw', subplot=subplot, plotrange=[0, 0, minAmp, maxAmp], figfile=calTableName+'.plots/'+calTableNameNoPath+'.amp.'+i+spwnames+'.png', spw=plotspw, fontsize=fontsize,showgui=showgui)
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, q to quit amplitudes, or n to go non-interactive. ")
                        if userRawInput.lower() == 'q':
                            quitloop = True
                            break
                        if userRawInput.lower() == 'n': interactive = False
                        
                    if (i == antList[0]):
                        casaCmd += "#   plotcal(caltable='%s', xaxis='time', yaxis='amp', antenna=i, iteration='antenna,spw', subplot=%d, plotrange=[0, 0, %f, %f], figfile='%s.plots/%s.amp.'+str(i)+'%s.png', spw='%s', showgui=%s)\n" % (calTableName,subplot,minAmp, maxAmp,calTableName,calTableNameNoPath, spwnames, plotspw,showgui)  # Added by CLB
                  if (quitloop): break
                print casaCmd  # Added by CLB
            #if calStats['GAIN_phase']['medabsdevmed'] != 0:
            if abs(calStats['GAIN_phase']['min']) > 0.001 or abs(calStats['GAIN_phase']['max']) > 0.001:
                minPhase = math.degrees(calStats['GAIN_phase']['min'])
                maxPhase = math.degrees(calStats['GAIN_phase']['max'])
                casaCmd  = "# This is what checkCalTable executed:\n"  # Added by CLB
                casaCmd += "#for i in %s:\n" % list(antList)   # Added by CLB
                for i in antList:
                  quitloop = False
                  for startSpw in range(0,len(spwsInSolution),subplotRows):
                    if (len(spwsInSolution) <= subplotRows):
                        plotspw = ''
                        spwnames = ''
                    else:
                        plotspw = range(startSpw,np.min([startSpw+subplotRows,len(spwsInSolution)]))
                        plotspw = list(np.array(spwsInSolution)[plotspw])
                        plotspw = str(plotspw).replace(' ','').strip('[]')
                        spwnames = '.spw' + plotspw[0] + '-' + plotspw[-1]
                    plotcal(caltable=calTableName, xaxis='time', yaxis='phase', antenna=i, iteration='antenna,spw', subplot=subplot, plotrange=[0, 0, minPhase, maxPhase], figfile=calTableName+'.plots/'+calTableNameNoPath+'.phase.'+i+spwnames+'.png', spw=plotspw, fontsize=fontsize,showgui=showgui)
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, q to quit, or n to go non-interactive. ")
                        if userRawInput.lower() == 'q':
                            quitloop = True
                            break
                        if userRawInput.lower() == 'n': interactive = False
                    if (i == antList[0]):
                        casaCmd += "#    plotcal(caltable='%s', xaxis='time', yaxis='phase', antenna=i, iteration='antenna,spw', subplot=%d, plotrange=[0, 0,%f,%f], figfile='%s.plots/%s.phase.'+str(i)+'%s.png', spw='%s', showgui=%s)\n" % (calTableName, subplot, minPhase, maxPhase,calTableName,calTableNameNoPath, spwnames, plotspw,showgui)  # Added by CLB
                  if (quitloop): break
                print casaCmd  # Added by CLB
            # endif   tb.
        # endif calType

    def checkCalTable2(self, calTableName, interactive=True):

        casaCmd = ''

        supportedCalTypes = ['B Jones', 'G Jones', 'B TSYS', 'T Jones']

        tb.open(calTableName+'/CAL_DESC')
        msName = dict.fromkeys(tb.getcol('MS_NAME')).keys()
        if len(msName) != 1: sys.exit('ERROR: Too many names.')
        msName = msName[0]
        tb.close()

        tb.open(calTableName)
        calType = (tb.info())['subType']
        if calType not in supportedCalTypes: sys.exit('ERROR: Cal type not supported.')

        if calType == 'B TSYS':
            fieldIds = sorted(dict.fromkeys(tb.getcol('FIELD_ID')).keys())
            tb.close()
            casaCmd = casaCmd + "vm = aU.ValueMapping("+msName+")\n\n"
            casaCmd = casaCmd + "for i in "+str(fieldIds)+":\n"
            casaCmd = casaCmd + "  aU.plotbandpass(caltable = '"+calTableName+"',\n"
            casaCmd = casaCmd + "    overlay = 'antenna',\n"
            casaCmd = casaCmd + "    xaxis = 'freq',\n"
            casaCmd = casaCmd + "    yaxis = 'amp',\n"
            casaCmd = casaCmd + "    subplot = 22,\n"
            casaCmd = casaCmd + "    buildpdf = False,\n"
            casaCmd = casaCmd + "    interactive = "+str(interactive)+",\n"
            casaCmd = casaCmd + "    field = str(i),\n"
            casaCmd = casaCmd + "    vm = vm,\n"
            casaCmd = casaCmd + "    figfile = '"+calTableName+".plots/"+calTableName+".field'+str(i))\n"

        if calType == 'B Jones':
            tb.close()
            casaCmd = casaCmd + "vm = aU.ValueMapping("+msName+")\n\n"
            casaCmd = casaCmd + "aU.plotbandpass(caltable = '"+calTableName+"',\n"
            if os.path.isdir(calTableName+'_smooth20flat_ri') == True:
                casaCmd = casaCmd + "  caltable2 = '"+calTableName+"_smooth20flat_ri',\n"
            else:
                casaCmd = casaCmd + "  #caltable2 = '"+calTableName+"_smooth20flat_ri', # please uncomment this line if you have run smoothbandpass\n"
            casaCmd = casaCmd + "  xaxis = 'freq',\n"
            casaCmd = casaCmd + "  yaxis = 'both',\n"
            casaCmd = casaCmd + "  showatm = True,\n"
            casaCmd = casaCmd + "  pwv = 'auto',\n"
            casaCmd = casaCmd + "  subplot = 22,\n"
            casaCmd = casaCmd + "  buildpdf = False,\n"
            casaCmd = casaCmd + "  interactive = "+str(interactive)+",\n"
            casaCmd = casaCmd + "  vm = vm,\n"
            casaCmd = casaCmd + "  figfile = '"+calTableName+".plots/"+calTableName+"')\n"

        if calType in ['G Jones', 'T Jones']:

            calStats = {}
            calStats['GAIN_amp'] = (tb.statistics(column='GAIN', complex_value='amp'))['GAIN']
            calStats['GAIN_phase'] = (tb.statistics(column='GAIN', complex_value='phase'))['GAIN']
            tb.close()

            tb.open(msName+'/ANTENNA')
            antList = tb.getcol('NAME')
            tb.close()

            os.system('mkdir '+calTableName+'.plots')

            if calStats['GAIN_amp']['medabsdevmed'] != 0:
                minAmp = calStats['GAIN_amp']['min']
                maxAmp = calStats['GAIN_amp']['max']
                for i in antList:
                    plotcal(caltable=calTableName, xaxis='time', yaxis='amp', antenna=i, iteration='antenna,spw', subplot=221, plotrange=[0, 0, minAmp, maxAmp], figfile=calTableName+'.plots/'+calTableName+'.amp.'+i+'.png')
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, q to quit.")
                        if userRawInput.lower() == 'q': break
            if calStats['GAIN_phase']['medabsdevmed'] != 0:
                minPhase = math.degrees(calStats['GAIN_phase']['min'])
                maxPhase = math.degrees(calStats['GAIN_phase']['max'])
                for i in antList:
                    plotcal(caltable=calTableName, xaxis='time', yaxis='phase', antenna=i, iteration='antenna,spw', subplot=221, plotrange=[0, 0, minPhase, maxPhase], figfile=calTableName+'.plots/'+calTableName+'.phase.'+i+'.png')
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, q to quit.")
                        if userRawInput.lower() == 'q': break

        return casaCmd

    def getFieldsForFixPlanets(self, msName):

        if getCasaVersion() < '4.5':

            tb.open(msName+'/FIELD')
            phaseDir = tb.getcol('PHASE_DIR')
            # The following 'if/else' block will be needed to prevent fixplanets from running when not necessary.
            if ('EPHEMERIS_ID' in tb.colnames()):
                ephemerisID = tb.getcol('EPHEMERIS_ID')
            else:
                ephemerisID = -np.ones(len(phaseDir))
            tb.close()

            fieldIds = []
            for i in range(len(phaseDir[0][0])):
                if phaseDir[0][0][i] == 0 and phaseDir[1][0][i] == 0:
                    # The following 'if' statement will prevent fixplanets from running when not necessary.
                    # once it has been proven to work (i.e., CAS-7821, 7630 fixed)
                    if (getCasaVersion() < '4.5' or ephemerisID[i] < 0):
                        fieldIds.append(i)

        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(msName)

            fieldIds = []

            for i in range(mymsmd.nfields()):

                phaseCenter = mymsmd.phasecenter(i)
                if phaseCenter['m0']['value'] == 0 and phaseCenter['m1']['value'] == 0:
                    fieldIds.append(i)

            mymsmd.close()

        return fieldIds

    def runFixPlanets(self, msName):

        fieldIds = self.getFieldsForFixPlanets(msName)

        if len(fieldIds) != 0:

            #casaCmd = 'print "# Running fixplanets on fields with 0,0 coordinates."\n\n'
            casaCmd = ''

            tb.open(msName+'/FIELD')
            fieldNames = tb.getcol('NAME')
            tb.close()

            fieldNames = ['%s' %fieldNames[i] for i in fieldIds]
            fieldNames = ','.join(fieldNames)
            fieldIds = ['%s' %i for i in fieldIds]
            fieldIds = ','.join(fieldIds)

            casaCmd = casaCmd + "fixplanets(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "  field = '"+fieldIds+"', # "+fieldNames+"\n"
            casaCmd = casaCmd + "  fixuvw = True)\n"

            return casaCmd

    def applyAprioriCalTables(self, msName, tsys='', wvr='', antpos='', tsysmap='', tsysChanTol='', tsysPerField=False):

        #casaCmd = 'print "# Application of the WVR, Tsys and antpos cal tables."'
        casaCmd = ''

        if tsys=='' and wvr=='' and antpos=='': sys.exit('ERROR: No cal table specified.')

        gainTable = []
        gainTable.append(tsys)
        gainTable.append(wvr)
        gainTable.append(antpos)
        gainTable = ['%s' %i for i in gainTable if i != '']

        spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
        spwIds = sorted(spwInfo.keys())
        spwIds1 = ','.join(['%s' %i for i in spwIds])

        if tsys=='':

            casaCmd = casaCmd + "\n\napplycal(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
            casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
            if re.search('^3.3', getCasaVersion()) == None:
                casaCmd = casaCmd + "  interp = 'linear,linear',\n"
            else:
                casaCmd = casaCmd + "  interp = 'linear',\n"
            if getCasaVersion() <= '4.2.2':
                casaCmd = casaCmd + "  calwt = False,\n"
            else:
                casaCmd = casaCmd + "  calwt = True,\n"
            casaCmd = casaCmd + "  flagbackup = False)\n"

        else:

            if re.search('^3.3', getCasaVersion()) == None:
                if tsysmap == '':

                    if tsysPerField == True:

                        casaCmd = casaCmd + "\n\nfrom almahelpers_localcopy import tsysspwmap\n"

                        if tsysChanTol == '':
                            casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+tsys+"', perField=True)\n\n"
                        else:
                            tsysChanTol = int(tsysChanTol)
                            casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+tsys+"', tsysChanTol = "+str(tsysChanTol)+", perField=True)\n\n"

                    else:

                        casaCmd = casaCmd + "\n\nfrom recipes.almahelpers import tsysspwmap\n"

                        if tsysChanTol == '':
                            casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+tsys+"')\n\n"
                        else:
                            tsysChanTol = int(tsysChanTol)
                            casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+tsys+"', tsysChanTol = "+str(tsysChanTol)+")\n\n"

                else:
                    casaCmd = casaCmd + "\n\ntsysmap = "+str(tsysmap)+"\n\n"

            tb.open(msName+'/FIELD')
            sourceIds = tb.getcol('SOURCE_ID')
            sourceNames = tb.getcol('NAME')
            tb.close()

            sourceIds1 = sorted(dict.fromkeys(sourceIds).keys())

            phaseCal = self.getPhaseCal(msName)

#            if os.path.exists(tsys) == True:
#                  tb.open(tsys)
#                  fieldIds = sorted(dict.fromkeys(tb.getcol('FIELD_ID')).keys())
#                  tb.close()
#            else:
#                  intentSources = self.getIntentsAndSourceNames(msName)
#                  fieldIds = intentSources['CALIBRATE_ATMOSPHERE']['id']

            intentSources = self.getIntentsAndSourceNames(msName)
            fieldIds = intentSources['CALIBRATE_ATMOSPHERE']['id']

            for i in sourceIds1:

                fieldIds1 = (np.where(sourceIds == i))[0]
                sourceName = sourceNames[fieldIds1[0]]

                if getCasaVersion() >= casaVersionWithMSMD and tsys != '':

                    spwIds2 = []
                    sourceIntents = []
                    mymsmd = msmdtool()
                    mymsmd.open(msName)
                    for j in fieldIds1:
                        for k in mymsmd.spwsforfield(j):
                            spwIds2.append(k)
                        sourceIntents.append(mymsmd.intentsforfield(j))
                    mymsmd.close()

                    spwIds2 = np.unique(spwIds2)
                    spwIds1 = ','.join(['%s' %j for j in spwIds if j in spwIds2])

                    sourceIntents = np.unique(np.hstack(np.array(sourceIntents))).tolist()

                    found = 0

                    for j in range(len(sourceIntents)):
                        if re.search('CALIBRATE_ATMOSPHERE#[A-Z_]|CALIBRATE_WVR#[A-Z_]', sourceIntents[j]) == None:
                            found = 1
                            break

                    if found == 0: continue

                if len(fieldIds1) > 1:
                    j0 = 0
                    fieldIds2 = str(fieldIds1[j0])
                    for j in range(len(fieldIds1)-1):
                        if fieldIds1[j+1] == fieldIds1[j]+1: continue
                        fieldIds2 = fieldIds2 + '~' + str(fieldIds1[j])
                        j0 = j+1
                        fieldIds2 = fieldIds2 + ',' + str(fieldIds1[j0])
                    fieldIds2 = fieldIds2 + '~' + str(fieldIds1[j+1])
                else:
                    fieldIds2 = str(fieldIds1[0])

                fieldIds3 = [j for j in fieldIds1 if j in fieldIds]

#                 if len(fieldIds3) > 1: sys.exit('ERROR: Too many Tsys fields per source.')
                if len(fieldIds3) > 1:
                    print 'WARNING: Too many Tsys fields per source.'
                    fieldIds3[0] = ','.join(['%d' %j for j in fieldIds3])

                if len(fieldIds3) == 0 or i in intentSources['OBSERVE_CHECK']['sourceid']:
                    if i in intentSources['OBSERVE_TARGET']['sourceid']:

#                         if phaseCal[sourceName]['phaseCalId'] in fieldIds:
#                             fieldIds3 = [phaseCal[sourceName]['phaseCalId']]
#                             casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+phaseCal[sourceName]['phaseCalName']+". This is probably Ok."
#                         else:
# 
#                             found = 0
#                             for j in phaseCal.keys():
#                                 if j == sourceName: continue
#                                 if phaseCal[j]['phaseCalId'] == phaseCal[sourceName]['phaseCalId']:
#                                     sourceIds2 = np.unique(phaseCal[j]['sciSourceIds'])
#                                     if len(sourceIds2) != 1: sys.exit('ERROR')
#                                     fieldIds3 = []
#                                     for k in range(len(intentSources['CALIBRATE_ATMOSPHERE']['sourceid'])):
#                                         if intentSources['CALIBRATE_ATMOSPHERE']['sourceid'][k] == sourceIds2:
#                                             fieldIds3.append(intentSources['CALIBRATE_ATMOSPHERE']['id'][k])
#                                     if (len(fieldIds3) > 0):
#                                         fieldIds3[0] = ','.join(['%d' %k for k in fieldIds3])
#                                         found = 1
#                                         break
#                             if found == 1:
#                                 casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+j+". This is probably Ok."
#                             else:
#                                 casaCmd = casaCmd + "\n\n# Warning: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. This is a science target, so this is probably *NOT* Ok."
#                                 continue

                        found = 0
                        for j in phaseCal.keys():
                            if j == sourceName: continue
                            if phaseCal[j]['phaseCalId'] == phaseCal[sourceName]['phaseCalId']:
                                sourceIds2 = np.unique(phaseCal[j]['sciSourceIds'])
                                if len(sourceIds2) != 1: sys.exit('ERROR')
                                fieldIds3 = []
                                for k in range(len(intentSources['CALIBRATE_ATMOSPHERE']['sourceid'])):
                                    if intentSources['CALIBRATE_ATMOSPHERE']['sourceid'][k] == sourceIds2:
                                        fieldIds3.append(intentSources['CALIBRATE_ATMOSPHERE']['id'][k])
                                if (len(fieldIds3) > 0):
                                    fieldIds3[0] = ','.join(['%d' %k for k in fieldIds3])
                                    found = 1
                                    break
                        if found == 1:
                            casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+j+". This is probably Ok."
                        else:

                            if phaseCal[sourceName]['phaseCalId'] in fieldIds:
                                fieldIds3 = [phaseCal[sourceName]['phaseCalId']]
                                casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+phaseCal[sourceName]['phaseCalName']+". This is probably Ok."
                            else:
                                casaCmd = casaCmd + "\n\n# Warning: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. This is a science target, so this is probably *NOT* Ok."
                                continue

                    elif i in intentSources['CALIBRATE_PHASE']['sourceid']:
#                         if len(fieldIds1) != 1: sys.exit('ERROR')
#                         found = 0
#                         for j in sorted(phaseCal.keys()):
#                             if phaseCal[j]['phaseCalId'] == fieldIds1[0]:
#                                 found = 1
#                                 break
#                         if found == 1:
#                             sourceIds2 = np.unique(phaseCal[j]['sciSourceIds'])
#                             if len(sourceIds2) != 1: sys.exit('ERROR')
#                             fieldIds3 = []
#                             for k in range(len(intentSources['CALIBRATE_ATMOSPHERE']['sourceid'])):
#                                 if intentSources['CALIBRATE_ATMOSPHERE']['sourceid'][k] == sourceIds2:
#                                     fieldIds3.append(intentSources['CALIBRATE_ATMOSPHERE']['id'][k])
# #              The following 'if' statement would prevent crash if fieldIds3 == []
#                             if (len(fieldIds3) > 0):
#                                 fieldIds3[0] = ','.join(['%d' %k for k in fieldIds3])
#                             casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+j+". This is probably Ok2."
#                         else:
#                             casaCmd = casaCmd + "\n\n# Warning: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. This is a phase calibrator, so this is probably *NOT* Ok."
#                             continue
                        if len(fieldIds1) != 1: sys.exit('ERROR')
                        found = 0
                        for j in sorted(phaseCal.keys()):
                            if phaseCal[j]['phaseCalId'] == fieldIds1[0]:
                                sourceIds2 = np.unique(phaseCal[j]['sciSourceIds'])
                                if len(sourceIds2) != 1: sys.exit('ERROR')
                                fieldIds3 = []
                                for k in range(len(intentSources['CALIBRATE_ATMOSPHERE']['sourceid'])):
                                    if intentSources['CALIBRATE_ATMOSPHERE']['sourceid'][k] == sourceIds2:
                                        fieldIds3.append(intentSources['CALIBRATE_ATMOSPHERE']['id'][k])
                                if (len(fieldIds3) > 0):
                                    fieldIds3[0] = ','.join(['%d' %k for k in fieldIds3])
                                    found = 1
                                    break
                        if found == 1:
                            casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+j+". This is probably Ok."
                        else:
                            casaCmd = casaCmd + "\n\n# Warning: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. This is a phase calibrator, so this is probably *NOT* Ok."
                            continue
                    elif i in intentSources['OBSERVE_CHECK']['sourceid']:
                        if len(fieldIds1) != 1: sys.exit('ERROR')
                        found = 0
                        for j in phaseCal.keys():
                            if j == sourceName: continue
                            if phaseCal[j]['phaseCalId'] == phaseCal[sourceName]['phaseCalId']:
                                found = 1
                                break
                        if found == 1:
                            sourceIds2 = np.unique(phaseCal[j]['sciSourceIds'])
                            if len(sourceIds2) != 1: sys.exit('ERROR')
                            fieldIds3 = []
                            for k in range(len(intentSources['CALIBRATE_ATMOSPHERE']['sourceid'])):
                                if intentSources['CALIBRATE_ATMOSPHERE']['sourceid'][k] == sourceIds2:
                                    fieldIds3.append(intentSources['CALIBRATE_ATMOSPHERE']['id'][k])
#              The following 'if' statement would prevent crash if fieldIds3 == []
                            if (len(fieldIds3) > 0):
                                fieldIds3[0] = ','.join(['%d' %k for k in fieldIds3])
                            casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on "+j+". This is probably Ok."
                        else:
                            casaCmd = casaCmd + "\n\n# Warning: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. This is a check source, so this is probably *NOT* Ok."
                            continue
                    else:

                        found = 0

                        if len(fieldIds1) == 1:
                            fieldIds1 = fieldIds1[0]
                            if type(phaseCal) is not NoneType:
                                for j in phaseCal:
                                    if phaseCal[j]['phaseCalId'] == fieldIds1:
                                        sciSourceIds1 = phaseCal[j]['sciSourceIds']
                                        sciSourceIds1 = sorted(dict.fromkeys(sciSourceIds1).keys())
                                        if len(sciSourceIds1) == 1:
                                            sciSourceIds1 = sciSourceIds1[0]
                                            ij = np.where(np.array(intentSources['CALIBRATE_ATMOSPHERE']['sourceid']) == sciSourceIds1)[0]
                                            if len(ij) == 1:
                                                ij = ij[0]
                                                fieldIds3 = [intentSources['CALIBRATE_ATMOSPHERE']['id'][ij]]
                                                found = 1
                                                break

                        if found == 0:

                            if getCasaVersion() >= casaVersionWithMSMD and tsys != '':

                                fieldIds4 = (np.where(sourceIds == i))[0]
                                mymsmd = msmdtool()
                                mymsmd.open(msName)
                                fieldIds5 = mymsmd.fieldsforname(sourceName)

                                fieldIds5 = [j for j in fieldIds5 if j not in fieldIds4]

                                fieldIds6 = []
                                for j in fieldIds5:
                                    fieldIntents = mymsmd.intentsforfield(j)
                                    if 'CALIBRATE_ATMOSPHERE#ON_SOURCE' in fieldIntents and 'CALIBRATE_ATMOSPHERE#OFF_SOURCE' in fieldIntents:
                                        fieldIds6.append(j)

                                mymsmd.close()

                                if len(fieldIds6) != 0:

                                    fieldIds3 = [','.join(['%d' %k for k in fieldIds6])]
                                    casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, so I used the one made on another source with the same name. This is probably Ok."
                                    found = 1

                            if found == 0:

                                casaCmd = casaCmd + "\n\n# Note: "+sourceName+" didn't have any Tsys measurement, and I couldn't find any close measurement. But this is not a science target, so this is probably Ok."
                                continue

                gainField = []
                for j in range(len(gainTable)): gainField.append('')
#              The following 'if' statement would prevent crash if fieldIds3 == []
                if (len(fieldIds3) > 0):
                    gainField[0] = str(fieldIds3[0])
                else:
                    gainField[0] = intentSources['CALIBRATE_ATMOSPHERE']['idstring'][0]

                gainSpwMap = []
                for j in range(len(gainTable)): gainSpwMap.append("[]")

                if tsysPerField == True:
                    gainSpwMap[0] = "tsysmap['"+str(gainField[0])+"']"
                else:
                    gainSpwMap[0] = 'tsysmap'

                gainSpwMap = ','.join(gainSpwMap)

                casaCmd = casaCmd + "\n\napplycal(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  field = '"+fieldIds2+"',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
                casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
                casaCmd = casaCmd + "  gainfield = "+str(gainField)+",\n"
                if re.search('^3.3', getCasaVersion()) == None:
                    casaCmd = casaCmd + "  interp = 'linear,linear',\n"
                else:
                    casaCmd = casaCmd + "  interp = 'linear',\n"
                if re.search('^3.3', getCasaVersion()) == None: casaCmd = casaCmd + "  spwmap = ["+gainSpwMap+"],\n"
                casaCmd = casaCmd + "  calwt = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

            casaCmd = casaCmd + "\n\nif applyonly != True: es.getCalWeightStats('"+msName+"') \n"

            #casaCmd = casaCmd + "plotms(vis = '"+msName+"',\n"
            #casaCmd = casaCmd + "    xaxis = 'time',\n"
            #casaCmd = casaCmd + "    yaxis = 'wt',\n"
            #casaCmd = casaCmd + "    spw = '"+spwIds1+"',\n"
            #casaCmd = casaCmd + "    antenna = '*&*',\n"
            #casaCmd = casaCmd + "    coloraxis = 'field',\n"
            #casaCmd = casaCmd + "    plotfile = '"+msName+".weights.png')\n"

        return casaCmd

    def getIntentsAndSourceNames(self, msName):

        intentsToSearch = ['CALIBRATE_POINTING', 'CALIBRATE_FOCUS', 'CALIBRATE_BANDPASS', 'CALIBRATE_FLUX', 'CALIBRATE_AMPLI', 'CALIBRATE_PHASE', 'OBSERVE_TARGET', 'CALIBRATE_ATMOSPHERE', 'OBSERVE_CHECK', 'CALIBRATE_DIFFGAIN']

        tb.open(msName+'/STATE')
        obsModes = tb.getcol('OBS_MODE')
        tb.close()

        tb.open(msName+'/FIELD')
        fieldNames = tb.getcol('NAME')
        sourceIds = tb.getcol('SOURCE_ID')
        tb.close()

        tb.open(msName+'/DATA_DESCRIPTION')
        spwIds = tb.getcol('SPECTRAL_WINDOW_ID').tolist()
        tb.close()

        intentSources = {}

        for i in range(len(intentsToSearch)):

            obsModes1 = []
            for j in range(len(obsModes)):
                if re.search(intentsToSearch[i], obsModes[j]) is not None:
                    obsModes1.append(j)

            obsModes1 = sorted(dict.fromkeys(obsModes1).keys())

            intentSources[intentsToSearch[i]] = {}

            if len(obsModes1) == 0:

                intentSources[intentsToSearch[i]]['id'] = ['']
                intentSources[intentsToSearch[i]]['idstring'] = ['']
                intentSources[intentsToSearch[i]]['name'] = ['']
                intentSources[intentsToSearch[i]]['spw'] = ['']
                intentSources[intentsToSearch[i]]['sourceid'] = ['']

            else:

                tb.open(msName)

                fieldIds = []
                dataDescIds = []
                for j in obsModes1:
                    tb1 = tb.query('STATE_ID == '+str(j))
                    fieldIds1 = sorted(dict.fromkeys(tb1.getcol('FIELD_ID')).keys())
                    fieldIds.extend(fieldIds1)
                    dataDescIds1 = sorted(dict.fromkeys(tb1.getcol('DATA_DESC_ID')).keys())
                    dataDescIds.extend(dataDescIds1)
                    tb1.close() # added on July 28, 2014

                tb.close()

                fieldIds = sorted(dict.fromkeys(fieldIds).keys())
                fieldNames1 = ['%s' %fieldNames[j] for j in fieldIds]
                #fieldNames1 = sorted(dict.fromkeys(fieldNames1).keys())
                dataDescIds = sorted(dict.fromkeys(dataDescIds).keys())
                sourceIds1 = [sourceIds[j] for j in fieldIds]

                if len(fieldIds) != 0:
                    intentSources[intentsToSearch[i]]['id'] = fieldIds
                    fieldIdStrings = []
                    for f in fieldIds:
                        fieldIdStrings.append(str(f))
                    intentSources[intentsToSearch[i]]['idstring'] = fieldIdStrings
                    intentSources[intentsToSearch[i]]['name'] = fieldNames1
                    intentSources[intentsToSearch[i]]['spw'] = [spwIds[k] for k in dataDescIds]
                    intentSources[intentsToSearch[i]]['sourceid'] = sourceIds1
                else:
                    intentSources[intentsToSearch[i]]['id'] = ['']
                    intentSources[intentsToSearch[i]]['idstring'] = ['']
                    intentSources[intentsToSearch[i]]['name'] = ['']
                    intentSources[intentsToSearch[i]]['spw'] = ['']
                    intentSources[intentsToSearch[i]]['sourceid'] = ['']

        return intentSources

    def listOfIntentsWithSources(self, msName):

        intentSources = self.getIntentsAndSourceNames(msName)

        for i in sorted(intentSources.keys()):
            print '# '+i+': '+','.join(sorted(dict.fromkeys(intentSources[i]['name']).keys()))

    def doBandpassCalibration(self, msName, msName1='', bpassCalId='', chanAvg=1.0, refant='', iHaveSplitMyScienceSpw=False, calTableName=[], lowSNR=False, doplot=True, phaseDiff='', solnorm=True, lbc=False):

        #casaCmd = 'print "# Bandpass calibration."\n\n'
        casaCmd = ''

        if msName1 == '': msName1 = msName
        if refant == '': sys.exit('ERROR: No reference antenna specified.')
        if chanAvg > 1: sys.exit('ERROR: The channel averaging bandwidth must be specified as a fraction of the total bandwidth.')
        if lowSNR == True: chanAvg = 1.0

        if phaseDiff == True and solnorm == True:
            print 'WARNING: Forcing solnorm to False.'
            solnorm = False

        tb.open(msName+'/FIELD')
        fieldNames = tb.getcol('NAME')
        tb.close()

        intentSources = self.getIntentsAndSourceNames(msName)
        ampCalId = intentSources['CALIBRATE_AMPLI']['id'] + intentSources['CALIBRATE_FLUX']['id']
        ampCalId = np.unique([i for i in ampCalId if i != '']).tolist()

        if len(ampCalId) > 1:
            casaCmd = casaCmd + "# Note: there are more than one flux calibrator, I'm picking the first one: "+fieldNames[ampCalId[0]]+".\n"
            ampCalId = ampCalId[0]

        if bpassCalId == '':

#             intentSources = self.getIntentsAndSourceNames(msName)
            bpassCalId = intentSources['CALIBRATE_BANDPASS']['id']

            if bpassCalId[0] != '':

                if len(bpassCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one bandpass calibrator, I'm picking the first one: "+fieldNames[bpassCalId[0]]+".\n"
                bpassCalId = bpassCalId[0]

            else:

                casaCmd = casaCmd + "# Note: there are no bandpass calibrator, I'm picking a phase calibrator.\n"
                phaseCalId = intentSources['CALIBRATE_PHASE']['id']
#                 ampCalId = intentSources['CALIBRATE_AMPLI']['id'] + intentSources['CALIBRATE_FLUX']['id']
#                 ampCalId = [i for i in ampCalId if i != '']
                phaseOnlyCalId = [i for i in phaseCalId if i not in ampCalId]
                if len(phaseOnlyCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one phase calibrator, I'm picking the first one: "+fieldNames[phaseOnlyCalId[0]]+".\n"
                bpassCalId = phaseOnlyCalId[0]

        spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
        spwIds = sorted(spwInfo.keys())

#        sciNumChans = []
#        for i in spwInfo: sciNumChans.append(spwInfo[i]['numChans'])
#        sciNumChans = sorted(dict.fromkeys(sciNumChans).keys())
#        if len(sciNumChans) != 1: sys.exit('ERROR: Configuration not supported.')
#        sciNumChans = sciNumChans[0]

        sciNumChans = []
        for i in spwIds: sciNumChans.append(spwInfo[i]['numChans'])
        if len(dict.fromkeys(sciNumChans).keys()) != 1:
            print 'WARNING: This seems to be a mixed-mode dataset, the script generator has been updated, but for some time, please check carefully the script.'

##

        spwInfo1 = self.getSpwInfo(msName)
        spwIds1 = sorted(spwInfo1.keys())

        spwInfo2 = self.getSpwInfo(msName, intent = 'CALIBRATE_PHASE')
        spwIds2 = sorted(spwInfo2.keys())

        if spwIds1 != spwIds2:
            print 'WARNING: THIS SEEMS TO BE A BW-SWITCHING OR B2B-TRANSFER OBSERVATION. THE FORMER IS SUPPORTED, THE LATTER NOT ENTIRELY YET.'
            if getCasaVersion() < '4.2.0': sys.exit('ERROR: PLEASE USE CASA 4.2 OR LATER')
            print 'WARNING: Forcing solnorm to False.'
            solnorm = False
            phaseDiff = True

##

        spwSpec = ''
        for i in range(len(spwIds)):
            if spwSpec != '': spwSpec = spwSpec+','
            startChan = int((spwInfo[spwIds[i]]['numChans'] / 2.) * (1-chanAvg))
            endChan = int((spwInfo[spwIds[i]]['numChans'] / 2.) * (1+chanAvg))-1
            if iHaveSplitMyScienceSpw == True:
                spwSpec = spwSpec+str(i)
            else:
                spwSpec = spwSpec+str(spwIds[i])
            spwSpec = spwSpec+':'+str(startChan)+'~'+str(endChan)

        bpassCalScanList = []
        if getCasaVersion() >= casaVersionWithMSMD:
            mymsmd = msmdtool()
            mymsmd.open(msName)
            bpassCalScanList = mymsmd.scansforfield(bpassCalId)
            if getCasaVersion() >= '4.2.0':
                atmCalScanList = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
            else:
                atmCalScanList = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
                if (atmCalScanList == []):
                    atmCalScanList = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#HOT')
            bpassCalScanList = [str(i) for i in bpassCalScanList if i not in atmCalScanList]
            mymsmd.close()
        bpassCalScanList = ','.join(bpassCalScanList)

        calTableName1 = msName1+'.bandpass'
        casaCmd = casaCmd + "os.system('rm -rf %s.ap_pre_bandpass') \n"%(msName1) # Added by CLB
        casaCmd = casaCmd + "\ngaincal(vis = '"+msName1+"',\n"
        casaCmd = casaCmd + "  caltable = '"+msName1+".ap_pre_bandpass',\n"
        casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
        casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
        if bpassCalScanList != '': casaCmd = casaCmd + "  scan = '"+bpassCalScanList+"',\n"
        casaCmd = casaCmd + "  solint = 'int',\n"
        casaCmd = casaCmd + "  refant = '"+refant+"',\n"
        casaCmd = casaCmd + "  calmode = 'p')\n"
        if doplot == True:
            casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+msName1+".ap_pre_bandpass', msName='"+msName1+"', interactive=False) \n\n"
        casaCmd = casaCmd + "os.system('rm -rf %s.bandpass') \n"%(msName1) # Added by CLB
        casaCmd = casaCmd + "bandpass(vis = '"+msName1+"',\n"
        casaCmd = casaCmd + "  caltable = '"+calTableName1+"',\n"
        casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
        if bpassCalScanList != '': casaCmd = casaCmd + "  scan = '"+bpassCalScanList+"',\n"
        casaCmd = casaCmd + "  solint = 'inf',\n"
        casaCmd = casaCmd + "  combine = 'scan',\n"
        casaCmd = casaCmd + "  refant = '"+refant+"',\n"
#         casaCmd = casaCmd + "  solnorm = True,\n"
        casaCmd = casaCmd + "  solnorm = "+str(solnorm)+",\n"
        casaCmd = casaCmd + "  bandtype = 'B',\n"
        casaCmd = casaCmd + "  gaintable = '"+msName1+".ap_pre_bandpass')\n"

        minSciNumChans = min(sciNumChans)

        if minSciNumChans > 256:
            if re.search('^3.3', getCasaVersion()) == None:
                casaCmd = casaCmd + "\nos.system('rm -rf %s.bandpass_smooth20ch') \n"%(msName1)
                casaCmd = casaCmd + "\nbandpass(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  caltable = '"+calTableName1+'_smooth20ch'+"',\n"
                casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
                if bpassCalScanList != '': casaCmd = casaCmd + "  scan = '"+bpassCalScanList+"',\n"
                if lbc == True:
                    casaCmd = casaCmd + "  solint = 'inf,8MHz',\n"
                else:
                    casaCmd = casaCmd + "  solint = 'inf,20ch',\n"
                casaCmd = casaCmd + "  combine = 'scan',\n"
                casaCmd = casaCmd + "  refant = '"+refant+"',\n"
#                 casaCmd = casaCmd + "  solnorm = True,\n"
                casaCmd = casaCmd + "  solnorm = "+str(solnorm)+",\n"
                casaCmd = casaCmd + "  bandtype = 'B',\n"
                casaCmd = casaCmd + "  gaintable = '"+msName1+".ap_pre_bandpass')\n"
                if doplot == True:
                    casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+'_smooth20ch'+"', msName='"+msName1+"', interactive=False) \n"
            else:
                casaCmd = casaCmd + "\nos.system('rm -rf %s.bandpass_smooth20flat_ri') \n"%(msName1) # Added by CLB
                casaCmd = casaCmd + "\nif applyonly != True: aU.smoothbandpass('"+calTableName1+"') \n"

        if doplot == True:
            casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+"', msName='"+msName1+"', interactive=False) \n"

        if minSciNumChans > 256:
            if re.search('^3.3', getCasaVersion()) == None:
                calTableName1 = calTableName1+'_smooth20ch'
            else:
                calTableName1 = calTableName1+'_smooth20flat_ri'
        calTableName.append(calTableName1)

        if phaseDiff == True:
            if bpassCalId != ampCalId:

                casaCmd = casaCmd + "\n\n"

                fluxscaleDictName = []
                casaCmd = casaCmd + self.doGainCalibration(msName, msName1=msName1, refant=refant, bandpass=calTableName1, calmode2='a', phaseDiff=False, fluxscaleDictName=fluxscaleDictName, iHaveSplitMyScienceSpw=iHaveSplitMyScienceSpw)

                casaCmd = casaCmd + "\nsetjy(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
                casaCmd = casaCmd + "  standard = 'manual',\n"
                casaCmd = casaCmd + "  spw = '',\n"
                casaCmd = casaCmd + "  fluxdensity = "+fluxscaleDictName[0]+"['"+str(bpassCalId)+"']['fitFluxd'],\n"
                casaCmd = casaCmd + "  spix = "+fluxscaleDictName[0]+"['"+str(bpassCalId)+"']['spidx'][1],\n"  # Added trailing [1] - T. Hunter 2014-08-11
                casaCmd = casaCmd + "  reffreq = '%fGHz'%(1e-9*"+fluxscaleDictName[0]+"['"+str(bpassCalId)+"']['fitRefFreq']))\n\n" # T. Hunter 2014-08-11

                calTableName1 = msName1+'.bandpass2'
                casaCmd = casaCmd + "os.system('rm -rf %s.bandpass2') \n"%(msName1) # Added by CLB
                casaCmd = casaCmd + "bandpass(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  caltable = '"+calTableName1+"',\n"
                casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
                if bpassCalScanList != '': casaCmd = casaCmd + "  scan = '"+bpassCalScanList+"',\n"
                casaCmd = casaCmd + "  solint = 'inf',\n"
                casaCmd = casaCmd + "  combine = 'scan',\n"
                casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                casaCmd = casaCmd + "  solnorm = False,\n"
                casaCmd = casaCmd + "  bandtype = 'B',\n"
                casaCmd = casaCmd + "  gaintable = '"+msName1+".ap_pre_bandpass')\n"

                minSciNumChans = min(sciNumChans)

                if minSciNumChans > 256:
                    if re.search('^3.3', getCasaVersion()) == None:
                        casaCmd = casaCmd + "\nos.system('rm -rf %s.bandpass2_smooth20ch') \n"%(msName1)
                        casaCmd = casaCmd + "\nbandpass(vis = '"+msName1+"',\n"
                        casaCmd = casaCmd + "  caltable = '"+calTableName1+'_smooth20ch'+"',\n"
                        casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[int(bpassCalId)]+"\n"
                        if bpassCalScanList != '': casaCmd = casaCmd + "  scan = '"+bpassCalScanList+"',\n"
                        casaCmd = casaCmd + "  solint = 'inf,20ch',\n"
                        casaCmd = casaCmd + "  combine = 'scan',\n"
                        casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                        casaCmd = casaCmd + "  solnorm = False,\n"
                        casaCmd = casaCmd + "  bandtype = 'B',\n"
                        casaCmd = casaCmd + "  gaintable = '"+msName1+".ap_pre_bandpass')\n"
                        if doplot == True:
                            casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+'_smooth20ch'+"', msName='"+msName1+"', interactive=False) \n"
                    else:
                        casaCmd = casaCmd + "\nos.system('rm -rf %s.bandpass2_smooth20flat_ri') \n"%(msName1) # Added by CLB
                        casaCmd = casaCmd + "\nif applyonly != True: aU.smoothbandpass('"+calTableName1+"') \n"

                if doplot == True:
                    casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+"', msName='"+msName1+"', interactive=False) \n"

                if minSciNumChans > 256:
                    if re.search('^3.3', getCasaVersion()) == None:
                        calTableName1 = calTableName1+'_smooth20ch'
                    else:
                        calTableName1 = calTableName1+'_smooth20flat_ri'
    #             calTableName = []
    #             calTableName.append(calTableName1)
                calTableName[0] = calTableName1

        return casaCmd

    def doAprioriFlagging(self, msName, flagAutoCorr=True, flagCalIntents=True):

        #casaCmd = 'print "# A priori flagging."\n\n'
        casaCmd = ''

        if flagCalIntents == True:

            intentsToFlag = ['POINTING', 'FOCUS', 'SIDEBAND_RATIO', 'ATMOSPHERE']

            vm = ValueMapping(msName)
            fullIntentList = vm.uniqueIntents

            scanIntentList = []
            for i in intentsToFlag:
                for j in fullIntentList:
                    if re.search(i, j) is not None:
                        scanIntentList.append('*'+i+'*')
                        break

            scanIntentList = ','.join(scanIntentList)

        if flagAutoCorr == True:

            tb.open(msName+'/DATA_DESCRIPTION')
            spwIds = tb.getcol('SPECTRAL_WINDOW_ID')
            tb.close()

            tb.open(msName+'/PROCESSOR')
            procType = tb.getcol('TYPE')
            tb.close()

            procType1 = np.where(procType == 'RADIOMETER')[0]

            spwIds1 = []

            tb.open(msName)

            for i in procType1:
                tb1 = tb.query('PROCESSOR_ID == '+str(i))
                dataDescIds1 = tb1.getcol('DATA_DESC_ID')
                dataDescIds1 = np.unique(dataDescIds1)
                for j in dataDescIds1:
                    spwIds1.append(spwIds[j])
                tb1.close() # added on July 28, 2014

            tb.close()

            spwIds1 = [i for i in range(len(spwIds)) if i not in spwIds1]

            if len(spwIds1) > 1:
                j0 = 0
                spwIds2 = str(spwIds1[j0])
                for j in range(len(spwIds1)-1):
                    if spwIds1[j+1] == spwIds1[j]+1: continue
                    spwIds2 = spwIds2 + '~' + str(spwIds1[j])
                    j0 = j+1
                    spwIds2 = spwIds2 + ',' + str(spwIds1[j0])
                spwIds2 = spwIds2 + '~' + str(spwIds1[j+1])
            else:
                spwIds2 = str(spwIds1[0])

        if flagAutoCorr == True:
            if re.search('^3.3', getCasaVersion()) is not None:
                casaCmd = casaCmd + "flagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manualflag',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds2+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
            elif getCasaVersion() >= '4.1.0':
                casaCmd = casaCmd + "flagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds2+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
            else:
                casaCmd = casaCmd + "tflagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds2+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        if flagCalIntents == True:

            if re.search('^3.3', getCasaVersion()) is not None:
                casaCmd = casaCmd + "flagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manualflag',\n"
                casaCmd = casaCmd + "  intent = '"+scanIntentList+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n"
            elif getCasaVersion() >= '4.1.0':
                casaCmd = casaCmd + "flagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  intent = '"+scanIntentList+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n"
            else:
                casaCmd = casaCmd + "tflagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  intent = '"+scanIntentList+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n"

        tb.open(msName)
        tableNames = tb.keywordnames()
        tb.close()

        if 'FLAG_CMD' in tableNames:

            tb.open(msName+'/FLAG_CMD')
            nFlagRows = tb.nrows()
            tb.close()

            if nFlagRows != 0:

                if re.search('^3.3', getCasaVersion()) == None:
                    casaCmd = casaCmd + "\nflagcmd(vis = '"+msName+"',\n"
                    casaCmd = casaCmd + "  inpmode = 'table',\n"
                    casaCmd = casaCmd + "  useapplied = True,\n"
#                     casaCmd = casaCmd + "  action = 'plot')\n\n"
                    casaCmd = casaCmd + "  action = 'plot',\n"
                    casaCmd = casaCmd + "  plotfile = '"+msName+".flagcmd.png')\n\n"
                    casaCmd = casaCmd + "flagcmd(vis = '"+msName+"',\n"
                    casaCmd = casaCmd + "  inpmode = 'table',\n"
                    casaCmd = casaCmd + "  useapplied = True,\n"
                    casaCmd = casaCmd + "  action = 'apply')\n"
                else:
                    casaCmd = casaCmd + "\nflagcmd(vis = '"+msName+"',\n"
                    casaCmd = casaCmd + "  flagmode = 'table',\n"
                    casaCmd = casaCmd + "  optype = 'plot')\n\n"
                    casaCmd = casaCmd + "flagcmd(vis = '"+msName+"',\n"
                    casaCmd = casaCmd + "  flagmode = 'table',\n"
                    casaCmd = casaCmd + "  optype = 'apply')\n"

        return casaCmd

    def doInitialFlagging(self, msName, msName1='', chanEdge=0.0625, thresh=0.2, iHaveSplitMyScienceSpw=False):

        #specLines = {'Neptune': [[340.0, 352.0]], 'Titan': [[229, 232]]}
        #specLines = {'Neptune': [[340.0, 352.0]]}
        specLines = {'Neptune': [[114.00,116.50], [227.00,234.50], [340.00,351.50], [455.00,467.50], [686.00,696.50], [803.00,810.50]], # CO
            'Titan': [[114.93,115.66], [229.51,231.71], [343.86,347.58], [458.34,463.74], [687.83,694.58], [803.55,809.76], # CO
            [110.19,110.21], [220.30,220.50], [330.39,330.78], [440.47,441.10], [660.68,661.46], [770.74,771.63], [880.83,881.72], # 13CO
            [88.46,88.80], [176.75,177.78], [264.99,266.78], [353.33,355.68], [441.79,444.47], [618.52,622.09], [707.09,710.66], [795.65,799.22], [883.92,887.75], # HCN
            [86.05,86.06], [172.07,172.14], [258.07,258.24], [430.07,430.40], [602.02,602.53], [773.97,774.55], [859.93,860.52], # HC15N
            [86.34,86.34], [172.65,172.71], [258.94,259.09], [431.49,431.83], [604.04,604.49], [776.56,777.08], [862.81,863.33] # H13CN
            ]}

        if msName1 == '': msName1 = msName

        #casaCmd = 'print "# Initial flagging."\n\n'
        casaCmd = ''

        if re.search('^3.3', getCasaVersion()) is not None or getCasaVersion() >= '4.1.0':
            casaCmd = casaCmd + "# Flagging shadowed data\n\n"
            casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
            casaCmd = casaCmd + "  mode = 'shadow',\n"
            casaCmd = casaCmd + "  flagbackup = False)\n\n"
        else:
            casaCmd = casaCmd + "# Flagging shadowed data\n\n"
            casaCmd = casaCmd + "tflagdata(vis = '"+msName1+"',\n"
            casaCmd = casaCmd + "  mode = 'shadow',\n"
            casaCmd = casaCmd + "  flagbackup = False)\n\n"

        spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
        spwIds = sorted(spwInfo.keys())
#         if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))

#        sciNumChans = []
#        for i in spwInfo: sciNumChans.append(spwInfo[i]['numChans'])
#        sciNumChans = sorted(dict.fromkeys(sciNumChans).keys())
#        if len(sciNumChans) != 1: sys.exit('ERROR: Configuration not supported.')
#        sciNumChans = sciNumChans[0]
#
#        if sciNumChans <= 256:
#
#            spwSpec = ''
#            for i in spwIds:
#                if spwSpec != '': spwSpec = spwSpec+','
#                spwSpec = spwSpec+str(i)+':0~'+str(long(sciNumChans*chanEdge-1))+';'+str(long(sciNumChans-sciNumChans*chanEdge))+'~'+str(sciNumChans-1)
#
#            if re.search('^3.3', getCasaVersion()) is not None:
#                casaCmd = casaCmd + "# Flagging edge channels\n\n"
#                casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
#                casaCmd = casaCmd + "  mode = 'manualflag',\n"
#                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
#                casaCmd = casaCmd + "  flagbackup = False)\n\n"
#            else:
#                casaCmd = casaCmd + "# Flagging edge channels\n\n"
#                casaCmd = casaCmd + "tflagdata(vis = '"+msName1+"',\n"
#                casaCmd = casaCmd + "  mode = 'manual',\n"
#                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
#                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        sciNumChans = []
        for i in sorted(spwInfo.keys()): sciNumChans.append(spwInfo[i]['numChans'])
        if len(dict.fromkeys(sciNumChans).keys()) != 1:
            print 'WARNING: This seems to be a mixed-mode dataset, the script generator has been updated, but for some time, please check carefully the script.'

        spwSpec = ''

        if getCasaVersion() >= casaVersionWithMSMD:
            mymsmd = msmdtool()
            mymsmd.open(msName)
            TDMspws = mymsmd.tdmspws()
            mymsmd.close()

            for i in range(len(spwIds)):
                if spwIds[i] in TDMspws:
                    if spwSpec != '': spwSpec = spwSpec+','
                    if iHaveSplitMyScienceSpw == True:
                        spwSpec = spwSpec+str(i)
                    else:
                        spwSpec = spwSpec+str(spwIds[i])
                    spwSpec = spwSpec+':0~'+str(long(sciNumChans[i]*chanEdge-1))+';'+str(long(sciNumChans[i]-sciNumChans[i]*chanEdge))+'~'+str(sciNumChans[i]-1)

        else:

            for i in range(len(spwIds)):
                if sciNumChans[i] <= 256:
                    if spwSpec != '': spwSpec = spwSpec+','
                    if iHaveSplitMyScienceSpw == True:
                        spwSpec = spwSpec+str(i)
                    else:
                        spwSpec = spwSpec+str(spwIds[i])
                    spwSpec = spwSpec+':0~'+str(long(sciNumChans[i]*chanEdge-1))+';'+str(long(sciNumChans[i]-sciNumChans[i]*chanEdge))+'~'+str(sciNumChans[i]-1)

        if spwSpec != '':
            if re.search('^3.3', getCasaVersion()) is not None:
                casaCmd = casaCmd + "# Flagging edge channels\n\n"
                casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  mode = 'manualflag',\n"
                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
            elif getCasaVersion() >= '4.1.0':
                casaCmd = casaCmd + "# Flagging edge channels\n\n"
                casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
            else:
                casaCmd = casaCmd + "# Flagging edge channels\n\n"
                casaCmd = casaCmd + "tflagdata(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        spwInfo1 = self.getSpwInfo(msName, intent='CALIBRATE_AMPLI|CALIBRATE_FLUX')

        if len(spwInfo1) != 0:

            spwIds = sorted(spwInfo1.keys())
#             if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))

            intentSources = self.getIntentsAndSourceNames(msName)
            calFieldIds = intentSources['CALIBRATE_AMPLI']['id'] + intentSources['CALIBRATE_FLUX']['id']
            calFieldIds = [i for i in calFieldIds if i != '']
            calFieldNames = intentSources['CALIBRATE_AMPLI']['name'] + intentSources['CALIBRATE_FLUX']['name']
            calFieldNames = [i for i in calFieldNames if i != '']

            for i in range(len(calFieldIds)):
                if calFieldNames[i] in specLines.keys():
                    for j in specLines[calFieldNames[i]]:
                        for k in range(len(spwIds)):
                            spwId1 = int(sorted(spwInfo1.keys())[k])
                            chanRange = getChanRangeFromFreqRange(vis = msName, spwid = spwId1, minf = j[0]*1.e9, maxf = j[1]*1.e9)
                            if chanRange == [-1, -1]: continue

                            if iHaveSplitMyScienceSpw == True:
                                spwId2 = sorted(spwInfo.keys()).index(spwId1)
                            else:
                                spwId2 = spwId1

                            if (chanRange[1]-chanRange[0]) / (spwInfo[spwId1]['numChans']*1.) > thresh: print '# Warning: more than '+str(thresh*100)+'% of spw '+str(spwId2)+' on '+calFieldNames[i]+' will be flagged due to atmospheric line.'
                            spwSpec = str(spwId2)+':'+str(chanRange[0])+'~'+str(chanRange[1])

                            if re.search('^3.3', getCasaVersion()) is not None:
                                casaCmd = casaCmd + "# Flagging atmospheric line(s)\n\n"
                                casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
                                casaCmd = casaCmd + "  mode = 'manualflag',\n"
                                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                                casaCmd = casaCmd + "  field = '"+str(calFieldIds[i])+"',\n"
                                casaCmd = casaCmd + "  flagbackup = False)\n\n"
                            elif getCasaVersion() >= '4.1.0':
                                casaCmd = casaCmd + "# Flagging atmospheric line(s)\n\n"
                                casaCmd = casaCmd + "flagdata(vis = '"+msName1+"',\n"
                                casaCmd = casaCmd + "  mode = 'manual',\n"
                                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                                casaCmd = casaCmd + "  field = '"+str(calFieldIds[i])+"',\n"
                                casaCmd = casaCmd + "  flagbackup = False)\n\n"
                            else:
                                casaCmd = casaCmd + "# Flagging atmospheric line(s)\n\n"
                                casaCmd = casaCmd + "tflagdata(vis = '"+msName1+"',\n"
                                casaCmd = casaCmd + "  mode = 'manual',\n"
                                casaCmd = casaCmd + "  spw = '"+spwSpec+"',\n"
                                casaCmd = casaCmd + "  field = '"+str(calFieldIds[i])+"',\n"
                                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        return casaCmd

    def generateWVRCalTable(self, msName, calTableName=[], refant='', smooth=True, doplot=True, remcloud=False):

        if remcloud == True and getCasaSubversionRevision() < '35187':
            sys.exit('ERROR: remcloud option is only supported for CASA >= r35187')

        #casaCmd = 'print "# Generation and time averaging of the WVR calibration table."\n\n'
        casaCmd = ''

        tb.open(msName+'/OBSERVATION')
        obsTimeRange = tb.getcol('TIME_RANGE')
        tb.close()
        obsTimeStart = ((obsTimeRange[0]/86400.0)+2400000.5-2440587.5)*86400.0
        obsTimeStart = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTimeStart))
        if obsTimeStart > '2013-01-21T00:00:00':
            wvrTimeOffset = 0
        else:
            wvrTimeOffset = -1

        tb.open(msName+'/ANTENNA')
        antNames = tb.getcol('NAME')
        tb.close()

        found = 0
        for i in antNames:
            if re.search('^[CP]M[0-9]+', i) == None: found = 1
        if found == 0:
            calTableName.append('')
            return casaCmd

        intentSources = self.getIntentsAndSourceNames(msName)

        sciSourceId = intentSources['OBSERVE_TARGET']['sourceid']
        sciSourceId1 = dict.fromkeys(sciSourceId).keys()
        if sciSourceId1[0] != '':
            #if len(sciSourceId1) != 1: casaCmd = casaCmd + "# Warning: there are more than one science target, I'm picking the lowest id. Please check this is right.\n\n"
            sciSourceName = intentSources['OBSERVE_TARGET']['name'][sciSourceId.index(min(sciSourceId1))]
            sciSourceId = min(sciSourceId1)

            phaseCal = self.getPhaseCal(msName)

        if remcloud == True:
            casaCmd = casaCmd + "import recipes.remove_cloud as rc\n\n"

        casaCmd = casaCmd + "os.system('rm -rf %s.wvr') \n\n"%(msName)
        if remcloud == True:
            casaCmd = casaCmd + "os.system('rm -rf %s.cloud_offsets') \n\n"%(msName)
        casaCmd = casaCmd + "os.system('rm -rf %s.wvrgcal') \n\n"%(msName)

        spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')

        integTime = []
        for i in spwInfo: integTime.append(spwInfo[i]['integTime'])
        integTime = dict.fromkeys(integTime).keys()
        if len(integTime) != 1: casaCmd = casaCmd + "# Warning: more than one integration time found on science data, I'm picking the lowest value. Please check this is right.\n\n"
        integTime = min(integTime)

        if re.search('^3.3', getCasaVersion()) is not None:

            #casaCmd = casaCmd + "os.system(" + '"' + "wvrgcal --ms "+msName+" --output "+msName+".wvr --toffset -1 --statsource '"+sciSourceName+"' --segsource"
            casaCmd = casaCmd + "os.system(" + '"' + "wvrgcal --ms "+msName+" --output "+msName+".wvr --toffset "+str(wvrTimeOffset)+" --segsource"
            if sciSourceId1[0] != '':
                #if len(phaseCal) == 1: casaCmd = casaCmd + " --tie '"+str(phaseCal[sciSourceName]['phaseCalId'])+","+str(sciSourceId)+"'"
                if len(phaseCal) == 1: casaCmd = casaCmd + " --statsource '"+sciSourceName+"' --tie '"+str(phaseCal[sciSourceName]['phaseCalId'])+","+str(sciSourceId)+"'"
            casaCmd = casaCmd + ' | tee '+msName+'.wvrgcal")\n\n'

        else:

            if remcloud == True:
                casaCmd = casaCmd + "rc.remove_cloud(vis='"+msName+"', offsetstable='"+msName+".cloud_offsets')\n\n"

            casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
            casaCmd = casaCmd + "casalog.setlogfile('"+msName+".wvrgcal')\n\n"
            casaCmd = casaCmd + "wvrgcal(vis = '"+msName+"',\n"

            if remcloud == True:
                casaCmd = casaCmd + "  offsetstable = '"+msName+".cloud_offsets',\n"

            casaCmd = casaCmd + "  caltable = '"+msName+".wvr',\n"

            if getCasaVersion() >= '4.3.0':

                spwIds = sorted(spwInfo.keys())
                casaCmd = casaCmd + "  spw = "+str(spwIds)+",\n"

                if smooth == True and integTime > 1.152:
                    casaCmd = casaCmd + "  smooth = '"+str(integTime)+"s',\n"

            casaCmd = casaCmd + "  toffset = "+str(wvrTimeOffset)
            if sciSourceId1[0] != '':
                casaCmd = casaCmd + ",\n  tie = "+str([','.join([i, phaseCal[i]['phaseCalName']]) for i in phaseCal])+",\n"
                casaCmd = casaCmd + "  statsource = '"+sciSourceName+"')\n\n"
            else:
                casaCmd = casaCmd + ")\n\n"
            casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"

        calTableName1 = msName+'.wvr'

        if (getCasaVersion() >= '4.2.0') and getCasaVersion() < '4.3.0':
            casaCmd = casaCmd + "# This is a temporary workaround, which will be included in a future version of CASA\n\n"
            casaCmd = casaCmd + "tb.open('"+calTableName1+"', nomodify=False)\n"
            casaCmd = casaCmd + "count = 0\n"
            casaCmd = casaCmd + "numrows = tb.nrows()\n"
            casaCmd = casaCmd + "mycparamcol = tb.getcol('CPARAM')\n"
            casaCmd = casaCmd + "for i in range(0, numrows):\n"
            casaCmd = casaCmd + "    if mycparamcol[0][0][i] == (1.+0.j):\n"
            casaCmd = casaCmd + "        tb.putcell('FLAG', i, [[True]])\n"
            casaCmd = casaCmd + "        count += 1\n"
            casaCmd = casaCmd + "tb.close()\n"
            casaCmd = casaCmd + "del mycparamcol\n"
            casaCmd = casaCmd + "if(numrows>0):\n"
            casaCmd = casaCmd + "    print 'Flagged', count, 'of', numrows, 'solutions =', 100.*count/float(numrows),'%'\n\n\n"

#         spwInfo = self.getSpwInfo(msName)
#         integTime = []
#         for i in spwInfo: integTime.append(spwInfo[i]['integTime'])
#         integTime = dict.fromkeys(integTime).keys()
#         if len(integTime) != 1: casaCmd = casaCmd + "# Warning: more than one integration time found on science data, I'm picking the lowest value. Please check this is right.\n\n"
#         integTime = min(integTime)

        if getCasaVersion() < '4.3.0':
            if smooth == True and integTime > 1.152:
                casaCmd = casaCmd + "os.system('rm -rf %s.wvr.smooth') \n\n"%(msName)
                casaCmd = casaCmd + "smoothcal(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  tablein = '"+msName+".wvr',\n"
                casaCmd = casaCmd + "  caltable = '"+msName+".wvr.smooth',\n"
                casaCmd = casaCmd + "  smoothtype = 'mean',\n"
                casaCmd = casaCmd + "  smoothtime = "+str(integTime)+")\n\n\n"
                calTableName1 = msName+'.wvr.smooth'

        calTableName.append(calTableName1)

        if doplot == True:
    # CLB added plots of WVR cross-correlations
            sciSpwInfo = self.getSpwInfo(msName)     # added by Todd on Sep 12, 2012
            sciSpw0 = sorted(sciSpwInfo.keys())[0]   # added by Todd on Sep 12, 2012
            casaCmd = casaCmd + "if applyonly != True: aU.plotWVRSolutions(caltable='%s', spw='%s', antenna='%s',\n" %(calTableName1,sciSpw0,refant)
            casaCmd = casaCmd + "  yrange=[-199,199],subplot=22, interactive=False,\n"
            casaCmd = casaCmd + "  figfile='%s') \n\n" %(calTableName1+'.plots/'+calTableName1.split('/')[-1])
            casaCmd = casaCmd + "#Note: If you see wraps in these plots, try changing yrange or unwrap=True \n"
            casaCmd = casaCmd + "#Note: If all plots look strange, it may be a bad WVR on the reference antenna.\n"
            casaCmd = casaCmd + "#      To check, you can set antenna='' to show all baselines.\n"

        if getCasaVersion() < '4.2.0':

            tb.open(msName+'/DATA_DESCRIPTION')
            spwIds = tb.getcol('SPECTRAL_WINDOW_ID')
            tb.close()

            tb.open(msName+'/PROCESSOR')
            procType = tb.getcol('TYPE')
            tb.close()

            procType1 = np.where(procType == 'RADIOMETER')[0]

            spwIds1 = []

            tb.open(msName)

            for i in procType1:
                tb1 = tb.query('PROCESSOR_ID == '+str(i))
                dataDescIds1 = tb1.getcol('DATA_DESC_ID')
                dataDescIds1 = np.unique(dataDescIds1)
                for j in dataDescIds1:
                    spwIds1.append(str(spwIds[j]))
                tb1.close() # added on July 28, 2014

            tb.close()

            spwIds1 = ','.join(spwIds1)

            if re.search('^3.3', getCasaVersion()) is not None:
                casaCmd = casaCmd + "\n\nflagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manualflag',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
            elif re.search('^4.1', getCasaVersion()) is not None:
                casaCmd = casaCmd + "\n\nflagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"
#             elif getCasaVersion() >= '4.2.0':
#                 casaCmd = casaCmd + "\n\nflagdata(vis = '"+msName+"',\n"
#                 casaCmd = casaCmd + "  mode = 'manual',\n"
#                 casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
#                 casaCmd = casaCmd + "  flagbackup = False)\n\n"
            else:
                casaCmd = casaCmd + "\n\ntflagdata(vis = '"+msName+"',\n"
                casaCmd = casaCmd + "  mode = 'manual',\n"
                casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
                casaCmd = casaCmd + "  autocorr = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        return casaCmd

    def readWvrgcalOutput(self, fname):

        if fname == '': sys.exit('ERROR: You must specify a file name.')

        f = open(fname)
        fc = f.read()
        f.close()

        fc1 = re.findall('[0-9]{4}\-[0-9]{2}\-[0-9]{2} [0-9]{2}\:[0-9]{2}\:[0-9]{2}\tINFO\twvrgcal\:\:\:\:casa\t[0-9]+ +[A-Z]{2}[0-9]{2} +[A-Za-z]+ +[A-Za-z]+ +[0-9.e+-]+ +[0-9.e+-]+', fc)

        wvrInfo = {}

        wvrInfo['ants'] = {}

        for i in range(len(fc1)):

            fc2 = fc1[i].split('\t')[3].split()

            wvrInfo['ants'][fc2[1]] = {}
            wvrInfo['ants'][fc2[1]]['RMS'] = float(fc2[4])
            wvrInfo['ants'][fc2[1]]['Disc'] = float(fc2[5])

        wvrInfo['stats'] = {}

        for i in ['RMS', 'Disc']:

            values1 = []
            for j in wvrInfo['ants'].keys():
                values1.append(wvrInfo['ants'][j][i])

            wvrInfo['stats'][i] = {}
            wvrInfo['stats'][i]['mean'] = np.mean(values1)
            wvrInfo['stats'][i]['median'] = np.median(values1)
            wvrInfo['stats'][i]['std'] = np.std(values1)
            wvrInfo['stats'][i]['MAD'] = np.median(abs(values1-np.median(values1))) / 0.6745

            wvrInfo['stats'][i]['outliers'] = []

            outliers1 = []
            for j in wvrInfo['ants'].keys():
                if abs(wvrInfo['ants'][j][i]-wvrInfo['stats'][i]['median']) >= 3 * wvrInfo['stats'][i]['MAD']:
                    outliers1.append(j)

            if len(j) != 0:
                wvrInfo['stats'][i]['outliers'] = outliers1

        return wvrInfo

    def clearPointingTable(self, msName):

        #casaCmd = 'print "# Clearing the pointing table."\n\n'
        casaCmd = ''

        casaCmd = casaCmd + "tb.open('"+msName+"/POINTING', nomodify = False)\n"
        casaCmd = casaCmd + "a = tb.rownumbers()\n"
        casaCmd = casaCmd + "tb.removerows(a)\n"
        casaCmd = casaCmd + "tb.close()\n"

        return casaCmd

    def fluxscale2(self, caltable='', refFieldId='', preavg=1, removeOutliers=False, msName='', writeToFile=False):

        setjyModels = ['Mars', 'Jupiter', 'Uranus', 'Neptune', 'Pluto', 'Io', 'Europa', 'Ganymede', 'Callisto', 'Titan', 'Triton', 'Ceres', 'Pallas', 'Vesta', 'Juno', 'Victoria', 'Davida']

        tb.open(caltable+'/SPECTRAL_WINDOW')
        spwChanFreq = tb.getcol('CHAN_FREQ')[0]
        tb.close()

        tb.open(caltable+'/FIELD')
        fieldNames = tb.getcol('NAME')
        tb.close()

        tb.open(caltable)

        calFieldIds = tb.getcol('FIELD_ID')
        calFieldIds = sorted(dict.fromkeys(calFieldIds).keys())
        calFieldNames = [fieldNames[i] for i in calFieldIds]

        if refFieldId == '':
            refFieldId = [i for i in calFieldIds if fieldNames[i] in setjyModels]
            if len(refFieldId) == 0: return {}
            refFieldId = refFieldId[0]
            print 'fluxscale2: You have not specified a reference field id, I have picked one automatically: '+fieldNames[refFieldId]
        else:
            refFieldId = int(refFieldId)

        ampGains = {}

        for fieldId in calFieldIds:

            ampGains[fieldId] = {}

            tb1 = tb.query('FIELD_ID == '+str(fieldId))
            times1 = tb1.getcol('TIME')
            tb1.close() # Necessary to prevent table lock when running generated script. - T. Hunter 2014-08-11 
            times1 = sorted(dict.fromkeys(times1).keys())

            while len(times1) != 0:

                ij = sorted(np.where(np.abs([tt-times1[0] for tt in times1]) < preavg)[0], reverse=True)

                times2 = []
                for i in ij:
                    times2.append(times1[i])
                    times1.pop(i)
                time3 = np.mean(times2)

                tb1 = tb.query('FIELD_ID == '+str(fieldId)+' AND TIME >= '+str(time3-preavg/2.)+' AND TIME <= '+str(time3+preavg/2.))

                spwIds = tb1.getcol('SPECTRAL_WINDOW_ID')
                tb1.close() # Necessary to prevent table lock when running generated script. - T. Hunter 2014-08-11 
                if len(spwIds) == 0: continue # why this test??
                spwIds = sorted(dict.fromkeys(spwIds).keys())

                ampGains[fieldId][time3] = {}

                for i in spwIds:

                    tb1 = tb.query('FIELD_ID == '+str(fieldId)+' AND TIME >= '+str(time3-preavg/2.)+' AND TIME <= '+str(time3+preavg/2.)+' AND SPECTRAL_WINDOW_ID == '+str(i))

                    antIds = tb1.getcol('ANTENNA1')
                    if len(antIds) == 0: continue # why this test?
                    antIds = sorted(dict.fromkeys(antIds).keys())
                    tb1.close() # Necessary to prevent table lock when running generated script. - T. Hunter 2014-08-11 

                    for j in antIds:

                        tb1 = tb.query('FIELD_ID == '+str(fieldId)+' AND TIME >= '+str(time3-preavg/2.)+' AND TIME <= '+str(time3+preavg/2.)+' AND SPECTRAL_WINDOW_ID == '+str(i)+' AND ANTENNA1 == '+str(j))

                        gains1 = tb1.getcol('CPARAM')
                        if len(gains1) == 0: continue # why this test?
                        flags1 = tb1.getcol('FLAG')
                        tb1.close() # Necessary to prevent table lock when running generated script. - T. Hunter 2014-08-11 
                        for k in range(len(gains1)):

                            ampGains1 = []
                            for l in range(len(gains1[k][0])):
                                if flags1[k][0][l] == False: ampGains1.append(abs(gains1[k][0][l]))

                            if len(ampGains1) != 0:
                                if i not in ampGains[fieldId][time3].keys(): ampGains[fieldId][time3][i] = {}
                                if k not in ampGains[fieldId][time3][i].keys(): ampGains[fieldId][time3][i][k] = {}
                                ampGains[fieldId][time3][i][k][j] = np.mean(ampGains1)

        tb.close()

        if refFieldId not in ampGains.keys(): sys.exit('ERROR: Reference field id not found.')

        ampGains1 = {}

        for fieldId in ampGains.keys():
            if fieldId == refFieldId: continue
            for timeId in ampGains[fieldId].keys():
                for spwId in ampGains[fieldId][timeId].keys():
                    for polId in ampGains[fieldId][timeId][spwId].keys():
                        for antId in ampGains[fieldId][timeId][spwId][polId].keys():
                            timeIds2 = []
                            ampGains2 = []
                            for timeId1 in ampGains[refFieldId].keys():
                                if spwId in ampGains[refFieldId][timeId1].keys():
                                    if polId in ampGains[refFieldId][timeId1][spwId].keys():
                                        if antId in ampGains[refFieldId][timeId1][spwId][polId].keys():
                                            timeIds2.append(timeId1)
                                            ampGains2.append(ampGains[refFieldId][timeId1][spwId][polId][antId])
                            if len(ampGains2) != 0:
                                if fieldId not in ampGains1.keys(): ampGains1[fieldId] = {}
                                if timeId not in ampGains1[fieldId].keys(): ampGains1[fieldId][timeId] = {}
                                if spwId not in ampGains1[fieldId][timeId].keys(): ampGains1[fieldId][timeId][spwId] = {}
                                if polId not in ampGains1[fieldId][timeId][spwId].keys(): ampGains1[fieldId][timeId][spwId][polId] = {}
                                if len(ampGains2) == 1:
                                    ampGains1[fieldId][timeId][spwId][polId][antId] = (ampGains[fieldId][timeId][spwId][polId][antId] / ampGains2[0])**2
                                else:
                                    ampGainsLin = scipy.interpolate.interp1d(timeIds2, ampGains2)
                                    ampGains1[fieldId][timeId][spwId][polId][antId] = (ampGains[fieldId][timeId][spwId][polId][antId] / ampGainsLin(timeId))**2

        ampGains2 = {}

        for fieldId in ampGains1.keys():
            for timeId in ampGains1[fieldId].keys():
                for spwId in ampGains1[fieldId][timeId].keys():
                    for polId in ampGains1[fieldId][timeId][spwId].keys():
                        ampGains3 = []
                        for antId in ampGains1[fieldId][timeId][spwId][polId].keys(): ampGains3.append(ampGains1[fieldId][timeId][spwId][polId][antId])
                        if len(ampGains3) != 0:
                            if removeOutliers == True:
                                ampGainsMedian = np.median(ampGains3)
                                ampGainsMAD = np.median(abs(ampGains3-ampGainsMedian)) / 0.6745
                                ampGains3 = [k for k in ampGains3 if abs(k-ampGainsMedian) < 3*ampGainsMAD]
                            if fieldId not in ampGains2.keys(): ampGains2[fieldId] = {}
                            if timeId not in ampGains2[fieldId].keys(): ampGains2[fieldId][timeId] = {}
                            if spwId not in ampGains2[fieldId][timeId].keys(): ampGains2[fieldId][timeId][spwId] = {}
                            if polId not in ampGains2[fieldId][timeId][spwId].keys(): ampGains2[fieldId][timeId][spwId][polId] = {}
                            ampGains2[fieldId][timeId][spwId][polId]['mean'] = np.mean(ampGains3)
                            ampGains2[fieldId][timeId][spwId][polId]['stddev'] = np.std(ampGains3)

        ampGains3 = {}

        for fieldId in ampGains2.keys():
            timeId3 = []
            for timeId in ampGains2[fieldId].keys(): timeId3.append(timeId)
            timeId3 = np.mean(timeId3)
            timeId3 = ((timeId3/86400.0)+2400000.5-2440587.5)*86400.0
            timeId3 = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(timeId3))
            for timeId in ampGains2[fieldId].keys():
                for spwId in ampGains2[fieldId][timeId].keys():
                    for polId in ampGains2[fieldId][timeId][spwId].keys():
                        if fieldId not in ampGains3.keys(): ampGains3[fieldId] = {}
                        if timeId3 not in ampGains3[fieldId].keys(): ampGains3[fieldId][timeId3] = {}
                        if spwId not in ampGains3[fieldId][timeId3].keys(): ampGains3[fieldId][timeId3][spwId] = {}
                        if polId not in ampGains3[fieldId][timeId3][spwId].keys(): ampGains3[fieldId][timeId3][spwId][polId] = {}
            for spwId in ampGains3[fieldId][timeId3].keys():
                for polId in ampGains3[fieldId][timeId3][spwId].keys():
                    ampGainsMeans4 = []
                    ampGainsStd4 = []
                    for timeId in ampGains2[fieldId].keys():
                        if spwId in ampGains2[fieldId][timeId].keys():
                            if polId in ampGains2[fieldId][timeId][spwId].keys():
                                ampGainsMeans4.append(ampGains2[fieldId][timeId][spwId][polId]['mean'])
                                ampGainsStd4.append(ampGains2[fieldId][timeId][spwId][polId]['stddev'])
                    sum1 = 0.
                    sum2 = 0.
                    for k in range(len(ampGainsMeans4)):
                        sum1 += ampGainsMeans4[k]/ampGainsStd4[k]**2
                        sum2 += 1./ampGainsStd4[k]**2
                    ampGains3[fieldId][timeId3][spwId][polId]['mean'] = sum1 / sum2
                    ampGains3[fieldId][timeId3][spwId][polId]['stddev'] = sqrt(1. / sum2)

        if writeToFile == True:

            if msName == '': sys.exit('ERROR: Please provide an ms name.')

            f1 = open(caltable+'.fluxscale2', 'w')

            print >> f1, "#################################################################################################"
            print >> f1, "# Measurements on ?? at Band ?? produced by ??"
            print >> f1, "# ASDM used: "+msName.replace('.ms', '')
            print >> f1, "#"
            print >> f1, "# WVR correction applied"
            print >> f1, "# Additional flags applied in: ??"
            print >> f1, "# Using reference antenna: ??"
            print >> f1, "# Bandpass calibrator: ??"
            print >> f1, "# Absolute Flux Density from: "+fieldNames[refFieldId]
            print >> f1, "#"
            print >> f1, "#           source scan elev"

            tb.open(caltable)
            scanList = tb.getcol('SCAN_NUMBER')
            tb.close()

            scanList = np.unique(scanList)

            fieldNames1 = []
            mymsmd = msmdtool()
            mymsmd.open(msName)
            for i in scanList:
                fieldNames1.append(mymsmd.fieldsforscan(scan=i, asnames=True)[0])
            mymsmd.close()

            azimuth1 = []
            elevation1 = []

            for i in range(len(scanList)):

                scanInfo1 = getWeather(msName, scan=str(scanList[i]))[0]

                print >> f1, '# %16s %3d  %5.2f' %(fieldNames1[i], scanList[i], scanInfo1['elevation'])

                azimuth1.append(scanInfo1['azimuth'])
                elevation1.append(scanInfo1['elevation'])

            print >> f1, "#"
            print >> f1, "# Data Format[Units]:"
            print >> f1, "# sourceName , ra [Hour:Min:Sec] , ra_err [arcsec], dec [Degree:Min:Sec],dec_err [arcsec],"
            print >> f1, "# frequency [Hz], flux [Jy], flux_err [Jy],"
            print >> f1, "# degree [%], degree_err [%],  angle [deg], angle_err [deg],"
            print >> f1, "# min_baseline [klambda], max_baseline [klambda], date_observed [YYYY-MM-DDT]"
            print >> f1, "# NE means No Entry"
            print >> f1, "#"
            print >> f1, "#"
            print >> f1, "#################################################################################################"
            print >> f1, "#    source                       freq        S     dS     %P    d%P uvmin   uvmax     Date"

            for fieldId in ampGains3.keys():

                ij = np.where(np.array(fieldNames1) == fieldNames[fieldId])[0]
                if len(ij) != 0:
                    uvmax = []
                    for k in ij: uvmax.append(getBaselineStats(msName, azimuth=azimuth1[k], elevation=elevation1[k], verbose=False)[2])
                    uvmax = '%7.1f' %(-1.*np.mean(uvmax))
                else:
                    uvmax = 'NE'

                for timeId in ampGains3[fieldId].keys():
                    for spwId in ampGains3[fieldId][timeId].keys():
                        if len(ampGains3[fieldId][timeId][spwId].keys()) != 1: continue # to remove when going full polarization
                        for polId in ampGains3[fieldId][timeId][spwId].keys():
                            print >> f1, '%12s, NE, NE, NE, NE, %7.2fE+09, %5.4f, %5.4f, NE, NE, NE, NE, %7.1f, %s, %10s' \
                                %(fieldNames[fieldId], spwChanFreq[spwId]/1.e9, ampGains3[fieldId][timeId][spwId][polId]['mean'], ampGains3[fieldId][timeId][spwId][polId]['stddev'], 0, uvmax, timeId[0:10])

            print >> f1, "#"
            print >> f1, "#################################################################################################"

            f1.close()

        return ampGains3

    def getFieldsForSetjy(self, msName):

        setjyModels = ['Venus', 'Mars', 'Jupiter', 'Uranus', 'Neptune', 'Pluto', 'Io', 'Europa', 'Ganymede', 'Callisto', 'Titan', 'Triton', 'Ceres', 'Pallas', 'Vesta', 'Juno', 'Victoria', 'Davida']

        #tb.open(msName+'/FIELD')
        #fieldNames = tb.getcol('NAME')
        #tb.close()

        intentSources = self.getIntentsAndSourceNames(msName)
        ampSourceIds = intentSources['CALIBRATE_AMPLI']['id'] + intentSources['CALIBRATE_FLUX']['id']
        ampSourceIds = [i for i in ampSourceIds if i != '']
        ampSourceNames = intentSources['CALIBRATE_AMPLI']['name'] + intentSources['CALIBRATE_FLUX']['name']
        ampSourceNames = [i for i in ampSourceNames if i != '']

        fieldIds = []
        for i in range(len(ampSourceNames)):
            for j in setjyModels:
                if re.search(j, ampSourceNames[i], re.IGNORECASE) is not None: fieldIds.append(ampSourceIds[i])

        fieldIds = sorted(np.unique(fieldIds).tolist())

        return fieldIds

    def fixForICT1818(self, msName, correctScienceTarget=False):
        """
        ICT-1818: sendSubScanCorrelatorData invocation: throwable was thrown (java.lang.NullPointerException)
        """
        setjyModels = ['Venus', 'Mars', 'Jupiter', 'Uranus', 'Neptune', 'Pluto', 'Io', 'Europa', 'Ganymede', 'Callisto', 'Titan', 'Triton', 'Ceres', 'Pallas', 'Vesta', 'Juno', 'Victoria', 'Davida']

        fieldIdsToCorrect = []
        mymsmd = msmdtool()
        mymsmd.open(msName)

        nfields = mymsmd.nfields()
        
        for i in range(nfields):
        
            fieldName = mymsmd.namesforfields(i)[0]

            for j in range(len(setjyModels)):
                
                if re.search(setjyModels[j]+'_[0-9]+', fieldName, re.IGNORECASE) is not None:

                    if correctScienceTarget == True or 'OBSERVE_TARGET#ON_SOURCE' not in mymsmd.intentsforfield(i):
                        fieldIdsToCorrect.append(i)

                    break

        mymsmd.close()

        print fieldIdsToCorrect

        sourceIdsToCorrect = []

        tb.open(msName+'/FIELD', nomodify=False)

        for i in fieldIdsToCorrect:

            sourceId = tb.getcell('SOURCE_ID', rownr = i)
            sourceIdsToCorrect.append(sourceId)
        
            fieldName = tb.getcell('NAME', rownr = i)
            fieldName = fieldName.split('_')[0]
            tb.putcell('NAME', rownr = i, thevalue = fieldName)

        tb.close()

        print sourceIdsToCorrect

        tb.open(msName+'/SOURCE', nomodify=False)

        for i in sourceIdsToCorrect:

            tb1 = tb.query('SOURCE_ID == '+str(i))

            for j in tb1.rownumbers().tolist():

                fieldName = tb.getcell('NAME', rownr = j)
                fieldName = fieldName.split('_')[0]
                tb.putcell('NAME', rownr = j, thevalue = fieldName)

            tb1.close()

        tb.close()
        
    def getFluxesFromSourceTable(self, msName):

        sourceFluxes = {}

        tb.open(msName)
        keywordnames1 = tb.keywordnames()
        tb.close()

        if 'ASDM_SOURCE' in keywordnames1:

            tb.open(msName + '/ASDM_SOURCE')

            for i in range(tb.nrows()):

                if tb.iscelldefined('frequency', i) == False or tb.iscelldefined('flux', i) == False: continue

                sourceId = tb.getcell('sourceId', i)
                sourceName = tb.getcell('sourceName', i)

                frequency1 = tb.getcell('frequency', i).tolist()
                flux1 = tb.getcell('flux', i).tolist()

                if len(frequency1) != len(flux1): sys.exit('ERROR: The number of frequencies and flux values do not match.')
                if len(frequency1) != 1: print "WARNING: There are more than one flux values."

                for j in range(len(flux1)):
                    if flux1[j][1] != 0: print "WARNING: Source "+sourceName+" has a non-0 value for Q."
                    if flux1[j][2] != 0: print "WARNING: Source "+sourceName+" has a non-0 value for U."
                    if flux1[j][3] != 0: print "WARNING: Source "+sourceName+" has a non-0 value for V."

                if sourceId not in sourceFluxes: sourceFluxes[sourceId] = {}
                if 'sourceName' not in sourceFluxes[sourceId]: sourceFluxes[sourceId]['sourceName'] = sourceName
                if 'frequency' not in sourceFluxes[sourceId]: sourceFluxes[sourceId]['frequency'] = []
                if 'flux' not in sourceFluxes[sourceId]: sourceFluxes[sourceId]['flux'] = []

                for j in range(len(frequency1)):
                    if frequency1[j] not in sourceFluxes[sourceId]['frequency']:
#                        print "row %d: appending %f GHz, %f Jy to source %d" % (i,frequency1[j]*1e-9,flux1[j][0],sourceId) 
                        sourceFluxes[sourceId]['frequency'].append(frequency1[j])
                        sourceFluxes[sourceId]['flux'].append(flux1[j][0])

            tb.close()

        return sourceFluxes

    def runSetjy(self, msName, msName1='', iHaveSplitMyScienceSpw=False):

        if msName1 == '': msName1 = msName

        casaCmd = ''

        fieldIds = self.getFieldsForSetjy(msName)

        if fieldIds != []:

            #casaCmd = 'print "# Putting a model for the flux calibrator(s)."\n\n'

            tb.open(msName+'/FIELD')
            fieldNames = tb.getcol('NAME')
            ephemerisIds = tb.getcol('EPHEMERIS_ID')
            phaseDirKeywords = tb.getcolkeywords('PHASE_DIR')
            phaseDirRef = tb.getcol('PhaseDir_Ref')
            tb.close()

            fieldNames1 = ['%s' %fieldNames[i] for i in fieldIds]
            fieldNames = ','.join(fieldNames1)
            fieldIds = ['%s' %i for i in fieldIds]
            fieldIds1 = ','.join(fieldIds)

            spwInfo = self.getSpwInfo(msName, intent='CALIBRATE_AMPLI|CALIBRATE_FLUX')
            spwIds = sorted(spwInfo.keys())
#             if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))
            if iHaveSplitMyScienceSpw == True:
                spwInfo1 = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
                spwIds1 = sorted(spwInfo1.keys())
                spwIds = [spwIds1.index(i) for i in spwIds]
            spwIds = ['%s' %i for i in spwIds]
            spwIds = ','.join(spwIds)

            if getCasaVersion() == '4.5.0':

                ij = np.where(phaseDirKeywords['MEASINFO']['TabRefTypes'] == 'ICRS')[0][0]
                icrscode = phaseDirKeywords['MEASINFO']['TabRefCodes'][ij]

                for i in range(len(fieldIds)):

                    casaCmd = casaCmd + "setjy(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  field = '"+fieldIds[i]+"', # "+fieldNames1[i]+"\n"
                    casaCmd = casaCmd + "  spw = '"+spwIds+"',\n"

                    if ephemerisIds[int(fieldIds[i])] != -1 and phaseDirRef[int(fieldIds[i])] == icrscode:
                        casaCmd = casaCmd + "  standard = 'Butler-JPL-Horizons 2012',\n"
                        casaCmd = casaCmd + "  useephemdir = True)\n\n"
                    else:
                        casaCmd = casaCmd + "  standard = 'Butler-JPL-Horizons 2012')\n\n"

            else:

                casaCmd = casaCmd + "setjy(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  field = '"+fieldIds1+"', # "+fieldNames+"\n"
                casaCmd = casaCmd + "  spw = '"+spwIds+"',\n"
                if re.search('^3.', getCasaVersion()) == None:
                    casaCmd = casaCmd + "  standard = 'Butler-JPL-Horizons 2012')\n\n"
                else:
                    casaCmd = casaCmd + "  standard = 'Butler-JPL-Horizons 2010')\n\n"

            casaCmd = casaCmd + "if applyonly != True:\n"
            casaCmd = casaCmd + "  os.system('rm -rf %s.setjy.field*.png') \n"%(msName1)
            casaCmd = casaCmd + "  for i in "+str(fieldIds)+":\n"
            casaCmd = casaCmd + "    plotms(vis = '"+msName1+"',\n"
            casaCmd = casaCmd + "      xaxis = 'uvdist',\n"
            casaCmd = casaCmd + "      yaxis = 'amp',\n"
            casaCmd = casaCmd + "      ydatacolumn = 'model',\n"
            casaCmd = casaCmd + "      field = str(i),\n"
            casaCmd = casaCmd + "      spw = '"+spwIds+"',\n"
            casaCmd = casaCmd + "      avgchannel = '9999',\n"
            casaCmd = casaCmd + "      coloraxis = 'spw',\n"
            casaCmd = casaCmd + "      plotfile = '"+msName1+".setjy.field'+i+'.png')\n"

        else:

            intentSources = self.getIntentsAndSourceNames(msName)
            intentSources1 = intentSources['CALIBRATE_FLUX']

            if len(intentSources1['sourceid']) != 0:

#                 fluxCalSourceId = intentSources1['sourceid']
#                 if len(fluxCalSourceId) != 1: sys.exit("ERROR: There are more than one flux calibrator.")
#                 fluxCalSourceId = fluxCalSourceId[0]
#                 fluxCalSourceName = intentSources1['name'][0]
#                 fluxCalFieldIds = intentSources1['id']
# 
#                 sourceFluxes = self.getFluxesFromSourceTable(msName)

                found = 0

                if getCasaVersion() >= '4.2.0':

                    fluxCalSourceId = intentSources1['sourceid']
                    fluxCalSourceNames = intentSources1['name']

                    found = 0

                    sourceFluxes = getALMAFluxForMS(msName)

                    if len(sourceFluxes) != 0:

                        for j in sourceFluxes.keys():
                            if j not in fluxCalSourceNames:
                                sourceFluxes.pop(j)

                        if len(sourceFluxes) != 0:

                            found = 1

                            if len(sourceFluxes.keys()) > 1:
                                print "WARNING: THERE ARE MORE THAN ONE FLUX CALIBRATOR. I WILL PICK THE FIRST ONE. THIS MAY BE WRONG."

                            fluxCalSourceName = sourceFluxes.keys()[0]

                            casaCmd = casaCmd + "setjy(vis = '"+msName1+"',\n"
                            casaCmd = casaCmd + "  standard = 'manual',\n"
                            casaCmd = casaCmd + "  field = '"+fluxCalSourceName+"',\n"
                            casaCmd = casaCmd + "  fluxdensity = ["+str(sourceFluxes[fluxCalSourceName]['fluxDensity'])+", 0, 0, 0],\n"
                            casaCmd = casaCmd + "  spix = "+str(sourceFluxes[fluxCalSourceName]['spectralIndex'])+",\n"
                            casaCmd = casaCmd + "  reffreq = '"+str(sourceFluxes[fluxCalSourceName]['frequency']/1.e9)+"GHz')\n\n"

                if found == 0:

                    fluxCalSourceId = intentSources1['sourceid']

                    sourceFluxes = self.getFluxesFromSourceTable(msName)

                    if len(fluxCalSourceId) > 1:
                        print "WARNING: THERE ARE MORE THAN ONE FLUX CALIBRATOR. I WILL PICK THE FIRST ONE. THIS MAY BE WRONG."
                        fluxCalSourceId = [j for j in fluxCalSourceId if j in sourceFluxes.keys()]

                    if len(fluxCalSourceId) == 0: sys.exit("ERROR: There are no flux calibrator.")

                    fluxCalSourceId = fluxCalSourceId[0]

                    fluxCalSourceName = intentSources1['name'][intentSources1['sourceid'].index(fluxCalSourceId)]

                    if len(intentSources1['sourceid']) > 1:
                        tb.open(msName+'/FIELD')
                        tb1 = tb.query('SOURCE_ID == '+str(fluxCalSourceId))
                        fluxCalFieldIds1 = tb1.rownumbers().tolist()
                        tb1.close()
                        tb.close()
                        fluxCalFieldIds = [j for j in fluxCalFieldIds1 if j in intentSources1['id']]
                    else:
                        fluxCalFieldIds = intentSources1['id']

                    if fluxCalSourceId in sourceFluxes:

                        if fluxCalSourceName != sourceFluxes[fluxCalSourceId]['sourceName']: sys.exit("ERROR: Source names do not match.")

                        fluxCalFieldIds = ['%s' %i for i in fluxCalFieldIds]
                        fluxCalFieldIds = ','.join(fluxCalFieldIds)

                        vm = ValueMapping(msName)

                        spwInfo = self.getSpwInfo(msName, intent='CALIBRATE_FLUX')
                        spwIds = sorted(spwInfo.keys())

                        spwMeanFreq = []
                        for j in spwIds: spwMeanFreq.append(vm.spwInfo[j]['meanFreq'])

                        if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))

                        for j in range(len(spwIds)):

                            frequency1 = []
                            for k in sourceFluxes[fluxCalSourceId]['frequency']: frequency1.append(abs(k-spwMeanFreq[j]))
                            ij = frequency1.index(min(frequency1))

                            frequency1 = sourceFluxes[fluxCalSourceId]['frequency'][ij]
                            flux1 = sourceFluxes[fluxCalSourceId]['flux'][ij]
                    
                            casaCmd = casaCmd + "setjy(vis = '"+msName1+"',\n"
                            casaCmd = casaCmd + "  field = '"+fluxCalFieldIds+"', # source name = "+fluxCalSourceName+"\n"
                            casaCmd = casaCmd + "  spw = '"+str(spwIds[j])+"', # center frequency of spw = "+str(spwMeanFreq[j]/1.e9)+"GHz\n"
                            if (getCasaVersion() >= '4.2.0'): casaCmd = casaCmd + "  standard = 'manual',\n"
                            casaCmd = casaCmd + "  fluxdensity = ["+str(flux1)+", 0, 0, 0]) # frequency of measurement = "+str(frequency1/1.e9)+"GHz\n\n"


        return casaCmd

    def doGainCalibration(self, msName, msName1='', refant='', bandpass='', gaintypeForAmp='T', doplot=True, calFieldsOnly=True, calmode2='ap', phaseDiff='', phaseDiffCalTableName=[], fluxscaleDictName=[], ampForSci=[], iHaveSplitMyScienceSpw=False, phaseDiffPerSpwSetup=False):

        if msName1 == '': msName1 = msName
        if refant == '': sys.exit('ERROR: No reference antenna specified.')
        if bandpass == '': sys.exit('ERROR: No bandpass cal table specified.')

        if getCasaVersion() >= '4.2.0': fluxscaleDictName.append('fluxscaleDict')

        tb.open(msName+'/FIELD')
        fieldNames = tb.getcol('NAME')
        tb.close()

        fieldIds = range(len(fieldNames))

        intentSources = self.getIntentsAndSourceNames(msName)
        sciFieldIds = intentSources['OBSERVE_TARGET']['id']
        if 'OBSERVE_CHECK' in intentSources.keys(): sciFieldIds += intentSources['OBSERVE_CHECK']['id']
        if sciFieldIds[0] == '': print 'WARNING: THERE SEEMS TO BE NO SCIENCE FIELD'

        if calFieldsOnly == True:
            calFieldIds = [i for i in fieldIds if i not in sciFieldIds]
        else:
            calFieldIds = [i for i in fieldIds]

###

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = msmdtool()
            mymsmd.open(msName)
            hasdata = []
            for i in calFieldIds:
                calFieldIntents = mymsmd.intentsforfield(i)
                hasdata1 = 0
                for j in calFieldIntents:
                    if re.search('^CALIBRATE_(POINTING|ATMOSPHERE|WVR)', j) == None:
                        hasdata1 = 1
                        break
                hasdata.append(hasdata1)
            mymsmd.close()

            calFieldIds = [calFieldIds[i] for i in range(len(calFieldIds)) if hasdata[i] == 1]

###

        if len(calFieldIds) == '': sys.exit('ERROR: There seems to be no calibrator field.')

        calFieldNames = [fieldNames[i] for i in calFieldIds]
        calFieldNames = ','.join(calFieldNames)

        if len(calFieldIds) > 1:
            j0 = 0
            calFieldIds1 = str(calFieldIds[j0])
            for j in range(len(calFieldIds)-1):
                if calFieldIds[j+1] == calFieldIds[j]+1: continue
                calFieldIds1 = calFieldIds1 + '~' + str(calFieldIds[j])
                j0 = j+1
                calFieldIds1 = calFieldIds1 + ',' + str(calFieldIds[j0])
            calFieldIds1 = calFieldIds1 + '~' + str(calFieldIds[j+1])
        else:
            calFieldIds1 = str(calFieldIds[0])

        spwInfo = self.getSpwInfo(msName)
        spwIds = sorted(spwInfo.keys())

###

#         if phaseDiff == False:
        if phaseDiff == '':

            spwInfo2 = self.getSpwInfo(msName, intent = 'CALIBRATE_PHASE')
            spwIds2 = sorted(spwInfo2.keys())

            if spwIds != spwIds2:
                print 'WARNING: THIS SEEMS TO BE A BW-SWITCHING OR B2B-TRANSFER OBSERVATION. THE FORMER IS SUPPORTED, THE LATTER NOT ENTIRELY YET.'
                if getCasaVersion() < '4.2.0': sys.exit('ERROR: PLEASE USE CASA 4.2 OR LATER')
                phaseDiff = True

###

        casaCmd = ''

        if phaseDiff == True:

#             spwInfo1 = self.getSpwInfo(msName, intent = 'CALIBRATE_PHASE')
#             spwIds1 = sorted(spwInfo1.keys())
# 
#             if spwIds != spwIds1 and sciFieldIds[0] != '':
            if sciFieldIds[0] != '':

                if phaseDiffPerSpwSetup == True:

                    print 'WARNING: THIS SEEMS TO BE A BW-SWITCHING OR B2B-TRANSFER OBSERVATION. THE FORMER IS SUPPORTED, THE LATTER NOT ENTIRELY YET.'
                    if getCasaVersion() < '4.2.0': sys.exit('ERROR: PLEASE USE CASA 4.2 OR LATER')

                    bpassCalId = intentSources['CALIBRATE_BANDPASS']['id']
                    if bpassCalId[0] == '': sys.exit('ERROR: There are no bandpass calibrator.')
                    if len(bpassCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one bandpass calibrator, I'm picking the first one: "+fieldNames[bpassCalId[0]]+".\n"
                    bpassCalId = bpassCalId[0]

                    diffGainCalId = ''
                    diffGainCalScanList = ''
                    if 'CALIBRATE_DIFFGAIN' in intentSources.keys():
                        diffGainCalId = intentSources['CALIBRATE_DIFFGAIN']['id']
                        if len(diffGainCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one diffgain calibrator, I'm picking the first one: "+fieldNames[diffGainCalId[0]]+".\n"
                        diffGainCalId = diffGainCalId[0]
                    if diffGainCalId == '':
                        diffGainCalId = bpassCalId
                    else:
                        mymsmd = msmdtool()
                        mymsmd.open(msName)
                        diffGainCalScanList = mymsmd.scansforintent('CALIBRATE_DIFFGAIN#*').tolist()
                        mymsmd.close()
                        diffGainCalScanList = [str(j) for j in diffGainCalScanList]
                        diffGainCalScanList = ','.join(diffGainCalScanList)

                    casaCmd = casaCmd + "os.system('rm -rf %s.phasediff_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".phasediff_inf',\n"
                    casaCmd = casaCmd + "  field = '"+str(diffGainCalId)+"',\n"
                    if diffGainCalScanList != '': casaCmd = casaCmd + "  scan = '"+diffGainCalScanList+"',\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  combine = 'scan',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = 'G',\n"
                    casaCmd = casaCmd + "  calmode = 'p',\n"
                    casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                    phaseDiffCalTableName.append(msName1+'.phasediff_inf')

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phasediff_inf', msName='"+msName1+"', interactive=False) \n\n"

    ###
                    mymsmd = msmdtool()
                    mymsmd.open(msName)

                    spwIds3 = mymsmd.spwsforintent('CALIBRATE_BANDPASS*').tolist()+mymsmd.spwsforintent('OBSERVE_TARGET*').tolist()
                    spwIds3 = np.unique([j for j in spwIds3 if j not in mymsmd.chanavgspws() and j not in mymsmd.wvrspws()]).tolist()

#                     spwSetups = []
#                     for i in mymsmd.scannumbers():
#                         spwIds4 = [j for j in mymsmd.spwsforscan(i) if j in spwIds3]
#                         if len(spwIds4) != 0: spwSetups.append(spwIds4)
#                     spwSetups1 = []
#                     for i in spwSetups:
#                         if i not in spwSetups1: spwSetups1.append(i)
#                     spwSetups1.sort(key=lambda x:x[0])

                    spwSetups = {}
                    for i in spwIds3:
                        scanList3 = str(mymsmd.scansforspw(i).tolist())
                        if scanList3 not in spwSetups.keys(): spwSetups[scanList3] = []
                        spwSetups[scanList3].append(i)
                    spwSetups1 = []
                    for i in spwSetups.values():
                        if i not in spwSetups1: spwSetups1.append(i)
                    spwSetups1.sort(key=lambda x:x[0])

                    calspwmap = []
                    for i in range(len(spwSetups1)):
                        for j in range(len(spwSetups1[i])):
                            calspwmap.append(min(spwSetups1[i]))

                    if iHaveSplitMyScienceSpw == True:

                        for i in range(len(spwSetups1)):
                            for j in range(len(spwSetups1[i])):
                                spwSetups1[i][j] = spwIds3.index(spwSetups1[i][j])

                        for i in range(len(calspwmap)):
                            calspwmap[i] = spwIds3.index(calspwmap[i])

                    casaCmd = casaCmd + "calspwmap = "+str(calspwmap)+"\n\n"

                    mymsmd.close()

    ###

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_int') \n"%(msName1)
                    casaCmd = casaCmd + "for spw in "+str(spwSetups1)+":\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".phase_int',\n"
                    casaCmd = casaCmd + "    field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "    solint = 'int',\n"
                    casaCmd = casaCmd + "    spw = ','.join([str(j) for j in spw]),\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = 'G',\n"
                    casaCmd = casaCmd + "    calmode = 'p',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_int', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.ampli_inf') \n"%(msName1)
                    casaCmd = casaCmd + "for spw in "+str(spwSetups1)+":\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "    field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "    solint = 'inf',\n"
                    casaCmd = casaCmd + "    spw = ','.join([str(j) for j in spw]),\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "    calmode = 'a',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf', '"+msName1+".phase_int'],\n"
                    casaCmd = casaCmd + "    spwmap = [[], [], calspwmap])\n\n"

                    ampForSci.append(msName1+'.ampli_inf')

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".ampli_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                    casaCmd = casaCmd + "os.system('rm -rf %s.fluxscale') \n"%(msName1)
                    casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    casaCmd = casaCmd + fluxscaleDictName[0] + " = fluxscale(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                    casaCmd = casaCmd + "  reference = '"+str(bpassCalId)+"', # "+fieldNames[bpassCalId]+"\n"
                    casaCmd = casaCmd + "  refspwmap = calspwmap,\n"
                    casaCmd = casaCmd + "  incremental = True)\n\n"
                    casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"
                    casaCmd = casaCmd + "if applyonly != True: es.fluxscale2(caltable = '"+msName1+".ampli_inf', removeOutliers=True, msName='"+msName+"', writeToFile=True, preavg=10000)\n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_inf') \n"%(msName1)
                    casaCmd = casaCmd + "for spw in "+str(spwSetups1)+":\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".phase_inf',\n"
                    casaCmd = casaCmd + "    field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "    solint = 'inf',\n"
                    casaCmd = casaCmd + "    spw = ','.join([str(j) for j in spw]),\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = 'G',\n"
                    casaCmd = casaCmd + "    calmode = 'p',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_inf', msName='"+msName1+"', interactive=False) \n"

                else:

                    print 'WARNING: THIS SEEMS TO BE A BW-SWITCHING OR B2B-TRANSFER OBSERVATION. THE FORMER IS SUPPORTED, THE LATTER NOT ENTIRELY YET.'
                    if getCasaVersion() < '4.2.0': sys.exit('ERROR: PLEASE USE CASA 4.2 OR LATER')

                    bpassCalId = intentSources['CALIBRATE_BANDPASS']['id']
                    if bpassCalId[0] == '': sys.exit('ERROR: There are no bandpass calibrator.')
                    if len(bpassCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one bandpass calibrator, I'm picking the first one: "+fieldNames[bpassCalId[0]]+".\n"
                    bpassCalId = bpassCalId[0]

                    diffGainCalId = ''
                    diffGainCalScanList = ''
                    if 'CALIBRATE_DIFFGAIN' in intentSources.keys():
                        diffGainCalId = intentSources['CALIBRATE_DIFFGAIN']['id']
                        if len(diffGainCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one diffgain calibrator, I'm picking the first one: "+fieldNames[diffGainCalId[0]]+".\n"
                        diffGainCalId = diffGainCalId[0]
                    if diffGainCalId == '':
                        diffGainCalId = bpassCalId
                    else:
                        mymsmd = msmdtool()
                        mymsmd.open(msName)
                        diffGainCalScanList = mymsmd.scansforintent('CALIBRATE_DIFFGAIN#*').tolist()
                        mymsmd.close()
                        diffGainCalScanList = [str(j) for j in diffGainCalScanList]
                        diffGainCalScanList = ','.join(diffGainCalScanList)

                    casaCmd = casaCmd + "os.system('rm -rf %s.phasediff_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".phasediff_inf',\n"
                    casaCmd = casaCmd + "  field = '"+str(diffGainCalId)+"',\n"
                    if diffGainCalScanList != '': casaCmd = casaCmd + "  scan = '"+diffGainCalScanList+"',\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  combine = 'scan',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = 'G',\n"
                    casaCmd = casaCmd + "  calmode = 'p',\n"
                    casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                    phaseDiffCalTableName.append(msName1+'.phasediff_inf')

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phasediff_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_int') \n"%(msName1)
                    casaCmd = casaCmd + "for i in "+str(calFieldIds)+": # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".phase_int',\n"
                    casaCmd = casaCmd + "    field = str(i),\n"
                    casaCmd = casaCmd + "    solint = 'int',\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = 'G',\n"
                    casaCmd = casaCmd + "    calmode = 'p',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_int', msName='"+msName1+"', interactive=False) \n\n"

    ###
                    mymsmd = msmdtool()
                    mymsmd.open(msName)

                    if iHaveSplitMyScienceSpw == True:
                        spwInfo3 = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
                        spwIds3 = sorted(spwInfo3.keys())
                        numSpws = len(spwIds3)
                    else:
                        numSpws = mymsmd.nspw()

                    calspwmap = {}

                    for i in calFieldIds:

                        fieldSpws = mymsmd.spwsforfield(i)

                        if iHaveSplitMyScienceSpw == True:
                            fieldSpws = [spwIds3.index(j) for j in fieldSpws if j in spwIds3]

                        calspwmap[i] = [min(fieldSpws)] * numSpws

                    mymsmd.close()

                    casaCmd = casaCmd + "calspwmap = "+repr(calspwmap)+"\n\n"

    ###

                    casaCmd = casaCmd + "os.system('rm -rf %s.ampli_inf') \n"%(msName1)
                    casaCmd = casaCmd + "for i in "+str(calFieldIds)+": # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "    field = str(i),\n"
                    casaCmd = casaCmd + "    solint = 'inf',\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "    calmode = 'a',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf', '"+msName1+".phase_int'],\n"
                    casaCmd = casaCmd + "    spwmap = [[], [], calspwmap[i]])\n\n"

                    ampForSci.append(msName1+'.ampli_inf')

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".ampli_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                    casaCmd = casaCmd + "os.system('rm -rf %s.fluxscale') \n"%(msName1)
                    casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    casaCmd = casaCmd + fluxscaleDictName[0] + " = fluxscale(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                    casaCmd = casaCmd + "  reference = '"+str(bpassCalId)+"', # "+fieldNames[bpassCalId]+"\n"
                    casaCmd = casaCmd + "  refspwmap = calspwmap["+str(bpassCalId)+"],\n"
                    casaCmd = casaCmd + "  incremental = True)\n\n"
                    casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"
                    casaCmd = casaCmd + "if applyonly != True: es.fluxscale2(caltable = '"+msName1+".ampli_inf', removeOutliers=True, msName='"+msName+"', writeToFile=True, preavg=10000)\n\n"

    #                 casaCmd = casaCmd + "os.system('rm -rf %s.phase_inf') \n"%(msName1)
    #                 casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
    #                 casaCmd = casaCmd + "  caltable = '"+msName1+".phase_inf',\n"
    #                 casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
    #                 casaCmd = casaCmd + "  solint = 'inf',\n"
    #                 casaCmd = casaCmd + "  combine = 'spw',\n"
    #                 casaCmd = casaCmd + "  refant = '"+refant+"',\n"
    #                 casaCmd = casaCmd + "  gaintype = 'G',\n"
    #                 casaCmd = casaCmd + "  calmode = 'p',\n"
    #                 casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf'])\n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_inf') \n"%(msName1)
                    casaCmd = casaCmd + "for i in "+str(calFieldIds)+": # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "    caltable = '"+msName1+".phase_inf',\n"
                    casaCmd = casaCmd + "    field = str(i),\n"
                    casaCmd = casaCmd + "    solint = 'inf',\n"
                    casaCmd = casaCmd + "    combine = 'spw',\n"
                    casaCmd = casaCmd + "    refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "    gaintype = 'G',\n"
                    casaCmd = casaCmd + "    calmode = 'p',\n"
                    casaCmd = casaCmd + "    append = True,\n"
                    casaCmd = casaCmd + "    gaintable = ['"+bandpass+"', '"+msName1+".phasediff_inf'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_inf', msName='"+msName1+"', interactive=False) \n"

        else:

            #if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))

            fluxCalId = self.getFieldsForSetjy(msName)

            #casaCmd = 'print "# Gain calibration."\n\n'
            #casaCmd = ''

            if len(fluxCalId) == 0:
                casaCmd = casaCmd + "os.system('rm -rf %s.phase_int') \n"%(msName1)
                casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  caltable = '"+msName1+".phase_int',\n"
                casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                casaCmd = casaCmd + "  solint = 'int',\n"
                casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                casaCmd = casaCmd + "  gaintype = 'G',\n"
                casaCmd = casaCmd + "  calmode = 'p',\n"
                casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_int', msName='"+msName1+"', interactive=False) \n\n"

                intentSources1 = intentSources['CALIBRATE_FLUX']

                if len(intentSources1['sourceid']) != 0:

    #                 fluxCalSourceId = intentSources1['sourceid']
    #                 if len(fluxCalSourceId) != 1: sys.exit("ERROR: There are more than one flux calibrator.")
    #                 fluxCalSourceId = fluxCalSourceId[0]
    #                 fluxCalSourceName = intentSources1['name'][0]
    #                 fluxCalFieldIds = intentSources1['id']
    # 
    #                 sourceFluxes = self.getFluxesFromSourceTable(msName)

                    sourceFluxes = self.getFluxesFromSourceTable(msName)

                    fluxCalSourceId = intentSources1['sourceid']

                    if len(fluxCalSourceId) > 1:
                        print "WARNING: THERE ARE MORE THAN ONE FLUX CALIBRATOR. I WILL PICK THE FIRST ONE. THIS MAY BE WRONG."
                        fluxCalSourceId = [j for j in fluxCalSourceId if j in sourceFluxes.keys()]

                    if len(fluxCalSourceId) == 0: sys.exit("ERROR: There are no flux calibrator.")

                    fluxCalSourceId = fluxCalSourceId[0]

                    fluxCalSourceName = intentSources1['name'][intentSources1['sourceid'].index(fluxCalSourceId)]

                    if len(intentSources1['sourceid']) > 1:
                        tb.open(msName+'/FIELD')
                        tb1 = tb.query('SOURCE_ID == '+str(fluxCalSourceId))
                        fluxCalFieldIds1 = tb1.rownumbers().tolist()
                        tb1.close()
                        tb.close()
                        fluxCalFieldIds = [j for j in fluxCalFieldIds1 if j in intentSources1['id']]
                    else:
                        fluxCalFieldIds = intentSources1['id']

                    if fluxCalSourceId in sourceFluxes:

                        if fluxCalSourceName != sourceFluxes[fluxCalSourceId]['sourceName']: sys.exit("ERROR: Source names do not match.")

                        fluxCalId = fluxCalFieldIds[:]

                if len(fluxCalId) != 0:

                    if len(fluxCalId) > 1: casaCmd = casaCmd + "# Note: There are more than one flux calibrator in this dataset, I'm using the first one.\n\n"
                    fluxCalId = fluxCalId[0]

                    casaCmd = casaCmd + "os.system('rm -rf %s.ampli_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "  calmode = 'a',\n"
                    casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phase_int'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".ampli_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                    casaCmd = casaCmd + "os.system('rm -rf %s.fluxscale') \n"%(msName1)
                    casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    if getCasaVersion() >= '4.2.0':
                        casaCmd = casaCmd + fluxscaleDictName[0] + " = fluxscale(vis = '"+msName1+"',\n"
                    else:
                        casaCmd = casaCmd + "fluxscale(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                    casaCmd = casaCmd + "  reference = '"+str(fluxCalId)+"') # "+fieldNames[fluxCalId]+"\n\n"
                    casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"
                    casaCmd = casaCmd + "if applyonly != True: es.fluxscale2(caltable = '"+msName1+".ampli_inf', removeOutliers=True, msName='"+msName+"', writeToFile=True, preavg=10000)\n\n"

                else:

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".flux_inf',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "  calmode = 'a',\n"
                    casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phase_int'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".flux_inf', msName='"+msName1+"', interactive=False) \n\n"

                    #casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    #casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    #casaCmd = casaCmd + "fluxscale(vis = '"+msName1+"',\n"
                    #casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    #casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                    #casaCmd = casaCmd + "  reference = fluxCalId)\n\n"
                    #casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"

            else:

                if len(fluxCalId) > 1: casaCmd = casaCmd + "# Note: There are more than one Solar system object in this dataset, I'm using the first one as flux calibrator.\n\n"
                fluxCalId = fluxCalId[0]

                tb.open(msName+'/ANTENNA')
                antList = tb.getcol('NAME')
                tb.close()

                antList1 = self.getAntennasForFluxscale2(msName, fluxCalId=str(fluxCalId), refant=refant)

                if len(antList) == len(antList1):

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_int') \n"%(msName1)
                    casaCmd = casaCmd + "\ngaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".phase_int',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  solint = 'int',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = 'G',\n"
                    casaCmd = casaCmd + "  calmode = 'p',\n"
                    casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_int', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.ampli_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                    casaCmd = casaCmd + "  gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "  calmode = 'a',\n"
                    casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phase_int'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".ampli_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                    casaCmd = casaCmd + "os.system('rm -rf %s.fluxscale') \n"%(msName1)
                    casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    if getCasaVersion() >= '4.2.0':
                        casaCmd = casaCmd + fluxscaleDictName[0] + " = fluxscale(vis = '"+msName1+"',\n"
                    else:
                        casaCmd = casaCmd + "fluxscale(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                    casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                    casaCmd = casaCmd + "  reference = '"+str(fluxCalId)+"') # "+fieldNames[fluxCalId]+"\n\n"
                    casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"
                    casaCmd = casaCmd + "if applyonly != True: es.fluxscale2(caltable = '"+msName1+".ampli_inf', removeOutliers=True, msName='"+msName+"', writeToFile=True, preavg=10000)\n\n"

                else:

                    if sciFieldIds[0] != '':
                        phaseCal = self.getPhaseCal(msName)  # Added by CLB
                        phaseCalNames = []  # Added by CLB
                        phaseCalIds = []
                        for i in phaseCal:  # Added by CLB
                            phaseCalNames.append(phaseCal[i]['phaseCalName']) # Added by CLB
                            phaseCalIds.append(phaseCal[i]['phaseCalId'])

                    if len(antList1) < 2:
                        print 'WARNING: THE SOLAR SYSTEM OBJECT SEEMS TO BE EXTREMELY RESOLVED'
                        print 'WARNING: I COULD NOT FIND A SUBSET OF ANTENNAS ON WHICH TO RUN GAINCAL'
                        print 'WARNING: YOU SHOULD LOOK AT THE DATA, AND THEN UPDATE THE SCRIPT'

                    casaCmd += "# Note: the Solar system object used for flux calibration is highly resolved on some baselines.\n"
                    casaCmd += "# Note: we will first determine the flux of the phase calibrator(s) on a subset of antennas.\n\n"

                    if re.search('^3.', getCasaVersion()) == None:
                        casaCmd += "delmod"
                    else:
                        casaCmd += "clearcal"

                    if sciFieldIds[0] != '':
    #                     casaCmd += "('%s',field='%s')\n\n" % (msName1, ",".join(map(str,list(np.unique(phaseCalNames))))) # Added by CLB
                        casaCmd += "('%s',field='%s')\n\n" % (msName1, ",".join(map(str,list(np.unique(phaseCalIds))))) # Added by CLB
                    else:
    #                     casaCmd += "('%s',field='%s')\n\n" % (msName1, ",".join(map(str,list(np.unique(calFieldNames)))))
                        casaCmd += "('%s',field='%s')\n\n" % (msName1, ",".join(map(str,list(np.unique(calFieldIds)))))

                    numAntList1 = len(antList1)
                    antList1 = ','.join(antList1)

                    casaCmd = casaCmd + "os.system('rm -rf %s.phase_short_int') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".phase_short_int',\n"
                    casaCmd = casaCmd + "  field = '"+str(fluxCalId)+"', # "+fieldNames[fluxCalId]+"\n"
                    casaCmd = casaCmd + "  selectdata = True,\n"
                    casaCmd = casaCmd + "  antenna = '"+str(antList1)+"&',\n"
                    casaCmd = casaCmd + "  solint = 'int',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"

                    if numAntList1 < 5:
                        casaCmd = casaCmd + "  minblperant = "+str(numAntList1-1)+",\n"
                        casaCmd = casaCmd + "  minsnr = 2.0,\n"

                    casaCmd = casaCmd + "  gaintype = 'G',\n"
                    casaCmd = casaCmd + "  calmode = 'p',\n"
                    casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

    ###

                    calFieldIds1 = [str(i) for i in calFieldIds if i != fluxCalId]
                    calFieldIds1 = ','.join(calFieldIds1)

                    calFieldNames = [fieldNames[i] for i in calFieldIds if i != fluxCalId]
                    calFieldNames = ','.join(calFieldNames)

                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".phase_short_int',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  selectdata = True,\n"
                    casaCmd = casaCmd + "  solint = 'int',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"

                    if numAntList1 < 5:
                        casaCmd = casaCmd + "  minblperant = "+str(numAntList1-1)+",\n"
                        casaCmd = casaCmd + "  minsnr = 2.0,\n"

                    casaCmd = casaCmd + "  gaintype = 'G',\n"
                    casaCmd = casaCmd + "  calmode = 'p',\n"
                    casaCmd = casaCmd + "  append = True,\n"
                    casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

    ###

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_short_int', msName='"+msName1+"', interactive=False) \n\n"

                    calFieldIds1 = [str(i) for i in calFieldIds]
                    calFieldIds1 = ','.join(calFieldIds1)

                    calFieldNames = [fieldNames[i] for i in calFieldIds]
                    calFieldNames = ','.join(calFieldNames)

                    casaCmd = casaCmd + "os.system('rm -rf %s.ampli_short_inf') \n"%(msName1)
                    casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_short_inf',\n"
                    casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                    casaCmd = casaCmd + "  selectdata = True,\n"
    #                casaCmd = casaCmd + "  antenna = '"+str(antList1)+"&',\n"
                    casaCmd = casaCmd + "  solint = 'inf',\n"
                    casaCmd = casaCmd + "  refant = '"+refant+"',\n"

                    if numAntList1 < 5:
                        casaCmd = casaCmd + "  minblperant = "+str(numAntList1-1)+",\n"
                        casaCmd = casaCmd + "  minsnr = 2.0,\n"

                    casaCmd = casaCmd + "  gaintype = '"+gaintypeForAmp+"',\n"
                    casaCmd = casaCmd + "  calmode = 'a',\n"
                    casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phase_short_int'])\n\n"

                    if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".ampli_short_inf', msName='"+msName1+"', interactive=False) \n\n"

                    casaCmd = casaCmd + "os.system('rm -rf %s.flux_short_inf') \n"%(msName1)
                    casaCmd = casaCmd + "os.system('rm -rf %s.fluxscale') \n"%(msName1)
                    casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                    casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                    if getCasaVersion() >= '4.2.0':
                        casaCmd = casaCmd + fluxscaleDictName[0] + " = fluxscale(vis = '"+msName1+"',\n"
                    else:
                        casaCmd = casaCmd + "fluxscale(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_short_inf',\n"
                    casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_short_inf',\n"
                    casaCmd = casaCmd + "  reference = '"+str(fluxCalId)+"') # "+fieldNames[fluxCalId]+"\n\n"
                    casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"
                    casaCmd = casaCmd + "if applyonly != True: es.fluxscale2(caltable = '"+msName1+".ampli_short_inf', removeOutliers=True, msName='"+msName+"', writeToFile=True, preavg=10000)\n\n"

                    if sciFieldIds[0] != '':

                        casaCmd = casaCmd + "f = open('"+msName1+".fluxscale')\n"
                        casaCmd = casaCmd + "fc = f.readlines()\n"
                        casaCmd = casaCmd + "f.close()\n\n"

                        #phaSourceId = intentSources['CALIBRATE_PHASE']['sourceid']
                        #ampSourceId = intentSources['CALIBRATE_AMPLI']['sourceid']
                        #phaOnlySourceId = [i for i in phaSourceId if i not in ampSourceId]
                        #phaOnlySourceId1 = dict.fromkeys(phaOnlySourceId).keys()
                        #if len(phaOnlySourceId1) != 1: casaCmd = casaCmd + "# Warning: there are more than one phase calibrator, I'm picking the one with the highest id. Please check this is right.\n\n"
                        #phaOnlySourceId = max(phaOnlySourceId1)

                        phaseCal = self.getPhaseCal(msName)
                        phaseCalNames = []
                        for i in phaseCal:
                            phaseCalNames.append(phaseCal[i]['phaseCalName'])

                        casaCmd = casaCmd + "for phaseCalName in "+str(list(set(phaseCalNames)))+":\n"
                        casaCmd = casaCmd + "  for i in range(len(fc)):\n"
                        #casaCmd = casaCmd + "    if re.search('Flux density for '+phaseCalName+' in SpW=[0-9]+ is: [0-9]+\.[0-9]+', fc[i]) is not None:\n"
                        casaCmd = casaCmd + "    if fc[i].find('Flux density for '+phaseCalName) != -1 and re.search('in SpW=[0-9]+(?: \(.*?\))? is: [0-9]+\.[0-9]+', fc[i], re.DOTALL|re.IGNORECASE) is not None:\n"
                        #casaCmd = casaCmd + "      line = (re.findall('in SpW=[0-9]+ is: [0-9]+\.[0-9]+', fc[i]))[0]\n"
                        casaCmd = casaCmd + "      line = (re.search('in SpW=[0-9]+(?: \(.*?\))? is: [0-9]+\.[0-9]+', fc[i], re.DOTALL|re.IGNORECASE)).group(0)\n"
                        casaCmd = casaCmd + "      spwId = (line.split('='))[1].split()[0]\n"
                        casaCmd = casaCmd + "      flux = float((line.split(':'))[1].split()[0])\n"
                        casaCmd = casaCmd + "      setjy(vis = '"+msName1+"',\n"
                        casaCmd = casaCmd + "        field = phaseCalName.replace(';','*;').split(';')[0],\n"
                        casaCmd = casaCmd + "        spw = spwId,\n"
                        if (getCasaVersion() >= '4.2.0'): casaCmd = casaCmd + "        standard = 'manual',\n"
                        casaCmd = casaCmd + "        fluxdensity = [flux,0,0,0])\n\n"


                        casaCmd = casaCmd + "os.system('rm -rf %s.phase_int') \n"%(msName1)
                        casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                        casaCmd = casaCmd + "  caltable = '"+msName1+".phase_int',\n"
                        casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                        casaCmd = casaCmd + "  solint = 'int',\n"
                        casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                        casaCmd = casaCmd + "  gaintype = 'G',\n"
                        casaCmd = casaCmd + "  calmode = 'p',\n"
                        casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                        if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_int', msName='"+msName1+"', interactive=False) \n\n"

                        casaCmd = casaCmd + "os.system('rm -rf %s.flux_inf') \n"%(msName1)
                        casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                        casaCmd = casaCmd + "  caltable = '"+msName1+".flux_inf',\n"
                        casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                        casaCmd = casaCmd + "  solint = 'inf',\n"
                        casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                        casaCmd = casaCmd + "  gaintype = '"+gaintypeForAmp+"',\n"
                        casaCmd = casaCmd + "  calmode = 'a',\n"
                        casaCmd = casaCmd + "  gaintable = ['"+bandpass+"', '"+msName1+".phase_int'])\n\n"

                        if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".flux_inf', msName='"+msName1+"', interactive=False) \n\n"

                        #casaCmd = casaCmd + "mylogfile = casalog.logfile()\n"
                        #casaCmd = casaCmd + "casalog.setlogfile('"+msName1+".fluxscale')\n\n"
                        #casaCmd = casaCmd + "fluxscale(vis = '"+msName1+"',\n"
                        #casaCmd = casaCmd + "  caltable = '"+msName1+".ampli_inf',\n"
                        #casaCmd = casaCmd + "  fluxtable = '"+msName1+".flux_inf',\n"
                        #casaCmd = casaCmd + "  reference = '"+str(phaOnlySourceId)+"') # "+fieldNames[phaOnlySourceId]+"\n\n"
                        #casaCmd = casaCmd + "casalog.setlogfile(mylogfile)\n\n"

            if sciFieldIds[0] != '' and calmode2 == 'ap':
                casaCmd = casaCmd + "os.system('rm -rf %s.phase_inf') \n"%(msName1)
                casaCmd = casaCmd + "gaincal(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  caltable = '"+msName1+".phase_inf',\n"
                casaCmd = casaCmd + "  field = '"+calFieldIds1+"', # "+calFieldNames+"\n"
                casaCmd = casaCmd + "  solint = 'inf',\n"
                casaCmd = casaCmd + "  refant = '"+refant+"',\n"
                casaCmd = casaCmd + "  gaintype = 'G',\n"
                casaCmd = casaCmd + "  calmode = 'p',\n"
                casaCmd = casaCmd + "  gaintable = '"+bandpass+"')\n\n"

                if doplot == True: casaCmd = casaCmd + "if applyonly != True: es.checkCalTable('"+msName1+".phase_inf', msName='"+msName1+"', interactive=False) \n"

        return casaCmd

    def getRefAntenna(self, msName, minEl=40, percentile=85, lbc=False, minDays=20):

        if lbc == True: percentile=50

        if minDays != '':

            tb.open(msName+'/OBSERVATION')
            obsTimeRange = tb.getcol('TIME_RANGE')
            obsTime = (obsTimeRange[0]+obsTimeRange[1])/2.0
            obsTime = ((obsTime/86400.0)+2400000.5-2440587.5)*86400.0
            obsTime = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTime))
            obsTime = datetime.datetime.strptime(obsTime, '%Y-%m-%dT%H:%M:%S')
            tb.close()

            try:
                g=open(os.path.expanduser('~/AIV/science/PadData/antennaMoves.txt'), 'r')
            except:
                try:
                    mypath = self.locatePath('PadData/antennaMoves.txt')
                    g=open(mypath)
                except:
                    print "Failed to find path=%s" % (mypath)

            gc=g.read().splitlines()
            g.close()

            gc=sorted(gc)

            lastMove = {}

            for line in gc:

                line=line.strip()
                if (len(line) < 1): continue  # added by T. Hunter
                if line[0] == '#': continue
                ele=line.split()

                moveDate = datetime.datetime.strptime(ele[0], '%Y-%m-%dT%H:%M')

                if moveDate <= obsTime:

                    dateDiff = obsTime - moveDate
                    dateDiff = dateDiff.days + dateDiff.seconds / 86400.

                    lastMove[ele[1]] = dateDiff

        tb.open(msName+'/ANTENNA')
        antList = tb.getcol('NAME').tolist()
        antDiam = tb.getcol('DISH_DIAMETER').tolist()
        tb.close()

        baselineLen = getBaselineLengths(msName)

        antInfo = {}

        for i in antList:
            antInfo[i] = {}
            minLen = 100000.
            maxLen = 0.
            otherAntOnMinLen = ''
            for j in baselineLen:
                if i in j[0]:
                    if j[1] < minLen:
                        minLen = j[1]
                        antList1 = j[0].split('-')
                        antList1.pop(antList1.index(i))
                        otherAntOnMinLen = antList1[0]
                    if j[1] > maxLen: maxLen = j[1]
            antInfo[i]['otherAntOnMinLen'] = otherAntOnMinLen
            antInfo[i]['minLen'] = minLen
            antInfo[i]['maxLen'] = maxLen

        minLen = []
        for i in antInfo: minLen.append(antInfo[i]['minLen'])
        ij = int(ceil(percentile*len(minLen)/100.)-1)
        minLen1 = sorted(minLen)[ij]

        refAnt = ''
        maxLen = 100000.

        for i in antInfo:
            #if re.search('CM[0-9]{2}', i) is not None: continue
            diam1 = []
            diam1.append(antDiam[antList.index(i)])
            diam1.append(antDiam[antList.index(antInfo[i]['otherAntOnMinLen'])])
            if antInfo[i]['minLen'] > minLen1: continue
            if antInfo[i]['minLen'] < max(diam1) / sin(radians(minEl)): continue

            if minDays != '':
                if lastMove[i] <= minDays: continue

            if antInfo[i]['maxLen'] < maxLen:
                refAnt = i
                maxLen = antInfo[i]['maxLen']

        return refAnt

    def applyBandpassAndGainCalTables(self, msName, msName1='', iHaveSplitMyScienceSpw=False, bandpass='', phaseForCal='', phaseForSci='', flux='', phaseDiffCalTableName='', ampForSci='', useForLoop=True, phaseDiffPerSpwSetup=False):

        #casaCmd = 'print "# Application of the bandpass and gain cal tables."\n\n'
        casaCmd = ''

        if bandpass == '' or phaseForCal == '' or phaseForSci == '' or flux == '': sys.exit('ERROR: Missing table(s).')
        if msName1 == '': msName1 = msName

        tb.open(msName+'/FIELD')
        fieldNames = tb.getcol('NAME')
        tb.close()

        fieldIds = range(len(fieldNames))

        intentSources = self.getIntentsAndSourceNames(msName)
        sciFieldIds = intentSources['OBSERVE_TARGET']['id']
        if sciFieldIds[0] == '': sys.exit('ERROR: There seems to be no science field.')

        checkFieldIds = intentSources['OBSERVE_CHECK']['id']
        if checkFieldIds[0] != '':
            sciFieldIds += intentSources['OBSERVE_CHECK']['id']

        calFieldIds = [i for i in fieldIds if i not in sciFieldIds]
        if len(calFieldIds) == '': sys.exit('ERROR: There seems to be no calibrator field.')

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = msmdtool()
            mymsmd.open(msName)
            hasdata = []
            for i in calFieldIds:
                calFieldIntents = mymsmd.intentsforfield(i)
                hasdata1 = 0
                for j in calFieldIntents:
                    if re.search('^CALIBRATE_(POINTING|ATMOSPHERE|WVR)', j) == None:
                        hasdata1 = 1
                        break
                hasdata.append(hasdata1)
            mymsmd.close()

            calFieldIds = [calFieldIds[i] for i in range(len(calFieldIds)) if hasdata[i] == 1]

###

        if len(phaseDiffCalTableName) != 0:

            if phaseDiffPerSpwSetup == True:
                mymsmd = msmdtool()
                mymsmd.open(msName)

                spwIds3 = mymsmd.spwsforintent('CALIBRATE_BANDPASS*').tolist()+mymsmd.spwsforintent('OBSERVE_TARGET*').tolist()
                spwIds3 = np.unique([j for j in spwIds3 if j not in mymsmd.chanavgspws() and j not in mymsmd.wvrspws()]).tolist()

#                 spwSetups = []
#                 for i in mymsmd.scannumbers():
#                     spwIds4 = [j for j in mymsmd.spwsforscan(i) if j in spwIds3]
#                     if len(spwIds4) != 0: spwSetups.append(spwIds4)
#                 spwSetups1 = []
#                 for i in spwSetups:
#                     if i not in spwSetups1: spwSetups1.append(i)
#                 spwSetups1.sort(key=lambda x:x[0])

                spwSetups = {}
                for i in spwIds3:
                    scanList3 = str(mymsmd.scansforspw(i).tolist())
                    if scanList3 not in spwSetups.keys(): spwSetups[scanList3] = []
                    spwSetups[scanList3].append(i)
                spwSetups1 = []
                for i in spwSetups.values():
                    if i not in spwSetups1: spwSetups1.append(i)
                spwSetups1.sort(key=lambda x:x[0])

                calspwmap = []
                for i in range(len(spwSetups1)):
                    for j in range(len(spwSetups1[i])):
                        calspwmap.append(min(spwSetups1[i]))

                if iHaveSplitMyScienceSpw == True:

                    for i in range(len(spwSetups1)):
                        for j in range(len(spwSetups1[i])):
                            spwSetups1[i][j] = spwIds3.index(spwSetups1[i][j])

                    for i in range(len(calspwmap)):
                        calspwmap[i] = spwIds3.index(calspwmap[i])

                casaCmd = casaCmd + "calspwmap = "+str(calspwmap)+"\n\n"

                mymsmd.close()

            else:
                mymsmd = msmdtool()
                mymsmd.open(msName)

                if iHaveSplitMyScienceSpw == True:
                    spwInfo3 = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
                    spwIds3 = sorted(spwInfo3.keys())
                    numSpws = len(spwIds3)
                else:
                    numSpws = mymsmd.nspw()

                calspwmap = {}

                for i in calFieldIds:

                    fieldSpws = mymsmd.spwsforfield(i)

                    if iHaveSplitMyScienceSpw == True:
                        fieldSpws = [spwIds3.index(j) for j in fieldSpws if j in spwIds3]

                    calspwmap[i] = [min(fieldSpws)] * numSpws

                mymsmd.close()

                casaCmd = casaCmd + "calspwmap = "+repr(calspwmap)+"\n\n"

###

        phaseCal = self.getPhaseCal(msName)
        phaseCalFieldIds = []
        for j in phaseCal:
            phaseCalFieldIds.append(phaseCal[j]['phaseCalId'])
        phaseCalFieldIds = sorted(dict.fromkeys(phaseCalFieldIds).keys())
        calFieldIds = [i for i in calFieldIds if i not in phaseCalFieldIds]
        calFieldIds1 = [str(i) for i in calFieldIds]

        calFieldNames = [fieldNames[i] for i in calFieldIds]
        calFieldNames = ','.join(calFieldNames)

        gainTable = []
        gainTable.append(bandpass)

        if len(phaseDiffCalTableName) == 0:

            gainTable.append(phaseForCal)
            gainTable.append(flux)

            if useForLoop == True:
                casaCmd = casaCmd + "for i in "+str(calFieldIds1)+": # "+calFieldNames+"\n"
                casaCmd = casaCmd + "  applycal(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "    field = str(i),\n"
                casaCmd = casaCmd + "    gaintable = "+str(gainTable)+",\n"
                casaCmd = casaCmd + "    gainfield = ['', i, i],\n"
                if re.search('^3.3', getCasaVersion()) == None:
                    casaCmd = casaCmd + "    interp = 'linear,linear',\n"
                else:
                    casaCmd = casaCmd + "    interp = 'linear',\n"
                if getCasaVersion() <= '4.2.2':
                    casaCmd = casaCmd + "    calwt = False,\n"
                else:
                    casaCmd = casaCmd + "    calwt = True,\n"
                casaCmd = casaCmd + "    flagbackup = False)\n"
            else:
                for i in calFieldIds:
                    casaCmd = casaCmd + "applycal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  field = '"+str(i)+"', # "+fieldNames[i]+"\n"
                    casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
                    casaCmd = casaCmd + "  gainfield = ['', '"+str(i)+"', '"+str(i)+"'],\n"
                    if re.search('^3.3', getCasaVersion()) == None:
                        casaCmd = casaCmd + "  interp = 'linear,linear',\n"
                    else:
                        casaCmd = casaCmd + "  interp = 'linear',\n"
                    if getCasaVersion() <= '4.2.2':
                        casaCmd = casaCmd + "  calwt = False,\n"
                    else:
                        casaCmd = casaCmd + "  calwt = True,\n"
                    casaCmd = casaCmd + "  flagbackup = False)\n\n"

        else:

                gainTable.append(phaseDiffCalTableName[0])
                gainTable.append(phaseForCal)

                bpassCalId = intentSources['CALIBRATE_BANDPASS']['id']

                if bpassCalId[0] != '':

                    if len(bpassCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one bandpass calibrator, I'm picking the first one: "+fieldNames[bpassCalId[0]]+".\n"
                    bpassCalId = bpassCalId[0]

                else:

                    casaCmd = casaCmd + "# Note: there are no bandpass calibrator, I'm picking a phase calibrator.\n"
                    phaseCalId = intentSources['CALIBRATE_PHASE']['id']
                    ampCalId = intentSources['CALIBRATE_AMPLI']['id'] + intentSources['CALIBRATE_FLUX']['id']
                    ampCalId = [i for i in ampCalId if i != '']
                    phaseOnlyCalId = [i for i in phaseCalId if i not in ampCalId]
                    if len(phaseOnlyCalId) != 1: casaCmd = casaCmd + "# Note: there are more than one phase calibrator, I'm picking the first one: "+fieldNames[phaseOnlyCalId[0]]+".\n"
                    bpassCalId = phaseOnlyCalId[0]

                casaCmd = casaCmd + "applycal(vis = '"+msName1+"',\n"
                casaCmd = casaCmd + "  field = '"+str(bpassCalId)+"', # "+fieldNames[bpassCalId]+"\n"
                casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
                casaCmd = casaCmd + "  gainfield = ['"+str(bpassCalId)+"', '', '"+str(bpassCalId)+"'],\n"
                casaCmd = casaCmd + "  interp = [],\n"

                if phaseDiffPerSpwSetup == True:
                    casaCmd = casaCmd + "  spwmap = [[], [], calspwmap],\n"
                else:
                    casaCmd = casaCmd + "  spwmap = [[], [], calspwmap["+str(bpassCalId)+"]],\n"

                if getCasaVersion() <= '4.2.2':
                    casaCmd = casaCmd + "  calwt = False,\n"
                else:
                    casaCmd = casaCmd + "  calwt = True,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

                gainTable.append(ampForSci[0])

                for i in calFieldIds:

                    if i == bpassCalId: continue

                    casaCmd = casaCmd + "applycal(vis = '"+msName1+"',\n"
                    casaCmd = casaCmd + "  field = '"+str(i)+"', # "+fieldNames[i]+"\n"
                    casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
                    casaCmd = casaCmd + "  gainfield = ['', '', '"+str(i)+"', '"+str(i)+"'],\n"
                    casaCmd = casaCmd + "  interp = ['', 'nearest', 'linearPD', ''],\n"

                    if phaseDiffPerSpwSetup == True:
                        casaCmd = casaCmd + "  spwmap = [[], [], calspwmap, calspwmap],\n"
                    else:
                        casaCmd = casaCmd + "  spwmap = [[], [], calspwmap["+str(i)+"], calspwmap["+str(i)+"]],\n"

                    if getCasaVersion() <= '4.2.2':
                        casaCmd = casaCmd + "  calwt = False,\n"
                    else:
                        casaCmd = casaCmd + "  calwt = True,\n"
                    casaCmd = casaCmd + "  flagbackup = False)\n\n"

        gainTable = []
        gainTable.append(bandpass)

        if re.search('^3.3', getCasaVersion()) == None:
            gainTableInterp = "'linear,linear'"
        else:
            gainTableInterp = "'linear'"

        if len(phaseDiffCalTableName) != 0:

            if len(ampForSci) != 1: sys.exit('ERROR: missing table')

            gainTable.append(phaseDiffCalTableName[0])
            gainTable.append(phaseForSci)
            gainTable.append(ampForSci[0])
            gainTable.append(flux)

            gainTableInterp = "['', 'nearest', 'linearPD', '', '']"

        else:

            gainTable.append(phaseForSci)
            gainTable.append(flux)

        for i in phaseCalFieldIds:

            sciFieldIds = []
            sciFieldNames = []
            for j in phaseCal:
                if phaseCal[j]['phaseCalId'] == i:
                    sciFieldIds1 = phaseCal[j]['sciFieldIds']
                    for k in sciFieldIds1: sciFieldIds.append(k)
                    sciFieldNames.append(j)
            sciFieldIds = sorted(sciFieldIds)
            sciFieldNames = ','.join(sciFieldNames)

            if len(sciFieldIds) > 1:
                j0 = 0
                sciFieldIds1 = str(sciFieldIds[j0])
                for j in range(len(sciFieldIds)-1):
                    if sciFieldIds[j+1] == sciFieldIds[j]+1: continue
                    sciFieldIds1 = sciFieldIds1 + '~' + str(sciFieldIds[j])
                    j0 = j+1
                    sciFieldIds1 = sciFieldIds1 + ',' + str(sciFieldIds[j0])
                sciFieldIds1 = sciFieldIds1 + '~' + str(sciFieldIds[j+1])
            else:
                sciFieldIds1 = str(sciFieldIds[0])

            if phaseDiffPerSpwSetup == True:
                mymsmd = msmdtool()
                mymsmd.open(msName)

                spwIds4 = mymsmd.spwsforfield(i).tolist()
                spwIds4 = [j for j in spwIds4 if j not in mymsmd.chanavgspws() and j in spwIds3]

                calspwmap = []
                for k in range(len(spwSetups1)):
                    for j in range(len(spwSetups1[k])):
                        calspwmap.append(min(spwIds4))

                if iHaveSplitMyScienceSpw == True:

                    for k in range(len(calspwmap)):
                        calspwmap[k] = spwIds3.index(calspwmap[k])

                casaCmd = casaCmd + "calspwmap = "+str(calspwmap)+"\n\n"

                mymsmd.close()

            casaCmd = casaCmd + "\napplycal(vis = '"+msName1+"',\n"
            casaCmd = casaCmd + "  field = '"+str(i)+","+sciFieldIds1+"', # "+sciFieldNames+"\n"
            casaCmd = casaCmd + "  gaintable = "+str(gainTable)+",\n"
            if len(phaseDiffCalTableName) != 0:
                casaCmd = casaCmd + "  gainfield = ['', '', '"+str(i)+"', '"+str(i)+"', '"+str(i)+"'], # "+fieldNames[i]+"\n"
            else:
                casaCmd = casaCmd + "  gainfield = ['', '"+str(i)+"', '"+str(i)+"'], # "+fieldNames[i]+"\n"
            casaCmd = casaCmd + "  interp = "+gainTableInterp+",\n"
            if len(phaseDiffCalTableName) != 0:
                if phaseDiffPerSpwSetup == True:
                    casaCmd = casaCmd + "  spwmap = [[], [], calspwmap, calspwmap, calspwmap,\n"
                else:
                    casaCmd = casaCmd + "  spwmap = [[], [], calspwmap["+str(i)+"], calspwmap["+str(i)+"], calspwmap["+str(i)+"]],\n"
            if getCasaVersion() <= '4.2.2':
                casaCmd = casaCmd + "  calwt = False,\n"
            else:
                casaCmd = casaCmd + "  calwt = True,\n"
            casaCmd = casaCmd + "  flagbackup = False)\n"

        return casaCmd

    def getPhaseCal(self, msName):
        print "Running ValueMapping"
        vm = ValueMapping(msName)
        print "Completed ValueMapping"
        scanList = vm.uniqueScans

        phaseOnlyScanList = []
        for i in scanList:
            scanIntents = vm.getIntentsForScan(i)
            isPhaseOnlyScan = 1
            for j in scanIntents:
                scanIntent = (j.split('#'))[0]
                if re.search('^CALIBRATE_((PHASE)|(WVR))$', scanIntent) == None:
                    isPhaseOnlyScan = 0
                    break
            if isPhaseOnlyScan == 1: phaseOnlyScanList.append(i)

        if len(phaseOnlyScanList) != 0:

            phaseCal = {}

            for i in phaseOnlyScanList:
                scanField = vm.getFieldsForScan(i)
                if len(scanField) != 1: sys.exit('ERROR: Unexpected number of fields.')
                scanField = scanField[0]
                if scanField not in phaseCal:
                    phaseCal[scanField] = {}
                    phaseCal[scanField]['scans'] = []
                phaseCal[scanField]['scans'].append(i)

            for i in phaseCal:
                scanList = range(min(phaseCal[i]['scans']), max(phaseCal[i]['scans'])+1)
                scanList = [j for j in scanList if j not in phaseCal[i]['scans']]
                fieldList = []
                for j in scanList:
                    fieldList1 = vm.getFieldsForScan(j)
                    for k in fieldList1: fieldList.append(k)
                fieldList = sorted(dict.fromkeys(fieldList).keys())
                phaseCal[i]['fieldNames'] = fieldList

            tb.open(msName+'/FIELD')
            fieldNames = tb.getcol('NAME')
            sourceIds = tb.getcol('SOURCE_ID')
            tb.close()

            intentSources = self.getIntentsAndSourceNames(msName)
            sciFieldIds = intentSources['OBSERVE_TARGET']['id']
            if sciFieldIds[0] == '':
#                 sys.exit('ERROR: There seems to be no science field.')
                print "WARNING: There seems to be no science field."
                return {}
            sciFieldNames = intentSources['OBSERVE_TARGET']['name']

            checkFieldIds = intentSources['OBSERVE_CHECK']['id']
            if checkFieldIds[0] != '':
                sciFieldIds += intentSources['OBSERVE_CHECK']['id']
                sciFieldNames += intentSources['OBSERVE_CHECK']['name']

            phaseCal1 = {}

            for i in sciFieldNames:
                phaseCal1[i] = {}
                sciFieldIds1 = np.where(fieldNames == i)[0].tolist()
                sciFieldIds1 = [j for j in sciFieldIds1 if j in sciFieldIds]
                sciSourceIds1 = [sourceIds[j] for j in sciFieldIds1]
                phaseCal1[i]['sciFieldIds'] = sciFieldIds1
                phaseCal1[i]['sciSourceIds'] = sciSourceIds1
                phaseCalNames = []
                phaseCalFirstScan = []
                for j in phaseCal:
                    if i in phaseCal[j]['fieldNames']:
                        phaseCalNames.append(j)
                        phaseCalFirstScan.append(min(phaseCal[j]['scans']))
                if len(phaseCalNames) == 0 or len(phaseCalFirstScan) == 0:
                    print "WARNING: I couldn't find reliably a phase cal for field "+i+" so I picked the first one in the list, note this may be wrong."
                    j = phaseCal.keys()[0]
                    phaseCalNames.append(j)
                    phaseCalFirstScan.append(min(phaseCal[j]['scans']))
                phaseCal1[i]['phaseCalName'] = phaseCalNames[phaseCalFirstScan.index(min(phaseCalFirstScan))]
                #phaseCalId = np.where(fieldNames == phaseCal1[i]['phaseCalName'])[0].tolist()
                #phaseCalId = [j for j in phaseCalId if j in intentSources['CALIBRATE_PHASE']['id']]
                phaseCalId = []
                for j in vm.getFieldIdsForFieldName(phaseCal1[i]['phaseCalName']):
                    if min(phaseCalFirstScan) in vm.getScansForFieldID(j): phaseCalId.append(j)
                phaseCalId = sorted(dict.fromkeys(phaseCalId).keys())
                if len(phaseCalId) != 1: sys.exit('ERROR: Possible confusion between field ids.')
                phaseCal1[i]['phaseCalId'] = phaseCalId[0]
                phaseCal1[i]['allPhaseCalNames'] = phaseCalNames

            return phaseCal1

    def doFluxCalibration(self, msNames, fluxFile='allFluxes.txt', refant=''):

        if type(msNames).__name__ == 'str': msNames = [msNames]

        if os.path.exists(fluxFile) == False: sys.exit('ERROR: Flux file '+fluxFile+' does not seem to exist in the current directory.')

        casaCmd = 'print "# Flux calibration of the data."\n\n'

#         for i in range(len(msNames)): casaCmd = casaCmd + self.split2(msNames[i], outMsName=msNames[i]+'.cal')

        f = open(fluxFile, 'r')
        fc = f.readlines()
        f.close()

        msName = []
        fieldName = []
        spwId = []
        fluxVal = []

        for line in fc:

            if len(line) == 0 or line.isspace() == True or line.lstrip()[0] == '#': continue

            casaCmd = casaCmd + '# ' + line

            line = line.split('"')
            fieldName.append(line[1])
            line = line[2].split()
            spwId.append(line[0])
            fluxVal.append(line[3])
            msName.append(line[5])

        msName = np.array(msName)
        fieldName = np.array(fieldName)

        casaCmd = casaCmd + '\n'

        for i in range(len(msName)):

            if msName[i] not in msNames: sys.exit('ERROR: Missing dataset.')

            casaCmd = casaCmd + "setjy(vis = '"+msName[i]+"',\n"
            casaCmd = casaCmd + "  field = '"+fieldName[i]+"',\n"
            casaCmd = casaCmd + "  spw = '"+spwId[i]+"',\n"
            if (getCasaVersion() >= '4.2.0'): casaCmd = casaCmd + "  standard = 'manual',\n"
            casaCmd = casaCmd + "  fluxdensity = ["+fluxVal[i]+", 0, 0, 0])\n\n"

        for i in range(len(msNames)):

            calFieldNames = np.unique(fieldName[np.where(msName == msNames[i])])
            calFieldNames = ','.join(calFieldNames)

            #myRefAnt = self.getRefAntenna(msNames[i])
            myRefAnt = refant
            if myRefAnt == '': myRefAnt = self.getRefAntenna(msNames[i])
            casaCmd = casaCmd + "os.system('rm -rf %s.ampli_inf') \n"%(msNames[i])
            casaCmd = casaCmd + "gaincal(vis = '"+msNames[i]+"',\n"
            casaCmd = casaCmd + "  caltable = '"+msNames[i]+".ampli_inf',\n"
            casaCmd = casaCmd + "  field = '"+calFieldNames+"',\n"
            casaCmd = casaCmd + "  solint = 'inf',\n"
            casaCmd = casaCmd + "  combine = 'scan',\n"
            casaCmd = casaCmd + "  refant = '"+myRefAnt+"',\n"
            casaCmd = casaCmd + "  gaintype = 'T',\n"
            casaCmd = casaCmd + "  calmode = 'a')\n\n"

            phaseCal = self.getPhaseCal(msNames[i])

            for sciFieldName in phaseCal.keys():

                sciFieldIds = phaseCal[sciFieldName]['sciFieldIds']

                if len(sciFieldIds) > 1:
                    j0 = 0
                    sciFieldIds1 = str(sciFieldIds[j0])
                    for j in range(len(sciFieldIds)-1):
                        if sciFieldIds[j+1] == sciFieldIds[j]+1: continue
                        sciFieldIds1 = sciFieldIds1 + '~' + str(sciFieldIds[j])
                        j0 = j+1
                        sciFieldIds1 = sciFieldIds1 + ',' + str(sciFieldIds[j0])
                    sciFieldIds1 = sciFieldIds1 + '~' + str(sciFieldIds[j+1])
                else:
                    sciFieldIds1 = str(sciFieldIds[0])

                casaCmd = casaCmd + "applycal(vis = '"+msNames[i]+"',\n"
                casaCmd = casaCmd + "  field = '"+str(phaseCal[sciFieldName]['phaseCalId'])+","+sciFieldIds1+"', # "+phaseCal[sciFieldName]['phaseCalName']+","+sciFieldName+"\n"
                casaCmd = casaCmd + "  gaintable = '"+msNames[i]+".ampli_inf',\n"
                casaCmd = casaCmd + "  gainfield = '"+str(phaseCal[sciFieldName]['phaseCalId'])+"', # "+phaseCal[sciFieldName]['phaseCalName']+"\n"
                casaCmd = casaCmd + "  calwt = False,\n"
                casaCmd = casaCmd + "  flagbackup = False)\n\n"

        if len(msNames) > 1:
            casaCmd = casaCmd + 'print "# Concatenating the data."\n\n'
            casaCmd = casaCmd + "concat(vis = "+str([i for i in msNames])+",\n"
            casaCmd = casaCmd + "  concatvis = 'calibrated.ms')\n\n"

        return casaCmd

    def generateFluxFile(self, msNames, outfile='allFluxes.txt'):

        if type(msNames).__name__ == 'str': msNames = [msNames]

        msNames = sorted(msNames)

        spwInfo = self.getSpwInfo(msNames[0])
        spwIds = sorted(spwInfo.keys())

        vm = ValueMapping(msNames[0])
        spwMeanFreq = []
        for i in spwIds: spwMeanFreq.append(vm.spwInfo[i]['meanFreq'] / 1.e9)

        fluxVal = {}

        for i in range(len(msNames)):

            spwInfo = self.getSpwInfo(msNames[i])
            if sorted(spwInfo.keys()) != spwIds: sys.exit('ERROR: The number of spw ids is not the same in all datasets.')

            vm = ValueMapping(msNames[i])
            for j in range(len(spwIds)):
                if vm.spwInfo[spwIds[j]]['meanFreq'] / 1.e9 != spwMeanFreq[j]: print 'WARNING: The mean frequency of spw '+str(spwIds[j])+' of dataset '+msNames[i]+' differs from that of the first dataset.'

            if os.path.exists(msNames[i]+'.fluxscale') != True:
                print 'WARNING: Could not find a .fluxscale file associated to '+msNames[i]+'. Looking for any .fluxscale file.'
                msNameBase = re.findall('^uid___[0-9a-z]+_[0-9a-z]+_[0-9a-z]+', msNames[i], re.IGNORECASE)
                if len(msNameBase) != 1:
                    print 'WARNING: I failed.'
                    continue
                msNameBase = msNameBase[0]
                fluxscaleFilename = glob.glob('*.fluxscale')
                if len(fluxscaleFilename) == 0:
                    print 'WARNING: I failed.'
                    continue
                found = 0
                for j in range(len(fluxscaleFilename)):
                    if re.search(msNameBase, fluxscaleFilename[j]) is not None:
                        fluxscaleFilename = fluxscaleFilename[j]
                        print 'Found '+fluxscaleFilename
                        found = 1
                        break
                if found == 0:
                    print 'WARNING: I failed.'
                    continue
            else:
                fluxscaleFilename = msNames[i]+'.fluxscale'

            f = open(fluxscaleFilename, 'r')
            fc = f.readlines()
            f.close()

            for j in range(len(fc)):
                if re.search('Flux density for .+ in SpW=[0-9]+(?: \(.*?\))? is: [0-9]+\.[0-9]+ \+/- [0-9]+\.[0-9]+', fc[j], re.DOTALL|re.IGNORECASE) is not None:
                    line = (re.findall('Flux density for .+ in SpW=[0-9]+(?: \(.*?\))? is: [0-9]+\.[0-9]+ \+/- [0-9]+\.[0-9]+', fc[j], re.DOTALL|re.IGNORECASE))[0]
                    fieldName = (re.findall('for .+ in', line, re.IGNORECASE))[0]
                    fieldName = fieldName[4:len(fieldName)-3]
                    spwId = (re.findall('in SpW=[0-9]+', line, re.IGNORECASE))[0]
                    spwId = int((spwId.split('='))[1])
                    flux = (re.findall('is: [0-9]+\.[0-9]+ \+/- [0-9]+\.[0-9]+', line, re.IGNORECASE))[0]
                    flux1 = float(flux.split()[1])
                    error1 = float(flux.split()[3])
                    if fieldName not in fluxVal: fluxVal[fieldName] = {}
                    if spwId not in fluxVal[fieldName]:
                        fluxVal[fieldName][spwId] = {}
                        fluxVal[fieldName][spwId]['flux'] = []
                        fluxVal[fieldName][spwId]['error'] = []
                        fluxVal[fieldName][spwId]['msName'] = []
                    fluxVal[fieldName][spwId]['flux'].append(flux1)
                    fluxVal[fieldName][spwId]['error'].append(error1)
                    fluxVal[fieldName][spwId]['msName'].append(msNames[i])

        #if len(fluxVal) == 0: sys.exit('ERROR: No fluxscale file found.')

        if len(fluxVal) != 0:
            for fieldName in fluxVal:
                for spwId in fluxVal[fieldName]:
                    sum1 = 0.
                    sum2 = 0.
                    for i in range(len(fluxVal[fieldName][spwId]['flux'])):
                        sum1 = sum1 + fluxVal[fieldName][spwId]['flux'][i] / fluxVal[fieldName][spwId]['error'][i]**2
                        sum2 = sum2 + 1. / fluxVal[fieldName][spwId]['error'][i]**2
                    meanFlux = sum1 / sum2
                    #meanFlux = np.mean(fluxVal[fieldName][spwId]['flux'])
                    fluxVal[fieldName][spwId]['meanFlux'] = meanFlux

        obsTime = []
        calFieldNames = []

        for msName in msNames:

            tb.open(msName+'/OBSERVATION')
            obsTimeRange = tb.getcol('TIME_RANGE')
            tb.close()

            obsTime1 = (obsTimeRange[0]+obsTimeRange[1])/2.0
            obsTime1 = ((obsTime1/86400.0)+2400000.5-2440587.5)*86400.0
            obsTime1 = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTime1))
            obsTime.append(obsTime1)

#            intentSources = self.getIntentsAndSourceNames(msName)
#            bpassCalFieldName = intentSources['CALIBRATE_BANDPASS']['name']

            phaseCal = self.getPhaseCal(msName)
            phaseCalFieldNames = []
            for i in phaseCal.keys(): phaseCalFieldNames.append(phaseCal[i]['allPhaseCalNames'])

            calFieldNames1 = []
#            for i in bpassCalFieldName: calFieldNames1.append(i)
            for i in phaseCalFieldNames:
                for j in i: calFieldNames1.append(j)
            calFieldNames1 = sorted(dict.fromkeys(calFieldNames1).keys())
            calFieldNames.append(calFieldNames1)

        calFieldNames2 = []
        for i in calFieldNames:
            for j in i: calFieldNames2.append(j)
        calFieldNames2 = sorted(dict.fromkeys(calFieldNames2).keys())

        f1 = open(outfile, 'w')

        for fieldName in calFieldNames2:

            print >> f1, ''

            for spwId in spwIds:
                for msName in msNames:

                    fieldName1 = '"'+fieldName+'"'
                    line = '%50s ' %fieldName1 + '%5d ' %spwId + '%10.2f ' %spwMeanFreq[spwIds.index(spwId)]

                    found = 0
                    if fieldName in fluxVal:
                        if spwId in fluxVal[fieldName]:
                            if msName in fluxVal[fieldName][spwId]['msName']:
                                k = fluxVal[fieldName][spwId]['msName'].index(msName)
                                line = line + '%12.5f ' %fluxVal[fieldName][spwId]['flux'][k]
                                found = 1
                    if found == 0: line = line + '           -'

                    found = 0
                    if fieldName in fluxVal:
                        if spwId in fluxVal[fieldName]:
                            line = line + '%12.5f ' %fluxVal[fieldName][spwId]['meanFlux']
                            found = 1
                    if found == 0: line = line + '           -'

                    k = msNames.index(msName)
                    line = line + '%25s ' %obsTime[k] + ' %40s' %msName

                    print >> f1, line

        f1.close()

    def split2(self, msName, msName1='', outMsName='', splitMyScienceSpw=False, timebin=0., iHaveSplitMyScienceSpw=False, allowHybrid=True, intentsToDiscard=''):

        #casaCmd = 'print "# Splitting the data."\n\n'
        casaCmd = ''

        if msName1 == '': msName1 = msName
        if outMsName == '': outMsName = msName1+'.split'

        spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')
        spwIds = sorted(spwInfo.keys())

        if intentsToDiscard != '':

            if getCasaVersion() < casaVersionWithMSMD: sys.exit('ERROR')
            mymsmd = msmdtool()
            mymsmd.open(msName)

            if iHaveSplitMyScienceSpw == True:

                listOfIntents = []

                for i in spwIds:
                    for j in mymsmd.intentsforspw(i):
                        listOfIntents.append(j)

                listOfIntents = np.unique(listOfIntents).tolist()

            else:

                listOfIntents = mymsmd.intents()

            mymsmd.close()

            listOfIntents = [i for i in listOfIntents if re.search(intentsToDiscard, i, re.IGNORECASE) == None]

        if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))
        spwIds = ['%d' %i for i in spwIds]
        spwIds = ','.join(spwIds)

        numChans = []
        for i in sorted(spwInfo.keys()): numChans.append(spwInfo[i]['numChans'])
        if max(numChans) <= 256 and timebin != 0: casaCmd = casaCmd + "# Important note: the correlator mode for this dataset was TDM, you may want not to do any time averaging.\n\n"

        if allowHybrid != True:

            tb.open(msName+'/ANTENNA')
            antDiam = tb.getcol('DISH_DIAMETER')
            antNames = tb.getcol('NAME')
            tb.close()

            antDiam1 = np.unique(antDiam)

            antNames2 = ''

            if len(antDiam1) != 1:

                numAnts = {}
                for i in range(len(antDiam1)):
                    numAnts[antDiam1[i]] = len(np.where(antDiam == antDiam1[i])[0])

                numAntsMax = max(numAnts.values())

                antDiam2 = []
                for i in range(len(antDiam1)):
                    if numAnts[antDiam1[i]] == numAntsMax:
                        antDiam2.append(antDiam1[i])
                if len(antDiam2) != 1: sys.exit('ERROR')
                antDiam2 = antDiam2[0]

                ij = np.where(antDiam == antDiam2)
                antNames1 = antNames[ij]

                antNames2 = []
                for i in range(len(antNames1)):
                    antNames3 = re.findall('^[a-z]+', antNames1[i], re.IGNORECASE)
                    if len(antNames3) == 0: continue
                    antNames2.append(antNames3[0]+'*')
                antNames2 = ','.join(np.unique(antNames2).tolist())+'&'
                
        casaCmd = casaCmd + "os.system('rm -rf %s') \n"%(outMsName)
        casaCmd = casaCmd + "os.system('rm -rf %s.flagversions') \n\n"%(outMsName)
        if intentsToDiscard != '': casaCmd = casaCmd + "listOfIntents = %s\n\n"%(pprint.pformat(listOfIntents))
        casaCmd = casaCmd + "split(vis = '"+msName1+"',\n"
        casaCmd = casaCmd + "  outputvis = '"+outMsName+"',\n"
        casaCmd = casaCmd + "  datacolumn = 'corrected',\n"
        if splitMyScienceSpw == True: casaCmd = casaCmd + "  spw = '"+spwIds+"',\n"
        if intentsToDiscard != '': casaCmd = casaCmd + "  intent = ','.join(listOfIntents),\n"        
        if timebin != 0.: casaCmd = casaCmd + "  timebin = '"+str(timebin)+"s',\n"
        if allowHybrid != True and antNames2 != '': casaCmd = casaCmd + "  antenna = '"+antNames2+"',\n"
        casaCmd = casaCmd + "  keepflags = True)\n\n"

        return casaCmd

    def runCleanOnSource(self, msName, sourceId='', searchForLines=False, chanWid=1, angScale=0, iHaveSplitMyScienceSpw=False):

        import bisect
        import itertools
#        import matplotlib.pyplot as plt

        optimumImsize = [128, 216, 256, 360, 432, 640, 800, 1000, 1296, 1600, 2048]

        casaCmd = 'print "# Running clean."\n\n'

        tb.open(msName+'/FIELD')
        sourceIds = tb.getcol('SOURCE_ID')
        fieldNames = tb.getcol('NAME')
        tb.close()

        if sourceId == '':
            casaCmd = casaCmd + '# You have not specified a source Id, I will assume you want to clean the science target(s).\n\n'
            intentSources = self.getIntentsAndSourceNames(msName)
            sourceId = sorted(dict.fromkeys(intentSources['OBSERVE_TARGET']['sourceid']).keys())
            sourceId = ['%s' %i for i in sourceId]
        myim = imtool()
        myim.open(msName)
        imInfo = myim.advise()
        myim.close()

        if re.search('^3.', getCasaVersion()) == None:
            if imInfo[2]['unit'] != 'arcsec': sys.exit('ERROR: Cell unit not supported.')
            cellsizeInArcsec = imInfo[2]['value'] * 0.5
        else:
            if imInfo['cell']['unit'] != 'arcsec': sys.exit('ERROR: Cell unit not supported.')
            cellsizeInArcsec = imInfo['cell']['value'] * 0.5

        if cellsizeInArcsec > 0.2:
            cellsizeInArcsec = np.int(cellsizeInArcsec*20)/20.0
        elif cellsizeInArcsec > 0.10:
            cellsizeInArcsec = np.int(cellsizeInArcsec*100)/100.0
        elif cellsizeInArcsec > 0.02:
            cellsizeInArcsec = np.int(cellsizeInArcsec*200)/200.0
        elif cellsizeInArcsec > 0.01:
            cellsizeInArcsec = np.int(cellsizeInArcsec*1000)/1000.0
        else:
            cellsizeInArcsec = np.int(cellsizeInArcsec*2000)/2000.0

        if searchForLines == True: specLines = self.searchForLines(msName, chanWid=chanWid, angScale=angScale)

        save_stdout = sys.stdout
        sys.stdout = open('plotmosaic.output', 'w')
        plt.ioff()

        for i in sourceId:

            fieldIds1 = (np.where(sourceIds == int(i)))[0]
            if len(fieldIds1) > 1:
                j0 = 0
                fieldIds2 = str(fieldIds1[j0])
                for j in range(len(fieldIds1)-1):
                    if fieldIds1[j+1] == fieldIds1[j]+1: continue
                    fieldIds2 = fieldIds2 + '~' + str(fieldIds1[j])
                    j0 = j+1
                    fieldIds2 = fieldIds2 + ',' + str(fieldIds1[j0])
                fieldIds2 = fieldIds2 + '~' + str(fieldIds1[j+1])
            else:
                fieldIds2 = str(fieldIds1[0])

            spwInfo = self.getSpwInfo(msName)
            spwIds = sorted(spwInfo.keys())
            if iHaveSplitMyScienceSpw == True: spwIds = range(len(spwIds))

            mosaicInfo = plotmosaic(msName, sourceid=i, coord='relative')

            if len(fieldIds1) > 1:
                fieldAtCenter = str(mosaicInfo[0])
            else:
                fieldAtCenter = fieldIds2

            xImsizeInArcsec = abs(mosaicInfo[2] - mosaicInfo[1])
            yImsizeInArcsec = abs(mosaicInfo[4] - mosaicInfo[3])

            xImsizeInCells = xImsizeInArcsec/cellsizeInArcsec
            yImsizeInCells = yImsizeInArcsec/cellsizeInArcsec
            j = bisect.bisect_right(optimumImsize, xImsizeInCells)
            if j != len(optimumImsize): xImsizeInCells = optimumImsize[j]
            j = bisect.bisect_right(optimumImsize, yImsizeInCells)
            if j != len(optimumImsize): yImsizeInCells = optimumImsize[j]

            if searchForLines == True and int(i) in specLines:
                spwIds1 = []
                for j in spwIds:
                    if j not in specLines[int(i)]:
                        spwIds1.append(str(j))
                    else:
                        spwIds2 = []
                        for k in specLines[int(i)][j]:
                            for ij in range(k[0], k[1]+1):
                                spwIds2.append(ij)
                        spwIds3 = [ij for ij in range(spwInfo[j]['numChans']) if ij not in spwIds2]
                        spwIds4 = []
                        for ij, k in itertools.groupby(enumerate(spwIds3), lambda (x, y): y - x):
                            k = list(k)
                            spwIds4.append(str(k[0][1]) + '~' + str(k[-1][1]))
                        spwIds1.append(str(j) + ':' + ';'.join(spwIds4))
                        #spwIds2 = str(j) + ':0~'
                        #for k in specLines[int(i)][j]:
                        #    spwIds2 = spwIds2 + str(k[0]-1) + ';' + str(k[1]+1) + '~'
                        #spwIds2 = spwIds2 + str(spwInfo[j]['numChans'])
                        #spwIds1.append(spwIds2)
            else:
                spwIds1 = ['%s' %j for j in spwIds]

            spwIds1 = ','.join(spwIds1)

            casaCmd = casaCmd + "clean(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "  imagename = '"+msName+".image.continuum.source"+i+"',\n"
            casaCmd = casaCmd + "  field = '"+fieldIds2+"', # "+fieldNames[fieldIds1[0]]+"\n"
            casaCmd = casaCmd + "  spw = '"+spwIds1+"',\n"
            casaCmd = casaCmd + "  mode = 'mfs',\n"
            if len(fieldIds1) > 1: casaCmd = casaCmd + "  imagermode = 'mosaic',\n"
            casaCmd = casaCmd + "  interactive = True,\n"
            casaCmd = casaCmd + "  imsize = ["+str(xImsizeInCells)+", "+str(yImsizeInCells)+"],\n"
            casaCmd = casaCmd + "  cell = '"+str(cellsizeInArcsec)+"arcsec',\n"
            casaCmd = casaCmd + "  phasecenter = "+fieldAtCenter+",\n"
            casaCmd = casaCmd + "  weighting = 'briggs',\n"
            casaCmd = casaCmd + "  robust = 0.5)\n\n"

            if searchForLines == True:
                if int(i) in specLines:
                    for j in specLines[int(i)]:
                        for k in specLines[int(i)][j]:
                            casaCmd = casaCmd + "clean(vis = '"+msName+"',\n"
                            casaCmd = casaCmd + "  imagename = '"+msName+".image.line.source"+i+".spw"+str(j)+".chans"+str(k[0])+"-"+str(k[1])+"',\n"
                            casaCmd = casaCmd + "  field = '"+fieldIds2+"', # "+fieldNames[fieldIds1[0]]+"\n"
                            casaCmd = casaCmd + "  spw = '"+str(j)+"',\n"
                            casaCmd = casaCmd + "  mode = 'channel',\n"
                            casaCmd = casaCmd + "  nchan = "+str((k[1]+1-k[0])/chanWid)+",\n"
                            casaCmd = casaCmd + "  start = "+str(k[0])+",\n"
                            casaCmd = casaCmd + "  width = "+str(chanWid)+",\n"
                            if getCasaVersion() >= '4.2.0':
                                casaCmd = casaCmd + "  interpolation = 'linear',\n"
                            else:
                                casaCmd = casaCmd + "  interpolation = 'nearest',\n"
                            if len(fieldIds1) > 1: casaCmd = casaCmd + "  imagermode = 'mosaic',\n"
                            casaCmd = casaCmd + "  interactive = True,\n"
                            casaCmd = casaCmd + "  imsize = ["+str(xImsizeInCells)+", "+str(yImsizeInCells)+"],\n"
                            casaCmd = casaCmd + "  cell = '"+str(cellsizeInArcsec)+"arcsec',\n"
                            casaCmd = casaCmd + "  phasecenter = "+fieldAtCenter+",\n"
                            casaCmd = casaCmd + "  weighting = 'briggs',\n"
                            casaCmd = casaCmd + "  robust = 0.5)\n\n"

        plt.ion()
        sys.stdout = save_stdout
        os.system('rm plotmosaic.output')

        return casaCmd

    def getRADecStringForField(self, msName, fieldId=''):

        if fieldId == '': sys.exit('ERROR: No field Id specified.')

        fieldRADec = getRADecForField(msName, int(fieldId), usemstool=True)
        fieldRA = math.degrees(fieldRADec[0][0])
        fieldDec = math.degrees(fieldRADec[1][0])

        fieldRA = fieldRA/15.
        fieldRAh = int(fieldRA)
        fieldRAm = int(fieldRA%1*60)
        fieldRAs = (fieldRA%1*60)%1*60

        sign = int(abs(fieldDec)/fieldDec)

        fieldDec = abs(fieldDec)
        fieldDecd= int(fieldDec)
        fieldDecm= int(fieldDec%1*60)
        fieldDecs= (fieldDec%1*60)%1*60

        if(sign==+1):
            return "J2000 %02dh%02dm%05.2fs +%02dd%02dm%05.2fs" %(fieldRAh,fieldRAm,fieldRAs,fieldDecd,fieldDecm,fieldDecs)
        elif(sign==-1):
            return "J2000 %02dh%02dm%05.2fs -%02dd%02dm%05.2fs" %(fieldRAh,fieldRAm,fieldRAs,fieldDecd,fieldDecm,fieldDecs)

    def searchForLines(self, msName, fieldId='', chanWid=1, angScale=0, cutOff=0.2, minLineWid=3, chanPadding=1):

        import itertools
#         if (plotxyAvailable == False):
#             print "es.searchForLines needs to be updated to not use plotxy in this version of casa"
#             return
        vm = ValueMapping(msName)

        tb.open(msName)
        dataColNames = tb.colnames()
        tb.close()

        if 'CORRECTED_DATA' in dataColNames:
            dataCol = 'corrected'
        else:
            dataCol = 'data'

        tb.open(msName+'/FIELD')
        sourceIds = tb.getcol('SOURCE_ID')
        tb.close()

        intentSources = self.getIntentsAndSourceNames(msName)
        sciSourceIds = intentSources['OBSERVE_TARGET']['sourceid']
        sciSourceIds = sorted(dict.fromkeys(sciSourceIds).keys())

        spwInfo = self.getSpwInfo(msName)
        spwIds = sorted(spwInfo.keys())

        specLines = {}

        for i in sciSourceIds:

            fieldIds1 = (np.where(sourceIds == i))[0]
            fieldIds1 = [j for j in fieldIds1 if j in intentSources['OBSERVE_TARGET']['id']]

            for fid in fieldIds1:

                if fieldId != '' and fid != int(fieldId): continue

                for j in spwIds:

                    spwChanFreqs = vm.spwInfo[j]['chanFreqs']

                    if angScale != 0:
                        maxFreq = max(spwChanFreqs) / 1e9
                        uvRange = '0~'+str((72000. / maxFreq)/angScale)+'m'
                    else:
                        uvRange = ''

                    sum1 = {}
                    count1 = {}
                    for k in ['real', 'imag']:
                        sum1[k] = {}
                        count1[k] = {}

                        if getCasaVersion() <= '3.4.0':

                            plotxy(vis = msName, xaxis = 'chan', yaxis = k, datacolumn = dataCol, selectdata = True, antenna = '*&*', uvrange = uvRange, spw = str(j), field = str(fid),
                                   averagemode = 'vector', timebin = 'all', crossscans = True, crossbls = True, width = str(chanWid), interactive = False, figfile = 'plotxy.'+k+'.txt')
                            f = open('plotxy.'+k+'.txt', 'r')
                            fc = f.readlines()
                            f.close()
                            for line in fc:
                                line = line.strip()
                                if line == '': continue
                                ele1 = line.split()
                                chan1 = int(ele1[0])
                                comp1 = float(ele1[1])
                                if chan1 not in sum1[k].keys():
                                    sum1[k][chan1] = 0.
                                    count1[k][chan1] = 0
                                sum1[k][chan1] = sum1[k][chan1] + comp1
                                count1[k][chan1] = count1[k][chan1] + 1
                            os.system('rm -f plotxy.'+k+'.txt')

                        elif getCasaVersion() >= '4.2.0':

                            plotms(vis = msName, xaxis = 'chan', yaxis = k, ydatacolumn = dataCol, selectdata = True, antenna = '', uvrange = uvRange, spw = str(j), field = str(fid),
                                   averagedata = True, avgtime = '1e8', avgscan = True, avgbaseline = True, avgchannel = str(chanWid), plotfile = 'plotms.'+k+'.txt', expformat = 'txt', overwrite = True)
                            f = open('plotms.'+k+'.txt', 'r')
                            fc = f.readlines()
                            f.close()
                            for line in fc:
                                line = line.strip()
                                if line == '': continue
                                if line[0] == '#': continue
                                ele1 = line.split()
                                chan1 = int(round(float(ele1[0])/chanWid))
                                comp1 = float(ele1[1])
                                if chan1 not in sum1[k].keys():
                                    sum1[k][chan1] = 0.
                                    count1[k][chan1] = 0
                                sum1[k][chan1] = sum1[k][chan1] + comp1
                                count1[k][chan1] = count1[k][chan1] + 1
                            os.system('rm -f plotms.'+k+'.txt')

                        else:

                            sys.exit('ERROR: version of CASA not supported.')

                    chanMax = max([max(sum1['real']), max(sum1['imag'])])

                    avg1 = []
                    for chan1 in range(chanMax+1):
                        if chan1 in sum1['real'] and chan1 in sum1['imag']:
                            avg1.append(sqrt( (sum1['real'][chan1]/count1['real'][chan1])**2 + (sum1['imag'][chan1]/count1['imag'][chan1])**2))
                        else:
                            avg1.append(0)

                    plt.clf()
                    #plt.plot(range(0, len(avg1)*chanWid, chanWid), avg1)
                    plt.plot([spwChanFreqs[ij]/1.e9 for ij in range(0, len(avg1)*chanWid, chanWid)], avg1)
                    plt.savefig(msName+'.source'+str(i)+'.field'+str(fid)+'.spw'+str(j)+'.png')

                    hist, bin_edges = np.histogram(avg1, bins=int(ceil(sqrt(len(avg1)))))
                    ij = np.where(hist >= cutOff * max(hist))[0]
                    max1 = bin_edges[max(ij)+1]

                    k = 0
                    while k <= len(avg1)-minLineWid:
                        if avg1[k] > max1:
                            for kl in range(k, len(avg1)):
                                if avg1[kl] <= max1: break
                            if kl-k >= minLineWid:
                                specLine = [(k-chanPadding)*chanWid, (kl+chanPadding)*chanWid-1]
                                if i not in specLines: specLines[i] = {}
                                if j not in specLines[i]: specLines[i][j] = []
                                specLines[i][j].append(specLine)
                            k = kl-1
                        k = k+1

                    if i in specLines:
                        if j in specLines[i]:
                            specLines1 = []
                            for k in specLines[i][j]:
                                for kl in range(k[0], k[1]+1): specLines1.append(kl)
                            specLines1 = sorted(dict.fromkeys(specLines1).keys())
                            specLines2 = []
                            for kl, k in itertools.groupby(enumerate(specLines1), lambda (x, y): y - x):
                                k = list(k)
                                specLines2.append([k[0][1], k[-1][1]])
                            specLines[i][j] = specLines2

        return specLines


    def saveFlags(self, msName, name=''):

        if name == '': sys.exit('ERROR: Missing version name.')

        #casaCmd = 'print "# Saving flag column to version '+name+'"\n\n'
        casaCmd = ''

        if name == 'Original':
            casaCmd = casaCmd + "\nif not os.path.exists('"+msName+".flagversions/Original.flags'):\n"
            casaCmd = casaCmd + "  flagmanager(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "    mode = 'save',\n"
            casaCmd = casaCmd + "    versionname = '"+name+"')\n\n"
        else:
            casaCmd = casaCmd + "\nflagmanager(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "  mode = 'save',\n"
            casaCmd = casaCmd + "  versionname = '"+name+"')\n\n"

        return casaCmd

    def saveFlagStats(self, msName, name='', statsFile=''):

        if name == '': sys.exit('ERROR: You must specify a version name.')

        time1 = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        if os.path.exists(statsFile) == False:
            f = open(statsFile, 'w')
            f.write('{}')
            f.close()

        f = open(statsFile)
        stats1 = eval(f.read())
        f.close()

        myaf = aftool()
        myaf.open(msName)
        myaf.selectdata()
        myaf.parsesummaryparameters()
        myaf.init()
        stats2 = myaf.run()
        myaf.done()

        clearstat()

        if 'report0' not in stats2.keys(): sys.exit('ERROR: Unexpected dictionnary.')
        if 'spw' not in stats2['report0'].keys(): sys.exit('ERROR: Unexpected dictionnary.')
        spwIds = stats2['report0']['spw'].keys()

        tb.open(msName+'/SPECTRAL_WINDOW')
        spwNames = tb.getcol('NAME')
        tb.close()

        for i in spwIds:
            if int(i) not in range(len(spwNames)): sys.exit('ERROR: Missing spectral window.')
            stats2['report0']['spw'][i]['name'] = spwNames[int(i)]

        ij = stats1.keys()
        if len(ij) != 0:
            ij = max(ij)
        else:
            ij = -1

        stats1[ij+1] = {}
        stats1[ij+1]['time'] = time1
        stats1[ij+1]['name'] = name
        stats1[ij+1]['summary'] = stats2['report0']

        f = open(statsFile, 'w')
        f.write(repr(stats1))
        f.close()

        return stats1

    def fixForCSV2453(self, msName):
        """
        CSV-2453: Amplitude calibrators are not observed in Early Science SBs from 30 Dec 2012 to 1 January 2013
        """

        setjyModels = ['Mars', 'Jupiter', 'Uranus', 'Neptune', 'Pluto', 'Io', 'Europa', 'Ganymede', 'Callisto', 'Titan', 'Triton', 'Ceres', 'Pallas', 'Vesta', 'Juno', 'Victoria', 'Davida']
        setjyModels = [i.upper() for i in setjyModels]

        vm = ValueMapping(msName)

        for i in vm.uniqueFields:
            if i.upper() not in setjyModels: continue
            scanList = vm.getScansForField(i)
            for j in scanList:
                scanIntents = vm.getIntentsForScan(j).tolist()
                if 'CALIBRATE_DELAY#ON_SOURCE' in scanIntents:
                    editIntents(msName, field=i, scan=j, newintents='AMPLITUDE', append=True)

    def fixForICT331(self, asdmName):
        """
        ICT-331: stateIds reported as null in the ASDM Main Table
        """
        f = open(asdmName+'/Scan.xml')
        fc = f.read()
        f.close()

        blocks = re.findall('<row>.*?</row>', fc, re.DOTALL|re.MULTILINE)
        if len(blocks) == 0: sys.exit('Found 0 block.')

        scanIntents = {}

        for i in range(len(blocks)):

            scanNumber = re.findall('<scanNumber>.*?</scanNumber>', blocks[i])[0]
            scanNumber = int(scanNumber.replace('<scanNumber>', '').replace('</scanNumber>', ''))

            scanIntents1 = re.findall('<scanIntent>.*?</scanIntent>', blocks[i])[0]
            scanIntents1 = scanIntents1.replace('<scanIntent>', '').replace('</scanIntent>', '')
            scanIntents1 = re.findall('[A-Za-z_]+', scanIntents1)
            scanIntents1 = [j for j in scanIntents1 if j != 'CALIBRATE_WVR']

            scanIntents[scanNumber] = scanIntents1

        f = open(asdmName+'/Main.xml')
        fc = f.read()
        f.close()

        blocks = re.findall('<row>.*?</row>', fc, re.DOTALL|re.MULTILINE)
        if len(blocks) == 0: sys.exit('Found 0 block.')        

        needsFix = False
        needsSyscalRegen = False

        for i in range(len(blocks)):

            scanNumber = re.findall('<scanNumber>.*?</scanNumber>', blocks[i])[0]
            scanNumber = int(scanNumber.replace('<scanNumber>', '').replace('</scanNumber>', ''))

            stateIds = re.findall('<stateId>.*?</stateId>', blocks[i])[0]
            stateIds = stateIds.replace('<stateId>', '').replace('</stateId>', '').strip()

            if re.search('null', stateIds) is not None:

                print 'Scan '+str(scanNumber)+' is affected.'

                needsFix = True
                if 'CALIBRATE_ATMOSPHERE' in scanIntents[scanNumber]: needsSyscalRegen = True

                stateIds1 = stateIds.replace('null_', 'State_')

                block = blocks[i].replace(stateIds, stateIds1)
                if len(re.findall(blocks[i], fc)) != 1: sys.exit('ERROR')
                fc = fc.replace(blocks[i], block)

        if needsFix == True:

            os.system('cp '+asdmName+'/Main.xml '+asdmName+'/Main.xml.old')

            f = open(asdmName+'/Main.xml', 'w')
            f.write(fc)
            f.close()

            print 'Main.xml was fixed. (The previous version was copied to "Main.xml.old".)'

            if needsSyscalRegen:
                print 'NOTE: YOU WILL NEED TO REGENERATE THE SYSCAL TABLE.'

    def checkRMS(self, msNames='', cycle='', numAnts='', timeOnSource='', numFieldsPerSource='', maxFlag=0.1, groupFieldsByRADec=False, groupSpwsByFreq=False, mergeSources=False, maxFlagUsefulRange=True, chanEdge=0.0625):
        """
        msNames: list of measurement sets, or a string with a wildcard character
        specify either cycle or numAnts:
           cycle: integer or string integer (e.g. 3 will set numAnts_ACA=10, 12m=36)
           numAnts: integer or string integer
        timeOnSource: the expected time on source (e.g. from the P2G SCOPS ticket)
        """
        # groupSpwsByFreq will need implementation!! remember to check spw ids from one field to the next

        print 'WARNING: THIS WAS NOT TESTED FOR SESSIONS'
        print 'WARNING: OPTION groupSpwsByFreq NOT IMPLEMENTED YET'

        if msNames == '': sys.exit('ERROR: YOU MUST SPECIFY A LIST (CALIBRATED) MEASUREMENT SETS')

        if '*' in msNames:
            msNames = glob.glob(msNames)
            msNames = sorted(msNames)

        if type(msNames) is str:
            msNames = [msNames]

        if timeOnSource == '': sys.exit('ERROR: YOU MUST SPECIFY A TIME ON SOURCE')
        timeOnSource = float(timeOnSource)

        if numFieldsPerSource == '':
            print 'WARNING: YOU HAVE NOT SPECIFIED A NUMBER OF FIELDS PER SOURCE'
        else:
            numFieldsPerSource = int(numFieldsPerSource)

        if cycle == '' and numAnts == '': sys.exit('ERROR: YOU MUST SPECIFY EITHER A CYCLE OR A NUMBER OF ANTENNAS')
        if cycle != '' and numAnts != '': sys.exit('ERROR: YOU CANNOT SPECIFY A CYCLE AND A NUMBER OF ANTENNAS')

        if cycle != '':
            if int(cycle) == 1:
                numAnts_ACA = 9
                numAnts_BL12 = 32
            elif int(cycle) == 2:
                numAnts_ACA = 9
                numAnts_BL12 = 34
            elif int(cycle) == 3:
                numAnts_ACA = 10
                numAnts_BL12 = 36
            elif int(cycle) == 4:
                numAnts_ACA = 10
                numAnts_BL12 = 40
            elif int(cycle) == 5:
                numAnts_ACA = 10
                numAnts_BL12 = 43
            else:
                sys.exit('ERROR: CYCLE NOT SUPPORTED')
        else:
            numAnts = int(numAnts)

        maxRatios = {3:1.1, 4:1.1, 6:1.1, 7:1.15, 8:1.2, 9:1.2, 10:1.2}

        maxFlag = float(maxFlag)

        mydict = {}
        array = ''

        for i in range(len(msNames)):

            msName = msNames[i]

            print '# Processing -> ', msName
            mymsmd = msmdtool()
            mymsmd.open(msName)

            sciSpwIds = mymsmd.spwsforintent('OBSERVE_TARGET#ON_SOURCE')
            sciSpwIds = [j for j in sciSpwIds if mymsmd.nchan(j) > 1]
            wvrSpwIds = mymsmd.wvrspws()
            sciSpwIds = np.array([j for j in sciSpwIds if j not in wvrSpwIds])

            sciFieldIds = mymsmd.fieldsforintent('OBSERVE_TARGET#ON_SOURCE')

            antennaNames = mymsmd.antennanames()

            sciSpwMeanFreq = []
            sciSpwChanWidth = []
            sciSpwChanNum = []
            for j in sciSpwIds:
                sciSpwMeanFreq.append(mymsmd.meanfreq(j))
                sciSpwChanWidth1 = np.unique(mymsmd.chanwidths(j))
                if len(sciSpwChanWidth1) != 1: sys.exit('ERROR')
                sciSpwChanWidth.append(sciSpwChanWidth1[0])
                sciSpwChanNum.append(mymsmd.nchan(j))

            if maxFlagUsefulRange == True:
                if len([j for j in sciSpwIds if j in mymsmd.fdmspws()]) == 0:
                    maxFlag += chanEdge*2

            mymsmd.close()

            numCMAnts = 0
            for j in range(len(antennaNames)):
                if re.search('^CM', antennaNames[j]) is not None:
                    numCMAnts += 1
            if 1. * numCMAnts / len(antennaNames) > 0.5:
                array1 = 'ACA'
            else:
                array1 = 'BL12'
            if array == '':
                array = array1
            else:
                if array != array1: sys.exit('ERROR: THE FIRST DATASET WAS IDENTIFIED AS '+array+' WHILE THE CURRENT ONE IS IDENTIFIED AS '+array1)

            tb.open(msName+'/FIELD')
            sourceIds = tb.getcol('SOURCE_ID')
            fieldDirs = tb.getcol('PHASE_DIR')
            tb.close()

            sourceIds1 = np.unique(sourceIds[sciFieldIds])

            print '# Found ', len(sourceIds1), ' science source(s)'

            tb.open(msName+'/SOURCE')
            sourceIds2 = tb.getcol('SOURCE_ID')
            sourceNames2 = tb.getcol('NAME')
            sourceDirs2 = tb.getcol('DIRECTION')
            tb.close()

            tb.open(msName+'/DATA_DESCRIPTION')
            spwId2DataDescId = tb.getcol('SPECTRAL_WINDOW_ID').tolist()
            tb.close()

            tb.open(msName+'/SPECTRAL_WINDOW')
            spwNames = tb.getcol('NAME').tolist()
            tb.close()
            mymsmd = msmdtool()
            mymsmd.open(msName)
            scienceScanNums = mymsmd.scansforintent('OBSERVE_TARGET#ON_SOURCE').tolist()
            mymsmd.close()

            tb.open(msName)

            for j in range(len(sourceIds1)):

                ij = np.where(sourceIds2 == sourceIds1[j])

                sourceName = np.unique(sourceNames2[ij])
                sourceDir = sourceDirs2.swapaxes(0,1)[ij]
                sourceDir = sourceDir.swapaxes(0,1)
                if len(sourceName) != 1 or len(np.unique(sourceDir[0])) != 1 or len(np.unique(sourceDir[1])) != 1: sys.exit('ERROR')
                sourceName = sourceName[0]
                sourceDir = [np.unique(sourceDir[0])[0], np.unique(sourceDir[1])[0]]

                found = 0

                if len(mydict.keys()) == 0:
                    k = 0
                else:
                    if mergeSources == True:
                        k = 0
                        found = 1
                    else:
                        for k in mydict.keys():
                            if mydict[k]['sourceName'] == sourceName and mydict[k]['sourceDir'] == sourceDir:
                                found = 1
                                break
                        if found == 0:
                            k = max(mydict.keys()) + 1

                if found == 0:
                    mydict[k] = {}
                    mydict[k]['sourceName'] = sourceName
                    mydict[k]['sourceDir'] = sourceDir
                    mydict[k]['perField'] = {}

                sciFieldIds1 = np.where(sourceIds == sourceIds1[j])[0]
                sciFieldIds1 = [kl for kl in sciFieldIds1 if kl in sciFieldIds]

                for ij in sciFieldIds1:

                    found = 0

                    if len(mydict[k]['perField'].keys()) == 0:
                        kl = 0
                    else:
                        if groupFieldsByRADec == True:
                            for kl in mydict[k]['perField'].keys():
                                if mydict[k]['perField'][kl]['fieldDir'] == [ str(fieldDirs[0][0][ij]), str(fieldDirs[1][0][ij]) ]:
                                    found = 1
                                    break
                        else:
                            if sciFieldIds1.index(ij) in mydict[k]['perField'].keys():
                                kl = sciFieldIds1.index(ij)
                                found = 1
                            else:
                                kl = max(mydict[k]['perField'].keys()) + 1

                    if found == 0:
                        mydict[k]['perField'][kl] = {}
                        mydict[k]['perField'][kl]['fieldDir'] = [ str(fieldDirs[0][0][ij]), str(fieldDirs[1][0][ij]) ]
                        mydict[k]['perField'][kl]['perSpw'] = {}

                    for ij1 in sciSpwIds:

                        tb1 = tb.query('DATA_DESC_ID == '+str(spwId2DataDescId.index(ij1))+' AND FIELD_ID == '+str(ij)+' AND SCAN_NUMBER IN '+str(scienceScanNums))
                        if tb1.nrows() == 0: continue

                        found = 0

                        if len(mydict[k]['perField'][kl]['perSpw'].keys()) == 0:
                            kl1 = 0
                        else:
                            if groupSpwsByFreq == True:
                                sys.exit('ERROR')
                            else:
                                if sciSpwIds.tolist().index(ij1) in mydict[k]['perField'][kl]['perSpw'].keys():
                                    kl1 = sciSpwIds.tolist().index(ij1)
                                    found = 1
                                else:
                                    kl1 = max(mydict[k]['perField'][kl]['perSpw'].keys()) + 1

                        if found == 0:
                            mydict[k]['perField'][kl]['perSpw'][kl1] = {}

#                         tb1 = tb.query('DATA_DESC_ID == '+str(spwId2DataDescId.index(ij1))+' AND FIELD_ID == '+str(ij)+' AND SCAN_NUMBER IN '+str(scienceScanNums))
#                         if tb1.nrows() == 0: continue

                        exp1 = np.unique(tb1.getcol('EXPOSURE'))
                        if len(exp1) != 1: sys.exit('ERROR')
                        exp1 = exp1[0]

                        if 'exp' not in mydict[k]['perField'][kl]['perSpw'][kl1].keys():
                            mydict[k]['perField'][kl]['perSpw'][kl1]['exp'] = exp1
                        else:
                            if mydict[k]['perField'][kl]['perSpw'][kl1]['exp'] != exp1: sys.exit('ERROR')

                        if 'meanFreq' not in mydict[k]['perField'][kl]['perSpw'][kl1].keys():
                            mydict[k]['perField'][kl]['perSpw'][kl1]['meanFreq'] = sciSpwMeanFreq[sciSpwIds.tolist().index(ij1)]
#                             mydict[k]['perField'][kl]['perSpw'][kl1]['band'] = getBand(sciSpwMeanFreq[sciSpwIds.tolist().index(ij1)])
                            band1 = re.findall('ALMA_RB_[0-9]+', spwNames[ij1])
                            if len(band1) != 1: sys.exit('ERROR')
                            mydict[k]['perField'][kl]['perSpw'][kl1]['band'] = int(band1[0].split('_')[2])
                        else:
                            if mydict[k]['perField'][kl]['perSpw'][kl1]['meanFreq'] != sciSpwMeanFreq[sciSpwIds.tolist().index(ij1)]:
                                print 'WARNING: THE MEAN FREQUENCY OF SPW ', ij1, ' OF CURRENT MS DOES NOT MATCH THE MEAN FREQUENCY OF THE SAME SPW OF THE FIRST MS'

                        if 'chanWidth' not in mydict[k]['perField'][kl]['perSpw'][kl1].keys():
                            mydict[k]['perField'][kl]['perSpw'][kl1]['chanWidth'] = sciSpwChanWidth[sciSpwIds.tolist().index(ij1)]
                        else:
                            if mydict[k]['perField'][kl]['perSpw'][kl1]['chanWidth'] != sciSpwChanWidth[sciSpwIds.tolist().index(ij1)]:
                                print 'WARNING: THE CHANNEL WIDTH OF SPW ', ij1, ' OF CURRENT MS DOES NOT MATCH THE MEAN FREQUENCY OF THE SAME SPW OF THE FIRST MS'

                        if 'chanNum' not in mydict[k]['perField'][kl]['perSpw'][kl1].keys():
                            mydict[k]['perField'][kl]['perSpw'][kl1]['chanNum'] = sciSpwChanNum[sciSpwIds.tolist().index(ij1)]
                        else:
                            if mydict[k]['perField'][kl]['perSpw'][kl1]['chanNum'] != sciSpwChanNum[sciSpwIds.tolist().index(ij1)]:
                                print 'WARNING: THE NUMBER OF CHANNELS OF SPW ', ij1, ' OF CURRENT MS DOES NOT MATCH THE MEAN FREQUENCY OF THE SAME SPW OF THE FIRST MS'

                        tb1 = tb.query('FLAG_ROW == FALSE AND DATA_DESC_ID == '+str(spwId2DataDescId.index(ij1))+' AND FIELD_ID == '+str(ij))
                        if tb1.nrows() > 0:

                            ant1 = tb1.getcol('ANTENNA1')
                            ant2 = tb1.getcol('ANTENNA2')
                            flag1 = tb1.getcol('FLAG')
                            flag2 = flag1.swapaxes(1,2)

                            nchan1 = len(flag2[0][0])

                            if 'nvis' not in mydict[k]['perField'][kl]['perSpw'][kl1].keys():
                                nvis1 = 0
                            else:
                                nvis1 = mydict[k]['perField'][kl]['perSpw'][kl1]['nvis']

                            for ij2 in range(len(ant1)):

                                if ant1[ij2] == ant2[ij2]: continue

                                flag3 = []
#                                 for ij3 in range(2):
                                for ij3 in range(len(flag2)):
                                    flag3.append(1. * len(np.where(np.array(flag2[ij3][ij2]) == True)[0]) / nchan1)

                                if len(np.where(np.array(flag3) > maxFlag)[0]) == 0:
                                    nvis1 += 1

                            mydict[k]['perField'][kl]['perSpw'][kl1]['nvis'] = nvis1
                            print "Found "+str(nvis1)+" visibility rows for field "+str(kl)+", SPW "+str(kl1)

                        else:

                            mydict[k]['perField'][kl]['perSpw'][kl1]['nvis'] = 0
                            print "Found zero visibility rows for field "+str(kl)+", SPW "+str(kl1) 

            tb1.close()
            tb.close()

        if cycle != '':
            if array == 'ACA':
                numAnts = numAnts_ACA
            else:
                numAnts = numAnts_BL12

        for i in mydict.keys():

            numFieldsPerSource1 = numFieldsPerSource

            if numFieldsPerSource1 == '':
                numFieldsPerSource1 = len(mydict[i]['perField'].keys())
            else:
                if len(mydict[i]['perField'].keys()) != numFieldsPerSource1: sys.exit('ERROR: THE OBSERVED NUMBER OF FIELDS PER SOURCE DOES NOT MATCH THE SPECIFIED NUMBER')

            for j in mydict[i]['perField'].keys():
                for k in mydict[i]['perField'][j]['perSpw'].keys():
                    nvis1 = mydict[i]['perField'][j]['perSpw'][k]['nvis']
                    if nvis1 != 0:
                        mydict[i]['perField'][j]['perSpw'][k]['ratio'] = np.sqrt( ( numAnts * (numAnts-1) * (timeOnSource * 60. / numFieldsPerSource1) ) / (2. * nvis1 * exp1) )
                    else:
                        mydict[i]['perField'][j]['perSpw'][k]['ratio'] = float('inf')

        for i in mydict.keys():

            mydict[i]['perSpw'] = {}
    
            ij = []
            band = []
            for j in mydict[i]['perField'].keys():
                for k in mydict[i]['perField'][j]['perSpw'].keys():
                    ij.append(k)
                    band.append(mydict[i]['perField'][j]['perSpw'][k]['band'])
            ij = np.unique(ij)
            band = np.unique(band)
            if len(band) != 1: sys.exit('ERROR')

            for j in ij:

                mydict[i]['perSpw'][j] = {}
                mydict[i]['perSpw'][j]['band'] = band[0]
                mydict[i]['perSpw'][j]['ratio'] = {}

                ratio1 = []
                for k in mydict[i]['perField'].keys():
                    if j in mydict[i]['perField'][k]['perSpw'].keys():
                        ratio1.append(mydict[i]['perField'][k]['perSpw'][j]['ratio'])

                mydict[i]['perSpw'][j]['ratio']['min'] = np.min(ratio1)
                mydict[i]['perSpw'][j]['ratio']['max'] = np.max(ratio1)
                mydict[i]['perSpw'][j]['ratio']['median'] = np.median(ratio1)

        print '---------'
        print 'Number of executions = ', len(msNames)

        for i in mydict.keys():

            print '\nSource name = ', mydict[i]['sourceName']
            print 'Number of fields found = ', len(mydict[i]['perField'].keys())
            print 'Maximum rms ratio across all fields, per spw:\n'

            for j in mydict[i]['perSpw'].keys():

                line = str(j)+' -> '+str(mydict[i]['perSpw'][j]['ratio']['max'])+' -> '

                if mydict[i]['perSpw'][j]['ratio']['max'] < maxRatios[mydict[i]['perSpw'][j]['band']]:
                    line += 'PASS'
                else:
                    line += 'FAIL -> need '+str(len(msNames) * ( (1./maxRatios[mydict[i]['perSpw'][j]['band']])**2 - (1./mydict[i]['perSpw'][j]['ratio']['max'])**2 ))+' additional executions'

                print line

        return mydict

    def fieldDirNotInSourceDirs(self, fieldDir, sourceDirs2):
        for sd in sourceDirs2:
            separation = angularSeparationRadians(fieldDir[0], fieldDir[1], 
                                                  sd[0], sd[1])
            if separation < np.radians(200e-6 / 3600.):
                return False
        return True

    def fixForCSV2555(self, msName):
        """
        CSV-2555: Inconsistency in FIELD_ID, SOURCE_ID and Spw_ID in single dish data
        """
        print 'INFO: Running routine fixForCSV2555 on '+msName

#         mymsmd = msmdtool()
#         mymsmd.open(msName)
#         scanList = mymsmd.scannumbers()
#         for i in scanList:
#             fieldList = mymsmd.fieldsforscan(i)
#             if len(fieldList) != 1:
#                 print 'WARNING: Scan '+str(i)+' has more than one field.'
#         mymsmd.close()

        corr = False

        tb.open(msName+'/SOURCE')

        sourceNames = tb.getcol('NAME')
        sourceDirs = tb.getcol('DIRECTION')
        sourceDirs = np.transpose(sourceDirs)
        sourceDirs = np.array([tuple(i) for i in sourceDirs])

        tb.close()

        tb.open(msName+'/FIELD', nomodify=False)

        fieldNameList = tb.getcol('NAME')

#         k = -1
        sourceInfo = []

        for i in range(tb.nrows()):

            fieldName = tb.getcell('NAME', rownr=i)

            ij = np.where(sourceNames == fieldName)
            if len(ij) == 0: sys.exit('ERROR')

            sourceDirs1 = [sourceDirs[j].tolist() for j in ij[0]]

            sourceDirs2 = [tuple(sourceDirs1[0])]
            for j in range(1, len(sourceDirs1)):
                if tuple(sourceDirs1[j]) in sourceDirs2: continue
                sourceDirs2.append(tuple(sourceDirs1[j]))

            if len(sourceDirs2) == 1:

                if tuple([fieldName, sourceDirs2[0]]) not in sourceInfo:

                    sourceInfo.append(tuple([fieldName, sourceDirs2[0]]))
#                     k += 1

                k = sourceInfo.index(tuple([fieldName, sourceDirs2[0]]))

            else:

                fieldDir = tb.getcell('PHASE_DIR', rownr=i)
                fieldDir = tuple(np.transpose(fieldDir)[0])
                # PRTSPR-21346
                if self.fieldDirNotInSourceDirs(fieldDir, sourceDirs2):
#                if fieldDir not in sourceDirs2:
                    print "row = ", i
                    print "radians: %s not in %s" % (str(fieldDir), str(sourceDirs2))
                    sys.exit('ERROR')

                if tuple([fieldName, fieldDir]) not in sourceInfo:

                    sourceInfo.append(tuple([fieldName, fieldDir]))
#                     k += 1

                k = sourceInfo.index(tuple([fieldName, fieldDir]))

            if tb.getcell('SOURCE_ID', rownr=i) != k:
                tb.putcell('SOURCE_ID', rownr=i, thevalue=k)
                corr = True

        tb.close()

        tb.open(msName+'/SOURCE', nomodify=False)

        for i in range(tb.nrows()):

            sourceName = tb.getcell('NAME', rownr=i)
            sourceDir = tb.getcell('DIRECTION', rownr=i)
            sourceDir = tuple(sourceDir.tolist())

            k = -1
            found = 0
            for j in range(len(sourceInfo)):
#                if sourceName == sourceInfo[j][0] and sourceDir == sourceInfo[j][1]:
                # PRTSPR-21346
                if sourceName == sourceInfo[j][0] and angularSeparationRadians(sourceDir[0], sourceDir[1], sourceInfo[j][1][0], sourceInfo[j][1][1]) < np.radians(200e-6/3600):
                    k = j
                    found = 1
                    break

            if found == 0:
                print 'WARNING: IT LOOKS BAD... THERE IS IN THE SOURCE TABLE A LINE WITH A DIRECTION THAT IS NOT PRESENT IN THE FIELD TABLE (not within 0.2mas).'
                for j in range(len(sourceInfo)):
                    if sourceName == sourceInfo[j][0]:
                        k = j
                        found = 1
                        print "WARNING: ASSIGNING THE SOURCE ID OF '"+sourceInfo[j][0]+"' TO '"+sourceName+"'. IF THIS OBJECT IS NOT A SOLAR SYSTEM OBJECT, THEN IT IS VERY BAD, PLEASE REPORT TO JAO (E.G. ERIC V.); OTHERWISE, IT IS PROBABLY FINE."
                        break

            if found == 0: sys.exit('ERROR')

            if tb.getcell('SOURCE_ID', rownr=i) != k:
                tb.putcell('SOURCE_ID', rownr=i, thevalue=k)
                corr = True

        tb.close()

        clearstat()

        if corr == True:
            print 'INFO: Some issues were found, and corrected.'
        else:
            print 'INFO: No issue found.'

        print 'INFO: Finished running routine fixForCSV2555 on '+msName

    def getJyPerK(self, msNames, averageAntennas = True, averageBands = False, averageBasebands = False, deltaDays = 1, deltaFrequencies = 1e9, deltaElevations = 0, deltaTemperatures = 0, removeOutliers = True, interactive=False, useModelFit=True):

        if type(msNames).__name__ == 'str': msNames = [msNames]

        if useModelFit == True:

            try:
                f=open(os.path.expanduser('~/AIV/science/DSO/jy_per_k_fit.txt'), 'r')
            except:
                try:
                    mypath = self.locatePath('DSO/jy_per_k_fit.txt')
                    f=open(mypath)
                except:
                    print "Failed to find path=%s" % (mypath)

            fc = f.read()
            f.close()

            fc = fc.split('\n')

            jyperkFit = {}

            for i in range(len(fc)):

                fc1 = fc[i].split()
                if len(fc1) != 8: continue

                date = fc1[0]
                bands = fc1[1].split(',')
                bands = [int(j) for j in bands]

                jyperkFit[date] = {}
                jyperkFit[date]['bands'] = bands
                jyperkFit[date]['a'] = float(fc1[2])
                jyperkFit[date]['b'] = float(fc1[3])
                jyperkFit[date]['c'] = float(fc1[4])
                jyperkFit[date]['d'] = float(fc1[5])
                jyperkFit[date]['e'] = float(fc1[6])
                jyperkFit[date]['f'] = float(fc1[7])

        f = open('jyperk.csv', 'w')
        print >> f, 'MS,Antenna,Spwid,Polarization,Factor'
        f.close()

        for msName in msNames:

            tb.open(msName+'/ANTENNA')
            antNames1 = tb.getcol('NAME')
            tb.close()

            antNames = []
            for i in range(len(antNames1)):
                if re.search('^PM', antNames1[i]) is not None:
                    antNames.append(antNames1[i])

            tb.open(msName+'/OBSERVATION')
            obsTimeRange = tb.getcol('TIME_RANGE')
            date = (obsTimeRange[0]+obsTimeRange[1])/2.0
            date = ((date/86400.0)+2400000.5-2440587.5)*86400.0
            date = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(date))
            tb.close()

            if useModelFit == True:

                diff2 = []
                for i in range(len(jyperkFit.keys())):
                    diff1 = datetime.datetime.strptime(jyperkFit.keys()[i], '%Y-%m-%d') - datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S')
                    diff2.append(abs(diff1.days + diff1.seconds/86400.))

                date2 = jyperkFit.keys()[diff2.index(min(diff2))]

            tb.open(msName+'/SPECTRAL_WINDOW')
            spwNames = tb.getcol('NAME')
            tb.close()

            spwInfo = self.getSpwInfo(msName, intent='OBSERVE_TARGET|CALIBRATE_BANDPASS')

            for i in spwInfo.keys():
    #             spwInfo[i]['band'] = int(spwNames[i].split('#')[0].split('_')[2])
                spwBand = re.findall('ALMA_RB_[0-9]+', spwNames[i], re.IGNORECASE)
                if len(spwBand) != 1: sys.exit('ERROR')
                spwInfo[i]['band'] = int(spwBand[0].split('_')[2])
            mymsmd = msmdtool()
            mymsmd.open(msName)
            scanList = mymsmd.scansforintent('OBSERVE_TARGET#ON_SOURCE')
            mymsmd.close()

            weatherInfo = getWeather(msName, scan = scanList.tolist())
            elevation = weatherInfo[0]['elevation']
            temperature = weatherInfo[0]['temperature']

            try:
                f=open(os.path.expanduser('~/AIV/science/DSO/jy_per_k.txt'), 'r')
            except:
                try:
                    mypath = self.locatePath('DSO/jy_per_k.txt')
                    f=open(mypath)
                except:
                    print "Failed to find path=%s" % (mypath)

    #         f = open(os.path.expanduser('~/AIV/science/DSO/jy_per_k.txt'), 'r')
            fc = f.read()
            f.close()

            fc = fc.split('\n')

            colnames = ['asdm', 'antenna', 'spw', 'value', 'date', 'caltarget', 'band', 'baseband', 'frequency', 'bandwidth', 'elevation', 'temperature']

            jyperk = {}

            for i in range(len(fc)):

                fc1 = fc[i].split('\t')
                if len(fc1) != 12: continue

                jyperk[i] = {}
                for j in range(len(colnames)):
                    jyperk[i][colnames[j]] = fc1[j]

            if removeOutliers == True:

                jyperkValues = []
                for i in jyperk.keys():
                    jyperkValues.append(float(jyperk[i]['value']))

                jyperkValuesMedian = np.median(jyperkValues)
                jyperkValuesMAD = np.median(abs(jyperkValues-jyperkValuesMedian)) / 0.6745

            date = datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S')

            spwIds = sorted(spwInfo.keys())

            jyperk1 = {}

            for antenna in antNames:

                jyperk1[antenna] = {}
            
                for id in spwIds:

                    band = spwInfo[id]['band']
                    baseband = spwInfo[id]['basebandNum']
                    frequency = spwInfo[id]['meanFreq']

                    jyperk1[antenna][id] = {}

                    if useModelFit == True and band in jyperkFit[date2]['bands']:

                        jyperk1[antenna][id]['mean'] = round(jyperkFit[date2]['a'] * math.exp((4. * math.pi * jyperkFit[date2]['b']/1e6 * frequency/c_mks)**2) \
                                                        + jyperkFit[date2]['c'] + jyperkFit[date2]['d'] * temperature \
                                                        + jyperkFit[date2]['e'] + jyperkFit[date2]['f'] * (elevation - 55.)**2, 3)
                        jyperk1[antenna][id]['std'] = ''
                        jyperk1[antenna][id]['n'] = ''

                    else:

                        jyperkValues = []

                        for i in jyperk.keys():

                            if jyperk[i]['band'] == '2': jyperk[i]['band'] = '3'

                            if jyperk[i]['antenna'] != antenna and averageAntennas == False: continue
                            if int(jyperk[i]['band']) != band and averageBands == False: continue
                            if int(jyperk[i]['baseband']) != baseband and averageBasebands == False: continue

                            date1 = datetime.datetime.strptime(jyperk[i]['date'], '%Y-%m-%dT%H:%M:%S')
                            diff1 = date1-date
                            diff1 = abs(diff1.days + diff1.seconds/86400.)
                            if deltaDays != 0 and diff1 > deltaDays: continue

                            if deltaFrequencies != 0 and abs(float(jyperk[i]['frequency'])-frequency) > deltaFrequencies: continue
                            if deltaElevations != 0 and abs(float(jyperk[i]['elevation'])-elevation) > deltaElevations: continue
                            if deltaTemperatures != 0 and abs(float(jyperk[i]['temperature'])-temperature) > deltaTemperatures: continue

                            if removeOutliers == True:
                                if abs(float(jyperk[i]['value'])-jyperkValuesMedian) > 2*jyperkValuesMAD: continue

                            jyperkValues.append(float(jyperk[i]['value']))

                        if len(jyperkValues) != 0:

                            jyperk1[antenna][id]['mean'] = round(np.mean(jyperkValues), 3)
                            jyperk1[antenna][id]['std'] = round(np.std(jyperkValues), 3)
                            jyperk1[antenna][id]['n'] = len(jyperkValues)

                        else:

                            if interactive == False:
                                print 'ERROR: NO SOLUTION FOUND'
                                sys.exit(1)

                            jyperk1[antenna][id]['mean'] = ''
                            jyperk1[antenna][id]['std'] = ''
                            jyperk1[antenna][id]['n'] = 0

            f = open('jyperk.csv', 'a')
            for ant in sorted(jyperk1.keys()):
                for id in sorted(jyperk1[ant].keys()):
                    print >> f, msName+','+ant+','+str(id)+',I,'+str(jyperk1[ant][id]['mean'])
            f.close()

        if len(msNames) == 1: return jyperk1

    def getJyPerKstats(self):

        f = open(os.path.expanduser('~/AIV/science/DSO/jy_per_k.txt'), 'r')
        fc = f.read()
        f.close()

        fc = fc.split('\n')

        fact = []

        for i in range(len(fc)):
            if fc[i] == '': continue
            fact.append(float(fc[i].split('\t')[3]))

        fact_median = np.median(fact)
        fact_mad = np.median(abs(fact-fact_median)) / 0.6745

        print 'all data (with outliers): median =', fact_median, 'MAD =', fact_mad, 'N =', len(fact)

        antenna = []
        fact = []
        band = []
        freq = []
        elev = []
        temp = []

        for i in range(len(fc)):

            if fc[i] == '': continue
            fact1 = float(fc[i].split('\t')[3])
            if abs(fact1-fact_median) > 3*fact_mad: continue

            antenna.append(fc[i].split('\t')[1])
            fact.append(fact1)
            band1 = float(fc[i].split('\t')[6])
            if band1 == 2: band1 = 3
            band.append(band1)
            freq.append(float(fc[i].split('\t')[8]))
            elev.append(float(fc[i].split('\t')[10]))
            temp.append(float(fc[i].split('\t')[11]))

        print '\nall data (outliers removed): mean =', np.mean(fact), 'stddev =', np.std(fact), 'N =', len(fact)
        print ''

        for i in np.unique(band):
            ij = np.where(np.array(band) == i)
            print 'band = '+str(int(i))+' : mean =', np.mean(np.array(fact)[ij]), 'stddev =', np.std(np.array(fact)[ij]), 'N =', len(ij[0])
        print ''

        for i in np.unique(antenna):
            ij = np.where(np.array(antenna) == i)
            print 'antenna = '+i+' : mean =', np.mean(np.array(fact)[ij]), 'stddev =', np.std(np.array(fact)[ij]), 'N =', len(ij[0])
        print ''

        for i in np.unique(band):
            ij1 = np.where(np.array(band) == i)[0]
            for j in np.unique(antenna):
                ij2 = np.where(np.array(antenna) == j)[0]
                ij = np.array([k for k in ij1 if k in ij2])
                if len(ij) == 0: continue
                print 'band = '+str(int(i))+' - antenna = '+j+' : mean =', np.mean(np.array(fact)[ij]), 'stddev =', np.std(np.array(fact)[ij]), 'N =', len(ij)
            print ''

        print 'correlation coefficient with elevation (all data):', np.corrcoef(elev, fact)[0][1]
        print ''

        print 'correlation coefficient with temperature (all data):', np.corrcoef(temp, fact)[0][1]
        print ''

        print 'correlation coefficient with frequency (all data):', np.corrcoef(freq, fact)[0][1]
        print ''

    def listobs3(self, msName, figfile = '', colorby = 'intent'):

#        import matplotlib.pyplot as plt

        if colorby not in ['', 'intent', 'spw']: sys.exit('ERROR')
        if (getCasaVersion() < '4.1.0') and colorby == 'spw': sys.exit('ERROR')

        colors = ['orange', 'blue', 'cyan', 'red', 'green', 'magenta', 'yellow', 'orange', 'blue', 'cyan', 'red', 'green', 'magenta', 'yellow', 'orange', 'blue']
#         intents = ['OBSERVE_TARGET#ON_SOURCE', 'OBSERVE_CHECK_SOURCE#ON_SOURCE', 'CALIBRATE_PHASE#ON_SOURCE', 'CALIBRATE_BANDPASS#ON_SOURCE', 'CALIBRATE_AMPLI#ON_SOURCE', \
#             'CALIBRATE_FLUX#ON_SOURCE', 'CALIBRATE_ATMOSPHERE#ON_SOURCE', 'CALIBRATE_POINTING#ON_SOURCE', 'CALIBRATE_SIDEBAND_RATIO#ON_SOURCE', \
#             'CALIBRATE_POLARIZATION#ON_SOURCE', 'CALIBRATE_DELAY#ON_SOURCE']
        intents = ['OBSERVE_TARGET', 'OBSERVE_CHECK_SOURCE', 'CALIBRATE_PHASE', 'CALIBRATE_BANDPASS', 'CALIBRATE_AMPLI', \
            'CALIBRATE_FLUX', 'CALIBRATE_ATMOSPHERE', 'CALIBRATE_POINTING', 'CALIBRATE_SIDEBAND_RATIO', \
            'CALIBRATE_POLARIZATION', 'CALIBRATE_DELAY', 'CALIBRATE_DIFFGAIN']

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = msmdtool()
            mymsmd.open(msName)

            if 'CALIBRATE_APPPHASE_ACTIVE#ON_SOURCE' in mymsmd.intents():
                intents.append('CALIBRATE_APPPHASE_ACTIVE')
                colors.append('blue')

            scanList = mymsmd.scannumbers()
            scanTimes1 = mymsmd.timesforscan(1)
            scanTimes2 = mymsmd.timesforscan(scanList[len(scanList)-1])

            if colorby == 'spw':

                spwList1 = mymsmd.chanavgspws()
                spwList2 = mymsmd.wvrspws()

                spwList = []
                for i in scanList:
                    spwList3 = mymsmd.spwsforscan(i)
                    spwList3 = [j for j in spwList3 if j not in spwList1]
                    spwList3 = [j for j in spwList3 if j not in spwList2]
#                     spwList.append(tuple(spwList3))
                    if tuple(spwList3) not in spwList: spwList.append(tuple(spwList3))

#                 spwList = np.unique(spwList)
                spwList = [list(j) for j in spwList]

        else:

            vm = ValueMapping(msName)
            scanList = vm.uniqueScans
            scanTimes1 = vm.getTimesForScan(1)
            scanTimes2 = vm.getTimesForScan(scanList[len(scanList)-1])

        obsStart = scanTimes1.min()
        obsEnd = scanTimes2.max()
        obsDuration = (obsEnd-obsStart) / 60.

        fig = plt.figure(figsize=(14,9))
        ax = fig.add_subplot(111)

        for i in scanList:

            if (getCasaVersion() >= casaVersionWithMSMD):

                scanTimes = mymsmd.timesforscan(i)
                scanIntent = mymsmd.intentsforscan(i)
            
            else:

                scanTimes = vm.getTimesForScan(i)
                scanIntent = vm.getIntentsForScan(i)

            scanStartTime = (scanTimes.min() - obsStart) / 60.
            scanDuration = (scanTimes.max() - scanTimes.min()) / 60.

            for j in range(len(intents)):

                for scanIntent2 in scanIntent:

                    if re.search(intents[j], scanIntent2, re.IGNORECASE) is not None:

                        scanY = 5*j

                        label1 = ''

                        if colorby == '':
                            scanColor = colors[0]

                        if colorby == 'intent':
                            scanColor = colors[scanY/5]

                        if colorby == 'spw':

                            spwList3 = mymsmd.spwsforscan(i)
                            spwList3 = [k for k in spwList3 if k not in spwList1]
                            spwList3 = [k for k in spwList3 if k not in spwList2]

                            scanColor = colors[spwList.index(spwList3)]
                        
                        ax.broken_barh([(scanStartTime, scanDuration)] , (scanY, 5), facecolors=scanColor)
                        ax.annotate(str(i), (scanStartTime, scanY+6))
                        
                        break

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd.close()

        if colorby == 'spw':
            for i in range(len(spwList)):
                print spwList[i], ' -> ', colors[i]

        ax.set_ylim(0, len(intents)*5+2.5)
        ax.set_xlim(-1, obsDuration+1)
        ax.set_xlabel('Minutes since start of observation')
        ax.set_yticks(np.array(range(len(intents)))*5+2.5)
        intents1 = [j.replace('#ON_SOURCE', '').replace('CALIBRATE', 'CAL').replace('OBSERVE', 'OBS').replace('SIDEBAND', 'SB') for j in intents]
        ax.set_yticklabels(intents1)
        ax.grid(True)

        obsStart=((obsStart/86400.0)+2400000.5-2440587.5)*86400.0
        obsEnd=((obsEnd/86400.0)+2400000.5-2440587.5)*86400.0
        plt.title('Measurement set = '+msName+' - Start time = '+timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsStart))+' - End time = '+timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsEnd)), fontsize = 12)

        if figfile != '': fig.savefig(figfile)

    def addReducScriptStep(self, fx=None, stepTitles=None, thisStepTitle=None, stepText=None, indent='  ', applyonly=False):
        # prints new step to file fx,
        # returns modified version of stepTitles

        applyonly = False ## to be removed once we move to CASA4.2

        if not (type(fx)==file):
            raise Exception("fx must be a file open for writing")

        if not (type(stepTitles)==dict):
            raise Exception("stepTitles must be a dictionary")
        currentNum = len(stepTitles)

        if not (type(thisStepTitle)==str):
            raise Exception("thisStepTitle must be a string")

        if not (type(stepText)==str):
            raise Exception("stepText must be a string")

        if not (type(indent)==str and len(indent)>1):
            raise Exception("indent must be a string of spaces with a length >= 2")

        stepText = indent + stepText.replace('\n','\n'+indent)

        print >> fx, "# "+thisStepTitle
        print >> fx, "mystep = "+str(currentNum)

        if applyonly == False:
            print >> fx, "if(mystep in thesteps):"
        else:
            print >> fx, "if(mystep in thesteps or applyonly == True):"

        print >> fx, indent+"casalog.post('Step '+str(mystep)+' '+step_title[mystep],'INFO')"
        print >> fx, indent+"print 'Step ', mystep, step_title[mystep]\n"
        print >> fx, stepText+"\n"

        stepTitles[currentNum] = thisStepTitle

        return stepTitles

    def prependReducScriptHeader(self, fx=None, stepTitles=None, scriptTitle='', indent='  '):

        if not (type(fx)==file):
            raise Exception("fx must be a file open for writing")

        if not (type(stepTitles)==dict):
            raise Exception("stepTitles must be a dictionary")

        if not (type(indent)==str and len(indent)>1):
            raise Exception("indent must be a string of spaces with a length >= 2")

#         myheader = "# ALMA Data Reduction Script\n\n" \
#                    + "# " + scriptTitle + "\n\n" \
#                    + "thesteps = []\n" \
#                    + "step_title = "+str(stepTitles).replace("'," , "',\n             " )+'\n\n' \
#                    + "if 'applyonly' not in globals(): applyonly = False\n" \
#                    + "if applyonly != True:\n" \
#                    + indent + "try:\n" \
#                    + indent + indent + "print 'List of steps to be executed ...', mysteps\n" \
#                    + indent + indent + "thesteps = mysteps\n" \
#                    + indent + "except:\n" \
#                    + indent + indent + "print 'global variable mysteps not set.'\n" \
#                    + indent + "if (thesteps==[]):\n" \
#                    + indent + indent + "thesteps = range(0,len(step_title))\n" \
#                    + indent + indent + "print 'Executing all steps: ', thesteps\n\n" \
#                    + "# The Python variable 'mysteps' will control which steps\n" \
#                    + "# are executed when you start the script using\n" \
#                    + "#   execfile('scriptForCalibration.py')\n" \
#                    + "# e.g. setting\n" \
#                    + "#   mysteps = [2,3,4]" \
#                    + "# before starting the script will make the script execute\n" \
#                    + "# only steps 2, 3, and 4\n" \
#                    + "# Setting mysteps = [] will make it execute all steps.\n"

# to be removed once we move to CASA4.2
        myheader = "# ALMA Data Reduction Script\n\n" \
                   + "# " + scriptTitle + "\n\n" \
                   + "thesteps = []\n" \
                   + "step_title = "+str(stepTitles).replace("'," , "',\n             " )+'\n\n' \
                   + "if 'applyonly' not in globals(): applyonly = False\n" \
                   + "try:\n" \
                   + indent + "print 'List of steps to be executed ...', mysteps\n" \
                   + indent + "thesteps = mysteps\n" \
                   + "except:\n" \
                   + indent + "print 'global variable mysteps not set.'\n" \
                   + "if (thesteps==[]):\n" \
                   + indent + "thesteps = range(0,len(step_title))\n" \
                   + indent + "print 'Executing all steps: ', thesteps\n\n" \
                   + "# The Python variable 'mysteps' will control which steps\n" \
                   + "# are executed when you start the script using\n" \
                   + "#   execfile('scriptForCalibration.py')\n" \
                   + "# e.g. setting\n" \
                   + "#   mysteps = [2,3,4]" \
                   + "# before starting the script will make the script execute\n" \
                   + "# only steps 2, 3, and 4\n" \
                   + "# Setting mysteps = [] will make it execute all steps.\n"

        sname = fx.name

        fx.close()
        fx = open(sname, 'r+')
        old = fx.read() # read everything in the file
        fx.seek(0) # rewind
        fx.write(myheader +"\n"+ old) # prepend the header

        return True

    def generateReducScript(self, msNames='', step='calib', corrAntPos=True, timeBinForFinalData=0., refant='', bpassCalId='', chanWid=1, angScale=0, run=False, lowSNR=False, projectCode='', schedblockName='', schedblockUid='', queue='', state='', upToTimeForState=2, useLocalAlmaHelper=False, tsysChanTol=1, sdQSOflux=1, runPhaseClosure=False, skipSyscalChecks=False, lazy=False, lbc=False, phaseDiff='', remcloud=False, bdfflags=True, phaseDiffPerSpwSetup=False, tsysPerField=False, splitMyScienceSpw=True, bpassCalTableName=''):
        """
        msNames: a string or a list of strings of UIDs (either ASDM or MS) to process
        step: calib, softreg, fluxcal, imaging, wvr, all, calsurvey, SDeff, SDcalibLine, SDcalibCont
        corrAntPos: if True, then run correctMyAntennaPositions
        timeBinForFinalData: a value in seconds (string, int, or float), passed to split
        refant: the reference antenna to use (instead of automatic selection), must be a string
        bpassCalId: use the specified source for bandpass (rather than the intents)
        chanWid: integer, used by runCleanOnSource and searchForLines
        angScale: value in arcsec, used by runCleanOnSource and searchForLines
        run: if True, then run the script after creating it
        lowSNR: Boolean passed to doBandpassCalibration to use whole spw for pre-bandpass phase-up
        projectCode, schedblockName, queue, state, upToTimeForState: used for automatically finding EBs
        useLocalAlmaHelper: if True, run tsysspwmap inside generator, rather than in the resulting script
        tsysChanTol: integer argument passed to tsysspwmap
        sdQSOflux: flux density to use for quasar in single dish case (step='SDeff')
        runPhaseClosure: if True, then run au.phaseClosureStats
        skipSyscalChecks: if True, then don't check for negative Tsys problems
        lbc: if True, invoke long-baseline campaign usage in correctMyAntennaPositions, i.e.
                  search='both_latest' and  maxSearchDays=30
        """
        if (useLocalAlmaHelper):
            try:
                from almahelpers_localcopy import tsysspwmap
            except:
                from recipes.almahelpers import tsysspwmap
        else:
            from recipes.almahelpers import tsysspwmap

        if (type(refant) != str):
            print "refant must be a string"
            return
        if state != '':

            password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            top_level_url = 'http://www.alma.cl/~evillard/ProjectTracking/Cycle1/ScriptGenerator'
            handler = urllib2.HTTPBasicAuthHandler(password_mgr)
            opener = urllib2.build_opener(handler)
            allBlocks = opener.open('http://www.alma.cl/~evillard/ProjectTracking/Cycle1/ScriptGenerator/'+state+'.txt').read().splitlines()

            utcDateNow = datetime.datetime.utcnow()

            if state in ['QA0_PASS', 'QA0_FAIL']:

                msNames = []

                for i in range(len(allBlocks)):

                    block1 = allBlocks[i].strip()
                    if re.search('^\*', block1) == None: continue

                    execblockUid = re.findall('uid://[A-Za-z0-9]+/[A-Za-z0-9]+/[A-Za-z0-9]+', block1)
                    if len(execblockUid) != 1: continue
                    execblockUid = execblockUid[0]

                    stateDate = re.findall('\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', block1)
                    if len(stateDate) != 1: continue
                    stateDate = stateDate[0]

                    stateDate = datetime.datetime.strptime(stateDate, '%Y-%m-%d %H:%M:%S')
                    dateDiff = utcDateNow - stateDate
                    dateDiff = dateDiff.days + dateDiff.seconds / 86400.

                    if dateDiff < upToTimeForState/24.: msNames.append(execblockUid)
    
                for i in range(len(msNames)): msNames[i] = re.sub(':|/', '_', msNames[i])
                print 'Found the following EBs: '+str(msNames)

        if queue != '':

            if os.path.isfile(queue) == False: sys.exit('ERROR: queue file does not exist.')
            f = open(queue)
            fc = f.readlines()
            f.close()

            ij = -1
            queue1 = {}

            for i in range(len(fc)):

                line = fc[i].strip()
                if len(line) == 0: continue
                if line[0] == '#': continue

                if re.search('^uid\:\/\/[0-9a-z]+\/[0-9a-z]+\/[0-9a-z]+', line, re.IGNORECASE) is not None:
                    ij += 1
                    queue1[ij] = {}
                    queue1[ij]['execblockUid'] = re.findall('^uid\:\/\/[0-9a-z]+\/[0-9a-z]+\/[0-9a-z]+', line, re.IGNORECASE)[0]

                if re.search('^201[0-9]\.[0-9]\.[0-9]{5}.[A-Z] ', line, re.IGNORECASE) is not None:
                    ij += 1
                    queue1[ij] = {}
                    queue1[ij]['projectCode'] = re.findall('^201[0-9]\.[0-9]\.[0-9]{5}.[A-Z]', line, re.IGNORECASE)[0]
                    queue1[ij]['schedblockName'] = re.findall('(?<=^201[0-9]\.[0-9]\.[0-9]{5}.[A-Z] ).+', line, re.IGNORECASE)[0].strip()

            msNames = []
            for i in queue1:
                if 'execblockUid' in queue1[i]:
                    msNames.append(queue1[i]['execblockUid'])
            msNames = sorted(msNames)
            self.generateReducScript(msNames=msNames, step=step, refant=refant, bpassCalId=bpassCalId, run=run, lowSNR=lowSNR, lbc=lbc, phaseDiff=phaseDiff, remcloud=remcloud)
#            print "self.generateReducScript(msNames="+str(msNames)+", step='"+step+"', refant='"+refant+"', bpassCalId='"+bpassCalId+"', run="+str(run)+", lowSNR="+str(lowSNR)+")"

#             for i in queue1:
#                 if 'projectCode' in queue1[i] and 'schedblockName' in queue1[i]:
#                     self.generateReducScript(projectCode=queue1[i]['projectCode'], schedblockName=queue1[i]['schedblockName'], step=step, refant=refant, bpassCalId=bpassCalId, run=run, lowSNR=lowSNR)
# #                    print "self.generateReducScript(projectCode='"+queue1[i]['projectCode']+"', schedblockName='"+queue1[i]['schedblockName']+"', step='"+step+"', refant='"+refant+"', bpassCalId='"+bpassCalId+"', run="+str(run)+", lowSNR="+str(lowSNR)+")"

            for i in queue1:
                if 'projectCode' in queue1[i] and 'schedblockName' in queue1[i]:
                    prj_sb_file = open(queue1[i]['projectCode']+'_'+queue1[i]['schedblockName']+'_launchScript.py','w')
                    log_file = open(queue1[i]['projectCode']+'_'+queue1[i]['schedblockName']+'_logfile.log','w')
                    if type(phaseDiff) == str:
                        text_of_file = "es.generateReducScript(projectCode='"+queue1[i]['projectCode']+"', schedblockName='"+queue1[i]['schedblockName']+"', step='"+step+"', refant='"+refant+"', bpassCalId='"+bpassCalId+"', run="+str(run)+", lowSNR="+str(lowSNR)+", lbc="+str(lbc)+", phaseDiff='"+phaseDiff+"', remcloud="+str(remcloud)+")"
                    else:
                        text_of_file = "es.generateReducScript(projectCode='"+queue1[i]['projectCode']+"', schedblockName='"+queue1[i]['schedblockName']+"', step='"+step+"', refant='"+refant+"', bpassCalId='"+bpassCalId+"', run="+str(run)+", lowSNR="+str(lowSNR)+", lbc="+str(lbc)+", phaseDiff="+str(phaseDiff)+", remcloud="+str(remcloud)+")"
                    prj_sb_file.write(text_of_file)
                    prj_sb_file.close()
                    server = subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', queue1[i]['projectCode']+'_'+queue1[i]['schedblockName']+'_launchScript.py'], stdout=log_file , stderr=log_file)

            return(0)

        latestValidatedVersion = '4.4.0' # 2015-08-20
        if re.search('^'+latestValidatedVersion, getCasaVersion()) == None:
            print 'WARNING: You are currently running CASA %s rather than CASA %s.' % (getCasaVersion(), latestValidatedVersion)
            print 'WARNING: The scripts have been ported, but for a bit of time, please be careful with the output.'
            print 'WARNING: If you observe any issue or strange behavior, please send an email to Eric V. (evillard@alma.cl)'
#            raw_input('Hit a key to proceed.')

        if type(msNames).__name__ == 'str': msNames = [msNames]
###        if type(msNames).__name__ == 'str': msNames = glob.glob(msNames)
###        for i in range(len(msNames)): msNames[i] = msNames[i].rstrip(os.path.sep)

        if ((projectCode != '' and schedblockName != '') or schedblockUid != '') and step in ['calib', 'all', 'SDscience']:

            password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            top_level_url = 'http://www.alma.cl/~evillard/ProjectTracking/Cycle1/DataReducer'
            handler = urllib2.HTTPBasicAuthHandler(password_mgr)
            opener = urllib2.build_opener(handler)
            allExecblocks1 = opener.open('http://www.alma.cl/~evillard/ProjectTracking/Cycle1/DataReducer/allExecblocks_QA0_PASS.txt').read().splitlines()

            password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            top_level_url = 'http://www.alma.cl/~evillard/ProjectTracking/Cycle2/DataReducer'
            handler = urllib2.HTTPBasicAuthHandler(password_mgr)
            opener = urllib2.build_opener(handler)
            allExecblocks2 = opener.open('http://www.alma.cl/~evillard/ProjectTracking/Cycle2/DataReducer/allExecblocks_QA0_PASS.txt').read().splitlines()

            password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            top_level_url = 'http://www.alma.cl/~evillard/ProjectTracking/Cycle3/DataReducer'
            handler = urllib2.HTTPBasicAuthHandler(password_mgr)
            opener = urllib2.build_opener(handler)
            allExecblocks3 = opener.open('http://www.alma.cl/~evillard/ProjectTracking/Cycle3/DataReducer/allExecblocks_QA0_PASS.txt').read().splitlines()

            password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()
            top_level_url = 'http://www.alma.cl/~evillard/ProjectTracking/Cycle4/DataReducer'
            handler = urllib2.HTTPBasicAuthHandler(password_mgr)
            opener = urllib2.build_opener(handler)
            allExecblocks4 = opener.open('http://www.alma.cl/~evillard/ProjectTracking/Cycle4/DataReducer/allExecblocks_QA0_PASS.txt').read().splitlines()

            allExecblocks = allExecblocks1 + allExecblocks2 + allExecblocks3 + allExecblocks4

            msNames = []
            schedblockUids = []
            for i in range(len(allExecblocks)):
                if allExecblocks[i].strip() == '': continue
                block1 = allExecblocks[i].split('\t')

                if schedblockUid != '':

                    if block1[3].strip() == schedblockUid:
                        msNames.append(block1[4].strip())
                        schedblockUids.append(block1[3].strip())

                else:

                    if block1[0].strip() == projectCode and block1[2].strip() == schedblockName:
                        msNames.append(block1[4].strip())
                        schedblockUids.append(block1[3].strip())

            schedblockUids = sorted(dict.fromkeys(schedblockUids).keys())
            if len(schedblockUids) != 1: sys.exit('ERROR: Found zero SB, or more than one.')

            for i in range(len(msNames)): msNames[i] = re.sub(':|/', '_', msNames[i])
            print 'Found the following EBs: '+str(msNames)

            valid_chars = "-_%s%s" % (string.ascii_letters, string.digits)

            if schedblockUid != '':

#                 schedblockUid1 = ''.join(i for i in schedblockUid if i in valid_chars)
                schedblockUid1 = schedblockUid.replace('/', '_').replace(':', '_')
                schedblockDir = 'SB_'+schedblockUid1

            else:

                schedblockName1 = ''.join(i for i in schedblockName if i in valid_chars)
                schedblockDir = 'SB_'+projectCode+'_'+schedblockName1

            if os.path.isdir(schedblockDir) == True:
                i = 0
                while os.path.isdir(schedblockDir+'_'+str(i)) == True: i += 1
                schedblockDir = schedblockDir+'_'+str(i)
            print 'Creating directory: ', schedblockDir
            os.mkdir(schedblockDir)
            print 'Changing current working directory to: ', schedblockDir
            os.chdir(schedblockDir)

        currDir = os.getcwd()
###        msNames = sorted(msNames)

###        for i in range(len(msNames)):

#         if step == 'softreg':
#             asis1 = 'Antenna Station Receiver Source CalAtmosphere CalWVR'
#         else:
#             asis1 = 'Antenna Station Receiver Source CalAtmosphere CalWVR'

        asis1 = 'Antenna Station Receiver Source CalAtmosphere CalWVR CorrelatorMode SBSummary'

        if step in ['SDcalibLine', 'SDcalibCont', 'SDampcal', 'SDscience']:
            with_pointing_correction = True
        else:
            with_pointing_correction = False

        i = 0

        while i < len(msNames):

            msNames[i] = msNames[i].rstrip(os.path.sep)

            if re.search('^uid\:\/\/[0-9a-z]+\/[0-9a-z]+\/[0-9a-z]+$', msNames[i], re.IGNORECASE) is not None:
                msNames[i] = re.sub(':|/', '_', msNames[i])

            corrModes1 = ''

            if re.search('^uid___[0-9a-z]+_[0-9a-z]+_[0-9a-z]+$', msNames[i], re.IGNORECASE) is not None:

                if os.path.exists(msNames[i]) == True:

                    if os.path.exists(msNames[i]+'.ms') == False:

                        print 'WARNING: The asdm exists, but the ms does not exist, running importasdm.'

                        if getCasaVersion() >= '4.2.2':

                            f1 = open(msNames[i]+'/CorrelatorMode.xml')
                            fc1 = f1.read()
                            f1.close()

                            corrModes = re.findall('<correlatorName>.*?</correlatorName>', fc1, re.IGNORECASE)
                            if len(corrModes) == 0: sys.exit('ERROR')
                            corrModes1 = []
                            for j in range(len(corrModes)):
                                corrModes1.append(corrModes[j].replace('<correlatorName>', '').replace('</correlatorName>', ''))
                            corrModes1 = np.unique(corrModes1).tolist()
                            if len(corrModes1) != 1: sys.exit('ERROR')
                            corrModes1 = corrModes1[0]
                            if corrModes1 not in ['ALMA_ACA', 'ALMA_BASELINE']: sys.exit('ERROR')

                        if getCasaVersion() >= '4.7.2':

                            if corrModes1 == 'ALMA_ACA':
                                importasdm(msNames[i], asis=asis1, bdfflags=False, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)
                                if bdfflags == True:
                                    print 'WARNING: This is an ACA dataset: the BDF flags must be applied separately.'
                                    os.system(os.environ['CASAPATH'].split()[0]+'/bin/bdflags2MS -f "COR DELA INT MIS SIG SYN TFB WVR ZER" '+msNames[i]+' '+msNames[i]+'.ms')
                            else:
                                importasdm(msNames[i], asis=asis1, bdfflags=bdfflags, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)

                        elif getCasaVersion() >= '4.7.0' and getCasaVersion() < '4.7.2':

                            if corrModes1 == 'ALMA_ACA':
                                importasdm(msNames[i], asis=asis1, bdfflags=False)
                            else:
                                importasdm(msNames[i], asis=asis1, bdfflags=bdfflags)

                        elif getCasaVersion() >= '4.2.2' and getCasaVersion() < '4.7.0':

                            importasdm(msNames[i], asis=asis1, bdfflags=False)

                        else:

                            importasdm(msNames[i], asis=asis1)

                elif os.path.exists('../'+msNames[i]):  # Added by Todd for people outside JAO

                    if getCasaVersion() >= '4.2.2':

                        f1 = open('../'+msNames[i]+'/CorrelatorMode.xml')
                        fc1 = f1.read()
                        f1.close()

                        corrModes = re.findall('<correlatorName>.*?</correlatorName>', fc1, re.IGNORECASE)
                        if len(corrModes) == 0: sys.exit('ERROR')
                        corrModes1 = []
                        for j in range(len(corrModes)):
                            corrModes1.append(corrModes[j].replace('<correlatorName>', '').replace('</correlatorName>', ''))
                        corrModes1 = np.unique(corrModes1).tolist()
                        if len(corrModes1) != 1: sys.exit('ERROR')
                        corrModes1 = corrModes1[0]
                        if corrModes1 not in ['ALMA_ACA', 'ALMA_BASELINE']: sys.exit('ERROR')

                    if getCasaVersion() >= '4.7.2':

                        if corrModes1 == 'ALMA_ACA':
                            importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1, bdfflags=False, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)
                            if bdfflags == True:
                                print 'WARNING: This is an ACA dataset: the BDF flags must be applied separately.'
                                os.system(os.environ['CASAPATH'].split()[0]+'/bin/bdflags2MS -f "COR DELA INT MIS SIG SYN TFB WVR ZER" ../'+msNames[i]+' ./'+msNames[i]+'.ms')
                        else:
                            importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1, bdfflags=bdfflags, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)

                    elif getCasaVersion() >= '4.7.0' and getCasaVersion() < '4.7.2':

                        if corrModes1 == 'ALMA_ACA':
                            importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1, bdfflags=False)
                        else:
                            importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1, bdfflags=bdfflags)

                    elif getCasaVersion() >= '4.2.2' and getCasaVersion() < '4.7.0':

                        importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1, bdfflags=False)

                    else:

                        importasdm('../'+msNames[i], vis='./'+msNames[i]+'.ms', asis=asis1)

                else:

                    if os.path.exists(msNames[i]+'.ms') == False:

                        print 'WARNING: Neither the asdm nor the ms exists, running asdmExport.'

                        out1 = os.system('asdmExport '+msNames[i])
                        if out1 > 0:
                            os.system('/usr/local/bin/asdmExport '+msNames[i])
                        if os.path.exists(msNames[i]+'.tar') == True:
                            os.system('tar xvf '+msNames[i]+'.tar')

                        print 'WARNING: The ms does not exist, running importasdm.'

                        if getCasaVersion() >= '4.2.2':

                            f1 = open(msNames[i]+'/CorrelatorMode.xml')
                            fc1 = f1.read()
                            f1.close()

                            corrModes = re.findall('<correlatorName>.*?</correlatorName>', fc1, re.IGNORECASE)
                            if len(corrModes) == 0: sys.exit('ERROR')
                            corrModes1 = []
                            for j in range(len(corrModes)):
                                corrModes1.append(corrModes[j].replace('<correlatorName>', '').replace('</correlatorName>', ''))
                            corrModes1 = np.unique(corrModes1).tolist()
                            if len(corrModes1) != 1: sys.exit('ERROR')
                            corrModes1 = corrModes1[0]
                            if corrModes1 not in ['ALMA_ACA', 'ALMA_BASELINE']: sys.exit('ERROR')

                        if getCasaVersion() >= '4.7.2':

                            if corrModes1 == 'ALMA_ACA':
                                importasdm(msNames[i], asis=asis1, bdfflags=False, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)
                                if bdfflags == True:
                                    print 'WARNING: This is an ACA dataset: the BDF flags must be applied separately.'
                                    os.system(os.environ['CASAPATH'].split()[0]+'/bin/bdflags2MS -f "COR DELA INT MIS SIG SYN TFB WVR ZER" '+msNames[i]+' '+msNames[i]+'.ms')
                            else:
                                importasdm(msNames[i], asis=asis1, bdfflags=bdfflags, lazy=lazy, process_caldevice=False, with_pointing_correction=with_pointing_correction)

                        elif getCasaVersion() >= '4.7.0' and getCasaVersion() < '4.7.2':

                            if corrModes1 == 'ALMA_ACA':
                                importasdm(msNames[i], asis=asis1, bdfflags=False)
                            else:
                                importasdm(msNames[i], asis=asis1, bdfflags=bdfflags)

                        elif getCasaVersion() >= '4.2.2' and getCasaVersion() < '4.7.0':

                            importasdm(msNames[i], asis=asis1, bdfflags=False)

                        else:

                            importasdm(msNames[i], asis=asis1)

                msNames[i] = msNames[i]+'.ms'

            else:

                if os.path.exists(msNames[i]) == False:

                    msName1 = glob.glob(msNames[i])
                    if len(msName1) == 0: sys.exit('ERROR: '+msNames[i]+' does not seem to exist in the current directory.')
                    msNames.pop(i)
                    for j in msName1: msNames.insert(i, j)

            if getCasaVersion() >= '4.2.2' and corrModes1 == '':

                tb.open(msNames[i])
                keywordnames1 = tb.keywordnames()
                tb.close()

                if 'ASDM_CORRELATORMODE' not in keywordnames1:
                
                    print '\n\n\nWARNING: You have not imported the CorrelatorMode table from the ASDM.'
                    print 'WARNING: If this is a 12m array dataset, then it is Ok. Otherwise, please regenerate the MS using the script generator.\n\n\n'

                else:

                    tb.open(msNames[i]+'/ASDM_CORRELATORMODE')
                    corrModes1 = np.unique(tb.getcol('correlatorName'))
                    tb.close()

                    if len(corrModes1) != 1: sys.exit('ERROR')
                    if corrModes1 == 'ALMA_ACA':

                        print '\n\n\nWARNING: This is a 7m/TP array dataset. It seems you have not used the script generator to generate the MS.'
                        print 'WARNING: Please note that the application of the BDF flags is particular. It is recommended that you use the script generator to generate the MS.\n\n\n'

            i = i+1

        msNames = sorted(msNames)

        for i in range(len(msNames)):

            if step not in ['fluxcal', 'imaging']: self.fixForCSV2555(msNames[i])

            if os.getlogin == 'aod':
                self.listOfIntentsWithSources(msNames[i])
                self.listobs3(msNames[i], figfile=msNames[i]+'.listobs3.png')
                self.plotAntennas(msNames[i])
                tosInfo = timeOnSource(msNames[i])

            spwInfo = self.getSpwInfo(msNames[i])
            spwIds = sorted(spwInfo.keys())
            vm = ValueMapping(msNames[i])
            spwScans = vm.getScansForSpw(spwIds[0]).tolist()
            for j in spwIds:
                if vm.getScansForSpw(j).tolist() != spwScans:
                    print 'WARNING: The scans are not the same for all science spws.'
                    print 'WARNING: The script generator is not compatible with this, it will very likely fail.'
                    print 'WARNING: If it does not fail, do not expect the reduction script to be good. Please check it carefully.'
#                    raw_input('Hit a key to proceed.')

        if step == 'wvr':

            for msName in msNames:

                f1 = open(msName+'.scriptForWVRCalibration.py', 'w')
                print >> f1, "import re\n"
                print >> f1, "es = aU.stuffForScienceDataReduction() \n\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                myRefAnt = refant
                if myRefAnt == '': myRefAnt = self.getRefAntenna(msName)
                print >> f1, "# Using reference antenna = "+myRefAnt+"\n"

                print >> f1, self.doAprioriFlagging(msName)
                print >> f1, self.generateWVRCalTable(msName)
                print >> f1, "es.wvr_stat(ms1='"+msName+"', refAnt='"+myRefAnt+"', qa2_output_dir='./')\n"

                f1.close()

        if step == 'softreg':

            msNamesDir = []

            for msName in msNames:

                mystepdict = {}
                mystepindent = "  "

                #msName = re.search('uid___[a-zA-Z0-9]+_[a-zA-Z0-9]+_[a-zA-Z0-9]+\.ms', msNames[i])
                #if msName == None: sys.exit('ERROR: '+msNames[i]+' does not seem to be a standard ms.')
                #msName = msName.group(0)
                #if os.path.exists(msName) == False: sys.exit('ERROR: '+msNames[i]+' does not seem to exist in the current directory.')

                if run == True:
                    os.chdir(currDir)
                    subDir = 'EB'+str(msNames.index(msName))+'_'+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]
                    os.mkdir(subDir)
                    msNamesDir.append(subDir)
#                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'* '+subDir)
                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'.* '+subDir)
                    os.chdir(subDir)

                tsysmap = ''
                if re.search('^3.3', getCasaVersion()) == None and useLocalAlmaHelper == True:
                    os.system('rm -Rf '+msName+'.tsys.temp')
                    gencal(vis = msName, caltable = msName+'.tsys.temp', caltype = 'tsys')
                    tsysmap = tsysspwmap(vis = msName, tsystable = msName+'.tsys.temp', tsysChanTol=tsysChanTol)
                    os.system('rm -Rf '+msName+'.tsys.temp')
                    vm = ValueMapping(msName)
                    spwInfo = self.getSpwInfo(msName)
                    spwIds = sorted(spwInfo.keys())
                    for j in spwIds:
#                        if tsysmap[j] == -1:
                        spwIntents = vm.getIntentsForSpw(tsysmap[j])
                        if 'CALIBRATE_ATMOSPHERE#ON_SOURCE' not in spwIntents:
                            sys.exit('ERROR: INCOMPLETE TSYS SPW MAPPING!')

                f1 = open(msName+'.scriptForSoftwareCheckout.py', 'w')
                print >> f1, "import re\n"
                print >> f1, "es = aU.stuffForScienceDataReduction() \n\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                tempStdout = sys.stdout
                sys.stdout = f1
                self.listOfIntentsWithSources(msName)
                sys.stdout = tempStdout

                myRefAnt = refant
                if myRefAnt == '': myRefAnt = self.getRefAntenna(msName)
                print >> f1, "\n# Using reference antenna = "+myRefAnt+"\n"

                print >> f1, 'print "# A priori calibration"\n'
                stext = self.runFixPlanets(msName)
                if stext is not None: self.addReducScriptStep(f1, mystepdict, "Running fixplanets on fields with 0,0 coordinates", stext, mystepindent)

                stext = "os.system('rm -rf %s.listobs')\n" %(msName) # Added by CLB
                stext += "listobs(vis = '"+msName+"',\n  listfile = '"+msName+".listobs')\n\n" # Modified by CLB
                stext += "f = open('"+msName+".listobs')\nfc = f.read()\nf.close()\n\n"
                stext += "scanList = re.findall('(?<=[0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9] - [0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]).*', fc)\nf = open('"+msName+".scanlist', 'w')\nf.write(repr(scanList))\nf.close()\n\n"
                stext += "spwList = re.findall('.*ALMA_RB_[0-9]{2}#BB_[0-9]#SW-[0-9]{2}#.*', fc)\nf = open('"+msName+".spwlist', 'w')\nf.write(repr(spwList))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "listobs", stext, mystepindent)

                stext = "tos1 = aU.timeOnSource('"+msName+"')\n\nf = open('"+msName+".timeonsource', 'w')\nf.write(repr(tos1))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "timeOnSource", stext, mystepindent)

                stext = "tempStdout = sys.stdout\n\nsys.stdout = open('"+msName+".sbgains1', 'w')\nSBinfo = aU.plotSBGain('"+msName+"', doplot = False)\n\nsys.stdout = tempStdout\n\n"
                stext += "f = open('"+msName+".sbgains', 'w')\nf.write(repr(SBinfo))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "SB gains", stext, mystepindent)

                stext = "ptgResults = aU.plotPointingResultsFromASDM('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', doplot=False, thresholdArcsec=10.0, fractionOfScansBad=0.6)"
                stext += "\n\nf = open('"+msName+".pointingresults', 'w')\nf.write(repr(ptgResults))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "Pointing results", stext, mystepindent)

                stext = self.doAprioriFlagging(msName)
                self.addReducScriptStep(f1, mystepdict, "A priori flagging", stext, mystepindent)

                stext = "es.saveFlagStats('"+msName+"', name='after a priori flagging', statsFile='"+msName+".flagstats')"
                self.addReducScriptStep(f1, mystepdict, "Saving flag stats after a priori flagging", stext, mystepindent)

                wvrCalTableName = []
                stext = self.generateWVRCalTable(msName, wvrCalTableName, refant=myRefAnt, doplot=False)
                if stext != '':
                    stext += "wvrInfo = es.readWvrgcalOutput('"+msName+".wvrgcal')\n\nf = open('"+msName+".wvrgcal2', 'w')\nf.write(repr(wvrInfo))\nf.close()\n\n"
                    stext += "#es.wvr_stat(ms1='"+msName+"', refAnt='"+myRefAnt+"', qa2_output_dir='./')\n\n"
                self.addReducScriptStep(f1, mystepdict, "Generation and time averaging of the WVR cal table", stext, mystepindent)

                tsysCalTableName = []
                stext = self.generateTsysCalTable(msName, tsysCalTableName, doplot=False)
                stext += "tempStdout = sys.stdout\n\nsys.stdout = open('"+msName+".negativetsys', 'w')\naU.detectNegativeTsys('"+msName+"', edge=8)\n\n"
                stext += "sys.stdout = open('"+msName+".negativetrec', 'w')\naU.detectNegativeTrx('"+msName+"', edge=8)\n\nsys.stdout = tempStdout\n\n"
                stext += "mydict = aU.plotbandpass('"+tsysCalTableName[0]+"', interactive=False, channeldiff=6)\n\n"
                stext += "f = open('"+tsysCalTableName[0]+".platforming', 'w')\nf.write(repr(mydict['platforming']))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "Generation of the Tsys cal table", stext, mystepindent)

                stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0], tsysmap=tsysmap)
                self.addReducScriptStep(f1, mystepdict, "Application of the WVR and Tsys cal tables", stext, mystepindent)

                stext = "es.saveFlagStats('"+msName+"', name='after applying WVR and Tsys cal tables', statsFile='"+msName+".flagstats')"
                self.addReducScriptStep(f1, mystepdict, "Saving flag stats after applying WVR and Tsys cal tables", stext, mystepindent)

                stext = self.split2(msName, splitMyScienceSpw=True, timebin=timeBinForFinalData)
                self.addReducScriptStep(f1, mystepdict, "Split out science SPWs and time average", stext, mystepindent)

                print >> f1, 'print "# Calibration"\n'
                stext = self.doInitialFlagging(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True)
                self.addReducScriptStep(f1, mystepdict, "Initial flagging", stext, mystepindent)

                stext = "es.saveFlagStats('"+msName+".split', name='after initial flagging', statsFile='"+msName+".flagstats')"
                self.addReducScriptStep(f1, mystepdict, "Saving flag stats after initial flagging", stext, mystepindent)

                stext = self.runSetjy(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True)
                self.addReducScriptStep(f1, mystepdict, "Putting a model for the flux calibrator(s)", stext, mystepindent)
                bpassCalTableName = []
                stext = self.doBandpassCalibration(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True, refant=myRefAnt, calTableName=bpassCalTableName, lowSNR=lowSNR, doplot=False)
                stext += "mydict = aU.plotbandpass('"+bpassCalTableName[0]+"', interactive=False, channeldiff=6)\n\n"
                stext += "f = open('"+bpassCalTableName[0]+".platforming', 'w')\nf.write(repr(mydict['platforming']))\nf.close()\n\n"
                self.addReducScriptStep(f1, mystepdict, "Bandpass calibration", stext, mystepindent)
                stext = self.doGainCalibration(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True, refant=myRefAnt, bandpass=bpassCalTableName[0], doplot=False, calFieldsOnly=False)
                stext += "sys.stdout = open('"+msName+".delayjumps', 'w')\nes.detectDelayJumps(msname = '"+msName+"')\n\nsys.stdout = tempStdout\n\n"
                self.addReducScriptStep(f1, mystepdict, "Gain calibration", stext, mystepindent)

                stext = self.applyBandpassAndGainCalTables(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True, bandpass=bpassCalTableName[0], phaseForCal=msName+'.split.phase_int', phaseForSci=msName+'.split.phase_inf', flux=msName+'.split.flux_inf')
                self.addReducScriptStep(f1, mystepdict, "Application of the bandpass and gain cal tables", stext, mystepindent)

                stext = "es.saveFlagStats('"+msName+".split', name='after applying bandpass and gain cal tables', statsFile='"+msName+".flagstats')"
                self.addReducScriptStep(f1, mystepdict, "Saving flag stats after applying bandpass and gain cal tables", stext, mystepindent)

                if runPhaseClosure == True:
                    stext = "clos1 = aU.phaseClosureStats('"+msName+"', chanEdge = 0.4)\n\nf = open('"+msName+".phaseclosure', 'w')\nf.write(repr(clos1))\nf.close()\n\n"
                    self.addReducScriptStep(f1, mystepdict, "Check of phase closures (on bandpass calibrator scan)", stext, mystepindent)

                stext = "es.analyseSoftregOutputs('"+msName+"')"
                self.addReducScriptStep(f1, mystepdict, "Final assessment", stext, mystepindent)

                self.prependReducScriptHeader(f1, mystepdict, "Calibration", mystepindent)

                f1.close()

                print "\n\nName of generated script -> "+msName+".scriptForSoftwareCheckout.py"

            if run == True:
                for msName in msNames:
                    os.chdir(os.path.join(currDir, msNamesDir[msNames.index(msName)]))
                    clearstat()
                    subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', msName+'.scriptForSoftwareCheckout.py'])

        if step in ['calib', 'all']:

            msNamesDir = []

            for msName in msNames:

                mystepdict = {}
                mystepindent = "  "

                #msName = re.search('uid___[a-zA-Z0-9]+_[a-zA-Z0-9]+_[a-zA-Z0-9]+\.ms', msNames[i])
                #if msName == None: sys.exit('ERROR: '+msNames[i]+' does not seem to be a standard ms.')
                #msName = msName.group(0)
                #if os.path.exists(msName) == False: sys.exit('ERROR: '+msNames[i]+' does not seem to exist in the current directory.')

                if run == True or (projectCode != '' and schedblockName != '') or schedblockUid != '':
                    os.chdir(currDir)
                    subDir = 'EB'+str(msNames.index(msName))+'_'+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]
                    os.mkdir(subDir)
                    msNamesDir.append(subDir)
#                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'* '+subDir)
                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'.* '+subDir)
                    os.chdir(subDir)

                tsysmap = ''
                if re.search('^3.3', getCasaVersion()) == None and skipSyscalChecks == False:

                    print "\n*** ANALYSIS OF TSYS TABLE ***"

                    print "\n*** SEARCH FOR NEGATIVE TSYS ***"
                    detectNegativeTsys(vis = msName, edge = 8, showfield = True)

                    print "\n*** SEARCH FOR NEGATIVE TREC ***"
                    detectNegativeTrx(vis = msName, edge = 8, showfield = True)

                    os.system('rm -Rf '+msName+'.tsys.temp')
                    gencal(vis = msName, caltable = msName+'.tsys.temp', caltype = 'tsys')

                    print "\n*** SEARCH FOR MISSING SCANS IN SYSCAL TABLE ***"
                    mymsmd = msmdtool()
                    mymsmd.open(msName)
                    if (getCasaVersion() >= '4.2.0'):
                        scans1 = sorted(mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#*').tolist()) # T. Hunter 2014-08-14
                        # There are cases, e.g. uid___A002_X7ea111_Xc03.ms where the OFF_SOURCE intent is present
                        # in the ms but the ON_SOURCE is not, but the corresponding Tsys value is present.
                        # As of 4.2.0, the forintent methods of msmd accept the wildcard character.
                    else:
                        scans1 = sorted(mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE').tolist())
                    mymsmd.close()

                    tb.open(msName+'.tsys.temp')                    
                    scans2 = sorted(np.unique(tb.getcol('SCAN_NUMBER')).tolist())
                    tb.close()

                    if len(scans1) == 0 or len(scans2) == 0 or scans1 != scans2:
                        print "len(scans1)=%d, len(scans2)=%d" % (len(scans1), len(scans2))
                        sys.exit('ERROR: THE SYSCAL TABLE IS MISSING ONE (OR MORE) SCAN(S). IT MAY BE NECESSARY TO RE-GENERATE IT.')
                    else:
                        print "-> OK"

                    if useLocalAlmaHelper == True:
                        tsysmap = tsysspwmap(vis = msName, tsystable = msName+'.tsys.temp', tsysChanTol=tsysChanTol)
                        vm = ValueMapping(msName)
                        spwInfo = self.getSpwInfo(msName)
                        spwIds = sorted(spwInfo.keys())
                        for j in spwIds:
#                        if tsysmap[j] == -1:
                            spwIntents = vm.getIntentsForSpw(tsysmap[j])
                            if 'CALIBRATE_ATMOSPHERE#ON_SOURCE' not in spwIntents:
                                sys.exit('ERROR: INCOMPLETE TSYS SPW MAPPING!')

                    os.system('rm -Rf '+msName+'.tsys.temp')


                f1 = open(msName+'.scriptForCalibration.py', 'w')
                print >> f1, "import re\n"
                print >> f1, "import os\n"
                print >> f1, "import casadef\n"
                print >> f1, "if applyonly != True: es = aU.stuffForScienceDataReduction() \n\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                tempStdout = sys.stdout
                sys.stdout = f1
                self.listOfIntentsWithSources(msName)
                sys.stdout = tempStdout

                myRefAnt = refant
                if myRefAnt == '': myRefAnt = self.getRefAntenna(msName, lbc=lbc)
                print >> f1, "\n# Using reference antenna = "+myRefAnt+"\n"

                stext = "if os.path.exists('"+msName+"') == False:\n"

                if getCasaVersion() >= '4.7.2':

                    if corrModes1 == 'ALMA_ACA':
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False, lazy="+str(lazy)+", process_caldevice=False)"
                        if bdfflags == True:
                            stext += "\n  os.system(os.environ['CASAPATH'].split()[0]+'/bin/bdflags2MS -f \"COR DELA INT MIS SIG SYN TFB WVR ZER\" "+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+" "+msName+"')"
                    else:
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags="+str(bdfflags)+", lazy="+str(lazy)+", process_caldevice=False)"

                elif getCasaVersion() >= '4.7.0' and getCasaVersion() < '4.7.2':

                    if corrModes1 == 'ALMA_ACA':
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False)"
                    else:
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags="+str(bdfflags)+")"

                elif getCasaVersion() >= '4.2.2' and getCasaVersion() < '4.7.0':

                    stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False)"

                else:

                    stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"')"

                stext += "\n  if not os.path.exists('"+msName+".flagversions'):\n    print 'ERROR in importasdm. Output MS is probably not useful. Will stop here.'\n    thesteps = []"

                stext += "\nif applyonly != True: es.fixForCSV2555('"+msName+"')"
                self.addReducScriptStep(f1, mystepdict, "Import of the ASDM", stext, mystepindent, applyonly=True)
                # fixsyscaltimes: see CAS-4981, CSV-2841, ICT-3642; sometimes needed for cycle 0-2.
                stext = "from recipes.almahelpers import fixsyscaltimes\nfixsyscaltimes(vis = '"+msName+"')"
                self.addReducScriptStep(f1, mystepdict, "Fix of SYSCAL table times", stext, mystepindent, applyonly=True)

                print >> f1, 'print "# A priori calibration"\n'
                stext = self.runFixPlanets(msName)
                if stext is not None: self.addReducScriptStep(f1, mystepdict, "Running fixplanets on fields with 0,0 coordinates", stext, mystepindent, applyonly=True)

                stext = "os.system('rm -rf %s.listobs')\n" %(msName) # Added by CLB
                stext += "listobs(vis = '"+msName+"',\n  listfile = '"+msName+".listobs')\n\n" # Modified by CLB
                self.addReducScriptStep(f1, mystepdict, "listobs", stext, mystepindent)
                stext = self.doAprioriFlagging(msName)
                self.addReducScriptStep(f1, mystepdict, "A priori flagging", stext, mystepindent)
                wvrCalTableName = []
                stext = self.generateWVRCalTable(msName, wvrCalTableName, refant=myRefAnt, remcloud=remcloud)
                self.addReducScriptStep(f1, mystepdict, "Generation and time averaging of the WVR cal table", stext, mystepindent)
                tsysCalTableName = []
                stext = self.generateTsysCalTable(msName, tsysCalTableName)
                self.addReducScriptStep(f1, mystepdict, "Generation of the Tsys cal table", stext, mystepindent)

                if corrAntPos == True:
                    stext = self.correctMyAntennaPositions(msName, lbc=lbc)
                    if stext is not None:
                        self.addReducScriptStep(f1, mystepdict, "Generation of the antenna position cal table", stext, mystepindent)
                        stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0], antpos=msName+'.antpos', tsysmap=tsysmap, tsysChanTol=tsysChanTol, tsysPerField=tsysPerField)
                        self.addReducScriptStep(f1, mystepdict, "Application of the WVR, Tsys and antpos cal tables", stext, mystepindent, applyonly=True)
                    else:
                        stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0], tsysmap=tsysmap, tsysChanTol=tsysChanTol, tsysPerField=tsysPerField)
                        self.addReducScriptStep(f1, mystepdict, "Application of the WVR and Tsys cal tables", stext, mystepindent, applyonly=True)
                else:
                    stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0], tsysmap=tsysmap, tsysChanTol=tsysChanTol, tsysPerField=tsysPerField)
                    self.addReducScriptStep(f1, mystepdict, "Application of the WVR and Tsys cal tables", stext, mystepindent, applyonly=True)

                stext = self.split2(msName, splitMyScienceSpw=splitMyScienceSpw, timebin=timeBinForFinalData)
                self.addReducScriptStep(f1, mystepdict, "Split out science SPWs and time average", stext, mystepindent, applyonly=True)

                print >> f1, 'print "# Calibration"\n'
                stext = "os.system('rm -rf %s.split.listobs')\n" % (msName) # Added by CLB
                # following line changed to += by CLB

                if getCasaVersion() < '4.5.0':
                    stext += "listobs(vis = '"+msName+".split',\n  listfile = '"+msName+".split.listobs')\n\n"
                    stext += self.clearPointingTable(msName+'.split')
                    stext += self.saveFlags(msName+'.split', name='Original')
                    self.addReducScriptStep(f1, mystepdict, "Listobs, clear pointing table and save original flags", stext, mystepindent)
                else:
                    stext += "listobs(vis = '"+msName+".split',\n  listfile = '"+msName+".split.listobs')\n\n"
                    stext += self.saveFlags(msName+'.split', name='Original')
                    self.addReducScriptStep(f1, mystepdict, "Listobs, and save original flags", stext, mystepindent)

                stext = self.doInitialFlagging(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=splitMyScienceSpw)
                self.addReducScriptStep(f1, mystepdict, "Initial flagging", stext, mystepindent)
                stext = self.runSetjy(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=splitMyScienceSpw)
                self.addReducScriptStep(f1, mystepdict, "Putting a model for the flux calibrator(s)", stext, mystepindent)

                if bpassCalTableName == '':
                    stext = self.saveFlags(msName+'.split', name='BeforeBandpassCalibration')
                    self.addReducScriptStep(f1, mystepdict, "Save flags before bandpass cal", stext, mystepindent, applyonly=True)
                    bpassCalTableName = []
                    stext = self.doBandpassCalibration(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=splitMyScienceSpw, refant=myRefAnt, calTableName=bpassCalTableName, lowSNR=lowSNR, lbc=lbc, phaseDiff=phaseDiff)
                    self.addReducScriptStep(f1, mystepdict, "Bandpass calibration", stext, mystepindent)
                else:
                    bpassCalTableName = [bpassCalTableName]

                stext = self.saveFlags(msName+'.split', name='BeforeGainCalibration')
                self.addReducScriptStep(f1, mystepdict, "Save flags before gain cal", stext, mystepindent, applyonly=True)
                phaseDiffCalTableName = []
                ampForSci = []
                stext = self.doGainCalibration(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=splitMyScienceSpw, refant=myRefAnt, bandpass=bpassCalTableName[0], phaseDiffCalTableName=phaseDiffCalTableName, ampForSci=ampForSci, phaseDiff=phaseDiff, phaseDiffPerSpwSetup=phaseDiffPerSpwSetup)
                self.addReducScriptStep(f1, mystepdict, "Gain calibration", stext, mystepindent)
                stext = self.saveFlags(msName+'.split', name='BeforeApplycal')
                self.addReducScriptStep(f1, mystepdict, "Save flags before applycal", stext, mystepindent, applyonly=True)

# to be removed once we move to CASA4.2
#                 stext = "\nif applyonly == True:\n  flagmanager(vis = '"+msName+".split',\n    mode = 'restore',\n    versionname = 'BeforeApplycal')\n\n"
#                 self.addReducScriptStep(f1, mystepdict, "Restore flags before applycal", stext, mystepindent, applyonly=True)

                stext = self.applyBandpassAndGainCalTables(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=splitMyScienceSpw, bandpass=bpassCalTableName[0], phaseForCal=msName+'.split.phase_int', phaseForSci=msName+'.split.phase_inf', flux=msName+'.split.flux_inf', phaseDiffCalTableName=phaseDiffCalTableName, ampForSci=ampForSci, phaseDiffPerSpwSetup=phaseDiffPerSpwSetup)
                self.addReducScriptStep(f1, mystepdict, "Application of the bandpass and gain cal tables", stext, mystepindent, applyonly=True)
                stext = self.split2(msName, msName1=msName+'.split', outMsName=msName+'.split.cal', allowHybrid=False, intentsToDiscard='ATMOSPHERE|POINTING', iHaveSplitMyScienceSpw=splitMyScienceSpw)
                self.addReducScriptStep(f1, mystepdict, "Split out corrected column", stext, mystepindent, applyonly=True)
                stext = self.saveFlags(msName+'.split.cal', name='AfterApplycal')
                self.addReducScriptStep(f1, mystepdict, "Save flags after applycal", stext, mystepindent, applyonly=True)

                self.prependReducScriptHeader(f1, mystepdict, "Calibration", mystepindent)

                f1.close()

            if run == True:
                for msName in msNames:
                    os.chdir(os.path.join(currDir, msNamesDir[msNames.index(msName)]))
                    clearstat()
                    subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', msName+'.scriptForCalibration.py'])

        if step == 'fluxcal':

            if os.path.exists('allFluxes.txt') == False:
                self.generateFluxFile(msNames)
            else:
                print 'File allFluxes.txt already exists, it will be loaded.'

            myRefAnt = refant # note: no need to run getRefAntenna because it will be called in doFluxCalibration if refant=''
            f1 = open('scriptForFluxCalibration.py', 'w')
            print >> f1, "import re\n"
            if getCasaVersion() < '5.1':
                print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
            else:
                print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
            print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"
            print >> f1, self.doFluxCalibration(msNames, refant=myRefAnt)
            f1.close()

            if run == True:
                clearstat()
                subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', 'scriptForFluxCalibration.py'])

        if step == 'imaging':

            if len(msNames) > 1: sys.exit('ERROR: the script generator does not support (yet) imaging of multiple datasets.')
            msNames = msNames[0]

            f1 = open('scriptForImaging.py', 'w')
            print >> f1, "import re\n"
            if getCasaVersion() < '5.1':
                print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
            else:
                print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
            print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"
            print >> f1, self.runCleanOnSource(msNames, chanWid=chanWid, angScale=angScale)
            f1.close()

        if step == 'calsurvey':

            mystepdict = {}
            mystepindent = "  "

            for msName in msNames:

                #msName = re.search('uid___[a-zA-Z0-9]+_[a-zA-Z0-9]+_[a-zA-Z0-9]+\.ms', msNames[i])
                #if msName == None: sys.exit('ERROR: '+msNames[i]+' does not seem to be a standard ms.')
                #msName = msName.group(0)
                #if os.path.exists(msName) == False: sys.exit('ERROR: '+msNames[i]+' does not seem to exist in the current directory.')

                tsysmap = ''
                if re.search('^3.3', getCasaVersion()) == None and skipSyscalChecks == False:

                    print "\n*** ANALYSIS OF TSYS TABLE ***"

                    print "\n*** SEARCH FOR NEGATIVE TSYS ***"
                    detectNegativeTsys(vis = msName, edge = 8, showfield = True)

                    print "\n*** SEARCH FOR NEGATIVE TREC ***"
                    detectNegativeTrx(vis = msName, edge = 8, showfield = True)

                    os.system('rm -Rf '+msName+'.tsys.temp')
                    gencal(vis = msName, caltable = msName+'.tsys.temp', caltype = 'tsys')

                    print "\n*** SEARCH FOR MISSING SCANS IN SYSCAL TABLE ***"

                    mymsmd = msmdtool()
                    mymsmd.open(msName)
                    if getCasaVersion() >= '4.2.0':
                        scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
                    else:
                        scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
                        if (scans1 == []):
                            scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#HOT')
                    mymsmd.close()

                    tb.open(msName+'.tsys.temp')                    
                    scans2 = np.unique(tb.getcol('SCAN_NUMBER'))
                    tb.close()

                    if (scans1 == scans2).all():
                        print "-> OK"
                    else:
                        sys.exit('ERROR: THE SYSCAL TABLE IS MISSING ONE (OR MORE) SCAN(S). IT MAY BE NECESSARY TO RE-GENERATE IT.')

                    if useLocalAlmaHelper == True:
                        tsysmap = tsysspwmap(vis = msName, tsystable = msName+'.tsys.temp', tsysChanTol=tsysChanTol)
                        vm = ValueMapping(msName)
                        spwInfo = self.getSpwInfo(msName)
                        spwIds = sorted(spwInfo.keys())
                        for j in spwIds:
#                        if tsysmap[j] == -1:
                            spwIntents = vm.getIntentsForSpw(tsysmap[j])
                            if 'CALIBRATE_ATMOSPHERE#ON_SOURCE' not in spwIntents:
                                sys.exit('ERROR: INCOMPLETE TSYS SPW MAPPING!')

                    os.system('rm -Rf '+msName+'.tsys.temp')

                f1 = open(msName+'.scriptForCalibration.py', 'w')
                print >> f1, "import re\n"
                print >> f1, "es = aU.stuffForScienceDataReduction() \n\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                myRefAnt = refant
                if myRefAnt == '': myRefAnt = self.getRefAntenna(msName)
                print >> f1, "# Using reference antenna = "+myRefAnt+"\n"

                print >> f1, 'print "# A priori calibration"\n'
                stext = self.runFixPlanets(msName)
                if stext is not None: self.addReducScriptStep(f1, mystepdict, "Running fixplanets on fields with 0,0 coordinates", stext, mystepindent)

                stext = "os.system('rm -rf %s.listobs')\n" %(msName) # Added by CLB
                stext += "listobs(vis = '"+msName+"',\n  listfile = '"+msName+".listobs')\n\n" # Modified by CLB
                self.addReducScriptStep(f1, mystepdict, "listobs", stext, mystepindent)
                stext = self.doAprioriFlagging(msName)
                self.addReducScriptStep(f1, mystepdict, "A priori flagging", stext, mystepindent)
                wvrCalTableName = []
                stext = self.generateWVRCalTable(msName, wvrCalTableName)
                self.addReducScriptStep(f1, mystepdict, "Generation and time averaging of the WVR cal table", stext, mystepindent)
                tsysCalTableName = []
                stext = self.generateTsysCalTable(msName, tsysCalTableName)
                self.addReducScriptStep(f1, mystepdict, "Generation of the Tsys cal table", stext, mystepindent)

                if corrAntPos == True:
                    stext = self.correctMyAntennaPositions(msName)
                    self.addReducScriptStep(f1, mystepdict, "Generation of the antenna position cal table", stext, mystepindent)
                    stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0], antpos=msName+'.antpos', tsysmap=tsysmap)
                    self.addReducScriptStep(f1, mystepdict, "Application of the WVR, Tsys and antpos cal tables", stext, mystepindent)
                else:
                    stext = self.applyAprioriCalTables(msName, tsys=tsysCalTableName[0], wvr=wvrCalTableName[0])
                    self.addReducScriptStep(f1, mystepdict, "Application of the WVR and Tsys cal tables", stext, mystepindent)

                stext = self.split2(msName, splitMyScienceSpw=True, timebin=timeBinForFinalData)
                self.addReducScriptStep(f1, mystepdict, "Split out science SPWs and time average", stext, mystepindent)

                print >> f1, 'print "# Calibration"\n'
                stext = "os.system('rm -rf %s.split.listobs')\n" % (msName) # Added by CLB
                # following line changed to += by CLB
                stext += "listobs(vis = '"+msName+".split',\n  listfile = '"+msName+".split.listobs')\n\n" \
                    + self.clearPointingTable(msName+'.split') \
                    + self.saveFlags(msName+'.split', name='Original')
                self.addReducScriptStep(f1, mystepdict, "Listobs, clear pointing table, and save original flags", stext, mystepindent)
                stext = self.doInitialFlagging(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True)
                self.addReducScriptStep(f1, mystepdict, "Initial flagging", stext, mystepindent)
                stext = self.runSetjy(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True)
                self.addReducScriptStep(f1, mystepdict, "Putting a model for the flux calibrator(s)", stext, mystepindent)
                stext = self.saveFlags(msName+'.split', name='BeforeBandpassCalibration')
                self.addReducScriptStep(f1, mystepdict, "Save flags before bandpass cal", stext, mystepindent)
                bpassCalTableName = []
                stext = self.doBandpassCalibration(msName, msName1=msName+'.split', bpassCalId=bpassCalId, iHaveSplitMyScienceSpw=True, refant=myRefAnt, calTableName=bpassCalTableName)
                self.addReducScriptStep(f1, mystepdict, "Bandpass calibration", stext, mystepindent)
                stext = self.saveFlags(msName+'.split', name='BeforeGainCalibration')
                self.addReducScriptStep(f1, mystepdict, "Save flags before gain cal", stext, mystepindent)
                stext = self.doGainCalibration(msName, msName1=msName+'.split', iHaveSplitMyScienceSpw=True, refant=myRefAnt, bandpass=bpassCalTableName[0], gaintypeForAmp='T')
                self.addReducScriptStep(f1, mystepdict, "Gain calibration", stext, mystepindent)

                self.prependReducScriptHeader(f1, mystepdict, "Calibration", mystepindent)

                f1.close()

            if run == True:
                for msName in msNames:
                    clearstat()
                    subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', msName+'.scriptForCalibration.py'])

        if step == 'SDeff':

            msNamesDir = []

            for msName in msNames:

                if run == True:
                    os.chdir(currDir)
                    subDir = 'EB'+str(msNames.index(msName))+'_'+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]
                    os.mkdir(subDir)
                    msNamesDir.append(subDir)
#                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'* '+subDir)
                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'.* '+subDir)
                    os.chdir(subDir)

                fieldNames = self.getIntentsAndSourceNames(msName)['OBSERVE_TARGET']['name']
                fieldNames = sorted(dict.fromkeys(fieldNames).keys())
                if len(fieldNames) != 1: sys.exit('ERROR: Unexpected number of fields.')
                fieldNames = fieldNames[0]
                if fieldNames.upper() in ['VENUS', 'MARS', 'JUPITER', 'URANUS', 'NEPTUNE', 'IO', 'EUROPA', 'GANYMEDE', 'CALLISTO', 'TITAN', 'CERES', 'JUNO', 'PALLAS', 'VESTA', 'HYGEIA']:
                    print 'Observation type = SSO'
                    sdEffType = 'SSO'
                else:
                    print 'Observation type = QSO'
                    sdEffType = 'QSO'

                tb.open(msName+'/OBSERVATION')
                obsTimeRange = tb.getcol('TIME_RANGE')
                obsTime = (obsTimeRange[0]+obsTimeRange[1])/2.0
                obsTime = ((obsTime/86400.0)+2400000.5-2440587.5)*86400.0
                obsTime = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTime))
                tb.close()

                mystepdict = {}
                mystepindent = "  "

                f1 = open(msName+'.scriptForSDefficiencies.py', 'w')
                print >> f1, "import re\n"
                print >> f1, "es = aU.stuffForScienceDataReduction()\n"
                print >> f1, "import analysisUtilsForSD as aUsd\n\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, " sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                asdmName1 = re.findall('^uid___[0-9a-z]+_[0-9a-z]+_[0-9a-z]+', msName, re.IGNORECASE)[0]

                stext = "aUsd.continuumReducer2('"+asdmName1+"')"
                self.addReducScriptStep(f1, mystepdict, "Make continuum images", stext, mystepindent)

                tb.open(msName+'/ANTENNA')
                antNames = tb.getcol('NAME')
                tb.close()

                antNames1 = []
                for i in antNames:
                    if re.search('^CM[0-9]+', i) == None: antNames1.append(i)
                if len(antNames1) == 0: sys.exit('ERROR: No antenna to process.')

                vm = ValueMapping(msName)
                sciScans = vm.getScansForIntent('OBSERVE_TARGET#ON_SOURCE').tolist()
                sciScans = [str(i) for i in sciScans]
                sciScans = ','.join(sciScans)

                weatherInfo = {}
                for i in antNames1:
                    weatherInfo[i] = getWeather(msName, antenna=i, scan=sciScans)[0]

                spwInfo = self.getSpwInfo(msName)
                spwIds = sorted(spwInfo.keys())

                stext = ''

                for i in antNames1:
                    for j in spwIds:

                        msName1 = asdmName1 + '.' + i + '.cal.ms'
                        imgName1 = asdmName1 + '.' + i + '.SPW' + str(j) + '.SF.im'

                        stext += "aUsd.SdImDWtApp(ms_SD = '"+msName1+"',\n  im_SD = '"+imgName1+"',\n  outimage = '"+imgName1+".wt',\n  spwid = "+str(j)+",\n  gridfunc = 'SF')\n"

                    stext += '\n'

                self.addReducScriptStep(f1, mystepdict, "Mitigating noisy effect at edge of SD image", stext, mystepindent)

                if sdEffType == 'SSO':

                    stext = 'ssoParams = {}\n\n'

                    for i in antNames1:

                        msName1 = asdmName1 + '.' + i + '.cal.ms'

                        stext += "ssoParams['"+i+"'] = {}\n"
                        stext += "s = aUsd.sso_params('"+msName1+"')\n\n"

                        stext += "for i in "+str(spwIds)+":\n\n"
                        stext += "  s.setSpwId(int(i))\n"
                        stext += "  s.doCalc()\n"
                        stext += "  ssoResults = s.getResults()\n\n"
                        stext += "  ssoParams['"+i+"'][i] = {}\n"
                        stext += "  ssoParams['"+i+"'][i]['eqsize'] = ( ssoResults['Apparent Size'][0][0] + ssoResults['Apparent Size'][1][0] ) / 2.\n"
                        stext += "  ssoParams['"+i+"'][i]['psize'] = ( ssoResults['Apparent Size'][0][1] + ssoResults['Apparent Size'][1][1] ) / 2.\n"
                        stext += "  ssoParams['"+i+"'][i]['pnang'] = ( ssoResults['Apparent Size'][0][2] + ssoResults['Apparent Size'][1][2] ) / 2.\n"
                        stext += "  ssoParams['"+i+"'][i]['btemp'] = ( ssoResults['Brightness Temperature'][0] + ssoResults['Brightness Temperature'][1] ) / 2.\n\n"

                    stext += "f = open('"+msName+".ssoParams.txt', 'w')\n"
                    stext += "print >> f, ssoParams\n"
                    stext += "f.close()\n\n"

                    self.addReducScriptStep(f1, mystepdict, "Obtain apparent size and brightness temperature for Solar system object", stext, mystepindent)

                stext = 'sdEffs = {}\n\n'

                for i in antNames1:

                    msName1 = asdmName1 + '.' + i + '.cal.ms'

                    stext += "for i in "+str(spwIds)+":\n\n"
                    stext += "  a = aUsd.analysis_sdim('"+asdmName1+"."+i+".SPW'+str(i)+'.SF.im.wt')\n"

                    if sdEffType == 'SSO':
                        stext += "  a.setSSOParams(eqsize = ssoParams['"+i+"'][i]['eqsize'],\n    psize = ssoParams['"+i+"'][i]['psize'],\n    pnang = ssoParams['"+i+"'][i]['pnang'],\n    btemp = ssoParams['"+i+"'][i]['btemp'])\n"
                        stext += "  a.doSSOAnalysis(antbeam = True)\n"
                        stext += "  results = a.getSSOResults()\n"
                        stext += "  #a.showSSOModel()\n"
                        stext += "  #a.showSSOResults()\n\n"
                    else:
                        stext += "  a.setQSOFlux("+str(sdQSOflux)+")\n"
                        stext += "  a.doQSOAnalysis()\n"
                        stext += "  results = a.getQSOResults()\n"
                        stext += "  #a.showSdBeam()\n\n"

                    stext += "  ij = len(sdEffs)\n"
                    stext += "  sdEffs[ij] = {}\n"
                    stext += "  sdEffs[ij]['execBlockUid'] = '"+asdmName1+"'\n"
                    stext += "  sdEffs[ij]['obsTime'] = '"+obsTime+"'\n"
                    stext += "  sdEffs[ij]['antennaName'] = '"+i+"'\n"
                    stext += "  sdEffs[ij]['spwId'] = i\n"
                    stext += "  sdEffs[ij]['frequency'] = results['Frequency']/1e9\n"
                    stext += "  sdEffs[ij]['meanElevation'] = "+str(weatherInfo[i]['elevation'])+"\n"
                    stext += "  sdEffs[ij]['meanTemp'] = "+str(weatherInfo[i]['temperature'])+"\n"
                    stext += "  sdEffs[ij]['meanWindSpeed'] = "+str(weatherInfo[i]['windspeed'])+"\n"
                    stext += "  sdEffs[ij]['effectiveBeamSize'] = results['Effective Beam Size'].tolist()\n"
                    stext += "  sdEffs[ij]['mainBeamEfficiency'] = results['Main Beam Efficiency']\n\n"

                stext += "f = open('"+msName+".sdEfficiencies.txt', 'w')\n"
                stext += "print >> f, sdEffs\n"
                stext += "f.close()\n\n"

                self.addReducScriptStep(f1, mystepdict, "Obtain efficiencies and (effective) beam size", stext, mystepindent)

                self.prependReducScriptHeader(f1, mystepdict, "Calculation of SD efficiencies", mystepindent)

                f1.close()

#         if step in ['SDcalib', 'SDcalibLine', 'SDcalibCont']:
        if step in ['SDcalibLine', 'SDcalibCont', 'SDampcal', 'SDscience']:

            if getCasaVersion() < '4.2.0': sys.exit('ERROR: PLEASE USE CASA 4.2 OR LATER FOR SD DATA REDUCTION')

            if step == 'SDscience' and len(msNames) > 1:

                spwInfo = self.getSpwInfo(msNames[0])
                spwIds = sorted(spwInfo.keys())

                for j in range(1, len(msNames)):

                    spwInfo1 = self.getSpwInfo(msNames[j])
                    spwIds1 = sorted(spwInfo1.keys())
                    if spwIds1 != spwIds: print 'WARNING: THE SCIENCE SPWS ARE NOT THE SAME FOR ALL EXECUTIONS.'

            msNamesDir = []
            imagingParams = {}

            for msName in msNames:

                mystepdict = {}
                mystepindent = "  "

                if run == True or (projectCode != '' and schedblockName != '') or schedblockUid != '' or step == 'SDscience':
                    os.chdir(currDir)
                    subDir = 'EB'+str(msNames.index(msName))+'_'+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]
                    os.mkdir(subDir)
                    msNamesDir.append(subDir)
#                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'* '+subDir)
                    os.system('mv '+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+'.* '+subDir)
                    os.chdir(subDir)

                tsysmap = ''
                if re.search('^3.3', getCasaVersion()) == None:

                    print "\n*** ANALYSIS OF TSYS TABLE ***"

                    print "\n*** SEARCH FOR NEGATIVE TSYS ***"
                    detectNegativeTsys(vis = msName, edge = 8, showfield = True)

                    print "\n*** SEARCH FOR NEGATIVE TREC ***"
                    detectNegativeTrx(vis = msName, edge = 8, showfield = True)

                    os.system('rm -Rf '+msName+'.tsys.temp')
                    gencal(vis = msName, caltable = msName+'.tsys.temp', caltype = 'tsys')

                    print "\n*** SEARCH FOR MISSING SCANS IN SYSCAL TABLE ***"
                    mymsmd = msmdtool()
                    mymsmd.open(msName)
                    if getCasaVersion() >= '4.2.0':
                        scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
                    else:
                        scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
                        if (scans1 == []):
                            scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#HOT')
                    if ('CALIBRATE_ATMOSPHERE#REFERENCE' in mymsmd.intents()):
                        # The presence of extra AtmCals with a REFERENCE intent will cause scans1 != scans2
                        scansWithZeroLevel = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#REFERENCE')
                        scans1 = np.array(sorted(list(set(scans1)-set(scansWithZeroLevel))))
                    mymsmd.close()

                    tb.open(msName+'.tsys.temp')                    
                    scans2 = np.unique(tb.getcol('SCAN_NUMBER'))
                    tb.close()

                    if (scans1 == scans2).all():
                        print "-> OK"
                    else:
                        print "scans1 = ", scans1
                        print "scans2 = ", scans2
                        sys.exit('ERROR: THE SYSCAL TABLE IS MISSING ONE (OR MORE) SCAN(S). IT MAY BE NECESSARY TO RE-GENERATE IT.')

                    if useLocalAlmaHelper == True:
                        tsysmap = tsysspwmap(vis = msName, tsystable = msName+'.tsys.temp', tsysChanTol=tsysChanTol)
                        vm = ValueMapping(msName)
                        spwInfo = self.getSpwInfo(msName)
                        spwIds = sorted(spwInfo.keys())
                        for j in spwIds:
#                        if tsysmap[j] == -1:
                            spwIntents = vm.getIntentsForSpw(tsysmap[j])
                            if 'CALIBRATE_ATMOSPHERE#ON_SOURCE' not in spwIntents:
                                if 'CALIBRATE_ATMOSPHERE#HOT' not in spwIntents:
                                    sys.exit('ERROR: INCOMPLETE TSYS SPW MAPPING!')

                    os.system('rm -Rf '+msName+'.tsys.temp')

                if step == 'SDampcal':
                    f1 = open(msName+'.scriptForSDampcalReduction.py', 'w')
                else:
                    f1 = open(msName+'.scriptForSDCalibration.py', 'w')

                print >> f1, "import os"
                print >> f1, "import re\n"

                sourcelines1 = ''.join(inspect.getsourcelines(createCasaTool)[0])
                if re.search('""".*?"""', sourcelines1, re.DOTALL) is not None:
                    sourcelines2 = re.findall('""".*?"""', sourcelines1, re.DOTALL)[0]
                    sourcelines1 = sourcelines1.replace(sourcelines2, '')
                print >> f1, sourcelines1

                sourcelines1 = ''.join(inspect.getsourcelines(getDataColumnName)[0])
                if re.search('""".*?"""', sourcelines1, re.DOTALL) is not None:
                    sourcelines2 = re.findall('""".*?"""', sourcelines1, re.DOTALL)[0]
                    sourcelines1 = sourcelines1.replace(sourcelines2, '')
                print >> f1, sourcelines1

                sourcelines1 = ''.join(inspect.getsourcelines(scaleAutocorr)[0])
                if re.search('""".*?"""', sourcelines1, re.DOTALL) is not None:
                    sourcelines2 = re.findall('""".*?"""', sourcelines1, re.DOTALL)[0]
                    sourcelines1 = sourcelines1.replace(sourcelines2, '')
                print >> f1, sourcelines1

                if (getCasaVersion() < '4.2.2' or getCasaSubversionRevision() < '29969'): print >> f1, "import filltsys\n"
                print >> f1, "if applyonly != True: es = aU.stuffForScienceDataReduction()\n"
                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, "  sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                tempStdout = sys.stdout
                sys.stdout = f1
                self.listOfIntentsWithSources(msName)
                sys.stdout = tempStdout

                print >> f1, "\n"

                stext = "if os.path.exists('"+msName+"') == False:\n"

                if getCasaVersion() >= '4.7.2':

                    if corrModes1 == 'ALMA_ACA':
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False, lazy="+str(lazy)+", process_caldevice=False, with_pointing_correction="+str(with_pointing_correction)+")"
                        if bdfflags == True:
                            stext += "\n  os.system(os.environ['CASAPATH'].split()[0]+'/bin/bdflags2MS -f \"COR DELA INT MIS SIG SYN TFB WVR ZER\" "+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+" "+msName+"')"
                    else:
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags="+str(bdfflags)+", lazy="+str(lazy)+", process_caldevice=False, with_pointing_correction="+str(with_pointing_correction)+")"
    
                elif getCasaVersion() >= '4.7.0' and getCasaVersion() < '4.7.2':

                    if corrModes1 == 'ALMA_ACA':
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False, with_pointing_correction="+str(with_pointing_correction)+")"
                    else:
                        stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags="+str(bdfflags)+", with_pointing_correction="+str(with_pointing_correction)+")"

                elif getCasaVersion() >= '4.2.2' and getCasaVersion() < '4.7.0':

                    stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"', bdfflags=False, with_pointing_correction="+str(with_pointing_correction)+")"

                else:

                    stext += "  importasdm('"+re.findall('.+(?=\.ms)', msName, re.IGNORECASE)[0]+"', asis='"+asis1+"')"

                stext += "\nif applyonly != True: es.fixForCSV2555('"+msName+"')"
                self.addReducScriptStep(f1, mystepdict, "Import of the ASDM", stext, mystepindent, applyonly=True)

                stext = self.runFixPlanets(msName)
                if stext is not None: self.addReducScriptStep(f1, mystepdict, "Running fixplanets on fields with 0,0 coordinates", stext, mystepindent)

                tb.open(msName+'/ANTENNA')
                antNames = tb.getcol('NAME').tolist()
                tb.close()

                stext = "os.system('rm -rf %s.listobs')\n" %(msName) # Added by CLB
                stext += "listobs(vis = '"+msName+"',\n  listfile = '"+msName+".listobs')\n\n" # Modified by CLB

#                 stext += "if applyonly != True: aU.getTPSampling(vis = '"+msName+"', showplot = True, plotfile = '"+msName+".sampling.png')"

                stext += "if applyonly != True:\n"
                stext += "  aU.getTPSampling(vis = '"+msName+"', showplot = True, plotfile = '"+msName+".sampling.png')\n"
                stext += "  for i in "+str(antNames)+":\n    aU.getTPSampling(vis = '"+msName+"', antenna = i, showplot = True, plotfile = '"+msName+".sampling.'+i+'.png')"

                self.addReducScriptStep(f1, mystepdict, "listobs", stext, mystepindent)

                stext = self.doAprioriFlagging(msName, flagAutoCorr=False, flagCalIntents=False)
                self.addReducScriptStep(f1, mystepdict, "A priori flagging", stext, mystepindent)

                if getCasaVersion() < '5.0':

    #                 tb.open(msName+'/ANTENNA')
    #                 antNames = tb.getcol('NAME').tolist()
    #                 tb.close()

                    if (getCasaVersion() >= '4.2.2' and getCasaSubversionRevision() >= '29969'):

                        stext = "for i in "+str(antNames)+":\n  os.system('rm -Rf "+msName+".'+i+'*')\n\n"
                        stext += "sdsave(infile = '"+msName+"',\n  splitant = True,\n  outfile = '"+msName+".asap',\n  overwrite = True)\n\n"
                        self.addReducScriptStep(f1, mystepdict, "Split by antenna", stext, mystepindent)

                    else:

                        stext = "for i in "+str(antNames)+":\n  os.system('rm -Rf "+msName+".'+i+'*')\n\n"
                        stext += "sd.splitant(filename = '"+msName+"',\n  outprefix = '"+msName+"',\n  overwrite = True)\n\n"
                        self.addReducScriptStep(f1, mystepdict, "Split by antenna", stext, mystepindent)

                    asapNames = [msName+'.'+i+'.asap' for i in antNames]
                    asapNames = sorted(asapNames)

                    stext = ''
                    for i in asapNames:
                        stext += "os.system('rm -Rf "+i+".sdlist')\n"
                        stext += "sdlist(infile = '"+i+"',\n  outfile = '"+i+".sdlist')\n\n"
                    self.addReducScriptStep(f1, mystepdict, "sdlist", stext, mystepindent)

                else:

                    asapNames = [msName]

                tsysCalTableName = []
                stext = self.SDfillTsysSolutions(asapNames, msName=msName, doplot=True, tsysCalTableName=tsysCalTableName)
                if (getCasaVersion() >= '4.2.2' and getCasaSubversionRevision() >= '29969'):
                    self.addReducScriptStep(f1, mystepdict, "Generation of the Tsys cal table", stext, mystepindent)
                else:
                    self.addReducScriptStep(f1, mystepdict, "Filling the Tsys solutions in the dataset", stext, mystepindent)

                skyCalTableName = []

                if getCasaVersion() >= '5.0':

                    if step in ['SDcalibLine', 'SDscience']:
                        stext = self.SDfillTsysSolutions(asapNames, msName=msName, doplot=True, tsysCalTableName=skyCalTableName, sky=True, calmode='ps')
                    else:
                        stext = self.SDfillTsysSolutions(asapNames, msName=msName, doplot=True, tsysCalTableName=skyCalTableName, sky=True, calmode='otfraster')
                    self.addReducScriptStep(f1, mystepdict, "Generation of the Sky cal table", stext, mystepindent)

### this will need a cleaner implementation

                spwInfo = self.getSpwInfo(msName)
                vm = ValueMapping(msName)

                chanFlags = {}

                for i in sorted(spwInfo.keys()):
                    if vm.spwInfo[i]['bandwidth'] > 1875000000:
                        chanEdge = int((vm.spwInfo[i]['numChannels'] - (1875000000. / vm.spwInfo[i]['bandwidth']) * vm.spwInfo[i]['numChannels']) / 2.)
                        maskflag = str([[0, chanEdge-1], [vm.spwInfo[i]['numChannels']-chanEdge, vm.spwInfo[i]['numChannels']-1]])
                        if maskflag not in chanFlags.keys():
                            chanFlags[maskflag] = []
                        chanFlags[maskflag].append(i)

                stext = ''

                if (getCasaVersion() >= '4.2.2'):
                    for i in asapNames:
                        for maskflag in chanFlags.keys():
                            maskflag1 = eval(maskflag)
                            maskflag2 = []
                            for j in range(len(maskflag1)):
                                maskflag2.append('~'.join([str(k) for k in maskflag1[j]]))
                            maskflag2 = ';'.join(maskflag2)
                            spwmaskflag = []
                            for j in chanFlags[maskflag]:
                                spwmaskflag.append(str(j)+':'+maskflag2)
                            spwmaskflag = ','.join(spwmaskflag)
                            if getCasaVersion() >= '5.0':
                                stext += "flagdata(vis = '"+i+"',\n  mode = 'manual',\n  spw = '"+spwmaskflag+"')\n\n"
                            else:
                                stext += "sdflag(infile = '"+i+"',\n  mode = 'manual',\n  spw = '"+spwmaskflag+"',\n  overwrite = True)\n\n"
                else:
                    for i in asapNames:
                        for maskflag in chanFlags.keys():
                            stext += "sdflag2(infile = '"+i+"',\n  specunit = 'channel',\n  mode = 'manual',\n  ifs = "+str(chanFlags[maskflag])+",\n  maskflag = "+maskflag+",\n  overwrite = True)\n\n"

                self.addReducScriptStep(f1, mystepdict, "Do initial flagging", stext, mystepindent)

###

                tb.open(msName+'/OBSERVATION')
                obsTimeRange = tb.getcol('TIME_RANGE')
                tb.close()
                obsTimeStart = ((obsTimeRange[0]/86400.0)+2400000.5-2440587.5)*86400.0
                obsTimeStart = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTimeStart))

                if step in ['SDcalibLine', 'SDscience']:

                    if getCasaVersion() < '5.0':
                        stext = self.SDdoCalibration(asapNames, msName=msName, calmode='ps', tsysCalTableName=tsysCalTableName[0])
                    else:
                        stext = self.SDdoCalibration(asapNames, msName=msName, tsysCalTableName=tsysCalTableName[0], skyCalTableName=skyCalTableName[0])
                    self.addReducScriptStep(f1, mystepdict, "Calibration of the data into Kelvins", stext, mystepindent)

                    if getCasaVersion() < '5.0':

                        asapNames = [i+'.cal' for i in asapNames]

                        if obsTimeStart < '2015-10-01T00:00:00':

                            stext = ''
                            for i in asapNames:
                                stext += "os.system('rm -Rf "+i+".nlc')\n\n"
                                stext += "sdscale(infile = '"+i+"',\n  outfile = '"+i+".nlc',\n  factor = 1.25)\n\n"
                            self.addReducScriptStep(f1, mystepdict, "Application of non-linearity correction factor", stext, mystepindent)

                            asapNames = [i+'.nlc' for i in asapNames]

                    stext = self.SDdoBaselineSubtraction(asapNames, msName=msName)
                    self.addReducScriptStep(f1, mystepdict, "Subtracting the baseline", stext, mystepindent)

                    asapNames = [i+'.bl' for i in asapNames]

                else:

                    if getCasaVersion() < '5.0':
                        stext = self.SDdoCalibration(asapNames, msName=msName, calmode='otfraster', tsysCalTableName=tsysCalTableName[0])
                    else:
                        stext = self.SDdoCalibration(asapNames, msName=msName, tsysCalTableName=tsysCalTableName[0], skyCalTableName=skyCalTableName[0])
                    self.addReducScriptStep(f1, mystepdict, "Calibration of the data into Kelvins", stext, mystepindent)

                    if getCasaVersion() < '5.0':

                        asapNames = [i+'.cal' for i in asapNames]

                        if obsTimeStart < '2015-10-01T00:00:00':

                            stext = ''
                            for i in asapNames:
                                stext += "os.system('rm -Rf "+i+".nlc')\n\n"
                                stext += "sdscale(infile = '"+i+"',\n  outfile = '"+i+".nlc',\n  factor = 1.25)\n\n"
                            self.addReducScriptStep(f1, mystepdict, "Application of non-linearity correction factor", stext, mystepindent)

                            asapNames = [i+'.nlc' for i in asapNames]

                spwInfo = self.getSpwInfo(msName)
                spwIds = sorted(spwInfo.keys())
                spwIds = [str(i) for i in spwIds]

                if getCasaVersion() < '5.0':

                    stext = ''
                    for i in asapNames:
                        stext += "os.system('rm -Rf "+i+".ms')\n\n"
                        if getCasaVersion() >= '4.2.2':
                            stext += "sdsave(infile = '"+i+"',\n  outfile = '"+i+".ms',\n  spw = '"+','.join(spwIds)+"',\n  outform = 'MS2')\n\n"
                        else:
                            stext += "sdsave(infile = '"+i+"',\n  outfile = '"+i+".ms',\n  outform = 'MS2')\n\n"
                    self.addReducScriptStep(f1, mystepdict, "Converting ASAP -> MS", stext, mystepindent)

                    asapNames = [i+'.ms' for i in asapNames]

    #                 moved to just above
    #                 spwInfo = self.getSpwInfo(msName)
    #                 spwIds = sorted(spwInfo.keys())
    #                 spwIds = [str(i) for i in spwIds]

                stext = ''

                if len(asapNames) > 1:
#                     for i in asapNames:
#                         stext += "os.system('rm -Rf "+i+".split')\n\n"
#                         stext += "split(vis = '"+i+"',\n  outputvis = '"+i+".split',\n  spw = '"+','.join(spwIds)+"',\n  datacolumn = 'float_data')\n\n"
#                     asapNames = [i+'.split' for i in asapNames]
                    stext += "os.system('rm -Rf "+msName+".cal')\n\n"
                    stext += "concat(vis = [ \\\n    '"+"', \\\n    '".join(asapNames)+"' ], \\\n  concatvis = '"+msName+".cal')\n\n"
#                     stext += "os.system('rm -Rf "+msName+".cal.split')\n\n"
#                     stext += "split(vis = '"+msName+".cal',\n  outputvis = '"+msName+".cal.split',\n  spw = '"+','.join(spwIds)+"',\n  datacolumn = 'float_data')\n\n"
                else:
#                     stext += "os.system('rm -Rf "+msName+".cal.split')\n\n"
#                     stext += "split(vis = '"+asapNames[0]+"',\n  outputvis = '"+msName+".cal.split',\n  spw = '"+','.join(spwIds)+"',\n  datacolumn = 'float_data')\n\n"
                    stext += "os.system('rm -Rf "+msName+".cal')\n\n"
                    stext += "os.system('cp -Rf "+asapNames[0]+" "+msName+".cal')\n\n"

                self.addReducScriptStep(f1, mystepdict, "Split and concatenation", stext, mystepindent)

                if step == 'SDscience':

                    jyperk = self.getJyPerK(msName, interactive=True)

                    f2 = open('jyperk.txt', 'w')
                    pprint.pprint(jyperk, stream=f2, indent=2)
                    f2.close()

                    f2 = open('jyperk.txt')
                    jyperk = f2.read()
                    f2.close()

                    stext = "jyperk = \\\n" + jyperk + "\n"

                    if getCasaVersion() >= '5.0':

#                         spwInfo = self.getSpwInfo(msName)
#                         spwIds = sorted(spwInfo.keys())

                        blspwmap = {}
                        for i in spwIds: blspwmap[str(i)] = str(spwIds.index(i))
                        stext += "blspwmap = "+str(blspwmap)+"\n"

                    stext += "os.system('rm -Rf "+msName+".cal.jy')\n"
                    stext += "os.system('cp -Rf "+msName+".cal "+msName+".cal.jy')\n\n"

                    stext += "for ant in jyperk.keys():\n"
                    stext += "  for spw in jyperk[ant].keys():\n"

                    if getCasaVersion() < '5.0':
                        stext += "    scaleAutocorr(vis='"+msName+".cal.jy', scale=jyperk[ant][spw]['mean'], antenna=ant, spw=spw)\n"
                    else:
                        stext += "    scaleAutocorr(vis='"+msName+".cal.jy', scale=jyperk[ant][spw]['mean'], antenna=ant, spw=int(blspwmap[str(spw)]))\n"
    
                    self.addReducScriptStep(f1, mystepdict, "Convert the Science Target Units from Kelvin to Jansky", stext, mystepindent)

                if step in ['SDscience', 'SDampcal']:

                    imagingParams[msName] = {}

                    imagingParams[msName]['spwIds'] = spwIds

                    xSampling, ySampling, maxsize = getTPSampling(msName, showplot=False, pickFirstRaster=True)
                    imagingParams[msName]['maxsize'] = maxsize
                    mymsmd = msmdtool()
                    mymsmd.open(msName)

                    for i in sorted(spwInfo.keys()):

                        imagingParams[msName][i] = {}

                        freq = mymsmd.meanfreq(i)
                        imagingParams[msName][i]['freq'] = freq

                        theorybeam = primaryBeamArcsec(frequency=freq*1e-9, fwhmfactor=1.13, diameter=12)
                        imagingParams[msName][i]['theorybeam'] = theorybeam
#                        print "Running sfBeam(frequency=%f, pixelsize=%f, convsupport=6, img=None, stokes='both', xSamplingArcsec=%f, ySamplingArcsec=%f, fwhmfactor=1.13, diameter=12)" % (freq*1e-9, theorybeam/9.0, xSampling, ySampling)
                        minor, major, fwhmsfBeam, sfbeam = sfBeam(frequency=freq*1e-9, pixelsize=theorybeam/9.0, convsupport=6, img=None, stokes='both', xSamplingArcsec=xSampling, ySamplingArcsec=ySampling, fwhmfactor=1.13, diameter=12)
                        imagingParams[msName][i]['sfbeam'] = sfbeam

                    fieldId = mymsmd.fieldsforintent('OBSERVE_TARGET#ON_SOURCE')
                    if len(fieldId) != 1: sys.exit('ERROR: UNEXPECTED NUMBER OF FIELDS.')
                    fieldId = fieldId[0]
                    imagingParams[msName]['fieldId'] = fieldId

                    fieldName = mymsmd.namesforfields(fieldId)
                    if len(fieldName) != 1: sys.exit('ERROR: UNEXPECTED NUMBER OF FIELDS.')
                    fieldName = fieldName[0]
                    imagingParams[msName]['fieldName'] = fieldName

                    mymsmd.close()

                if step == 'SDampcal':

                    stext = "# the values below were calculated assuming fwhmfactor = 1.13\n\n"
                    stext += "maxsize = "+str(imagingParams[msName]['maxsize'])+"\n\n"

                    stext += "theorybeam = {}\n"
                    for i in sorted(spwInfo.keys()):
                        stext += "theorybeam['"+str(i)+"'] = "+str(imagingParams[msName][i]['theorybeam'])+" # mean freq = "+str(imagingParams[msName][i]['freq']*1e-9)+"\n"

                    setjyModels = ['Venus', 'Mars', 'Jupiter', 'Uranus', 'Neptune', 'Pluto', 'Io', 'Europa', 'Ganymede', 'Callisto', 'Titan', 'Triton', 'Ceres', 'Pallas', 'Vesta', 'Juno', 'Victoria', 'Davida']

                    doPlanet = 0
                    for j in range(len(setjyModels)):
                        if re.search(setjyModels[j], fieldName, re.IGNORECASE) is not None:
                            doPlanet = 1
                            break

                    if doPlanet == 1:
                        supportedSSOTPampCals = ['mercury', 'venus', 'mars', 'jupiter', 'saturn', 'uranus', 'neptune']
                        if fieldName.lower() not in supportedSSOTPampCals: sys.exit('ERROR: SSO NOT SUPPORTED AS TP AMP CAL.')

                    stext += "\nfor spw in "+str(spwIds)+":\n\n"
                    stext += "  cell = theorybeam[spw]/9.0\n"
                    stext += "  imsize = int(round(maxsize/cell)*2)\n\n"
                    stext += "  for ant in "+str(antNames)+":\n\n"
                    stext += "    sdimaging(infiles = '"+msName+".cal',\n"
                    stext += "      field = '"+fieldName+"',\n"
                    stext += "      spw = spw,\n"
                    stext += "      antenna = ant,\n"
                    stext += "      nchan = 1,\n"
                    stext += "      mode = 'channel',\n"
                    stext += "      width = '4080',\n"
                    stext += "      gridfunction = 'SF',\n"
                    stext += "      convsupport = 6,\n"

                    if doPlanet == 1:
                        stext += "      ephemsrcname = '"+fieldName+"',\n"
                    else:
                        stext += "      phasecenter = "+str(fieldId)+",\n"

                    stext += "      imsize = imsize,\n"
                    stext += "      cell = str(cell)+'arcsec',\n"
                    stext += "      overwrite = True,\n"
                    stext += "      outfile = '"+msName+".cal.%s.spw%s.image' % (ant, spw))\n"

                    self.addReducScriptStep(f1, mystepdict, "Imaging", stext, mystepindent)

                    stext = "srcflux = {}\n"

                    for i in sorted(spwInfo.keys()):

                        if doPlanet == 1:
                            planetInfo = planetFlux(vis=msName, spw=i)
                            srcflux = planetInfo['fluxDensity']
                            srcsize = (planetInfo['majorAxis']*planetInfo['minorAxis'])**0.5
                            spwfreq = planetInfo['meanFrequency']
                        else:
                            qsoInfo = getALMAFluxForMS(msName, field=fieldName, spw=str(i))
                            srcflux = qsoInfo[fieldName]['fluxDensity']
                            spwfreq = qsoInfo[fieldName]['frequency']

                        stext += "srcflux['"+str(i)+"'] = "+str(srcflux)+" # mean freq = "+str(spwfreq*1e-9)+"\n"

                    if doPlanet == 1:
                        stext += "\nsrcsize = "+str(srcsize)+"\n"

                    stext += "\njyperk = {}\n"

                    stext += "\nfor ant in "+str(antNames)+":\n\n"
                    stext += "  jyperk[ant] = {}\n\n"
                    stext += "  for spw in "+str(spwIds)+":\n\n"
                    stext += "    if os.path.exists('"+msName+".cal.%s.spw%s.image' % (ant, spw)):\n\n"
                    stext += "      peak = imstat('"+msName+".cal.%s.spw%s.image' % (ant, spw))['max'][0]\n\n"

                    if doPlanet == 1:

                        stext += "      fwhm = aU.getfwhm2('"+msName+".cal.%s.spw%s.image' % (ant, spw))\n"
                        stext += "      print 'Apparent FWHM (inc. gridding convolution) is %.2f arcsec' % fwhm\n\n"
                        stext += "      deconvfwhm = aU.deconvolveDiskFromBeam(fwhm, srcsize)\n"
                        stext += "      print 'FWHM deconvolved for planet size is %.2f arcsec' % deconvfwhm\n\n"
                        stext += "      # correction factor for dilution due to planet size\n"
                        stext += "      srcsizecorr = (deconvfwhm/fwhm)**2\n\n"
                        stext += "      jyperk[ant][spw] = srcflux[spw] / peak * srcsizecorr"

                    else:

                        stext += "      jyperk[ant][spw] = srcflux[spw] / peak"

                    self.addReducScriptStep(f1, mystepdict, "Determination of the Jy/K factors", stext, mystepindent)

                    stext = "asdm = '"+re.findall('uid___[a-zA-Z0-9]+_[a-zA-Z0-9]+_[a-zA-Z0-9]+', msName)[0]+"'\n"

                    tb.open(msName+'/OBSERVATION')
                    obsTimeRange = tb.getcol('TIME_RANGE')
                    obsTime = (obsTimeRange[0]+obsTimeRange[1])/2.0
                    obsTime = ((obsTime/86400.0)+2400000.5-2440587.5)*86400.0
                    obsTime = timeUtilities.strftime('%Y-%m-%dT%H:%M:%S', timeUtilities.gmtime(obsTime))
                    tb.close()

                    stext += "date = '"+obsTime+"'\n"

                    stext += "ampcal = '"+fieldName+"'\n"
                    mymsmd = msmdtool()
                    mymsmd.open(msName)

                    spwbb = {}
                    spwfreq = {}
                    spwbw = {}

                    for i in sorted(spwInfo.keys()):
                        spwbb[str(i)] = str(mymsmd.baseband(int(i)))
                        spwfreq[str(i)] = str(mymsmd.meanfreq(int(i)))
                        spwbw[str(i)] = str(mymsmd.bandwidths(int(i)))

                    stext += "band = '"+str(getBand(spwfreq[spwfreq.keys()[0]]))+"'\n"
                    stext += "bb = "+str(spwbb)+" # spw baseband number\n"
                    stext += "freq = "+str(spwfreq)+" # spw mean frequency\n"
                    stext += "bw = "+str(spwbw)+" # spw bandwidth\n"

                    scanList = mymsmd.scansforintent('OBSERVE_TARGET#ON_SOURCE')

                    mymsmd.close()

                    weatherInfo = getWeather(msName, scan = scanList.tolist())

                    stext += "elev = '"+str(weatherInfo[0]['elevation'])+"' # mean elevation\n"
                    stext += "temp = '"+str(weatherInfo[0]['temperature'])+"' # mean temperature\n\n"

                    stext += "f = open('"+msName+".cal.jyperk.txt', 'w')\n\n"

                    stext += "for ant in "+str(antNames)+":\n"
                    stext += "  for spw in "+str(spwIds)+":\n\n"
                    stext += "    if ant in jyperk.keys():\n"
                    stext += "      if spw in jyperk[ant].keys():\n"
                    stext += "        print >> f, '\t'.join([asdm, ant, spw, str(jyperk[ant][spw]), date, ampcal, band, bb[spw], freq[spw], bw[spw], elev, temp])\n"

                    stext += "\nf.close()\n"

                    self.addReducScriptStep(f1, mystepdict, "Writing out the Jy/K factors", stext, mystepindent)

                self.prependReducScriptHeader(f1, mystepdict, "Calibration", mystepindent)

                f1.close()

###

            if step == 'SDscience':

                os.chdir(currDir)

                mystepdict = {}
                mystepindent = "  "

                f1 = open('scriptForSDimaging.py', 'w')

                if getCasaVersion() < '5.1':
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', casadef.casa_version) == None:"
                else:
                    print >> f1, "if re.search('^"+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"', '.'.join([str(i) for i in cu.version().tolist()[:-1]])) == None:"
                print >> f1, "  sys.exit('ERROR: PLEASE USE THE SAME VERSION OF CASA THAT YOU USED FOR GENERATING THE SCRIPT: "+re.findall('^[0-9]+.[0-9]+.[0-9]+', getCasaVersion())[0]+"')\n\n"

                stext = 'msNames = [ \\\n'
                for i in range(len(msNames)):
                    stext += "'"+os.path.join(msNamesDir[i], msNames[i])+".cal.jy', \\\n"
                stext += ']\n\n'

                tos = []
                stext += "# Time on source\n"
                for i in range(len(msNames)):
                    tos.append(timeOnSource(os.path.join(msNamesDir[i], msNames[i]))['minutes_on_science'])
                    stext += "# "+msNames[i]+" = "+str(round(tos[i], 1))+" min\n"
                stext += "# Total = "+str(round(np.sum(tos), 1))+" min"

                self.addReducScriptStep(f1, mystepdict, "Define the calibrated datasets", stext, mystepindent)

                splitMS = False
                for i in range(len(msNames)):
                    if sorted(imagingParams[msNames[i]]['spwIds']) != sorted(imagingParams[msNames[0]]['spwIds']):
                        print 'WARNING: the science spw indices are not the same across all EBs, I will need to run split.'
                        splitMS = True
                        break

                if splitMS == True:

                    stext = ''
                    for i in range(len(msNames)):

                        stext += "os.system('rm -Rf "+os.path.join(msNamesDir[i], msNames[i])+".cal.jy.split')\n\n"
#                         stext += self.split2(msNames[i], msName1=msNames[i]+'.cal.jy', splitMyScienceSpw=True)
                        stext += "split(vis = '"+os.path.join(msNamesDir[i], msNames[i])+".cal.jy',\n"
                        stext += "  outputvis = '"+os.path.join(msNamesDir[i], msNames[i])+".cal.jy.split',\n"
                        stext += "  datacolumn = 'all',\n"
                        stext += "  spw = '"+','.join(sorted(imagingParams[msNames[i]]['spwIds']))+"')\n\n"

                        spwIds1 = sorted(imagingParams[msNames[i]]['spwIds'])
                        spwIds1 = [int(j) for j in spwIds1]
                        for j in range(len(spwIds1)):
                            imagingParams[msNames[i]][j] = imagingParams[msNames[i]][spwIds1[j]]
                            imagingParams[msNames[i]].pop(spwIds1[j])

                        spwIds1 = range(len(imagingParams[msNames[i]]['spwIds']))
                        spwIds1 = [str(j) for j in spwIds1]
                        imagingParams[msNames[i]]['spwIds'] = spwIds1

                    stext += 'msNames = [ \\\n'
                    for i in range(len(msNames)):
                        stext += "'"+os.path.join(msNamesDir[i], msNames[i])+".cal.jy.split', \\\n"
                    stext += ']\n\n'

                    self.addReducScriptStep(f1, mystepdict, "Split the science spectral windows", stext, mystepindent)

                stext = "# only the spectral windows listed below will be imaged\n"
                stext += "spwIds = "+str(imagingParams[msNames[0]]['spwIds'])+"\n\n"

                if getCasaVersion() >= '5.0':

                    blspwmap = {}
                    for i in imagingParams[msNames[0]]['spwIds']: blspwmap[i] = str(imagingParams[msNames[0]]['spwIds'].index(i))
                    stext += "blspwmap = "+str(blspwmap)+"\n"

#                 stext += "# spectral resolution\n"
#                 stext += "width = {}\n"
#                 for i in sorted(spwInfo.keys()):
#                     stext += "width['"+str(i)+"'] = '1.0kHz' # update this with the resolution requested by the PI\n"

                self.addReducScriptStep(f1, mystepdict, "Define the imaging parameters", stext, mystepindent)

                fieldId = imagingParams[msNames[0]]['fieldId']
                fieldName = imagingParams[msNames[0]]['fieldName']

                stext = "# the values below were calculated assuming fwhmfactor = 1.13\n\n"
                stext += "maxsize = "+str(imagingParams[msNames[0]]['maxsize'])+"\n\n"

                stext += "theorybeam = {}\n"
#                 for i in sorted(spwInfo.keys()):
                for i in sorted(imagingParams[msNames[0]]['spwIds']):
                    stext += "theorybeam['"+str(i)+"'] = "+str(imagingParams[msNames[0]][int(i)]['theorybeam'])+" # mean freq = "+str(imagingParams[msNames[0]][int(i)]['freq']*1e-9)+"\n"

                stext += "\n# the values below were calculated assuming cell = theorybeam[spw]/9.0\n"
                stext += "sfbeam = {}\n"
#                 for i in sorted(spwInfo.keys()):
                for i in sorted(imagingParams[msNames[0]]['spwIds']):
                    stext += "sfbeam['"+str(i)+"'] = "+str(imagingParams[msNames[0]][int(i)]['sfbeam'])+" # mean freq = "+str(imagingParams[msNames[0]][int(i)]['freq']*1e-9)+"\n"

                stext += "\nfor spw in spwIds:\n\n"

                stext += "  cell = theorybeam[spw]/9.0\n"
                stext += "  imsize = int(round(maxsize/cell)*2)\n\n"

                stext += "  sdimaging(infiles = msNames,\n"
                stext += "    field = '"+fieldName+"',\n"

                if getCasaVersion() < '5.0':
                    stext += "    spw = spw,\n"
                else:
                    stext += "    spw = blspwmap[spw],\n"

                stext += "    mode = 'channel',\n"
#                 stext += "    width = width[spw],\n"
                stext += "    outframe = 'LSRK',\n"
                stext += "    gridfunction = 'SF',\n"
                stext += "    convsupport = 6,\n"
                stext += "    phasecenter = "+str(fieldId)+",\n"
                stext += "    imsize = imsize,\n"
                stext += "    cell = str(cell)+'arcsec',\n"
                stext += "    overwrite = True,\n"
                stext += "    outfile = 'concat.spw%s.image' % (spw))\n\n"

                self.addReducScriptStep(f1, mystepdict, "Image the Science Target", stext, mystepindent)

                stext = "\nfor spw in spwIds:\n\n"
                stext += "  imhead(imagename = 'concat.spw%s.image' % (spw),\n"
                stext += "    mode = 'put',\n"
                stext += "    hdkey = 'bunit',\n"
                stext += "    hdvalue = 'Jy/beam')\n\n"

                self.addReducScriptStep(f1, mystepdict, "Correct the brightness unit in the image header", stext, mystepindent)

                stext = "\nfor spw in spwIds:\n\n"
                stext += "  myia = iatool()\n"
                stext += "  myia.open('concat.spw%s.image' % (spw))\n"
                stext += "  myia.setrestoringbeam(major = str(sfbeam[spw])+'arcsec', minor = str(sfbeam[spw])+'arcsec', pa = '0deg')\n"
                stext += "  myia.done()\n"

                self.addReducScriptStep(f1, mystepdict, "Add Restoring Beam Header Information to the Science Image", stext, mystepindent)

                stext = "\nfor spw in spwIds:\n\n"
                stext += "  exportfits(imagename = 'concat.spw%s.image' % (spw),\n"
                stext += "    fitsimage = 'concat.spw%s.image.fits' % (spw))\n\n"

                self.addReducScriptStep(f1, mystepdict, "Export images to fits", stext, mystepindent)

                self.prependReducScriptHeader(f1, mystepdict, "Imaging", mystepindent)

                f1.close()

###

            if run == True:
                for msName in msNames:
                    os.chdir(os.path.join(currDir, msNamesDir[msNames.index(msName)]))
                    clearstat()
                    if step == 'SDampcal':
                        subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', msName+'.scriptForSDampcalReduction.py'])
                    else:
                        subprocess.Popen(['casapy', '-r', getCasaVersion(), '--nologger', '-c', msName+'.scriptForSDCalibration.py'])

        # end of generateReducScript()

    def analyseSoftregOutputs(self, msName):

        f1 = open(msName + '.fullreport.txt', 'w')

        if os.path.exists(msName+'.phaseclosure'):

            print >> f1, "\n### Analysis of phase closure ###\n"

            print >> f1, "This is done on the scan of the bandpass calibrator."
            print >> f1, "The check will be PASS if the abs of the mean of all phase closures below is less than 0.5 deg.\n"

            f = open(msName+'.phaseclosure')
            fc = eval(f.read())
            f.close()

            print >> f1, "scan_id spw_id     min     max    mean  stddev\n"
            
            flag = 0
            for i in fc.keys():
                for j in fc[i].keys():
                    print >> f1, "%7i %6i %7.2f %7.2f %7.2f %7.2f" %(i, j, fc[i][j]['min'], fc[i][j]['max'], fc[i][j]['mean'], fc[i][j]['stddev'])
                    if fc[i][j]['mean'] > 0.5:
                        flag = 1

            if flag == 1:
                print >> f1, '\nCheck for phase closure -> FAIL'
                print 'Check for phase closure -> FAIL'
            else:
                print >> f1, '\nCheck for phase closure -> PASS'
                print 'Check for phase closure -> PASS'

        if os.path.exists(msName+'.sbgains'):

            print >> f1, "\n### Analysis of sideband ratios ###\n"

            print >> f1, "The check will be PASS if ...\n"

            f = open(msName+'.sbgains1')
            fc = f.read()
            f.close()

            fc1 = re.findall('.* for Pol [XY] =.*', fc)
            print >> f1, '\n'+'\n'.join(fc1)+'\n'

            f = open(msName+'.sbgains')
            fc = eval(f.read())
            f.close()

            flag = 0
            if len(fc[2]) > 0:
                flag = 1
                print >> f1, 'List of suspects:\n'
                print >> f1, 'ant_name BB_id pol_id SB_ratio\n'
                for i in fc[2].keys():
                    for j in fc[2][i].keys():
                        for k in fc[2][i][j].keys():
                            print >> f1, "%8s %5i %6i %8.2f" %(i, j, k, fc[2][i][j][k])
            else:
                print >> f1, 'No suspect found'

            if flag == 1:
                print >> f1, '\nCheck for sideband ratios -> FAIL'
                print 'Check for sideband ratios -> FAIL'
            else:
                print >> f1, '\nCheck for sideband ratios -> PASS'
                print 'Check for sideband ratios -> PASS'

        if os.path.exists(msName+'.wvrgcal2'):

            print >> f1, "\n### Analysis of WVR data ###\n"

            print >> f1, "The check will be PASS if ...\n"

            f = open(msName+'.wvrgcal2')
            fc = eval(f.read())
            f.close()

            print >> f1, "ant_name  Disc   RMS\n"
            for i in fc['ants'].keys():
                print >> f1, "%8s %5i %5i" %(i, fc['ants'][i]['Disc'], fc['ants'][i]['RMS'])
            
            flag = 0
            if len(fc['stats']['Disc']['outliers']) > 0 or len(fc['stats']['RMS']['outliers']) > 0:
                flag = 1
                print >> f1, '\nList of suspects:\n'
                outliers = []
                for i in fc['stats']['Disc']['outliers']: outliers.append(i)
                for i in fc['stats']['RMS']['outliers']: outliers.append(i)
                outliers = sorted(np.unique(outliers))
                print >> f1, ','.join(outliers)
            else:
                print >> f1, '\nNo suspect found'

            if flag == 1:
                print >> f1, '\nCheck for wvrgcal Disc/RMS -> FAIL'
                print 'Check for wvrgcal Disc/RMS -> FAIL'
            else:
                print >> f1, '\nCheck for wvrgcal Disc/RMS -> PASS'
                print 'Check for wvrgcal Disc/RMS -> PASS'

        if os.path.exists(msName+'.negativetrec'):

            print >> f1, "\n### Analysis of Syscal table (search for negative Trec) ###\n"

            print >> f1, "The check will be PASS if ...\n"

            f = open(msName+'.negativetrec')
            fc = f.read()
            f.close()

            flag = 0
            fc1 = re.findall(' *[0-9]+ *\[ *[0-9]+=[A-Za-z0-9]+, *[0-9]+,.*', fc)
            if len(fc1) != 0:
                fc3 = []
                for i in range(len(fc1)):
                    fc2 = fc1[i].replace(',', '').replace('[', '').replace(']', '').replace('=', ' ').split()
                    antName = fc2[2]
                    spwId = fc2[3]
                    polId = fc2[5]
                    fc3.append(tuple([antName, spwId, polId]))
                fc3 = np.unique(fc3)
                print >> f1, '\nList of suspects:'
                print >> f1, "\nant_name spw_id pol_id\n"
                for i in range(len(fc3)):
                    print >> f1, "%8s %6s %6s" %(fc3[i][0], fc3[i][1], fc3[i][2])

                fc2 = re.findall('A total of [0-9]+ negative Trx values encountered out of [0-9]+ possible \([0-9.]+\%\).', fc)[0]
                num1 = float(re.findall('[0-9.]+', fc2)[0])
                num2 = float(re.findall('[0-9.]+', fc2)[1])
                percent1 = 100.*num1/num2
                print >> f1, "\nFound %i negative Trec values, out of %i, which amounts to %.2f %%." %(num1, num2, percent1)
                if percent1 > 5:
                    flag = 1
            else:
                print >> f1, '\nNo suspect found'
            
            if flag == 1:
                print >> f1, '\nCheck for negative Trec -> FAIL'
                print 'Check for negative Trec -> FAIL'
            else:
                print >> f1, '\nCheck for negative Trec -> PASS'
                print 'Check for negative Trec -> PASS'

        if os.path.exists(msName+'.negativetsys'):

            print >> f1, "\n### Analysis of Syscal table (search for negative Tsys) ###\n"

            print >> f1, "The check will be PASS if ...\n"

            f = open(msName+'.negativetsys')
            fc = f.read()
            f.close()

            flag = 0
            fc1 = re.findall(' *[0-9]+ *\[ *[0-9]+=[A-Za-z0-9]+, *[0-9]+,.*', fc)
            if len(fc1) != 0:
                fc3 = []
                for i in range(len(fc1)):
                    fc2 = fc1[i].replace(',', '').replace('[', '').replace(']', '').replace('=', ' ').split()
                    antName = fc2[2]
                    spwId = fc2[3]
                    polId = fc2[6]
                    fc3.append(tuple([antName, spwId, polId]))
                fc3 = np.unique(fc3)
                print >> f1, '\nList of suspects:'
                print >> f1, "\nant_name spw_id pol_id\n"
                for i in range(len(fc3)):
                    print >> f1, "%8s %6s %6s" %(fc3[i][0], fc3[i][1], fc3[i][2])

                fc2 = re.findall('A total of [0-9]+ negative values encountered out of [0-9]+ possible \([0-9.]+\%\).', fc)[0]
                num1 = float(re.findall('[0-9.]+', fc2)[0])
                num2 = float(re.findall('[0-9.]+', fc2)[1])
                percent1 = 100.*num1/num2
                print >> f1, "\nFound %i negative Tsys values, out of %i, which amounts to %.2f %%." %(num1, num2, percent1)
                if percent1 > 5:
                    flag = 1
            else:
                print >> f1, '\nNo suspect found'
            
            if flag == 1:
                print >> f1, '\nCheck for negative Tsys -> FAIL'
                print 'Check for negative Tsys -> FAIL'
            else:
                print >> f1, '\nCheck for negative Tsys -> PASS'
                print 'Check for negative Tsys -> PASS'

#         if os.path.exists(tsysCalTableName[0]+'.platforming'): #### need change here
# 
#             f = open(tsysCalTableName[0]+'.platforming') #### need change here
#             fc = eval(f.read())
#             f.close()
#             
#             flag = 0
#             if len(fc) > 0:
#                 flag = 1
# 
#             if flag == 1:
#                 print 'Check for platforming in Tsys -> NOT OK'
#             else:
#                 print 'Check for platforming in Tsys -> OK'

#         if os.path.exists(bpassCalTableName[0]+'.platforming'): #### need change here
# 
#             f = open(bpassCalTableName[0]+'.platforming') #### need change here
#             fc = eval(f.read())
#             f.close()
#             
#             flag = 0
#             if len(fc) > 0:
#                 flag = 1
# 
#             if flag == 1:
#                 print 'Check for platforming in bandpass -> NOT OK'
#             else:
#                 print 'Check for platforming in bandpass -> OK'

        if os.path.exists(msName+'.delayjumps'):

            print >> f1, "\n### Analysis of phase data (search for delay jumps) ###\n"

            print >> f1, "The check will be PASS if ...\n"

            f = open(msName+'.delayjumps')
            fc = f.read()
            f.close()

            flag = 0
            fc1 = re.findall('[0-9]+-[0-9]+-[0-9]+T[0-9]+\:[0-9]+\:[0-9]+ +[A-Za-z0-9]+', fc)
            if len(fc1) != 0:
                flag = 1
                print >> f1, '\nList of suspects:'
                print >> f1, "\nant_name spw_id pol_id\n"
                for i in range(len(fc1)):
                    fc2 = fc1[i].split()[1].split('spw')
                    antName = fc2[0]
                    spwId = fc2[1].split('pol')[0]
                    polId = fc2[1].split('pol')[1]
                    print >> f1, "%8s %6s %6s" %(antName, spwId, polId)
            else:
                print >> f1, '\nNo suspect found'

            if flag == 1:
                print >> f1, '\nCheck for delay jumps -> FAIL'
                print 'Check for delay jumps -> FAIL'
            else:
                print >> f1, '\nCheck for delay jumps -> PASS'
                print 'Check for delay jumps -> PASS'

        f1.close()

    def ampcal_uvdist(self, ms2='', qa2_output_dir='', spw='', antenna='', correlation=''):
        """
        qa2_scripts/ampcal_uvdist.py

        This program plots the calibrated and the model visibility
        data for the selected source (usually a solar system object)
        The spw parameter is needed by the pipeline QA2 script since the pipeline never splits.
        The antenna parameter will plot only the data from the specified antennas. This should
           only be used by the pipeline QA2 script which calls this function twice, once with
           antenna='' and once with a list of antennas.

        INPUTS NEEDED:
           Assumes data base is ms2

        OUTPUTS:
        The calibrated and model amplitudes for the selected field
        number is placed in:   qa2_output_dir+'ampcal_uvdist.png'

        USEAGE: assumes ms2 as the visibility data set.  Program looks for
        the relevant files.
        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        ss_object = self.getIntentsAndSourceNames(ms2)['CALIBRATE_AMPLI']['name'][0]
        if (ss_object == ''):
            ss_object = self.getIntentsAndSourceNames(ms2)['CALIBRATE_FLUX']['name'][0]

        # plotxy fails for single-polarization data.
        # It also cannot overplot a model created with usescratch=False, so we will
        # use this work-around in all cases when we switch to casa 4.0.0. - T. Hunter
        pols = self.findNumberOfPolarizations(ms2)
        if (os.path.exists('%sampcal_uvdist_labeled.png' % (qa2_output_dir))):
            os.system('rm %sampcal_uvdist_labeled.png' % (qa2_output_dir))
        if (antenna == ''):
            if (os.path.exists('%sampcal_uvdist.png' % (qa2_output_dir))):
                os.system('rm %sampcal_uvdist.png' % (qa2_output_dir))
        else:
            if (os.path.exists('%sampcal_uvdist_antenna_subset.png' % (qa2_output_dir))):
                os.system('rm %sampcal_uvdist_antenna_subset.png' % (qa2_output_dir))
        if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
            plotmsparm = "showgui=False,"
        else:
            plotmsparm = ""
        if (pols < 2 or getCasaVersion() >= '4.0.0'):
            if (antenna == ''):
                figfile = '%sampcal_uvdist.png' % (qa2_output_dir)
                figfileModel = '%sampcal_uvdist_model.png' % (qa2_output_dir)
                figfileCorrected = '%sampcal_uvdist_corrected.png' % (qa2_output_dir)
            else:
                figfile = '%sampcal_uvdist_antenna_subset.png' % (qa2_output_dir)
                figfileModel     = '%sampcal_uvdist_model_antenna_subset.png' % (qa2_output_dir)
                figfileCorrected = '%sampcal_uvdist_corrected_antenna_subset.png' % (qa2_output_dir)

            cmd="plotms("+plotmsparm+"vis='%s', xaxis = 'uvdist', yaxis = 'amp', ydatacolumn = 'model', title='%s Model', field='%s', averagedata=True, avgtime='30', avgchannel='8000', plotfile='%s', coloraxis='spw', overwrite=True, spw='%s', antenna='%s', correlation='%s')" % (ms2,ss_object,ss_object,figfileModel,spw,antenna, correlation)
            print "Running "+cmd
            exec cmd

            cmd="plotms("+plotmsparm+"vis='%s', xaxis = 'uvdist', yaxis = 'amp', ydatacolumn = 'corrected', title='%s Corrected Data', field='%s', averagedata=True, avgtime='30', avgchannel='8000', plotfile='%s', coloraxis='spw', overwrite=True, spw='%s', antenna='%s', correlation='%s')" % (ms2,ss_object,ss_object,figfileCorrected,spw,antenna,correlation)
            print "Running "+cmd
            exec cmd

            # The following is for pipeline
            os.system("montage -tile 2x1 -geometry 1000x1000+0+0 %s %s %s"%(figfileModel,figfileCorrected,figfile))
        else:
            print "Running plotxy(vis='%s', xaxis='uvdist', yaxis='amp', field='%s', antenna='%s', overplot=False, datacolumn='model', averagemode='vector', timebin='30', width='4000', interactive=False, spw='%s')" % (ms2,ss_object,antenna,spw)
            plotxy(vis=ms2,
                   xaxis = 'uvdist', yaxis = 'amp',
                   field = ss_object,
                   antenna = antenna,
                   overplot = False, datacolumn = 'model',
                   averagemode = 'vector',
                   timebin = '30', width = '4000',
                   interactive = False, spw=spw)

            if (antenna == ''):
                figfile = '%sampcal_uvdist.png' % (qa2_output_dir)
            else:
                figfile = '%sampcal_uvdist_antenna_subset.png' % (qa2_output_dir)
                
            print "Running plotxy(vis='%s', xaxis='uvdist', yaxis='amp', field='%s', antenna='%s', overplot=True, datacolumn='corrected', averagemode='vector', timebin='30', width='4000', plotsymbol=',', interactive=False, figfile='%s', spw='%s')" % (ms2,ss_object,antenna,figfile,spw)
            plotxy(vis=ms2,
                   xaxis = 'uvdist', yaxis = 'amp',
                   field = ss_object,
                   antenna = antenna,
                   overplot = True, datacolumn = 'corrected',
                   averagemode = 'vector',
                   timebin = '30', width = '4000', plotsymbol = ',',
                   interactive = False,
                   figfile = figfile, spw=spw)

    def pickSubplotGrid(self, nant):
        nsub1 = 9; nsub2 = 8
        if nant <65: nsub1 = 8; nsub2 = 8
        if nant <57: nsub1 = 8; nsub2 = 7
        if nant <50: nsub1 = 7; nsub2 = 7
        if nant <43: nsub1 = 6; nsub2 = 7
        if nant <37: nsub1 = 6; nsub2 = 6
        if nant <31: nsub1 = 6; nsub2 = 5
        if nant <26: nsub1 = 5; nsub2 = 5
        if nant <21: nsub1 = 4; nsub2 = 5
        if nant <17: nsub1 = 4; nsub2 = 4
        if nant <13: nsub1 = 3; nsub2 = 4
        return(nsub1, nsub2)

    def ant_amp_temporal(self, ms2='', phase_cal='', caltable='', qa2_output_dir='', 
                         spw=[], nSpwsFlagged=0, phaseDiff=False):
        """
        ant_amp_temporal.py

        This program plots the antenna-based gains obtained from the
        phase calibrators---used to calibrate the target

        INPUTS NEEDED:

           ms2: the measurement set
           phase_cal: should be specified (integer ID, integer string, or name)
           caltable: must be specified
           nSpwsFlagged: number of spws that were either fully flagged during calibration
                  or unused due to spw-mapping for low S/N.
                  Setting this necessary as it checks that there is the correct number
                  of spws in the caltable that were observed on the phase calibrator.
           phaseDiff: if True, then don't check for detailed spw matching
           spw: this argument is ignored!

        OUTPUTS:
        The phase plots for each antenna are placed in
           ant_amp_temporal.png
        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(ms2)
        nspwsExpected = len(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('CALIBRATE_PHASE*')))
        mymsmd.close()
        phase_cal = str(phase_cal)
        if (not phase_cal.isdigit()):
            phase_cal = parseFieldArgument(ms2, phase_cal)
            if (phase_cal == None): return '-1'
            phase_cal = str(phase_cal[0][0])
        #  Plot calibrator gains

        #  Get antenna parameters

        tb.open(ms2+'/ANTENNA')
        ant_names=tb.getcol('NAME')
        nant = len(ant_names)
        tb.close()

        #  Get gaintable

        tb.open(caltable)
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3
        flag = tb.getcol('FLAG')
        tb1 = tb.query('FIELD_ID == '+str(phase_cal))
        flags = tb1.getcol('FLAG')
        if (len(flags) == 0):
            tb1.close()
            tb.close()
#            raise Exception('ant_amp_temporal: no rows found for FIELD_ID '+
#                            phase_cal +  ' in caltable '+ caltable +
#                            '.  You may need to re-run es.generateQA2Report and specify a' +
#                            ' different phase calibrator using the phase_cal parameter (e.g. phase_cal="3").')
            print 'ant_amp_temporal: no rows found for FIELD_ID '+ phase_cal +  ' in caltable '+ caltable + \
                  '.  Is the phase calibrator completely flagged?  You may need to re-run es.generateQA2Report and specify a' + \
                  ' different phase calibrator using the phase_cal parameter (e.g. phase_cal="3").'
            return(-2)

        keep = np.where(flags[0][0]==False)[0]
        print "Kept %d of %d unflagged solutions" % (len(keep), len(flags[0][0]))
        time = tb1.getcol('TIME')[keep]
        time = time-time[0]+5.0
        ant = tb1.getcol('ANTENNA1')[keep]
        if (calFormat == 33):
            gain = tb1.getcol('GAIN')[0][0][keep]
            spw = tb1.getcol('CAL_DESC_ID')[keep]
            if (len(tb1.getcol('GAIN')) == 1):
                Gsolution = False
            else:
                Gsolution = True
                gain2 = tb1.getcol('GAIN')[1][0][keep]
        else:
            gain = tb1.getcol('CPARAM')[0][0][keep]
            spw = tb1.getcol('SPECTRAL_WINDOW_ID')[keep]
            if (len(tb1.getcol('CPARAM')) == 1):
                Gsolution = False
            else:
                Gsolution = True
                gain2 = tb1.getcol('CPARAM')[1][0][keep]
        field = tb1.getcol('FIELD_ID')[keep]
        g = np.abs(gain)
        gg = g  #[0][0]
        if (Gsolution):
            gg2 = np.abs(gain2)
            print "This is a G solution."
        else:
            print "This is a T solution."

        tb.close()
        tb1.close()
        if (spw == []):
            print "No spws found in the cal table!"
            return
        spw_un = np.unique(spw)
        ant_un = np.unique(ant)
        nspw = len(spw_un)
        if (nspw+nSpwsFlagged < nspwsExpected and not phaseDiff):
            print "There are only %d spws (not %d) in the caltable = %s." % (nspw, nspwsExpected, os.path.basename(caltable))
            if (nSpwsFlagged == 0):
                print "If you flagged any spws during calibration, or you used spw-mapping for low S/N,"
                print "then re-run es.generateQA2Report with the nSpwsFlagged parameter set to the number"
                print "of spws that were either flagged or not used (probably %d)." % (nspwsExpected-nspw)
                print "Otherwise, you need to go back to the calibration script, find and fix the problem."
            else:
                print "You need to go back to the calibration script, determine why, and fix the problem."
            print "If this is an ACA dataset, you may need to decrease minblperant in gaincal and bandpass."
            return(-1)
            
        nant = len(ant_un)
        ggf = []
        for i in range (0, len(gg)):
            if gg[i] != 1.0: 
                ggf.append(gg[i])
            if (Gsolution):
                if gg2[i] != 1.0: 
                    ggf.append(gg2[i])

        if (len(ggf) < 1):
            print "No solutions found."
            print "If this was a phaseDiff dataset, then you need to set phaseDiff=True when you run es.generateQA2Report."
            return
        gmin = np.min(ggf)
        gmax = np.max(ggf)
        gmed = np.median(ggf)
        gmin = 0.8*gmin
        if gmax > 5.0*gmed:
            gmax = 5.0*gmed

        gmin = 0.0
        gmax = 1.1*gmax
        tmin = np.min(time)
        tmax = np.max(time)
            
        if (tmin == tmax):
            tmin = tmax-300
            tmax = tmax+300
        else:
            tmin = tmin - (tmax-tmin)*0.2
            tmax = tmax * 1.2
#        print 'gain range ', gmin, gmax
#        print 'time range ', tmin, tmax
        tincd = 3600.0
        tdiff = np.int((0.8*tmax-tmin)/tincd) * tincd
        while (tdiff == 0):
            tincd *= 0.5
            tdiff = np.int((0.8*tmax-tmin)/tincd) * tincd

        #  Set up plots

        #  Formatting of plots
        nsub3 = 0
        nsub1, nsub2 = self.pickSubplotGrid(nant)

        #  Loop over antenna
        pb.clf()
        color = ['b','r','g','y']
        color += ['k','m','c','b']
        color += color
        color += color
        color += color
        for iant in ant_un:
            nsub3 = nsub3 + 1
            for ispw in range(len(spw_un)): # in spw
                gamp = []
                gamp2 = []
                tamp = []
                tamp2 = []
                for pt in range(len(gg)):
                    if ((ant[pt]==iant) and (spw[pt]==spw_un[ispw]) and (gg[pt] != 1.0)):
                        gamp.append(gg[pt])
                        tamp.append(time[pt])
                    if (Gsolution):
                        if (ant[pt]==iant) and (spw[pt]==spw_un[ispw]) and (gg2[pt] != 1.0):
                            gamp2.append(gg2[pt])
                            tamp2.append(time[pt])
                    #
                #
                desc = pb.subplot(nsub1,nsub2,nsub3)
                pb.subplots_adjust(hspace=0.30, wspace=0.20)
                if (Gsolution):
#                    print "len(tamp) = %d, len(gamp) = %d, len(gamp2) = %d" % (len(tamp),len(gamp),len(gamp2))
                    pb.plot(tamp,gamp,'%so'%(color[ispw]), tamp2,gamp2,'%s+'%(color[ispw]))
                else:
                    pb.plot(tamp,gamp,'%so'%(color[ispw]))
                        

                pb.ylim(gmin,gmax)
                pb.xlim(tmin,tmax)
                if nsub3 != 1:
                    desc.set_yticklabels([])
                else:
                    pb.ylabel('Amplitude')
                pb.setp(plt.gca().get_ymajorticklabels(), size=8)

                pb.xticks(np.arange(0.0,tmax,tdiff))
                pb.setp(plt.gca().get_xmajorticklabels(), size=8)
                if nsub3 != nant:
                    desc.set_xticklabels([])
                else:
                    pb.xlabel('Time (sec)')

                pb.title('Ampl. '+ant_names[iant], size=10)

        print "Saving %s" % (qa2_output_dir+'ant_amp_temporal.png')
        pb.savefig(qa2_output_dir+'ant_amp_temporal.png')
        return(0)

    def ant_gain_check(self, ms2='', qa2_output_dir='', caltable=None, verbose=True, field=''):
        """
        This is an experimental python script that determines the statistics
        of the pre-bandpass gain levels calibration.  It is meant to determine
        any bad antennas/pol/spws.

        INPUTS NEEDED: ms2 (the .ms.split measurement set)
        OPTIONAL:
           cal table, else it assumes table is in ms2+'.ampli_short_inf'
           field, else it assumes the (first) bandpass calibrator

        OUTPUTS:
        The ascii output file lists the relative gains of all data streams
        qa2_output_dir+'ant_gain_check.txt'
        """

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)

        #  Get antenna paramters
        mtb = createCasaTool(tbtool)    
        if (ms2 != ''):
            mtb.open(ms2+'/ANTENNA')
            ant_names = mtb.getcol('NAME')
            mtb.close()
            npol = self.findNumberOfPolarizations(ms2)
        else:
            print "Assuming npol=2. If not correct, then set ms2."
            npol = 2

        #  Get gaintable
        if caltable==None:
            if (os.path.exists(ms2+'.ampli_short_inf')):
                caltable = ms2+'.ampli_short_inf'
            elif (os.path.exists(ms2+'.ampli_inf')):
                caltable = ms2+'.ampli_inf'
            else:
                caltable = ms2+'.ap_pre_bandpass'
        if (not os.path.exists(caltable)):
            print "Could not find caltable = ", caltable
            return
        mtb.open(caltable)
        names = mtb.colnames()
        field_ids = mtb.getcol('FIELD_ID')
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3
        if (field == ''):
            intentSources = self.getIntentsAndSourceNames(ms2)
            print intentSources
            field = intentSources['CALIBRATE_BANDPASS']['id'][0]
            if (field == ''):
                # read it from the table
                print "No BANDPASS intent, reading the field used for BANDPASS from the caltable..."
                field = field_ids[0]
            print "Picking bandpass field = %s." % (str(field))
        mytb = mtb.query('FIELD_ID == %s' % str(field))
        mytime = mytb.getcol('TIME')
        if (len(mytime) == 0):
            # The requested calibrator is not present, so use all (usually one).
            mytb = mtb
        time = mytb.getcol('TIME')
        time = time-time[0]+5.0
        ant = mytb.getcol('ANTENNA1')
        flags = mytb.getcol('FLAG')
        if (calFormat == 33):
            gain = mytb.getcol('GAIN')
            spw = mytb.getcol('CAL_DESC_ID')
        else:
            gain = mytb.getcol('CPARAM')
            spw = mytb.getcol('SPECTRAL_WINDOW_ID')
        g = np.abs(gain)
        nrows = len(ant)
        mytb.close()
        mtb.close()
        spw_un = np.unique(spw)
        ant_un = np.unique(ant)
        nspw = len(spw_un)
        nant = len(ant_un)
        if (ms2 == ''):
            ant_names = np.array(['xxxx']*nant)
            print "rows = %d" % (nrows)
        #  Get average g
        npts = g.shape[2]
        gg = []
        # to allow this to be run on a (non-normalized) BP table:
        nch=g.shape[1]
        # The np.min() is needed for full-polarization data.
        #        for i in range(0,np.min([npol,2])):
        for i in range(len(g)):  # necessary for T solutions to avoid crash
            for j in range(0,npts):
                for k in range(0,nch):
                    if (flags[i][k][j] == False): gg.append(g[i][k][j])
#                    if g[i][k][j] != 1.0: gg.append(g[i][k][j])

        gavg = np.median(gg)

        #   Open file for writing
        zfileRes = qa2_output_dir+'ant_gain_check.txt'
        os.system('rm -f '+zfileRes)
        f = open (zfileRes, 'w')
        if (verbose):
            print 'Creating file '+zfileRes
        f.write('\n\n')
        f.write('************************************************************************** \n')
        f.write('\n')
        f.write('                    MEDIAN GAIN VALUE = %8.3F \n\n' % (gavg))
        f.write('                RELATIVE ANTENNA GAIN FOR BANDPASS OBSERVATION \n\n')
        f.write(' Antenna       ')
        for ispw in spw_un.tolist(): # in the split file, spws start at 0
            f.write('SPW%2d' % ispw)
            if (ispw != spw_un.tolist()[-1]):
                f.write('             ')
            else:
                f.write('\n')
        f.write('    ' + '        X        Y'*len(spw_un.tolist()) + '\n')

        #  get a gain,phase for each ant, spw stream

        g_xall = []
        g_yall = []
        low_gain = 0.90
        high_gain = 1.10

        #  Get gain and phase average and rms for each stream (both pols)
        Tsol = '  Tsol  '
        for iant in range(0,nant):
            gant_xavg = []
            gant_yavg = []
            gant_xrms = []
            gant_yrms = []
            g_xstar = []
            g_ystar = []
            for ispw in spw_un.tolist(): # in the split file, spws start at 0
                g_x = []
                g_y = []
                for j in range(0,nrows):
                    if (iant == ant[j]) & (ispw == spw[j]):
                        for k in range(0,nch):
#                            if g[0][k][j] != 1.0:
                            if (flags[0][k][j] == False):
                                g_x.append(g[0][k][j])

#                            if g[1][k][j] != 1.0:
                            if (len(flags) > 1):
                                if (flags[1][k][j] == False):
                                    g_y.append(g[1][k][j])
                    if (len(g_x) > 0):
                        g_xavg = np.average(g_x)/gavg
                        g_xvar = np.var(g_x)/gavg
                    else:
                        g_xavg = 0
                        g_xvar = 0
                    if (len(g_y) > 0):
                        g_yavg = np.average(g_y)/gavg
                        g_yvar = np.var(g_y)/gavg
                    else:
                        g_yavg = 0
                        g_yvar = 0

                gant_xavg.append(g_xavg)
                if (len(g_x) > 0):
                    if (g_xavg > high_gain) or (g_xavg < low_gain):
                        g_xstar.append('**')
                    else:
                        g_xstar.append('  ')
                else:
                    g_xstar.append('flagged')
                gant_xrms.append(np.sqrt(g_xvar))
                gant_yavg.append(g_yavg)
                gant_yrms.append(np.sqrt(g_yvar))

                if (len(g_y) > 0):
                    if (g_yavg > high_gain) or (g_yavg < low_gain):
                        g_ystar.append('**')
                    else:
                        g_ystar.append('  ')
                elif (len(g) > 1):
                    g_ystar.append('flagged')
                else:
                    g_ystar.append(Tsol)


            if (g_xstar[0] == 'flagged'):
                g_xstarstring = ' flagged'
            else:
                g_xstarstring = '%6.2f%2s' % (gant_xavg[0],g_xstar[0])
            if (g_ystar[0] == 'flagged'):
                g_ystarstring = ' flagged'
            elif (g_ystar[0] == Tsol):
                g_ystarstring = Tsol
            else:
                g_ystarstring = '%6.2f%2s' % (gant_yavg[0],g_ystar[0])

            f.write('%3d-%4s %s %s' % (iant, ant_names[iant], g_xstarstring, 
                                        g_ystarstring))
            for ispw in range(1,nspw-1):
                if (g_xstar[ispw] == 'flagged'):
                    g_xstarstring = ' flagged'
                else:
                    g_xstarstring = '%6.2f%2s' % (gant_xavg[ispw],g_xstar[ispw])
                if (g_ystar[ispw] == 'flagged'):
                    g_ystarstring = ' flagged'
                elif (g_ystar[ispw] == Tsol):
                    g_ystarstring = Tsol
                else:
                    g_ystarstring = '%6.2f%2s' % (gant_yavg[ispw],g_ystar[ispw])
                f.write (' %s %s' % (g_xstarstring, g_ystarstring))
            if (nspw > 1):
                if (g_xstar[nspw-1] == 'flagged'):
                    g_xstarstring = ' flagged'
                else:
                    g_xstarstring = '%6.2f%2s' % (gant_xavg[nspw-1],g_xstar[nspw-1])
                if (g_ystar[nspw-1] == 'flagged'):
                    g_ystarstring = ' flagged'
                elif (g_ystar[nspw-1] == Tsol):
                    g_ystarstring = Tsol
                else:
                    g_ystarstring = '%6.2f%2s' % (gant_yavg[nspw-1],g_ystar[nspw-1])
                f.write (' %s %s\n' % (g_xstarstring, g_ystarstring))
            else:
                f.write('\n')

        f.write ('\n ** means outside of normalized range: %6.2f to %6.2f \n ' % (low_gain, high_gain))

        f.close()
        if (verbose):
            os.system('cat '+zfileRes)

    def findNumberOfPolarizations(self, ms2):
        #  Find number of pols, assuming it is the same for all spws!
        #  Thus this should only be called after the science spws have been split out.
        tb.open(ms2 +'/DATA_DESCRIPTION')
        polId = tb.getcol('POLARIZATION_ID')
        tb.close()
        if (len(polId) <= 4):
            # This is the traditional way of computing it for Cycle 0 data.
            tb.open(ms2 +'/POLARIZATION')
            corrProdRow = tb.selectrows(polId)
            corrProd = corrProdRow.getcell('CORR_PRODUCT', 0)
        else:
            # Since cycles 0 and 1 have only 4 spws, here we can guess that the data
            # have not been split, so pick the first science spw. - Todd Hunter
            #    Get a science spw
            spwdict = self.getSpwInfo(ms2)
            firstScienceSpw = spwdict.keys()[0]
#            print "first science spw = ", firstScienceSpw
            # This is the way that the pipeline datasets (which are never split) require it.
            tb.open(ms2 +'/POLARIZATION')
            corrProd = tb.getcell('CORR_PRODUCT',polId[firstScienceSpw])
        tb.close()
        corrProd = corrProd.transpose()
        nPol = corrProd.shape[0]
        return(nPol)

    def ant_phase_temporal(self, ms2='', caltable='', phase_cal='', qa2_output_dir='', spw=[]):

        """
        ant_phase_temporal.py

        This program plots the antenna-based phases obtained from the
        phase calibrators---used to calibrate the target

        INPUTS NEEDED:
           Assumes original table is in ms2
           caltable must be specified
           phase_cal: integer ID, integer string, or name

        OUTPUTS:
        The phase plots for each antenna are placed in
             ant_phase_temporal.png'

        USEAGE: assumes ms2 as the visibility data set.  Program looks for
        the relevant files.

        caltable = ms2+'.gain_inf'
        execfile ('qa2_plot_bandpass.py')
        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)

        #  Get antenna parameters
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(ms2)
        ant_names = mymsmd.antennanames()
        nant = len(ant_names)
        mymsmd.close()

        phase_cal = str(phase_cal)
        if (not phase_cal.isdigit()):
            phase_cal = parseFieldArgument(ms2, phase_cal)
            if (phase_cal == None): return '-1'
            phase_cal = str(phase_cal[0][0])

        polsInData = self.findNumberOfPolarizations(ms2)
        print "Found %d polarizations in the data" % (polsInData)
        
        #  Get gaintable in order to plot phases
        tb.open(caltable)
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3
        tb1 = tb.query('FIELD_ID == '+phase_cal)
        flags = tb1.getcol('FLAG')
        pols = np.shape(flags)[0]
        print "Found %d polarizations in the caltable" % (pols)
        if (polsInData == 1):
            pols = 1  # the other pol will be present in solution but completely flagged,
                      # so leaving pols=2 will cause a crash in the 'for' loop below.
        
        if(len(flags)==0):
            tb1.close()
            tb.close()
#            raise Exception('ant_phase_temporal: no rows found for FIELD_ID '+
#                            phase_cal +  ' in caltable '+ caltable)
            print 'ant_phase_temporal: no rows found for FIELD_ID '+ phase_cal +  ' in caltable '+ caltable +'. Is the phase calibrator totally flagged?'
            return
        ant = []
        timex = []
        timey = []
        px = []
        py = []
        for p in range(pols):
            keep = np.where(flags[p][0]==False)[0]
            time = tb1.getcol('TIME')[keep]
            time = time-time[0]+5.0
            ant = tb1.getcol('ANTENNA1')[keep]
            if (calFormat == 33):
                gain = tb1.getcol('GAIN')[p][0][keep]
                myspw = tb1.getcol('CAL_DESC_ID')[keep]
            else:
                gain = tb1.getcol('CPARAM')[p][0][keep]
                myspw = tb1.getcol('SPECTRAL_WINDOW_ID')[keep]
            field = tb1.getcol('FIELD_ID')[keep]
            phs = np.arctan2(np.imag(gain),np.real(gain))*180.0 / np.pi
            if (p==0):
                px = phs
                timex = time
            else:
                py = phs
                timey = time
        tb1.close()
        tb.close()
        nphases = len(ant)
        spw_un = np.unique(myspw)
        ant_un = np.unique(ant)
        nant = len(ant_un)

        #  Set up plots
        tmin = np.min(time)
        tmax = np.max(time)
        tincd = 3600.0
        tdiff = np.int((0.8*tmax-tmin)/tincd) * tincd
        while (tdiff == 0):
            tincd *= 0.5
            tdiff = np.int((0.8*tmax-tmin)/tincd) * tincd
        tmin = tmin - (tmax-tmin)*0.2
        tmax = tmax * 1.2


        #  Formatting of plots
        nsub1, nsub2 = self.pickSubplotGrid(nant)
        nsub3 = 0

        #  Loop over antenna
        pb.close()
        pb.clf()
        if (spw == []):
            spw = spw_un
        for iant in ant_un:
            if ant_names[iant] != 'junk':
                nsub3 = nsub3 + 1
                for ispw in spw_un:
                    if (ispw not in spw): continue
                    pxphase = []
                    pyphase = []
                    tampx = []
                    tampy = []
                    for pt in range(0,nphases):
                        if (ant[pt]==iant) and (myspw[pt]==ispw):
#                        if (iant == 6):
#                            print "Appending spw %d" % (ispw)
                            if(pt<len(timex)):
                                tampx.append(timex[pt])
                                pxphase.append(px[pt])
                            if(pt<len(timey)):
                                tampy.append(timey[pt])
                                pyphase.append(py[pt])


                    nn = len(pxphase)
                    if nn >0:
                        for i in range (1,nn):
                            pdiff = pxphase[i]-pxphase[i-1]
                            pdiff = np.mod(pdiff+900.0,360.0)-180.0
                            pxphase[i] = pxphase[i-1] + pdiff
                            if (len(pyphase) > 0):
                                pdiff = pyphase[i]-pyphase[i-1]
                                pdiff = np.mod(pdiff+900.0,360.0)-180.0
                                pyphase[i] = pyphase[i-1] + pdiff

                        pxavg = np.median(pxphase)
                        pxphase = pxphase - pxavg
                        if (len(pyphase) > 0):
                            pyavg = np.median(pyphase)
                            pyphase = pyphase - pyavg
                        desc = pb.subplot(nsub1,nsub2,nsub3)
                        pb.subplots_adjust(hspace=0.30, wspace=0.20)
                        if (pols > 1):
                            pb.plot(tampx,pxphase,'bo',tampy,pyphase,'go')
                        else:
                            pb.plot(tampx,pxphase,'bo')
                        pb.ylim (-190.0, 190.0)
                        if nsub3 != 1:
                            desc.set_yticklabels([])
                        else:
                            pb.ylabel('Phase (deg)')

                        pb.xticks(np.arange(0.0,tmax,tdiff))
                        pb.setp(plt.gca().get_xmajorticklabels(), size=8)
                        pb.setp(plt.gca().get_ymajorticklabels(), size=8)
                        pb.yticks([-180,-90,0,90,180])
                        if nsub3 != nant:
                            desc.set_xticklabels([])
                        else:
                            pb.xlabel('Time (sec)')

                        pb.title('Phase '+ant_names[iant], size=10)

        pb.savefig(qa2_output_dir+'ant_phase_temporal.png')

    def bandpass_plot(self, ms2='', qa2_output_dir='', 
                      bandpassShowFlaggedSolutions=False,
                      startant=0, stopant=-1, caltable='', debug=False):
        """
        This program plots the mean bandpass spectrum.  It will plot both 
        the original and/or the smoothed or BPOLY solution for comparison.

        INPUTS NEEDED:
           None.  assumes original table is in ms2+'.bandpass',
                  smooth table is in           ms2+'.smooth_20flat_ri'
                  or bpoly table is in         ms2+'.bpoly'
           unless ms2='' and caltable is specified

        OUTPUTS:
        The plots are put in several files with the name form:
        """

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        if (caltable == ''):
            caltable = ms2+'.bandpass'
        caltable2 = 'N'
        # casa 3.3 method
        if os.path.exists(caltable+'_smooth20flat_ri'):
            caltable2 = caltable+'_smooth20flat_ri'

        # casa 3.4 method
        if os.path.exists(caltable+'_smooth20ch'):
            caltable2 = caltable+'_smooth20ch'

        if os.path.exists(caltable+'_bpoly'):
            caltable2 = caltable+'_bpoly'

        if caltable2 != 'N':
            overlayString = '(red = solint version)'
        else:
            overlayString = ''
            
        #  Plot bandpass amp
        mytb = createCasaTool(tbtool)
        mytb.open(caltable)
        pb.clf()
        names = mytb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
            spw = mytb.getcol('SPECTRAL_WINDOW_ID')
        else:
            calFormat = 33  # <= casa 3.3
            spw = mytb.getcol('CAL_DESC_ID')
        spw_un = np.unique(spw)
        if (len(spw_un) <= 4):
            nsub1 = len(spw_un)
            nsub2 = 1
            hspace = 0.40
            wspace = 0.0
        else:
            n_spw = len(spw_un)
            nsub1 = int(round(np.sqrt(n_spw)))
            nsub2 = int(ceil(1.0*n_spw/nsub1))
            hspace = 0.40
            wspace = 0.30
        nsub3 = 0
        nchanPerSpw = {}
        for ispw in spw_un:
            nsub3 = nsub3 + 1
            if (calFormat == 33):
                tb1 = mytb.query('CAL_DESC_ID=='+str(ispw))
                g = tb1.getcol('GAIN')
            else:
                tb1 = mytb.query('SPECTRAL_WINDOW_ID=='+str(ispw))
                g = tb1.getcol('CPARAM')
            flags = tb1.getcol('FLAG')
            ant = tb1.getcol('ANTENNA1')
            tb1.close()
            gbp = np.abs(g)
            gch = []
            n0 = gbp.shape[0]
            n1 = gbp.shape[1]
            n2 = gbp.shape[2]
            if (stopant < 0):
                stopant = n2
            elif (stopant > n2):
                print "Stopping at final antenna %d (stopant=%d)" % (n2-1,n2)
                stopant = n2
            nAntennas = stopant-startant
            chan = []
            nchanPerSpw[ispw] = n1
            for ich in range(n1):
                gsum = 0.0
                gnumThisChan = 0
                for pol in range(n0):
                    for iant in range(startant,stopant):
                        if (not flags[pol][ich][iant]):
                            gsum = gsum + gbp[pol][ich][iant]
                            gnumThisChan += 1
                if (gnumThisChan > 0):
                    chan.append(ich)
                    gch.append(gsum/gnumThisChan)
            adesc = pb.subplot(nsub1, nsub2, nsub3)
            pb.subplots_adjust(hspace=hspace, wspace=wspace)
            if (bandpassShowFlaggedSolutions):
                pb.plot(chan,gch,'b,')
            else:
                pb.plot(np.array(chan),np.array(gch),'b,')
                pb.xlim([0,n1])
            if (getCasaVersion() < casaVersionWithMSMD or ms2==''):
                myTitle = 'Avg Bandpass spw '+str(ispw)+' '+overlayString 
            else:
                mymsmd = createCasaTool(msmdtool)
                mymsmd.open(ms2)
                meanfreq = mymsmd.meanfreq(ispw)
                mymsmd.close()
                myTitle = 'Avg Bandpass spw%02d (%.1fGHz) %s' % (ispw, meanfreq*1e-9,overlayString)
            pb.title(myTitle, fontsize=12-nsub2)
            pb.setp(adesc.get_xticklabels(), fontsize=9-nsub1)
            pb.setp(adesc.get_yticklabels(), fontsize=9-nsub1)
            yFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
        mytb.close()
        pb.xlabel('Channel')

        if caltable2 != 'N':
            nsub3 = 0
            for ispw in spw_un:
                nsub3 = nsub3 + 1
                mytb.open(caltable2)
                names = mytb.colnames()
                if ('CAL_DESC_ID' not in names):
                    calFormat = 34  # >= casa 3.4
                    tb1 = mytb.query('SPECTRAL_WINDOW_ID=='+str(ispw))
                    g = tb1.getcol('CPARAM')
                else:
                    calFormat = 33  # <= casa 3.3
                    tb1 = mytb.query('CAL_DESC_ID=='+str(ispw))
                    g = tb1.getcol('GAIN')
                flags = tb1.getcol('FLAG')
                ant = tb1.getcol('ANTENNA1')
                gbp = np.abs(g)
                tb1.close()
                mytb.close()
                gch = []
                n0 = gbp.shape[0]
                n1 = gbp.shape[1]
                n2 = gbp.shape[2]
                chan = []
                for ich in range(n1):
                    gsum = 0.0
                    gnumThisChan = 0
                    for pol in range(n0):
                        for iant in range(startant,stopant):
                            if (not flags[pol][ich][iant]):
                                gsum = gsum + gbp[pol][ich][iant]
                                gnumThisChan += 1
                    if (gnumThisChan > 0):
                        chan.append(ich)
                        gch.append(gsum/gnumThisChan)
                pb.subplot(nsub1, nsub2, nsub3)
                pb.subplots_adjust(hspace=hspace, wspace=wspace)
                if (calFormat == 34):
                    # we now use solint='20ch' which reduces num_chan by x20
                    # But make it work if people use different freq solint.
                    pb.plot(np.array(chan)*nchanPerSpw[ispw]/n1, gch, 'r,',mec='r')
                else:
                    pb.plot(chan,gch,'r,',mec='r')
        pb.savefig(qa2_output_dir+'bandpass_avg.png')

    def bandpass_rms(self, ms2='', refAnt='', qa2_output_dir='', caltable=''):
        """
        bandpass_rms.py

        This is an experimental python script that determines the rms channel
        to channel scatter in the bandpass.  It can be used to determine if
        smoothing or BPOLY is needed.

        INPUTS NEEDED:
           None.  assumes table is in ms2+'.bandpass'

        OUTPUTS:
        The ascii output file lists the relative gains of all data streams

        bandpass_rms.txt'

        USEAGE: assumes ms2 as the visibility data set

        execfile ('bandpass_rms.py')

        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        if (caltable == ''):
            caltable = ms2+'.bandpass'

# Someday, we might want to show stats for the smoothed solution
# instead. - Todd
#        caltable = ms2+'.bandpass_smooth20ch'
#        if (os.path.exists(caltable) == False):
#            caltable = ms2+'.bandpass'

        #  Get antenna parameters

        tb.open(ms2+'/ANTENNA')
        ant_names=tb.getcol('NAME')
        nant = len(ant_names)
#        print 'number of antenna ', nant,'  refant = ', refAnt
        tb.close()

        #  Get bandpass table

        supportMixedModes = True  # used while debugging new code
        tb.open(caltable)
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3
        time=tb.getcol('TIME')
        time = time-time[0]+5.0
        ant = tb.getcol('ANTENNA1')
        if (calFormat == 33):
            gain = tb.getcol('GAIN')
            spw = tb.getcol('CAL_DESC_ID')
        else:
            if (supportMixedModes):
                gain = []
                for i in range(len(time)):
                    gain.append(tb.getcell('CPARAM', i))  # support mixed modes
            else:  # old code
                gain = tb.getcol('CPARAM')
            spw = tb.getcol('SPECTRAL_WINDOW_ID')

        if (supportMixedModes and calFormat>=34):
            fg = []
            g = []
            p = []
            for i in range(len(time)):
                fg.append(tb.getcell('FLAG', i))   # support mixed modes
                g.append(np.abs(gain[i]))
                p.append(np.arctan2(np.imag(gain[i]),np.real(gain[i]))*180.0 / np.pi)
#            print "len(g) = ", len(g)             # nrows
#            print "len(g[0]) = ", len(g[0])       # 2 = npols
#            print "len(g[0][0]) = ", len(g[0][0]) # 240 = nchan
            g = zip(*g)  # np.transpose(g,(1,2,0)) works for non-mixed modes
            p = zip(*p)  # np.transpose(p,(1,2,0)) works for non-mixed modes
            newg = []
            newp = []
            for i in range(len(g)):
                newg.append(zip(*g[i]))
                newp.append(zip(*p[i]))
            g = newg
            p = newp
        else: # old code
            fg = tb.getcol('FLAG')
            g = np.abs(gain)
            p = np.arctan2(np.imag(gain),np.real(gain))*180.0 / np.pi
            # shapes should be [npol, nchan, nrows]

        clen = len(g[0])  # e.g., will be 3840 for FDM non-mixed modes
#        print "clen = ", clen
        tb.close()
        ns=len(ant) # number of solutions (i.e. rows) in the table
        ant_un = np.unique(ant)
        spw_un = np.unique(spw)
        nspw = len(spw_un)
        nch = len(g[1])

        #  Get avg gain and rms for each stream (both pols)

        zfileRes = qa2_output_dir+'bandpass_rms.txt'
        os.system('rm -f '+zfileRes)
        print 'creating file '+zfileRes
        f = open (zfileRes, 'w')

        f.write('\n\n')
        f.write('************************************************************************* \n')
        f.write('\n')
        f.write('      NORMALIZED BANDPASS AMPLITUDE RMS OVER '+str(nch)+' CHANNELS \n')
        f.write('          using table %s  \n\n' % (caltable))
        f.write('  Antenna      ')
        for ispw in spw_un:
            f.write('SPW%d'%ispw)
            if (ispw == spw_un[-1]):
                f.write('\n')
            else:
                f.write('           ')
        f.write('      ')
        for ispw in spw_un:
            f.write('       X      Y')
        f.write('\n')
        gall_rms_x = []
        gall_rms_y = []
        rms_med = []
        for iant in ant_un:
            # need the following line in case spw=0 is not present in caltable (eg. cycle1/219)
            f1string = '%3d-%4s  '% (iant,ant_names[iant]) 
            for ispw in spw_un:
                gspw_x = []
                gspw_y = []
                for j in range(0,ns):  
                    if (iant == ant[j]) and (ispw == spw[j]):
                        for ic in range (int(0.05*clen),int(0.95*clen)):
                            if (supportMixedModes):
                                gspw_x.append(g[0][ic][j])  # support mixed modes (g is now a list not an array)
                                gspw_y.append(g[1][ic][j])
                            else:  # old code
                                gspw_x.append(g[0,ic,j])
                                gspw_y.append(g[1,ic,j])
                            #
                        #
                    #
                #
                grms_x = np.sqrt(np.var(gspw_x))
                grms_y = np.sqrt(np.var(gspw_y))
                rms_med.append(grms_x)
                rms_med.append(grms_y)
                if ispw == 0:
                    f1string = ('%3d-%4s  %6.3f %6.3f  '% (iant,ant_names[iant], grms_x,grms_y))
                    gall_rms_x.append(grms_x)
                    gall_rms_y.append(grms_y)

        #        if (ispw > 0) and (ispw < nspw-1):
        #            f2string = ('%s %6.3f %6.3f '% (f1string,grms_x,grms_y))
        #            gall_rms_x.append(grms_x)
        #            gall_rms_y.append(grms_y)
        #            f1string = f2string

        #        if ispw == (nspw-1):
        #            f3string = ('%s %6.3f %6.3f \n'% (f2string,grms_x,grms_y))
        #            gall_rms_x.append(grms_x)
        #            gall_rms_y.append(grms_y)

        #        if ispw == (nspw-1):
        #            f3string = ('%s %6.3f %6.3f \n'% (f2string,grms_x,grms_y))

                if ispw > 0:
                    f2string = ('%s %6.3f %6.3f '% (f1string,grms_x,grms_y))
                    gall_rms_x.append(grms_x)
                    gall_rms_y.append(grms_y)
                    f1string = f2string

#                if ispw == (nspw-1):
                if ispw == spw_un[-1]:
                    f3string = ('%s \n'% (f1string))

            f.write(f3string)


        rms_med = np.median(rms_med)
        f.write('\n\n    BANDPASS RMS MEDIAN VALUE = %6.3f \n' % (rms_med))
        if rms_med > 0.05:
            f.write ('Consider using BPOLY, or B with pre-averaging (e.g. solint="8MHz")\n')


        #  Get outliers in each spw
        gx = gall_rms_x
        gy = gall_rms_y
        gx = np.reshape(gx,(nant,nspw))
        gy = np.reshape(gy,(nant,nspw))
        gx = np.transpose(gx)
        gy = np.transpose(gy)
#        print "shape(gx) = ", np.shape(gx)
#        print "shape(gy) = ", np.shape(gy)
        tsigma = 3.0
        pbad = []
        antbad = []
        spwbad = []
        f.write('\n\n       RMS OUTLIERS >%3.1f SIGMA\n\n' % (tsigma))
        f.write(' SPW     Xpol           Ypol\n')
        f.write('      mean    rms    mean   rms     OUTLIERS \n\n')
#        print "spw_un = ", spw_un
        for i in range(nspw):
            ispw = spw_un[i]
            nout = 0; noutstr = 'No Outliers'
#            print "shape(gx[%d]) = " % (i), np.shape(gx[i])
#            print "shape(gy[%d]) = " % (i), np.shape(gy[i])
            xavg = np.median(gx[i])
            xeavg = np.sqrt(np.var(gx[i]))
            yavg = np.median(gy[i])
            yeavg = np.sqrt(np.var(gy[i]))
            f.write('%3d  %6.4f %6.4f  %6.4f %6.4f'% (ispw, xavg, xeavg, yavg, yeavg))
            for iant in ant_un:
                xoff = (gx[i][iant]-xavg)/xeavg
                cpol = 'X'
                if (np.abs(xoff) > tsigma):
                    if (nout == 0):
                        f.write('  %s  ant=%2d  sigma=%4.1f \n'% (cpol, iant, xoff))
                    else:
                        f.write('%36s  ant=%2d  sigma=%4.1f \n'% (cpol, iant, xoff))
                    nout=nout+1
                    pbad.append(cpol)
                    antbad.append(iant)
                    spwbad.append(ispw)
                if (yeavg != 0.0):
                    yoff = (gy[i][iant]-yavg)/yeavg
                    cpol = 'Y'
                    if (np.abs(yoff) > tsigma):
                        if (nout == 0):
                            f.write('  %s  ant=%2d  sigma=%4.1f \n'% (cpol, iant, yoff))
                        else:
                            f.write('%36s  ant=%2d  sigma=%4.1f \n'% (cpol, iant, yoff))
                        nout += 1
                        pbad.append(cpol)
                        antbad.append(iant)
                        spwbad.append(ispw)
            if nout == 0: f.write('  %s \n'% (noutstr))


        f.close()
        os.system('cat '+zfileRes)

        #  Plot band bandpasses
        nobad = len(pbad)
        if nobad > 0:
          if getCasaVersion() >= '4.2.0':
              # cannot plot complex numbers with a simple pb.plot() in the newer pylab
              print "Cannot produce bandpass_bad.png in casa versions >= 4.2.0, but it is not used in QA2 report."
          else:
            print '******* see plot in bandpass_bad.png ******'
            pb.clf()
            nsub1 = nobad/2 + 1
            nsub2 = 2; nsub3 = 0
            tb.open (caltable)
            for i in range(0,len(pbad)):
                nsub3 = nsub3 + 1
                if (calFormat == 33):
                    tb1 = tb.query('CAL_DESC_ID=='+str(spwbad[i])+' and ANTENNA1=='+str(antbad[i]))
                    if pbad[i] == 'X': g = tb1.getcol('GAIN')[0]
                    if pbad[i] == 'Y': g = tb1.getcol('GAIN')[1]
                else:
                    tb1 = tb.query('SPECTRAL_WINDOW_ID=='+str(spwbad[i])+' and ANTENNA1=='+str(antbad[i]))
                    if pbad[i] == 'X':
                        g = tb1.getcol('CPARAM')[0]
                    if pbad[i] == 'Y':
                        g = tb1.getcol('CPARAM')[1]

                gg = np.transpose(g)[0]
                chan = range(0,len(gg))
                pb.subplot(nsub1, nsub2, nsub3)
                pb.plot(chan,gg,'b,')
                pb.title('Bandpass: spw '+str(spwbad[i])+'; ant '+str(antbad[i])+'; pol '+pbad[i])
                pb.xticks([])
            pb.savefig(qa2_output_dir+'bandpass_bad.png')
            tb.close()
            
    def flag_calc(self, in_ms, use_fg_tool=False, calculatePercent=False, spw=''):
        # Create the local instance of the flag tool and open it
        afToolVersion = '4.2.1'
        if (getCasaVersion() >= afToolVersion and use_fg_tool==False):
            afLoc = aftool()   
        elif (getCasaVersion() >= '4.0.0'):
            fgLoc = fgtool()   
        else:
            fgLoc = fgtool.create()

        if (getCasaVersion() < afToolVersion or use_fg_tool):
            fgLoc.open( in_ms )
            # Get the flagging statistics
            fgLoc.setdata()
            fgLoc.setflagsummary()
            flag_stats_dict = fgLoc.run()
            # Close and delete the local flag tool
            fgLoc.done()
            del fgLoc
            if (calculatePercent):
                flag_stats_dict = stuffPercentIntoFlagdict(flag_stats_dict)
        else:
            afLoc.open(in_ms)
            afLoc.selectdata(spw=spw)
            afLoc.parsesummaryparameters()
            afLoc.init()
            flag_stats_dict = afLoc.run()
            if (calculatePercent):
                flag_stats_dict = stuffPercentIntoAFdict(flag_stats_dict)
            flag_stats_dict = flag_stats_dict['report0']
            afLoc.done()
        # Return the dictionary containing the flagging statistics
        return flag_stats_dict

    def flag_stats(self, ms2='', qa2_output_dir='', use_fg_tool=False, calculatePercent=False, spw=''):
        """
        flag_stats.py

        This is an experimental python script that determines the distribution
        of flags in the calibrated data base.  It only includes flags from
        shadowing and anomalous bad data.

        INPUTS NEEDED:

           None.  assumes visibility data set is ms2

        OUTPUTS:

        The ascii output file lists the spw and antenna percentage of
        flagged data.

        qa2/flag_stat.txt'

        USEAGE: assumes ms2 as the visibility data set

        execfile (flag_stats.py)

        """
        if (not os.path.exists(ms2)):
            print "Could not find ms2 = ", ms2
            return
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        flagStats = self.flag_calc(ms2, use_fg_tool=use_fg_tool, calculatePercent=calculatePercent, spw=spw)

        zfileRes = qa2_output_dir+'flag_stat.txt'
        os.system('rm -f '+zfileRes)
        f = open (zfileRes, 'w')
        print 'opening file '+zfileRes

        f.write('\n\n\n    FLAGGING STATISTICS \n\n')
        f.write( 'Overall -> %.2f percent' %(100.0*flagStats['flagged']/flagStats['total'])+'\n')
        f.write('\n')
        f.write('Per spw (over total of dataset):\n')
        for i in flagStats['spw']:
            f.write(i+' -> %.2f' %(100.0*flagStats['spw'][i]['flagged']/flagStats['total'])+'\n')

        f.write('')
        f.write('Per antenna (over total of dataset):\n')
        for i in flagStats['antenna']:
            f.write( i+' -> %.2f' %(100.0*flagStats['antenna'][i]['flagged']/flagStats['total'])+'\n')
        f.close()
        return(flagStats)

    def flux_values(self, ms2='', qa2_output_dir=''):

        """
        flux_values.py

        This program reads the log file obtained with flux scale, and puts
        the output in a better format.

        execfile ('flux_values.py')

        INPUTS NEEDED:

           None.  assumes table is in ms2+'.fluxscale'

        OUTPUTS:

        The ascii output  is put in

        ms2+'.flux.txt'

        USEAGE:

        execfile ('qa2_flux_values.txt')

        """

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        caltable = ms2+'.fluxscale'
        if os.path.isfile(caltable) == False: return 0
        caltable2 = qa2_output_dir+'flux.txt'
        f1 = open(caltable, 'r')
        f2 = open(caltable2, 'w')

        f2.write('**********************************************************\n\n')
        f2.write('                    Flux Density Determinations \n\n')

        lines = f1.readlines()
        for line in lines:
            x = line.find('Found reference')
            if x!=-1:
                line_out = line[x+26:x+42]
                f2.write('Reference source %s\n' %(line_out))

            x = line.find('Flux density for')
            if x!=-1:
                line_out = line[x+17:]
                if line_out.find('INSUFFICIENT DATA') < 0:
                    # Do not show non-science spws, which will generate this text when spws not reindexed.
                    f2.write('%s' %(line_out.replace(' +/- ','+-').replace('freq=','').replace(' = ','=')))

            x = line.find('Fitted spectrum')
            if x!=-1:
                line_out = line[x:].replace(' with fitorder=1','').replace(' for','').replace('Fitted','Fit')
                line_out = line_out.replace(' +/- ','+-').replace('freq=','').replace('Flux density = ','')
                f2.write('%s' %(line_out))

        f1.close()
        caltable_band9 = caltable[:-9] + 'cal_fluxfile'
        if (os.path.isfile(caltable_band9)):
            print "Appending results from extra file = ", caltable_band9
            f1 = open(caltable_band9, 'r')
            lines = f1.readlines()
            for line in lines:
                x = line.find('Found reference')
                if x!=-1:
                    line_out = line[x+26:x+42]
                    f2.write('Reference source %s\n' %(line_out))

                x = line.find('Flux density for')
                if x!=-1:
                    line_out = line[x+17:]
                    f2.write('%s' %(line_out.replace(' +/- ','+-').replace('freq=','').replace(' = ','=')))

                x = line.find('Fitted spectrum')
                if x!=-1:
                    line_out = line[x:].replace(' with fitorder=1','').replace(' for','').replace('Fitted','Fit')
                    line_out = line_out.replace(' +/- ','+-').replace('freq=','').replace('Flux density = ','')
                    f2.write('%s' %(line_out))
            f1.close()
        
        f2.close()
        os.system('cat '+caltable2)

    def addTrailingSlashIfNecessary(self, qa2_output_dir):
        """
        If name is not null, and does not end in a '/', then append a '/'.
        Also, create the directory if it does not exist, so that qa2 functions
        can be called independently, and before generating the full qa2 report.
        """
        if (len(qa2_output_dir) > 0):
            if (os.path.exists(qa2_output_dir) == False):
                print "Creating directory ", qa2_output_dir
                os.mkdir(qa2_output_dir)
            if (qa2_output_dir[-1] != '/'):
                qa2_output_dir += '/'
        return(qa2_output_dir)

    def listobs2(self, ms2='', makeplot=True, qa2_output_dir='', 
                 plotAntennasActualSize=False, xlim=None, ylim=None):

        """
        This is an experimental qa2 python script that produces a more
        readable listobs and plotants than the casapy version.


        INPUTS NEEDED:

           ms2 = visibility data set.  inputset to desired ms.
           makeplot  T = make antenna array plot, F = do not ...
           plotAntennaActualSize: will behave similar to plotants, but without 
                                  the problems that plotants has:
                  1. It will work on measurement sets that are read-only.
                  2. The title will not include the directory.
           xlim, ylim: plotrange (in meters), used only if plotAntennaActualSize is True 

        OUTPUTS:

        The ascii listobs output file is placed in

        qa2_output_dir+'NewListobs.txt'

        The antenna plot file is placed in

        qa2_output_dir+'antenna_config.png'

        USEAGE:

        ms2 = <data set ms>
        qa2_output_dir = <output directory path>
        makeplot = T
        execfile (listobs.py)

        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        myms = mstool()
        myms.open(ms2)
        scanInfo = myms.getscansummary()
        myms.close()
        if (getCasaVersion() < casaVersionWithMSMD):
            vm = ValueMapping(ms2)
            msname = vm.inputMs
            spw_info=vm.spwInfo
            conditions = listconditions(vis=ms2,byscan=True,scan='',antenna='0',verbose=False,vm=vm)
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms2)
            msname = ms2
            conditions = listconditions(vis=ms2,byscan=True,scan='',antenna='0',verbose=False)
        try:
            scanInfoSummary = scanInfo['summary']  # CASA 3.4
        except:
            scanInfoSummary = scanInfo  # CASA 4.0.0
        scan_list = scanInfoSummary.keys() 
        #  Sort scans
        scan_num = []
        for sc in scan_list:
            scan_num.append(int(sc))

        scan_srt = np.sort(scan_num)

        nscans = len(scan_srt)

        #   Get experiment time range
        if (getCasaVersion() < casaVersionWithMSMD):
            ttemp = vm.getTimesForScan(scan_srt[0])
            int_time = scanInfoSummary[str(scan_srt[0])]['0']['IntegrationTime']
            ttemp = ((ttemp/86400.0)+2400000.5-2440587.5)*86400.0 - int_time/2.0
            scan_begin = np.min(ttemp)
            ttemp = vm.getTimesForScan(scan_srt[nscans-1])
            ttemp = ((ttemp/86400.0)+2400000.5-2440587.5)*86400.0 + int_time/2.0
            scan_end = np.max(ttemp)
        else:
            ttemp = mymsmd.timesforscans(mymsmd.scannumbers())
            ttemp = ((ttemp/86400.0)+2400000.5-2440587.5)*86400.0
            scan_begin = np.min(ttemp)
            scan_end = np.max(ttemp)
        exp_start=timeUtilities.strftime('%Y/%m/%d/%H:%M:%S', timeUtilities.gmtime(scan_begin))
        exp_end=timeUtilities.strftime('%Y/%m/%d/%H:%M:%S', timeUtilities.gmtime(scan_end))

        scan_list = []
        field_list = []
        time_on_field = []

        #   Open file for writing
        #   Split data set?
        zfileRes = qa2_output_dir+'NewListObs.txt'
        print "removing file = ", zfileRes
        os.system('rm -f '+zfileRes)
        f = open (zfileRes, 'w')
        print 'opening file '+zfileRes
        #
        f.write( '\n')
        f.write( '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n')
        f.write( '\n')
        f.write( '          SUMMARY INFORMATION FOR  %s '% (os.path.basename(msname))+'\n')
        f.write( '\n')
        f.write( '   Experiment Duration:  %19s to'%  (exp_start)+'\n')
        f.write( '                         %19s'%  (exp_end)+'\n')
        f.write( '\n')
        f.write( '   Processed from ms: '+ms2+'\n')
        f.write( '   Written to file:   NewListobs.txt\n')
        f.write( '\n')
        f.write( '                                   SCAN LISTING \n')
        f.write( '\n')
        f.write( '  Scan FdId srcId FieldName         StartTime    StopTime     Int(s) Elev  ScanIntent\n')
        for isc in scan_srt:
        #    print 'scan ', isc
            iscstr = str(isc)
            subscan = []
            nk = scanInfoSummary[iscstr].keys()
            for sc in nk:
                subscan.append(int(sc))

            sub_scan = np.sort(subscan)
            sfid = []
            sstart = []
            sstop = []
            nrows = []
            for isubsc in sub_scan:
                j = str(isubsc)
                fid = scanInfoSummary[iscstr][j]['FieldId']
                start_time = scanInfoSummary[iscstr][j]['BeginTime']
                stop_time = scanInfoSummary[iscstr][j]['EndTime']
                integration_time = scanInfoSummary[iscstr][j]['IntegrationTime']
                sfid.append(fid)
                sstart.append(start_time)
                sstop.append(stop_time)

        #   Integration time addition
            int_time = integration_time / 2.0 / 3600.0 / 24.0
        #   Combine consecutive fieldids
            nslots = len(sfid)
            ib = []
            ie = []
            ib.append(0)
            for i in range(1,nslots):
                if sfid[i] != sfid[i-1]:
                    ie.append(i-1)
                    ib.append(i)

            ie.append(nslots-1)
            nsources = len(ie)
            for i in range (0,nsources):
                ibeg = ib[i]
                iend = ie[i]
                field = sfid[ibeg]
                if (getCasaVersion() < casaVersionWithMSMD):
                    field_name = vm.getFieldNamesForFieldId(field)
                    source_id = vm.getFieldIdsForFieldName(field_name)[0]
                else:
                    field_name = mymsmd.namesforfields(field)[0]
                    source_id = mymsmd.fieldsforname(field_name)[0]
                if len(field_name) > 12: field_name = field_name[0:12]+'*'

                mjd_start = sstart[ibeg] - int_time
                mjd_stop = sstop[iend] + int_time
                q_start = qa.quantity(mjd_start, unitname='d')
                q_stop  = qa.quantity(mjd_stop, unitname='d')
                scan_list.append(isc)
                field_list.append(field)
                time_on_field.append((mjd_stop-mjd_start)* 1440.0)
                elev = conditions[isc]['elevation']
        #        pwv = conditions[isc]['pwv']
                if (getCasaVersion() < casaVersionWithMSMD):
                    intent = vm.getIntentsForScan(isc)
                else:
                    intent = mymsmd.intentsforscan(isc)
                jintent = string.join(intent, '')
                scan_intent = []
                if jintent.find('POINTING')!=-1: scan_intent.append('Cal Pointing')

                if jintent.find('FOCUS')!=-1: scan_intent.append('Cal Focus')

                if jintent.find('ATMOSPHERE')!=-1: scan_intent.append('Cal atmos=Tsys')

                if jintent.find('BANDPASS')!=-1: scan_intent.append('Cal Bandpass')

                if jintent.find('PHASE')!=-1: scan_intent.append('Cal Phase')

                if jintent.find('AMPLI')!=-1: scan_intent.append('Cal Flux')

                if jintent.find('SIDEBAND')!=-1: scan_intent.append('Cal Sideband')

                if jintent.find('TARGET')!=-1: scan_intent.append('Obs Target')

                f.write (' %4d %4d %4d   %13s  %s - %s  %5.2f %6.1f  %s\n' % (isc, field, source_id, field_name.ljust(16), call_qa_time(q_start,prec=7), call_qa_time(q_stop,prec=7), integration_time, elev, string.join(scan_intent,', ')))
        #
        #
        #
        #      Get source information
        f.write( '\n')
        f.write( '\n')
        f.write( '                               FIELD INFORMATION \n')
        f.write( '\n')
        f.write( ' Fid  Srd  Field                       RA  (J2000)    DEC       Fld Time  #Scans\n')
        f.write( '                                                                  (min)\n')
        # temp = timeOnSource(ms=ms2,verbose=False) # no longer used?
        tb.open(ms2+'/FIELD')
        name = tb.getcol('NAME')
        sid = tb.getcol('SOURCE_ID')
        pos = tb.getcol('PHASE_DIR')
        tb.close()
        nfld = len(name)
        n_of_scans = len(field_list)
        for i in range(0,nfld):
            ra=str(pos[0][0][i])+'rad'
            rra=call_qa_time(ra,prec=11)
            dec=str(pos[1][0][i])+'rad'
            rdec=call_qa_angle(dec,prec=10)
            total_time = 0.0
            num_scans = 0
            for ix in range(0,n_of_scans):
                if field_list[ix] == i:
                    total_time = total_time + time_on_field[ix]
                    num_scans = num_scans + 1

            f.write( '%4d %4d  %22s %14s %1s%12s  %5.2f    %3d\n' % (i,sid[i],name[i].ljust(22), rra, rdec[0:1],rdec[2:],total_time, num_scans))
        #       print '%4d %4d  %22s %14s %1s%12s  %5.2f    %3d\n' % (i,sid[i],name[i].ljust(22), rra, rdec[0:1],rdec[2:],total_time, num_scans)



        #      Get spectral window information
        f.write( '\n')
        f.write( '\n')
        f.write( '                        FREQUENCY INFORMATION \n')
        f.write( '\n')
        f.write( 'spw  nchan      -----Frequencies (GHz)-------     --Channel Width-- \n')
        f.write( '               First         Last     Bandwidth     MHz     km/s     POLN \n')
        f.write( '\n')
        if (getCasaVersion() < casaVersionWithMSMD):
            spw_size = len(spw_info)
        else:
            spw_size = mymsmd.nspw()

        #  Getting polarizations
        polId = []
        tb.open(ms2+'/DATA_DESCRIPTION')
        for spwId in range(0,spw_size):
            if (getCasaVersion() >= casaVersionWithMSMD):
                # msmd reports all the high-numbered WVR spws which we want to avoid
                if (spwId in mymsmd.wvrspws() and spwId>0):
                    spw_size = spwId
                    break
            polId.append(tb.query('SPECTRAL_WINDOW_ID == '+str(spwId)).getcell('POLARIZATION_ID', 0))

        tb.close()

        polId = sorted(dict.fromkeys(polId).keys())[0]

        tb.open(ms2 +'/POLARIZATION')
        corrProdRow = tb.selectrows(polId)
        corrProd = corrProdRow.getcell('CORR_PRODUCT', 0)
        corrType = corrProdRow.getcell('CORR_TYPE', 0)
        tb.close()
        corrProd = corrProd.transpose()

        numCorr = corrProd.shape[0]

        if numCorr == 2:
            polProdNames = ['XX', 'YY']
        elif numCorr == 4:
            polProdNames = ['XX', 'XY', 'YX', 'YY']
        elif numCorr == 1:
            if (corrType == 9):
                polProdNames = ['XX']
            elif (corrType == 12):
                polProdNames = ['YY']
        else:
            sys.exit("Number of correlations not supported")

        #  Does spw0 have wvr?

        if (getCasaVersion() >= casaVersionWithMSMD):
            Nwvr = len(mymsmd.wvrspws())
        else:
            if spw_info.keys()[0] == 0:
                Nwvr = 0
            else:
                Nwvr = 1
        if (Nwvr > 0):
            f.write ("  0     4   184.550       189.550     7.500                       ['I'] \n")

        if (getCasaVersion() >= '4.1.0'):
            # remove this once CAS-5450 is resolved
            mytb = createCasaTool(tbtool)
            mytb.open(msname+'/SPECTRAL_WINDOW')
        for i in range(Nwvr,spw_size):
            if (getCasaVersion() < casaVersionWithMSMD):
                bandwidth = spw_info[i]['bandwidth']/1.0E9
                num_chan = spw_info[i]['numChannels']
                chan_width = spw_info[i]['chanWidth']/1.0E6
                chan_1_freq = spw_info[i]['chanFreqs'][0]/1.0E9
                chan_L_freq = spw_info[i]['chanFreqs'][num_chan-1]/1.0E9
            else:
                # replace the next two lines when CAS-5450 is resolved
                chan_width = mytb.getcell("CHAN_WIDTH",i)[0]/1.0E6
                bandwidth = mytb.getcell('TOTAL_BANDWIDTH',i)/1.0E9
                num_chan = mymsmd.nchan(i)
                chan_1_freq = mymsmd.chanfreqs(i)[0]/1.0E9
                chan_L_freq = mymsmd.chanfreqs(i)[num_chan-1]/1.0E9
                
            vel_res = chan_width / chan_1_freq * 299.7
            f.write( '%3d %5d %12.6f %12.6f %7.3f %11.3f %8.2f  %s \n' % (i,num_chan,chan_1_freq,chan_L_freq,bandwidth,chan_width,vel_res,polProdNames))
        if (getCasaVersion() >= '4.1.0'):
            # remove this once CAS-5450 is resolved
            mytb.close()

        #      Get antenna information
        f.write( '\n')
        f.write( '\n')
        f.write( '                      ANTENNA INFORMATION \n')
        f.write( '\n')
        f.write(  ' ID  Name    Pad   Size     Longitude   Latitude      E-off   N-off  Elev \n')
        f.write( '                    (m)                                 (m)     (m)   (m) \n')
        tb.open(ms2+'/ANTENNA')
        position = tb.getcol('POSITION')
        diam = tb.getcol('DISH_DIAMETER')
        station = tb.getcol('STATION')
        antenna = tb.getcol('NAME')
        nant = len(antenna)
        tb.close()
        lon0 = np.radians(ALMA_LONGITUDE)
        lat0 = np.radians(ALMA_LATITUDE)
        plotx = []
        ploty = []
        for i in range (nant):
            xx = position[0][i]
            yy = position[1][i]
            zz = position[2][i]
            elev = sqrt(xx**2+yy**2+zz**2)-6379960.0
            lat = math.asin(zz/sqrt(xx**2+yy**2+zz**2))
            lon = math.atan2(yy, xx)
            zlat = str(lat)+'rad'
            zlon = str(lon)+'rad'
            qlat = call_qa_angle(zlat,prec=8)
            qlon = call_qa_angle(zlon,prec=8)
            qqlat = qlat[0]+qlat[2:]
            qqlon = qlon[0]+qlon[2:]
            n_off = (lat - lat0)*6379960.0 +215.0
            e_off = (lon - lon0)*6379960.0 * cos(lat) - 3.0
            f.write( '%3d  %4s %6s %6.1f  %12s %12s  %7.1f %7.1f %5.1f \n' %(i,antenna[i],station[i],diam[i],qqlon,qqlat,e_off,n_off,elev))
            plotx.append (e_off)
            ploty.append (n_off)
        #
        if makeplot:
            pngname = 'antenna_config.png'
            plotfile = qa2_output_dir + pngname
            if (xlim is not None or ylim is not None):
                plotfile = qa2_output_dir + 'antenna_config_zoom.png'
            plotAntennaPositionList(plotx, ploty, antenna, diam, os.path.basename(ms2),
                                    plotfile, plotAntennasActualSize, xlim, ylim)

        f.close()
        os.system('cat '+zfileRes)
        # end of listobs2

    def mosaic_plot(self, ms2='', qa2_output_dir=''):

        """
        mosaic_plot.py

        This program plots the mosaic region.

        INPUTS NEEDED:

           vis = desired ms

        OUTPUTS:

        The mosaic plot is put in 'qa2_mosaic_plot.png'


        USEAGE:

        execfile ('qa2_mosaic_plot_.py')

        """

        # Is this a mosaic?

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        a=self.getIntentsAndSourceNames(ms2)
        idstr = a['OBSERVE_TARGET']['idstring']
        sid =   a['OBSERVE_TARGET']['sourceid']
        if idstr != sid:
            plotmosaic(vis=ms2, sourceid=sid[0], figfile = qa2_output_dir+'mosaic_plot.png', showImageBorder=True, pblevel=0.2)

    def buildAllChannelsDict(self, ms2, calspws):
        channels = {}
        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms2)
            for i in calspws:
                channels[i] = str(mymsmd.nchan(i)) # prevents warning from plotms
            mymsmd.close()
        else:
            for i in calspws:
                channels[i] = '8000'
        return(channels)

    def phase_cal_check(self, ms2='', phase_cal='', qa2_output_dir=''):

        """
        qa2_phase_cal_check.py

        This script plots the phase calibration
          amp and phase versus uvdist for each spw
          amp and phase versys frequency for each spw

        INPUTS NEEDED:
           Assumes data base is ms2
           Needs phase_cal: field number or name

        OUTPUTS:
        The calibrated and model amplitudes for the selected field
        number is placed in
            qa2_output_dir+'phase_cal_uvdist.png'
            qa2_output_dir+'phase_cal_freq.png'
        """
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        phase_cal = str(phase_cal)
        if (not phase_cal.isdigit()):
            phase_cal = parseFieldArgument(ms2, phase_cal)
            if (phase_cal == None): return '-1'
            phase_cal = str(phase_cal[0][0])
            
        pols = self.findNumberOfPolarizations(ms2)
        #  Get number of spw
        if True:
            calspws = getScienceSpws(ms2, 'CALIBRATE_PHASE#ON_SOURCE', returnString=False)
            nspw = len(calspws)
        else:
            a = vishead(vis=ms2, mode = 'get',hdkey = 'spw_name')
            nspw = len(a[0])
            calspws = range(nspw)
        channels = self.buildAllChannelsDict(ms2, calspws)

        #  Plot amp, phase versus uvdist for calibrator
        nsubplot = 100*nspw+20
        if (pols < 2 or getCasaVersion() >= '4.0.0'):
            # plotxy fails in this case, so make separate plotms plots and montage them together
            # It also cannot overplot a model created with usescratch=False, so we will
            # likely use this work-around in all cases when we switch to casa 4.0.0. - T. Hunter
            plotfiles = ''
            for i in calspws:
                myplotfile = qa2_output_dir + 'phase_cal_ampuvdist%d.png' % i
                plotfiles += myplotfile + ' '
                if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                    showgui = ", showgui=False"
                else:
                    showgui = ""
                print "Running plotms(vis='%s', title='spw %d amplitude', xaxis='uvdist', yaxis='amp', ydatacolumn='corrected', spw=str(%d), averagedata=True, avgchannel='%s', field='%s', avgtime='60', plotfile='%s',coloraxis='corr', overwrite=True%s)" % (ms2,i,i,channels[i],phase_cal,myplotfile,showgui)
                if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                    plotms(vis=ms2, title='spw %d amplitude' % (i), xaxis = 'uvdist', yaxis = 'amp',
                           ydatacolumn = 'corrected', spw=str(i), averagedata = True, avgchannel=channels[i],# '8000', 
                           field = phase_cal, avgtime= '60', plotfile=myplotfile,coloraxis='corr',
                           overwrite=True, showgui=False)
                else:
                    plotms(vis=ms2, title='spw %d amplitude' % (i), xaxis = 'uvdist', yaxis = 'amp',
                           ydatacolumn = 'corrected', spw=str(i), averagedata = True, avgchannel=channels[i],# '8000',
                           field = phase_cal, avgtime= '60', plotfile=myplotfile,coloraxis='corr',
                           overwrite=True)
                myplotfile = qa2_output_dir+'phase_cal_phaseuvdist%d.png' % i
                plotfiles += myplotfile + ' '
                print "Running plotms(vis='%s', title='spw %d phase', xaxis='uvdist', yaxis='phase', ydatacolumn='corrected', spw=str(%d), averagedata=True, avgchannel='%s', field='%s', avgtime='60', plotfile='%s',coloraxis='corr', overwrite=True%s)" % (ms2,i,i,channels[i],phase_cal,myplotfile,showgui)
                if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                   plotms(vis=ms2, title='spw %d phase' % (i), xaxis = 'uvdist', yaxis = 'phase',
                       ydatacolumn = 'corrected', spw=str(i), averagedata = True, avgchannel=channels[i],#'8000', 
                       field = phase_cal, avgtime= '60', plotfile=myplotfile,coloraxis='corr',
                       overwrite=True, showgui=False)
                else:
                   plotms(vis=ms2, title='spw %d phase' % (i), xaxis = 'uvdist', yaxis = 'phase',
                       ydatacolumn = 'corrected', spw=str(i), averagedata = True, avgchannel=channels[i],# '8000', 
                       field = phase_cal, avgtime= '60', plotfile=myplotfile,coloraxis='corr',
                       overwrite=True)
                
            rows = 2*int(round(np.sqrt(nspw*2))/2)
            if (rows == 0): rows = 1 # will now be either 1,2,4,6 etc.
            cols = int(ceil(2.0*nspw/rows))
            cmd = "montage -tile %dX%d -geometry 1000x1000+0+0  %s %sphase_cal_uvdist.png"%(rows,cols,plotfiles,qa2_output_dir)
            print "Running %s" % (cmd)
            os.system(cmd)
            os.system('rm -f %s' % plotfiles)
        else:
            for i in calspws:
                nsubplot = nsubplot+1
                print "Running plotxy(vis='%s', xaxis = 'uvdist', yaxis = 'amp', datacolumn = 'corrected', spw=str(%d), averagemode = 'vector', width = '%s', plotsymbol = ',', field = '%s', timebin = '60',subplot=%d)" % (ms2,i,channels[i],phase_cal,nsubplot)
                plotxy(vis=ms2, xaxis = 'uvdist', yaxis = 'amp', datacolumn = 'corrected', spw=str(i),
                       averagemode = 'vector', width=channels[i], plotsymbol = ',',
                       field = phase_cal, timebin = '60',subplot=nsubplot)
                nsubplot = nsubplot+1
                if (i != calspws[-1]):
                    figfile = ''
                else:
                    figfile = qa2_output_dir+'phase_cal_uvdist.png'
                print "Running plotxy(vis='%s', xaxis = 'uvdist', yaxis = 'phase', datacolumn = 'corrected', spw=str(%d), averagemode = 'vector', width = '%s', plotsymbol = ',', field = '%s', timebin = '60',subplot=%d, figfile='%s')" % (ms2,i,channels[i],phase_cal,nsubplot,figfile)
                plotxy(vis=ms2, xaxis = 'uvdist', yaxis = 'phase',
                       datacolumn = 'corrected', spw=str(i),
                       averagemode = 'vector', width=channels[i], plotsymbol = ',',
                       field = phase_cal, timebin = '60', subplot=nsubplot, figfile = figfile)

        #  Plot amp, phase versus freq for calibrator
        #  Get number of channels
        vm = ValueMapping(ms2)
        spw_Info = vm.spwInfo
        nchan = spw_Info[calspws[0]]['numChannels']
        nchan = nchan / 128
        if nchan < 2:
            nchan = 1
            nwidth = ''
        else:
            nwidth = str(nchan)

        nsubplot = 100*nspw+20
        if (pols < 2 or getCasaVersion() >= '4.0.0'):
            # plotxy fails in this case, so make separate plotms plots and montage them together.
            # It also cannot overplot a model created with usescratch=False, so we will
            # likely use this work-around in all cases when we switch to casa 4.0.0. - T. Hunter
            plotfiles = ''
            if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                showgui = ", showgui=False"
            else:
                showgui = ""
            for i in calspws:
                myplotfile = qa2_output_dir+'phase_cal_ampfreq%d.png' % i
                plotfiles += myplotfile + ' '
                print "Running plotms(vis='%s', title='spw %d amplitude', xaxis='freq', yaxis='amp', ydatacolumn='corrected', spw=str(%d), averagedata=True, avgchannel='%s', avgbaseline=True, field='%s', avgtime='100000', avgscan=True,plotfile='%s',coloraxis='corr', overwrite=True%s)" % (ms2,i,i,nwidth,phase_cal,myplotfile,showgui)
                if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                    plotms(vis=ms2, title='spw %d amplitude' % (i), xaxis = 'freq', yaxis = 'amp',
                       ydatacolumn = 'corrected', spw=str(i),
                       averagedata = True, avgchannel = nwidth, avgbaseline=True,
                       field = phase_cal, avgtime= '100000',avgscan=True,
                       plotfile = myplotfile,coloraxis='corr', overwrite=True, showgui=False)
                else:
                    plotms(vis=ms2, title='spw %d amplitude' % (i), xaxis = 'freq', yaxis = 'amp',
                       ydatacolumn = 'corrected', spw=str(i),
                       averagedata = True, avgchannel = nwidth, avgbaseline=True,
                       field = phase_cal, avgtime= '100000',avgscan=True,
                       plotfile = myplotfile,coloraxis='corr', overwrite=True)
                myplotfile = qa2_output_dir+'phase_cal_phasefreq%d.png' % i
                plotfiles += myplotfile + ' '
                print "Running plotms(vis='%s', title='spw %d phase', xaxis='freq', yaxis='phase', ydatacolumn='corrected', spw=str(%d), averagedata=True, avgchannel='%s', avgbaseline=True, field='%s', avgtime='100000', avgscan=True,plotfile='%s',coloraxis='corr', overwrite=True%s)" % (ms2,i,i,nwidth,phase_cal,myplotfile,showgui)
                if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
                    plotms(vis=ms2, title='spw %d phase' % (i), xaxis = 'freq', yaxis = 'phase',
                       ydatacolumn = 'corrected', spw=str(i),
                       averagedata = True, avgchannel = nwidth, avgbaseline=True,
                       field = phase_cal, avgtime= '100000', avgscan=True,
                       plotfile=myplotfile,coloraxis='corr', overwrite=True,showgui=False)
                else:
                    plotms(vis=ms2, title='spw %d phase' % (i), xaxis = 'freq', yaxis = 'phase',
                       ydatacolumn = 'corrected', spw=str(i),
                       averagedata = True, avgchannel = nwidth, avgbaseline=True,
                       field = phase_cal, avgtime= '100000', avgscan=True,
                       plotfile=myplotfile,coloraxis='corr', overwrite=True)
            rows = 2*int(round(np.sqrt(nspw*2))/2)  
            if (rows == 0): rows = 1  # will now be either 1,2,4,6 etc.
            cols = int(ceil(2.0*nspw/rows))
            cmd = "montage -tile %dX%d -geometry 1000x1000+0+0  %s %sphase_cal_freq.png"%(rows,cols,plotfiles,qa2_output_dir)
            print "Running %s" % (cmd)
            os.system(cmd)
            os.system('rm -f %s' % plotfiles)
        else:
            for i in calspws:
                nsubplot = nsubplot+1
                print "Running plotxy(vis='%s', xaxis='freq', yaxis='amp', datacolumn='corrected', spw='%s', averagemode='vector', width='%s', timebin='100000', crossscans=True, crossbls=True, interactive=False, field='%s', subplot=%d)" % (ms2,str(i),nwidth,phase_cal,nsubplot)
                plotxy(vis=ms2,
                       xaxis = 'freq', yaxis = 'amp',
                       datacolumn = 'corrected', spw=str(i),
                       averagemode = 'vector', width = nwidth, timebin='100000',
                       crossscans = True, crossbls = True, interactive = False,
                       field = phase_cal, subplot=nsubplot)
                nsubplot = nsubplot+1
                if i != calspws[-1]:
                    figfile = ''
                else:
                    figfile = qa2_output_dir+'phase_cal_freq.png'
                print "Running plotxy(vis='%s', xaxis='freq', yaxis='phase', datacolumn='corrected', spw='%s', averagemode='vector', width='%s', timebin='100000', crossscans=True, crossbls=True, interactive=False, field='%s', subplot=%d, figfile='%s')" % (ms2,str(i),nwidth,phase_cal,nsubplot,figfile)
                plotxy(vis=ms2,
                xaxis = 'freq', yaxis = 'phase',
                datacolumn = 'corrected', spw=str(i),
                averagemode = 'vector', width = nwidth,timebin='100000',
                crossscans = True, crossbls = True, interactive = False,
                field = phase_cal,subplot=nsubplot,
                figfile = figfile)

    def sensitivity_calculator(self, ms1='', ms2='', caltable='', s_id='', 
                               tsys_field='', qa2_output_dir='', tsysChanTol=1,
                               debug=False, intent='OBSERVE_TARGET', nant=None,
                               dropchan=0, useLocalAlmaHelper=True):
        """
        Sensitivity calculator

        This is an experimental python script that determines
        the expected sensitivity for observations of a science
        target field with aggregate bandwidth.

        The default source_id is the first OBSERVE_TARGET.  If a
        mosaic, the sensitivity for one field in the source_id is
        determined.  source_id can be overwritten as an INPUT.

        INPUTS:  vis:            the calibrated measurement set name
                 ctable:         tsys table name
                 s_id:           s_id = ''.  Use first OBSERVE_TARGET and
                                   one field if mosaic.
                                 s_id = 'N'. Use this source number.  Will
                                   include all fields if mosaic.
                 tsys_field:  Required. Can be integer ID or string integer ID
                 nant:   Number of antennas (default = use total number of antennas)
                 dropchan:  the number of channels to drop from each spw

          Examples:  s_id='';execfile('sensitivity_calculator.py')
                          will determine expected rms for the first target

                     s_id='4';execfile('sensitivity_calculator.py')
                          will determine expected rms for source id 4.

        OUTPUTS:  The expected rms sensitivity for aggregate bandwidth,
             which is stored in mfs_sensitivity.

          obs_spw:                   A numerical list of the spectral windows
          chan_sensitivity[obs_spw]: The rms sensitivity in mJy for one channel
                                      per spw
          chan_width[obs_spw]:       The width of one channel (GHz) per spw
          num_chan[obs_spw]:         The number of channels per spw
          spw_sensitivity[obs_spw]:  The rms sensitivity in mJy per spw
          mfs_sensitivity:           The rms sensitivity in mJy for all spw
        """
        if (useLocalAlmaHelper):
            try:
                from almahelpers_localcopy import tsysspwmap
                useLocalTsysspwmap = True
            except:
                from recipes.almahelpers import tsysspwmap
                useLocalTsysspwmap = False
        else:
            from recipes.almahelpers import tsysspwmap
            useLocalTsysspwmap = False

        import numpy
        if (tsys_field == ''):
            print "es.sensitivity_calculator() requires the tsys_field parameter to be set"
            return
        if (ms2 == ''):
            ms2 = ms1 + '.split'
        if (not os.path.exists(ms2)):
            return("Could not find the split ms: ", ms2)
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        # Initialization of normalized values for each band
        # Taken from alma sensitivity calculator.  Band 5 added on July 18, 2016. - TRH
        band_low =  [ 75.0, 120.0, 163.0, 211.0, 300.0, 380.0, 600.0, 787.0]
        band_high = [120.0, 163.0, 211.0, 300.0, 380.0, 500.0, 750.0, 1000.0]
        band_name = ['3','4','5','6','7','8','9','10']
        tsys_nominal = [75.0, 86.0, 120.0, 90.0, 150.0, 387.0, 1200.0, 1515.0]
        sensitivities = [0.20, 0.24, 0.37, 0.27, 0.50, 1.29, 5.32, 8.85]  

        #  Assume apropri sensitivity for band 3,4,6,7,8,9,10
        #  Sensitivity units are in mJy and are normalized to:
        #    16 12-m antennas,
        #    8 GHz bandwidth
        #    Dual freq bandwidth
        #    for tsys_nominal given above
        #    Integration time of one minute

        #  Determine the time on first target source field

        tos = self.getIntentsAndSourceNames(ms2)

        if s_id == '':
            tos[intent].keys()
            source_id = tos[intent]['sourceid'][0]
            if (source_id == ''):
                print "You need to specify a source ID with the s_id parameter"
                return
            field_all = tos[intent]['id']
            nfield = len(field_all)
            time_os = timeOnSource(ms2)
            min_all = time_os[source_id]['minutes_on_source']
            min_per_field = min_all / nfield
        else:
            time_os = timeOnSource(ms2)
            all_scans = numpy.unique(time_os['source_ids'])
            source_id = int(s_id)
            if source_id in all_scans:
                min_per_field = time_os[source_id]['minutes_on_source']
            else:
                print '*************************************************'
                print '******* source_id =', source_id, ' NOT FOUND'
                print '*************************************************'
                print "You may need to run es.fixForCSV2555() on this dataset."
                return(None)


        #  Determine the number of antennas
        if (nant == None):
            mytb = createCasaTool(tbtool)
            mytb.open(ms2+'/ANTENNA')
            antenna = mytb.getcol('NAME')
            mytb.close()
            nant = len(numpy.unique(antenna))

        #  Get frequency information
        # obs_spw1 contains spw IDs numbered as per the original ms, e.g. 0..21
        # obs_spw contains spw IDs numbered as per split MS, i.e. 0..3 (or 0..7 for BW-switching),
        #        because the split MS has both the 4 phasecal spws and the 4 target spws
        # This code was originally written assuming there would be a one-to-one correspondence.
        # But this will not be true for certain spectral scan datasets where different bandpass calibrator
        #    was used for different tunings, and thus need to be split into separate datasets for calibration.
        #    In this case, len(obs_spw1) > len(obs_spw)
        if (getCasaSubversionRevision() >= casaRevisionWithAlmaspws):
            # filter obs_spw1 to contain only the science target spws
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms1)
            obs_spw1 = sorted(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent(intent+'*')))
            mymsmd.close()
        else:
            obs_spw1 = sorted(self.getSpwInfo(ms1).keys())
        tsysmap = tsysspwmap(vis=ms1, tsystable=ms1+'.tsys', tsysChanTol=tsysChanTol)
        
        vm = ValueMapping(ms2)
        npol = vm.nPolarizations
        d_pol = 'single_pol'
        if npol >= 2: d_pol = 'dual_pol'

        spw_info = vm.spwInfo
        if (getCasaSubversionRevision() >= casaRevisionWithAlmaspws):
            mymsmd.open(ms2)
            obs_spw = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent(intent+'*'))
            # filters spw_info to contain only OBSERVE_TARGET spws
            spw_info = filterDictionary(spw_info, obs_spw)
            if (len(obs_spw) != len(obs_spw1)):
                all_spw1 = len(obs_spw1)
                # further filter obs_spw1 to only contain spws that are in the split ms
                obs_spw1 = np.intersect1d(obs_spw1, spwsForNames(ms1, mymsmd.namesforspws(obs_spw)))
                print "Filtered out %d spws that are not in the split ms." % (all_spw1-len(obs_spw1))
            mymsmd.close()

        obs_spw = spw_info.keys()
        n_spw = len(obs_spw)
        chan_width = []
        mean_freq = []
        band_index = []
        num_chan = []
#        print "len(obs_spw)=%d: %s" % (len(obs_spw), obs_spw)
        for dspw in obs_spw:  
            chan_width.append(spw_info[dspw]['chanWidth']/1.0E9)
            num_chan.append(spw_info[dspw]['numChannels'])
            freq = spw_info[dspw]['meanFreq']/1.0E9
            mean_freq.append(freq)
            priorLength = len(band_index)
            for i in range(len(band_low)):
                if (freq>band_low[i]) and (freq<band_high[i]):
                    band_index.append(i)
                    break
            if (len(band_index) == priorLength):
                print "Did not find a matching Band for freq = ", freq
        if (len(band_index) == 0):
            print "You need to specify intent."
            return
        #  Get tsys for each spw
        if (caltable == ''):
            caltable = ms1+'.tsys'
        mytb = createCasaTool(tbtool)
        mytb.open(caltable)
        names = mytb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
            spw = mytb.getcol('SPECTRAL_WINDOW_ID')
        else:
            calFormat = 33  # <= casa 3.3
            spw = mytb.getcol('CAL_DESC_ID')
        original_spw = np.unique(spw)
        ss = str(tsys_field)
        tsys_spw = []
#        for dspw in obs_spw: # Normally obs_spw has spws0..3, but will have 0..7 in BW-switching
#                  data.  So, when obs_spw1 is pared to the 4 spws of interest (above), the previous
#                  loop definition of dspw will overflow the array obs_spw1 (below), so I changed
#                  the dspw loop definition to be 0..len(obs_spw1). - Todd
        for dspw in range(len(obs_spw1)):   
            if (calFormat == 33):
#                 tb1 = mytb.query('FIELD_ID=='+ss+' and CAL_DESC_ID=='+str(original_spw[dspw]))
                tb1 = mytb.query('FIELD_ID=='+ss+' and CAL_DESC_ID=='+str(tsysmap[obs_spw1[dspw]]))
                gain = numpy.real(tb1.getcol('GAIN'))
            else:
#                 tb1 = mytb.query('FIELD_ID=='+ss+' and SPECTRAL_WINDOW_ID=='+str(original_spw[dspw]))
                if debug:
                    print "dspw=%d, obs_spw1=%s, len(tsysmap)=%d" % (dspw,str(obs_spw1),len(tsysmap))
                gain = []
                if (len(tsysmap) > 0):
                    print "Querying %s for field='%s', dspw=%d, obs_spw1[dspw]=%d, spw='%s'" % (caltable, ss, dspw, obs_spw1[dspw], str(tsysmap[obs_spw1[dspw]]))
                    tb1 = mytb.query('FIELD_ID=='+ss+' and SPECTRAL_WINDOW_ID=='+str(tsysmap[obs_spw1[dspw]]))
                    gain = numpy.real(tb1.getcol('FPARAM'))
                if (len(gain) == 0):
                  if (useLocalTsysspwmap):
                      print "Re-running tsysspwmap with the field parameter set to ", ss
                      print "tsysspwmap(vis='%s', tsystable='%s.tsys', tsysChanTol=%d, field='%s')" % (ms1, ms1, tsysChanTol, ss)
                      tsysspwmap_original = tsysmap[:]
                      tsysmap = tsysspwmap(vis=ms1, tsystable=ms1+'.tsys', tsysChanTol=tsysChanTol, field=ss)
                      if (len(tsysmap) <= obs_spw1[dspw]):
#                          print "len(tsysmap)=%d, obs_spw1[dspw]=%d" % (len(tsysmap), obs_spw1[dspw])
                          # We need to change the tsysfield
                          print "Looking for a new tsys_field consistent with the tsysspwmap"
                          mymsmd.open(ms1)
                          tsys_fields = mymsmd.fieldsforintent('CALIBRATE_ATMOSPHERE*')
                          mymsmd.close()
                          # Go back to the original tsyspwmap
                          if (len(tsysspwmap_original) > 0):
                              tsysmap = tsysspwmap_original
                          for ss in tsys_fields:
                              print "Re-running tsysspwmap with the field parameter set to ", ss
                              print "tsysspwmap(vis='%s', tsystable='%s.tsys', tsysChanTol=%d, field='%d')" % (ms1, ms1, tsysChanTol, ss)
                              tsysmap = tsysspwmap(vis=ms1, tsystable=ms1+'.tsys', tsysChanTol=tsysChanTol, field=ss)
                              ss = str(ss)
                              if (obs_spw1[dspw] >= len(tsysmap)):
                                  print "tsysmap(field=%s) = " % (ss), tsysmap
                                  continue
                              tb1 = mytb.query('FIELD_ID=='+ss+' and SPECTRAL_WINDOW_ID=='+str(tsysmap[obs_spw1[dspw]]))
                              gain = numpy.real(tb1.getcol('FPARAM'))
                              tb1.close()
                              if (len(gain) > 0): 
                                  print "Picking new tsys_field = ", ss
                                  break
                          if (len(gain) < 1):
                              print "Could not find a field consistent with the Tsys spw mapping for spw %d" % (obs_spw1[dspw])
                              if (useLocalAlmaHelper):
                                  print "Try re-running with useLocalAlmaHelper=False."
                              return
                      tb1 = mytb.query('FIELD_ID=='+ss+' and SPECTRAL_WINDOW_ID=='+str(tsysmap[obs_spw1[dspw]]))
                      gain = numpy.real(tb1.getcol('FPARAM'))
                      tb1.close()
                  if (len(gain) == 0):
                    # The following section may not be necessary if the field parameter of tsysspwmap fixes all problems.
                    # It is still necessary for dataset uid___A002_X779b0a_X83.
                    print "There is a problem with tsysspwmap for this dataset (both with and without the field parameter)."
                    if (getCasaSubversionRevision() >= casaRevisionWithAlmaspws):
                        mymsmd.open(ms1)
                        print "Running workaround to find correct spw."
                        spwsForField = np.array(sorted(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),
                                                                      mymsmd.spwsforfield(int(ss)))))
                        availableTsysSpws = np.intersect1d(mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE*'), spwsForField)
                        if (len(availableTsysSpws) == 0):
                            print "I cannot find a Tsys spw to use.  File a ticket on tsysspwmap."
                            return
                        mindiff = 1e12
                        myBaseband = mymsmd.baseband(obs_spw1[dspw])
                        for availableSpw in availableTsysSpws:
                            if (mymsmd.baseband(availableSpw) == myBaseband):
                                diff = np.abs(mymsmd.meanfreq(availableSpw)-mymsmd.meanfreq(obs_spw1[dspw]))
                                if (diff < mindiff):
                                    mindiff = diff
                                    bestSpw = availableSpw
                        print "Best spw in same baseband (%d) = %d, with mean freq diff = %f GHz from spw %d" % (myBaseband, bestSpw, mindiff*1e-9,obs_spw1[dspw])
                        tb1 = mytb.query('FIELD_ID=='+ss+' and SPECTRAL_WINDOW_ID=='+str(bestSpw))
                        gain = numpy.real(tb1.getcol('FPARAM'))
                        tb1.close()
                        mymsmd.close()
                        if (len(gain) == 0):
                            print "I cannot find a Tsys spw to use.  File a ticket on tsysspwmap."
                            return
                    else:
                        print "This version of CASA is too old to run the workaround."
                        return
            xsum = sum(sum(gain[0]))
            ysum = sum(sum(gain[1]))
            if (xsum > 0 and ysum > 0):
                tsys_spw.append(numpy.median(gain))
            elif (xsum > 0):
                tsys_spw.append(numpy.median(gain[0]))
            else:
                tsys_spw.append(numpy.median(gain[1]))
#            print "spw %d: median tsys=%f" % (dspw, numpy.median(gain))

        mytb.close()

        #  Determine expected sensitivities for each spw for each channel

        chan_sensitivity = []
        spw_sensitivity = []
#        print "len(obs_spw1)=%d: %s" % (len(obs_spw1), obs_spw1)
#        print "len(tsys_spw)=%d: %s" % (len(tsys_spw), tsys_spw)
#        print "len(tsys_nominal)=%d: %s" % (len(tsys_nominal), tsys_nominal)
#        print "len(band_index)=%d: %s" % (len(band_index), band_index)
#        for dspw in obs_spw:    
        for dspw in range(len(obs_spw1)):   # See comment above regarding this change.
            rel_tsys = tsys_spw[dspw] / tsys_nominal[band_index[dspw]]
            s_temp = sensitivities[band_index[dspw]] * rel_tsys            #  scale by tsys
            s_temp = s_temp / numpy.sqrt(min_per_field)                    #  scale by inverse sqrt time
#            print "nant = %d" % nant
            s_temp = s_temp * 16.0 / nant                                  #  scale by antenna number
            if sevenMeterAntennasMajority(ms2):
                s_temp *= (12./7)**2                                       # scale by antenna collecting area
            s_temp = s_temp / numpy.sqrt(abs(chan_width[dspw]) / 8.0)           #  scale by chan bandwidth
            if d_pol != 'dual_pol': s_temp = s_temp * 1.414                #  not dual frequency?
            chan_sensitivity.append(s_temp)
            spw_sensitivity.append(s_temp / numpy.sqrt(num_chan[dspw]-dropchan))

        #  Results

        print '\n SENSITIVITY CALCULATION:\n     Number of spw             %2d\n     Polarization               %s \n     Number of Antennas        %3d \n     Source_Id             %6d \n     Field Integration Time   %7.2f min \n' % (n_spw, d_pol, nant, source_id, min_per_field)

        print '\n spw   mean freq      T_sys avg  chan width    channel rms     # chan    spw rms\n'

        mfs_rms = 0.0
#        for dspw in obs_spw:
        for dspw in range(len(obs_spw1)):
            mfs_rms = mfs_rms + 1.0 / spw_sensitivity[dspw]**2
#            print ' %2d   %7.3f GHz    %6.1f K   %+8.4f MHz   %7.2f mJy     %5d    %6.2f mJy' %  (dspw, mean_freq[dspw], tsys_spw[dspw],chan_width[dspw]*1.0E3, chan_sensitivity[dspw], num_chan[dspw], spw_sensitivity[dspw])
            print '%2d %2d %7.3f GHz    %6.1f K   %+8.4f MHz   %7.2f mJy     %5d    %7.3f mJy' %  (dspw, obs_spw1[dspw], mean_freq[dspw], tsys_spw[dspw],chan_width[dspw]*1.0E3, chan_sensitivity[dspw], num_chan[dspw]-dropchan, spw_sensitivity[dspw])

        mfs_sensitivity = numpy.sqrt(1.0/mfs_rms)
        print ' ALL     %70.3f mJy ' % (mfs_sensitivity)

        return {'min_per_field': min_per_field, 
                'mfs_sensitivity': mfs_sensitivity}

    def shadowed_ant(self, ms2='', qa2_output_dir=''):

        """
        shadowed_ant.py

        This is an experimental qa2 python script that determines the antenna
        and time range the were flagged because of shadowing.

        Must be run just after the shadowing flag command

        INPUTS NEEDED:

           ms2 = visibility data set (usual default)
           Assumes flag file of ms2+flagversions/flags.BeforeBandpassCalibration'

        OUTPUTS:

        The ascii output file is placed in

        qa2_output_dir+'shadowed_ant.txt'


        USEAGE:

        execfile (shadowed_ant.py)

        HISTORY

        29 Apr - wrapping issue patched

        """

        import pylab as pl

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        tb.open(ms2)
        time=tb.getcol('TIME')
        ant1 = tb.getcol('ANTENNA1')
        ant2 = tb.getcol('ANTENNA2')
        flag=tb.getcol('FLAG_ROW')
        tb.done()

        #  Get saved flagcolumn after shadowing only
        fg_ver = ms2+'.flagversions/flags.BeforeBandpassCalibration'
        tb.open(fg_ver)
        flag = tb.getcol('FLAG_ROW')
        tb.done()

        # DERIVE THE UNIQUE TIME STAMPS
        uniqt = np.unique(time)
        uniqt.sort()
        n_time = uniqt.shape[0]

        # DERIVE THE UNIQUE ANTENNAS
        uniqa = np.unique(np.append(ant1,ant2))
        n_ant = uniqa.shape[0]
        max_ant = np.max(uniqa)  # 9/10/2012

        #   Open file for writing
        zfileRes = qa2_output_dir+'shadowed_ant.txt'
        if os.path.exists: os.system('rm -f '+zfileRes)

        f = open (zfileRes, 'w')
        print 'opening file '+zfileRes
        #
        f.write( '\n\n')
        f.write( '* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n')
        f.write( '\n')
        f.write( '              SHADOWING OF ANTENNAS\n')

        # -------------------------------------------------------------------
        # PROBLEM 1 ... EXTRACT "ANTENNA" FLAGS
        # -------------------------------------------------------------------

        # ... so this is easy if we have an array that is n_time x n_ant x
        # n_ant in shape. We just collapse along the second axis and look for
        # where the number of flags at a timestep equals (n_ant-1). That is,
        # just look for the unique time stamps where baselines with all other
        # antennas are flagged. The problem is that constructing this array is
        # painful because (at least as I set it up here) you have to
        # constantly requery the array. Still, for a small dataset this is
        # pretty fast in numpy. Here goes.

        # (1) Build a flags-by-baseline 3-d array (time, ant1, ant2)

        flag_base = np.zeros([n_time, max_ant+1, max_ant+1],dtype=np.bool)    # 9/10/2012

        if (len(flag) != len(time)):
            print "WARNING: There is a mismatch between the number of rows in %s (%d) and %s (%d)." % (ms2,len(time), fg_ver, len(flag))
            print "You may need to 'rm -rf %s*' and re-run your script starting from the split step." % (ms2)
        for i in np.arange(n_time):
            # ... find rows with this timestamp and a flag
#            print "shape(time) = ", np.shape(time)
#            print "shape(uniqt) = ", np.shape(uniqt)
#            print "flag = ", np.shape(flag)
            ind = ((time == uniqt[i])*(flag == 1)).nonzero()

            # ... continue if no flags
            if ind[0].shape[0] == 0: continue
            # ... note each flagged row in our new array
            for row in ind[0]:
                flag_base[i,ant1[row],ant2[row]] = True
                flag_base[i,ant2[row],ant1[row]] = True

        # (2) Collapse this to a flags-by-antenna array. Sum along one of the
        # antenna axes and then not where all baselines show a flag.

        flag_ant =  np.sum(flag_base, axis=2) >= (n_ant-1)

        # we now have antenna flags in this data set!

        # To look at this visually do this:
        # pl.imshow(np.transpose(flag_ant), aspect='auto')
        # ... this is time on x and antenna on y

        # -------------------------------------------------------------------
        # PROBLEM 2 ... EXTRACT TIME RANGES
        # -------------------------------------------------------------------

        # This is also pretty easy in principle once we have the previous
        # array. We have the unique time stamps and for each antenna. We
        # consider each antenna in turn and step through our array of True
        # (flagged) and False (unflagged) vs time. When flags flip from True
        # to False (or vice verse) in contiguous elements we want to include
        # that in our output.

        didshadow = 0
        for ant in uniqa:
            # this is flagged (True/False) vs. time
#            print "np.shape(flag_ant) = ", np.shape(flag_ant)
#            print "len(flag_ant[0]) = ", len(flag_ant[0])
#            print "ant = ", ant

            # Todd added the following line to prevent a crash on
            # uid___A002_X436934_X48c.ms
            if (ant >= len(flag_ant[0])): break

            flag_v_time = flag_ant[:,ant]

            if np.sum(flag_v_time) == 0:
        #        print "No flags for antenna "+str(ant)
                continue

            # Note where flags start
            flag_started = (flag_v_time == False)* \
                (np.roll(flag_v_time, shift=-1,axis=0) == True)

            # Take care of first time stamp
            if flag_v_time[0] == True:
                flag_started[0] = True

            # Take care of last time stamp (the roll wraps)
            if flag_v_time[0] == True and flag_v_time[-1] == False:
                flag_started[-1] = False

            # Note where flags stop
            flag_stopped = (flag_v_time == True)* \
                (np.roll(flag_v_time, shift=-1,axis=0) == False)

            # Take care of last time stamp
            if flag_v_time[-1] == True:
                flag_stopped[-1] = True

            if np.sum(flag_started) != np.sum(flag_stopped):
                print "Something weird is happening."
                print np.sum(flag_started), np.sum(flag_stopped)

            # Use our "starts" and "stops" to report time ranges
            start_ind = (flag_started).nonzero()
            start_times = uniqt[start_ind]
            for start_time in start_times:
                stop_ind = (flag_stopped*(uniqt >= start_time)).nonzero()
                stop_time = np.min(uniqt[stop_ind[0]])
                mjd_start = start_time / 3600. / 24.
                mjd_stop = stop_time / 3600. / 24.
                q_start = qa.quantity(mjd_start, unitname='d')
                q_stop = qa.quantity(mjd_stop, unitname='d')
                didshadow = 1
                f.write("     antenna: "+str(ant)+" shadowed "+call_qa_time(q_start)+" to "+call_qa_time(q_stop))
                f.write('\n')

        if didshadow == 0:
            f.write('\n           No shadowed antennas\n')

        f.close()
        #os.system('cat '+zfileRes)

    def target_check(self, ms1='', ms2='', target='', target_source='', 
                     tsys_caltable='',
                     tsys_field='', qa2_output_dir='', fdmSpwsToImage='',
                     flaggedFraction=0.5, flagStats=None, 
                     useLocalAlmaHelper=True, reverseUvplotXaxis=True):
        """
        One target is chosen.  A full bandwidth image is made
        and the peak and rms of the image is determined.  Assuming ALMA
        parameters and valid tsys observations, the expected sensitivity is
        determined and compared with the image sensitivity.  The psf and
        the uv-coverage are also made.

        INPUTS NEEDED:
           ms2 is the assumed data set
           target = 'xx'  is the field number of the target to image
           target_source = 'xx' is the field number for sensitivity calculation
           tsys_field = 'yy' is the field number with the relevant tsys
                if tsys_field = '', tsys_field is set to target.
           fdmSpwsToImage: a comma-delimited string of FDM spw IDs
                default = '' which means to include all of them
                Set it to [] to ignore all of them (i.e. only use the TDM spws)
           
        OUTPUTS:
        The calibrated and model amplitudes for the selected field
        number is placed in

            qa2_output_dir+'sensitivity.txt'    contains information about the image
            qa2_output_dir+'target.image.png' is a display of the target image (done by hand)
            qa2_output_dir+'target.psf.png'   is a display of the target psf (done by hand)
            qa2_output_dir+'target.uvcov.png'  is a display of the target uv coverage

        USEAGE: assumes ms2 as the visibility data set.

        target = '4'
        execfile ('target_check.py')
        """
        import numpy
        from clean import clean
        from imstat import imstat
        from imhead import imhead

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        #  Image on target and check on sensitivity
        #
        # Initializations
        if (target == ''):
            print "You must specify target field ID."
            return
        if (len(ms2) < 1):
            print "You must specify ms2"
            return
        if not os.path.exists(ms2):
            print "Could not find ms2"
            return
        vm = ValueMapping(ms2)
        spw_info=vm.spwInfo
        original_keys = spw_info.keys()
        if (getCasaSubversionRevision() >= casaRevisionWithAlmaspws):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms2)
            obs_spw = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('OBSERVE_TARGET*'))
            # filters spw_info to contain only OBSERVE_TARGET spws
            spw_info = filterDictionary(spw_info, obs_spw)
            mymsmd.close()

        #  Get a frequency
        if (0 not in spw_info.keys() and original_keys == spw_info.keys()):
            print "Are you sure that ms2 was set to the name of the split ms?"
            return(None)
        freq = spw_info[spw_info.keys()[0]]['meanFreq'] / 1.0E9

        image_sizes = [128,216,256,360,432,640,800,1000,1296,1600,2048]

        tb.open(ms2+'/ANTENNA')
        antenna = tb.getcol('NAME')
        tb.close()
        nant = len(numpy.unique(antenna))

        #  Get band

        zfileRes = qa2_output_dir+'sensitivity.txt'
        os.system('rm -f '+zfileRes)
        f = open (zfileRes, 'w')
        print 'opening file '+zfileRes

        #  Get image parameters

        print 'getting imaging parameters'

        #  Find longest baseline

        baselines = getBaselineLengths(ms2, unflagged=True, flaggedFraction=flaggedFraction, flagStats=flagStats)
        if (len(baselines) < 1):
            baselines = getBaselineLengths(ms2)
            
        ll = baselines[len(baselines)-1]
        baseline_max = ll[1]
        print 'longest (unflagged) baseline is ',ll[0] ,'with length ', baseline_max
        b = 15000.0 / baseline_max / freq
        print 'theoretical pixel separation ', b

        #  Round to nearest unit
        if b > 0.20:
            b = numpy.int(b*20)/20.0
        elif b > 0.10:
            b = numpy.int(b*100.0)/100.0
        elif b > 0.02:
            b = numpy.int(b*200.0)/200.0
        elif b > 0.01:
            b = numpy.int(b*1000.0)/1000.0
        else:
            b = numpy.int(b*2000.0)/2000.0

        zcell = str(b)+'arcsec'
        print "Choosing cellsize = ", zcell

        #  Field of view (for 12m antenna)
        pbsize = 6000.0 / (spw_info[spw_info.keys()[0]]['chanFreqs'][0]*1.0E-9)
        if sevenMeterAntennasMajority(ms2):
            pbsize *= 12/7.

        #  Find best image size that is >1.5*pbsize/cellsize.
        #  Note: 1.5*pbsize corresponds to the 20% level for a Gaussian beam
        possible_size = 1.5*pbsize/b

        for zimsize in image_sizes:
            if zimsize > possible_size: break

        f.write('\n\n')
        f.write('************************************************************* \n')
        f.write('\n')
        f.write('        CHECK OF A TARGET IMAGE AND SENSITIVITY\n\n')
        f.write('    longest baseline       = %7.1f (meters)\n'% (baseline_max))
        f.write('    recommended cellsize   = %7.4f (arcsec)\n'% (b))
        f.write('    primary beam FWHM      = %6.2f (arcsec)\n'% (pbsize))
        f.write('    recommended image size = %5d\n\n'  % (zimsize))
        print "Running es.sensitivity_calculator(ms1='%s', ms2='%s', caltable='%s', s_id='%s', tsys_field='%s', qa2_output_dir='%s', useLocalAlmaHelper=%s)" % (ms1,ms2,tsys_caltable,target_source,tsys_field,qa2_output_dir,useLocalAlmaHelper)
        tmp1 = self.sensitivity_calculator(ms1=ms1, ms2=ms2, caltable=tsys_caltable, s_id=target_source, tsys_field=tsys_field, qa2_output_dir=qa2_output_dir,useLocalAlmaHelper=useLocalAlmaHelper)
        if tmp1 == None:
            print "Stopping because sensitivity_calculator returned: None"
            return(None)

        #  Make the image of selected target
        newWidths = []
        doSplit = False
        newFdmSpwsToImage = []
        # Make sure the spws are a list of strings
        if (type(fdmSpwsToImage) == str):
            fdmSpwsToImage = fdmSpwsToImage.split(',')
        else:
            fdmSpwsToImage = [str(i) for i in fdmSpwsToImage]
        spwsToImage = []
        for s in spw_info.keys():
            if (spw_info[s]['numChannels'] > 256):
                if (str(s) in fdmSpwsToImage or len(fdmSpwsToImage) == 0 or fdmSpwsToImage==['']):
                    newWidths.append(int(spw_info[s]['numChannels']/32))
                    spwsToImage.append(s)
                    doSplit = True
                    if (len(fdmSpwsToImage) == 0 or fdmSpwsToImage==['']):
                        newFdmSpwsToImage.append(str(s))
                else:
                    print "not in fdmSpwsToImage=%s and len=%d" % (str(fdmSpwsToImage),len(fdmSpwsToImage))
            else:
                newWidths.append(spw_info[s]['numChannels'])
                spwsToImage.append(s)
        if (len(newFdmSpwsToImage) > 0):
            if ((64 not in newWidths) and (128 not in newWidths) and (256 not in newWidths)):
                fdmSpwsToImage = newFdmSpwsToImage[0] 
                print "Since no TDM spws are present, and no FDM spws were specified, I am choosing the first FDM spw: %s." % (fdmSpwsToImage)
                newWidths = newWidths[0]
            else:  # a mix of TDM and FDM windows, so split them all out
                fdmSpwsToImage = ','.join([str(i) for i in spwsToImage])
        else:
            fdmSpwsToImage = ','.join([str(i) for i in fdmSpwsToImage])

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
        if (doSplit):
            ms3 = ms2+'.chanavg' 
            os.system('rm -rf '+ms3)
            print 'Due to the presence of 1 or more FDM windows, splitting target field with channel averaging: ', newWidths
            print "Running split(vis='%s', outputvis='%s', width=%s, field='%s', datacolumn='corrected', spw='%s')" % (ms2, ms3, newWidths, target, fdmSpwsToImage)
            split(vis=ms2, outputvis=ms3, width=newWidths, field=target, datacolumn='corrected', spw=fdmSpwsToImage)
            cleanvis = ms3
            cleanfield = '0'  # original method (fails if target='name' and first field is AtmCal only)
            if (type(target) == str):
                if (not target.split(',')[0].isdigit()):
                    # Target has been specified by name, so get all matching
                    # fields (including the case of a mosaic).
                    mymsmd.open(cleanvis)
                    cleanfield = ','.join([str(i) for i in mymsmd.fieldsforname(target)])
                    mymsmd.close()
                elif (len(target.split(',')) > 1):
                    # e.g. convert '4,5,6,9' to '0,1,2,3'
                    cleanfield = ','.join([str(i) for i in range(len(target.split(',')))])
            firstfield = target.split(',')[0].split('~')[0]  # pick first field if a list or range is given
        else:
            print 'This is a TDM dataset (or only TDM spws were selected), so no need to average channels prior to imaging.'
            cleanvis = ms2
            firstfield = target.split(',')[0].split('~')[0]  # pick first field if a list or range is given
            cleanfield = firstfield

        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd.open(cleanvis)
            cleanfieldname = mymsmd.namesforfields(int(cleanfield.split(',')[0]))[0]
            mymsmd.close()
        else:
            cleanfieldname = ''
        print 'making mfs image of selected target'
        os.system('rm -rf '+qa2_output_dir+'target_check*')
        print version(True)+" Running clean(vis='%s', field='%s', imagename='%starget_check', imsize=%d, cell='%s', threshold='%fmJy', interactive=False, niter=100)" % (cleanvis, cleanfield, qa2_output_dir, zimsize, zcell, 3.0*tmp1['mfs_sensitivity'])
        try:
            clean(vis=cleanvis,
              field = cleanfield,
              imagename = qa2_output_dir+'target_check',
              imsize = zimsize, cell = zcell,
              threshold = '%fmJy'%(3.0*tmp1['mfs_sensitivity']), # Added 9/7/2012
              interactive = False, niter=100)
        except:
            print "Clean failed.  There may be too much data flagged, or only a few antennas at long baselines."
            print "For example, you may have specified the target parameter to be a field that has only Tsys data."
            return None  # None will trigger an abort of generateQA2Report

        #  Get rms and peak box information

        zbox1 = str(int(0.1*zimsize)); zbox2 = str(int(0.9*zimsize))

        a=imstat(imagename=qa2_output_dir+'target_check.image',
               box = zbox1+','+zbox1+','+zbox2+','+zbox2)

        amax = a['max'][0]

        zbox1 = str(int(0.1*zimsize)); zbox2 = str(int(0.3*zimsize))

        a=imstat(imagename=qa2_output_dir+'target_check.image',
               box = zbox1+','+zbox1+','+zbox2+','+zbox2)
        arms = a['rms'][0]

        clev = float(arms*2.5)

        #  Make plot of object and store

        imview(raster = {'file':qa2_output_dir+'target_check.image'},
               contour = {'file':qa2_output_dir+'target_check.image',
                          'levels':[-1,1,2,4,6,8,10,12,16,20,30,50],
                          'unit':clev},
               zoom = 1,
               out = qa2_output_dir+'target_image.png')

        imview(raster = {'file':qa2_output_dir+'target_check.psf'},
               contour = {'file':qa2_output_dir+'target_check.psf',
                          'levels':[-3,-2,-1,1,2,3,5,7,9,9.5],
                          'unit':0.1},
               zoom = 1,
               out = qa2_output_dir+'target_psf.png')
        if (plotxyAvailable and False):
            print "Running plotxy(vis='%s',xaxis='u',yaxis='v',spw='%d:100~100',field='%s',clearpanel='All',interactive=False,figfile='%s')" % (ms2,spw_info.keys()[0],target,qa2_output_dir+'target_uv.png')
            plotxy(vis = ms2,
                   xaxis = 'u', yaxis = 'v',
                   spw = '%d:100~100' % (spw_info.keys()[0]),
                   field = target, clearpanel='All',
                   interactive = False,
                   figfile = qa2_output_dir+'target_uv.png')
        else:
            mymsmd = createCasaTool(msmdtool)
            if (doSplit):
                uvspw = fdmSpwsToImage.split(',')[0]
            else:
                mymsmd.open(ms2)
                uvspw = mymsmd.spwsforfield(int(target))[0]
                print "Selected spw=%d for plotuv" % (uvspw)
                mymsmd.close()

            plotuvTarget = target
            if (type(target) == str):
                mymsmd.open(ms2)
                if (not target.split(',')[0].isdigit()):
                    # Target has been specified by name, so get all matching
                    # fields (including the case of a mosaic).  Then drop
                    # any Tsys-only fields, then take the first one.
                    fieldsforname = ','.join([str(i) for i in mymsmd.fieldsforname(target)])
                    plotuvTarget = np.intersect1d(fieldsforname,[str(i) for i in mymsmd.fieldsforintent('OBSERVE_TARGET*')])[0]
                elif (len(target.split(',')) > 1):
                    plotuvTarget = np.intersect1d(target,[str(i) for i in mymsmd.fieldsforintent('OBSERVE_TARGET*')])[0]
                mymsmd.close()


            print "Running plotuv(vis='%s', maxnpts=1000000, spw='%s', field='%s', figfile='%starget_uv.png')" % (ms2,uvspw,plotuvTarget,qa2_output_dir)
            plotuv(vis = ms2, maxnpts=5000000, spw=uvspw, field=plotuvTarget,
                   figfile = qa2_output_dir+'target_uv.png')
            fn2 = qa2_output_dir+'target_uv.png'
            if reverseUvplotXaxis:
                a,b = plt.xlim()
                if (a < b):
                    plt.xlim([b,a])
                    plt.savefig(fn2)
            else:
                fn1 = qa2_output_dir+'target_uv_fld%s.png' % (plotuvTarget)
                print "Running os.rename('%s', '%s')" % (fn1,fn2)
                os.rename(fn1, fn2)


        #  Get image parameters

        a = imhead(imagename = qa2_output_dir+'target_check.image',
                   mode = 'list')
        freq = a['crval4']*1.0E-9
        bwidth = a['cdelt4']*1.0E-9
        bmaj = a['beammajor']
        bmin = a['beamminor']
        bpa = a['beampa']
        if (type(bmaj) == dict):
            # casa >= 4.1.0  (previously these were floats)
            bmaj = bmaj['value']
            bmin = bmin['value']
            bpa = bpa['value']

        f.write('    target                 = %2s \n' % (target))
        f.write('    resolution             = %6.3f x %6.3f in pa %6.1f\n' % (bmaj, bmin, bpa))
        f.write('    time on target         = %6.2f (min)\n'  % (tmp1['min_per_field']))
        f.write('    peak on image          = %7.3f (mJy)\n'  % (amax*1000.0))
        f.write('    rms on image           = %7.3f (mJy)\n'  % (arms*1000.0))
        f.write('    expected sensitivity   = %7.3f (mJy) (aggregate bandwidth)\n'  % (tmp1['mfs_sensitivity']))
        f.close()
        os.system('cat '+zfileRes)
        return(firstfield, cleanfieldname)

    def target_spectrum(self, ms2='', target='', dospw='', qa2_output_dir='',
                        uvrange='0~30m', avgchannel=5, correlation=''):
        """
        target_spectrum.py

        One target is chosen.  The spectrum for the short spacings
        is made for all spw's.

        INPUTS NEEDED:
           ms2 is the assumed data set
           target = 'xx'  is the field number of the target
           dospw = '0'    put in spw's and channel range needed

        OUTPUTS:
        The source spectrum is placed in

            qa2_output_dir+'target_spectrum.png' 

        USEAGE: assumes ms2 as the visibility data set.
        target = '7'
        dospw = '0'
        execfile ('target_spectrum.py')
        """
        pols = self.findNumberOfPolarizations(ms2)
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)

        (longestLength,shortestLength,longestBaseline,shortestBaseline) = getBaselineExtrema(ms2)
        if (uvrange.find('~') >= 0):
            uvrangeMax = float(uvrange.split('~')[1].split('m')[0])
            if (shortestLength > uvrangeMax):
                baselineStats = getBaselineStats(ms2)
                print "WARNING: No data found for uvrange=%s, increasing max baseline to %.0fm (20th percentile)" % (uvrange, baselineStats[6])
                uvrange = uvrange.split('~')[0] + '~%.0fm' % (baselineStats[6])
                print "new uvrange = ", uvrange
        sep_spw = dospw.split(',')
        n_spw = len(sep_spw)
        subplot = 100*n_spw + 10
        if (getCasaVersion() >= '4.2.0' and getCasaSubversionRevision() > '27480'):
            plotmsparm="showgui=False,"
        else:
            plotmsparm=""
        if (pols < 2 or getCasaVersion() >= '4.0.0'):
            # plotxy fails in this case, so make separate plotms plots and montage them together.
            # It also cannot overplot a model created with usescratch=False, so we will
            # likely use this work-around in all cases when we switch to casa 4.0.0. - T. Hunter
            plotfiles = ''
            for spw in sep_spw:
                myplotfile = '%starget_spectrum_spw%s.png' % (qa2_output_dir,spw)
                plotfiles += myplotfile + ' '
                cmd="plotms("+plotmsparm+"vis='%s', xaxis='freq', yaxis='amp', ydatacolumn='corrected', field='%s', averagedata=True, avgtime = '100000', avgscan=True, avgbaseline=True, coloraxis='corr', avgchannel='%d', uvrange='%s', spw='%s', plotfile='%s', overwrite=True, title='spw %s (%s)', correlation='%s')" % (ms2,target,avgchannel,uvrange,spw,myplotfile,spw,uvrange,correlation)
                print "es.target_spectrum() is Running "+cmd
                exec cmd
                #print "es.target_spectrum() is Running plotms(vis='%s', xaxis='freq', yaxis='amp', ydatacolumn='corrected', field='%s', averagedata=True, avgtime = '100000', avgscan=True, avgbaseline=True, coloraxis='corr', avgchannel='%d', uvrange='%s', spw='%s', plotfile='%s', overwrite=True, title='spw %s (%s)', correlation='%s')" % (ms2,target,avgchannel,uvrange,spw,myplotfile,spw,uvrange,correlation)
                #plotms(showgui=False,vis=ms2, xaxis='freq', yaxis='amp', ydatacolumn='corrected', field=target,
                #       averagedata=True, avgtime = '100000', avgscan=True, avgbaseline=True, coloraxis='corr',
                #       avgchannel=str(avgchannel), uvrange=uvrange, spw=spw, plotfile=myplotfile,
                #       overwrite=True,title='spw '+spw+' (%s)'%uvrange, correlation=correlation)
                if getCasaVersion() < '4.2.0': waitForPlotms()
            # Here we define a grid to allow an arbitrary number of spws
            rows = int(round(np.sqrt(n_spw)))
            cols = int(ceil(1.0*n_spw/rows))
            cmd = "montage -tile %dX%d -geometry 1000x1000+0+0  %s %starget_spectrum.png"%(rows,cols,plotfiles,qa2_output_dir)
            print "Running %s" % (cmd)
            os.system(cmd)
            os.system('rm -f %s' % plotfiles)
        else:
          for spw in sep_spw:
            subplot = subplot + 1
            print "Running plotxy(vis='%s', xaxis='freq', yaxis='amp', datacolumn='corrected', field='%s', plotsymbol='o', averagemode='vector', timebin='100000', crossscans=True, crossbls=True, width='5', uvrange='%s', spw='%s', subplot=%d, figfile='%s', interactive=False)" % (ms2,target,uvrange,spw,subplot,qa2_output_dir+'target_spectrum.png')
            os.system('rm -rf plotxy.log')
            mylogfile = casalog.logfile()
            casalog.setlogfile('plotxy.log')
            plotxy(vis = ms2,
                   xaxis = 'freq', yaxis = 'amp', datacolumn = 'corrected',
                   field = target, plotsymbol = 'o',
                   averagemode = 'vector', timebin = '100000',
                   crossscans = True, crossbls = True, width = '5',
                   uvrange = uvrange,
                   spw = spw, subplot = subplot,
                   figfile = qa2_output_dir+'target_spectrum.png', interactive = False)
            casalog.setlogfile(mylogfile)
            logtext = open('plotxy.log','r')
            if 'SEVERE' in logtext.read():
                print "WARNING: Blank plot!"
                print "Did you flag the short spacings for spw %s on field %s?  If so, then you could try increasing the uvrange." % (spw,target)
            logtext.close()
            os.system('rm -rf plotxy.log')
    
    def tsysAverage(self, caltable, qa2_output_dir='', showFlaggedSolutions=False,
                    startant=0, stopant=-1, plotfile=''):
        """
        tsysAverage.py
        This program plots the average Tsys per spw.

        INPUTS NEEDED:
           None.  caltable

        OUTPUTS:
        A png plot
        """

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)

        if not os.path.exists(caltable):
            print "Could not find caltable = ", caltable
        mytb = createCasaTool(tbtool)
        mytb.open(caltable)
        pb.clf()
        desc = pb.subplot(111)
        names = mytb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
            spw = mytb.getcol('SPECTRAL_WINDOW_ID')
        else:
            calFormat = 33  # <= casa 3.3
            spw = mytb.getcol('CAL_DESC_ID')
        spw_un = np.unique(spw)
        if (len(spw_un) <= 4):
            nsub1 = len(spw_un)
            nsub2 = 1
            hspace = 0.40
            wspace = 0.0
        else:
            n_spw = len(spw_un)
            nsub1 = int(round(np.sqrt(n_spw)))
            nsub2 = int(ceil(1.0*n_spw/nsub1))
            hspace = 0.40
            wspace = 0.30
        nsub3 = 0
        nchanPerSpw = {}
        for ispw in spw_un:
            nsub3 = nsub3 + 1
            if (calFormat == 33):
                tb1 = mytb.query('CAL_DESC_ID=='+str(ispw))
                g = tb1.getcol('GAIN')
            else:
                tb1 = mytb.query('SPECTRAL_WINDOW_ID=='+str(ispw))
                g = tb1.getcol('FPARAM')
            flags = tb1.getcol('FLAG')
            ant = tb1.getcol('ANTENNA1')
            gbp = g
            gch = []
            n0 = gbp.shape[0]
            n1 = gbp.shape[1]
            n2 = gbp.shape[2]
            if (stopant < 0):
                stopant = n2
            elif (stopant > n2):
                print "Stopping at final antenna %d (stopant=%d)" % (n2-1,n2)
                stopant = n2
            nAntennas = stopant-startant
            chan = range(0,n1)
            nchanPerSpw[ispw] = n1
            for ich in range(0,n1):
                gsum = 0.0
                for pol in range(0,n0):
                    for iant in range(startant,stopant):
                        gsum = gsum + gbp[pol][ich][iant]
                gch.append(gsum/n0/nAntennas)
            adesc = pb.subplot(nsub1, nsub2, nsub3)
            pb.subplots_adjust(hspace=hspace, wspace=wspace)
            if (showFlaggedSolutions):
                pb.plot(chan,gch,'k.-')
            else:
                unflaggedChans = np.unique(np.where(flags==False)[1])
                pb.plot(np.array(chan)[unflaggedChans],np.array(gch)[unflaggedChans],'k.-')
                pb.xlim([np.min(chan), np.max(chan)])
            if (getCasaVersion() < casaVersionWithMSMD):
                myTitle = 'Average Tsys spw '+str(ispw)
            else:
                meanfreq = getSpwMeanFreqFromCaltable(caltable,ispw)
                myTitle = 'Average Tsys spw%02d (%.1fGHz) in %s' % (ispw, meanfreq, os.path.basename(caltable))
            pb.title(myTitle, fontsize=12-nsub2)
            pb.setp(adesc.get_xticklabels(), fontsize=10-nsub1)
            pb.setp(adesc.get_yticklabels(), fontsize=10-nsub1)
            pb.ylabel('Kelvin')
            yFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
        tb1.close()
        mytb.close()
        pb.xlabel('Channel')
        if (plotfile == ''):
            plotfile = 'tsysAverage.png'
        png = qa2_output_dir+plotfile
        pb.text(0.62,-0.07,'ObsDate=%s'%mjdsecToUT(getMJDSecFromCaltable(caltable)),transform=desc.transAxes,size=10)
        pb.savefig(png)
        print "Left plot in ", png

    def tsys_stat(self, ms1='', tsys_field='', makeplot=True, qa2_output_dir='', use_plotbandpass=True,
                  dontPlotFlaggedAntennas=True, ms2='', flaggedFraction=0.991, debug=False):

        """
        tsys_stat.py

        This is an experimental python script that determines the statistics,
        the average and outliers for the tsys.  Plots are made of the TDM
        tsys determination.

        INPUTS NEEDED:
        ms1: visibility data set.  The Tsys caltable is assumed to be: ms1+'.tsys'
        tsys_field: choose a specific field (normally left blank --> all)
        dontPlotFlaggedAntennas: if True, and ms1+'.split' exists, then only plot
              the Tsys for antennas present in the .ms.split measurement set
        ms2: the split data set (only considered if dontPlotFlaggedAntennas=True)
        flaggedFraction: threshold to consider antenna completely flagged
              0.991 was selected as default because 1-(128-8-8)/(3840*3+128)=0.9904
        debug: passed to listconditions
                 
        OUTPUTS:
        The ascii output file lists the scans for each tsys observation, and
        any outliers for each antenna/spw.

        <qa2_output_dir>+'tsys_stat.txt'
        <qa2_output_dir>+'tsys_plot.png'

        USEAGE: assumes ms1 as the visibility data set and the TDM tsys
                is in ms1+'.tsys'.

        makeplot = True
        execfile ('qa2_scripts/tsys_stat.py')

        """

        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)

        #  Determines rms and average value of Tsys (TDM)

        #  Get antenna parameters

        tb.open(ms1+'/ANTENNA')
        ant_names=tb.getcol('NAME')
        ant_pos=tb.getcol('POSITION')
        nant = len(ant_names)
        tb.close()

        #  Get amplitude and other information

        caltable = ms1+'.tsys'               #  Put in caltable name

        tb.open(caltable)
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3

        time=tb.getcol('TIME')
        time = time-time[0]+5.0
        antenna1 = tb.getcol('ANTENNA1')
        if (calFormat == 33):
            gain = tb.getcol('GAIN')  # This assumes the same number of channels in all spws!
            spw = tb.getcol('CAL_DESC_ID')
            gain_amp = np.abs(gain)
            nchan = np.ones(len(gain))*gain.shape[1]
        else:
#            gain = tb.getcol('FPARAM')  # This assumes the same number of channels in all spws!
            spw = tb.getcol('SPECTRAL_WINDOW_ID')
            gain = {}
            gain_amp = {}
            nchan = {}
            for myrow in range(tb.nrows()):
                gain[myrow] = tb.getcell('FPARAM', myrow)
                gain_amp[myrow] = np.abs(gain[myrow])
                nchan[myrow] = gain[myrow].shape[1]
        spw_un = np.unique(spw)
        fldid = tb.getcol('FIELD_ID')
        scanno = tb.getcol('SCAN_NUMBER')
        nspw = len(spw_un)
        tb.close()
        nstream = len(antenna1)
        ntimes = 0
        dotime = 1
        fld_un = np.unique(fldid)

        zfileRes = qa2_output_dir+'tsys_stat.txt'
        if os.path.exists (zfileRes): os.system('rm -f '+zfileRes)

        f = open (zfileRes, 'w')
        print 'opening file '+zfileRes

        #  Get average tsys per each scan/elevation

        vm = ValueMapping(ms1)
        scans = unique(scanno)
        nscans = len(scans)
        #   Loop over each scan
        TX_save = []
        TY_save = []
        elev_save = []
        conditions = listconditions(vis=ms1,byscan=True,scan='',antenna='0',
                                    verbose=False,vm=vm,debug=debug)
        for isc in range(nscans):
            tsys_x = []
            tsys_y = []
            for ist in range(nstream):
                if scans[isc] == scanno[ist]:
                    ncrange = range(int(0.2*nchan[ist]), int(0.8*nchan[ist]))
#                    print "nchan[%d] = %d, ncrange = " % (ist, nchan[ist]), ncrange
                    for nc in ncrange:
#                        tsys_x.append(gain_amp[0,nc,ist])
#                        tsys_y.append(gain_amp[1,nc,ist])
                        tsys_x.append(gain_amp[ist][0,nc])
                        tsys_y.append(gain_amp[ist][1,nc])
            T_x = np.median(tsys_x)
            T_y = np.median(tsys_y)
            TX_save.append(T_x)
            TY_save.append(T_y)
            if (scans[isc] > 0):
                elev_save.append(conditions[scans[isc]]['elevation'])
            else:
                # protect against bad SysCal table, e.g. uid___A002_X835491_X4bb (SCOPS-679)
                elev_save.append(0)
                print "Scan number=0 encountered in Tsys caltable.  Please report this problem on SCOPS-679."
        #    sfield = vm.getFieldsForScan(scans[isc])

        nscans = len(elev_save)
        scan_tsys=[]
        f.write('\n\n')
        f.write('*********************************************************** \n')
        f.write('\n')
        f.write('              MEDIAN TSYS WITH SOURCE/ELEVATION \n')
        f.write('                  (see plots for details) \n')
        f.write('Scan   Fid                Source      Elev    Median T_x  Median T_y \n')
        TXs = []
        TYs = []
        for isc in range(nscans):
            # protect against bad SysCal table, e.g. uid___A002_X835491_X4bb (SCOPS-679)
            if (scans[isc] > 0):
                sfield = vm.getFieldsForScan(scans[isc])
                fid = vm.getFieldIdsForFieldName(sfield)
            else:
                sfield = ['unknown']
                fid = [-1]
            f.write('%4d  %4d %24s %6.1f   %7d     %7d\n'% (scans[isc], fid[0], sfield[0], elev_save[isc], TX_save[isc], TY_save[isc]))
        #    print '%4d  %4d %24s %6.1f   %7d     %7d \n'% (scans[isc], sfield[0], elev_save[isc], TX_save[isc], TY_save[isc])
            scan_tsys.append(sfield[0])
            TXs.append(TX_save[isc])
            TYs.append(TY_save[isc])

        #  Find outlier Tsys's

        #  Set up averages

        max_spw = []
        for ispw in range(len(spw_un)):
            varx = []
            avgx = []
            vary = []
            avgy = []
            for iant in range(0,nant):
                ggx = []
                ggy = []
                for id in range(0,nstream):
#                    print "%d vs. %d,  %d vs. %d" % (antenna1[id],iant,spw[id],ispw)
                    if ((antenna1[id] == iant) and (spw[id] == spw_un[ispw])):
                        ncrange = range(int(0.2*nchan[id]), int(0.8*nchan[id]))
                        for ic in ncrange:
#                            ggx.append(gain_amp[0][ic][id])
#                            ggy.append(gain_amp[1][ic][id])
                            ggx.append(gain_amp[id][0][ic])
                            ggy.append(gain_amp[id][1][ic])

                varx.append(np.var(ggx))
                avgx.append(np.average(ggx))
                vary.append(np.var(ggy))
                avgy.append(np.average(ggy))

            medavgx = np.median(avgx)
            medavgy = np.median(avgy)
            medvarx = 0.0
            medvary = 0.0
            nx = 0
            ny = 0
            for iant in range(0,nant):
                difx = np.abs(avgx[iant]-medavgx)
                dify = np.abs(avgy[iant]-medavgy)
                if (difx < 5.0*medavgx):
                    medvarx = medvarx + np.abs(avgx[iant]-medavgx)
                    nx = nx + 1

                if (dify < 5.0*medavgy):
                    medvary = medvary + np.abs(avgy[iant]-medavgy)
                    ny = ny + 1


            medvarx = medvarx / np.sqrt(float(nx))
            medvary = medvary / np.sqrt(float(ny))
            max_spw.append(0.5*(medavgx+medavgy)+2.5*(medvarx+medvary))
            if ispw == 0:
                f.write('\n\n\n')
                f.write('            MEDIAN TSYS versus ANTENNA/SPW and OUTLIERS \n\n')
                f.write('              TSYS MEDIAN                >3-sigma OUTLIERS \n')
                f.write('       XPOL              YPOL                OUTLIERS \n')
                f.write(' SPW    T   rms        T   rms      antenna  Pol  tsys  n-sigma \n\n')

            f.write('%2d %2d  %5.0f %4.0f     %5.0f %4.0f ' %(ispw, spw_un[ispw], medavgx, medvarx, medavgy, medvary))
            nout = 0
            for iant in range(0,nant):
                offx = np.abs(avgx[iant]-medavgx)/medvarx
                offy = np.abs(avgy[iant]-medavgy)/medvarx
                if offx > 3.0:
                    if (nout == 0):
                        f.write('  %3d %4s   X %5d  %5.1f \n'%(iant, ant_names[iant],avgx[iant], offx))
                    else:
                        f.write('%36d %4s   X %5d  %5.1f \n'%(iant, ant_names[iant],avgx[iant], offx))
                    nout += 1
                if offy > 3.0:
                    if (nout == 0):
                        f.write('  %3d %4s   Y %5d  %5.1f \n'%(iant, ant_names[iant],avgy[iant], offy))
                    else:
                        f.write('%36d %4s   Y %5d  %5.1f \n'%(iant, ant_names[iant],avgy[iant], offy))
                    nout += 1
            if (nout == 0): f.write('  No outliers \n')

        f.close()

        os.system('cat '+zfileRes)

        if makeplot == True:
          tsysSpwInfo = self.getSpwInfo(ms1,intent='CALIBRATE_ATMOSPHERE')
          tsys_spw = tsysSpwInfo.keys()
          numspw = len(tsys_spw)
#          print "numspw = ", numspw
#          lchan = int(0.1*nchan[0]); hchan = int(0.9*nchan[0]); chanstr = str(lchan)+'~'+str(hchan)
          chanstr = "90%"
          if use_plotbandpass:
            ncols = 2
            nrows = int(np.ceil(np.float(numspw)/ncols))
#            print "numspw=%d, nrows=%d" % (numspw, nrows)
            if (nrows > 4):
                nrows = 4
                tsys_spw = sorted(tsys_spw)
                print "WARNING: there is a large number of Tsys spws: ", tsys_spw
                tsys_spw = tsys_spw[:nrows*ncols] # this will be 4*2=8
                print "WARNING: capping number of Tsys spw plots to %d: " % (nrows*ncols), tsys_spw
            figfile = qa2_output_dir+'tsys_plot.png'
            tsys_spw_string = ','.join([str(j) for j in tsys_spw])
            subplot = nrows*10 + ncols
            if subplot == 12:
                subplot = 21 # plotbandpass does not support 1 row, 2 columns
            antenna = ''
            if (dontPlotFlaggedAntennas):
                if (ms2 == ''):
                    ms2 = ms1+'.split'
                if os.path.exists(ms2):
                    unflagged, flagged = getUnflaggedAntennas(ms2, flaggedFraction=flaggedFraction)
                    antenna = ','.join(unflagged)
                    print "Will only plot the %d unflagged of %d antennas in the .split ms: %s" % (len(unflagged), len(unflagged)+len(flagged), antenna)
                    
            showimage = False
            for i in sorted(tsys_spw):
                if tsysSpwInfo[i]['refFreq'] > 550e9: showimage = True
            print "Running plotbandpass(caltable='%s',overlay='antenna,time',xaxis='freq',yaxis='amp',field='%s',spw='%s',plotrange=[0,0,0,%f],figfile='%s',chanrange='%s',subplot=%d,showfdm=True,interactive=False, figfileSequential=True, antenna='%s', showatm=True, showimage=%s)" % (caltable, str(tsys_field), tsys_spw_string, 0, figfile, chanstr, subplot, antenna, showimage)
            plotbandpass(caltable,overlay='antenna,time',xaxis='freq',yaxis='amp',field=tsys_field,
                         spw=tsys_spw_string, plotrange=[0,0,0,0],figfile=figfile,chanrange=chanstr,
                         subplot=subplot, showfdm=True, interactive=False, figfileSequential=True,
                         antenna=antenna, showatm=True, showimage=showimage) # added showatm on June 3, 2015
          else:
            showgui = False
            # Allow for more than 4 spws, since BW switching data may have up to 8
            nrows = int(np.round(np.sqrt(numspw)))
            ncols = int(np.ceil(numspw*1.0/nrows))
            if (nrows*ncols > 9):
                nrows = 3
                ncols = 3
            subplot = nrows*100 + ncols*10 + 1
            plotctr = 0
            plots = 1
            tsys_field = ''  # no need to set this.  Blank will fix bandwidth switching.
            if (numspw > 9 and numspw % 9 > 0):
                # insure that the rest of the final page is blanked
                numpanels = int(np.ceil(numspw*1.0/9)*9)
            else:
                numpanels = numspw
            for ipanel in range (numpanels):
                if (ipanel > numspw-1):
                    i = numspw-1   
                    xaxisMax = 1e6-1  # i.e. 1 THz (ensure blank final plot until the end of page)
                else:
                    i = ipanel
                    xaxisMax = 0 # automatic
                if (np.isnan(max_spw[i])):
                    # Take care of the single-polarization case, where max_spw will be NaN
                    if (np.sum(TXs) > 0):
                        max_spw[i] = np.median(TXs) * 2
                    elif (np.sum(TYs) > 0):
                        max_spw[i] = np.median(TYs) * 2
                if ((i!=numspw-1 or numspw>9) and (plotctr != nrows*ncols-1)):
                    if (plotctr == 0):
                        clearpanel = 'All'
                    else:
                        clearpanel = 'Auto'
                    print "Running plotcal(caltable='%s', xaxis='freq', yaxis='amp', field='%s', spw='%s', showgui=%s, plotsymbol=',', plotrange=[0,%d,0,%f], subplot=%d, clearpanel='%s')" % (caltable,tsys_field,str(tsys_spw[i])+':'+chanstr,showgui,xaxisMax,max_spw[i],subplot+plotctr,clearpanel)
                    plotcal(caltable = caltable, xaxis = 'freq', yaxis = 'amp', field = tsys_field,
                        spw = str(tsys_spw[i])+':'+chanstr, showgui = showgui, plotsymbol = ',',
                        plotrange = [0,xaxisMax,0,max_spw[i]], subplot=subplot+plotctr, clearpanel=clearpanel)
                    plotctr += 1
                else:
                    figfile = qa2_output_dir+'tsys_plot.png'
                    if (plots > 1):
                        figfile = qa2_output_dir+'tsys_plot%d.png' % (plots)
                    print "Running plotcal(caltable='%s', xaxis='freq', yaxis='amp', field='%s', spw='%s', showgui=%s, plotsymbol=',', plotrange=[0,%d,0,%f], subplot=%d, figfile='%s')" % (caltable,tsys_field,str(tsys_spw[i])+':'+chanstr,showgui,xaxisMax,max_spw[i],subplot+plotctr, figfile)
                    plotcal(caltable = caltable, xaxis = 'freq', yaxis = 'amp', field = tsys_field,
                        spw = str(tsys_spw[i])+':'+chanstr, showgui = showgui, plotsymbol = ',',
                        plotrange = [0,xaxisMax,0,max_spw[i]], subplot=subplot+plotctr,
                        figfile = figfile)
                    plotctr = 0
                    subplot = nrows*100 + ncols*10 + 1
                    plots += 1
    
    def wvr_stat(self, ms1='', refAnt='',qa2_output_dir='',
                 autoscale_yaxis=True, wvr_gaintable='', scanintent='BANDPASS',
                 solint='int', spw='', pol='', plotfile='wvr_plot.png',
                 nsigma_coherence=5, unwrap_phase=True, showFlaggedData=False,
                 debug=False):
        """
        wvr_stat.py

        This is an experimental qa2 python script that analyzes the
        bandpass calibrator data to determine the phase rms before and
        after application of wvr.  This is useful to determine if the
        the wvr corrections are reasonable, and to suggests flags or
        averaging of any bad antenna wvrgcals.  Uses spw 0, 'XX' only.

        INPUTS NEEDED:
           ms1: assumes visibility data set is ms1
           wvr_gaintable: should be left as '' for manual reduction.
              Alternatively, it is set when called from analyzemscal.py which passes
              in the name of the wvr table created by the pipeline.
        OPTIONAL INPUTS:
           refAnt: can be defined before entry, otherwise uses '0'
           qa2_output_dir: the directory to write the .txt and .png files
           autoscale_yaxis: True, False, or a range e.g. [-360,360]
           scanintent: the intent for which to choose the scan to use
           solint: passed to gaincal
           spw: which spectral window to analyze (as numbered in the pre-split ms, e.g. 17)
           pol: which polarization to analyze
           plotfile: name of the plot file to produce
           unwrap_phase: Boolean
           showFlaggedData: Boolean, show flagged solutions or not
        OUTPUTS:

        The ascii output file contains the statistics for each antenna (wrt
        to refAnt) and the output from wvrgcal in:

        <qa2_output_dir>/wvr_stat.txt'

        The corrected (green) and uncorrected (blue) phases are
        shown for each antenna in

        <qa2_output_dir>/wvr_plot.png'

        USEAGE: assumes ms1 as the visibility data set
                assumes refAnt='0', if not defined

        execfile (wvr_stat.py)

        """
        import pylab as pl
#        from clearplot import clearplot # this is defunct in CASA 5.0+
        from gaincal import gaincal

        if (autoscale_yaxis != True and autoscale_yaxis != False):
            autoscale_yaxis_range = autoscale_yaxis
            autoscale_yaxis = False
        else:
            autoscale_yaxis_range = [-200,200]
        qa2_output_dir = self.addTrailingSlashIfNecessary(qa2_output_dir)
        if (refAnt == ''):
            refAnt = '0'
            refAntID = '0'
        else:
            refAntID = getAntennaIndex(ms1,refAnt)

        #   Which gain table.  Smoothed or not?
        if (wvr_gaintable == ''):
            wvr_gaintable = ms1+'.wvr.smooth'
            if not os.path.exists(wvr_gaintable): 
                wvr_gaintable = ms1+'.wvr'
        if not os.path.exists(wvr_gaintable): 
            print "WVR gaintable not found."
            return

        makeplot = True
        print "Running ValueMapping"
        vm = ValueMapping(ms1)
        print "Completed ValueMapping"

        #  Get antenna parameters

        tb.open(ms1+'/ANTENNA')
        ant_names=tb.getcol('NAME')
        ant_pos=tb.getcol('POSITION')
        nant = len(ant_names)
        tb.close()

        #    Get bandpass scan
        if (getCasaVersion() >= casaVersionWithMSMD and spw != ''):
            # This is necessary for spectral scan / bandwidth switching
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms1)
            scan_list = np.intersect1d(mymsmd.scansforintent('*'+scanintent+'*'),
                                       mymsmd.scansforspw(int(spw)))
            print "Got %s scan_list = " % (scanintent), scan_list
            mymsmd.close()
        else:
            scan_list = vm.uniqueScans
        cscan = None
        sfield = ''
        for isc in scan_list:
            intent = vm.getIntentsForScan(isc)
            jintent = string.join(intent, '')
            if jintent.find(scanintent)!=-1:
                if (scanintent.find('PHASE')>=0):
                    # skip the amplitude and bandpass calibrator scans if they also have PHASE intent
                    if (jintent.find('BANDPASS')>=0 or jintent.find('AMPLI')>=0 or
                        jintent.find('FLUX')>=0):
                        continue
                sfield = vm.getFieldsForScan(isc)[0]
                if (scanintent.find('BANDPASS')>=0):
                    cscan = str(isc)
                    print "Choosing BANDPASS scan ", cscan
                    break
                else:
                    # use all scans, not just the first scan
                    if (cscan == None):
                        cscan = str(isc)
                    else:
                        cscan += ',' + str(isc)

        checkIfScanFlagged = False
        if (cscan == None):
            print "No %s intent found." % (scanintent)
            for isc in scan_list:
                intent = vm.getIntentsForScan(isc)
                jintent = string.join(intent, '')
                if jintent.find('PHASE')!=-1:
                    print "Using first PHASE calibrator"
                    checkIfScanFlagged = True
                    sfield = vm.getFieldsForScan(isc)[0]
                    cscan = str(isc)
                    break
        if (cscan == None):
            print "No %s nor PHASE calibrator scans found!" % (scanintent)
            return

        #  Get a science spw
        if (spw == ''):
            a = self.getSpwInfo(ms1); jspw = a.keys()[0]
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms1)
            myscan = int(cscan.split(',')[0])
            spwsforscan = mymsmd.spwsforscan(myscan)
            if (jspw not in spwsforscan):
                # The prior simple selection does not work for the case of spectral scan observations.
                print "spw%d not in spwsforscan%d=%s, a.keys()=%s" % (jspw, myscan, str(spwsforscan), str(a.keys()))
                newspw = np.intersect1d(spwsforscan,a.keys())
                if (len(newspw) > 0):
                    # spectral scan case
                    newspw = newspw[0]
                    print "Scan %s does not have spw=%d, picking spw=%d" % (cscan, jspw, newspw)
                    jspw = newspw
                else:
                    # bw switching case
                    cscan = -1
                    for isc in scan_list:
                        spwsforscan = mymsmd.spwsforscan(int(isc))
                        if (jspw in spwsforscan):
                            cscan = str(isc)
                            print "Scan %s does not have spw=%d, picking scan=%s" % (myscan, jspw, cscan)
                            break
                    if (cscan == -1):
                        print "Could not find scan to match spw in wvr_stat.  Is this a BW switching dataset?"
                        return
            else:
                print "Confirmed that scan %s contains spw=%d" % (cscan, jspw)
            cspw = str(jspw)  # should apply a channel selection here to avoid edges
            mymsmd.close()
        else:
            cspw = str(spw)
        
        if (checkIfScanFlagged):
            cscan = getUnflaggedScans(ms1, cspw, sfield)
            if (len(cscan) < 1):
                print "All scans on field %s are flagged in spw %s" % (str(sfield), cspw)
                return
            cscan = str(cscan[0])
            print "Using first unflagged scan = ", cscan

        if (pol == ''):
            cpol = 'X'
        else:
            cpol = pol


        #   Remove previous phase gain solutions:
        os.system('rm -rf '+qa2_output_dir+'wvr_before')
        os.system('rm -rf '+qa2_output_dir+'wvr_after')

        if makeplot:
            pl.clf()
#            clearplot() # this function is defunct in CASA 5.0+


        #   Open file for writing
        if (plotfile != 'wvr_plot.png'):
            zfileRes = qa2_output_dir + 'wvr_stat_%s.txt' % (os.path.basename(plotfile).strip('.png'))
        else:
            zfileRes = qa2_output_dir+'wvr_stat.txt'
        if os.path.exists (zfileRes): os.system('rm -f '+zfileRes)

        f = open (zfileRes, 'w')
        print 'opening file for writing: '+zfileRes

        #   Make phase gain solution with and without wvr correction
        print "Running gaincals with spw = ", cspw
        print version(True)+" Running gaincal(vis='%s', refant='%s', calmode='p', selectdata=True, scan='%s',spw='%s',solint='%s', caltable='%swvr_before')" % (ms1,refAnt,cscan,cspw,solint,qa2_output_dir)
        gaincal(vis=ms1,
                refant=refAnt,calmode='p', selectdata=True,
                scan=cscan,spw=cspw,solint=solint,
                caltable=qa2_output_dir+'wvr_before')

#        print "Done the gaincal on the 'without' wvr correction"

        print version(True)+" Running gaincal(vis='%s', refant='%s', calmode='p', selectdata=True, scan='%s',spw='%s',solint='%s', caltable='%swvr_after', gaintable='%s')" % (ms1,refAnt,cscan,cspw,solint,qa2_output_dir,wvr_gaintable)
        gaincal(vis=ms1,
                refant=refAnt,calmode='p',selectdata=True,
                scan=cscan,spw=cspw,solint=solint, 
                caltable=qa2_output_dir+'wvr_after',gaintable = wvr_gaintable)

#        print "Done the gaincal on the 'with' wvr correction"
        f.write('number of antennas=%3d  refAnt=%4s   \n' % (nant, refAnt))


        #  Get antenna separations

        ant_sep=[]
        for i in range(nant):
            temp = (ant_pos[0,i]-ant_pos[0,refAntID])**2 + (ant_pos[1,i]-ant_pos[1,refAntID])**2 +(ant_pos[2,i]-ant_pos[2,refAntID])**2
            ant_sep.append(np.sqrt(temp))

        #  Get phases before wvrgcal

        tb.open(qa2_output_dir+'wvr_before')
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
        else:
            calFormat = 33  # <= casa 3.3

        time = tb.getcol('TIME')
        time = time-time[0]+0.0
        antenna1 = tb.getcol('ANTENNA1')
        if (calFormat == 33):
            gain = tb.getcol('GAIN')
        else:
            gain = tb.getcol('CPARAM')
        flags = tb.getcol('FLAG')
        p_1 = np.arctan2(np.imag(gain),np.real(gain))*180.0 / np.pi
        np1 = len(antenna1)
        #print 'number of phases ', np1
        tb.close()

        #  Get phases after wvrgcal

        tb.open(qa2_output_dir+'wvr_after')
        time = tb.getcol('TIME')
        if (len(time) != np1):
            print "Warning: wvr_after has %d rows, while wvr_before has %d ---> there may be a problem with one or more WVRs." % (len(time), np1) 
#        time = time-time[0]+0.0
        antenna1 = tb.getcol('ANTENNA1')
        if (calFormat == 33):
            gain = tb.getcol('GAIN')
        else:
            gain = tb.getcol('CPARAM')
        p_2 = np.arctan2(np.imag(gain),np.real(gain))*180.0 / np.pi
        np2=len(antenna1)
        #print 'number of phases ', np2
        tb.close()

        #  get a phase stream for each antenna

        var_1=[]
        var_2=[]
        if makeplot: pl.close()

        #  Formatting of plots
        nsub3 = 0
        nsub1, nsub2 = self.pickSubplotGrid(nant)

        for iant in range(nant):            
            if cpol == 'X':
                mypol = 0
            else:
                mypol = 1
            pa_1 = p_1[mypol][0]
            pa_2 = p_2[mypol][0]

            np1 = len(pa_1)
            pb_1 = []
            pb_2 = []
            tt = []
            for j in range(np1):
                if (j >= len(antenna1)):
                    # This is necessary if the wvr_after has fewer solutions than wvr_before (due to gaincal failures). - Todd
                    break
                if ((iant == antenna1[j]) and (not flags[mypol][0][j] or showFlaggedData)):
                    pb_1.append(pa_1[j])
                    pb_2.append(pa_2[j])
                    tt.append(time[j])
            npc = len(pb_1)
            pc_1 = pb_1
            pc_2 = pb_2
            if (unwrap_phase==False):
                # Make an independent copy of the list to ensure that raw
                # phases get plotted, even after the unwrapping for statistics.
                pc_1_plot = list(pc_1)
                pc_2_plot = list(pc_2)
            # Remove lobe ambiguities before computing statistics
            for i in range(1,npc):
                pdiff = pc_1[i]-pc_1[i-1]
                pdiff = np.mod(pdiff+900.0,360.0)-180.0
                pc_1[i] = pc_1[i-1] + pdiff
                pdiff = pc_2[i]-pc_2[i-1]
                pdiff = np.mod(pdiff+900.0,360.0)-180.0
                pc_2[i] = pc_2[i-1] + pdiff
            if (unwrap_phase):
                pc_1_plot = pc_1
                pc_2_plot = pc_2

        #     plot phases
            pmin = -180
            pmax = 180
            if makeplot == True:
                nsub3 = nsub3 + 1
                desc = pl.subplot(nsub1,nsub2,nsub3)
                pl.subplots_adjust(hspace=0.40, wspace=0.40)
                pl.hold(True)
                tt = pb.date2num(mjdSecondsListToDateTime(tt))
                if (autoscale_yaxis and len(pc_1)>0 and len(pc_2)>0):
                    pmax = np.max([np.max(pc_1), np.max(pc_2)])
                    pmin = np.min([np.min(pc_1), np.min(pc_2)])
                    pdiff = pmax-pmin
                    if pdiff <10: pdiff = 10
                    pmax = pmax + 0.25*pdiff
                    pmin = pmin - 0.25*pdiff
                pl.plot_date(tt, pc_1_plot, 'b.', markeredgecolor='b')
                pl.title('WVR '+ant_names[iant], size=10)
                if (autoscale_yaxis):
                    pl.plot_date(tt,pc_2_plot,'g.', markeredgecolor='g')
                else:
                    pl.plot_date(tt,pc_2_plot,'g.', markeredgecolor='g')
                # tt is in units of days
                ttrange = 0
                if (len(tt) > 0):
                    ttrange = np.max(tt) - np.min(tt) # tt[-1] - tt[0]
                    if (ttrange < 3.5/1440.):
                        ttmajor = 1
                        ttminor = 1
                    elif (ttrange < 10/1440.):
                        ttmajor = 2
                        ttminor = 1
                    elif (ttrange < 60/1440.):
                        ttmajor = 10
                        ttminor = 2
                    else:
                        ttmajor = 20
                        ttminor = 10
                    if (ttrange > 0):
                        desc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,300,ttmajor)))
                        desc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,300,ttminor)))
                    if (debug): print "ttrange=%f, ttmajor=%d, ttminor=%d" % (ttrange, ttmajor, ttminor)
                desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
                desc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
                if (iant != nant-1):
                    desc.set_xticklabels([])
                else:
                    pl.xlabel('UT (HH:MM)', size=10)
                pl.yticks(range(-540,541,90))
                if (autoscale_yaxis):
                    pl.ylim (pmin,pmax)
                else:
                    pl.ylim(autoscale_yaxis_range)
                if (ttrange >= 0):
                    pl.setp(plt.gca().get_xmajorticklabels(), size=7)
                    pl.setp(plt.gca().get_ymajorticklabels(), size=8)
                if (iant == 0):
                    pb.text(0.0, 1.3, 'before',color='b', transform=desc.transAxes,size=9)
                    pb.text(0.75, 1.3, 'after',color='g', transform=desc.transAxes,size=9)
                if (iant == 1):
                    pb.text(0.0, 1.3, 'SPW '+cspw+', Pol '+cpol,color='k', transform=desc.transAxes,size=10)
                if (iant == 2):
                    pb.text(0.25, 1.3, 'Scan '+cscan,color='k', transform=desc.transAxes,size=10)
                if (iant == 3):
                    pb.text(0.25, 1.3, sfield,color='k', transform=desc.transAxes,size=10)

            if (len(pc_1) > 0):
                var_1.append(np.var(pc_1))
            else:
                var_1.append(-1)  # i.e. all data flagged, so the measurement is meaningless

            if (len(pc_2) > 0):
                var_2.append(np.var(pc_2))
            else:
                var_2.append(-1) # i.e. all data flagged, so the measurement is meaningless

        if makeplot:
            pl.savefig(qa2_output_dir + plotfile)
            pl.clf()

        f.write('\n****************************************************************** \n\n')
        scan_string = '      '+scanintent+' scan='+cscan+'; spw='+cspw+'; pol='+cpol+' \n\n'
        f.write(scan_string)
        f.write('\n          PHASE FLUCTUATIONS OVER %s SCAN\n' % (scanintent))
        f.write('          BEFORE AND AFTER WVR CORRECTION: '+wvr_gaintable+'\n\n')
        f.write('Column Header Key:\n')
        f.write('A: Antenna Name\n')
        f.write('B: Spacing from reference antenna (m)\n')
        f.write('C: Phase RMS Before (deg)\n')
        f.write('D: Phase RMS After (deg)\n')
        f.write('E: D/C (%)\n')
        f.write('F: Coherence Before (%)\n')
        f.write('G: Coherence After (%)\n')
        f.write('H: Not Improved?\n\n')
        f.write('A          B       C       D      E    F    G  H\n')
        coherList = []
        coherListUnflagged = []
        for i in range(nant):
            # the abs() below simply prevents an error from a negative variance (i.e. flagged)
            coherAfter = np.cos(np.sqrt(abs(var_2[i]))*np.pi/180.0)**2
            coherBefore = np.cos(np.sqrt(abs(var_1[i]))*np.pi/180.0)**2
            with np.errstate(invalid='print'):
                if (var_1[i] < 0):
                    print "Antenna %d was flagged on %s scan" % (i,scanintent)
                    nextEntry = 0.0
                elif (var_1[i] != 0.0):
                    nextEntry = 100.0*np.sqrt(var_2[i]/var_1[i])
                    coherListUnflagged.append(nextEntry)
                else:
                    if (showFlaggedData):
                        print "Antenna %d has zero coherence.  It might be totally flagged." % (i)
                    nextEntry = 0.0
                coherList.append(nextEntry)
            improved_string = '            '
            if (var_1[i]<var_2[i]): improved_string = 'NI'
            if var_1[i] > 0.0: # 0.1:
                f.write('%4s  %7.1f  %6.1f  %6.1f  %4.0f  %3.0f  %3.0f  %2s\n' %(ant_names[i], ant_sep[i], sqrt(var_1[i]),sqrt(var_2[i]),100.0*sqrt(var_2[i]/var_1[i]),100.0*coherBefore,100.0*coherAfter,improved_string))
            else:
                f.write('%4s  %7.1f  flagged on %s scan\n' % (ant_names[i], ant_sep[i], scanintent))
        #
        medianCoherenceRatio = np.median(coherListUnflagged)
        madCoherenceRatio = plotbp3.mad(coherListUnflagged)
        madCoherenceOutliers = 0
        f.write('\nOutliers in "rms_after/rms_before" [>%g*MAD (>%.2f%%) above/below median (%.2f%%)]:' % (nsigma_coherence,nsigma_coherence*madCoherenceRatio,medianCoherenceRatio))
        for i in range(nant):
            if (abs(coherList[i] - medianCoherenceRatio) > nsigma_coherence*madCoherenceRatio):
                f.write(' '+ant_names[i])
                madCoherenceOutliers += 1
        if (madCoherenceOutliers == 0): f.write(' none')
        #  Add log output from wvrgcal
        f.write ('\n\n  wvrgcal output of average wvr for each antenna\n\n')
        zwvrgcal_log = ms1+'.wvrgcal'
        if (os.path.exists(zwvrgcal_log)):
            f1 = open (zwvrgcal_log, 'r')
            fc = f1.readlines()
            f1.close
            for i in range(len(fc)):
                if (re.findall('Flag?',fc[i])):
                    f.write(fc[i]);break


            for j in range(i+1,len(fc)):
                f.write(fc[j])
        else:
            f.write("Could not find %s.\n"%(zwvrgcal_log))
        f.close()
        return
        #os.system('cat '+zfileRes)
        # end of wvr_stat()

    def glue_qa2(self, qa2_output_dir='',target='',pols=2, cleanfield='', 
                 cleanfieldname='', columns=1, elevationSummary1='', 
                 elevationSummary2='', checksourceTextfile='',
                 checksourcePngs=[], convert='convert', vis=''):
        if (cleanfield == ''):
            cleanfield = target
        cwd1 = os.getcwd()
        os.chdir(qa2_output_dir)
        if vis != '':
            vis = vis.replace('.ms','_')

        os.system("rm -f qa2.pdf textfile.txt textfile.ps")
        if (os.path.exists('wvr_stat.txt')):
            wvr_stat_txt = 'wvr_stat.txt'
        else:
            wvr_stat_txt = ''
        os.system("cat %s   tsys_stat.txt  NewListObs.txt   ant_gain_check.txt   bandpass_rms.txt  flux.txt   flag_stat.txt   sensitivity.txt  %s >  textfile.txt" % (wvr_stat_txt,checksourceTextfile))

        os.system("enscript -Bc -fCourier5 --columns=%d -ptextfile.ps textfile.txt" % columns)

        os.system("ps2pdf textfile.ps %sqa2.pdf" % (vis))

        #  combine all plots
        # remove old versions if present
        os.system("rm -f *part*png")

        #  CONVERT IS USED TO ADD IN LABELS

        os.system("%s obs_display.png -font Utopia-Regular -pointsize 48 label:'Observing Schedule' -gravity Center -append obs_display_labeled.png"%convert)
        os.system("%s mosaic_plot.png -font Utopia-Regular -pointsize 48 label:'Mosaic Pointing Configuration' -gravity Center -append mosaic_plot_labeled.png"%convert)
        os.system("%s antenna_config.png -font Utopia-Regular -pointsize 48 label:'Antenna Configuration' -gravity Center -append antenna_config_labeled.png"%convert)
        if (os.path.exists('wvr_plot.png')):
            os.system("%s wvr_plot.png -font Utopia-Regular -pointsize 48 label:'Phase: before/after WVR' -gravity Center -append wvr_plot_labeled.png"%convert)
            wvr_plot_png = 'wvr_plot_labeled.png'
        else:
            wvr_plot_png = ''   # i.e. ACA dataset
        os.system("%s ant_amp_temporal.png -font Utopia-Regular -pointsize 48 label:'Temporal gain calibration' -gravity Center -append ant_amp_temporal_labeled.png"%convert)
        os.system("%s ant_phase_temporal.png -font Utopia-Regular -pointsize 48 label:'Temporal phase calibration' -gravity Center -append ant_phase_temporal_labeled.png"%convert)

        os.system("%s bandpass_avg.png -font Utopia-Regular -pointsize 48 label:'Average Bandpass for each spw' -gravity Center -append bandpass_avg_labeled.png"%convert)
        if (os.path.exists('bandpass_bad.png')):
            os.system("%s bandpass_bad.png -font Utopia-Regular -pointsize 48 label:'Poor Bandpass' -gravity Center -append bandpass_bad_labeled.png"%convert)
        os.system("%s tsys_plot.png -font Utopia-Regular -pointsize 48 label:'Composite Tsys for each spw' -gravity Center -append tsys_plot_labeled.png"%convert)
        tsys_plots = 'tsys_plot_labeled.png'
        if (os.path.exists('tsys_plot2.png')):
            os.system("%s tsys_plot2.png -font Utopia-Regular -pointsize 48 label:'Composite Tsys (part 2)' -gravity Center -append tsys_plot2_labeled.png"%convert)
            tsys_plots += ' tsys_plot2_labeled.png'
            if (os.path.exists('tsys_plot3.png')):
                os.system("%s tsys_plot3.png -font Utopia-Regular -pointsize 48 label:'Composite Tsys (part 3)' -gravity Center -append tsys_plot3_labeled.png"%convert)
                tsys_plots += ' tsys_plot3_labeled.png'
        if (os.path.exists('ampcal_uvdist.png')):
            # we used plotxy
            os.system("%s ampcal_uvdist.png -font Utopia-Regular -pointsize 48 label:'Flux calibration model and data' -gravity Center -append ampcal_uvdist_labeled.png"%convert)
        else:
            # we used plotms - this might be obsoleted now by the montage command in ampcal_uvdist()
            cmd = "%s ampcal_uvdist_model.png -font Utopia-Regular -pointsize 48 label:'Flux calibration model' -gravity Center -append ampcal_uvdist_model_labeled.png"%convert
            print "Running: ", cmd
            os.system(cmd)
            cmd = "%s ampcal_uvdist_corrected.png -font Utopia-Regular -pointsize 48 label:'Flux calibration data' -gravity Center -append ampcal_uvdist_corrected_labeled.png"%convert
            print "Running: ", cmd
            os.system(cmd)

        if (pols < 2):
            uvdist_pointsize = 96
        else:
            uvdist_pointsize = 48

        # The following is needed for datasets with many spws, which result in grids of spectra, and the
        # text becomes very small when the image is ~6000 pixels wide, so we increase the size accordingly.
        uvdist_pointsize *= 1 + (pngWidthHeight('target_spectrum.png')[0] / 1200)

        os.system("%s target_spectrum.png -font Utopia-Regular -pointsize %d label:'Target Spectrum for each spw' -gravity Center -append target_spectrum_labeled.png" % (convert,uvdist_pointsize))

        os.system("%s phase_cal_uvdist.png -font Utopia-Regular -pointsize %d label:'Phase Calibrator amp/phase vs uvdist' -gravity Center -append phase_cal_uvdist_labeled.png" % (convert,uvdist_pointsize))
        os.system("%s phase_cal_freq.png -font Utopia-Regular -pointsize %d label:'Phase Calibrator amp/phase vs freq' -gravity Center -append phase_cal_freq_labeled.png" % (convert,uvdist_pointsize))
        os.system("%s target_uv.png -font Utopia-Regular -pointsize 36 label:'Target (Field_ID=%s) u-v coverage' -gravity Center -append target_uv_labeled.png" % (convert,target))
        cleanfield = cleanfield + '=' + cleanfieldname
        os.system("%s -trim target_image.png -font Utopia-Regular -pointsize 36 label:'Target Image (Field_ID=%s)' -gravity Center -append target_image_labeled.png" % (convert,cleanfield))
        os.system("%s -trim target_psf.png -font Utopia-Regular -pointsize 48 label:'Target psf' -gravity Center -append target_psf_labeled.png"%convert)
        cmd = "montage -tile 2X3 -geometry 1000x1000+0+0   obs_display_labeled.png   mosaic_plot_labeled.png   antenna_config_labeled.png  %s  %s  %s %sqa2_part1.png" % (elevationSummary1, elevationSummary2, wvr_plot_png, vis)
        print "Running ", cmd
        os.system(cmd)

        if (os.path.exists('ampcal_uvdist_labeled.png')):
            # We used plotxy
            os.system("montage -tile 2X3 -geometry 1000x1000+0+0 ant_amp_temporal_labeled.png  ant_phase_temporal_labeled.png bandpass_avg_labeled.png %s target_spectrum_labeled.png  %sqa2_part2.png" % (tsys_plots,vis))
            os.system("montage -tile 2x3 -geometry 1000x1000+0+0 ampcal_uvdist_labeled.png  phase_cal_uvdist_labeled.png  phase_cal_freq_labeled.png    target_uv_labeled.png   target_image_labeled.png  target_psf_labeled.png  %sqa2_part3.png" % (vis))
        else:
            # We used plotms rather than plotxy (e.g. for single-polarization data)
            # Put uv-coverage plot on part2 to avoid 7 panels on part3.
            os.system("montage -tile 2X3 -geometry 1000x1000+0+0 ant_amp_temporal_labeled.png  ant_phase_temporal_labeled.png bandpass_avg_labeled.png %s target_spectrum_labeled.png  target_uv_labeled.png %sqa2_part2.png" % (tsys_plots,vis))
            os.system("montage -tile 2x3 -geometry 1000x1000+0+0  ampcal_uvdist_model_labeled.png  ampcal_uvdist_corrected_labeled.png  phase_cal_uvdist_labeled.png  phase_cal_freq_labeled.png target_image_labeled.png  target_psf_labeled.png  %sqa2_part3.png" % (vis))
        if (len(checksourcePngs) > 0):
            checksourceLabeledPngs = [checksourcePngs[0].replace('.png','_labeled.png'),
                                      checksourcePngs[1].replace('.png','_labeled.png')]
            os.system("%s %s -font Utopia-Regular -pointsize 48 label:'check source image' -gravity Center -append %s" % (convert,checksourcePngs[0], checksourceLabeledPngs[0]))
            os.system("%s %s -font Utopia-Regular -pointsize 48 label:'phase calibrator image' -gravity Center -append %s" % (convert,checksourcePngs[1], checksourceLabeledPngs[1]))
            os.system("montage -tile 2x3 -geometry 1000x1000+0+0 %s %s %sqa2_part4.png" % (checksourceLabeledPngs[0],
                                                                                            checksourceLabeledPngs[1],vis))

        os.chdir(cwd1)

    def genQA2ReportPostLog(self, ms1, ms2, phase_cal, target, target_source, tsys_field, dospw, 
                            refAnt, qa2_output_dir, uvrange, autoscale_yaxis, fdmSpwsToImage,
                            ant_gain_check_caltable, ant_amp_temporal_caltable,
                            ant_phase_temporal_caltable, wvrspw,avgchannel,
                            flaggedFraction, phaseDiff,useLocalAlmaHelper, ampcalspw, 
                            phasecalspw, nSpwsFlagged, wvrScanIntent, checksourceAnalysis,
                            bandpass_caltable, splitcal_vis):
        s = 'Starting es.generateQA2Report('
        if (ms1 != ''):
            s += "ms1='%s'," % (ms1)
        if (ms2 != ''):
            s += "ms2='%s'," % (ms2)
        if (phase_cal!=''):
            s += "phase_cal='%s'," % (str(phase_cal))
        if (target!=''):
            s += "target='%s'," % (str(target))
        if (target_source!=''):
            s += "target_source='%s'," % (str(target_source))
        if (tsys_field!=''):
            s += "tsys_field='%s'," % (str(tsys_field))
        if (dospw!=''):
            s += "dospw='%s'," % (str(dospw))
        if (refAnt!=''):
            s += "refAnt='%s'," % (str(refAnt))
        if (qa2_output_dir!=''):
            s += "qa2_output_dir='%s'," % (str(qa2_output_dir))
        if (uvrange!='0~30m'):
            s += "uvrange='%s'," % (str(uvrange))
        if (autoscale_yaxis!=True):
            s += "autoscale_yaxis='%s'," % (str(autoscale_yaxis))
        if (fdmSpwsToImage!=''):
            s += "fdmSpwsToImage='%s'," % (str(fdmSpwsToImage))
        if (ant_gain_check_caltable!=None):
            s += "ant_gain_check_caltable='%s'," % (ant_gain_check_caltable)
        if (ant_amp_temporal_caltable!=None):
            s += "ant_amp_temporal_caltable='%s'," % (ant_amp_temporal_caltable)
        if (ant_phase_temporal_caltable!=None):
            s += "ant_phase_temporal_caltable='%s'," % (ant_phase_temporal_caltable)
        if (wvrspw!=''):
            s += "wvrspw='%s'," % (str(wvrspw))
        if (avgchannel!=5):
            s += "avgchannel=%s," % (str(avgchannel))
        if (flaggedFraction!=0.75):
            s += "flaggedFraction=%g," % (str(flaggedFraction))
        if (phaseDiff!=''):
            s += "phaseDiff='%s'," % (str(phaseDiff))
        if (useLocalAlmaHelper!=True):
            s += "useLocalAlmaHelper='%s'," % (str(useLocalAlmaHelper))
        if (ampcalspw!=[]):
            s += "ampcalspw=%s," % (str(ampcalspw))
        if (phasecalspw!=[]):
            s += "phasecalspw=%s," % (str(phasecalspw))
        if (nSpwsFlagged!=0):
            s += "nSpwsFlagged=%d," % (nSpwsFlagged)
        if (wvrScanIntent!='BANDPASS'):
            s += "wvrScanIntent='%s'," % (wvrScanIntent)
        if (wvrScanIntent!='BANDPASS'):
            s += "wvrScanIntent='%s'," % (wvrScanIntent)
        if (checksourceAnalysis!=True):
            s += "checksourceAnalysis=%s," % (checksourceAnalysis)
        if (bandpass_caltable!=''):
            s += "bandpass_caltable='%s'," % (bandpass_caltable)
        if (splitcal_vis!=''):
            s += "splitcal_vis='%s'," % (splitcal_vis)
        if (s[-1] == ','):
            s = s[:-1]
        s += ')'
        casalog.post(s, 'INFO')

    def generateQA2Report(self, ms1='', ms2='', phase_cal='', target='',
                          target_source='', tsys_field='', dospw='', refAnt='',
                          qa2_output_dir='', uvrange='0~30m',
                          autoscale_yaxis=True, fdmSpwsToImage='',
                          ant_gain_check_caltable=None,
                          ant_amp_temporal_caltable=None,
                          ant_phase_temporal_caltable=None, wvrspw='',avgchannel=5,
                          flaggedFraction=0.75, phaseDiff='',useLocalAlmaHelper=True,
                          ampcalspw=[], phasecalspw=[], nSpwsFlagged=0, 
                          wvrScanIntent='BANDPASS', checksourceAnalysis=True, 
                          bandpass_caltable='', splitcal_vis='', convert='convert'):
        """
        QA2 Package to interface with the results from generateReducScript().

        Version 2.1:  Ed Fomalont, Feb 27, 2012
        Version 2.2:  streamlined, Amy Kimball, May 1, 2012
        updated instructions and other improvements, Feb 2014-2016  (Todd Hunter)

        REQUIRED INPUTS:
        ms1: the name of the parent ms (any trailing '/' will be removed)

        OPTIONAL INPUTS:
        ms2: the name of the split ms (the default is to add ".split" to ms1)
        phase_cal: the source ID (or name) of the phase calibrator as a string (e.g. '3')
        target_source: the source ID of the science target as a string (e.g. '3')
             It is used by es.sensitivity_calculator and to auto-pick the tsys_field.
             The default is the first source with OBSERVE_TARGET intent.
        target: the field ID of the science target as a string (e.g. '3')
                It is used by es.target_spectrum, and for cleaning and plotuv.  
                The default is the field ID of the target_source. It can also be
                a field name, in which case all matching field IDs will be used.
        tsys_field: the field ID(s) to use for tsys_stat plots as a string (e.g. '3')
                (only the first field will be used in sensitivity_calculator)
        dospw: a list of spws (as numbered after split) to use in target_spectrum 
               (e.g. '0,1')   (does not support the tilde character!)
        wvrspw: the science spw to use in wvr_stat (in the pre-split ms, e.g. '17')
        refAnt: the reference antenna name to use in wvr_stat (e.g. 'DV05')
        wvrScanIntent: the scan intent to use in wvr_stat
        qa2_output_dir: the directory to write the output files
        uvrange: the uv range to use in target_spectrum (e.g. '0~30m')
        autoscale_yaxis: passed to wvr_stat: either True, False or a range (i.e. [-180,180])
        fdmSpwsToImage: a list of spws to image in target_check (e.g. ['2','3'])
                default = '' which means to include all of them
                Set it to [] to ignore all of them (i.e. only use the TDM spws)
        ant_gain_check_caltable: the caltable to use in ant_gain_check
        ant_amp_temporal_caltable: the caltable to use in ant_amp_temporal
        ant_phase_temporal_caltable: the caltable to use in ant_phase_temporal
        avgchannel: the number of channels to average in target_spectrum (integer)
        flaggedFraction: when computing clean cellsize, don't consider baselines for
              antennas whose data are flagged by more than this fraction
        ampcalspw: which spws to plot in ant_amp_temporal (default = all)
           python list of integers, or a comma-delimited string
           set this to the flux calibrator's spws for bandwidth switching, e.g. '9,10,11,12'
           (But it now attempts to find these automatically using msmd.)
        phasecalspw: which spws to plot in ant_phase_temporal (default = all)
        nSpwsFlagged: number of spws that were fully flagged during calibration
        bandpass_caltable: the caltable to use in bandpass_rms and bandpass_plot
        convert: the full path to the ImageMagick 'convert' program

        INSTRUCTIONS

        1. Run es.generateReducScript in an appropriate directory.

        2. Run es.generateQA2Report('msname')
        where msname is the name of the (unsplit) ms
        This creates the qa2_output directory, and runs all the qa2 scripts below.

        SUMMARY OF CAL TABLES NEEDED:
        0. tsys_stat() expects                    uid___Axxxxxx_xxxx.ms.tsys

        1. wvr_stat() expects                     uid___Axxxxxx_xxxx.ms.wvr

        2. ant_gain_check() expects               uid___Axxxxxx_xxxx.ms.split.ap_pre_bandpass
              but you can specify it via the optional ant_gain_check_caltable argument
           
        3. bandpass_rms() expects                 uid___Axxxxxx_xxxx.ms.split.bandpass
        
        4. bandpass_plot() expects original table uid___Axxxxxx_xxxx.ms.split.bandpass
                and also looks for smoothed table uid___Axxxxxx_xxxx.ms.split.bandpass_smooth20ch
                                               or uid___Axxxxxx_xxxx.ms.split.bandpass_bpoly
                 but you can specify it via bandpass_caltable argument

        5. ant_amp_temporal() expects             uid___Axxxxxx_xxxx.ms.split.flux_inf
              unless phaseDiff=True or it is automatically determined to be a phaseDiff
              dataset in which case it will use:  uid___Axxxxxx_xxxx.ms.split.ampli_inf
           if it doesn't find it, it looks for    uid___Axxxxxx_xxxx.ms.split.cal_amp
              but you can specify it via the optional ant_amp_temporal_caltable argument

        6. ant_phase_temporal() expects           uid___Axxxxxx_xxxx.ms.split.phase_inf
           if it doesn't find it, it looks for    uid___Axxxxxx_xxxx.ms.split.cal_phase
              but you can specify it via the optional ant_phase_temporal_caltable argument

        7. flux_values() expects                  uid___Axxxxxx_xxxx.ms.split.fluxscale

        8. checksource() expects                  uid___Axxxxxx_xxxx.ms.split.cal
        """

        ms1 = ms1.rstrip('/')
        self.genQA2ReportPostLog(ms1, ms2, phase_cal, target, target_source, tsys_field, dospw, 
                                 refAnt, qa2_output_dir, uvrange, autoscale_yaxis, fdmSpwsToImage,
                                 ant_gain_check_caltable, ant_amp_temporal_caltable,
                                 ant_phase_temporal_caltable, wvrspw,avgchannel,
                                 flaggedFraction, phaseDiff,useLocalAlmaHelper, ampcalspw, 
                                 phasecalspw, nSpwsFlagged, wvrScanIntent, checksourceAnalysis,
                                 bandpass_caltable, splitcal_vis)
        if (ms2 == ''):
            ms2 = ms1 + '.split'
        else:
            ms2 = ms2.rstrip('/')
        if (os.path.exists(ms1) == False):
            print "could not find ms1 = ", ms1
            return
        if (os.path.exists(ms2) == False):
            print "could not find the split dataset: ms2 = ", ms2
            return
        # Check CASA version -- this still works in 5.3.0-101
        casaVersionString = casalog.version()
        casaMajorVersion = int(casalog.version().split()[2].split('.')[0])
        casaMinorVersion = int(casalog.version().split()[2].split('.')[1])
        casaVersion = casaMajorVersion*10 + casaMinorVersion
        caltable = ms1+'.tsys'
        if (not os.path.exists(caltable)):
            print "Could not find the Tsys caltable"
            return
        tb.open(caltable)
        names = tb.colnames()
        if ('CAL_DESC_ID' not in names):
            calFormat = 34  # >= casa 3.4
            if (casaVersion < calFormat):
                print "Fatal error: You are trying to run QA2 in %s on a dataset that was reduced in casa >= %.1f" % (casaVersionString,calFormat*0.1)
                print "Please restart casa in version >= %.1f" % (calFormat*0.1)
                return
        else:
            calFormat = 33  # <= casa 3.3
            if (casaVersion > calFormat):
                print "Fatal error: You are trying to run QA2 in %s on a dataset that was reduced in casa <= %.1f" % (casaVersionString,calFormat*0.1)
                print "Please restart casa in version %.1f" % (calFormat*0.1)
                return


        phaseCalInfo = self.getPhaseCal(ms1)

        intentsAndSourcesInfo = self.getIntentsAndSourceNames(ms1)
        if (target_source == ''):
            # Take the first science target
            target_source = str(intentsAndSourcesInfo['OBSERVE_TARGET']['sourceid'][0])  # ID as string
            target_source_name = intentsAndSourcesInfo['OBSERVE_TARGET']['name'][0]      # name as string
            if len(intentsAndSourcesInfo['OBSERVE_TARGET']['sourceid']) > 1:
                print "# Note: there are more than one science target: i'm picking the first one: %s = %s." % (target_source, target_source_name)
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms1)
            if (getCasaVersion() < casaVersionWithMSMDFieldnames):
                target_source_name = mymsmd.namesforfields()[int(target_source)]
            else:
                target_source_name = mymsmd.fieldnames()[int(target_source)]
            mymsmd.close
        if (tsys_field == ''):
          if target_source_name in intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name']:
              ij = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name'].index(target_source_name)
              tsys_field = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['idstring'][ij]
              print "Using Tsys from science target %s = field %s" % (target_source_name, tsys_field)
          else:
              print "Note: no Tsys measurement on science target: %s.  Checking phase calibrator instead." % (target_source_name)
              if (phaseCalInfo[target_source_name]['phaseCalName'] not in intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name']): 
                  # Check for other science targets with Tsys
                  print "No Tsys was measured on the phase calibrator either.  Checking other science targets by name."
                  for scienceSource in intentsAndSourcesInfo['OBSERVE_TARGET']['name']:
                      if scienceSource in intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name']:
                          ij = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name'].index(scienceSource)
                          tsys_field = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['idstring'][ij]
                          print "Using Tsys from science target %s = field %s" % (scienceSource, tsys_field)
                          break
                  if (tsys_field == ''):
                      print "No Tsys on any science targets or phase calibrator.  This should be QA2 fail!"
                      sys.exit('Error')
              else:
                  ij = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['name'].index(phaseCalInfo[target_source_name]['phaseCalName'])
                  tsys_field = intentsAndSourcesInfo['CALIBRATE_ATMOSPHERE']['idstring'][ij]
                  print "Using Tsys from phase calibrator: %s = field %s" % (target_source_name, tsys_field)

        if (phase_cal==''):
            phase_cal = str(phaseCalInfo[target_source_name]['phaseCalId'])
        if (getCasaVersion() >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(ms2)
        if (target == ''):
            target = str(phaseCalInfo[target_source_name]['sciFieldIds'][0])   # ID as string
            if (getCasaVersion() >= casaVersionWithMSMD):
                myspws = mymsmd.spwsforfield(int(target))
                if (len(myspws) == 0):
                    print "No science spws for field ID %s" % (target)
                    if (len(phaseCalInfo[target_source_name]['sciFieldIds']) > 1):
                        target = str(phaseCalInfo[target_source_name]['sciFieldIds'][1])   # ID as string
                        myspws = mymsmd.spwsforfield(int(target))
                        if (len(myspws) == 0):
                            print "No science spws for field ID %s" % (target)
                            print "Aborting.  Please specify a target ID that has science data."
                            mymsmd.close()
                            return
                        else:
                            print "Using target %s instead" % (target)
                    else:
                        mymsmd.close()
                        print "And no other field IDs available."
                        return

        if (dospw == ''):
            if (getCasaVersion() >= casaVersionWithMSMD):
                if (getCasaVersion() >= '4.2.0'):
                    obsIntent = '*OBSERVE_TARGET*'
                else:
                    obsIntent = 'OBSERVE_TARGET#ON_SOURCE'
                try:
                    dospw = ','.join([str(k) for k in np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent(obsIntent))])
                except:
                    if (getCasaVersion() >= casaVersionWithUndefinedFrame):
                        print "You are running casa %s but the data were calibrated in version < %s." % (getCasaVersion(),casaVersionWithUndefinedFrame)
                        print "Please restart casa in a version < %s" % (casaVersionWithUndefinedFrame)
                        return
                    else:
                        print "You are running casa %s but the data were calibrated in version >= %s." % (getCasaVersion(),casaVersionWithUndefinedFrame)
                        print "Please restart casa in a version >= %s" % (casaVersionWithUndefinedFrame)
                        return
            else:
                # old method, does not work for bandwidth switching
                spwInfo = self.getSpwInfo(ms1).keys()
                spwInfo = range(len(spwInfo)) # i.e., as numbered in the split ms
                dospw = ','.join([str(k) for k in spwInfo])

        #################
        # PRTSPR-31340: support BW-switching
        if type(ampcalspw) == list:
            ampcalspw = ','.join(ampcalspw)
        if (getCasaVersion() >= casaVersionWithMSMD):
            # automatic detection of ampcal spws needed for bandwidth switching
            if len(ampcalspw) == 0:
                calampspws = np.unique(list(mymsmd.spwsforintent('CALIBRATE_AMPLITUDE*')) + list(mymsmd.spwsforintent('CALIBRATE_FLUX*')))
                ampcalspw = ','.join([str(i) for i in calampspws])
            mymsmd.close()
        #################

        if refAnt == '': refAnt = self.getRefAntenna(ms1)

        if qa2_output_dir == '':
            msdir = os.path.dirname(os.path.abspath(ms1))
            if os.path.exists(msdir+'/qa2') == False:
                os.makedirs(msdir+'/qa2')
            qa2_output_dir = msdir+'/qa2/'
        else:
            qa2_output_dir += '/'
            if os.path.exists(qa2_output_dir) == False:
                os.makedirs(qa2_output_dir)

        pols = self.findNumberOfPolarizations(ms2)
        #-------------

        print '# Get Colorful Diagram of Observations'
        self.listobs3(msName=ms1,figfile=qa2_output_dir+'obs_display.png')
        elevSummary1 = qa2_output_dir+'/'+ms1+'elevationSummary_vs_time.png'
        elevSummary2 = qa2_output_dir+'/'+ms1+'elevationSummary_vs_azim.png'
        elevSummary1 = plotElevationSummary(ms1, plotfile=elevSummary1, overwrite=True, showgui=False)
        elevSummary2 = plotElevationSummary(ms1, plotfile=elevSummary2, vs_azim=True, overwrite=True, showgui=False)

        print '# Get listings of experiment and antenna-config plot'
        print "# If mosaic, make this plot"
        self.mosaic_plot(ms2=ms2, qa2_output_dir=qa2_output_dir)

        if not sevenMeterAntennasMajority(ms2):
            print '# Determine wvr correction from bandpass obs'
            print version(True)+" Running es.wvr_stat(ms1='%s', refAnt='%s', qa2_output_dir='%s', autoscale_yaxis=%s, spw='%s', scanintent='%s')" % (ms1,refAnt,qa2_output_dir,autoscale_yaxis, str(wvrspw), wvrScanIntent)
            self.wvr_stat(ms1=ms1, refAnt=refAnt, qa2_output_dir=qa2_output_dir, autoscale_yaxis=autoscale_yaxis, spw=wvrspw, scanintent=wvrScanIntent)

            # Produce a fixed-scale plot for display in analyzemscal
            print version(True)+" Running es.wvr_stat(ms1='%s', refAnt='%s', qa2_output_dir='%s', autoscale_yaxis=False, plotfile='wvr_plot_fixedscale.png', unwrap_phase=False, spw='%s', scanintent='%s')" % (ms1,refAnt,qa2_output_dir,str(wvrspw),wvrScanIntent)
            self.wvr_stat(ms1=ms1, refAnt=refAnt, qa2_output_dir=qa2_output_dir, autoscale_yaxis=False,
                          plotfile='wvr_plot_fixedscale.png', unwrap_phase=False, spw=wvrspw, scanintent=wvrScanIntent)

        print '# Tsys statistics and plots'
        print version(True) + " Calling es.tsys_stat(ms1='%s', tsys_field='%s', makeplot=True, qa2_output_dir='%s')" % (ms1,tsys_field,qa2_output_dir)
        self.tsys_stat(ms1=ms1, tsys_field=tsys_field, makeplot=True, qa2_output_dir=qa2_output_dir)

        print '# listing of split data set'
        print version(True)+" Running es.listobs2(ms2='%s', makeplot=True, qa2_output_dir='%s', plotAntennasActualSize=True)" % (ms2, qa2_output_dir)
        self.listobs2(ms2=ms2, makeplot=True, qa2_output_dir=qa2_output_dir, plotAntennasActualSize=True)

        print '# Any antennas shadowed?'
        print version(True)+" Calling es.shadowed_ant(ms2='%s', qa2_output_dir='%s')" % (ms2,qa2_output_dir)
        self.shadowed_ant(ms2=ms2, qa2_output_dir=qa2_output_dir)

        print '# Check antenna amp of bandpass scan'
        print version(True)+" Running es.ant_gain_check(ms2='%s', qa2_output_dir='%s')" % (ms2, qa2_output_dir)
        self.ant_gain_check(ms2=ms2, qa2_output_dir=qa2_output_dir, caltable=ant_gain_check_caltable)

        print '# Check channel to channel rms of bandpass scan and plot outliers'
        print version(True)+" Running es.bandpass_rms(ms2='%s', refAnt='%s', qa2_output_dir='%s', caltable='%s')" % (ms2,refAnt,qa2_output_dir,bandpass_caltable)
        self.bandpass_rms(ms2=ms2, refAnt=refAnt, qa2_output_dir=qa2_output_dir, caltable=bandpass_caltable)

        print '# Make an spw average bandpass plots for atmosphere effects'
        print version(True)+" Running es.bandpass_plot(ms2='%s', qa2_output_dir='%s', caltable='%s')" % (ms2, qa2_output_dir, bandpass_caltable)
        self.bandpass_plot(ms2=ms2, qa2_output_dir=qa2_output_dir, caltable=bandpass_caltable)

        print '# Printout of flux density determinations'
        print version(True)+" Running es.flux_values(ms2='%s', qa2_output_dir='%s')" % (ms2, qa2_output_dir)
        self.flux_values(ms2=ms2, qa2_output_dir=qa2_output_dir)

        print '# Plot temporal antenna amp calibration of phase cal'
        if (ant_amp_temporal_caltable == None):
            caltable = ms2+'.flux_inf'
            if phaseDiff == '':
                spwInfo = self.getSpwInfo(ms1)
                spwIds = sorted(spwInfo.keys())
                spwInfo2 = self.getSpwInfo(ms1, intent = 'CALIBRATE_PHASE')
                spwIds2 = sorted(spwInfo2.keys())
                if spwIds != spwIds2:
                    phaseDiff = True
            if (phaseDiff==True and os.path.exists(ms2+'.ampli_inf')):
                caltable = ms2+'.ampli_inf'
                print "Because this is a phaseDiff observation, I am using %s as the caltable for ant_amp_temporal." % (caltable)
        else:
            caltable = ant_amp_temporal_caltable
        if (not os.path.exists(caltable)):
            caltable = ms2+'.cal_amp' # alternative Band 9 calibration path
        if (not os.path.exists(caltable)):
            print "Neither .flux_inf nor .cal_amp are found.  Will use .ampli_inf, which is what happens when BP,Flux,Phase calibrators are the same object."
            caltable = ms2+'.ampli_inf' # for the case that bandpass_cal = flux_cal = phase_cal

        print version(True)+" Running es.ant_amp_temporal(ms2='%s', phase_cal='%s', caltable='%s', qa2_output_dir='%s', spw=%s)" % (ms2, phase_cal, caltable, qa2_output_dir, str(ampcalspw))
        result = self.ant_amp_temporal(ms2=ms2, phase_cal=phase_cal, caltable=caltable, 
                                       qa2_output_dir=qa2_output_dir, spw=ampcalspw, nSpwsFlagged=nSpwsFlagged, phaseDiff=phaseDiff)
        if result != 0:
            print "Stopping."
            return

        print '# Plot temporal antenna phase calibration of phase cal'
        if (ant_phase_temporal_caltable == None):
            caltable = ms2+'.phase_inf'
        else:
            caltable = ant_phase_temporal_caltable
        if (os.path.exists(caltable) == False):
            caltable = ms2+'.cal_phase'  # alternative Band 9 calibration path
        print version(True)+" Running es.ant_phase_temporal(ms2='%s', phase_cal='%s', caltable='%s', qa2_output_dir='%s', spw=%s)" % (ms2, phase_cal, caltable, qa2_output_dir, phasecalspw)

        self.ant_phase_temporal(ms2=ms2, caltable=caltable, phase_cal=phase_cal, qa2_output_dir=qa2_output_dir, spw=phasecalspw)

        print '# Plot fluxcal object model and calibrated data'
        print "********\nRunning es.ampcal_uvdist(ms2='%s', qa2_output_dir='%s', spw='%s')" % (ms2,qa2_output_dir,ampcalspw)
#        self.ampcal_uvdist(ms2=ms2, qa2_output_dir=qa2_output_dir, spw=dospw)
        self.ampcal_uvdist(ms2=ms2, qa2_output_dir=qa2_output_dir, spw=ampcalspw) # PRTSPR-31340

        print '# Check uvdist and freq response of uv calibration phase cal'
        print version(True)+" Running es.phase_cal_check(ms2='%s', phase_cal='%s', qa2_output_dir='%s')" % (ms2,phase_cal,qa2_output_dir)
        self.phase_cal_check(ms2=ms2, phase_cal=phase_cal, qa2_output_dir=qa2_output_dir)

        print '# Obtain flagging statistics'
        print version(True)+" Running es.flag_stats(ms2='%s', qa2_output_dir='%s')" % (ms2, qa2_output_dir)
        flagStats = self.flag_stats(ms2=ms2, qa2_output_dir=qa2_output_dir, spw=dospw)

        print '#  Check target properties'
        # Here we take the first field, but we will modify this inside sensitivity_calculator
        # if the tsys_field is the phase calibrator but it was not observed in an spw that 
        # tsysspw-mapped to a science spw.  - T. Hunter
        tsys_field = tsys_field.split(',')[0]
        print version(True)+" Running es.target_check(ms1='%s', ms2='%s', target='%s', target_source='%s', tsys_caltable='%s.tsys', tsys_field='%s', qa2_output_dir='%s', fdmSpwsToImage='%s', flaggedFraction='%f')" % (ms1, ms2, target, target_source, ms1, tsys_field, qa2_output_dir, fdmSpwsToImage, flaggedFraction)
        tcresult = self.target_check(ms1=ms1, ms2=ms2, target=target, 
                                     target_source=target_source,
                                     tsys_caltable=ms1+'.tsys', tsys_field=tsys_field,
                                     qa2_output_dir=qa2_output_dir, fdmSpwsToImage=fdmSpwsToImage,
                                     flaggedFraction=flaggedFraction, flagStats=flagStats, useLocalAlmaHelper=useLocalAlmaHelper)
        if (tcresult == None):
            print "Aborting"
            return
        cleanfield, cleanfieldname = tcresult
        print '#  Get a spectrum on the target'
        print version(True)+" Running es.target_spectrum(ms2='%s',target='%s',dospw='%s',qa2_output_dir='%s',uvrange='%s')" %  (ms2,target,dospw,qa2_output_dir,uvrange)
        self.target_spectrum(ms2=ms2, target=target, dospw=dospw, qa2_output_dir=qa2_output_dir,
                             uvrange=uvrange, avgchannel=avgchannel)

        if ((intentsAndSourcesInfo['OBSERVE_CHECK']['id'][0] != '')
            and (getCasaVersion() >= '4.5')
            and checksourceAnalysis):
            print "Running checksource analysis (using tclean)."
            textfiles, checksourcePngs = checksource.checksource(overwrite=True, subdir=qa2_output_dir, splitcal_vis=splitcal_vis)
            checksourceTextfile = textfiles[0]
        else:
            checksourceTextfile = ''
            checksourcePngs = []
        

        #  Make overall pdf file of text file and the three qa png files.
        print version(True)+" Running es.glue_qa2(qa2_output_dir='%s', target='%s', pols='%s', cleanfield='%s', elevationSummary1='%s', elevationSummary2='%s', convert='%s')" % (qa2_output_dir, target, pols, cleanfield, os.path.basename(elevSummary1), os.path.basename(elevSummary2), convert)
        self.glue_qa2(qa2_output_dir, target, pols, cleanfield, cleanfieldname,
                      elevationSummary1=os.path.basename(elevSummary1), 
                      elevationSummary2=os.path.basename(elevSummary2),
                      checksourceTextfile=checksourceTextfile, checksourcePngs=checksourcePngs, 
                      convert=convert)

    def generateScriptForPI(self, fname=''):

        f = open(fname, 'r')
        fc = f.read()
        f.close()

        casaCmd = re.findall('^ *(?:split|applycal) *\( *vis.*?\)', fc, re.DOTALL|re.MULTILINE|re.IGNORECASE)

        name1, ext1 = os.path.splitext(fname)
        fname1 = name1 + '_forPI' + ext1

        f = open(fname1, 'w')
        for i in casaCmd:
            print >> f, i
            print >> f, ''
        f.close()

    def SDfillTsysSolutions(self, asapName, msName='', spwIds='', tsysCalTableName='', tsysmap='', iHaveSplitMyScienceSpw=False, doplot=False, sky=False, calmode=''):

        # spwIds must be specified as a string, e.g. spwIds = '1,3,5,7'

        if re.search('^3.3', getCasaVersion()) is not None: sys.exit('ERROR: Your version of CASA is too old.')

        if msName == '':
            if spwIds == '' and tsysmap == '': sys.exit('ERROR: you have not specified neither msName, or spwIds and tsysmap.')
            if doplot == True: sys.exit('ERROR: you have not specified msName, so I cannot do any plot.')

        if type(asapName).__name__ == 'str': asapName = [asapName]

        casaCmd = ''

        if sky == False:

            calTableName1 = msName + '.tsys'

            casaCmd = casaCmd + "os.system('rm -Rf "+calTableName1+"')\n\n"
            casaCmd = casaCmd + "gencal(vis = '"+msName+"',\n"
            casaCmd = casaCmd + "  caltable = '"+calTableName1+"',\n"
            casaCmd = casaCmd + "  caltype = 'tsys')\n\n"

        else:

            calTableName1 = msName + '.sky'

            casaCmd = casaCmd + "os.system('rm -Rf "+calTableName1+"')\n\n"
            casaCmd = casaCmd + "sdcal(infile = '"+msName+"',\n"
            casaCmd = casaCmd + "  outfile = '"+calTableName1+"',\n"
            casaCmd = casaCmd + "  calmode = '"+calmode+"')\n\n"

        tsysCalTableName.append(calTableName1)

        if (getCasaVersion() < '4.2.2' or getCasaSubversionRevision() < '29969'):

            if tsysmap == '':
                casaCmd = casaCmd + "from recipes.almahelpers import tsysspwmap\n"
                casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+calTableName1+"')\n\n"
            else:
                casaCmd = casaCmd + "tsysmap = "+str(tsysmap)+"\n\n"

            if msName != '':
                spwInfo = self.getSpwInfo(msName)
                spwIds1 = sorted(spwInfo.keys())
                spwIds1 = [int(i) for i in spwIds1]
                if iHaveSplitMyScienceSpw == True: spwIds1 = range(len(spwIds1))
            else:
                spwIds1 = spwIds.split(',')
                spwIds1 = [int(i) for i in spwIds1]

            for i in asapName:
                casaCmd = casaCmd + "for i in "+str(spwIds1)+":\n"
                casaCmd = casaCmd + "  filltsys.fillTsys('"+i+"',\n"
                casaCmd = casaCmd + "    specif = i,\n"
                casaCmd = casaCmd + "    tsysif = tsysmap[i],\n"
                casaCmd = casaCmd + "    mode = 'linear',\n"
                casaCmd = casaCmd + "    extrap = True)\n\n"

        if doplot == True:
            if False:
                # old method, before plotbandpass accepted percentages
                tsysNumChans = []
                tsysSpwInfo = self.getSpwInfo(msName, intent='CALIBRATE_ATMOSPHERE')
                for i in tsysSpwInfo: tsysNumChans.append(tsysSpwInfo[i]['numChans'])
                tsysNumChans = sorted(dict.fromkeys(tsysNumChans).keys())
                if len(tsysNumChans) != 1:
                    print "WARNING: the Tsys spws do not all have the same number of channels ("+str(tsysNumChans)+"), I am using the smallest number for the plotting."
                tsysNumChans = tsysNumChans[0]

                chanEdge = 0.0390625
                startChan = int(tsysNumChans * chanEdge)
                endChan = int(tsysNumChans * (1-chanEdge))
                chanrange = str(startChan)+'~'+str(endChan)
            else:
                chanrange = '92.1875%'
            
            casaCmd = casaCmd + "plotbandpass(caltable='%s', overlay='time', \n" %(calTableName1)
            casaCmd = casaCmd + "  xaxis='freq', yaxis='amp', subplot=22, buildpdf=False, interactive=False,\n"
            casaCmd = casaCmd + "  showatm=True,pwv='auto',chanrange='"+chanrange+"',showfdm=True, \n"
            casaCmd = casaCmd + "  field='', figfile='%s') \n" %(calTableName1+'.plots.overlayTime/'+calTableName1.split('/')[-1])

            casaCmd = casaCmd + "\nif applyonly != True: es.checkCalTable('"+calTableName1+"', msName='"+msName+"', interactive=False)\n"

        return casaCmd

    def SDdoBaselineSubtraction(self, asapName, msName='', spwIds='', iHaveSplitMyScienceSpw=False, doplot=True):

        # spwIds must be specified as a string, e.g. spwIds = '1,3,5,7'

        if re.search('^3.3', getCasaVersion()) is not None: sys.exit('ERROR: Your version of CASA is too old.')

        if msName == '' and spwIds == '': sys.exit('ERROR: you have not specified neither msName, or spwIds.')

        if type(asapName).__name__ == 'str': asapName = [asapName]

        if msName != '':
            spwInfo = self.getSpwInfo(msName)
            spwIds1 = sorted(spwInfo.keys())
            spwIds1 = [int(i) for i in spwIds1]
            if iHaveSplitMyScienceSpw == True: spwIds1 = range(len(spwIds1))
            spwIds = ','.join([str(i) for i in spwIds1])
        else:
            spwIds1 = spwIds.split(',')
            spwIds1 = [int(i) for i in spwIds1]

        casaCmd = ''

        for i in asapName:

            if (getCasaVersion() < '4.4'):
                casaCmd = casaCmd + "# The following is a temporary workaround until CASA 4.4 is released.\n"
                casaCmd = casaCmd + "tb.open('"+i+"', nomodify = False)\n"
                casaCmd = casaCmd + "tb1 = tb.query('FLAGROW==1')\n"
                casaCmd = casaCmd + "flaggedrows = tb1.rownumbers()\n"
                casaCmd = casaCmd + "if len(flaggedrows) > 0: tb.removerows(flaggedrows)\n"
                casaCmd = casaCmd + "tb1.close()\n"
                casaCmd = casaCmd + "tb.flush()\n"
                casaCmd = casaCmd + "tb.close()\n\n"

            casaCmd = casaCmd + "os.system('rm -Rf "+i+".bl')\n\n"

            if getCasaVersion() >= '5.0':

                    casaCmd = casaCmd + "sdbaseline(infile = '"+i+"',\n"
                    casaCmd = casaCmd + "  datacolumn = 'corrected',\n"
                    casaCmd = casaCmd + "  spw = '"+','.join([str(j) for j in spwIds1])+"',\n"
                    casaCmd = casaCmd + "  maskmode = 'auto',\n"
                    casaCmd = casaCmd + "  thresh = 5.0,\n"
                    casaCmd = casaCmd + "  avg_limit = 4,\n"
                    casaCmd = casaCmd + "  blfunc = 'poly',\n"
                    casaCmd = casaCmd + "  order = 1,\n"
                    casaCmd = casaCmd + "  outfile = '"+i+".bl')\n\n"

            else:

                if (getCasaVersion() >= '4.2.2'):
                    casaCmd = casaCmd + "sdbaseline(infile = '"+i+"',\n"
                    casaCmd = casaCmd + "  spw = '"+','.join([str(j) for j in spwIds1])+"',\n"
                    casaCmd = casaCmd + "  maskmode = 'auto',\n"
                    casaCmd = casaCmd + "  thresh = 5.0,\n"
                    casaCmd = casaCmd + "  avg_limit = 4,\n"
        #            casaCmd = casaCmd + "  edge = [120],\n"
                    casaCmd = casaCmd + "  blfunc = 'poly',\n"
                    casaCmd = casaCmd + "  order = 1,\n"
                    casaCmd = casaCmd + "  outfile = '"+i+".bl',\n"
                    casaCmd = casaCmd + "  overwrite = True)\n\n"
                else:
                    casaCmd = casaCmd + "sdbaseline(infile = '"+i+"',\n"
                    casaCmd = casaCmd + "  iflist = "+str(spwIds1)+",\n"
                    casaCmd = casaCmd + "  maskmode = 'auto',\n"
                    casaCmd = casaCmd + "  thresh = 5.0,\n"
                    casaCmd = casaCmd + "  avg_limit = 4,\n"
        #            casaCmd = casaCmd + "  edge = [120],\n"
                    casaCmd = casaCmd + "  blfunc = 'poly',\n"
                    casaCmd = casaCmd + "  order = 1,\n"
                    casaCmd = casaCmd + "  outfile = '"+i+".bl',\n"
                    casaCmd = casaCmd + "  overwrite = True)\n\n"

            if doplot == True:
                if getCasaVersion() < '5.0':
                    casaCmd = casaCmd + "if applyonly != True: es.SDcheckSpectra('"+i+".bl', spwIds='"+spwIds+"', interactive=False)\n\n"
                else:
                    spwIds = range(len(spwIds.split(',')))
                    spwIds = ','.join([str(j) for j in spwIds])
                    casaCmd = casaCmd + "if applyonly != True: es.SDcheckSpectra('"+i+".bl', msName='"+i+".bl', spwIds='"+spwIds+"', interactive=False)\n\n"

        return casaCmd

    def SDdoCalibration(self, asapName, msName='', spwIds='', calmode='ps', tsysCalTableName='', tsysmap='', iHaveSplitMyScienceSpw=False, doplot=True, skyCalTableName=''):

        # spwIds must be specified as a string, e.g. spwIds = '1,3,5,7'

        if re.search('^3.3', getCasaVersion()) is not None: sys.exit('ERROR: Your version of CASA is too old.')

        if msName == '' and spwIds == '': sys.exit('ERROR: you have not specified neither msName, or spwIds.')

        if type(asapName).__name__ == 'str': asapName = [asapName]

        if msName != '':
            spwInfo = self.getSpwInfo(msName)
            spwIds1 = sorted(spwInfo.keys())
            spwIds1 = [int(i) for i in spwIds1]
            if iHaveSplitMyScienceSpw == True: spwIds1 = range(len(spwIds1))
            spwIds = ','.join([str(i) for i in spwIds1])
        else:
            spwIds1 = spwIds.split(',')
            spwIds1 = [int(i) for i in spwIds1]

        casaCmd = ''

        if (getCasaVersion() >= '4.2.2' and getCasaSubversionRevision() >= '29969'):

            if tsysmap == '':
                if tsysCalTableName == '': sys.exit('ERROR: you have not specified a Tsys cal table.')
                casaCmd = casaCmd + "from recipes.almahelpers import tsysspwmap\n"
                casaCmd = casaCmd + "tsysmap = tsysspwmap(vis = '"+msName+"', tsystable = '"+tsysCalTableName+"', trim = False)\n\n"
            else:
                casaCmd = casaCmd + "tsysmap = "+str(tsysmap)+"\n\n"

            if getCasaVersion() < '5.0':
                mymsmd = msmdtool()
                mymsmd.open(msName)
                tsysspw = [i for i in mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE') if i not in mymsmd.chanavgspws().tolist()+mymsmd.wvrspws().tolist()]
                if (tsysspw == []):
                    print "Will use CALIBRATE_ATMOSPHERE#HOT instead."
                    tsysspw = [i for i in mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE#HOT') if i not in mymsmd.chanavgspws().tolist()+mymsmd.wvrspws().tolist()]
            
                mymsmd.close()

                casaCmd = casaCmd + "spwmap = {}\n"
                casaCmd = casaCmd + "for i in "+str(spwIds1)+":\n"
                casaCmd = casaCmd + "  if not tsysmap[i] in spwmap.keys():\n"
                casaCmd = casaCmd + "    spwmap[tsysmap[i]] = []\n"
                casaCmd = casaCmd + "  spwmap[tsysmap[i]].append(i)\n\n"
    #             casaCmd = casaCmd + "tsysspw = ','.join([str(i) for i in sorted(spwmap.keys())])\n\n"

        for i in asapName:

            if getCasaVersion() < '5.0':

                casaCmd = casaCmd + "os.system('rm -Rf "+i+".cal')\n\n"

                if (getCasaVersion() >= '4.2.2' and getCasaSubversionRevision() >= '29969'):

                    if False: #SDtsysavg == True:

    ###

                        casaCmd = casaCmd + "sdcal2(infile = '"+i+"',\n"
                        casaCmd = casaCmd + "  calmode = '"+calmode+"',\n"
                        casaCmd = casaCmd + "  spw = '"+','.join([str(j) for j in sorted(spwIds1)])+"',\n"
                        casaCmd = casaCmd + "  outfile = '"+i+".temp.sky',\n"
                        casaCmd = casaCmd + "  overwrite = True)\n\n"

                        for j in sorted(spwIds1):

                            casaCmd = casaCmd + "sdcal2(infile = '"+i+"',\n"
                            casaCmd = casaCmd + "  calmode = 'tsys',\n"
                            casaCmd = casaCmd + "  tsysavg = True,\n"
                            casaCmd = casaCmd + "  spw = '"+str(j)+"',\n"
                            casaCmd = casaCmd + "  tsysspw = '"+str(j)+"',\n"
                            casaCmd = casaCmd + "  outfile = '"+i+".temp.tsys.spw"+str(j)+"',\n"
                            casaCmd = casaCmd + "  overwrite = True)\n\n"

    ###

                    else:

                        calmode1 =  calmode+',tsys,apply'

                        casaCmd = casaCmd + "sdcal2(infile = '"+i+"',\n"
                        casaCmd = casaCmd + "  calmode = '"+calmode1+"',\n"
                        casaCmd = casaCmd + "  spw = '"+','.join([str(j) for j in sorted(spwIds1+tsysspw)])+"',\n"
                        casaCmd = casaCmd + "  tsysspw = '"+','.join([str(j) for j in tsysspw])+"',\n"
                        casaCmd = casaCmd + "  spwmap = spwmap,\n"
                        casaCmd = casaCmd + "  outfile = '"+i+".cal',\n"
                        casaCmd = casaCmd + "  overwrite = True)\n\n"

                else:

                    casaCmd = casaCmd + "sdcal(infile = '"+i+"',\n"
                    casaCmd = casaCmd + "  calmode = '"+calmode+"',\n"
                    casaCmd = casaCmd + "  iflist = "+str(spwIds1)+",\n"
                    casaCmd = casaCmd + "  scanaverage = False,\n"
                    casaCmd = casaCmd + "  timeaverage = False,\n"
                    casaCmd = casaCmd + "  polaverage = False,\n"
                    casaCmd = casaCmd + "  outfile = '"+i+".cal',\n"
                    casaCmd = casaCmd + "  overwrite = True)\n\n"

            else:
                mymsmd = msmdtool()
                mymsmd.open(msName)
                targetFieldIds = mymsmd.fieldsforintent('OBSERVE_TARGET#ON_SOURCE')
                mymsmd.close()

                casaCmd = casaCmd + "for i in "+str([str(j) for j in targetFieldIds])+":\n"
                casaCmd = casaCmd + "  applycal(vis = '"+i+"',\n"
                casaCmd = casaCmd + "    applymode = 'calflagstrict',\n"
                casaCmd = casaCmd + "    spw = '"+','.join([str(j) for j in sorted(spwIds1)])+"',\n"
                casaCmd = casaCmd + "    field = i,\n"
                casaCmd = casaCmd + "    gaintable = ['"+tsysCalTableName+"', '"+skyCalTableName+"'],\n"
                casaCmd = casaCmd + "    gainfield = ['nearest', i],\n"
                casaCmd = casaCmd + "    spwmap = tsysmap)\n\n"

            if doplot == True:
                if getCasaVersion() < '5.0':
                    casaCmd = casaCmd + "if applyonly != True: es.SDcheckSpectra('"+i+".cal', spwIds='"+spwIds+"', interactive=False)\n\n"
                else:
                    casaCmd = casaCmd + "if applyonly != True: es.SDcheckSpectra('"+i+"', msName='"+i+"', spwIds='"+spwIds+"', interactive=False)\n\n"

        return casaCmd

    def SDcheckSpectra(self, asapName, msName='', spwIds='', specunit='channel', panel='scan', iHaveSplitMyScienceSpw=False, interactive=True):

        # spwIds must be specified as a string, e.g. spwIds = '1,3,5,7'

        if re.search('^3.3', getCasaVersion()) is not None: sys.exit('ERROR: Your version of CASA is too old.')

        if msName == '' and spwIds == '': sys.exit('ERROR: you have not specified neither msName, or spwIds.')

        if os.path.isdir(asapName+'.plots') == True:
            if (interactive == True):
                raw_input("Directory for plots already exists. It will be removed. Press Enter to continue...")
            os.system('rm -Rf '+asapName+'.plots')
        os.system('mkdir '+asapName+'.plots')

        if msName != '':
            spwInfo = self.getSpwInfo(msName)
            spwIds1 = sorted(spwInfo.keys())
            spwIds1 = [int(i) for i in spwIds1]
            if iHaveSplitMyScienceSpw == True: spwIds1 = range(len(spwIds1))
        else:
            spwIds1 = spwIds.split(',')
            spwIds1 = [int(i) for i in spwIds1]

        if (getCasaVersion() >= '4.2.2'):

            if getCasaVersion() >= '5.0':

                tb.open(msName)
                dataColNames = tb.colnames()
                tb.close()

                if 'CORRECTED_DATA' in dataColNames:
                    dataCol = 'corrected'
                else:
                    dataCol = 'data'

                for i in spwIds1:
                    plotms(vis=msName, spw=str(i), xaxis='channel', yaxis='amp', ydatacolumn=dataCol, avgtime='1e8', avgscan=True, plotfile=msName+'.plots/'+msName+'.spectra.spw'+str(i)+'.png', overwrite = True, showgui=False)
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, or n to go non-interactive. ")
                        if userRawInput.lower() == 'n': interactive = False

            else:

                for i in spwIds1:
                    sdplot(infile=asapName, spw=str(i), plottype='spectra', specunit=specunit, timeaverage=True, scanaverage=True, stack='p', panel=panel, outfile=asapName+'.plots/'+asapName+'.spectra.spw'+str(i)+'.png', overwrite = True)
                    if interactive == True:
                        userRawInput = raw_input("Press Enter to continue, or n to go non-interactive. ")
                        if userRawInput.lower() == 'n': interactive = False

                print "# This is what SDcheckSpectra executed:\n"
                print "# for i in "+str(spwIds1)+":"
                print "#   sdplot(infile='"+asapName+"', spw=str(i), plottype='spectra', specunit='"+specunit+"', timeaverage=True, scanaverage=True, stack='p', panel='"+panel\
                    +"', outfile='"+asapName+".plots/"+asapName+".spectra.spw'+str(i)+'.png', overwrite = True)"

        else:
            for i in spwIds1:
                sdplot(infile=asapName, iflist=[i], plottype='spectra', specunit=specunit, scanaverage=True, stack='pol', panel=panel, outfile=asapName+'.plots/'+asapName+'.spectra.spw'+str(i)+'.png', overwrite = True)
                if interactive == True:
                    userRawInput = raw_input("Press Enter to continue, or n to go non-interactive. ")
                    if userRawInput.lower() == 'n': interactive = False

            print "# This is what SDcheckSpectra executed:\n"
            print "# for i in "+str(spwIds1)+":"
            print "#   sdplot(infile='"+asapName+"', iflist=[i], plottype='spectra', specunit='"+specunit+"', scanaverage=True, stack='pol', panel='"+panel\
                +"', outfile='"+asapName+".plots/"+asapName+".spectra.spw'+str(i)+'.png', overwrite = True)"

    def detectOutliers(self, values, threshold=10., edgetrim=5):
        """
        Detect outlying samples from an array of values.

        threshold: if a value is deviated from the mean by more than
                   threshold*sigma, it is identified as an outlier,
                   where mean and sigma are not "raw" ones but
                   "robust" ones (see below)
        edgetrim: minimum and maximum 1/edgetrim samples are ignored
                  to determine robust (trimmed) mean and sigma
        """
        n_samples = len(values)
        subsample = pb.sort(values)[n_samples/edgetrim:-n_samples/edgetrim]
        std = subsample.std()
        mean = subsample.mean()
        return (pb.fabs(values-mean) > threshold*std)

    def detectDelayJumps(self, msname='', spw='', scan='', solint='int', refant=0, intent='CALIBRATE_PHASE#ON_SOURCE'):
        """
        Detect delay jumps using bandpass(bandtype=BPOLY).

        Outliers in the amplitude and phase slopes of the bandpass solution
        are identified as delay jumps.
        spw: spws to be analyzed (can be a comma-separated list)
        scan: scans to be analyzed (can be a comma-separated list)
        solint: time interval for solving bandpass
        refant: reference antenna ID (integer) for bandpass solution

        If spw and/or scan are left blank and CASA version is >= 4.1.0,
        they were set according to the given intent parameter.
        """

        tb.open('%s/ANTENNA' % msname)
        antnames = tb.getcol('NAME')
        tb.close()
        nants = len(antnames)

        if spw == '':
            if getCasaVersion() >= casaVersionWithMSMD:
                mymsmd = msmdtool()
                mymsmd.open(msname)
                phase_spw = mymsmd.spwsforintent(intent)
                wvrspws = mymsmd.wvrspws()
                spw = []
                for s in phase_spw:
                    if len(mymsmd.chanfreqs(s)) > 4 and s not in wvrspws:
                        spw.append(s)
                if len(spw) < 1:
                    print 'Found no non-wvr, multi-channel spws for intent=%s' \
                        % intent
                    return
                print 'Found %d non-wvr, multi-channel spws for intent=%s: %s' \
                    % (len(spw), intent, str(spw))
                spw = ','.join([str(i) for i in spw])
                mymsmd.close()
            else:
                print 'You must specify 1 or more spws via the spw parameter.'
                return

        if scan == '' and getCasaVersion() >= casaVersionWithMSMD:
            mymsmd = msmdtool()
            mymsmd.open(msname)
            scans = mymsmd.scansforintent(intent)
            if len(scans) > 1:
                scan = ','.join([str(i) for i in scans])
            mymsmd.close()

        bpcaltable = '%s.bpcal' % msname
        os.system('rm -rf %s' % bpcaltable)
        bandpass(vis = msname,
            caltable = bpcaltable,
            spw = spw,
            scan = scan,
            solint = solint,
            refant = '%s' % refant,
            bandtype = 'BPOLY',
            degamp = 1,
            degphase = 1,
            visnorm = True,
            maskedge = 10)

    ###

        #coeffs = readCoeffs(bpcaltable, spw)

        # Read polynomial coeffs and timestamps of bandpass table.

        # obtain CAL_DESC_IDs corresponding to spws.
        # should be [0, 1, ...] ...
        spws = [int(item) for item in spw.split(',')]
        tb.open('%s/CAL_DESC' % bpcaltable)
        spwin = tb.getcol('SPECTRAL_WINDOW_ID').squeeze()
        tb.close()
        caldescs = [pb.arange(len(spwin))[spwin==s][0] for s in spws]

        coeffs = {}
        tb.open(bpcaltable)
        nants1 = len(pb.unique(tb.getcol('ANTENNA1')))
        for i in range(nants1):
            coeffs[i] = {}
            for j in range(len(spws)):
                q = tb.query('ANTENNA1==%d && CAL_DESC_ID==%d' % (i, caldescs[j]))
                coeffs[i][spws[j]] = {'timestamp': q.getcol('TIME').squeeze(),
                    'acoeff': q.getcol('POLY_COEFF_AMP').squeeze(),
                    'pcoeff': q.getcol('POLY_COEFF_PHASE').squeeze()}
        tb.close()

    ###

        #spws = [int(item) for item in spw.split(',')]
        timestamp = coeffs[0][spws[0]]['timestamp']
        outliers = []
        # hereafter 2-pol spws are assumed
        for i in range(nants):
            for j in range(len(spws)):
                outX = (self.detectOutliers(coeffs[i][spws[j]]['acoeff'][1, :]) | \
                        self.detectOutliers(coeffs[i][spws[j]]['pcoeff'][1, :]))
                outY = (self.detectOutliers(coeffs[i][spws[j]]['acoeff'][3, :]) | \
                        self.detectOutliers(coeffs[i][spws[j]]['pcoeff'][3, :]))
                outliers.append(outX)
                outliers.append(outY)
        outliers = pb.array(outliers)
        olexist = outliers.sum(0, dtype=bool)
        antspwpol = pb.array([('%sspw%dpol%d' % (a, s, p)) \
            for a in antnames for s in spws for p in [0, 1]])
        if olexist.sum(dtype=bool):
            ts = timestamp[olexist]
            ol = outliers[:, olexist]
            for i in range(len(ts)):
                #print mjd2iso8601(ts[i]), ', '.join(antspwpol[ol[:, i]])
                print qa.time('%fs' % ts[i], form='fits')[0], \
                    ', '.join(antspwpol[ol[:, i]])
        else:
            print 'no delay jumps were detected.'

    def getOptimumRobustFactor(self, res0, robust0, res1):

        f = open(os.path.expanduser('~/AIV/science/analysis_scripts/briggs.pickle'), 'r')
        data = pickle.load(f)
        f.close()

        res2 = np.interp(robust0, data[0], data[1]) * res1 / res0

        robust2 = np.interp(res2, data[1], data[0])
        
        return(round(robust2, 2))

# end of class definition for stuffForScienceDataReduction

def clearTable(vis, table, dryrun=False):
    """
    Removes all the rows from an existing subtable of a measurement set.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (not os.path.exists(vis+"/"+table)):
        print "Could not find table."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/"+table, nomodify = False)
    a = mytb.nrows()
    if not dryrun:
        mytb.removerows(range(a))
        print "Removed %d rows" % (a)
    mytb.close()

def parseFieldArgument(vis, field, blendByName=True, mymsmd=''):
    """
    Takes a field specification (integer or string or list of IDs or names),
    converts to field names, then finds all field IDs associated with those 
    name(s).  Same as parseSingleFieldArgument but supports multiple fields.
    vis: measurement set
    field: field ID integer or string or list, or name
    blendByName: if True, then get fields for name after translating from ID.
    Returns: a list of IDs and names.  
    -Todd Hunter
    """
    if type(field) == str or type(field) == np.string_:
        fields = field.split(',')
    elif (type(field) == int or type(field) == np.int32 or type(field) == np.int64):
        fields = [field]
    elif (type(field) == list or type(field) == np.ndarray):
        fields = field
    else:
        print "parseFieldArgument(): Invalid field type"
        return
    field_ids = []
    fieldnames = []
    for field in fields:
        result = parseSingleFieldArgument(vis, field, blendByName, mymsmd)
        if result is not None:
            field_id, fieldname = result
            field_ids.append(field_id)
            fieldnames.append(fieldname)
    if (len(field_ids) == 0):
        return [],[] 
    else:
        return np.array(field_ids).flatten(), list(np.array(fieldnames).flatten())
    
def parseSingleFieldArgument(vis, field, blendByName=True, mymsmd=''):
    """
    Takes a single field ID (integer or string) or field name, converts to 
    field name, then finds all field IDs associated with that name.
    Returns: a list of IDs and names.  
    This is useful for gathering all field IDs of the science target 
    in a mosaic, which is needed for tsysspwmapWithNoTable.
    blendByName: if True, then get fields for name after translating from ID.
    -Todd Hunter
    """
    if (mymsmd == ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        msmdCreated = True
    else:
        msmdCreated = False
    nfields = mymsmd.nfields()
    if (type(field) == int or type(field) == np.int32 or type(field) == np.int64):
        if (field >= nfields or int(field) < 0):
            print "There are only %d fields in this dataset" % (nfields)
            return
        fieldnames = mymsmd.namesforfields(field)
        if blendByName:
            fieldIDlist = mymsmd.fieldsforname(fieldnames[0])
        else:
            fieldIDlist = [field]
    elif (field.isdigit()):
        if (int(field) >= nfields or int(field) < 0):
            print "There are only %d fields in this dataset" % (nfields)
            return
        fieldnames = mymsmd.namesforfields(int(field))
        if blendByName:
            fieldIDlist = mymsmd.fieldsforname(fieldnames[0])
        else:
            fieldIDlist = [field]
    elif (type(field) == str): # assume string type
        if (field not in mymsmd.namesforfields()):
            if field == '':
                print "Blank field name specified, returning all."
                fieldIDlist = range(nfields)
                fieldnames = mymsmd.namesforfields(fieldIDlist)
                if msmdCreated:
                    mymsmd.close()
                return fieldIDlist, fieldnames
            else:
                print "Field name '%s' is not in this dataset" % (field)
                return
        fieldIDlist = mymsmd.fieldsforname(field)
        fieldnames = [field]
    else:
        print "field parameter must be an integer or string"
        return
    if msmdCreated:
        mymsmd.close()
    return(fieldIDlist, fieldnames)

def parseSingleFieldArgumentFromLists(field, fieldIDlist, fieldnames):
    """
    Takes a single field ID (integer or string) or field name, converts to 
    field name, then finds all field IDs associated with that name.  Does not
    require a measurement set or msmd instance.
    Returns: a list of IDs and names.  
    -Todd Hunter
    """
    nfields = len(fieldIDlist)
    if (type(field) == int or type(field) == np.int32 or type(field) == np.int64):
        if (field >= nfields or int(field) < 0):
            print "There are only %d fields in this dataset" % (nfields)
            return
        fieldIDlist = [field]
    elif (field.isdigit()):
        if (int(field) >= nfields or int(field) < 0):
            print "There are only %d fields in this dataset" % (nfields)
            return
        fieldnames = fieldnames[int(field)]
        fieldIDlist = [field]
    elif (type(field) == str): # assume string type
        if (field not in fieldnames):
            if field == '':
                print "Blank field name specified, returning all."
                return fieldIDlist, fieldnames
            else:
                print "Field name '%s' is not in this dataset" % (field)
                return
        fieldIDlist = fieldnames.index(field)
        fieldnames = [field]
    else:
        print "field parameter must be an integer or string"
        return
    return(fieldIDlist, fieldnames)

def estimateFluxcalErrorFromTsys(vis, verbose=False):
    """
    Estimates the flux calibration error contributed by not observing Tsys on 
    all objects.
    """
    import tsysNormalize
    if not os.path.exists(vis):
        print "Could not find measurement set"
        return
    status = tsysFieldCheck(vis)
    if status == True:
        print "Tsys was measured on all relevant targets (phase, flux, science), thus no additional error is incurred."
        return 0
    print "Calling tsysNormalize.tsysTransfer('%s', newTsysTable='%s.newtsys', verbose=%s)" %  (vis, vis, verbose)
    tsysNormalize.tsysTransfer(vis, newTsysTable=vis+'.newtsys', verbose=verbose)
    # Now compare these two Tsys tables
    print "TBD: compare the original and new Tsys tables."

def tsysFieldCheck(vis):
    """
    Returns True if Tsys was measured on the flux and phase calibrators and
    all of the science targets.  Will be used for SCIREQ-825.
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    fields = mymsmd.fieldsforintent('*ATMOSPHERE*')
    intents = []
    for field in fields:
        intents += mymsmd.intentsforfield(field)
    intents = np.unique(intents)
    flux = False; phase = False; science = False
    if ('CALIBRATE_FLUX#ON_SOURCE' in intents):
        print "Tsys was measured on flux calibrator"
        flux = True
    if ('CALIBRATE_PHASE#ON_SOURCE' in intents):
        print "Tsys was measured on phase calibrator"
        phase = True
    names = mymsmd.fieldsforintent('OBSERVE_TARGET#ON_SOURCE', True)
    targets = 0
    uniqueNames = np.unique(names)
    for name in names:
        if ('CALIBRATE_ATMOSPHERE#OFF_SOURCE' in mymsmd.intentsforfield(name)):
            targets += 1
    mymsmd.close()
    if (targets == len(names)):
        print "Tsys was measured on all %d science fields" % (len(uniqueNames))
        science = True
    elif targets == 0:
        print "Tsys was not measured on any of the %d science fields" % (len(uniqueNames))
    else:
        print "Tsys was measured on only %d of %d science fields" % (targets, len(uniqueNames))
    mydict = {'science':science, 'flux':flux, 'phase':phase}
    return (science and flux and phase, mydict)
    
def inverseTsysspwmapWithNoTable(vis, field, spw, alternateIntents=['OBSERVE_TARGET'],
                                 debug=False, mymsmd='', scienceSpws=''):
    """
    vis: the measurement set
    field: field ID (as integer or string integer) or field name string, can be left ''
    spw: Tsys spw ID as integer or string
    alternateIntents: if no Tsys spws are found, then look for Tsys spws for 
       fields having these intents.  Start with first one.  If it fails, try 
       the second, etc. For example: alternateIntents=['OBSERVE_TARGET','DELAY']
                                  or alternateIntents='OBSERVE_TARGET,DELAY'
       Wildcards will be added automatically to individual intentes.
    Returns: a list of FDM or TDM spws that should use the specified spw as its Tsys spw
    """
    needToClose = False
    if mymsmd == '' or mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    if len(scienceSpws) == 0:
        if type(alternateIntents) == str:
            alternateIntents = alternateIntents.split(',')
        for intent in alternateIntents:
            if len(scienceSpws) == 0:
                scienceSpws = getScienceSpws(vis, mymsmd=mymsmd, returnString=False, intent=intent)
                print "scienceSpws for %s = %s" % (intent,scienceSpws)
    spwlist = []
    spwsForIntent = mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE*')
    for scienceSpw in scienceSpws:
        tsysspw = tsysspwmapWithNoTable(vis, field, scienceSpw, alternateIntents, 
                                        debug, mymsmd, spwsForIntent)
        if spw == tsysspw:
            spwlist.append(scienceSpw)
    if needToClose:
        mymsmd.close()
    return spwlist

def tsysspwmapWithNoTable(vis, field, spw, alternateIntents=[], debug=False, 
                          mymsmd='', spwsForIntent=None):
    """
    This is an implementation of tsysspwmap that does not require a tsys 
    caltable.  It is used by bandpassPreAverage and gaincalSNR.
    It should work for all normal ALMA data.
    vis: the measurement set
    field: field ID (as integer or string integer) or field name string
    spw: spw ID as integer or string
    alternateIntents: if no Tsys spws are found, then look for Tsys spws for 
       fields having these intents.  Start with first one.  If it fails, try 
       the second, etc. For example: alternateIntents=['OBSERVE_TARGET','DELAY']
                                   or alternateIntents='OBSERVE_TARGET,DELAY'
       Wildcards will be added automatically to individual intentes.
    mymsmd: an existing instance of the msmd tool for this vis
    spwsForIntent: an existing array of mymsmd.spwsforintent()
    Returns: the integer of the Tsys spw to use for the specified spw
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    spw = int(spw)
    result = parseFieldArgument(vis, field, mymsmd=mymsmd)
    if (result is None): return
    fieldIDlist, fieldnamelist = result
    if (mymsmd == '' or mymsmd is None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        msmdCreated = True
    else:
        msmdCreated = False
    spwsForField = np.array(sorted(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),
                                                  spwsForFields(mymsmd, fieldIDlist))))
    if spwsForIntent is None:
        spwsForIntent = mymsmd.spwsforintent('CALIBRATE_ATMOSPHERE*')
    tsysspws = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True), spwsForIntent)
    if debug: print "tsysspws=%s, spwsForField=%s" % (str(tsysspws), str(spwsForField))
    availableTsysSpws = np.intersect1d(tsysspws, spwsForField)
    if (len(availableTsysSpws) < len(spwsForField)):
        # This block will generally execute for any calibrator observed in multiple spectral
        # setups, e.g. pointing or any FDM spw on the BL correlator.
        if (alternateIntents == []):
            alternateIntents = 'OBSERVE_TARGET'
            print "Could not find Tsys spw match for all spws. Adding alternate intent = ", alternateIntents
        if (type(alternateIntents) == str):
            alternateIntents = alternateIntents.split(',')
        for alternateIntent in alternateIntents:
            fields = mymsmd.fieldsforintent('*%s*'%alternateIntent)
            spwsForField = np.array(sorted(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),
                                                          spwsForFields(mymsmd,fields,matchByName=True))))
            if debug: print "%s: tsysspws=%s, spwsForField=%s" % (alternateIntent, str(tsysspws), str(spwsForField))
            availableTsysSpws = np.intersect1d(tsysspws, spwsForField)
            if (len(availableTsysSpws) > 0): break
        if (len(availableTsysSpws) == 0):
            print "tsysspwmapWithNoTable: I cannot find a Tsys spw to use, even with alternate intent."
            return

    mindiff = 1e12
    bestSpw = -1
    for availableSpw in availableTsysSpws:
        if (mymsmd.baseband(availableSpw) == mymsmd.baseband(spw)):
            diff = np.abs(mymsmd.meanfreq(availableSpw)-mymsmd.meanfreq(spw))
            if (diff < mindiff):
                mindiff = diff
                bestSpw = availableSpw
    if msmdCreated:
        mymsmd.close()
    return(bestSpw)

def nextHighestIntegerDivisible(n, d):
    """
    Checks whether an integer is evenly divisible by a second
    integer, and if not, finds the next higher integer that is.
    n: larger integer
    d: smaller integer
    -Todd Hunter
    """
    while (n % d != 0 and d<n):
        d += 1;
    return d
        
def bandpassPreAverage(vis, tsysTable='', flux=None, field=None, 
                       intent='BANDPASS', spw=None, requiredSnr=50, 
                       computeUnflaggedAntennas=False, verbose=False,
                       tsysChanTol=1, atmcal=None, minChannelsInSolution=8,
                       outputfile=''):
    """
    Computes the minimum required pre-averaging bandwidth to achieve the 
    specified accuracy level in the bandpass solution for the specified field.
    The Tsys values are taken from the SYSCAL table, so no tsys table is 
    required.
    Required inputs:
       vis: the measurement set
    Optional inputs:
       tsysTable: if present, it is only used for tsysspwmap
       flux: the flux density value to use (default=query ALMA catalog for vis date)
       field: the field ID or name to use (default=the first BANDPASS calibrator)
       intent: the intent to use (instead of BANDPASS)
       spw: the spw or spw list to make predictions for (default=all with BANDPASS intent)
       requiredSnr: required by the science case (50 --> 2% accuracy)
       computeUnflaggedAntennas: use the agentflagger tool to exclude fully flagged 
            antennas from the sensitivity calculation
       tsysChanTol: only used if tsysTable is specified
       atmcal: an instance of class Atmcal; if None, then run Atmcal
               if False, then first try the faster, less robust method
       minChannelsInSolution: warn if required value is smaller than this
    Returns: a dictionary keyed by spw ID
    -Todd Hunter
    """
    if (atmcal == True):
        print "The valid options are:  False, None, or an Atmcal instance"
        return
    if (tsysTable != ''):
        from almahelpers_localcopy import tsysspwmap
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if (intent.upper().find('TARGET')>=0 or intent.upper().find('OBSERVE')>=0):
        print "Intent of OBSERVE_TARGET is not allowed because in general these targets are not in the flux catalog."
        return

    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    # 0) Get the number of antennas in the dataset. In principle, this should be the number 
    #    of unflagged antennas on the BANDPASS calibrator.   Here we have the simpler option 
    #    to compute the number of completely unflagged antennas.
    if (computeUnflaggedAntennas):
        try:
            # agent flagger will bomb if you don't have write privilege to the ms
            unflaggedAntennas, flaggedAntennas = getUnflaggedAntennas(vis)  # does not use msmd
            nAntennas = len(unflaggedAntennas)
        except:
            print "Continuing onward assuming no antennas are flagged."
            nAntennas = mymsmd.nantennas()
            computeUnflaggedAntennas = False
    else:
        nAntennas = mymsmd.nantennas()

    # 1) identify the (first) bandpass calibrator from the dataset
    if (field == None):
        field = mymsmd.fieldsforintent('*%s*' % intent)[0]
        fieldname = mymsmd.namesforfields(field)[0]
        print "Choosing field = %d = %s" % (field, fieldname)
    elif (type(field) == int):
        fieldname = mymsmd.namesforfields(field)[0]
    else:
        if (field.isdigit()):
            fieldname = mymsmd.namesforfields(str(field))[0]
        else:
            print "Unparsable field string"
            mymsmd.close()
            return
    # 2) Get the spw(s) to process.  If OBSERVE_TARGET is present in the list of
    #    intents, then only accept spws that have both OBSERVE_TARGET and
    #    CALIBRATE_BANDPASS, because in bandwidth-switching datasets, there will
    #    be some spws that have CALIBRATE_BANDPASS but not OBSERVE_TARGET.
    
    if (spw == None):
        spws = np.intersect1d(np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('*%s*'%intent)),mymsmd.spwsforfield(field))
        if (intent.find('BANDPASS')>=0 and 'OBSERVE_TARGET#ON_SOURCE' in mymsmd.intents()):
            spws = np.intersect1d(spws, mymsmd.spwsforintent('OBSERVE_TARGET#ON_SOURCE'))
        print "Choosing spws = ", spws
    else:
        spws = spw
    if (type(spw) == int):
        spws = [spw]

    # 3) Get the mean frequency, channel width, and scans of the bandpass 
    #    target observations for each spw. Compute total on-source time.
    meanfreqs = {}
    chanwidths = {}
    nchan = {}
    receiverBand = {}
    minutes = {}
    scans = {}
    bandwidths = {}
    for spw in spws:
        meanfreqs[spw] = mymsmd.meanfreq(spw)
        chanwidths[spw] = np.abs(np.median(mymsmd.chanwidths(spw)))
        bandwidths[spw] = mymsmd.bandwidths(spw)
        nchan[spw] = mymsmd.nchan(spw)
        if verbose: print "meanfreqs[spw=%d] = %f" % (spw,meanfreqs[spw])
        receiverBand[spw] = bandforspw(spw, mymsmd=mymsmd)
        scans[spw] = np.intersect1d(np.intersect1d(mymsmd.scansforintent('*%s*'%intent), mymsmd.scansforfield(field)),mymsmd.scansforspw(spw))
        if (verbose): print "Scans for spw %d: %s" % (spw,str(scans[spw]))

        # Get the exposure time on the target. In principle, this should be the time 
        # weighted by percentage of unflagged data.  Also, the method below will
        # include sub-scan latency, but it is simpler and faster than running au.timeOnSource.
        exposureTime = 0
        for scan in scans[spw]:
            timesforscan = mymsmd.timesforscan(scan)
            exposureTime += np.max(timesforscan)-np.min(timesforscan)
        minutes[spw] = exposureTime/60.
    
    # 4) Get the flux density from ALMA database.  Could alternatively get from 
    #    flux.csv if run from the pipeline, assuming those have been previously 
    #    corrected by au.getALMAFluxcsv.
    fluxDensity = {}
    frequency = {}
    if (flux == None):
        for spw in spws:
            if (verbose): print "Calling getALMAFluxForMS('%s','%s',spw=%d, silent=True)" % (vis,fieldname,spw)
            mydict = getALMAFluxForMS(vis, fieldname, spw=spw, silent=True, mymsmd=mymsmd)
            if (mydict == None):
                print "Failed to the contact ALMA calibrator catalog."
                mymsmd.close()
                return
            if (mydict == -1):
                print "Source not found"
                mymsmd.close()
                return
            fluxDensity[spw] = mydict[fieldname]['fluxDensity']
            frequency[spw] = mydict[fieldname]['frequency']
            if verbose: print "Flux density in spw %d = %f Jy." % (spw,fluxDensity[spw])
    else:
        for spw in spws:
            fluxDensity[spw] = flux
            frequency[spw] = mymsmd.meanfreq(spw)

    # 5) Get the median Tsys on the bandpass calibrator in each spw for the first scan
    tsysDictionary = {} # keys: CALIBRATE_BANDPASS spws, values: corresponding Tsys values
    tsysspw = {}
    scanMatch = True
    for spw in spws:
        # If there are multiple scans for an spw, then simply use the Tsys of the first scan
        if (tsysTable != ''):
            myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol, field=str(field))
            if (spw >= len(myspw)):
                myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol)
                if (spw >= len(myspw)):
                    print "spw %d not in %s" % (spw, str(myspw))
                    mymsmd.close()
                    return
            myspw = myspw[spw]
        else:
            alternateIntents = ['OBSERVE_TARGET','CALIBRATE_FLUX']
            if verbose:
                print "Running au.tsysspwmapWithNoTable('%s','%s','%s', alternateIntents=%s)" % (vis,str(field),str(spw),alternateIntents)
            myspw = tsysspwmapWithNoTable(vis, field, spw, alternateIntents, mymsmd=mymsmd)
        if (myspw == -1):
            # Fix required for when BANDPASS is not observed in same science spws as PHASE+TARGET (uid___A002_Xa2ce2e_X7bd)
            print "Tsys was not observed on field %s in spw %s. Pipeline will not work on this dataset." % (str(field),str(spw))
            baseband = mymsmd.baseband(spw)
            print "Disabling scanMatch and searching for Tsys spws in the same baseband (%d)." % (baseband)
            possibleSpws = spwsforintent_nonwvr_nonchanavg(mymsmd, intent='CALIBRATE_ATMOSPHERE#OFF_SOURCE')
            scanMatch = False
            for possibleSpw in possibleSpws:
                spwsInBaseband = getScienceSpwsInSameBaseband(vis, possibleSpw, mymsmd, scanMatch=False)
                if verbose: print "spwsInBaseband = ", spwsInBaseband
                if (spw in spwsInBaseband):
                    myspw = possibleSpw
                    print "Found matching Tsys spw %d" % (myspw)
                    break
            if (myspw == -1): 
                print "None found. Aborting."
                return
        if verbose: 
            if myspw is not None:
                print "Choosing Tsys spw %d for spw %d" % (myspw, spw)
            else:
                print "tsysspwmapWithNoTable returned None"
        if (myspw in tsysspw.values()):
            # We have already computed the median Tsys for this spw, so just copy it
            for v in tsysspw.keys():
                if (tsysspw[v] == myspw):
                    tsysDictionary[spw] = tsysDictionary[v]
        tsysspw[spw] = myspw
        intentfield = mymsmd.fieldsforintent('*'+intent+'*')[0]
        tsysscans = np.intersect1d(mymsmd.scansforfield(intentfield),
                                   mymsmd.scansforintent('*ATMOSPHERE*'))
        if scanMatch:
            tsysscans = np.intersect1d(mymsmd.scansforspw(myspw), tsysscans)
        if (len(tsysscans) == 0):
            if (intent.find('PHASE') >= 0):
                print "Looking for Tsys on OBSERVE_TARGET fields"
                intentfields = mymsmd.fieldsforintent('*OBSERVE_TARGET*')
                intentfields = np.unique(mymsmd.namesforfields(intentfields))
                for intentfield in intentfields:
                    scansforfield = mymsmd.scansforfield(intentfield)
                    tsysscans = np.intersect1d(scansforfield,
                                               mymsmd.scansforintent('*ATMOSPHERE*'))
                    if scanMatch:
                        tsysscans = np.intersect1d(mymsmd.scansforspw(myspw), tsysscans)
                    if (len(tsysscans) > 0):
                        print "Found Tsys on field=%s" % (intentfield)
                        break
                    
                if (len(tsysscans) == 0):
                    print "bandpassPreAverage: Found no Tsys scans for spw=%s and field=%s" % (str(spw), str(intentfields))
                    mymsmd.close()
                    return
            else:
                print "bandpassPreAverage: Found no Tsys scans for spw=%s and field=%s" % (str(spw), str(intentfield))
                mymsmd.close()
                return
        if verbose: print "Tsys scans = ", tsysscans
        if (spw not in tsysDictionary.keys()):
            # Get the median Tsys for the first Tsys scan that matches the CALIBRATE_BANDPASS spw
            # and is actually in the SYSCAL table (sometimes they are missing!)
            for tsysscan in tsysscans:
                if verbose: print "Calling plotTsys('%s',scan=%s,spw=%s)" % (vis,str(tsysscan),str(myspw))
                mydict, atmcal = plotTsys(vis, doplot=False, scan=tsysscan, spw=myspw, atmcal=atmcal, verbose=verbose, mymsmd=mymsmd)
                if (myspw in mydict.keys()):
                    break
            if (myspw not in mydict.keys() and atmcal is not None):
                print "Did not find Tsys on the %s target: %s.  Performing a more accurate check..." % (intent,fieldname)
                atmcal = None
                for tsysscan in tsysscans:
                    if verbose: print "Calling plotTsys('%s',scan=%s,spw=%s)" % (vis,str(tsysscan),str(myspw))
                    mydict, atmcal = plotTsys(vis, doplot=False, scan=tsysscan, spw=myspw, atmcal=atmcal, verbose=verbose)
                    if (myspw in mydict.keys()):
                        break
            if (myspw not in mydict.keys()):
                print "spw %d is not in the SYSCAL table for any of the scans %s, meaning that Tsys was not observed on the %s target: %s" % (myspw,str(tsysscans),intent,fieldname)
                mymsmd.close()
                return
            # Transfer this median Tsys to the dictionary that is keyed by the CALIBRATE_BANDPASS spws
            tsysDictionary[spw] = mydict[myspw]
        else:
            if verbose: print "Skipping median calculation because it was already done for this spw."
    # 6) compute the minimum pre-averaging width
    # Use the same approach as in es.sensitivity_calculator
    band_name = ['3','4','6','7','8','9','10']
    tsys_nominal = [75.0, 86.0, 90.0, 150.0, 387.0, 1200.0, 1515.0]
    sensitivities = [0.20, 0.24, 0.27, 0.50, 1.29, 5.32, 8.85]  # mJy (for 16*12m antennas, 1 minute, 8 GHz, 2pol)
    preaverageDictionary = {}
    preaverageDictionary[spw] = {}
    preaverageDictionary['vis'] = vis
    preaverageDictionary['field'] = field
    if (computeUnflaggedAntennas):
        mykey = 'unflaggedAntennas'
    else:
        mykey = 'totalAntennas'
    preaverageDictionary[mykey] = nAntennas
    preaverageDictionary['fieldname'] = fieldname
    nBaselines = nAntennas-1 # for an antenna-based solution
    tooFewChannels = False
    smallestCommonSolintEvenlyDivisible = 0
    smallestCommonSolintEvenlyDivisibleFDM = 0
    smallestCommonSolint = 0
    largestCommonSolintEvenlyDivisible = 0
    for spw in spws:
        if verbose: print "receiverBand[spw=%d] = %s" % (spw, str(receiverBand[spw]))
        idx = band_name.index(str(receiverBand[spw]))
        relativeTsys = tsysDictionary[spw] / tsys_nominal[idx]
        timeFactor = 1 / np.sqrt(minutes[spw])
        arraySizeFactor = np.sqrt(16*15/2.)/np.sqrt(nBaselines)
        preaverageDictionary[spw] = 0
        areaFactor = 1.0
        if sevenMeterAntennasMajority(mymsmd=mymsmd):
            areaFactor = (12./7.)**2  # scale by antenna collecting area
        bandwidthFactor = np.sqrt(8.0e9/abs(chanwidths[spw])) #  scale by chan bandwidth
        polarizationFactor = np.sqrt(2)  # scale to single polarization solutions
        factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                 bandwidthFactor * polarizationFactor
        sensitivity = sensitivities[idx] * factor
#        print "(%f) %f  %f  %f  %f  %f  %f = %f" % (sensitivities[idx],relativeTsys, timeFactor, arraySizeFactor, areaFactor, bandwidthFactor, polarizationFactor, factor)
        snrPerChannel = fluxDensity[spw]*1000 / sensitivity # convert from mJy to Jy
        requiredChannels = (requiredSnr / snrPerChannel)**2
        preaverageDictionary[spw] = {}
        evenChannels = nextHighestIntegerDivisible(nchan[spw], int(np.ceil(requiredChannels)))
        solint = requiredChannels * chanwidths[spw] * 1e-6
        preaverageDictionary[spw]['solint'] = '%fMHz' % (solint)
        if (solint > smallestCommonSolint):
            smallestCommonSolint = solint
        solintEvenlyDivisible = evenChannels * chanwidths[spw] * 1e-6
        preaverageDictionary[spw]['solintEvenlyDivisible'] = '%fMHz' % (solintEvenlyDivisible)
        if (solintEvenlyDivisible > largestCommonSolintEvenlyDivisible and solintEvenlyDivisible > chanwidths[spw]*1e-6):
            largestCommonSolintEvenlyDivisible = solintEvenlyDivisible
        if (solintEvenlyDivisible > smallestCommonSolintEvenlyDivisible):
            smallestCommonSolintEvenlyDivisible = solintEvenlyDivisible
        if (solintEvenlyDivisible > smallestCommonSolintEvenlyDivisibleFDM and nchan[spw] not in [64,128,256]):
            smallestCommonSolintEvenlyDivisibleFDM = solintEvenlyDivisible

        preaverageDictionary[spw]['totalChannels'] = nchan[spw]
        preaverageDictionary[spw]['solintChannels'] = '%d' % (np.ceil(requiredChannels))
        preaverageDictionary[spw]['solintChannelsEvenlyDivisible'] = '%d' % (evenChannels)
        preaverageDictionary[spw]['medianTsys'] = tsysDictionary[spw]
        preaverageDictionary[spw]['Tsys_spw'] = tsysspw[spw]
        preaverageDictionary[spw]['band'] = receiverBand[spw]
        preaverageDictionary[spw]['bandwidth'] = bandwidths[spw]
        preaverageDictionary[spw]['minutes'] = minutes[spw]
        preaverageDictionary[spw]['snrPerChannel'] = snrPerChannel
        preaverageDictionary[spw]['sensitivity_mJy'] = sensitivity
        preaverageDictionary[spw]['chanwidth_Hz'] = chanwidths[spw]
        preaverageDictionary[spw]['fluxDensity_Jy'] = fluxDensity[spw]
        preaverageDictionary[spw]['frequency_Hz'] = frequency[spw]
        solutionChannels = nchan[spw]/int(np.ceil(requiredChannels))
        if (solutionChannels < minChannelsInSolution):
            tooFewChannels = True
            asterisks = '***'
        else:
            asterisks = ''
        if (preaverageDictionary[spw]['medianTsys'] <= 0):
            print "%sspw %2d (%4.0fMHz) has a negative median Tsys: there must e a problem in the data" % (asterisks, spw, bandwidths[spw]*1e-6)
        else:
            print "%sspw %2d (%4.0fMHz) requires solint='%.2fMHz' (%d channels in solution) to reach S/N=%.0f" % (asterisks, spw, bandwidths[spw]*1e-6, requiredChannels * chanwidths[spw] * 1e-6, solutionChannels, requiredSnr)
        if (tooFewChannels):
            print "%s This spw would have less than %d channels in its solution!" % (asterisks, minChannelsInSolution)
    preaverageDictionary['smallestCommonSolint'] = '%fMHz' % (smallestCommonSolint)
    preaverageDictionary['smallestCommonSolintEvenlyDivisible'] = '%fMHz' % (smallestCommonSolintEvenlyDivisible)
    preaverageDictionary['smallestCommonSolintEvenlyDivisibleFDM'] = '%fMHz' % (smallestCommonSolintEvenlyDivisibleFDM)
    if (largestCommonSolintEvenlyDivisible < 1e20 and largestCommonSolintEvenlyDivisible>0):
        solintRecommended = largestCommonSolintEvenlyDivisible
    else:
        solintRecommended = smallestCommonSolintEvenlyDivisible
    preaverageDictionary['solintRecommended'] = '%fMHz' % (solintRecommended)
    mymsmd.close()
    if (outputfile != ''):
        if (outputfile == True):
            outputfile = vis + '.bandpassPreAverage.txt'
        output = open(outputfile,'w')
        output.write(pprint.pformat(preaverageDictionary,width=10))
        output.close()
    return(preaverageDictionary)

def computeAggregateBandwidth(vis, spw, mymsmd='', debug=False):
    """
    Computes the aggregate bandwidth for a list of spws of a measurement set.
    Accounts correctly for overlap.  Called by gaincalSNR().
    spw: an integer list, or comma-delimited string list of spw IDs
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "could not find measurement set"
        return
    if (mymsmd == ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        msmdCreated = True
    else:
        msmdCreated = False
    if (type(spw) == str):
        spw = spw.split(',')
    minfreqs = []
    maxfreqs = []
    for s in spw:
        chanfreqs = mymsmd.chanfreqs(s)
        chanwidths = mymsmd.chanwidths(s)
        minfreqs.append(np.min(chanfreqs)-0.5*np.median(chanwidths))
        maxfreqs.append(np.max(chanfreqs)+0.5*np.median(chanwidths))
    if msmdCreated:
        mymsmd.close()
    idx = np.argsort(minfreqs)
    minfreqs = np.array(minfreqs)[idx]
    maxfreqs = np.array(maxfreqs)[idx]
    aggregate = []
    aggregate.append([minfreqs[0], maxfreqs[0]])
    if debug: print "A: Setting window %d: %.2f-%.2f" % (0, minfreqs[0]*1e-9, maxfreqs[0]*1e-9)
    for i in range(1, len(minfreqs)):
        if (minfreqs[i] < aggregate[-1][1]):
            # i begins before current max window ends
            if (maxfreqs[i] > aggregate[-1][1]):
                # i ends after i-1 ends, so extend the end of current max window
                aggregate[-1][1] = maxfreqs[i]
                if debug: print "B: Setting window %d: %.2f-%.2f" % (len(aggregate)-1, aggregate[-1][0]*1e-9, aggregate[-1][1]*1e-9)
            else:
                # i ends before activeMax ends, so i is completely contained by activeMax window
                continue
        else:
            # i begins after i-1 ends, so we have a gap, so add a new interval
            aggregate.append([minfreqs[i], maxfreqs[i]])
            if debug: print "C: Setting window %d: %.2f-%.2f" % (len(aggregate)-1, aggregate[-1][0]*1e-9, aggregate[-1][1]*1e-9)
    bw = 0
    for i in range(len(aggregate)):
        bw += aggregate[i][1]-aggregate[i][0]
    return(bw)

def medianTsysForField(vis, field, spw, scan='', intent='CALIBRATE_ATMOSPHERE*',
                       verbose=True, mymsmd=''):
    """
    Computes the median Tsys over all scans on a specified field and spw, 
    optionally restricted to an intent.
    field: integer or string ID or string name
    spw: single integer or string integer
    scan: limit to these scans (python list or comma-delimited string)
    -Todd Hunter
    """
    spw = int(spw)
    tsys = []
    if (not os.path.exists(vis)):
        print "Measurement set not found"
        return
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    result = parseFieldArgument(vis, field, mymsmd=mymsmd)
    if (result == None): return
    fieldIDlist, fieldnamelist = result
    if (type(scan) == str):
        if (len(scan) == 0):
            scan = []
        else:
            scan = scan.split(',')
    elif (type(scan) != list and type(scan) != np.ndarray):
        scan = [scan]
    if (len(scan) < 1):
        scan = mymsmd.scansforfield(fieldIDlist[0])
    if (intent != ''):
        if verbose: print "Running msmd.scansforintent"
        scans_i = mymsmd.scansforintent(intent)
        scan = np.intersect1d(scan, scans_i)
        if verbose: print "Running msmd.spwsforintent"
        spws = mymsmd.spwsforintent(intent)
        if (spw not in spws):
            print "spw %d is not in the spwsforintent=%s" % (spw, str(spws))
            return
    if (len(scan) < 1):
        print "No scans found"
        return
    atmcal = Atmcal(vis, mymsmd=mymsmd)
    for sc in scan:
        if verbose: print "Finding Tsys for scan %d" % (sc)
        mydict, atmcal = plotTsys(vis, spw=spw, doplot=False, atmcal=atmcal, 
                                  scan=sc, mymsmd=mymsmd)
        tsys.append(mydict[spw])
    if verbose:
        print "Tsys = ", tsys
        print "Mean = ", np.mean(tsys)
        print "Median = ", np.median(tsys)
    if needToClose:
        mymsmd.close()
    return(np.median(tsys))

def gaincalMosaic(caltable, snr=5, fraction=0.5, returnString=True, verbose=False):
    """
    Examines a gaincal solution table on a per-field basis and returns a 
    list of field IDs that have more than [fraction] of the possible solutions 
    showing SNR > [snr].  Ignores flagged solutions, in order to properly process 
    concatenated datasets where not all fields were observed by all antennas 
    (e.g. combining 7m and 12m executions which have different pointings)
    returnString: if False, then return a python list of integers; otherwise
            it returns a comma-delimited string list of fields
    antenna: only relevant for verbose=True, will print the SNR for this antenna
    verbose: if True, print the number and fraction of strong solutions per field
    -Todd Hunter
    """
    fields = getFieldsFromCaltable(caltable)
    print "%d fields in this table." % (len(fields))
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    myfields = []
    for field in fields:
        myt = mytb.query('FIELD_ID == %d' % field)
        SNR = myt.getcol('SNR')  # shape = [Npol][1][Nsolutions]
        flag = myt.getcol('FLAG')
        idx1 = np.where(SNR > snr)
        idx2 = np.where(flag == 0)
        unflaggedSolutions = len(idx2[-1])
        idx = np.intersect1d(np.array(idx1),np.array(idx2)) # The np.array is no longer necessary in 5.x
        nStrongSolutions = len(idx)
        total = np.prod(np.shape(SNR)[:-1]) * unflaggedSolutions
        if float(nStrongSolutions)/total > fraction:
            myfields.append(field)
            gtr = '>'
        else:
            gtr = '<'
        if verbose:
            print "%3d: %4d/%4d = %.3f %s %.3f" % (field,nStrongSolutions,total,float(nStrongSolutions)/total,gtr,fraction)
        myt.close()
    mytb.close()
    if returnString:
        return ','.join([str(i) for i in myfields])
    else:
        return myfields

def gaincalSNR(vis, tsysTable='', flux=None, field=None, 
               intent='CALIBRATE_PHASE', spw=None, requiredSnr=25, 
               computeUnflaggedAntennas=False, edgeFraction=0.03125, 
               verbose=False, debugTsysspwmap=False, tsysChanTol=1,
               atmcal=None, minSnr=10, outputfile=''):
    """
    Computes the per-antenna SNR expected for gaincal(solint='inf')
    on a per-spw basis and recommends whether bandwidth transfer 
    and/or combine='spw' is needed.
    Required inputs:
       vis: the measurement set
    Optional inputs:
       tsysTable: if present, it is only used for tsysspwmap
       flux: the flux density value to use (Jy) (default=query ALMA catalog for vis date)
       field: the field ID or name to use (default=the first PHASE calibrator)
       intent: the intent to use for the calibrator (instead of CALIBRATE_PHASE)
       spw: the spw or spw list to make predictions for (default=all with OBSERVE_TARGET)
       requiredSnr: threshold for which to make decisions
       minSnr: threshold for when even aggregate bandwidth is expected to fail
       computeUnflaggedAntennas: use the agentflagger tool to exclude fully flagged 
            antennas from the sensitivity calculation
       edgeFraction: the fraction of BW to ignore on each edge of a TDM spw
                     .03125 corresponds to central 1875 MHz
       tsysChanTol: only used if tsysTable is present
       atmcal: an instance of class Atmcal; if None, then run Atmcal
               if False, then first try the faster, less robust method
       
    Returns: a dictionary keyed by spw ID
    -Todd Hunter
    """
    if (tsysTable != ''):
        from almahelpers_localcopy import tsysspwmap
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return

    maxEffectiveBandwidthPerBaseband = 2e9*(1-2.*edgeFraction)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    # 0) Get the number of antennas in the dataset. In principle, this should be the number 
    #    of unflagged antennas on the PHASE calibrator.   Here we have the simpler option 
    #    to compute the number of completely unflagged antennas.
    if (computeUnflaggedAntennas):
        try:
            # agent flagger will bomb if you don't have write privilege to the ms
            unflaggedAntennas, flaggedAntennas = getUnflaggedAntennas(vis)
            nAntennas = len(unflaggedAntennas)
        except:
            print "Continuing onward assuming no antennas are flagged."
            nAntennas = mymsmd.nantennas()
            computeUnflaggedAntennas = False
    else:
        nAntennas = mymsmd.nantennas()

    # 1) identify the (first) phase calibrator from the dataset
    if (field == None):
        allfields = mymsmd.fieldsforintent('*%s*' % intent)
        # the default phase calibrator to use is the first one
        field = allfields[0]
        fieldnames = mymsmd.namesforfields(allfields)
        fieldname = fieldnames[0]
        if (len(allfields) > 1):
            # If there are more than one phase calibrators, then
            # pick the first one that does NOT also have observe_target intent.
            # If all have both intents, then continue to use the first one.
            for i,fieldname in enumerate(fieldnames[1:]):
                if ('OBSERVE_TARGET#ON_SOURCE' not in mymsmd.intentsforfield(allfields[i+1])):
                    break
        if verbose: print "Choosing field = %d = %s" % (field, fieldname)
    elif (type(field) == int):
        fieldname = mymsmd.namesforfields(field)[0]
    else:
        if (field.isdigit()):
            fieldname = mymsmd.namesforfields(str(field))[0]
        else:
            print "Unparsable field string"
            mymsmd.close()
            return

    # 2) Get the OBSERVE_TARGET spw(s) to process. 
    if (spw == None):
        observeTargetSpws = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('*OBSERVE_TARGET*'))
        if verbose: print "Choosing OBSERVE_TARGET spws = ", observeTargetSpws
    else:
        observeTargetSpws = spw
        if (type(spw) == int):
            observeTargetSpws = [spw]
    gaincalSpws = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('*CALIBRATE_PHASE*'))
    allSpws = np.union1d(gaincalSpws,observeTargetSpws)

    # 3) Get the mean frequency, channel width, and scans of the gaincal
    #    target observations for each gaincal spw. Compute total on-source time.
    meanfreqs = {}
    basebands = {}
    chanwidths = {}
    bandwidths = {}
    nchan = {}
    receiverBand = {}
    minutes = {}
    scans = {}
    for spw in gaincalSpws:
        meanfreqs[spw] = mymsmd.meanfreq(spw)
        chanwidths[spw] = np.abs(np.median(mymsmd.chanwidths(spw)))
        bandwidths[spw] = mymsmd.bandwidths(spw)
        basebands[spw] = mymsmd.baseband(spw)
        nchan[spw] = mymsmd.nchan(spw)
        if verbose: print "meanfreqs[spw=%d] = %f" % (spw,meanfreqs[spw])
        receiverBand[spw] = bandforspw(spw, mymsmd=mymsmd)
        scans[spw] = np.intersect1d(np.intersect1d(mymsmd.scansforintent('*%s*'%intent), mymsmd.scansforfield(field)),mymsmd.scansforspw(spw))
        if (verbose): print "Scans for spw %d: %s" % (spw,str(scans[spw]))

        # Get the exposure time on the target. In principle, this should be the time 
        # weighted by percentage of unflagged data.  Also, the method below will
        # include sub-scan latency, but it is simpler and faster than running au.timeOnSource.
        timesforscans = []
        for scan in scans[spw]:
            timesforscan = mymsmd.timesforscan(scan)
            timesforscans.append(np.max(timesforscan)-np.min(timesforscan))
        # compute the median length of a solint='inf', combine=''
        minutes[spw] = np.median(timesforscans)/60.
    for spw in observeTargetSpws:
        meanfreqs[spw] = mymsmd.meanfreq(spw)
        chanwidths[spw] = np.abs(np.median(mymsmd.chanwidths(spw)))
        bandwidths[spw] = mymsmd.bandwidths(spw)
        nchan[spw] = mymsmd.nchan(spw)
        basebands[spw] = mymsmd.baseband(spw)
    uniqueBasebands = np.unique(basebands.values()) 
    nbasebands = len(uniqueBasebands)

    # 4) Get the flux density from ALMA database.  Could alternatively get from 
    #    flux.csv if run from the pipeline, assuming those have been previously 
    #    corrected by au.getALMAFluxcsv.
    fluxDensity = {}
    frequency = {}
    if not flux:
        print "Querying the ALMA calibrator database for flux densities of %s." % (fieldname)
        for spw in allSpws:
            if (verbose): print "Calling getALMAFluxForMS('%s','%s',spw=%d, silent=True)" % (vis,fieldname,spw)
            mydict = getALMAFluxForMS(vis, fieldname, spw=spw, silent=True, mymsmd=mymsmd, verbose=verbose) 
            if (fieldname not in mydict.keys()):
                print "No ALMA flux density measurements for %s in the ALMA catalog." % (fieldname)
                print "Use the flux parameter to specify its flux density."
                mymsmd.close()
                return
            fluxDensity[spw] = mydict[fieldname]['fluxDensity']
            frequency[spw] = mydict[fieldname]['frequency']
            if verbose: print "Flux density in spw %d = %f Jy." % (spw,fluxDensity[spw])
    else:
        # SJW make flux a list rather than a scalar, allowing pipeline to pass in flux per spw 
        for spw_id, spw_hz, flux_jy in flux:
            fluxDensity[spw_id] = flux_jy
            frequency[spw_id] = spw_hz
    aggregateBandwidth = computeAggregateBandwidth(vis, gaincalSpws, mymsmd)

    # 5) Get the median Tsys on the phase calibrator in each spw for the first scan
    tsysDictionary = {} # keys: CALIBRATE_PHASE spws, values: corresponding Tsys values
    tsysspw = {}
    for spw in gaincalSpws:
        # If there are multiple scans for an spw, then simply use the Tsys of the first scan
        if (tsysTable != ''):
            if verbose:
                print "Calling tsysspwmap('%s', '%s', tsysChanTol=%d, field='%s')" % (vis,tsysTable,tsysChanTol,str(field))
            myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol, field=str(field))
            if (spw >= len(myspw)):
                if verbose: print "Calling tsysspwmap('%s', '%s', tsysChanTol=%d)" % (vis,tsysTable,tsysChanTol)
                myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol)
                if (spw >= len(myspw)):
                    print "spw %d not in %s" % (spw, str(myspw))
                    mymsmd.close()
                    return
            myspw = myspw[spw]
        else:
            if verbose: print "Calling tsysspwmapWithNoTable('%s', %d, %d, ['OBSERVE_TARGET'])" % (vis,field,spw)
            myspw = tsysspwmapWithNoTable(vis, field, spw, alternateIntents='OBSERVE_TARGET', debug=debugTsysspwmap, mymsmd=mymsmd)
        if (myspw == None): return
        if verbose: print "Choosing Tsys spw %d for spw %d" % (myspw, spw)
        if (myspw == -1):
            print "Tsys spw map failed. Try supplying the tsysTable parameter."
            mymsmd.close()
            return
        tsysspw[spw] = myspw
        tsysscans = np.intersect1d(mymsmd.scansforspw(myspw), 
                                   mymsmd.scansforintent('*ATMOSPHERE*'))
        if verbose: print "Tsys scans = ", tsysscans
        # Get the median Tsys for the first Tsys scan that matches the CALIBRATE_PHASE spw
        # and is actually in the SYSCAL table (sometimes they are missing!)
        for tsysscan in tsysscans:
            if verbose: print "Calling au.plotTsys('%s',doplot=False,scan=%d, spw=%d)" % (vis,tsysscan,myspw)
            mydict,atmcal = plotTsys(vis, doplot=False, scan=tsysscan, spw=myspw, 
                                     atmcal=atmcal, verbose=verbose, mymsmd=mymsmd)
            if (mydict == None):
                mymsmd.close()
                return
            if (myspw in mydict.keys()):
                break
        # Transfer this median Tsys to the dictionary that is keyed by the CALIBRATE_PHASE spws
        if (myspw not in mydict.keys()):
            print "spw %d not in %s" % (myspw, str(mydict.keys()))
            print "spw %d is not in the SYSCAL table for any of the scans %s, meaning that Tsys was not observed on the %s target: %s" % (myspw,str(tsysscans),intent,fieldname)
            mymsmd.close()
            return
        tsysDictionary[spw] = mydict[myspw]

    # 6) compute the expected channel-averaged SNR
    # Use the same approach as in es.sensitivity_calculator
    band_name = ['3', '4', '5', '6', '7', '8', '9', '10']
    tsys_nominal = [75.0, 86.0, 120.0, 90.0, 150.0, 387.0, 1200.0, 1515.0]
    sensitivities = [0.20, 0.24, 0.37, 0.27, 0.50, 1.29, 5.32, 8.85]  # mJy (for 16*12m antennas, 1 minute, 8 GHz, 2pol)
    preaverageDictionary = {}
    preaverageDictionary[spw] = {}
    preaverageDictionary['vis'] = vis
    preaverageDictionary['field'] = field
    if (computeUnflaggedAntennas):
        mykey = 'unflaggedAntennas'
    else:
        mykey = 'totalAntennas'
    preaverageDictionary[mykey] = nAntennas
    preaverageDictionary['fieldname'] = fieldname
    nBaselines = nAntennas-1 # for an antenna-based solution
    snrs = {}
    bandwidthSwitching = {}
    mydict = {}
    widestSpwBandwidth = 0
    widestSpw = -1
    for spw in observeTargetSpws:
        if (bandwidths[spw] > widestSpwBandwidth):
            widestSpwBandwidth = bandwidths[spw]
            widestSpw = spw
    for spw in observeTargetSpws:
        obsspw = spw
        if (spw not in gaincalSpws):
            # If this spw was not observed on the phase calibrator, then use the widest 
            # spw from the same baseband that *was* observed on the phase calibrator
            # Ignore band-2-band possibility for now
            bestBandwidth = -1
            for gspw in gaincalSpws:
                if (basebands[gspw] == basebands[spw]):
                    if (bandwidths[gspw] > bestBandwidth):
                        bestBandwidth = bandwidths[gspw]
                        bestSpwMatch = gspw
            print "This is a bandwidth switching project (spw %d matched to spw %d)" % (spw, bestSpwMatch)
            spw = bestSpwMatch
        mydict[spw] = {}
        bandwidthSwitching[obsspw] = spw
        if verbose: print "receiverBand[spw=%d] = %s" % (spw, str(receiverBand[spw]))
        idx = band_name.index(str(receiverBand[spw]))
        relativeTsys = tsysDictionary[spw] / tsys_nominal[idx]
        if verbose: print "minutes[%d] = %f" % (spw, minutes[spw])
        timeFactor = 1 / np.sqrt(minutes[spw])
        arraySizeFactor = np.sqrt(16*15/2.)/np.sqrt(nBaselines)
        preaverageDictionary[spw] = 0
        areaFactor = 1.0
        if sevenMeterAntennasMajority(mymsmd=mymsmd):
            areaFactor = (12./7.)**2  # scale by antenna collecting area
            if (obsspw == observeTargetSpws[0]):
                print "This is an ACA 7m dataset." 
        bandwidthFactor = np.sqrt(8.0e9/(np.min([bandwidths[spw],maxEffectiveBandwidthPerBaseband]))) #  scale by chan bandwidth
        aggregateBandwidthFactor = np.sqrt(8.0e9/aggregateBandwidth)
        polarizationFactor = np.sqrt(2)  # scale to single polarization solutions
        factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                 bandwidthFactor * polarizationFactor
        sensitivity = sensitivities[idx] * factor
        factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                 aggregateBandwidthFactor * polarizationFactor
        aggregateBandwidthSensitivity = sensitivities[idx] * factor
#        print "(%f) %f  %f  %f  %f  %f  %f = %f" % (sensitivities[idx],relativeTsys, timeFactor, arraySizeFactor, areaFactor, bandwidthFactor, polarizationFactor, factor)
        snrPerSpw = fluxDensity[spw]*1000 / sensitivity # convert from mJy to Jy
        snrs[spw] = snrPerSpw
        mydict[spw]['snr'] = snrPerSpw
        mydict[spw]['meanFreq'] = meanfreqs[spw]
        mydict[spw]['medianTsys'] = tsysDictionary[spw]
        mydict[spw]['Tsys_spw'] = tsysspw[spw]
        mydict[spw]['bandwidth'] = bandwidths[spw]
        mydict[spw]['bandwidth_effective'] = np.min([bandwidths[spw], maxEffectiveBandwidthPerBaseband])
        mydict[spw]['snr_aggregate'] = fluxDensity[spw]*1000 / aggregateBandwidthSensitivity 
        mydict[spw]['calibrator_flux_density'] = fluxDensity[spw]
        mydict[spw]['solint_inf_seconds'] = minutes[spw]*60
        mydict['aggregate_bandwidth'] = np.min([aggregateBandwidth, maxEffectiveBandwidthPerBaseband*nbasebands])
        mydict['calibrator'] = fieldname
        if (spw == obsspw):
            # Then it is not a bandwidth-switching dataset, so compute snr in widest spw
            widestSpwBandwidthFactor = np.sqrt(8.0e9/widestSpwBandwidth)
            factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                widestSpwBandwidthFactor * polarizationFactor
            widestSpwBandwidthSensitivity = sensitivities[idx] * factor
            mydict[spw]['snr_widest_spw'] = fluxDensity[spw]*1000 / widestSpwBandwidthSensitivity
            mydict[spw]['widest_spw_bandwidth'] = widestSpwBandwidth
        else:
            mydict[spw]['snr_widest_spw'] = 0
    if (outputfile != ''):
        if outputfile == True:
            outputfile = vis+'.gaincalSNR.txt'
        output = open(outputfile,'w')
    for spw in observeTargetSpws:  
        calspw = bandwidthSwitching[spw]
        if (mydict[calspw]['snr'] >= requiredSnr):
            if (spw != calspw):
                mydict[calspw]['status'] = 'normal_bw_switching'
            else:
                mydict[calspw]['status'] = 'normal'
            t = "spw %2d (%4.0fMHz) calibrated by spw %d has sufficient S/N: %f" % (spw, bandwidths[spw]*1e-6, calspw, mydict[calspw]['snr'])
        elif (mydict[calspw]['snr_widest_spw'] >= requiredSnr):
            t = "spw %2d (%4.0fMHz) calibrated by widest spw (%d: bandwidth=%4.0fMHz) has sufficient S/N: %.1f" % (spw, bandwidths[spw]*1e-6, widestSpw, widestSpwBandwidth*1e-6, mydict[calspw]['snr_widest_spw'])
            mydict[calspw]['status'] = 'spwmap'
        elif (mydict[calspw]['snr_aggregate'] >= minSnr):
            t = "spw %2d (%4.0fMHz) calibrated by aggregate bandwidth (%4.0fMHz) has sufficient S/N: %.1f" % (spw, bandwidths[spw]*1e-6, aggregateBandwidth*1e-6, mydict[calspw]['snr_aggregate'])
            mydict[calspw]['status'] = 'combine_spw'
        elif (mydict[calspw]['medianTsys'] <= 0):
            t = "spw %2d (%4.0fMHz) has a negative median Tsys: there must be a problem in the data" % (spw,bandwidths[spw]*1e-6)
        else:
            t = "spw %2d (%4.0fMHz): Even aggregate bandwidth is insufficient (SNR<%.0f).  QA2 Fail!" % (spw,bandwidths[spw]*1e-6,minSnr)
            mydict[calspw]['status'] = 'starved'
        print t
        if (outputfile != ''):
            output.write(t+'\n')
        if (spw != calspw):
            # Then it is a bandwidth-switching dataset, so remove the snr_widest_spw key
            mydict[calspw].pop('snr_widest_spw',None)
    mymsmd.close()
    if (outputfile != ''):
        output.close()
        print "Wrote output file: ", outputfile
    return(mydict)

#============================================

# modified from aU.gaincalSNR by Remy
def bpcalSNR(vis, tsysTable='', flux=None, field=None, 
               intent='CALIBRATE_BANDPASS', spw=None, requiredSnr=20, 
               computeUnflaggedAntennas=False, edgeFraction=0.03125, 
               verbose=False, debugTsysspwmap=False, tsysChanTol=1,
               atmcal=None):
    """
    Computes the per-antenna SNR expected for gaincal for each spw
    on a per-spw basis and recommends a solint, and whether combining the spw is 
    recommended
    Required inputs:
       vis: the measurement set
    Optional inputs:
       tsysTable: if present, it is only used for tsysspwmap
       flux: the flux density value to use (Jy) (default=query ALMA catalog for vis date)
       field: the field ID or name to use (default=the first BP calibrator)
       intent: the intent to use for the calibrator (instead of CALIBRATE_BANDPASS)
       spw: the spw or spw list to make predictions for (default=all with OBSERVE_TARGET)
       requiredSnr: threshold for which to make decisions
       computeUnflaggedAntennas: use the agentflagger tool to exclude fully flagged 
            antennas from the sensitivity calculation
       edgeFraction: the fraction of BW to ignore on each edge of a TDM spw
                     .03125 corresponds to central 1875 MHz
       tsysChanTol: only used if tsysTable is present
       atmcal: an instance of class Atmcal; if None, then run Atmcal
               if False, then first try the faster, less robust method
       
    Returns: a dictionary keyed by spw ID
    -Todd Hunter
    """
    if (tsysTable != ''):
        from almahelpers_localcopy import tsysspwmap
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return

    maxEffectiveBandwidthPerBaseband = 2e9*(1-2.*edgeFraction)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    # 0) Get the number of antennas in the dataset. In principle, this should be the number 
    #    of unflagged antennas on the PHASE calibrator.   Here we have the simpler option 
    #    to compute the number of completely unflagged antennas.
    if (computeUnflaggedAntennas):
        try:
            # agent flagger will bomb if you don't have write privilege to the ms
            unflaggedAntennas, flaggedAntennas = getUnflaggedAntennas(vis)
            nAntennas = len(unflaggedAntennas)
        except:
            print "Continuing onward assuming no antennas are flagged."
            nAntennas = mymsmd.nantennas()
            computeUnflaggedAntennas = False
    else:
        nAntennas = mymsmd.nantennas()

    # 1) identify the (first) bp calibrator from the dataset
    if (field == None):
        allfields = mymsmd.fieldsforintent('*%s*' % intent)
        # the default bp calibrator to use is the first one
        field = allfields[0]
        fieldnames = mymsmd.namesforfields(allfields)
        fieldname = fieldnames[0]
        if (len(allfields) > 1):
            # If there are more than one bp calibrators, then
            # pick the first one that does NOT also have observe_target intent.
            # If all have both intents, then continue to use the first one.
            for i,fieldname in enumerate(fieldnames[1:]):
                if ('OBSERVE_TARGET#ON_SOURCE' not in mymsmd.intentsforfield(allfields[i+1])):
                    break
        if verbose: print "Choosing field = %d = %s" % (field, fieldname)
    elif (type(field) == int):
        fieldname = mymsmd.namesforfields(field)[0]
    else:
        if (field.isdigit()):
            fieldname = mymsmd.namesforfields(str(field))[0]
        else:
            print "Unparsable field string"
            return

    # 2) Get the OBSERVE_TARGET spw(s) to process. 
    if (spw == None):
        observeTargetSpws = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('*OBSERVE_TARGET*'))
        if verbose: print "Choosing OBSERVE_TARGET spws = ", observeTargetSpws
    else:
        observeTargetSpws = spw
        if (type(spw) == int):
            observeTargetSpws = [spw]
    # RI should be the intent from the user here
    bpSpws = np.intersect1d(mymsmd.almaspws(tdm=True,fdm=True),mymsmd.spwsforintent('*%s*' % intent))
    allSpws = np.union1d(bpSpws,observeTargetSpws)

    # 3) Get the mean frequency, channel width, and scans of the bp
    #    target observations for each bp spw. Compute total on-source time.
    myms = createCasaTool(mstool)
    myms.open(vis)
    scanInfo = myms.getscansummary()  # this is keyed by scan number, then integration within it
    myms.close()

    meanfreqs = {}
    basebands = {}
    chanwidths = {}
    bandwidths = {}
    nchan = {}
    receiverBand = {}
    seconds = {}
    integration = {}
    scans = {}
    for spw in bpSpws:
        meanfreqs[spw] = mymsmd.meanfreq(spw)
        chanwidths[spw] = np.abs(np.median(mymsmd.chanwidths(spw)))
        bandwidths[spw] = mymsmd.bandwidths(spw)
        basebands[spw] = mymsmd.baseband(spw)
        nchan[spw] = mymsmd.nchan(spw)
        if verbose: print "meanfreqs[spw=%d] = %f" % (spw,meanfreqs[spw])
        receiverBand[spw] = bandforspw(spw, mymsmd=mymsmd)
        scans[spw] = np.intersect1d(np.intersect1d(mymsmd.scansforintent('*%s*'%intent), mymsmd.scansforfield(field)),mymsmd.scansforspw(spw))
        if (verbose): print "Scans for spw %d: %s" % (spw,str(scans[spw]))

        # Get the exposure time on the cal. In principle, this should be the time 
        # weighted by percentage of unflagged data.  Also, the method below will
        # include sub-scan latency, but it is simpler and faster than running au.timeOnSource.
        timesforscans = []
        intsforscans = []
        for scan in scans[spw]:
            timesforscan = mymsmd.timesforscan(scan)
            timesforscans.append(np.max(timesforscan)-np.min(timesforscan))
            intsforscan = []
            for integ in sorted(scanInfo[str(scan)].keys()):
                if (spw in scanInfo[str(scan)][integ]['SpwIds']):
                    intsforscan.append(scanInfo[str(scan)][integ]['IntegrationTime'])
            intsforscans.append(np.min(intsforscan))

        # RI take max scan length - if BP=Pcal, could use combine='scan', but 
        # we expect there to be only one scan anyway, so this will usually be a NOP
        seconds[spw] = np.max(timesforscans)
        # RI for integration time, take min
        integration[spw] = np.min(intsforscans) # leave in seconds

    for spw in observeTargetSpws:
        meanfreqs[spw] = mymsmd.meanfreq(spw)
        chanwidths[spw] = np.abs(np.median(mymsmd.chanwidths(spw)))
        bandwidths[spw] = mymsmd.bandwidths(spw)
        nchan[spw] = mymsmd.nchan(spw)
        basebands[spw] = mymsmd.baseband(spw)
    uniqueBasebands = np.unique(basebands.values()) 
    nbasebands = len(uniqueBasebands)

    # 4) Get the flux density from ALMA database.  Could alternatively get from 
    #    flux.csv if run from the pipeline, assuming those have been previously 
    #    corrected by au.getALMAFluxcsv.
    fluxDensity = {}
    frequency = {}
    if (flux == None):
        for spw in allSpws:
            if (verbose): print "Calling getALMAFluxForMS('%s','%s',spw=%d, silent=True)" % (vis,fieldname,spw)
            mydict = getALMAFluxForMS(vis, fieldname, spw=spw, silent=True) 
            if (fieldname not in mydict.keys()):
                print "No ALMA flux density measurements for %s in the ALMA catalog." % (fieldname)
                print "Use the flux parameter to specify its flux density."
                return
            fluxDensity[spw] = mydict[fieldname]['fluxDensity']
            frequency[spw] = mydict[fieldname]['frequency']
            if verbose: 
                print "Flux density in spw %d = %f Jy." % (spw,fluxDensity[spw])
    else:
        for spw in allSpws:
            fluxDensity[spw] = flux
            frequency[spw] = mymsmd.meanfreq(spw)
    mymsmd.close()
    aggregateBandwidth = computeAggregateBandwidth(vis, bpSpws)

    # 5) Get the median Tsys on the bp calibrator in each spw for the first scan
    tsysDictionary = {} # keys: CALIBRATE_PHASE spws, values: corresponding Tsys values
    tsysspw = {}
    for spw in bpSpws:
        # If there are multiple scans for an spw, then simply use the Tsys of the first scan
        if (tsysTable != ''):
            if verbose: print "Calling tsysspwmap('%s', '%s', tsysChanTol=%d, field='%s')" % (vis,tsysTable,tsysChanTol,str(field))
            myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol, field=str(field))
            if (spw >= len(myspw)):
                if verbose: print "Calling tsysspwmap('%s', '%s', tsysChanTol=%d)" % (vis,tsysTable,tsysChanTol)
                myspw = tsysspwmap(vis, tsysTable, tsysChanTol=tsysChanTol)
                if (spw >= len(myspw)):
                    print "spw %d not in %s" % (spw, str(myspw))
                    return
            myspw = myspw[spw]
        else:
            if verbose: print "Calling tsysspwmapWithNoTable('%s', %d, %d, ['OBSERVE_TARGET','DELAY'])" % (vis,field,spw)
            myspw = tsysspwmapWithNoTable(vis, field, spw, alternateIntents='OBSERVE_TARGET', debug=debugTsysspwmap)
        if (myspw == None): return
        if verbose: print "Choosing Tsys spw %d for spw %d" % (myspw, spw)
        mymsmd.open(vis)
        tsysspw[spw] = myspw
        tsysscans = np.intersect1d(mymsmd.scansforspw(myspw), 
                                   mymsmd.scansforintent('*ATMOSPHERE*'))
        if verbose: print "Tsys scans = ", tsysscans
        mymsmd.close()
        # Get the median Tsys for the first Tsys scan that matches the CALIBRATE_PHASE spw
        # and is actually in the SYSCAL table (sometimes they are missing!)
        for tsysscan in tsysscans:
            if verbose: print "Calling au.plotTsys('%s',doplot=False,scan=%d, spw=%d)" % (vis,tsysscan,myspw)
            mydict,atmcal = plotTsys(vis, doplot=False, scan=tsysscan, spw=myspw, atmcal=atmcal, verbose=verbose)
            if (mydict == None):
                return
            if (myspw in mydict.keys()):
                break
        # Transfer this median Tsys to the dictionary that is keyed by the CALIBRATE_PHASE spws
        if (myspw not in mydict.keys()):
            print "spw %d not in %s" % (myspw, str(mydict.keys()))
            print "spw %d is not in the SYSCAL table for any of the scans %s, meaning that Tsys was not observed on the %s target: %s" % (myspw,str(tsysscans),intent,fieldname)
            return
        tsysDictionary[spw] = mydict[myspw]

    # 6) compute the expected channel-averaged SNR
    # Use the same approach as in es.sensitivity_calculator
    band_name = ['3','4','6','7','8','9','10']
    tsys_nominal = [75.0, 86.0, 90.0, 150.0, 387.0, 1200.0, 1515.0]
    sensitivities = [0.20, 0.24, 0.27, 0.50, 1.29, 5.32, 8.85]  # mJy (for 16*12m antennas, 1 minute, 8 GHz, 2pol)
    preaverageDictionary = {}
    preaverageDictionary[spw] = {}
    preaverageDictionary['vis'] = vis
    preaverageDictionary['field'] = field
    if (computeUnflaggedAntennas):
        mykey = 'unflaggedAntennas'
    else:
        mykey = 'totalAntennas'
    preaverageDictionary[mykey] = nAntennas
    preaverageDictionary['fieldname'] = fieldname
    nBaselines = nAntennas-1 # for an antenna-based solution
    snrs = {}
    bandwidthSwitching = {}
    mydict = {}
    widestSpwBandwidth = 0
    widestSpw = -1
    for spw in observeTargetSpws:
        if (bandwidths[spw] > widestSpwBandwidth):
            widestSpwBandwidth = bandwidths[spw]
            widestSpw = spw
    for spw in observeTargetSpws:
        obsspw = spw
        if (spw not in bpSpws):
            # If this spw was not observed on the bp calibrator, then use the widest 
            # spw from the same baseband that *was* observed on the phase calibrator
            # Ignore band-2-band possibility for now
            bestBandwidth = -1
            for gspw in bpSpws:
                if (basebands[gspw] == basebands[spw]):
                    if (bandwidths[gspw] > bestBandwidth):
                        bestBandwidth = bandwidths[gspw]
                        bestSpwMatch = gspw
            print "This is a bandwidth switching project (spw %d matched to spw %d)" % (spw, bestSpwMatch)
            spw = bestSpwMatch
        mydict[spw] = {}
        bandwidthSwitching[obsspw] = spw
        if verbose: print "receiverBand[spw=%d] = %s" % (spw, str(receiverBand[spw]))
        idx = band_name.index(str(receiverBand[spw]))
        relativeTsys = tsysDictionary[spw] / tsys_nominal[idx]
        # RI need to scale this to INT time, not total time
        if verbose: print "integration[%d] = %f" % (spw, integration[spw])
        timeFactor = 1 / np.sqrt(integration[spw]/60.)
        arraySizeFactor = np.sqrt(16*15/2.)/np.sqrt(nBaselines)
        preaverageDictionary[spw] = 0
        areaFactor = 1.0
        if sevenMeterAntennasMajority(vis):
            areaFactor = (12./7.)**2  # scale by antenna collecting area
            if (obsspw == observeTargetSpws[0]):
                print "This is an ACA 7m dataset." 
        bandwidthFactor = np.sqrt(8.0e9/(np.min([bandwidths[spw],maxEffectiveBandwidthPerBaseband]))) #  scale by chan bandwidth
        aggregateBandwidthFactor = np.sqrt(8.0e9/aggregateBandwidth)
        polarizationFactor = np.sqrt(2)  # scale to single polarization solutions
# calculate snr(int) and snr(scan) down here, and then say what solint is 
# required assuming snr propto (sqrt(solint)), with max solint=scan.
        factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                 bandwidthFactor * polarizationFactor
        sensitivity = sensitivities[idx] * factor
        factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                 aggregateBandwidthFactor * polarizationFactor
        aggregateBandwidthSensitivity = sensitivities[idx] * factor
#        print "(%f) %f  %f  %f  %f  %f  %f = %f" % (sensitivities[idx],relativeTsys, timeFactor, arraySizeFactor, areaFactor, bandwidthFactor, polarizationFactor, factor)
        snrPerSpw = fluxDensity[spw]*1000 / sensitivity # convert from mJy to Jy
        snrs[spw] = snrPerSpw
        mydict[spw]['integration'] = integration[spw]
        mydict[spw]['solint'] = integration[spw]
        mydict[spw]['scantime'] = seconds[spw]
        mydict[spw]['snr_int'] = snrPerSpw
        mydict[spw]['meanFreq'] = meanfreqs[spw]
        mydict[spw]['medianTsys'] = tsysDictionary[spw]
        mydict[spw]['Tsys_spw'] = tsysspw[spw]
        mydict[spw]['bandwidth'] = bandwidths[spw]
        mydict[spw]['bandwidth_effective'] = np.min([bandwidths[spw], maxEffectiveBandwidthPerBaseband])
        mydict[spw]['snr_aggregate'] = fluxDensity[spw]*1000 / aggregateBandwidthSensitivity 
        mydict[spw]['calibrator_flux_density'] = fluxDensity[spw]
        mydict['aggregate_bandwidth'] = np.min([aggregateBandwidth, maxEffectiveBandwidthPerBaseband*nbasebands])
        mydict['calibrator'] = fieldname
        if (spw == obsspw):
            # Then it is not a bandwidth-switching dataset, so compute snr in widest spw
            widestSpwBandwidthFactor = np.sqrt(8.0e9/widestSpwBandwidth)
            factor = relativeTsys * timeFactor * arraySizeFactor * areaFactor * \
                widestSpwBandwidthFactor * polarizationFactor
            widestSpwBandwidthSensitivity = sensitivities[idx] * factor
            mydict[spw]['snr_widest_spw'] = fluxDensity[spw]*1000 / widestSpwBandwidthSensitivity
            mydict[spw]['widest_spw_bandwidth'] = widestSpwBandwidth
        else:
            mydict[spw]['snr_widest_spw'] = 0

    for spw in observeTargetSpws:  
        calspw = bandwidthSwitching[spw]
        if (mydict[calspw]['snr_int'] >= requiredSnr):
            if (spw != calspw):
                mydict[calspw]['status'] = 'normal_bw_switching'
            else:
                mydict[calspw]['status'] = 'normal'
            print "spw %2d (%4.0fMHz) calibrated by spw %d has sufficient S/N for solint=INT=%fs: %f" % (spw, bandwidths[spw]*1e-6, calspw, mydict[calspw]['integration'],mydict[calspw]['snr_int'])
        else:
            if verbose: print "spw %2d (%4.0fMHz) calibrated by spw %d has INsufficient S/N for solint=INT=%fs: %f" % (spw, bandwidths[spw]*1e-6, calspw, mydict[calspw]['integration'],mydict[calspw]['snr_int'])

            solint = mydict[calspw]['integration']
            solint_required = (requiredSnr/mydict[calspw]['snr_int'])**2 * solint
            scantime = mydict[calspw]['scantime']
            if solint_required <= scantime:                                
                print "spw %2d (%4.0fMHz) calibrated by spw %d has sufficient S/N for solint=%fs (scan=%fs): %f" % (spw, bandwidths[spw]*1e-6, calspw, solint_required, scantime, mydict[calspw]['snr_int']*sqrt(solint_required/solint))
                mydict[calspw]['solint'] = solint_required
                mydict[calspw]['status'] = 'longersolint'
            elif verbose:
                print "spw %2d (%4.0fMHz) calibrated by spw %d has INsufficient S/N for solint=%fs (scan=%fs): %f" % (spw, bandwidths[spw]*1e-6, calspw, solint_required, scantime, mydict[calspw]['snr_int']*sqrt(solint_required/solint))
                    
            if (mydict[calspw]['snr_widest_spw'] >= requiredSnr):
                print "spw %2d (%4.0fMHz) calibrated by widest spw (%d: bandwidth=%4.0fMHz) has sufficient S/N for solint=INT=%fs: %.1f" % (spw, bandwidths[spw]*1e-6, widestSpw, widestSpwBandwidth*1e-6, solint, mydict[calspw]['snr_widest_spw'])
                mydict[calspw]['status'] = 'spwmap'

            else:
                if verbose: print "spw %2d (%4.0fMHz) calibrated by widest spw (%d: bandwidth=%4.0fMHz) has INsufficient S/N for solint=INT=%fs: %.1f" % (spw, bandwidths[spw]*1e-6, widestSpw, widestSpwBandwidth*1e-6, solint, mydict[calspw]['snr_widest_spw'])
                
                solint_required = (requiredSnr/mydict[calspw]['snr_widest_spw'])**2 * solint            
                if solint_required <= scantime:                                
                    print "spw %2d (%4.0fMHz) calibrated by widest spw (%d: bandwidth=%4.0fMHz) has sufficient S/N for solint=%fs (scan=%fs): %.1f" % (spw, bandwidths[spw]*1e-6, widestSpw, widestSpwBandwidth*1e-6, solint_required, scantime, mydict[calspw]['snr_widest_spw']*sqrt(solint_required/solint))
                    mydict[calspw]['solint'] = solint_required
                    mydict[calspw]['status'] = 'spwmap_and_longersolint'
                elif verbose:                     
                    print "spw %2d (%4.0fMHz) calibrated by widest spw (%d: bandwidth=%4.0fMHz) has INsufficient S/N for solint=%fs (scan=%fs): %.1f" % (spw, bandwidths[spw]*1e-6, widestSpw, widestSpwBandwidth*1e-6, solint_required, scantime, mydict[calspw]['snr_widest_spw']*sqrt(solint_required/solint))


                if (mydict[calspw]['snr_aggregate'] >= requiredSnr):
                    print "spw %2d (%4.0fMHz) calibrated by aggregate bandwidth (%4.0fMHz) has sufficient S/N for solint=INT=%fs: %.1f" % (spw, bandwidths[spw]*1e-6, aggregateBandwidth*1e-6,  solint, mydict[calspw]['snr_aggregate'])
                    mydict[calspw]['status'] = 'combine_spw'
                else:
                    if verbose:
                       print "spw %2d (%4.0fMHz) calibrated by aggregate bandwidth (%4.0fMHz) has INsufficient S/N for solint=INT=%fs: %.1f" % (spw, bandwidths[spw]*1e-6, aggregateBandwidth*1e-6,  solint, mydict[calspw]['snr_aggregate'])

                    solint_required = (requiredSnr/mydict[calspw]['snr_aggregate'])**2 * solint     
                    if solint_required < scantime:
                        print "spw %2d (%4.0fMHz) calibrated by aggregate bandwidth (%4.0fMHz) has sufficient S/N for solint=%fs (scan=%fs): %.1f" % (spw, bandwidths[spw]*1e-6, aggregateBandwidth*1e-6, solint_required, scantime, mydict[calspw]['snr_aggregate']*sqrt(solint_required/solint))
                        mydict[calspw]['solint'] = solint_required
                        mydict[calspw]['status'] = 'combine_spw_and_longersolint'
                    else:
                        if verbose:
                            print "spw %2d (%4.0fMHz) calibrated by aggregate bandwidth (%4.0fMHz) has INsufficient S/N for solint=%fs (scan=%fs): %.1f" % (spw, bandwidths[spw]*1e-6, aggregateBandwidth*1e-6, solint_required, scantime, mydict[calspw]['snr_aggregate']*sqrt(solint_required/solint))

                        print  "spw %2d (%4.0fMHz): Nothing can help this data." % (spw,bandwidths[spw]*1e-6)
                        mydict[calspw]['status'] = 'starved'

        if (spw != calspw):
            # Then it is a bandwidth-switching dataset, so remove the snr_widest_spw key
            mydict[calspw].pop('snr_widest_spw',None)

    return(mydict)


def wvrCorrelation(vis, spw=None, antenna=0, field=None, sigma=3, plotfile='',
                   scaleAstronomicalReceiver=False, pwv=None, normalizeToWVR3=False,
                   buildpdf=False, verbose=False, panels=1):
    """
    Computes the covariance between the time series of each of the WVR
    channels with the specified channel-averaged spw, normalized by the
    variance of the WVR channel.  This is meant to explore the conditions in
    which the WVR discrepancy is high to see if it is correlated with clouds.
    Inputs:
    spw: spw ID (integer or string), if None then use first science spw
    antenna: antenna ID or name or list.  '' ==> all antennas
    sigma: threshold to clip outlier points in the astronomical receiver datastream
    pwv: the pwv (in mm) for the observation, in case ASDM_CALWVR is not present
    normalizeToWVR3: if True, normalize astronomical data to Tsky of WVR 3
        if False, normalize to Tsky of the astronomical spw
    scaleAstronomicalSignal: if True, then magnify the black trace to occupy half
         the vertical scale (in order to better view small time variations)
    panels: 1 or 2, if 2 then show the Tsky in the lower panel
    Returns:
    The maximum correlation value of the 4 WVR channels.
    If more than one antenna, then return the median of the antenna maxima.
    Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find vis = ", vis
        return
    if (spw is not None):
        spw = int(spw)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (spw == None):
        spwlist = mymsmd.spwsforintent('*OBSERVE_TARGET*')
        chanavgspws = mymsmd.almaspws(chavg=True)
        spwlist = np.intersect1d(spwlist,chanavgspws)
        if (len(spwlist) < 1):
            print "No science spw found, use the spw argument to specify an spw."
            return
        spw = spwlist[0]
        print "Using spw ", spw
    nchan = mymsmd.nchan(spw)
    spwfreq = mymsmd.meanfreq(spw)*1e-9
    wvrspw = mymsmd.almaspws(wvr=True)[0]
    chanavgspws = mymsmd.almaspws(chavg=True)
    antennaNames = mymsmd.antennanames()
    mymsmd.close()
    if (nchan != 1):
        print "Comparison spw must be a single-channel spw. Available spws = ", chanavgspws
        return
    antennaList = parseAntenna(vis, antenna)
    maxCoefficient = []
    pngs = []
    for aid,antenna in enumerate(antennaList):
        print "Working on antenna %s (%d/%d)" % (antennaNames[antenna],aid+1,len(antennaList))
        v = Visibility(vis,antenna1=antenna,antenna2=antenna,spwID=spw,field=field,cross_auto_all='auto')
        rxData = v.amp[0] # take first polarization only
        rxTimestamps = v.specTime
        rxData = rxData[0] # take first (i.e. the only) channel

        # get wvr data
        v.setSpwID(wvrspw)
        wvrMedians = []
        wvrData4chan = v.amp[0]  # take first (i.e. the only) polarization only

        # scale receiver total power to outermost WVR channel
        if verbose: print "Median of astronomical data = ", np.median(rxData)
        if (normalizeToWVR3):
            tsky = np.median(wvrData4chan[3])
            rxData *= tsky/np.median(rxData)
            if verbose: print "Scaling median of astronomical data to Tsky of WVR channel 3 (%.1fK)." % (tsky)
        else:
            tskyfreq, tsky = computeTskyForSpw(vis,spw=spw)
            rxData *= np.median(tsky/np.median(rxData))
            if verbose: print "Scaling median of astronomical data to Tsky model for this spw (%.1fK)." % (tsky)
        rxDataMedian = np.median(rxData)
        rxData = rxData - rxDataMedian

        # drop outlier data from astronomical receiver
        idx = np.where(np.abs(rxData) < sigma*MAD(rxData))
        rxDataAll = rxData[idx]
        rxTimestamps = rxTimestamps[idx]

        coefficient = []
        medians = []
        pb.clf()
        pb.hold(True)
        c = ['b','g','r','m']
        for wvrchannel in range(4):
            wvrData = wvrData4chan[wvrchannel]
            wvrTimestamps = v.specTime
            
            # trim off wvr data before and after the receiver data
            idx = np.where(wvrTimestamps>np.min(rxTimestamps))[0][0]
            wvrData = wvrData[idx:]
            wvrTimestamps = wvrTimestamps[idx:]
            idx = np.where(wvrTimestamps<np.max(rxTimestamps))[0][-1]
            wvrDataGood = wvrData[:idx]
            wvrTimestamps = wvrTimestamps[:idx]
            wvrMedians.append(np.median(wvrDataGood))
            wvrData = wvrDataGood - np.median(wvrDataGood)
    #        print "ch%d: len(wvrData) = %d" % (wvrchannel, len(wvrData))

            # drop outlier data from WVR
            idx = np.where(np.abs(wvrData) < sigma*MAD(wvrData))[0]
            if (len(idx) < 1):
                print "All WVR ch%d data from %s are outliers" % (wvrchannel,antennaNames[antenna])
                skipAntenna = True
                break
            skipAntenna = False
            wvrData = wvrData[idx]
#            print "ch%d: len(wvrData) = %d" % (wvrchannel, len(wvrData))
            medians.append(np.median(wvrData))
            wvrTimestamps = wvrTimestamps[idx]
            lenWvrTimestamps = len(wvrTimestamps)
            
            # should really first drop any wvrTimestamps not within 10s of an astronomy point
            diffs = rxTimestamps[1:]-rxTimestamps[:-1]
            idx = np.where(diffs > 3*np.median(diffs))[0]
            for i in idx:
                keepBefore = np.where(wvrTimestamps <= rxTimestamps[i]+1)[0]
                keepAfter = np.where(wvrTimestamps >= rxTimestamps[i+1]-1)[0]
                idx2 = np.union1d(keepBefore,keepAfter)
                wvrData = wvrData[idx2]
                wvrTimestamps = wvrTimestamps[idx2]
#            print "Dropped %d WVR points that are far from astronomy spw points" % (lenWvrTimestamps-len(wvrTimestamps))
            wvrtt = pb.date2num(mjdSecondsListToDateTime(wvrTimestamps))

            adesc = pb.subplot(panels,1,1)
            pb.plot_date(wvrtt, wvrData, c[wvrchannel]+'.', markeredgecolor=c[wvrchannel])
            if (panels > 1):
                adesc = pb.subplot(panels,1,panels)
                pb.plot_date(wvrtt, wvrData+wvrMedians[-1], c[wvrchannel]+'.', markeredgecolor=c[wvrchannel])

            # upsample the astronomy data
            # Must run this everytime, since the number of wvrTimestamps may differ between
            # channels
            rxData = interpolateSpectrum(rxTimestamps, rxDataAll, wvrTimestamps)
            
            covariance = np.mean(rxData * wvrData)
            coefficient.append(covariance / np.std(wvrData+np.median(wvrDataGood))**2)
        if (skipAntenna): continue
        # Draw labels in order of high to low median (to prevent overlap)
#        idx = np.argsort(medians)
        adesc = pb.subplot(panels, 1, 1)
        for wvrchannel in range(4):
            pb.text(0.9, 0.3+wvrchannel*0.1, '%.3f'%(coefficient[wvrchannel]),color=c[wvrchannel],transform=adesc.transAxes)
            pb.text(0.01, 0.3+wvrchannel*0.1, 'ch%d:%3.0fK'%(wvrchannel,wvrMedians[wvrchannel]),color=c[wvrchannel],transform=adesc.transAxes)
        pb.text(0.01, 0.7, 'rx:%3.0fK'%(rxDataMedian),color='k',transform=adesc.transAxes)
        rxtt = pb.date2num(mjdSecondsListToDateTime(rxTimestamps))
        if (scaleAstronomicalReceiver):
            rxDataAll *= np.min(np.abs(pb.ylim()))*0.5/np.max(np.abs(rxDataAll))
        pb.plot_date(rxtt, rxDataAll, 'k.')
        x0,x1 = pb.xlim()
        xrange = x1-x0
        x0 -= xrange*0.18
        x1 += xrange*0.14
        pb.xlim([x0,x1])
        pwv = getMedianPWV(vis)[0]
        pb.xlabel('UT on %s' % (mjdsecToUT(wvrTimestamps[0]).split()[0]))
        pb.ylabel('Residual from median Tsky (K)')
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        pb.title(os.path.basename(vis) + ' %s WVR and spw %d (%.2f GHz) PWV=%.2fmm' % (antennaNames[antenna],spw,spwfreq,pwv), size=11)
        pb.draw()
        if (plotfile != ''):
            if (plotfile == True):
                plotfile = vis + '.wvrCorrelation.%s.spw%02d.png' % (antennaNames[antenna],spw)
            pb.savefig(plotfile)
            print "Plot left in ", plotfile
        maxCoefficient.append(np.max(coefficient))
        if (panels > 1):
            pb.subplot(panels,1,panels)
            pb.plot_date(rxtt, rxDataAll+rxDataMedian, 'k.')
            pb.xlim([x0,x1])
            pb.ylabel('Tsky (K)')

    if (buildpdf and plotfile != ''):
        buildPdfFromPngs(pngs,vis+'.wvrCorrelation.pdf')
    if (len(antennaList) > 1):
        print "max correlations: ", str(maxCoefficient)
    return(np.median(maxCoefficient))

def wvrAmplitudes(vis, field=None, scan=None, sigma=5):
    """
    Computes the median and maximum amplitudes of each of the four WVR
    channels on a per-antenna basis, for the specified field.
    field: ID
    scan: single scan or range as a string, e.g. '1~3' or '3~'
    sigma: the degree by which the value must be discrepant to be flagged
       with a star, sigma=5 catches DA55 and DV13 in uid___A002_X916b15_X1716
    Returns: a dictionary of the median amplitude over antennas, keyed by WVR channel
    - Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (sevenMeterAntennasOnly(vis)):
        print "This is a 7m-only dataset, so there are no WVRs."
        return
    antennaNames = getAntennaNames(vis)
    pol = 0
    medians = {0: [], 1:[], 2:[], 3:[]}
    maxs = {0: [], 1:[], 2:[], 3:[]}
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    wvrspws = mymsmd.almaspws(wvr=True)
    if (len(wvrspws) == 0):
        print "No WVR in this dataset."
        return
    print "Found wvr spw = ", wvrspws[0]
    if (type(scan) == str):
        if (scan[-1] == '~'):
            scan += str(int(np.max(mymsmd.scannumbers())))
            print "Using scans: ", scan
    mymsmd.close()
    for antenna in antennaNames:
        if (antenna.find('CM') >= 0):
            for channel in range(4):
                medians[channel].append(-1)
                maxs[channel].append(-1)
        else:
            v = Visibility(vis,field=field,spwID=wvrspws[0],antenna1=antenna,
                           antenna2=antenna,cross_auto_all='all',scan=scan)
            for channel in range(4):
                medians[channel].append(np.median(v.amp[pol][channel]))
                maxs[channel].append(np.max(v.amp[pol][channel]))
    print "           Channel 0      Channel 1      Channel 2      Channel 3"
    print "  Antenna  Median Maximum Median Maximum Median Maximum Median Maximum"
    outlier = {}
    medianOverAntennas = {}
    for i in range(4):
        outlier[i] = {}
        mad = MAD(medians[i])
        median = np.median(medians[i])
        for antenna in range(len(antennaNames)):
            if (abs(medians[i][antenna]-median) > sigma*mad):
                outlier[i][antenna] = '*'
            else:
                outlier[i][antenna] = ' '
        medianOverAntennas[i] = median
        
    for i,antenna in enumerate(antennaNames):
        if (medians[0][i] < 0):
            print "%2d  %s  No WVR on this antenna" % (i,antenna)
        else:
            print "%2d  %s %s%6.1f %6.1f %s%6.1f %6.1f %s%6.1f %6.1f %s%6.1f %6.1f" % (i,antenna,
                              outlier[0][i],
                              medians[0][i],maxs[0][i],
                              outlier[1][i],
                              medians[1][i],maxs[1][i],
                              outlier[2][i],
                              medians[2][i],maxs[2][i],
                              outlier[3][i],
                              medians[3][i],maxs[3][i])
    return medianOverAntennas

def getAntennaPositionXY(vis):
    """
    Gets local coordinates, names and diameters of antennas in a measurement set.
    Returns: 4 lists: X, Y, antennaName, diameter
    Currently called only by plotWVRDiscrepancy.
    -Todd Hunter
    """
    observatory = getObservatoryName(vis)
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ANTENNA')
    position = mytb.getcol('POSITION')
    diameter = mytb.getcol('DISH_DIAMETER')
    station = mytb.getcol('STATION')
    antenna = mytb.getcol('NAME')
    nant = len(antenna)
    mytb.close()
    if (observatory.find('ALMA') >= 0):
        lon0 = np.radians(ALMA_LONGITUDE)
        lat0 = np.radians(ALMA_LATITUDE)
    else:
        lat0, lon0, name = getObservatoryLatLong(observatory)
        lat0 = np.radians(lat0)
        lon0 = np.radians(lon0)
    plotx = []
    ploty = []
    for i in range (nant):
        xx = position[0][i]
        yy = position[1][i]
        zz = position[2][i]
        elev = sqrt(xx**2+yy**2+zz**2)-6379960.0
        lat = math.asin(zz/sqrt(xx**2+yy**2+zz**2))
        lon = math.atan2(yy, xx)
        zlat = str(lat)+'rad'
        zlon = str(lon)+'rad'
        qlat = call_qa_angle(zlat,prec=8)
        qlon = call_qa_angle(zlon,prec=8)
        qqlat = qlat[0]+qlat[2:]
        qqlon=qlon[0]+qlon[2:]
        n_off = (lat - lat0)*6379960.0
        e_off = (lon - lon0)*6379960.0 * cos(lat) 
        if (observatory.find('ALMA') >= 0):
            n_off += 215.0
            e_off -= 3.0
        plotx.append (e_off)
        ploty.append (n_off)
    return(plotx,ploty,antenna,diameter)

def getWVREfficienciesFromASDM(asdm):
    """
    Gets the WVR efficiencies from the ASDM CalReduction.xml file.
    Dictionary returned is keyed by antenna name and contains values
    for 'serialNumber' and 'coupling'.
    -Todd Hunter
    """
    efficiencies = au_noASDMLibrary.getWVREfficienciesFromASDM(asdm)
    return efficiencies
    
def plotWVRFrequencies(vis, plotfile=''):
    """
    Plots the channel frequencies of each WVR in each antenna.
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    spws = mymsmd.wvrspws()
    antennaNames = mymsmd.antennanames()
    pb.clf()
    for ant,spw in enumerate(spws):
        freqs = mymsmd.chanfreqs(spw)*1e-9
        if (spw == spws[0]):
            mark = '^'
        else:
            mark = 'o'
        pb.plot([ant-1], freqs[:1], 'r'+mark)
        pb.plot([ant-1], freqs[1:2], 'g'+mark)
        pb.plot([ant-1], freqs[2:3], 'b'+mark)
        pb.plot([ant-1], freqs[3:], 'k'+mark)
        if (ant > 0):
            pb.text(ant-1, 185.2, antennaNames[ant-1], rotation=90, size=9, weight='bold',
                    ha='center', va='center')
        else:
            pb.text(ant-1, 185.2, 'nominal', rotation=90, size=9, weight='bold',
                    ha='center', va='center')
    mymsmd.close()
    pb.xlabel('Antenna')
    pb.ylabel('Frequency (GHz)')
    pb.title(vis + ' (%s)'%getObservationStartDate(vis).split()[0])
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = vis + '.wvrfreqs.png'
        pb.savefig(plotfile)
        print "Wrote ", plotfile
    
def plotWVRDiscrepancy(vis,wvrdict=None, wvrlog='',plotfile='',showAntennaId=False):
    """
    Makes a plotants-style plot, but showing the wvr discrepancy beside the antenna name.
    Provide one of the following:
    wvrdict: a dictionary returned from wvrgcal
    wvrlog: a text file containing the wvrgcal results, or the casa log
    -Todd Hunter
    """
    import analyzemscal as amc
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    plotx, ploty, antennaNames, diam = getAntennaPositionXY(vis)
    asdm = vis.split('.ms')[0]
    title = asdm + ' WVR discrepancy'
    if (wvrdict is not None):
        discrepancy = [str(int(round(i))) for i in wvrdict['disc']]
    elif (wvrlog != ''):
        lines, report = amc.extractWvrgcalOutputFromLog(wvrlog, asdm)
        discrepancy = []
        for antennaName in antennaNames:
            for line in lines:
                if (line.find(antennaName)>=0):
                    data = line.split(antennaName)[1]
                    wvr,flag,rms,disc=data.split()
                    discrepancy.append(antennaName+'='+str(int(round(float(disc.strip('\n'))))))
                    break # go onto next antenna
        if (len(discrepancy) != len(antennaNames)):
            print "Did not find all antennas in wvrgcal result"
            return
    else:
        print "You must specify either wvrdict or wvrlog"
        return
    plotAntennaPositionList(plotx, ploty, discrepancy, diam, title,
                            plotfile=plotfile,showAntennaId=showAntennaId)

def wvrgcalStats(vis, statoption='source', outfile=True):
    """
    Runs wvrgcal with statsource set to each source (or field) individually 
    and reports the median of the rms and discrepancy of each run, and the 
    field elevation.
    statoption: 'source' or 'field'
    outfile: Boolean or string
    -Todd Hunter
    """
    if (not useWvrgcal):
        print "This version of CASA is too old to have wvrgcal."
        return
    if casadef.casa_version < casaVersionWithMSMD:
        print "This function is not supported in this old of a CASA."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    mydict = {}
    fieldNumbers = range(mymsmd.nfields())
    if (statoption == 'source'):
        fieldNames = np.unique(mymsmd.namesforfields(fieldNumbers))
        print "Running wvrgcal once for each of %d source IDs." % (len(fieldNames))
        for field in fieldNames:
            caltable = vis+'.'+field+'.wvr'
            if (os.path.exists(caltable)): shutil.rmtree(caltable)
            mydict[field] = wvrgcal(vis, statsource=field, caltable=caltable)
            if not mydict[field]['success']: return
    else:
        print "Running wvrgcal once for each of %d field IDs." % (len(fieldNumbers))
        for field in fieldNumbers:
            mydict[field] = wvrgcal(vis, statfield=field, caltable=caltable)
    caltable = vis+'.allfields.wvr'
    if (os.path.exists(caltable)): shutil.rmtree(caltable)
    print "Running wvrgcal for the combined dataset."
    mydict['allfields'] = wvrgcal(vis, statsource='', caltable=caltable)
    if (outfile):
        f = open(vis+'.wvrgcalStats','w')
    outline = "Field  Elevation(deg)  MedianRms(um)  MedianDisc(um)  MinDisc(um)  MaxDisc()"
    print outline
    if (outfile):
        f.write(outline + '\n')
    for field in sorted(mydict.keys()):
        if (field == 'allfields'):
            scans = mymsmd.scannumbers()
        else:
            scans = mymsmd.scansforfield(field)
        az,el = listazel(vis, scans, verbose=False)
        if (statoption == 'source'):
            if (field == 'allfields'):
                fieldNumber = -1
            else:
                fieldNumber = mymsmd.fieldsforname(field)[0]
        else:
            if (field == 'allfields'):
                fieldNumber = -1
            else:
                fieldNumber = field
                field = mymsmd.namesforfields(fieldNumber)[0]
        outline = "%2d=%12s  %6.2f  %10.2f  %10.2f  %10.2f  %10.2f" % (fieldNumber, field, el,
                                     np.median(mydict[field]['RMS_um']),
                                     np.median(mydict[field]['Disc_um']),
                                     np.min(mydict[field]['Disc_um']),
                                     np.max(mydict[field]['Disc_um'])
                                     )
        print outline
        if (outfile):
            f.write(outline + '\n')
            f.flush()
    mymsmd.close()
    if (outfile):
        f.close()
    
def getIntegrationTime(vis, spw=None, intent='OBSERVE_TARGET#ON_SOURCE', scan=None,
                       method='first', verbose=True, pointingTable=False):
    """
    Note: essentially obsoleted by msmd.exposuretime()
    Uses the ms and msmd tools to get the integration time (in seconds).  If nothing
    is specified, then it will use the first scan that has the OBSERVE_TARGET intent
    (or otherwise specified intent).  Alternatively, the scan can be specified. If
    the spw is not specified, then the first spw that has the OBSERVE_TARGET intent
    is used (ignoring SQLD spws).
    spw: integer or string
    intent: string, can have wildcards, and can be a comma-delimited string
    scan: integer or string
    method: 'first', 'median', 'mean' or 'stdev' (for standard deviation)
    pointingTable: also compute the median of the INTERVAL column in the pointing table
    Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find measurement set."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    methods = ['median','mean','first','stdev']
    if (method not in methods):
        print "invalid method.  available methods are %s" % (str(methods))
        return
    myms = createCasaTool(mstool)
    myms.open(vis)
    scanInfo = myms.getscansummary()  # this is keyed by scan number, then integration within it
    myms.close()
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    allIntents = mymsmd.intents()
    if (intent != ''):
        noData = True
        intents = intent.split(',')
        intent = ''
        for myIntent in intents:
            if (myIntent != intents[0]):
                intent += ','
            if myIntent.find('*') >= 0:
                # match wildcard request with complete intent
                myIntent = myIntent.replace('*','')
                for i in allIntents:
                    if i.find(myIntent) >= 0:
                        myIntent = i
                        break
            intent += myIntent
            if (myIntent.find('#') < 0):
                intent += '#ON_SOURCE'
        intents = intent.split(',')
        for myIntent in intents:
            if (myIntent in allIntents):
                noData = False
        if (noData):
            print "getIntegrationTime(): %s is not an intent in this dataset.  Available intents: %s" % (intent,mymsmd.intents())
            mymsmd.close()
            return
        scans = []
        for myIntent in intents:
            scans += list(mymsmd.scansforintent(myIntent))
    else:
        scans = mymsmd.scannumbers()
    if (scan is not None and scan != ''):
        scan = str(scan)
        if (int(scan) not in scans):
            if (int(scan) not in mymsmd.scannumbers()):
                print "Scan %s is not in the data." % (scan)
            else:
                print "Scan %s does not have intent=%s." % (scan, intent)
            print "The available scans with this intent are %s" % (str(scans))
            return
    else:
        if (len(scans) < 0):
            print "No scans have intent = %s" % (intent)
            return
        scan = str(scans[0])
        if verbose:
            print "Picking scan %s, which is the first with intent=%s" % (scan,intent)
    if (intent != ''):
        spws = []
        for myIntent in intent.split(','):
            spws += list(mymsmd.spwsforintent(myIntent))
        spws = np.array(spws)
        # be sure to not pick any SQLD spws
        spws = np.intersect1d(spws,mymsmd.almaspws(fdm=True,tdm=True))
    else:
        spws = mymsmd.almaspws(fdm=True,tdm=True)
    # The following line is necessary for spectral-scan SBs.
    spws = np.intersect1d(spws,mymsmd.spwsforscan(int(scan)))

    if (spw==None or spw==''):
        integration = '0'
        if (casadef.subversion_revision >= casaRevisionWithAlmaspws):
            spws = np.intersect1d(spws,mymsmd.almaspws(tdm=True,fdm=True,chavg=True,sqld=True))
        else:
            spws = np.setdiff1d(spws,mymsmd.wvrspws())
        if (len(spws) < 1):
            print "There are no spws with intent = %s" % (intent)
            return
        spws = [spws[0]]
    else:
        if (int(spw) not in spws):
            if (int(spw) >= mymsmd.nspw()):
                print "spw %s is not in the dataset" % (str(spw))
            else:
                print "spw %s does not have intent=%s." % (str(spw), intent)
            print "Available spws with this intent = %s" % (str(spws))
            return
        spws = [int(spw)]
    integrationTime = []
    for s in range(len(spws)):
        spw = spws[s]
        for integration in sorted(scanInfo[scan].keys()):
            if (spw in scanInfo[scan][integration]['SpwIds']):
                integrationTime.append(scanInfo[scan][integration]['IntegrationTime'])
                if (method=='first'):
                    break
        if (integrationTime != [] and method=='first'):
            break
    if (integrationTime == []):
        print "No spw with intent = %s is in any integrations of scan %s" % (intent, scan)
        return
    elif (verbose):
        print "Picking spw %d (with %d channels) to determine integration time" % (spw,mymsmd.nchan(spw))
    mymsmd.close()
    if (method == 'median'):
        print "Taking median of %d integrations" % (len(integrationTime))
        seconds = np.median(integrationTime)
    elif (method == 'mean'):
        print "Taking mean of %d integrations" % (len(integrationTime))
        seconds = np.mean(integrationTime)
    elif (method == 'stdev'):
        print "Taking standard deviation of %d integrations" % (len(integrationTime))
        seconds = np.std(integrationTime)
    else:
#        print "Reporting length of first integration. Use method parameter to compute mean/median/stdev."
        seconds = integrationTime[0]
    if (pointingTable):
        mytb = createCasaTool(tbtool)
        mytb.open(vis+'/POINTING')
        interval = mytb.getcol('INTERVAL')
        direction = mytb.getcol('DIRECTION')
        diffdirectionRA = (direction[0][0][1:] - direction[0][0][:-1])*ARCSEC_PER_RAD*np.cos(direction[1][0][1:])
        diffdirectionDec = (direction[1][0][1:] - direction[1][0][:-1])*ARCSEC_PER_RAD
        print "Median separation of points = %f,%f arcsec" % (np.median(diffdirectionRA),np.median(diffdirectionDec))
        print "Median INTERVAL in pointing table = ", np.median(interval)
        mytb.close()
    return seconds
    
def spectralindex(filename='',yfilename='',source='',verbose=False,
                  maxpoints=0,trials=2000,spw='',plotdir='',
                  labelspw=False,referenceFrame='TOPO',
                  plaintext=False, lineNumbers=None,columns=None,
                  yscale=1.0, plotunits='linear',freqs=[],fluxes=[],
                  errors=[],plotfile='',showplot=True,xaxis=[],
                  spectralIndex=None, silent=False, axisEqual=True,
                  wavelengths=[]):
    """
    This is primarily a wrapper for the spectralindex method of the linfit class.
    For help, type "help au.linfit().spectralindex"
    Other optional inputs:
    wavelengths: you can specify either freqs or wavelengths (units do not matter)
    spectralindex: If you have only one flux measurement, you can specify
       it along with a spectralindex and it will compute expected flux
       densities at the frequencies specified by the xaxis parameter.
    Returns: a dictionary containing the following 7 keys:
      'intercept', 'interceptUncertainty', 'meanOfLogX', 'spectralIndex', 
      'spectralIndexUncertainty, 'yaxis', and 'yaxisUncertainty'
    -Todd Hunter
    """
    if (type(freqs)==int or type(freqs)==float): freqs=[freqs]
    if (type(wavelengths)==int or type(wavelengths)==float): wavelengths=[wavelengths]
    if (type(fluxes)==int or type(fluxes)==float): fluxes=[fluxes]
    if (type(errors)==int or type(errors)==float): errors=[errors]
    if (type(xaxis)==int or type(xaxis)==float): xaxis=[xaxis]
    if (len(freqs) == 0 and len(wavelengths) > 0):
        freqs = c_mks/np.array(wavelengths)
    for i,freq in enumerate(freqs):
        if (type(freq) == int):
            freqs[i] = float(freq)
    if (len(freqs) == 1):
        if (spectralIndex == None):
            print "You must provide at least 2 freqs (if any) or 1 freq and the spectral index."
            return
        if (len(errors) < 1):
            print "You must provide the flux density uncertainty via the 'errors' parameter."
            return
        if (len(fluxes) < 1):
            print "You must provide the flux density measurement via the 'fluxes' parameter."
            return
        print "Using spectral index = ", spectralIndex
        freqs.append(freqs[0]*2.0)
        fluxes.append(fluxes[0]*(freqs[1]/freqs[0])**spectralIndex)
        errors.append(errors[0]*fluxes[1]/fluxes[0])
    return(linfit().spectralindex(filename,yfilename,source,verbose,
                                  maxpoints,trials,spw,plotdir,
                                  labelspw,referenceFrame,plaintext,
                                  lineNumbers,columns,yscale,plotunits,
                                  freqs,fluxes,errors,plotfile,showplot,
                                  xaxis,silent,axisEqual))

def coGradient(x, trials=10000):
    """
    Milam et al. 2005
    """
    return(computeStdDevMonteCarlo(slope=5.41, slopeSigma=1.07, intercept=19.03, interceptSigma=7.9, x=x, trials=trials))

def computeStdDevMonteCarlo(slope, slopeSigma, intercept, interceptSigma, x, trials=10000):
    """
    This is a wrapper for the computeStdDevMonteCarlo method of the linfit class.
    Computes Y and its uncertainty given uncertainties on a fitted slope
    and intercept, and a value of X.
    - Todd Hunter
    """
    return(linfit().computeStdDevMonteCarlo(slope, slopeSigma, intercept, interceptSigma, x, trials))
    
class linfit:
    """
    Todd Hunter
    """
    def computeMultivariateNormalStats(self, slope, intercept, covar, x, trials=10000,
                                       logfit=False, meanOfLogX=0):
        y = []
        # If the slope and intercept are correlated, then this will pick correlated
        # random variables, which reduces the spread of the result.
        mymean = [intercept,slope]
        random_intercept, random_slope = np.random.multivariate_normal(mymean,covar,trials).T
        if (logfit):
            for t in range(trials):
                y.append(10**(random_slope[t]*(np.log10(x)-meanOfLogX) + random_intercept[t]))
        else:
            for t in range(trials):
                y.append(10**(random_slope[t]*x + random_intercept[t]))
        rms = np.std(y,axis=0)
        ymin = np.min(y,axis=0)
        ymax = np.max(y,axis=0)
        ymean = np.mean(y,axis=0)
        return(rms, ymin, ymax, ymean)

    def computeStdDevMonteCarlo(self, slope, slopeSigma, intercept, interceptSigma, x, trials=10000,
                                logfit=False, meanOfLogX=0, covar=None, silent=False, returnMedian=False):
        """
        Computes Y and its uncertainty given a fitted slope and intercept, uncertainies on them,
        and a value of X.  Returns the uncertainty.
        """
        y = []
        if (type(covar) != type(None)):
            # If the slope and intercept are correlated, then this will pick correlated
            # random variables, which reduces the spread of the result.
            mymean = [intercept,slope]
            random_intercept, random_slope = np.random.multivariate_normal(mymean,covar,trials).T
        if (logfit):
            for t in range(trials):
                if (type(covar) == type(None)):
                    y.append(10**((slope+slopeSigma*pickRandomError())*(np.log10(x)-meanOfLogX) + intercept + interceptSigma*pickRandomError()))
                else:
                    y.append(10**(random_slope[t]*(np.log10(x)-meanOfLogX) + random_intercept[t]))
        else:
            for t in range(trials):
                if (covar == None):
                    y.append((slope+slopeSigma*pickRandomError())*x + intercept + interceptSigma*pickRandomError())
                else:
                    y.append(10**(random_slope[t]*x + random_intercept[t]))
        y = np.array(y)
        mad = MAD(y)
        median = np.median(y)
        # Clip out wild values beyond 6*sigma (using the MAD) when computing std
        rms = np.std(y[np.where(np.abs(y) < median+6*mad)])
        if (not silent):
            print "Median Monte-Carlo result for %f = %f +- %f (scaled MAD = %f)" % (x, median, rms, mad)
        if (returnMedian):
            return(rms, median)
        else:
            return(rms)
    
    def readFluxscaleResult(self,xfilename, yfilename, source, verbose=False,
                            maxpoints=0,spwlist=[],referenceFrame='TOPO',debug=False):
      """
      Specific function to read CASA output files from listobs and fluxscale.
      It returns the log10() of the frequency and flux densities read. The
      flux density uncertainties returned are scaled by the flux density values
      (but the ratios are not logged).
      """
      fx = open(xfilename,'r')
      fy = open(yfilename,'r')
      lines = fy.readlines()
      fy.close()
      x = []
      y = []
      yerror = []
      skiplist = ''
      trueSource = ''
      sourcesFound = []
      ignoreSpw = []  # This will be a list of spws with "Insufficient data"
      for line in lines:
          if (line.find('Flux')>=0 and (source=='' or line.find(source)>=0)):
              tokens = line.split()
              for t in range(len(tokens)):
                  if (tokens[t].find('SpW')>=0):
                      #  We have specified the spws to include
                      spw = int(tokens[t].split('=')[1])
                      if (line.find('INSUFFICIENT DATA')>=0):
                          ignoreSpw.append(spw)
                          print "Skipping spw %d due to INSUFFICIENT DATA result from fluxscale." % (spw)
                          break
                  if (tokens[t]=='is:'):
                      if (spw not in spwlist and spwlist != []):
                          skiplist += str(spw) + ','
                      else:
                          # print "Using spw %d" % spw
                          if (line.find('Hz) is') > 0):
                              moreTokens = 2  # casa >= 4.3
                          else: 
                              moreTokens = 0  # casa <= 4.2
                          if (tokens[t-4-moreTokens] != 'for'):
                              # there is a blank in the name
                              trueSource = tokens[t-4-moreTokens] + ' ' + tokens[t-3-moreTokens]
                          else:
                              trueSource = tokens[t-3-moreTokens]  # no blanks were found in the name
                          sourcesFound.append(trueSource)
                          if (debug):
                              print "parsing flux from %s" % (tokens[t+1])
                          y.append(float(tokens[t+1]))
                          if (debug):
                              print "parsing flux uncertainty from %s" % (tokens[t+3])
                          yerror.append(float(tokens[t+3]))
                          break
              if (len(y) == maxpoints and maxpoints>0): break
      if (len(y) == 0):
          if (trueSource == ''):
            print "Did not find any flux densities for source = %s" % (source)
          else:
            print "Did not find any flux densities for source = %s" % (trueSource)
          return([],[],[],[],[])
      if (len(skiplist) > 0):
        print "Skipping spw ", skiplist[0:-1]
      lines = fx.readlines()
      fx.close()
      bw = []
      freqUnits = ''
      spwsKept = []
      for line in lines:
          loc=line.find('Ch1(')
          if (loc>=0):
              freqUnits = line[loc+4:loc+7]
              if (verbose):
                  print "Read frequency units = ", freqUnits
          if (line.find(referenceFrame)>=0):
              tokens = line.split()
              for t in range(len(tokens)):
                      if (tokens[t]==referenceFrame):
                          try:
                              spw = int(tokens[t-2])
                          except:
                              spw = int(tokens[t-3])
                              
                          if ((spw not in spwlist and spwlist != []) or spw in ignoreSpw):
  #                            print "Skipping spw %d" % spw
                              continue
                          else:
                              spwsKept.append(spw)
                              bw.append(float(tokens[t+3]))
                              x.append(float(tokens[t+1])+bw[-1]*0.5*0.001)
                          break
                      if (len(x) == maxpoints and maxpoints>0):
                          print "Stopping after readings %d points ---------------" % (maxpoints)
                          break
      if (len(y) != len(x)):
          print "There is a mismatch between the number of spws in the %s frame (%d" % (referenceFrame,len(x))
          print "and the number of valid flux densities (%d)." % (len(y))
          if (len(np.unique(sourcesFound)) > 1):
              print "Please limit the fit to one source using the 'source' parameter: ", np.unique(sourcesFound)
          return([],[],[],[],[],[])
      if (verbose):
          print "Read %d x values for %s = " % (len(x),trueSource), x
          print "Read %d y values for %s = " % (len(y),trueSource), y
      else:
          print "Read %d x values for %s (avg=%.3f) = " % (len(x),trueSource,np.mean(x)), x
          print "Read %d y values for %s (avg=%.3f) = " % (len(y),trueSource,np.mean(y)), y
      if (freqUnits.find('MHz') >= 0):
          x = np.array(x)*0.001
          freqUnits = 'GHz'
      logx = np.log10(x)
      logyerror = list(np.array(yerror) / np.array(y))
      logy = np.log10(y)
      return (logx,logy,logyerror,trueSource,freqUnits,spwsKept)
  # end of readFluxscaleResult

    def parse_spw_argument(self,spw):
      """
      # returns an integer list of spws based on a string entered by the user
      #  e.g.  '1~7,9~15' yields [1,2,3,4,5,6,7,9,10,11,12,13,14,15]
      #        [1,2,3] yields [1,2,3]
      #        1 yields [1]
      """
      if (type(spw) == list):
          return(spw)
      elif (type(spw) == int):
          return([spw])
      sublists = spw.split(',')
      spwlist = []
      for s in sublists:
          spwrange = s.split('~')
          if (len(spwrange) > 1):
              try:
                  firstSpw = int(spwrange[0])
                  try:
                      secondSpw = int(spwrange[1])
                      for w in range(int(spwrange[0]),int(spwrange[1])+1):
                          spwlist.append(w)
                  except:
                      print "Unrecognized element in spw string: %s" % (spwrange[1])
              except:
                  print "Unrecognized element in spw string: %s" % (spwrange[0])
          else:
              try:
                  spwlist.append(int(spwrange[0]))
              except:
                  print "Unrecognized element in spw string: %s" % (spwrange[0])
      return spwlist

    def spectralIndexFitterMonteCarlo(self,filename,yfilename='',degree=1,source='',
                                      verbose=False,maxpoints=0,trials=2000,spw='',
                                      referenceFrame='TOPO', plaintext=False,
                                      lineNumbers=None, columns=None, yscale=1.0,
                                      freqs=[],fluxes=[], errors=[]):
      """
      If error bars are included with the data, then the return values are:
          p, covar contain the results of the weighted fit
          p2 contains the results of the unweighted fit
      If no error bars are included, then
          p contains the results of the unweighted fit
      lineNumbers: which lines to read, where 1 is the first line in the file
      columns: which columns to read for freq, flux, error (starting at 1)
      """
      spwlist = []
      nullReturn = ([],[],[],[],[], [],[],[],[],[], [], [])
      if (spw != [] and spw != ''):
        spwlist = self.parse_spw_argument(spw)
        if (len(spwlist) < 2):
            print "I need more than 1 spws to fit a spectral index."
            return(nullReturn)
        else:
            print "Will use spw = ", spwlist
      if (filename == ''):
          x = np.array(freqs, dtype=np.float)
          y = np.array(fluxes, dtype=np.float)
          yerror = np.array(errors, dtype=np.float)
          if (len(x) != len(y) or len(x) != len(yerror)):
              print "Inconsistent array lengths of freqs, fluxes, errors"
              return(nullReturn)
          freqUnits = 'GHz'
          spwsKept = 0
          if (type(x[0]) == str):
              newx = []
              for xf in x:
                  newx.append(parseFrequencyArgument(xf)*1e-9)
              x = newx
          elif (x[0] > 2000):
              x *= 1e-9
          yerror = list(yerror/y)
          x = np.log10(x)
          y = np.log10(y)
      elif (plaintext == False):
          (x,y,yerror,source,freqUnits,spwsKept) = self.readFluxscaleResult(filename,yfilename,source,verbose,maxpoints,spwlist,referenceFrame=referenceFrame)
      else:
          result = self.readPlaintextFile(filename,lineNumbers,columns)
          if (result == None): return(nullReturn)
          (x,y,yerror) = result
          source = 'source'
          freqUnits = 'GHz'
          spwsKept = 0
      y = np.array(y)*yscale
      if (len(x) == 0 or len(y) == 0):
          return(nullReturn)

      # normalize the X values about 0 such that the uncertainties between slope
      # and intercept will be uncorrelated
      meanOfLogX = np.mean(x)
      x = x-meanOfLogX

      if (len(yerror)>0):
          fitfunc = lambda p, x: p[0]*x + p[1]
          errfunc = lambda p,x,y,err: (y-fitfunc(p,x))/err
          pinit = [1.0,-1.0]
          slope = []
          yoffset = []
          errors = np.zeros(len(y))
          # first trial is with no errors
          for t in range(trials):
              ytrial = list(np.array(y) + np.array(yerror)*np.array(errors))
              out = optimize.leastsq(errfunc, pinit, args=(x,ytrial,yerror),full_output=1)
              p = out[0]
              if (t==0):
                  covar = out[1]
              slope.append(p[0])
              yoffset.append(p[1])
              errors = []
              for e in range(len(y)):
                  errors.append(pickRandomError())
          p = [slope[0], yoffset[0]]
          pmedian = [np.median(slope), np.median(yoffset)]
          perror = [np.std(slope), np.std(yoffset)]
          p2 = np.polyfit(x,y,degree)
      else:
          p = np.polyfit(x,y,degree)
          covar = []
          p2 = []
          perror = []
          pmedian = []
      # if you change the number of return values, be sure to change the definition of nullReturn above
      return(p,covar,x,y,yerror,p2,source,freqUnits, pmedian, perror, spwsKept, meanOfLogX)

    # end of spectralIndexFitterMonteCarlo

    def readPlaintextFile(self,filename,lineNumbers=None,columns=None):
        """
        Reads a file of the format:   Freq(GHz)   Flux   Error
        and returns the 3 columns as three arrays.
        lineNumbers: which lines to read, where 1 is the first line in the file
        columns: which columns to read for freq, flux, error (starting at 1)
        """
        f = open(filename,'r')
        lines = f.readlines()
        f.close()
        freq = []
        flux = []
        error = []
        linectr = 0
        for line in lines:
            linectr += 1
            if (line[0] != '#'):
                if (lineNumbers==None or linectr in lineNumbers):
                    if (columns==None):
                        a,b,c = line.split()
                        freq.append(float(a))
                        flux.append(float(b))
                        error.append(float(c))
                    else:
                        mycolumns = line.split()
                        n_mycolumns = len(mycolumns)
                        if (len(columns) < 3):
                            print "invalid column list: need to specify at least 3"
                            return
                        if (np.max(columns) >= n_mycolumns):
                            print "invalid column list: %d exceeds %d" % (np.max(columns),n_mycolumns)
                            return
  #                      print "parsing %s" % (mycolumns[columns[0]-1])
                        freq.append( float(mycolumns[columns[0]-1]))
                        flux.append( float(mycolumns[columns[1]-1]))
                        error.append(float(mycolumns[columns[2]-1]))
  #      print "Read %d lines" % (len(freq))
        logx = np.log10(freq)
        logyerror = list(np.array(error) / np.array(flux))
        logy = np.log10(flux)
        return(logx, logy, logyerror)
        
    def spectralIndexFitterCovarMatrix(self,filename='',yfilename='',degree=1,source='',
                                       verbose=False,maxpoints=0,spw='',
                                       referenceFrame='TOPO',plaintext=False,
                                       lineNumbers=None, columns=None, yscale=1.0,
                                       freqs=[],fluxes=[], errors=[]):
      """
      If error bars are included with the data, then the return values are:
          p, covar contain the results of the weighted fit
          p2 contains the results of the unweighted fit
      If no error bars are included, then
          p contains the results of the unweighted fit
      lineNumbers: which lines to read, where 1 is the first line in the file
      columns: which columns to read for freq, flux, error (starting at 1)
      """
      spwlist = []
      nullReturn = ([],[],[],[],[], [],[],[],[],[], [])
      if (spw != [] and spw != ''):
        spwlist = self.parse_spw_argument(spw)
        if (len(spwlist) < 2):
            print "I need more than 1 spws to fit a spectral index."
            return(nullReturn)
        else:
            print "Will use spw = ", spwlist
      if (filename == ''):
          x = np.array(freqs,dtype=float)
          y = np.array(fluxes,dtype=float)
          yerror = np.array(errors,dtype=float)
          if (len(x) != len(y) or len(x) != len(yerror)):
              print "Inconsistent array lengths of freqs, fluxes, errors"
              return
          freqUnits = 'GHz'
          spwsKept = 0
          if (type(x[0]) == str):
              newx = []
              for xf in x:
                  newx.append(parseFrequencyArgument(xf)*1e-9)
              x = newx
          elif (x[0] > 2000):
              x *= 1e-9
          yerror = list(yerror/y)
          x = np.log10(x)
          y = np.log10(y)
      elif (plaintext == False):
          # yerror returned by readFluxscaleResult = y_uncertainty / y
          (x,y,yerror,source,freqUnits,spwsKept) = self.readFluxscaleResult(filename,yfilename,source,
                                           verbose,maxpoints,spwlist,referenceFrame=referenceFrame)
      else:
          result = self.readPlaintextFile(filename,lineNumbers,columns)
          if (result == None): return
          (x,y,yerror) = result
          source = 'source'
          freqUnits = 'GHz'
          spwsKept = 0
      if (len(x) == 0 or len(y) == 0):
          return(nullReturn)
      y = np.log10(np.array(10**y)*yscale)
      
      # normalize the X values about 0 such that the uncertainties between slope
      # and intercept will be uncorrelated
      meanOfLogX = np.mean(x)
      x = x-meanOfLogX

      # simple fit with no errors
      p2 = np.polyfit(x,y,degree)

      x = 10**x
      y = 10**y

      if (len(yerror)>0):
          fitfunc = lambda p, x: p[0] + p[1]*np.log10(x)
          errfunc = lambda p,x,y,err: (np.log10(y)-fitfunc(p,x))/err
          pinit = [1.0,-1.0]
          out = optimize.leastsq(errfunc, pinit, args=(x,y,yerror),full_output=1)
          p = out[0]
          covar = out[1]
      else:
          print "No uncertainties were found for the flux density measurements."

      return(p,x,y,yerror,covar,source,freqUnits,spwsKept,p2,meanOfLogX)
    # end of spectralIndexFitterCovarMatrix

    def round_to_n(self, x, n):
        ''' 
        http://stackoverflow.com/questions/3410976/how-to-round-a-number-to-significant-figures-in-python 
        '''
        return np.round(x, -int(floor(log10(abs(x)))) + (n - 1))

    def calc_ticks(self, domain, tick_count, equidistant):
        if equidistant:
            ticks = np.logspace(np.log10(domain[0]), np.log10(domain[1]), num = tick_count, base = 10)
        else:
            ticks = np.linspace(domain[0], domain[1], num = tick_count)
        for n in range(1, 6):
            if len(set(self.round_to_n(tick, n) for tick in ticks)) == tick_count:
                break    
        return list(self.round_to_n(tick, n) for tick in ticks)

    def spectralIndexCovarMatrix(self,filename='',yfilename='',source='',verbose=False,
                                 maxpoints=0,spw='',plotdir='',
                                 labelspw=False,referenceFrame='TOPO',plaintext=False,
                                 lineNumbers=None, columns=None, yscale=1.0,plotunits='linear',
                                 freqs=[],fluxes=[],errors=[],plotfile='',showplot=True,
                                 xaxis=[], dashedCurvePoints=40, silent=False, axisEqual=True):
      """
      This function is designed to fit the spectral index to the results
      output from casa's fluxscale task, and make a summary plot. Currently,
      it requires the output from the casa listobs task to determine the center
      frequencies of each spectral window.  It calls scipy.optimize.leastsq()
      and uses the fractional covariance matrix that it returns to determine the
      uncertainty on the fitted slope on the basis of the error bars on each flux
      density, as long as there are more than 2 points.  This is the formula that
      Bryan Butler sent me in Feb 2013. However, for the case of only 2 points,
      the denominator becomes zero in his formula, so it instead uses the
      sqrt(covariance matrix) which seems to agree well with the Monte-Carlo
      method.             
      -- Todd Hunter

      filename: contains a listobs output file
      yfilename: contains a fluxscale output file
      source: sourcename to choose from the (possibly) multi-source fluxscale file
      maxpoints: the maximum number of spws to select for the fit (0=no max)
      spw: the spws to use, e.g. ''=all, '1~3,5,6~8'=[1,2,3,5,6,7,8]
      plotdir: the directory in which to write the plotfile
      labelspw: draw spw numeric labels adjacent to each point
      referenceFrame: the frequency reference frame, if not 'TOPO'
      plaintext: if True, then read the freqs, flux densities and uncertainties
                 from a single plain text file, specified by filename
      lineNumbers: which lines to read, where 1 is the first line in the file
      columns: which columns to read for freq, flux, error (starting at 1)
      freqs,fluxes,errors: alternative to using filename
      showplot: if True, produce a plot showing error bars and model
      xaxis: a list of points for which to compute model y values
      dashedCurvePoints: number of points to define the min/max/rms model lines
      axisEqual: if True, then when plotting, set axis('equal')
      """
      # x & y are returned in linear units of frequency (normalized about 1.0 MHz)
      # and flux density (usually Jy)
      # yerror is the (uncertainty in y) divided by y
      result = self.spectralIndexFitterCovarMatrix(filename,yfilename,degree=1,source=source,
                                                   verbose=verbose,maxpoints=maxpoints,
                                                   spw=spw, referenceFrame=referenceFrame,
                                                   plaintext=plaintext,lineNumbers=lineNumbers,
                                                   columns=columns, yscale=yscale,freqs=freqs,
                                                   fluxes=fluxes,errors=errors)
      if (result == None): return
      if (result[0] == []): return
      (p,x,y,yerror,covar,source,freqUnits,spwsKept,p2,meanOfLogX) = result
      if (plotdir == ''):
          plotdir = './'
      if (plotdir[-1] != '/'):
          plotdir += '/'
      if (p == []):
          # If the data import failed, then the fit will be blank, so return.
          return(p)

      # Get the result of the fit
      yoffset = p[0]
      slope = p[1]
      freq = x[0]
      freqUnNormalized = 10**(np.log10(freq) + meanOfLogX)
      amp = 10**(yoffset + np.log10(freq)*slope)

      # from Bryan Butler email on Feb 15/16, 2013
      summed_error = 0
      for ii in range(len(x)):
          model = yoffset + slope*x[ii]
          residual = (model - y[ii])**2 / (yerror[ii]**2)
          summed_error += residual
      if (len(x) > 2):
          residual_variance = summed_error / (len(x) - 2)
          slopeFitError = fabs(slope) / np.sqrt(covar[1][1]*residual_variance)
          yoffsetError = fabs(yoffset) / np.sqrt(covar[0][0]*residual_variance)
      else:
          # residual variance cannot be calculated due to divide by zero
          # but the following formula seem to agree with the Monte Carlo approach
          slopeFitError = fabs(slope) * np.sqrt(covar[1][1])
          yoffsetError = fabs(yoffset) * np.sqrt(covar[0][0]) 
      ampError = self.computeStdDevMonteCarlo(slope,slopeFitError,yoffset,yoffsetError,freqUnNormalized,
                                              logfit=True,meanOfLogX=meanOfLogX,covar=covar,silent=silent)
      mydict = {'spectralIndex': slope, 'spectralIndexUncertainty':slopeFitError,
                'intercept': yoffset, 'interceptUncertainty': yoffsetError,
                'meanOfLogX': meanOfLogX, 'yaxis': [], 'yaxisUncertainty': [], 'covar': covar}

      amp2 = (10.0**p2[1]) * (freq**p2[0])
      if (verbose):
          print "yoffset=%f, covar = " % (yoffset), covar
      if not silent:
          if (amp < 0.01):
              print "Error-weighted fit: Slope: %.3f+-%.3f  Flux D. @ %.3f%s: %.3f+-%.3f mJy" % (slope,
                                   slopeFitError, freqUnNormalized, freqUnits, amp*1000, ampError*1000)
              print "   Un-weighted fit: Slope: %.3f         Flux D. @ %.3f%s: %.3f mJy" % (p2[0], freqUnNormalized, freqUnits, amp2*1000)
          else:
              print "Error-weighted fit: Slope: %.3f+-%.3f  Flux D. @ %.3f%s: %.3f+-%.3f Jy" % (slope,
                                   slopeFitError, freqUnNormalized, freqUnits, amp, ampError)
              print "   Un-weighted fit: Slope: %.3f         Flux D. @ %.3f%s: %.3f Jy" % (p2[0], freqUnNormalized, freqUnits, amp2)
      
      if (showplot):
          pb.clf()
          desc = pb.subplot(111)
      logx = np.log10(x)
      logy = np.log10(y)
      logxsorted = np.sort(logx)
      yfit = yoffset + logx*slope
      for myx in xaxis:
          yaxis = 10**(yoffset+(np.log10(myx)-meanOfLogX)*slope)
          mydict['yaxis'].append(yaxis)
          yaxisUncertainty = self.computeStdDevMonteCarlo(slope,slopeFitError,yoffset,yoffsetError,myx,
                                                          logfit=True,meanOfLogX=meanOfLogX,covar=covar,
                                                          silent=silent)
          mydict['yaxisUncertainty'].append(yaxisUncertainty)
      dashedCurveX = 10**np.linspace(np.log10(np.min(x)),np.log10(np.max(x)),dashedCurvePoints)
      dashedCurveRms,dashedCurveMin,dashedCurveMax,dashedCurveMean = \
          self.computeMultivariateNormalStats(slope, yoffset, covar, dashedCurveX, trials=10000,
                                                  logfit=True, meanOfLogX=0)
      minvalue = np.log10(dashedCurveMin)
      maxvalue = np.log10(dashedCurveMax)
      logxsorted = np.log10(dashedCurveX)
      
      if (showplot):
          if (plotunits == 'linear'):
            if (verbose):   
                print "Using linear plot units"
            lower = y*yerror
            upper = y*yerror
            x = 10**(logx+meanOfLogX)  # This x is in linear units of GHz
            pb.errorbar(x,y,yerr=[lower,upper],color='k',ls='None')
            pb.loglog(x,y,'ko',
                      x,10**yfit,'r-',
                      10**(logxsorted+meanOfLogX),dashedCurveMean-dashedCurveRms,'r:',
                      10**(logxsorted+meanOfLogX),dashedCurveMean+dashedCurveRms,'r:'
                      )
            desc.set_xscale("log",subsx=range(10))
            desc.set_yscale("log",subsy=range(10))
            if (freqUnits != ''):
                pb.xlabel('Frequency (%s)'%freqUnits)
            else:
                pb.xlabel('Frequency')
            pb.ylabel('Flux Density (Jy)')
            x0 = np.min(x)
            x1 = np.max(x)
            xr = x1 - x0
            y0 = np.min(y-lower)
            y1 = np.max(y+upper)
            yr = y1-y0
            pb.xlim([x0-xr*0.1, x1+xr*0.1])
            pb.ylim([y0-yr*0.1, y1+yr*0.1])
            if (labelspw):
                for i in range(len(x)):
                    pb.text(x[i], y[i],'%d'%(spwsKept[i]),size=10)
          else:
              logx += meanOfLogX
              logxsorted += meanOfLogX
              pb.plot(logx,logy,'ko',logx,yfit,'r-',  
                      logxsorted, minvalue,'r--',logxsorted,maxvalue,'r--')
              lower = np.log10(y) - np.log10(y-y*yerror) 
              upper = np.log10(y+y*yerror) - np.log10(y)
              pb.errorbar(logx,logy,yerr=[lower,upper],color='k',ls='None')
              if (freqUnits != ''):
                  pb.xlabel('Log10(Frequency(%s))'%freqUnits)
              else:
                  pb.xlabel('Log10(Frequency)')
              pb.ylabel('Log10(FluxDensity(Jy))')
              if axisEqual:
                  pb.axis('equal')
              if (labelspw):
                  for i in range(len(x)):
                      pb.text(logx[i], logy[i],'%d'%(spwsKept[i]),size=10)
          if (amp < 0.01):
              pb.title(source+'  spectral index=%+.3f+-%.3f, F(%.2f%s)=%.3f+-%.3f mJy'%(slope,slopeFitError,freqUnNormalized,freqUnits,amp*1000,ampError*1000),size=14)
          else:
              pb.title(source+'  spectral index=%+.3f+-%.3f, F(%.2f%s)=%.3f+-%.3f Jy'%(slope,slopeFitError,freqUnNormalized,freqUnits,amp,ampError),size=14)
          desc.xaxis.grid(which='major')
          desc.yaxis.grid(which='major')
          desc.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter(useOffset=False))
          desc.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter(useOffset=False))
          desc.set_xticks(self.calc_ticks(pb.xlim(),tick_count=4,equidistant=True))
          desc.set_yticks(self.calc_ticks(pb.ylim(),tick_count=4,equidistant=True))
          if (plaintext):
              yfilename = filename
          if (yfilename != ''):
              ytext = yfilename
#              ytext = self.replaceUnderscores(ytext)
              pb.text(0.01, 0.01, 'data from %s'%(ytext), transform=desc.transAxes,size=10)
          if (plotfile == True):
            if (plaintext):
                pngname = '%s%s.png' % (plotdir,yfilename)
            else:
                pngname = '%s%s.%s.png' % (plotdir,yfilename,source)
          elif (plotfile != ''):
            pngname = plotfile
          if (plotfile != ''):
            if (os.access('./',os.W_OK) == False):
                fileWriteMessage = "Cannot write plot to current directory, therefore will write to /tmp."
                pngname = '/tmp/' + os.path.basename(pngname)
            pb.savefig(pngname)
            print "Plot saved in %s" % (pngname)
          pb.draw()
      return(mydict)
  # end of spectralIndexCovarMatrix()

    def spectralindex(self,filename='',yfilename='',source='',verbose=False,
                      maxpoints=0,trials=0,spw='',plotdir='',
                      labelspw=False,referenceFrame='TOPO',plaintext=False,
                      lineNumbers=None, columns=None, yscale=1.0, plotunits='linear',
                      freqs=[],fluxes=[],errors=[],plotfile='',showplot=True,xaxis=[],
                      silent=False, axisEqual=True):
      """
      This function is designed to fit the spectral index to the results
      output from casa's fluxscale task. Currently, it requires the output
      from the listobs task to determine the center frequencies of each spw.
      Usage: spectralIndex(filename='',yfilename='',source='',verbose=False,
                           maxpoints=0,trials=0,spw='',plotdir='',plaintext=False)
      filename: contains a listobs output file
      yfilename: contains a fluxscale output file
      source: sourcename to choose from the (possibly) multi-source fluxscale file
      maxpoints: the maximum number of spws to select for the fit (0=no max)
      trials: if > 0, use a Monte-Carlo technique estimate the fit uncertainties,
         otherwise, use the sqrt(covar_matrix) from scipy.optimize.leastsq (default).
         There is a minimum number of 100 trials, and ~1000 is recommended.
      spw: the spws to use, e.g. ''=all, '1~3,5,6~8'=[1,2,3,5,6,7,8]
      plotdir: the directory in which to write the plotfile
      labelspw: draw spw numeric labels adjacent to each point
      referenceFrame: the frequency reference frame, if not 'TOPO'
      plaintext: if True, then read the freqs, flux densities and uncertainties
                 from a single plain text file, specified by filename
      lineNumbers: which lines to read, where 1 is the first line in the file
      columns: which columns to read for freq, flux, error (starting at 1)
      yscale: factor to scale the y values after reading from the file
      plotunits: 'linear' or 'log' (only used if trials==0)
      freqs,fluxes,errors: alternative to using filename
      xaxis: a list of points for which to compute model y values
      axisEqual: if True, then when plotting, set axis('equal')
      """
      if (plaintext==False and yfilename=='' and (freqs==[] or fluxes==[] or errors==[])):
          print "When plaintext=False, you must also specify yfilename which is the output file from fluxscale."
          return
      if (plotunits not in ['linear','log']):
          print "plotunits must be either 'linear' or 'log'"
          return
      if (len(errors) == 2):
          # report the exact fit, and 1-sigma extrema fits
          si = np.log(fluxes[1]/float(fluxes[0])) / np.log(freqs[1]/float(freqs[0]))
          si1 = np.log((fluxes[1]+errors[1])/(fluxes[0]-errors[0])) / np.log(freqs[1]/float(freqs[0]))
          si2 = np.log((fluxes[1]-errors[1])/(fluxes[0]+errors[0])) / np.log(freqs[1]/float(freqs[0]))
          if (not silent):
              print "Spectral index exact value: %f,  1-sigma extrema: %f, %f,  mean unc=%f" % (si,si1,si2,0.5*abs(si2-si1))
      if (trials > 0):
          if (trials < 100):
              trials = 100
          return(self.spectralIndexMonteCarlo(filename,yfilename,source,verbose,maxpoints,
                                              trials,spw,plotdir,labelspw,referenceFrame,plaintext,
                                              lineNumbers,columns,yscale,plotunits,freqs,fluxes,
                                              errors,plotfile,showplot,xaxis,silent,axisEqual))
      else:
          return(self.spectralIndexCovarMatrix(filename,yfilename,source,verbose,maxpoints,
                                               spw,plotdir,labelspw,referenceFrame,
                                               plaintext,lineNumbers,columns,yscale,plotunits,
                                               freqs,fluxes,errors,plotfile,showplot,xaxis,
                                               silent,axisEqual))
            
    def spectralIndexMonteCarlo(self,filename='',yfilename='',source='',verbose=False,
                                maxpoints=0,trials=2000,spw='',plotdir='',
                                labelspw=False,referenceFrame='TOPO',
                                plaintext=False,lineNumbers=None,columns=None,yscale=1.0,
                                plotunits='linear',freqs=[],fluxes=[],errors=[],plotfile='',
                                showplot=True, xaxis=[], silent=False, axisEqual=True):
        """
        This function is designed to fit the spectral index to the results
        output from casa's fluxscale task. Currently, it requires the output
        from the listobs task to determine the center frequencies of each
        spectral window.  It runs a brief Monte-Carlo series of fits to
        determine the uncertainty on the fitted slope on the basis of the
        error bars on each flux density.    -- Todd Hunter

        filename: contains a listobs output file
        yfilename: contains a fluxscale output file
        source: sourcename to choose from the (possibly) multi-source fluxscale file
        maxpoints: the maximum number of spws to select for the fit (0=no max)
        trials: number of Monte-Carlo fits to run to estimate the fit uncertainties
        spw: the spws to use, e.g. ''=all, '1~3,5,6~8'=[1,2,3,5,6,7,8]
        plotdir: the directory in which to write the plotfile
        labelspw: draw spw numeric labels adjacent to each point
        referenceFrame: the frequency reference frame, if not 'TOPO'
        lineNumbers: which lines to read, where 1 is the first line in the file
        columns: which columns to read for freq, flux, error (starting at 1)
        xaxis: a list of points for which to compute model y values
        axisEqual: if True, then when plotting, set axis('equal')
        """
        (p,covar,x,y,yerror,p2,source,freqUnits,pmedian,perror,spwsKept,meanOfLogX) = \
            self.spectralIndexFitterMonteCarlo(filename,yfilename,degree=1,source=source,
                                               verbose=verbose,maxpoints=maxpoints,
                                               trials=trials,spw=spw,
                                               referenceFrame=referenceFrame, plaintext=plaintext,
                                               lineNumbers=lineNumbers, columns=columns,yscale=yscale,
                                               freqs=freqs,fluxes=fluxes,errors=errors)
        if (plotdir == ''):
            plotdir = './'
        if (plotdir[-1] != '/'):
            plotdir += '/'
        if (p == []):
            return(p)
        if (p2 != []):
            # Then we have two solutions, where the first one is the error-weighted fit.
            slope = p[0]
            yoffset = p[1]
            if (verbose):
                print "Completed %d Monte-Carlo error trials." % (trials)
            slopeErr = perror[0]
            yoffsetErr = perror[1]
            freq = 10**x[0]
            amp = 10**(p[1] + x[0]*slope)
            ampError = amp * perror[1]
            mydict = {'spectralIndex': slope, 'spectralIndexUncertainty':slopeErr,
                      'intercept': yoffset, 'interceptUncertainty': yoffsetErr,
                      'meanOfLogX': meanOfLogX, 'yaxis': [], 'yaxisUncertainty': []}
            freqUnNormalized = 10**(x[0] + meanOfLogX)
            if (not silent):
                print "Error-weighted fit: Slope: %.3f+-%.3f  Flux D. @ %.3f%s: %.3f+-%.3f" % (slope, slopeErr, freqUnNormalized, freqUnits, amp, ampError)
            if (verbose):
                yfit = x*pmedian[0] + pmedian[1]
                print "Predicted values = ", yfit
        else:
            # We only have one solution, so put it into p2.
            p2 = p
        amp2 = 10.0**p2[1]
        amp2 *= freq**p2[0]
        if (not silent):
            print "   Un-weighted fit: Slope: %.3f         Flux D. @ %.3f%s: %.3f" % (p2[0], freqUnNormalized, freqUnits, amp2)
        yfit = x*p[0]+p[1]  # the fit result with zero Monte-Carlo errors added to the data
        for myx in xaxis:
            mydict['yaxis'].append(10**(p[1] + (np.log10(myx)-meanOfLogX)*p[0]))
            mydict['yaxisUncertainty'].append(self.computeStdDevMonteCarlo(slope,slopeErr,yoffset,yoffsetErr,myx,
                                              logfit=True,meanOfLogX=meanOfLogX,covar=covar,silent=silent))
        dashedCurveHigh = []
        dashedCurveLow = []
        dashedCurve = []
        xsorted = np.sort(x)
        for myx in xsorted:
            uncertainty = self.computeStdDevMonteCarlo(slope,slopeErr,yoffset,yoffsetErr,10**(myx+meanOfLogX),
                                                       logfit=True,meanOfLogX=meanOfLogX,covar=covar,silent=silent)
            dashedCurveHigh.append(np.log10(10**(p[1] + myx*p[0]) + uncertainty))
            dashedCurveLow.append(np.log10(10**(p[1] + myx*p[0]) - uncertainty))
        if (showplot):
          pb.clf()
          desc = pb.subplot(111)
          desc.xaxis.grid(which='major')
          desc.yaxis.grid(which='major')
          if (pmedian != []):
              x += meanOfLogX
              xsorted += meanOfLogX
              pb.plot(x,y,'ko',x,yfit,'r-')
              pb.hold(True)
              pb.plot(xsorted,dashedCurveLow,'r--',
                      xsorted,dashedCurveHigh,'r--')
              pb.title(source+'  spectral index=%+.3f+-%.3f, F(%.2f%s)=%.3f+-%.3f Jy'%(slope,slopeErr,
                                  freqUnNormalized,freqUnits,amp,ampError),size=14)
          else:
              pb.plot(x,y,'ko', x,yfit,'r-')
              pb.title(source+' index=%.3f, F(%.2f%s)=%.3f' % (slope,freqUnNormalized,freqUnits,amp))
          if (labelspw):
            for i in range(len(x)):
                pb.text(x[i],y[i],'%d'%(spwsKept[i]),size=10)
          originalYerror = yerror*(10**y)
          lower = y-np.log10(10**y-originalYerror)
          upper = np.log10(10**y+originalYerror)-y
          pb.errorbar(x,y,yerr=[lower,upper],color='k',ls='None')
          if (freqUnits != ''):
              pb.xlabel('Log10(Frequency(%s))'%freqUnits)
          else:
              pb.xlabel('Log10(Frequency)')
          pb.ylabel('Log10(FluxDensity(Jy))')
          if axisEqual:
              pb.axis('equal')
          if (plaintext):
              yfilename = filename
          if (yfilename != ''):
              ytext = yfilename
#              ytext = self.replaceUnderscores(ytext)
              pb.text(0.01, 0.01, 'data from %s'%(ytext), transform=desc.transAxes,size=10)
          if (plotfile == True):
              pngname = '%s%s.%s.png' % (plotdir,yfilename,source)
          elif (plotfile != ''):
              pngname = plotfile
          if (plotfile != ''):
              if (os.access('./',os.W_OK) == False):
                  fileWriteMessage = "Cannot write plot to current directory, therefore will write to /tmp."
                  pngname = '/tmp/' + os.path.basename(pngname)
              pb.savefig(pngname)
              print "Plot saved in %s" % (pngname)
          pb.draw()
        return(mydict)
    # end of spectralIndexMonteCarlo

    def replaceUnderscores(self,y):
      """
      Replaced underscores with \_ to avoid strange effects when plotting text with pylab.text()
      """
      newy = ''
      for i in range(len(y)):
          if (y[i]=='_'):
              newy += '\_'
          else:
              newy += y[i]
      return(newy)

    def linfitFromFile(self, filename, xcol, ycol, yerrorcol=None, pinit=[0,0],
                       plot=False, plotfile=None, xlabel=None, ylabel=None, 
                       title=None,delimiter=None, residual=False):
        """
        Performs linear fit to data from the specified file, and data columns.
        xcol, ycol: columns to use from the file (starting at 0)
        yerrorcol: column to use for uncertainties (None -> 1% of ycol)
        pinit: contains the initial guess of [slope, intercept]
        plot: whether to generate a plot window
        plotfile: whether to generate a png file
        xlabel, ylabel, title: labels for the plot
        delimiter: column delimitier in your file
        residual: if True, show the residual of the fit in second panel
        Returns:
        * the fitted coefficients (and residuals if requested)
        * or None, if there are fewer than 3 data points
        """
        x,y = getxyFromFile(filename,xcol,ycol,delimiter)
        if (yerrorcol == None):
            yerror = y*0.01
        elif (type(yerrorcol) == np.float or type(yerrorcol) == float):
            yerror = y*yerrorcol
        else:
            yerror = y*0.01
        if (len(x) > 2):
            p = self.linfit(x,y,yerror,pinit,plot,plotfile,xlabel,ylabel,title,residual)
        else:
            p = None
        return p

    def linfit(self, x, y, yerror, pinit=[0.57,3.4], plot=False, plotfile=None,
               xlabel=None, ylabel=None, title=None, residual=False, 
               excludeXrange=[], returnResiduals=False):
        """
        Basic linear function fitter with error bars in y-axis data points.
        Uses scipy.optimize.leastsq().  Accepts either lists or arrays.
        Example:
             lf = au.linfit()
             lf.linfit(x, y, yerror, pinit)
        Input:
             x, y: x and y axis values
             yerror: uncertainty in the y-axis values
             pinit contains the initial guess of [slope, intercept]
             residual: if True, show the residual of the fit in second panel
             excludeXrange: exclude a range of x-axis values when doing the fit
                 e.g. [109,116] to avoid 109-116 GHz points
             returnResiduals: if True, return [slope,intercept,data-fit]
        Output:
           The fit result as: [slope, y-intercept]
        - Todd Hunter
        """
        x = np.array(x)
        y = np.array(y)
        yerror = np.array(yerror)
        if (excludeXrange != []):
            idx1 = np.where(x<excludeXrange[0])[0]
            idx2 = np.where(x>excludeXrange[1])[0]
            keep = np.union1d(idx1,idx2)
            x = x[keep]
            y = y[keep]
            yerror = yerror[keep]
        fitfunc = lambda p, x: p[1] + p[0]*x
        errfunc = lambda p,x,y,err: (y-fitfunc(p,x))/(err**2)
        out = optimize.leastsq(errfunc, pinit, args=(x,y,yerror/y), full_output=1)
        p = out[0]
        covar = out[1]
        residuals = y-(p[0]*x+p[1])
        if (plot):
            pb.clf()
            if (residual):
                desc = pb.subplot(211)
            else:
                desc = pb.subplot(111)
            pb.errorbar(x,y,yerr=yerror,fmt='o',color='b',ecolor='b')
            xline = np.array(pb.xlim())
            yline = p[0]*xline + p[1]
            pb.plot(xline, yline, 'k-')
            if (title == None):
                pb.title('y = (%g)x %+g' % (p[0], p[1]))
            else:
                pb.title(title)
                pb.text(0.4,0.92,'y = (%g)x %+g' % (p[0], p[1]), transform=desc.transAxes)
            if (xlabel is not None):
                pb.xlabel(xlabel)
            if (ylabel is not None):
                pb.ylabel(ylabel)
            if (plotfile == None): 
                plotfile = 'linfit.png'
            if (residual):
                pb.subplot(212)
                pb.plot(x,residuals,'b.')
                pb.ylabel('Residuals')
                if (xlabel is not None):
                    pb.xlabel(xlabel)
            pb.savefig(plotfile)
            pb.draw()
        if (returnResiduals):
            return([p[0], p[1], residuals])
        else:
            return(p)

    def odrFunction(self, B, x):
        return B[0]*x + B[1]

    def orthogonalDistanceRegression(self, x, y, xerror, yerror, loglog=False):
        """
        Performs a linear fit accounting for measurement uncertainties in both axes.
        loglog: if True, then take the log10 of the x and y vectors, and set
                xerror and yerror equal to xerror/x and yerror/y, respectively.
                Also, the intercept will be converted to the scaling coefficient.
        """
        if (loglog):
            xerror = np.array(xerror)/np.array(x)
            yerror = np.array(yerror)/np.array(y)
            print "Taking log10 of x and y"
            x = np.log10(x)
            y = np.log10(y)
        mydata = scipy.odr.RealData(x, y, sx=xerror, sy=yerror)
        myodr = scipy.odr.ODR(mydata, scipy.odr.Model(self.odrFunction), beta0=[1.,2.])
        myoutput = myodr.run()
#        myoutput.pprint()
        beta = myoutput.beta
        sd_beta = myoutput.sd_beta
        if (loglog):
            beta[1] = 10**(beta[1])  # convert intercept to scaling coefficent
            # treat sd_beta as a fractional standard deviation
            sd_beta[1] = 0.5*(10**(beta[1]+sd_beta[1]*beta[1]) - 10**(beta[1]-sd_beta[1]*beta[1]))
        return(beta, sd_beta)
        
#  def linfitplot(self)
    
# end of definition of class     linfit

def linfitFromFiles(filelist, xcol=0, ycol=1, plot=True, 
                    absolute=True, title='', verbose=False):
    """
    Takes a list of files, does a linear fit of the data columns inside,
    and plots the slope vs baseline length, which is encoded in the filename
    filelist: either comma-delimited string (with optional wildcard), or 
              a list of strings
    filename format:  name_xxxx.txt  where xxxx=baseline length in m
    """
    if (filelist.find('*') >= 0):
        filelist = glob.glob(filelist)
    elif (type(filelist) == str):
        filelist = filelist.split(',')
    print "Processing %d files" % (len(filelist))
    l = linfit()
    baseline = []
    slope = []
    for f in filelist:
        if verbose: print "au.linfit().linfitFromFile('%s', %d, %d)" % (f,xcol,ycol)
        p = l.linfitFromFile(f, xcol, ycol, plot=plot)
        if p == None: 
            if verbose: print "No data found in ", f
            continue
        try:
            baseline.append(float(f.split('_')[-1].rstrip('.txt')))
            if (absolute):
                p[0] = abs(p[0])
            slope.append(p[0])
        except:
            if verbose: print "No baseline length found in filename"
            pass
    pb.clf()
    pb.plot(baseline, slope, 'ko')
    pb.xlabel('baseline length (m)')
    pb.ylabel('absolute magnitude of slope (deg/GHz)')
    pb.title(title)
    png = 'slope_vs_baseline.png'
    pb.savefig(png)
    return png

def sevenMeterAntennasMajorityASDM(asdm):
    """
    Checks an ASDM for 7m antennas, and returns True if more than half
    of the antennas are 7m. See also sevenMeterAntennasOnlyASDM().
    """
    names, diameters = readAntennasFromASDM(asdm,diameters=True,verbose=FAlse)
    alln = len(names)
    seven = len(np.where(np.array(diameters) < 8.0)[0])
    return (seven > 0.5*alln)

def sevenMeterAntennasMajority(vis='', mymsmd=''):
    """
    Checks a measurement set for 7m antennas, and returns True if more than half
    of the antennas are 7m. See also sevenMeterAntennasOnly().
    vis: name of measurement set
    mymsmd: (optional) an pre-existing instance of the msmd tool for this measurement set
    """
    if (vis == '' and mymsmd == ''):
        print "You must specify either vis or an open instance of an msmd tool."
        return
    if (mymsmd == '' or mymsmd==None):
        if (not os.path.exists(vis)):
            print "Could not find measurement set"
            return
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        seven = len(mymsmd.antennaids(maxdiameter='7m'))
        alln = mymsmd.nantennas()
        mymsmd.close()
    else:
        seven = len(mymsmd.antennaids(maxdiameter='7m'))
        alln = mymsmd.nantennas()
    return(seven > 0.5*alln)

def sevenMeterAntennasOnlyASDM(asdm):
    """
    Checks an ASDM for antenna diameters, and returns True if all
    the antennas are 7m. See also sevenMeterAntennasMajorityASDM().
    """
    names, diameters = readAntennasFromASDM(asdm,diameters=True,verbose=False)
    alln = len(names)
    seven = len(np.where(np.array(diameters) < 8.0)[0])
    return (seven == alln)

def sevenMeterAntennasOnly(vis):
    """
    Checks for 'CM' in antenna names, and returns False if at least one
    antenna is not a CM antenna.  See also sevenMeterAntennasMajority().
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    antnames = getAntennaNames(vis)
    for name in antnames:
        if ('CM' not in name):
            return(False)
    return(True)

def replace_bpsol(intable,replacetable,antennas,outtable):
    """
    This function will read in two bandpass solution tables and write out
    a new table in which the solutions for the specified antennas in the
    the first table are replaced by the solutions in the second table.
    Currently, this only works for casa 3.3 format tables.
    -Remy Indebetouw
    """
    print "replacing solution for antennas ",antennas
    print "in "+intable
    print "with solutions from "+replacetable
    print "output to "+outtable

    if os.path.exists(outtable):
        print outtable+" exists - delete or choose another name"
        return 1

    # unsafe to filename chaff like trailing slashes
    os.system("cp -r "+intable+" "+outtable)
    
    if not tb.open(replacetable):
        print "can't find "+replacetable
        return 1

    # antennas should be a list of integers
    replaceantcol=tb.getcol("ANTENNA1")
    replacerowids=[]
    for ant in antennas:
        for i in range(len(replaceantcol)):
            if replaceantcol[i] == ant:
                replacerowids.append(i)
    replacerows=tb.selectrows(replacerowids)
    replaceants=replacerows.getcol("ANTENNA1")
    print "antenna numbers in replacement table: ",replaceants

    tb.done()
    
    if not tb.open(outtable,nomodify=False):
        print "can't find "+outtable
        return 1

    origantcol=tb.getcol("ANTENNA1")
    origrowids=[]
    for ant in antennas:
        for i in range(len(origantcol)):
            if origantcol[i] == ant:
                origrowids.append(i)

    oldrows=tb.selectrows(origrowids)
    oldants=oldrows.getcol("ANTENNA1")
    print "antenna numbers in original table: ",oldants
    
    if not pl.all( replaceants==oldants ):
        print "antenna row mismatch"
        return 1

    tb.removerows(antennas)    
    tb.done()
    replacerows.copyrows(outtable)
    replacerows.done()
    return 0

def uvplot(msfile, field='', plotrange=[0,0,0,0], figfile=False, markersize=2, 
           density=144, units='m', mirrorPoints=True):
    """
    A simple function to make u vs. v plot with points mirrored about the
    origin, similar to AIPS.  This functionality is not yet in casa's plotms,
    but it *is* in plotuv. For further help and examples, see
    https://safe.nrao.edu/wiki/bin/view/ALMA/Uvplt
    field: restrict to single field name or field ID
    units: 'm' or 'km'
    -Todd Hunter
    """
    fieldid = field
    if (os.path.exists(msfile) == False):
        print "Could not find ms = %s." % (msfile)
        return
    try:
        mytb = createCasaTool(tbtool)
        mytb.open(msfile)
        mytb.close()
    except:
        print "Could not open ms = %s." % (msfile)
        return
    if (type(fieldid) == str):
        if (fieldid == ''):
            print "Showing points for all fields"
            mytb.open(msfile)
            tb1 = mytb
        elif (len(fieldid) == sum([m in [str(m) for m in range(10)] for m in fieldid])):
            fieldid = int(fieldid)
            vm = ValueMapping(msfile)
            fieldname = vm.getFieldNamesForFieldId(fieldid)
            if (fieldname == None):
                print "No such field in the ms."
                return
            print "Showing field id = %d = %s" % (fieldid, fieldname)
            mytb.open(msfile)
            tb1 = mytb.query('FIELD_ID == '+str(fieldid))
        else:
            # convert from name to ID
            fieldname = fieldid
            vm = ValueMapping(msfile)
            fieldid = vm.getFieldIdsForFieldName(fieldname)[0]
            mytb.open(msfile)
            tb1 = mytb.query('FIELD_ID == '+str(fieldid))
            print "Showing field id = %d = %s" % (fieldid, fieldname)
    elif (type(fieldid) == int):
        tb1 = mytb.query('FIELD_ID == '+str(fieldid))
        vm = ValueMapping(msfile)
        fieldname = vm.getFieldNamesForFieldId(fieldid)
        if (fieldname == None):
            print "No such field in the ms."
            return
        print "Showing field id = %d = %s" % (fieldid, fieldname)
    else:
        print "unsupported field id type"
        return
          
    rawdata = tb1.getcol("UVW")
    if (len(rawdata) < 1):
        print "No data found for this field"
        return
    mytb.close()
    pb.clf()
    adesc = pb.subplot(111)
    if (units == 'km'):
        rawdata *= 0.001
    maxbase = max([max(rawdata[0,]),max(rawdata[1,])])  # in m
        
    pb.plot(rawdata[0,],rawdata[1,],'b.',markersize=markersize)
    if (mirrorPoints):
        pb.plot(-rawdata[0,],-rawdata[1,],'b.',markersize=markersize)
    if (plotrange[0] != 0 or plotrange[1] != 0):
        pb.xlim([plotrange[0],plotrange[1]])
    if (plotrange[2] != 0 or plotrange[3] != 0):
        pb.ylim([plotrange[2],plotrange[3]])
    pb.gca().set_aspect(aspect='equal')
    if (units == 'km'):
        pb.xlabel('u (km)',fontsize='medium')
        pb.ylabel('v (km)',fontsize='medium')
    else:
        pb.xlabel('u (meter)',fontsize='medium')
        pb.ylabel('v (meter)',fontsize='medium')
    if (fieldid==''):
        pb.title(os.path.basename(msfile) + '  all fields')
    else:
        pb.title(os.path.basename(msfile) + '  field %d = %s' % (fieldid,fieldname),fontsize=12)
    yFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.yaxis.set_major_formatter(yFormatter)
    adesc.yaxis.grid(True,which='major')
    xFormatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
    adesc.xaxis.set_major_formatter(xFormatter)
    adesc.xaxis.grid(True,which='major')
    if (figfile == True):
        if (msfile.find('/')==len(msfile)-1):
            msfile = msfile[0:len(msfile)-1]
        myfigfile = msfile + '.uvplot.png'
        pb.savefig(myfigfile,format='png',density=density)
    elif (figfile != False):
        myfigfile = figfile
        pb.savefig(myfigfile,format='png',density=density)
    else:
        print "To generate a .png file, re-run with: figfile=True or figfile='my.png'"
        return
    pb.draw()
    print "Plot left in = %s" % (myfigfile)

def modifyAntennaDiameter(vis, diameter=12, antenna=-1):
    """
    Set the antenna diameter to the specified value.
    antenna: which antenna, -1 for all
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ANTENNA', nomodify=False)
    dish = mytb.getcol('DISH_DIAMETER')
    if (antenna < 0):
        dish = diameter * np.ones(len(dish))
    else:
        dish[antenna] = diameter
    mytb.putcol('DISH_DIAMETER', dish)
    mytb.close()

def modifyAntenna(vis, newantenna1, row=0):
    """
    Change the antenna ID in one row of the ms, as a test for listobs behavior.
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not open measurement set = ", vis
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis,nomodify=False)
    c1 = 'ANTENNA1'
    c2 = 'ANTENNA2'
    uniqueAntennas = np.unique(list(mytb.getcol(c1)) + list(mytb.getcol(c2)))
    print "Antennas initially present in column %s or %s = %s" % (c1, c2, str(uniqueAntennas))
    antenna1 = mytb.getcell(c1,row)
    mytb.putcell(c1,row,newantenna1)
    print "Changed %s in row %d from %d to %d" % (c1, row, antenna1, newantenna1)
    uniqueAntennas = np.unique(list(mytb.getcol(c1)) + list(mytb.getcol(c2)))
    print "Antennas now present in column %s or %s = %s" % (c1, c2, str(uniqueAntennas))
    mytb.close()

def swapPhasecalChecksourceIntents(vis, phase='CALIBRATE_PHASE', 
          check='OBSERVE_CHECK_SOURCE', intermediary='CALIBRATE_DELAY'):
    """
    Uses au.modifyIntents to swap the CALIBRATE_PHASE and OBSERVE_CHECK_SOURCE
    intents in a measurement set.  It first sets the OBSERVE_CHECK_SOURCE to
    CALIBRATE_DELAY, then changes PHASE to CHECK_SOURCE, then DELAY to PHASE.
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    intents = mymsmd.intents()
    mymsmd.close()
    if intermediary.find('#ON_SOURCE') < 0:
        intermediary += '#ON_SOURCE'
    if phase.find('#ON_SOURCE') < 0:
        phase += '#ON_SOURCE'
    if check.find('#ON_SOURCE') < 0:
        check += '#ON_SOURCE'
    for intent in [check, phase]:
        if intent not in intents:
            print "%s is not in this dataset. Aborting." % (intent)
            print "Available intents = ", intents
            return
    if intermediary in intents:
        print "This dataset has %s in it. Choose a different intermediary." % intermediary
        if intermediary != 'CALIBRATE_POLARIZATION':
            print "Such as CALIBRATE_POLARIZATION."
        return
    print "Setting %s to %s" % (check,intermediary)
    modifyIntents(vis, check, intermediary)
    print "Setting %s to %s" % (phase,check)
    modifyIntents(vis, phase, check)
    print "Setting %s to %s" % (intermediary,phase)
    modifyIntents(vis, intermediary, phase)

def modifyIntents(vis='', oldintent='', newintent=''):
    """
    Change all appearances of an intent to be a different intent.
    See also editIntents, to do more granular changes.
    - Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not open measurement set = ", vis
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis + '/STATE', nomodify=False)
    intentcol = mytb.getcol('OBS_MODE')
    for i in range(len(intentcol)):
        intentcol[i] = intentcol[i].replace(oldintent,newintent)
    mytb.putcol('OBS_MODE',intentcol)
    mytb.close()

def getReferenceFrequency(caltable, spw=0):
    """
    Returns the reference frequency of the specified spw of a caltable.
    -Todd Hunter
    """
    swt = caltable+'/SPECTRAL_WINDOW'
    if (not os.path.exists(swt)):
        print "Could not find the spectral window table of this caltable."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(swt)
    ref = mytb.getcol('REF_FREQUENCY')
    mytb.close()
    return(ref[spw])
    
def modifyReferenceFrequency(caltable, frequency=0, spw=0):
    """
    Changes the REF_FREQUENCY column of the SPECTRAL_WINDOW table
    in a caltable.
    frequency: either floating point GHz or Hz or a string with units
               if set to zero, then use the mean of all ref_frequencies
               if set to negative value, then use the mean of all frequencies
                   in the parent measurement set that have intent=PHASE
    -Todd Hunter
    """
    swt = caltable+'/SPECTRAL_WINDOW'
    if (not os.path.exists(swt)):
        print "Could not find the spectral window table of this caltable."
        return
    frequency = parseFrequencyArgumentToHz(frequency)
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    vis = mytb.getkeyword('MSName')
    mytb.close()
    mytb.open(swt,nomodify=False)
    ref = mytb.getcol('REF_FREQUENCY')
    if (frequency == 0):
        frequency = np.mean(ref)
    elif (frequency < 0):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        phasespws = mymsmd.spwsforintent('*PHASE*')
        meanfreqs = []
        for phasespw in phasespws:
            meanfreqs.append(mymsmd.meanfreq(phasespw))
            print "spw %d has mean freq = %f GHz" % (phasespw, meanfreqs[-1]*1e-9)
        frequency = np.mean(meanfreqs)
        mymsmd.close()
    print "Changing ref_frequency from %f to %f GHz" % (ref[spw]*1e-9, frequency*1e-9)
    ref[spw] = frequency
    mytb.putcol('REF_FREQUENCY',ref)
    mytb.close()

def getIntentsFromASDM(asdm, stripPrefix=False, byscan=False):
    """
    Makes dictionary with field name as key and intents as the value
    Required parameters:
    asdm: the name of the ASDM
    byscan: if True, then return a dictionary keyed by intent, with values = scans
    -- Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not open ASDM = ", asdm
        return
    if (asdm[-1] != '/'):
        asdm = asdm + '/'
    xmlscans = minidom.parse(asdm+'/Scan.xml')
    scandict = {}
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    mydict = {}
    byscandict = {}
    for rownode in rowlist:
        rowpwv = rownode.getElementsByTagName("fieldName")
        # The following is necessary for the case that the SB was terminated
        # early, in which case the final entry of the Scan.xml might not have a <fieldName>
        if (rowpwv == []): continue
        names = rowpwv[0].childNodes[0].nodeValue.split()
        fieldname = str(names[2]).strip('"')
        if (fieldname not in mydict.keys()):
            mydict[fieldname] = []
        rowintent = rownode.getElementsByTagName("scanIntent")
        tokens = rowintent[0].childNodes[0].nodeValue.split()
        numIntents = int(tokens[1])
        scanNumber = int(rownode.getElementsByTagName("scanNumber")[0].childNodes[0].nodeValue.split()[0])
        for i in range(numIntents):
            intent = str(tokens[i+2])
            if stripPrefix:
                intent = intent[intent.find('_')+1:]
            if (intent not in mydict[fieldname]):
                mydict[fieldname].append(intent)
            if (intent not in byscandict.keys()):
                byscandict[intent] = []
            byscandict[intent].append(scanNumber)
    if byscan:
        return(byscandict)
    else:
        return(mydict)

def editFieldname(vis, field, newname, fieldID=-1):
    """
    Changes a field name in an MS, in the FIELD and SOURCE tables
    field: old name
    newname: new name
    fieldID: if specified, then restrict changes to this single field ID 
             (for testing purposes only)
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find ms"
        return
    mytb = createCasaTool(tbtool)
    for tbl in ['FIELD','SOURCE']:
        if (fieldID >=0 and tbl == 'SOURCE'): continue
        mytb.open(vis+'/'+tbl, nomodify=False)
        names = mytb.getcol('NAME')
        modified = 0
        if field in names:
            for i,name in enumerate(names):
                if (name == field and (fieldID==-1 or fieldID==i)):
                    names[i] = newname
                    modified += 1
        else:
            print "Field %s is not in the %s table. Available names: %s" % (field, tbl, str(np.unique(names)))
        if modified > 0:
            mytb.putcol('NAME',names)
        print "Changed %d rows in %s table." % (modified,tbl)
        mytb.close()

def editFieldnameASDM(asdm, field, newname):
    """
    Changes a field name in the ASDM (in 4 files: Source.xml, Scan.xml,
    Subscan.xml and Field.xml')
    -- Todd Hunter
    Required parameters:
    asdm: the name of the ASDM
    field: the old field name
    newname: the new field name
    """
    if (os.path.exists(asdm) == False):
        print "Could not open ASDM = ", asdm
        return
    if (asdm[-1] != '/'):
        asdm = asdm + '/'
    files = ['Source.xml', 'Scan.xml', 'Subscan.xml', 'Field.xml']
    for f in files:
        replaced = 0
        with open(asdm+f+'.new', "w") as out:
            for line in open(asdm+f):
                if (line.find(field) >= 0):
                    line = line.replace(field, newname)
                    replaced += 1
                out.write(line)
        os.rename(asdm+f+'.new', asdm+f)
        print "Replaced %d lines in %s" % (replaced,f)

def twoSourceDataset(vis, calibrator=0, phase=0, target=1, tsysScan=1,
                     bandpassAllScans=False, override=False):
    """
    This function modifies the intents on a 2-source dataset
    to allow it to be run through the script generator.  It must
    have a Tsys scan as the first scan. - Todd Hunter
    calibrator: the field ID of the bandpass/flux calibrator
    phase: the field ID of the phase calibrator
    target: the field ID (or list of IDs) of the science target(s)
    tsysScan: the scan number of the Tsys scan to use (usually 1)
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    scans = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
    mymsmd.close()
    calibrator = int(calibrator)
    if (type(target) != list):
        target = [int(target)]
    phaseTargets = phase
    if (type(phase) != list):
        phaseTargets = [int(phase)]
    if (tsysScan not in scans):
        print "Scan %d is not a Tsys scan" % (tsysScan)
        if (len(scans) > 0):
            tsysScan = scans[0]
            print "Using scan %d instead." % (tsysScan)
        else:
            print "In fact, there are no Tsys scans, so this function cannot be used."
            return
    for p in phaseTargets:
        editIntents(vis, field=p, newintents='PHASE')
    if (phase == calibrator):
        editIntents(vis, field=calibrator, scan=2,
                    newintents='FLUX,BANDPASS,PHASE')
    else:
        if bandpassAllScans:
            editIntents(vis, field=calibrator, 
                        newintents='FLUX,BANDPASS')
        else:
            editIntents(vis, field=calibrator, scan=2,
                        newintents='FLUX,BANDPASS')
    editIntents(vis, field=calibrator, scan=tsysScan, newintents='ATMOSPHERE')
    for t in target:
        editIntents(vis, field=t, newintents='TARGET')
    
def editIntentscsv(intentcsv, dryrun=False, verbose=False):
    """
    Reads a list of parameters from a csv text file and runs au.editIntents on them.
    Format: multiple scans or intents must be quoted, either single or double quote
    # any number of comment lines
    vis,field,scan,"WVR,BANDPASS"
    vis,field,,'FLUX,WVR'
    ...
    * field is a required argument, while scan is optional
    * scan: can be a single integer, integer list, or comma-delimited string list
    -Todd Hunter
    """
    if (not os.path.exists(intentcsv)):
        print "Could not find intentcsv file: ", intentcsv
        return
    f = open(intentcsv,'r')
    lines = f.readlines()
    f.close() 
    for originalLine in lines:
        if (originalLine[0] == '#'): continue
        line = originalLine.replace("'",'"').replace(' ','')
        if verbose:
            print "Parsing reformatted line: ", line[:-1]
        if (len(line.split(',')) > 3):
            token = []
            for i in csv.reader([line]):
                token.append(i)
            token = token[0]
            if (len(token) < 4):
                print "Skipping invalid line: ", originalLine
                continue
            vis = token[0].strip()
            field = token[1].strip()
            scan = token[2].strip()
            intents = token[3].strip()
            if (os.path.exists(vis)):
                cmd = "au.editIntents('%s','%s','%s','%s')" % (vis,field,scan,intents)
                if dryrun:
                    print "Would call %s\n" % (cmd)
                else:
                    print "Calling %s" % (cmd)
                    editIntents(vis,field,scan,intents)
            else:
                print "Could not find requested measurement set: ", vis

def scansForIntent(vis, intent='PHASE', returnString=True):
    """
    Returns a list of scans for the specified intent, using the msmd tool.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    print "%s field: %s" % (intent, mymsmd.fieldsforintent('*'+intent+'*'))
    scans = mymsmd.scansforintent('*'+intent+'*')
    mymsmd.close()
    if returnString:
        return ','.join([str(i) for i in scans])
    else:
        return scans
    
def editIntents(msName='', field='', scan='', newintents='',
                append=False, verbose=True):
    """
    Change the observation intents for a specified field.  Adapted from
    John Lightfoot's interactive function for the ALMA pipeline.
    Inputs:
    * field: required argument (integer or string ID, or name)
    * scan: optional, can be a single integer, integer list, or comma-delimited string list
    * append: set to True to add the specified intent to the existing intents
    * newintents: enter as a python list, or as single comma-delimited string
    * valid intents: the first 12 are simply a shorthand way to specify the latter 12
       'AMPLITUDE', 'ATMOSPHERE', 'BANDPASS', 'CHECK_SOURCE', 'WVR',
       'DELAY', 'FLUX', 'FOCUS', 'PHASE', 'POINTING', 'SIDEBAND_RATIO', 'TARGET',
       'CALIBRATE_AMPLI', 'CALIBRATE_ATMOSPHERE', 'CALIBRATE_BANDPASS',
       'CALIBRATE_DELAY', 'CALIBRATE_FLUX', 'CALIBRATE_FOCUS',
       'CALIBRATE_PHASE', 'CALIBRATE_POINTING', 'CALIBRATE_SIDEBAND_RATIO',
       'OBSERVE_TARGET', 'CALIBRATE_WVR', 'OBSERVE_CHECK_SOURCE'
    - T. Hunter
    """
    validIntents = ['AMPLITUDE','ATMOSPHERE','BANDPASS','CHECK_SOURCE',
                    'DELAY','FLUX','FOCUS', 'PHASE','POINTING', 
                    'SIDEBAND_RATIO', 'TARGET','WVR', 'CALIBRATE_AMPLI', 
                    'CALIBRATE_ATMOSPHERE', 'CALIBRATE_BANDPASS',
                    'CALIBRATE_DELAY', 'CALIBRATE_FLUX', 'CALIBRATE_FOCUS',
                    'CALIBRATE_PHASE', 'CALIBRATE_POINTING', 
                    'CALIBRATE_SIDEBAND_RATIO','OBSERVE_TARGET',
                    'CALIBRATE_WVR', 'OBSERVE_CHECK_SOURCE'
                    ]
    if (msName == ''):
        print "You must specify a measurement set."
        return
    if (field == ''):
        print "You must specify a field ID or name."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(msName + '/FIELD')
    fieldnames = mytb.getcol('NAME')
    if verbose:
        print "Found fieldnames = ", fieldnames
    mytb.close()

    mytb.open(msName + '/STATE')
    intentcol = mytb.getcol('OBS_MODE')
    intentcol = intentcol
    mytb.close()

    mytb.open(msName, nomodify=False)
    naddedrows = 0
    if (type(newintents)==list):
        desiredintents = ''
        for n in newintents:
            desiredintents += n
            if (n != newintents[-1]):
                desiredintents += ','
    else:
        desiredintents = newintents
    desiredintentsList = desiredintents.split(',')
        
    for intent in desiredintentsList:
        if ((intent in validIntents)==False):
            print "Invalid intent = %s.  Valid intents = %s" % (intent,validIntents)
            mytb.close()
            return
    foundField = False
    if (type(scan) != list):
        scan = str(scan)
    for id,name in enumerate(fieldnames):
        if (name == field or str(id) == str(field)):
            foundField = True
            if verbose:
                print 'FIELD_ID %s has name %s' % (id, name)
            if scan == '': 
                s = mytb.query('FIELD_ID==%s' % id)
                if verbose:
                    print "Got %d rows in the ms matching field=%s" % (s.nrows(),id)
            else:
                if (type(scan) == str):
                    scans = [int(x) for x in scan.split(',')]
                elif (type(scan) != list):
                    scans = [scan]
                else:
                    scans = scan
  #              s = mytb.query('FIELD_ID==%s AND SCAN_NUMBER==%s' % (id, scan))
                if verbose:
                    print "Querying: 'FIELD_ID==%s AND SCAN_NUMBER in %s'" % (id, str(scans))
                s = mytb.query('FIELD_ID==%s AND SCAN_NUMBER in %s' % (id, str(scans)))
  #              print "Got %d rows in the ms matching field=%s and scan=%s" % (s.nrows(),id,scan)
                if verbose:
                    print "Got %d rows in the ms matching field=%s and scan in %s" % (s.nrows(),id,str(scans))
            if (s.nrows() == 0):
                s.close()
                mytb.close()
                print "Found zero rows for this field (and/or scan). Stopping."
                return
            state_ids = s.getcol('STATE_ID')
            # original code from J. Lightfoot, can probably be replaced
            # by the np.unique() above
            states = []
            for state_id in state_ids:
                if state_id not in states:
                    states.append(state_id)
  #          print "states = ", states
            for ij in range(len(states)):
                states[ij] = intentcol[states[ij]]

            print 'current intents are:'
            for state in states:
                print state

            if append == False: states = []
            for desiredintent in desiredintentsList:
                if desiredintent.find('TARGET')>=0:
                    states.append('OBSERVE_TARGET#ON_SOURCE')
                elif desiredintent.find('CHECK_SOURCE')>=0:
                    states.append('OBSERVE_CHECK_SOURCE#ON_SOURCE')
                elif desiredintent.find('BANDPASS')>=0:
                    states.append('CALIBRATE_BANDPASS#ON_SOURCE')
                elif desiredintent.find('PHASE')>=0:
                    states.append('CALIBRATE_PHASE#ON_SOURCE')
                elif desiredintent.find('AMPLI')>=0:
                    states.append('CALIBRATE_AMPLI#ON_SOURCE')
                elif desiredintent.find('FLUX')>=0:
                    states.append('CALIBRATE_FLUX#ON_SOURCE')
                elif desiredintent.find('ATMOSPHERE')>=0:
                    states.append('CALIBRATE_ATMOSPHERE#ON_SOURCE')
                elif desiredintent.find('WVR')>=0:
                    states.append('CALIBRATE_WVR#ON_SOURCE')
                elif desiredintent.find('SIDEBAND_RATIO')>=0:
                    states.append('CALIBRATE_SIDEBAND_RATIO#ON_SOURCE')
                elif desiredintent.find('DELAY')>=0:
                    states.append('CALIBRATE_DELAY#ON_SOURCE')
                elif desiredintent.find('FOCUS')>=0:
                    states.append('CALIBRATE_FOCUS#ON_SOURCE')
                elif desiredintent.find('POINTING')>=0:
                    states.append('CALIBRATE_POINTING#ON_SOURCE')
                else:
                    print "Unrecognized intent = %s" % desiredintent
                    continue
                print 'setting %s' % (states[-1])

            if states != []:
                state = reduce(lambda x,y: '%s,%s' % (x,y), states)
                if state not in intentcol:
                    if verbose:
                        print 'adding intent to state table'
                    intentcol = list(intentcol)
                    intentcol.append(state)
                    intentcol = np.array(intentcol)
                    state_id = len(intentcol) - 1
                    naddedrows += 1
                    if verbose:
                        print 'state_id is', state_id
                    state_ids[:] = state_id
                else:
                    if verbose:
                        print 'intent already in state table'
                    state_id = np.arange(len(intentcol))[intentcol==state]
                    if verbose:
                        print 'state_id is', state_id
                    if (type(state_id) == list or type(state_id)==np.ndarray):
                        # ms can have identical combinations of INTENT, so just
                        # pick the row for the first appearance - T. Hunter
                        state_ids[:] = state_id[0]
                    else:
                        state_ids[:] = state_id
                s.putcol('STATE_ID', state_ids)
            s.close()
        # endif name==field
    # end for name overfieldnames
    if (foundField == False):
        print "Field not found"
        return
    mytb.close()

    if verbose:
        print 'writing new STATE table'
    mytb.open(msName + '/STATE', nomodify=False)
    if naddedrows > 0:
        mytb.addrows(naddedrows)
    mytb.putcol('OBS_MODE', intentcol)
    mytb.close()

def strDate2MJD(d, use_metool=True):
    """
    Converts date in string format 20110809 or 2011x08x09 to MJD
    where 'x' can be any non-numeric character, like '-' or '/'
    d: can also contain a timestring (colon-delimited)
    """
    hr = 0
    mn = 0
    sc = 0
    if ((d[4]==d[7]) and (d[4]<'0' or d[4]>'9') and (d[7]<'0' or d[7]>'9')):
        # a delimiter is present: e.g. # 2016-10-16
        year = d[0:4]
        month = d[5:7]
        day = d[8:10]
        if (len(d) > 11):
            tokens = len(d[11:].split(':'))
            hr = d[11:].split(':')[0]
            if (tokens > 1):
                mn =  d[11:].split(':')[1]
            if (tokens > 2):
                sc = d[11:].split(':')[2]
    else: # 20161016
        year = d[0:4]
        month = d[4:6]
        day = d[6:8]
        if (len(d) > 9):
            tokens = len(d[9:].split(':'))
            hr = d[9:].split(':')[0]
            if (tokens > 1):
                mn =  d[9:].split(':')[1]
            if (tokens > 2):
                sc = d[9:].split(':')[2]
    date='%s-%s-%sT%s:%s:%s'%(year,month,day,hr,mn,sc)
    if (not casaAvailable and use_metool):
        use_metool = False
    if (use_metool):
        myme = createCasaTool(metool)
        mjd = myme.epoch('utc',date)['m0']['value']
        myme.done()
    else:
        year = int(year)
        month = int(month)
        day = int(day)
        hr = int(hr)
        mn = int(mn)
        sc = float(sc)
        mjd = ymdhmsToMJD(year,month,day, hr,mn,sc)
    return mjd

def tunnel(server='pomona.osf.alma.cl', port=8080, gateway='tatio.aiv.alma.cl', user=''):
    """
    Open an ssh tunnel to a server in Chile, e.g. for accessing the calibrator catalog
    web tool. You need to have an account on a gateway machine in Chile for this to
    work, i.e. either on tatio.aiv.alma.cl or login.alma.cl.
    In the future, the calibrator catalog might become openly available to everyone
    at http://asa.alma.cl/sourcecatweb/sourcecat (but currently it is not).
    - Todd Hunter
    """
    response = os.popen('ps ax | grep ssh | grep %s' % (port)).read()
    if (user == ''):
        user = os.getenv('USER')
    command = 'ssh -N -f -L %d:%s:%d %s@%s' % (port,server,port,user,gateway)
    loc = response.find(command)
    if (loc >= 0):
        process = response[:loc].split('\n')[-1].split()[0]
        print "You already have this tunnel open (with process ID %s)" % (process)
        return
    if (response.find('ssh -N -f -L %d'%port) >= 0):
        process = response[:loc].split('\n')[-1].split()[0]
        print "You already have a tunnel open with port %d. You need to kill this process ID (%s) first" % (port,process)
        return
    print "Creating tunnel: %s" % (command)
    os.system(command)
    print "Now you can access the calibrator web tool at http://localhost:%d/sourcecatweb/sourcecat/" % (port)
    return

def computeFlaggedFraction(flagarray):
    """
    Called by timeOnSourceSD
    """
    flags = 0
    npoints = 0
    for row in flagarray:
        flags += np.sum(flagarray.flatten())
        npoints += len(flagarray.flatten())
    return(flags/(1.0*npoints))

def findNearestPairs(catalog='rfc_2016c_cat.txt', onlyCsources=True, radius=2):
    """
    Reads the specified VLBI position catalog and computes the nearest pairs.
    It generates a textfile called nearestPairs.txt, which contains 3 columns:
    the separation in degrees, and the names of the pairs.
    radius: the maximum separation to include in the resulting list.
    """
    # get the latest catalog
    if (not os.path.exists(catalog)):
        findNearestVLBISources('0:0:0 0:0:0', verbose=False)
    f = open(catalog,'r')
    lines = f.readlines()
    f.close()
    f = open('nearestPairs.txt','w',0)
    nsources = len(lines)
    print "Read %d lines" % nsources
    i = 0
    for line in lines:
        if (line[0] == '#'): 
            nsources -= 1
            continue
        i += 1
        tokens = line.split()
        if (i % 10 == 0):
            print "Working on %d/%d" % (i,nsources)
        radec = ':'.join(tokens[3:6]) + ' ' + ':'.join(tokens[6:9])
        mydict = findNearestVLBISources(radec, radius=radius, verbose=False)
        for key in mydict.keys():
            if ((mydict[key]['type'] == 'C' or not onlyCsources) and tokens[2] != key):
                f.write('%.3f %s %s\n' % (mydict[key]['separation'], tokens[2], key))
                f.flush()
    f.close()

def findNearestVLBISources(radecString, radius=3, frequency=None, 
                           catalog='rfc_2016c_cat.txt',
                           server='http://asa.alma.cl/sourcecat/xmlrpc',
                           phasecalFluxLimit=0.150, checksourceFluxLimit=0.05,
                           ageLimit=30, verbose=True, onlyTypeC=False,
                           sortby='name', fluxLimit=0.0):
    """
    Reads a VLBI catalog from astrogeo.org and finds all sources within 
    specified radius of the specified target. IT downloads the file first, if 
    necessary.
    radecString: various acceptable formats, including '17:20:05.3 -03:20:15'
                 (see help au.radec2rad for a complete description)
                 Also accepts proper names such as J2219+1806 and 3C273
    radius: search radius (in degrees)
    frequency: if not None, then also query for the flux densities
    server: this is only needed to instantiate the calDatabaseQuery object 
            that holds the catalog parsing logic 
    phasecalFluxLimit: minimum flux required (in Janskys)
    checksourceFluxLimit: minimum flux required (in Janskys)
    ageLimit: maximum age (in days) to consider flux measurement current
    onlyTypeC: if True, then only include 'C' types in response
    sortby: 'name' (default) or 'separation'; only works if frequency=None
    fluxLimit: if present, do not report sources below this value in Jy
    Returns:
    * if frequency is not specified: a dictionary keyed by source name
        with values equal to dictionaries keyed by 'separation' and 'type'
    * otherwise: a dictionary keyed by source name, with value equal to:
          None: if no flux information is available; or another dictionary
          if it is available, with keys='fluxDensity','fluxDensityUncertainty',
             'meanAge', 'monteCarloFluxDensity', 'separationDegrees', 'type',
             'ageDifference', 'spectra'Index', and 'spectralIndexUncertainty'
    -Todd Hunter
    """
    from . import calDatabaseQuery  # used by searchFlux

    if sortby != 'name' and frequency is not None:
        print "The sortby parameter does not work if frequency is specified."
        return
    if (radecString[0].upper() in ['J','B','N'] or radecString[1].upper() in ['C']):
        radecString = searchFlux(radecString,returnPosition=True, verbose=False)
        if (radecString == -1):
            print "No measurements found for %s, so I cannot convert name to position." % (radecString)
            return
    if (radec2rad(radecString) == None):
        return
    ccu = calDatabaseQuery.CalibratorCatalogUpdate(server=server)
    sourcelist, types = ccu.findNearestVLBISources(radecString, radius, catalog, 
                                                   returnDictionary=True, verbose=verbose)
    if (frequency == None):
        sourceinfo = {}
        for src in sourcelist.keys():
            if onlyTypeC:
                if types[src] != 'C':
                    continue
            sourceinfo[src] = {'separation': sourcelist[src], 'type': types[src]}
        if sortby == 'separation':
            sourceinfo = sorted(sourceinfo.items(), key=operator.itemgetter(1))
        return(sourceinfo)
    else:
        nsrc = 0
        for src in sourcelist.keys():
            if onlyTypeC:
                if types[src] != 'C':
                    continue
            nsrc += 1
        print "Querying ALMA catalog for flux densities from %d sources." % nsrc
        mydict = {}
        maxFlux = 0
        uncertainty = 0
        bestsrc = 'none'
        allflux = []
        allfluxsource = []
        allages = []
        for src in sourcelist.keys():
            if onlyTypeC:
                if types[src] != 'C':
                    continue
            candidate = getALMAFlux(src, frequency, silent=True)
            if (candidate == -1):
                mydict[src] = None
            else:
                if candidate['fluxDensity'] < fluxLimit :
                    continue
                mydict[src] = candidate
                mydict[src]['separationDegrees'] = sourcelist[src]
                mydict[src]['type'] = types[src]
                allflux.append(mydict[src]['fluxDensity'])
                allfluxsource.append(src)
                allages.append(mydict[src]['meanAge'])
                if (mydict[src]['fluxDensity'] > maxFlux):
                    bestsrc = src
                    maxFlux = mydict[src]['fluxDensity']
                    uncertainty = mydict[src]['fluxDensityUncertainty']
        if fluxLimit > 0:
            print "Found %d objects with ALMA measurements > %f Jy." % (len(allflux),fluxLimit)
        else:
            print "Found %d objects with ALMA measurements." % (len(allflux))
        if (bestsrc != 'none'):
            print "The highest flux density object is %s with %.1f+-%.1f mJy at %.1f deg." % (bestsrc, maxFlux*1000, uncertainty*1000,mydict[bestsrc]['separationDegrees'])
        totalSources = len(sourcelist.keys())
        allflux = np.array(allflux)
        allfluxsource = np.array(allfluxsource)
        allages = np.array(allages)
        idx = np.argsort(allflux)
        allflux = allflux[idx]
        allfluxsource = allfluxsource[idx]
        allages = allages[idx]
        phasecal = None
        checksource = None
        if (len(allflux) < 1):
            print "No sources have millimeter flux density measurements"
            return mydict
        if (allflux[-1] > phasecalFluxLimit):
            phasecal = allfluxsource[-1]
            phasecalFlux = allflux[-1]*1000
            if (allflux[-1] > 2*phasecalFluxLimit or allages[-1] > ageLimit):
                phasecalReobserve = False
            else:
                phasecalReobserve = True
            if (len(allflux) > 1):
                if (allflux[-2] > checksourceFluxLimit):  # need to add angular separation check
                    checksource = allfluxsource[-2]
                    checksourceFlux = allflux[-2]*1000
                    if (allflux[-2] > 2*checksourceFluxLimit or allages[-2] > ageLimit):
                        checksourceReobserve = False
                    else:
                        checksourceReobserve = True
        elif (allflux[-1] > checksourceFluxLimit):
            checksource = allfluxsource[-1]
            checksourceFlux = allflux[-1]*1000
            if (allflux[-1] > 2*checksourceFluxLimit or allages[-1] > ageLimit):
                checksourceReobserve = False
            else:
                checksourceReobserve = True
            
        if (phasecal == None):
            print "No sources meet phasecal flux limit."
            if (radius < 5):
                print "Try increasing search radius to 5 degrees to get more phasecal candidates."
            elif (len(allflux) < totalSources):
                print "Schedule a cone search to measure flux densities of the other %d phasecal candidates." % (totalSources-len(allflux))
            else:
                print "Schedule a cone search to identify new sources for phase calibration."
        else:
            if (phasecalReobserve):
                print "Recommended phase calibrator = %s, but need to reobserve it to confirm flux density (%.0f mJy)." % (phasecal, phasecalFlux)
            else:
                print "Recommended phase calibrator = %s (%.0f mJy)" % (phasecal, phasecalFlux)
        if (checksource == None):
            if (len(allflux) < 2):
                print "No potential check sources."
            else:
                print "None of the potential check sources meet check source flux limit."
            if (radius < 5):
                print "Try increasing search radius to 5 degrees to get more check source candidates."
            elif (len(allflux) < totalSources):
                print "Schedule a cone search to measure flux densities of the other %d check source candidates." % (totalSources-len(allflux))
            else:
                print "Schedule a cone search for new check sources."
        elif (checksourceReobserve):
            print "Recommended check source = %s, but need to reobserve it to confirm flux density (%.0f mJy)." % (checksource, checksourceFlux)
        else:
            print "Recommended check source = %s (%.0f mJy)." % (checksource, checksourceFlux)
                
        if sortby == 'separation':
            mydict = sorted(mydict.items(), key=operator.itemgetter(1))
        return(mydict)

def gridSourceReport(nsources=None,server='http://asa.alma.cl/sourcecat/xmlrpc',bands=[3,6,7]):
    """
    See: help au.calDatabaseQuery.CalibratorCatalogUpdate.gridSourceReport
    -Todd Hunter
    """
    from . import calDatabaseQuery  # used by searchFlux
    ccu = calDatabaseQuery.CalibratorCatalogUpdate(server=server)
    return(ccu.gridSourceReport(nsources,bands))

def getALMAFluxForMS(vis, field=None, frequency=None, verbose=False, 
                     searchAdjacentNames=False, server='', dayWindow=0,
                     showplot=False, plotfile='', intent='CALIBRATE', spw='',
                     silent=False, lowbandFlux=None, highbandFlux=None,
                     lowbandFrequency=None, highbandFrequency=None,
                     lowbandUncertainty=None, highbandUncertainty=None,
                     lowbandDate=None, highbandDate=None, referenceFrequency=None,
                     referenceFlux=None, mymsmd='', spectralIndex=None,
                     fitSpectralIndex='closest', interpolateFromBand='lowband'):
    """
    Calls getALMAFlux for sources in a measurement set, and returns a
    dictionary keyed by field name.
    field: list of field IDs or names (default = all)
    frequency: the frequency to use (default = mean freq of first TDM or FDM spw)
    searchAdjacentNames: pass this flag to au.searchFlux
    server: pass this string to au.searchFlux (name of xmlrpc database URL)
            can be 'internal', 'external' or full URL
    dayWindow: if non-negative, then process all measurements within this
               many days of the first measurement found (per band)
    showplot: if True, then produce a plot with errorbars and model
    plotfile: write the plot to a file
    intent: if field is not specified, then use only sources with this intent
    spw: if specified, then restrict the mean frequency determination to a 
         that single spw (or a list)
    spectralIndex: if specified, then pass as new defaultSpectralIndex and set ignoreHighBand=True
         which will prevent any fit from being performed
    fitSpectralIndex: 'contemporaneous' (previous default until 2017 Mar 31), 'closest' (default), 'mean'
        'contemporaneous': use the flux density pair nearest to specified date; 
        'closest': use the most recent pair with the smallest time separation;
        'mean': take weighted mean of all pairs having the smallest time separation
    interpolateFromBand: after determining spectral index, this parameter controls
        which band's measurement to interpolate from. Options are: 'lowband', 
        'highband', 'closestInTime' or 'closestInFrequency' (by ratio)

    The following parameters allow you to use a recent measurement in one band along
    with the best spectral index derived from the catalog to compute the flux density
    referenceFrequency: use catalog to get spectral index, then interpolate from this freq
    referenceFlux: use catalog to get spectral index, then interpolate from this measurement

    The following parameters allow you to use a different measurement from what
    is in the catalog:
    lowbandFlux: recently measured value to use instead of the database value (Jy)
    highbandFlux: recently measured value to use instead of the database value (Jy)
    lowbandFrequency: frequency of lowbandFlux
    highbandFrequency: frequency of highbandFlux
    lowbandUncertainty: uncertainty of lowbandFlux
    highbandUncertainty: uncertainty of highbandFlux
    lowbandDate: date for lowbandFlux
    highbandDate: date for highbandFlux
    
    Prints: a setjy command that can be pasted into script generator
          (.split is appended to the vis if not present)
    Returns: a dictionary keyed by field name, with each value being a
        dictionary containing six fields: 'frequency', 'fluxDensity', and
        'fluxDensityUncertainty', 'spectralIndex', 'spectralIndexUncertainty',
        and 'meanAge'.
    """
    if (lowbandFlux is not None or lowbandFrequency is not None or lowbandUncertainty is not None or lowbandDate is not None):
        if (lowbandFlux == None or lowbandFrequency == None or lowbandUncertainty == None or lowbandDate == None):
            print "lowbandFlux, lowbandFrequency, lowbandUncertainty, lowbandDate must all be specified."
            return
    if (highbandFlux is not None or highbandFrequency is not None or highbandUncertainty is not None or highbandDate is not None):
        if (highbandFlux == None or highbandFrequency == None or highbandUncertainty == None or highbandDate == None):
            print "highbandFlux, highbandFrequency, highbandUncertainty, highbandDate must all be specified."
            return
    if (referenceFrequency is not None or referenceFlux is not None):
        if (referenceFrequency == None or referenceFlux == None):
            print "referenceFrequency and referenceFlux must be specified together"
            return
        referenceFrequency = parseFrequencyArgumentToHz(referenceFrequency)
    if spectralIndex is not None:
        ignoreHighBand = True
        defaultSpectralIndex = spectralIndex
    else:
        ignoreHighBand = False
        defaultSpectralIndex = -0.7
    if  (type(field)==np.string_):
        field = str(field)
    if (os.path.exists(vis) == False):
        print "Could not open MS = %s" % (vis)
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        msmdCreated = True
    else:
        msmdCreated = False
    intent = intent.upper()
    if (field == ''): field = None
    if (frequency==None or frequency==''):
        # Need to set based on the spws present, or the specified spw
        if (spw==''):
            # set the spws based on the spws present in the measurement set
            if (casadef.subversion_revision >= casaRevisionWithAlmaspws):
                spws = mymsmd.almaspws(tdm=True,fdm=True)
            else:
                spws = np.setdiff1d(np.union1d(mymsmd.fdmspws(),mymsmd.tdmspws()), mymsmd.chanavgspws())
            # if OBSERVE_TARGET is present, only use those spws
            intents = mymsmd.intents()
            if ('OBSERVE_TARGET#ON_SOURCE' in intents):
                myspws = np.intersect1d(mymsmd.spwsforintent('OBSERVE_TARGET#ON_SOURCE'),spws)
                if (verbose):
                    print "spw interection of %s with %s = %s" % (mymsmd.spwsforintent('OBSERVE_TARGET#ON_SOURCE'),spws,myspws)
                spws = myspws
        else:
            # set based on the single spw specified
            if (type(spw) != list):
                spws = [int(spw)]
            else:
                spws = spw
        frequency = []
        for spw in spws:
            frequency.append(mymsmd.meanfreq(spw))
        frequency = np.mean(frequency)
        if (verbose):
            print "Using frequency = ", frequency
    else:
        frequency = parseFrequencyArgument(frequency)
    if (field==None):
        if (intent == 'CALIBRATE'):
            field = mymsmd.fieldsforintent('CALIBRATE_PHASE*')  # get all the fields
            myintents = mymsmd.intents()
            if ('CALIBRATE_BANDPASS#ON_SOURCE' in myintents):
                field = np.append(field,mymsmd.fieldsforintent('CALIBRATE_BANDPASS*'))
            if ('CALIBRATE_AMPLI#ON_SOURCE' in myintents):
                field = np.append(field,mymsmd.fieldsforintent('CALIBRATE_AMPLI*'))
            if ('CALIBRATE_FLUX#ON_SOURCE' in myintents):
                field = np.append(field,mymsmd.fieldsforintent('CALIBRATE_FLUX*'))
            if ('CALIBRATE_DELAY#ON_SOURCE' in myintents):
                field = np.append(field,mymsmd.fieldsforintent('CALIBRATE_DELAY*'))
            field = sorted(list(np.unique(field)))
        else:
            field = sorted(list(mymsmd.fieldsforintent('*%s*'%intent) ))
            if (field == []):
                if (intent.find('FLUX') >= 0):
                    print "Looking for intent = *AMPLI* instead"
                    field = sorted(list(mymsmd.fieldsforintent('*AMPLI*') ))
                elif (intent.find('AMPLI') >= 0):
                    print "Looking for intent = *FLUX* instead"
                    field = sorted(list(mymsmd.fieldsforintent('*FLUX*') ))
                    
    elif (type(field)==int):
        field = [field]
    elif (type(field)==str):
        if (field.isdigit()):
            field = [int(field)]
        else:
            fieldlist = []
            for f in field.split(','):
                if (f not in mymsmd.namesforfields()):
                    print "Field %s is not in the ms." % (f)
                    return
                fieldlist.append(mymsmd.fieldsforname(f))
            field = fieldlist

    date = getObservationStartDate(vis).split()[0]

    sources = {}
    for i,f in enumerate(field):
        if (not silent):
            print "Working on field %d of %d: %d = %s" % (i+1, len(field), f, mymsmd.namesforfields(f)[0])
        if (f == ''):
            print "Error in field ID.  Not found in MS"
            return
        lowband = 3
        highband = 7
        if (lowbandFrequency is not None):
            lowband = freqToBand(parseFrequencyArgumentToHz(lowbandFrequency))[0]
        if (highbandFrequency is not None):
            highband = freqToBand(parseFrequencyArgumentToHz(highbandFrequency))[0]
        mydict = getALMAFlux(mymsmd.namesforfields(f)[0], frequency, 
                             verbose=verbose, date=date,
                             searchAdjacentNames=searchAdjacentNames, 
                             server=server, dayWindow=dayWindow, 
                             showplot=showplot, plotfile=plotfile,
                             silent=silent, lowbandFlux=lowbandFlux, highbandFlux=highbandFlux,
                             lowbandFrequency=lowbandFrequency,
                             highbandFrequency=highbandFrequency,
                             lowbandUncertainty=lowbandUncertainty,
                             highbandUncertainty=highbandUncertainty,
                             lowbandDate=lowbandDate, highbandDate=highbandDate,
                             lowband=lowband,highband=highband, 
                             ignoreHighBand=ignoreHighBand, defaultSpectralIndex=defaultSpectralIndex,
                             fitSpectralIndex=fitSpectralIndex, interpolateFromBand=interpolateFromBand)
        
        # returns None if connection failed
        # returns -1 if source not found
        if (mydict is not None and mydict != -1):
            if (referenceFrequency is not None):
                print "Interpolating from %f GHz to %f GHz" % (referenceFrequency*1e-9,frequency*1e-9)
                mydict['fluxDensity'] = referenceFlux*(frequency/referenceFrequency)**mydict['spectralIndex']
            if (sources == -1 or sources == None):
                sources = {}
            sources[mymsmd.namesforfields(f)[0]] = {'fluxDensity': mydict['fluxDensity'],
                                                    'fluxDensityUncertainty': mydict['fluxDensityUncertainty'],
                                                    'frequency': frequency,
                                                    'spectralIndex': mydict['spectralIndex'],
                                                    'spectralIndexUncertainty': mydict['spectralIndexUncertainty'],
                                                    'meanAge': mydict['meanAge'], 'monteCarloFluxDensity': mydict['monteCarloFluxDensity']
                                                    }
            extraKeys = ['spectralIndexAgeSeparation', 'spectralIndexAgeOldest','spectralIndexAgeYoungest','spectralIndexNPairs']
            for extraKey in extraKeys:
                if extraKey in mydict:
                    sources[mymsmd.namesforfields(f)[0]][extraKey] = mydict[extraKey]
        elif (not silent):
            if (mydict == -1):
                print "Source not found in catalog"
                if (sources == {}):
                    sources = -1
            else:
                print "mydict = ", mydict
                print "Failed to contact ALMA calibrator catalog."
                sources = None
    if msmdCreated:
        mymsmd.close()
    if (vis.find('.split') < 0):
        vissplit = vis + '.split'  # for pasting into script generator
    else:
        vissplit = vis
    if (sources != -1 and sources is not None):
        for field in sources.keys():
            data = sources[field]
            if (not silent):
                gap = '\n        '
                print "  setjy('%s',%sstandard='manual', field='%s', spix=%f,%sreffreq='%fGHz', fluxdensity=[%f,0,0,0])" % (vissplit,gap,field,data['spectralIndex'],gap,data['frequency']*1e-9,data['fluxDensity'])
    return(sources)

def computeFutureDate(dateString, age):
    """
    Takes a date string (returned by the ALMA calibrator database, i.e. YYYY-MM-DD)
    and age in days and computes a future date string to use that is the same number
    of days into the future from the original date.
    """
    dateString = dateString.replace('/','-')
    if (dateString.find('-') < 0):
        dateString = dateString[:4]+'-'+dateString[4:6]+'-'+dateString[6:]
    mydate = datetime.datetime.strptime(dateString,"%Y-%m-%d") + datetime.timedelta(days=age)
    futureDateString = mydate.strftime('%Y-%m-%d')
    return(futureDateString)

def readCSVLineIntoList(line, delimiter=','):
    """
    Uses the python csv tool to read a comma-separated-value string into a
    list of component strings.
    -Todd Hunter
    """
    readerOutput = csv.reader(StringIO.StringIO(line), delimiter=delimiter)
    mytokens = []
    for tokens in readerOutput:
        for token in tokens:
            mytokens.append(token)
    return(mytokens)

def findFindcontPlot(cube, working=None, stage=26, verbose=False):
    """
    Given a pipeline working directory and a science target cube name,
    returns the full path to the findcont.residual.meanSpectrum.*.png
    cube: cube name, with or without the full path.  If full path is not
           given, you need to also specify working directory
    working: if not specified, then get it from the leading directory of 
           the specified cube name
    -Todd Hunter
    """
    if working is None:
        working = os.path.dirname(cube).rstrip('/')
        if working[0] != '/':
            if os.path.islink(cube):
                cubelink = os.readlink(cube).rstrip('/')
                if verbose: print "cubelink: ", cubelink
                working = os.path.dirname(cubelink)
            else:
                working = os.path.dirname(cube)
    else:
        working = os.path.dirname(cube)
    if verbose: print "Searching working: ", working
    path = findFindcontStageDir(working,stage)
    if verbose: print "path = ", path
    if path is not None:
        pngs = glob.glob(os.path.join(path,'*.png'))
        if verbose: print "possible pngs: ", pngs
        for png in pngs:
            if png.find(os.path.basename(cube)) >= 0:
                if verbose: print "found png: ", png
                return png
    else:
        pngs = glob.glob(cube+'.meanSpectrum*sigma*.png')
        for png in pngs:
            if png.find('mom0mom8') < 0:
                return png
        print "No matching plot found in working directory either."

def findFindcontStageDir(working,stage=26):
    """
    Given a pipeline working directory returns the full path to the findcont 
    stage in the weblog.  e.g. '/blah/SOUS/GOUS/MOUS/working/pipeline-blah/html/stage26'
    -Todd Hunter
    """
    dirs = glob.glob(os.path.join(working,'pipeline-*'))
    weblogs = []
    for dir in dirs:
        if dir.find('.context') < 0:
            weblogs.append(dir)
#    print "weblogs: ", weblogs
    if len(weblogs) < 1:
        print "Could not find weblog directory in ", dirs
        return None
    weblog = sorted(weblogs)[-1]
    path = os.path.join(working,weblog,'html','stage%d'%stage)
    return path

def findPipelineImage(workingdir, field, spw, imgtype='mfs', stokes='I',iter=2, 
                      suffix='image', debug=False):
    """
    Given a working directory, finds a pipeline image for the specified field
    and spw.
    spw: string or int
    field: string name
    iter: int or string, if 2 then look first for 2 then 1
    """
    iteration = 'iter%s' % str(iter)
    wildcard = '*' + '.'.join([imgtype,stokes,iteration,suffix])
    wildcard = os.path.join(workingdir,wildcard)
    if debug: print "Searching for: ", wildcard
    imglist = glob.glob(wildcard)
    if debug: print "imglist: ", imglist
    for img in imglist:
        if img.find(field) > 0 and img.find('.spw%s'%str(spw)) > 0:
            return img
    if iter == 2:
        # did not find iter2, so now try iter1 (Cycle 5 pipeline)
        iteration = 'iter1'
        wildcard = '*' + '.'.join([imgtype,stokes,iteration,suffix])
        wildcard = os.path.join(workingdir,wildcard)
        if debug: print "Searching for: ", wildcard
        imglist = glob.glob(wildcard)
        if debug: print "imglist: ", imglist
        for img in imglist:
            if img.find(field) > 0 and img.find('.spw%s'%str(spw)) > 0:
                return img
    return ''

def extractPipelineStage(filename):
    """
    Extracts a string corresponding to the pipeline stage that generated a file.
    Example:  '28'
    -Todd Hunter
    """
    return(filename.split('.s')[1].split('_')[0])

def replacePipelineStage(filename, newstage):
    """
    Replaces the stage number in the name of a pipeline-generated file.
    newstage: int or string int;  if negative, then use as offset.
    -Todd Hunter
    """
    stage = extractPipelineStage(filename)
    if (newstage < 0):
        filename = filename.replace('.s%s_'%stage, '.s%s_'%str(int(stage)+newstage))
    else:
        filename = filename.replace('.s%s_'%stage, '.s%s_'%str(newstage))
    return(filename)

def getALMAFluxcsv(fluxcsv, lowband=3, highband=7, searchAdjacentNames=False, 
                   separationThreshold=14, maximumSensibleSpectralIndex=0.0,
                   silent=True, outfile='', pathToMs='./', server='',
                   fitSpectralIndex='closest', showplot=False, verbose=False,
                   interpolateFromBand='lowband'):
    """
    Reads a flux.csv file generated by the pipeline's import task and fills in
    updated flux density values from the ALMA calibrator database. The original
    file is renamed to *.original.  
    fluxcsv: name of the flux.csv file to process (it can include the path)
       The file must contain 7, 8 or 9 tokens per data line, where 7 corresponds 
       to the period before the comment was added; and 8 corresponds to the 
       subsequent period before the 5th calibrator value was added (spidx).
    lowband: the ALMA Band number to use as the low frequency flux measurement
    highband: the ALMA Band number to use as the high frequency flux measurement
    searchAdjacentNames: pass this flag to au.searchFlux
    separationThreshold: in days, if Band3/7 measurements are further apart then this, or
          the mean age of all measurements used greater than this, then write a warning
    maximumSensibleSpectralIndex: if larger than this, then write a warning 
    silent: if True, then only print errors, not normal information
    outfile: name of file to produce (it can include the path), default='flux.csv'
    server: name of server, passed to getALMAFlux
    fitSpectralIndex: 'contemporaneous' (previous default until 2017 Mar 31), 'closest' (default), 'mean'
        'contemporaneous': use the flux density pair nearest to specified date; 
        'closest': use the most recent pair with the smallest time separation;
        'mean': take weighted mean of all pairs having the smallest time separation
    showplot: passed to getALMAFlux
    verbose: passed to getALMAFlux
    interpolateFromBand: after determining spectral index, this parameter controls
        which band's measurement to interpolate from. Options are: 'lowband', 
        'highband', 'closestInTime', or 'closestInFrequency' (by ratio)
    -Todd Hunter
    """
    if (casadef.casa_version < casaVersionWithMSMD):
        print "This function requires the msmd tool, and thus casa >= ", casaVersionWithMSMD
        return
    if (not os.path.exists(fluxcsv)):
        print "Could not find file = ", fluxcsv
        return
    if os.path.isdir(fluxcsv):
        print "The fluxcsv parameter needs to be the text file (usually 'flux.csv'), not a measurement set."
        return
    f = open(fluxcsv,"r")
    lines = f.readlines()
    f.close()
    if (outfile == ''):
        newfluxcsv = fluxcsv
    else:
        newfluxcsv = outfile
    if (not os.path.exists(fluxcsv+'.original') and fluxcsv==newfluxcsv):
        if (not os.access(fluxcsv,os.W_OK)):
            print "You do not have privilege to write a backup of this file in this directory. Use the outfile parameter."
            return
        os.rename(fluxcsv, fluxcsv+'.original')
    dirname = os.path.dirname(newfluxcsv)
    if (dirname == ''): dirname = './'
    if (not os.access(dirname,os.W_OK)):
        print "You do not have privilege to write in this directory.  Use the outfile parameter."
        return
    if (os.path.exists(newfluxcsv)):
        if (not os.access(newfluxcsv,os.W_OK)):
            print "You do not have privilege to modify this file.  Use the outfile parameter."
            return
    f = open(newfluxcsv, "w")
    timestamp = "au.getALMAFluxcsv v%s executed on %s" % (version(True), mjdToUT(getMJD()))
    mymsmd = createCasaTool(msmdtool)
    myvis = None
    warningVis = ''
    warningField = ''
    spectralIndexWarningVis = ''
    spectralIndexWarningField = ''
    timestampWritten = False
    if (len(lines) == 1):
        print "This file (%s) has no data lines." % (fluxcsv)
    skippedSources = [] # not found in catalog
    failedSources = []  # failed to contact server
    for linectr, line in enumerate(lines):
        if (linectr > 0):
            s = "getALMAFluxCSV(): Working on line %d of %d" % (linectr,len(lines)-1)
            print s
            casalog.post(s, 'INFO')
        if (line[0] == '#'):
            f.write(line)
        else:
            tokens = line.split(',')
            if (tokens[0].find('uid') != 0):
                f.write(line)  # This will write out the header line.
            else:
                mytokens = readCSVLineIntoList(line.strip('\n').strip('\r'), delimiter=',')
                spidx = None
                if (len(mytokens) == 7):
                    # older style did not have a comment field
                    uid,field,spw,I,Q,U,V = mytokens
                    comment = ''
                elif (len(mytokens) == 8):
                    # current pipeline style includes a comment field
                    uid,field,spw,I,Q,U,V,comment = mytokens
                    comment = comment.strip('"')
                    # allow this function to be run repeatedly without making the line longer and longer
#                    comment = comment.split(' # ')[0]
                    comment = comment.split(' #')[0]
                elif (len(mytokens) == 9):
                    # someone recently added a value after the V flux density
                    uid,field,spw,I,Q,U,V,spidx,comment = mytokens
                    comment = comment.strip('"')
                    # allow this function to be run repeatedly without making the line longer and longer
#                    comment = comment.split(' # ')[0]
                    comment = comment.split(' #')[0]
                else:
                    print "Unsupported number of tokens = %d (not 7, 8, or 9)" % (len(mytokens))
                    print "tokens = ", mytokens
                    return
                if (pathToMs == ''):
                    dirname = os.path.dirname(fluxcsv)
                    if (len(dirname) > 0): dirname += '/'
                    vis =  dirname + uid
                else:
                    vis = pathToMs + '/' + uid
                if (vis != myvis):
                    if (myvis is not None): mymsmd.close()
                    if (not os.path.exists(vis)):
                        print "Could not find the measurement set: ", vis
                        return
                    mymsmd.open(vis)
                    myvis = vis
                if (int(field) < 0):
                    # try to parse the field name from the comment
                    sourcename = comment.split()[0]
                    print "Parsed field name from the comment string = %s." % (sourcename)
                    intfield = mymsmd.fieldsforname(sourcename)[0]
                else:
                    intfield = int(field)
                    sourcename = mymsmd.namesforfields(intfield)[0]
                frequency = mymsmd.meanfreq(int(spw))
                intents = ','.join(mymsmd.intentsforfield(intfield))
                mytimes = mymsmd.timesforfield(intfield)
                mydict = None
                if len(mytimes) == 0:
                    print "Field %s was never observed!" % (str(intfield))
                    mydict = -1
                elif (sourcename in skippedSources):
                    print "Skipping source %s, as it was already not found in the catalog." % (sourcename)
                    mydict = -1
                else:
                    date = mjdsecToUT(mytimes[0]).split()[0]  # YYYY-MM-DD
                    if not silent:
                        print "Calling au.getALMAFlux('%s', %f, %d, %d, date='%s', fitSpectralIndex='%s', interpolateFromBand='%s')" % (sourcename, frequency, lowband, highband, date, fitSpectralIndex, interpolateFromBand)
                    mydict = getALMAFlux(sourcename, frequency, lowband, highband, date=date,
                                         searchAdjacentNames=searchAdjacentNames, silent=silent, 
                                         server=server, fitSpectralIndex=fitSpectralIndex, 
                                         showplot=showplot, verbose=verbose, 
                                         interpolateFromBand=interpolateFromBand)
                    if (mydict == None):
                        s = "getALMAFluxCSV(): Connection failed, skipping this source: %s" % (sourcename)
                        casalog.post(s,'WARN')
                        print s
                        failedSources.append(sourcename)
                    if (mydict == -1):
                        print "Source %s not found in catalog, skipping." % (sourcename)
                        skippedSources.append(sourcename)
                if (mydict == None or mydict == -1):
                    I = 0
                    ageDifference = 0
                    meanAge = 0
                else:
                    I = mydict['fluxDensity']
                    Iunc = mydict['fluxDensityUncertainty']
                    spectralIndex = mydict['spectralIndex']
                    spectralIndexUncertainty = mydict['spectralIndexUncertainty']
                    ageDifference = mydict['ageDifference']
                    meanAge = mydict['meanAge']
                if ((ageDifference > separationThreshold or meanAge > separationThreshold) and
                    (vis != warningVis or field != warningField)):
                    if (comment.find('AMPLITUDE')>=0 or comment.find('FLUX')>=0 or
                        intents.find('AMPLITUDE')>=0 or intents.find('FLUX')>=0):
                        if (ageDifference > separationThreshold):
                            print 'WARNING: Measurements for field %s (%s) at Band %d & %d differ by %.0f days, causing further uncertainty in the spectral index.' % (field, sourcename, lowband, highband, ageDifference)
                        if (meanAge > separationThreshold):
                            print 'WARNING: Measurements for field %s (%s) differ by %.0f days from the science observation, causing further flux density uncertainty.' % (field, sourcename, meanAge)
                        print 'Consult the time plots on the ALMA calibrator web tool to check the validity of the flux densities.'
                    warningVis = vis
                    warningField = field
                if (mydict == None):
                    dataline = line[:-2] + ' # failed to contact calibrator catalog server!\n'
                elif mydict == -1:
                    dataline = line[:-2] + ' # no entries in ALMA catalog!\n'
                else:
                    if (spidx == None):
                        originalLine = '%s,%s,%s,%.4f,%s,%s,%s' % (uid,field,spw,I,Q,U,V)
                    else:
                        originalLine = '%s,%s,%s,%.4f,%s,%s,%s,%s' % (uid,field,spw,I,Q,U,V,spectralIndex)
                    dataline = '%s,"%s # +-%.4fJy, freq=%.3fGHz' % (originalLine,comment,Iunc,frequency*1e-9)
                    if (vis != spectralIndexWarningVis or field != spectralIndexWarningField):
                        if (spectralIndex > maximumSensibleSpectralIndex):
                            print '#WARNING: The spectral index of %+.1f for field %s (%s) is unusual for a quasar. There may be a problem with the flux monitoring data\n' % (spectralIndex, field, sourcename)
                        if 'spectralIndexAgeOldest' in mydict.keys():    
                            spectralIndexAgeOldest = mydict['spectralIndexAgeOldest']
                            spectralIndexAgeYoungest = mydict['spectralIndexAgeYoungest']
                            if spectralIndexAgeOldest == spectralIndexAgeYoungest:
                                dataline += ", spec_index=%.3f+-%.3f, Band%d/%d_separation=%.0f days, spixAge=%+.0f days, Band%dage=%.0f days, setjy parameters for field %s (%s): spix=%.4f, reffreq='%.4fGHz', fluxdensity=[%.6f,0,0,0]" % (spectralIndex,spectralIndexUncertainty, lowband, highband, mydict['spectralIndexAgeSeparation'], spectralIndexAgeOldest, lowband, meanAge, field, sourcename, spectralIndex, frequency*1e-9,I)
                            else:
                                dataline += ", spec_index=%.3f+-%.3f, Band%d/%d_separation=%.0f days, spixAge=%+.0f-%+.0f days, Band%dage=%.0f days, setjy parameters for field %s (%s): spix=%.4f, reffreq='%.4fGHz', fluxdensity=[%.6f,0,0,0]" % (spectralIndex,spectralIndexUncertainty, lowband, highband, mydict['spectralIndexAgeSeparation'], spectralIndexAgeYoungest, spectralIndexAgeOldest, lowband, meanAge, field, sourcename, spectralIndex, frequency*1e-9,I)
                        else:
                            dataline += ", spec_index=%.3f+-%.3f, Band%d/%d_separation=%.0f days, meanAge=%.0f days, setjy parameters for field %s (%s): spix=%.4f, reffreq='%.4fGHz', fluxdensity=[%.6f,0,0,0]" % (spectralIndex,spectralIndexUncertainty, lowband, highband, ageDifference, meanAge, field, sourcename, spectralIndex, frequency*1e-9,I)
                        spectralIndexWarningVis = vis
                        spectralIndexWarningField = field
                if (mydict is not None and mydict != -1):
                    if (not timestampWritten):
                        dataline += ", " + timestamp
                        timestampWritten = True
                    f.write(dataline + '"\n')  
                else: # Just echo the original line because we could not find new info on the source
                    f.write(dataline)
    if (myvis is not None): mymsmd.close()
    f.close()

def getALMASpectralIndex(sourcename, date='', lowband=3, highband=7, server='', sourceBandLimit=500, 
                         dayWindow=1800, maxrows=500, returnDict=False, useMostRecent=True,
                         verbose=False, showFits=False, makeplot=False):
    """
    Searches ALMA calibrator catalog for pairs of measurements in 2 bands, finds the minimum
    separation (in integer days), and computes the median and MAD of the spectral index 
    measurement on *all* measurements that match that separation, or, optionally, 
    only the most recent measurement that match that separation.
    Inputs:
    date: optional string, YYYYMMDD, e.g. '20120101' or '2012-01-01'
          or '2012/01/01'  where delimiter can be any non-integer character
          if blank or None, then use today's date.
    lowband, highband: ALMA band numbers to use in catalog search
    server: pass this string to au.searchFlux (name of xmlrpc database URL)
            can be 'internal', 'external' or full URL
    showFits: if True, then print the result of each spectral index fit
    dayWindow: passed to searchFlux
    returnDict: if False, then return a tuple of spectralIndex and its uncertainty
                if True, then return a dictionary similar to linfit().spectralindex
                containing keys: 'spectralIndex', 'spectralIndexUncertainty',
                                 'ageDifference' 'intercept', 'meanOfLogX',
                                 'interceptUncertainty', 'npairs', 'oldest', 'youngest'
    useMostRecent: if True, then only fit the most recent age pair when multiple pairs
            have the same separation; if False, then fit each pair and take the weighted mean
            Note: False can take a long time for frequently-observed quasars (e.g. for
                  96 measurement pairs, it takes 56 seconds compared to 8 seconds.
    -Todd Hunter
    """
    if makeplot and useMostRecent:
        print "makeplot=True is only relevant with useMostRecent=False, setting it that way."
        useMostRecent = False
    if date == '':
        date = getCurrentDate()
    lowresults = searchFlux(sourcename, date, lowband, server=server, returnMostRecent=True,
                            sourceBandLimit=sourceBandLimit, dayWindow=dayWindow, 
                            maxrows=maxrows, verbose=verbose)
    lowAges = []
    if (type(lowresults) == int):
        return
    for result in lowresults:
        lowAges.append(result['age'])
    lowAges = np.unique(lowAges)
    highresults = searchFlux(sourcename, date, highband, server=server, returnMostRecent=True,
                             sourceBandLimit=sourceBandLimit, dayWindow=dayWindow, 
                             maxrows=maxrows, verbose=verbose)
    minSeparation = 1e10
    measurement = {}
    high_agepairs = []
    for lowAge in lowAges:
        if verbose: print "Checking low age = ", lowAge
        measurement[lowAge] = {'freq':[], 'flux':[], 'uncertainty':[]}
        # find the measurements that match this age
        for result in lowresults:
            if (lowAge == result['age']):
                measurement[lowAge]['freq'].append(result['frequency'])
                measurement[lowAge]['flux'].append(result['flux'])
                measurement[lowAge]['uncertainty'].append(result['uncertainty'])
        # find the highresult closest in age to the current lowAge        
        for i,result in enumerate(highresults):
            separation = abs(result['age'] - lowAge)
            if (separation < minSeparation):
                minSeparation = separation
                agepairs = [lowAge]
                highs = [i]
                high_agepairs = [result['age']]
            elif separation == minSeparation:
                agepairs.append(lowAge)
                highs.append(i)
                high_agepairs.append(result['age'])
        if verbose: print "  best matching high age = %d (%d), separation = %d" % (high_agepairs[-1], highs[-1], abs(high_agepairs[-1] - lowAge))
    if useMostRecent:
        i = np.argmin(np.abs(agepairs))
        highs = [highs[i]]
        agepairs = [agepairs[i]]
        s = "getALMAFluxCSV(): Fitting for spectral index with 1 measurement pair of age %d days from %s, with age separation of %d days" % (agepairs[0], date, minSeparation)
        print s
        casalog.post(s,'INFO')
        oldest = agepairs[0]
        youngest = oldest
    else:
        oldest = np.max(agepairs)
        youngest = np.min(agepairs)
        s = "getALMAFluxCSV(): Fitting for spectral index with %d measurement pairs between %d-%d days from %s, each with age separation of %d days" % (len(agepairs), youngest, oldest, date, minSeparation)
        casalog.post(s,'INFO')
    spectralIndex = []                                                 
    spectralIndexUncertainty = []     
    intercept = []; interceptUncertainty = []; meanOfLogX = []; covar = []
    silent = not verbose
    for i,age in enumerate(agepairs):
        if verbose:
            print "Picking i=%d, highs[i]=%d" % (i,highs[i])
        freqs = measurement[age]['freq'] + [highresults[highs[i]]['frequency']]
        fluxes = measurement[age]['flux'] + [highresults[highs[i]]['flux']]
        errors = measurement[age]['uncertainty'] + [highresults[highs[i]]['uncertainty']]
        if (useMostRecent): 
            print "  %s: freqs=%s, fluxes=%s" % (addDays(date,int(-age)), [float('%.2f' % i) for i in list(np.array(freqs)*1e-9)], fluxes)
            if verbose:
                print "  errors = ", errors
        mydict = linfit().spectralindex(freqs=freqs, fluxes=fluxes, errors=errors, silent=silent, showplot=makeplot) 
        intercept.append(mydict['intercept'])
        interceptUncertainty.append(mydict['interceptUncertainty'])
        meanOfLogX.append(mydict['meanOfLogX'])
        spectralIndex.append(mydict['spectralIndex'])
        spectralIndexUncertainty.append(mydict['spectralIndexUncertainty'])
        covar.append(mydict['covar'])
        if showFits: print "Result for age %d days: %.3f +- %.3f" % (age, spectralIndex[-1], spectralIndexUncertainty[-1])
    if not useMostRecent:
        print "Computing weighted mean and MAD of %d measurement pairs as old as %d days, each with age separation: %d days" % (len(spectralIndex), oldest, minSeparation)
        if verbose:
            print spectralIndex
    siUncertainty = np.array(spectralIndexUncertainty)
    si = np.average(spectralIndex, weights=1/siUncertainty**2)
    if (len(spectralIndex) > 1):
        siUncertainty = MAD(spectralIndex)
        if makeplot:
            pb.clf()
            pb.errorbar(-np.array(agepairs),spectralIndex,yerr=siUncertainty,color='k',fmt='o')
            pb.xlabel('Days relative to %s' % date)
            pb.ylabel('ALMA Spectral index (band %d-%d)' % (lowband,highband))
            pb.title(sourcename)
            pb.plot(pb.xlim(), [si,si], 'k--')
            pb.plot(pb.xlim(), [si+siUncertainty]*2, 'k:')
            pb.plot(pb.xlim(), [si-siUncertainty]*2, 'k:')
            png = sourcename + '_spectralindex.png'
            pb.savefig(png)
            print "Wrote plot: ", png
    else:
        siUncertainty = siUncertainty[0]
    if (not returnDict):
        return(si, siUncertainty)
    else:
        iUncertainty = np.array(interceptUncertainty)
        inter = np.average(intercept, weights=1/iUncertainty**2)
        mOLX = np.average(meanOfLogX, weights=1/iUncertainty**2)
        covar = np.average(covar, axis=0)
        meandict = {'spectralIndex': si, 'spectralIndexUncertainty': siUncertainty, 
                    'ageDifference': minSeparation, 'intercept': inter, 
                    'interceptUncertainty': MAD(intercept), 'meanOfLogX': mOLX,
                    'npairs': len(agepairs), 'oldest': youngest, 'youngest': oldest, 'covar': covar}
        return(meandict)

def getALMAFlux(sourcename, frequency, lowband=3, highband=7, ignoreLowBand=False,
                ignoreHighBand=False, simulateLowBand=False, simulateHighBand=False,
                defaultSpectralIndex=-0.7, defaultSpectralIndexUncertainty=0.2,
                verbose=False, trials=10000,date='',searchAdjacentNames=False, 
                server='', dayWindow=0, showplot=False, plotfile='', silent=False,
                separationThreshold=14, maximumSensibleSpectralIndex=0.0, lowbandFlux=None,
                highbandFlux=None, lowbandFrequency=None, highbandFrequency=None,
                lowbandUncertainty=None, highbandUncertainty=None,
                lowbandDate=None, highbandDate=None, sourceBandLimit=500,
                fitSpectralIndex='closest', makeSpectralIndexPlot=False,
                interpolateFromBand='lowband'): 
    """
    Queries the ALMA calibrator catalog for flux density measurements in two bands.
    It first computes the spectral index, then interpolates or extrapolates to the
    desired frequency.  It then performs a Monte-Carlo simulation to obtain the flux
    density uncertainty.  If the date is not specified, it simply gets the most recent
    measurements.  If the date is specified, then it finds the measurements in each
    band that are closest to that date, either in the past or future.
    
    returns None if connection failed
    returns -1 if source not found
    otherwise it returns a dictionary with the following keys:
      {'fluxDensity', 'spectralIndex','spectralIndexUncertainty','fluxDensityUncertainty', 
       'meanAge','ageDifference','monteCarloFluxDensity'}
    Parameters:
    sourcename: the name of the object (spaces after '3C' will be removed)
    frequency: the frequency for which to estimate the flux density.  It can be a
       floating point value in Hz or GHz, or string with units (Hz, kHz, MHz, GHz).
    lowband: the ALMA band to use for the low frequency measurement
    highband: the ALMA band to use for the high frequency measurement
    ignoreLowBand: ignore any measurements in the low frequency band
    ignoreHighBand: ignore any measurements in the high frequency band
    simulateLowBand: set to 3.0 Jy (meant only for allow testing)
    simulateHighBand: set to 1.0 Jy (meant only for testing)
    defaultSpectralIndex: spectral index to use if only one band measurement is available
    defaultSpectralIndexUncertainty:  uncertainty to use
    trials: the number of trials to run in the Monte-Carlo simulation of the uncertainty
    date: the date in the past to begin looking for earlier measurements (default=today)
          formats accepted: '20120101' or '2012-01-01' or '2012/01/01'  where the
                             delimiter can be any non-integer character
    searchAdjacentNames: pass this flag to au.searchFlux
    server: pass this string to au.searchFlux (name of xmlrpc database URL)
            can be 'internal', 'external' or full URL
    dayWindow: if non-negative, then process all measurements within this
               many days of the first measurement found (per band)
    showplot: if True, then produce a plot with errorbars and model
    plotfile: write the plot to a file
    silent: if True, then don't print the normal status messages
    separationThreshold: in days, if Band3/7 measurements are further apart then this, or
          the mean age of all measurements used greater than this, then write a warning
    maximumSensibleSpectralIndex: if larger than this, then write a warning
    fitSpectralIndex: 'contemporaneous' (previous default until 2017 Mar 31), 'closest' (default), 'mean'
        'contemporaneous': use the flux density pair nearest to specified date; 
        'closest': of all pairs with same smallest time separation, use closest pair;
        'mean': take weighted mean of all pairs having the smallest time separation
        The latter two will call getALMASpectralIndex with useMostRecent=True,False
        and dayWindow=1800.
    interpolateFromBand: after determining spectral index, this parameter controls
        which band's measurement to interpolate from. Options are: 'lowband', 
        'highband', 'closestInTime', or 'closestInFrequency' (by ratio)

    The following parameters allow you to use a different measurement from what
    is in the catalog:
    lowbandFlux: recently measured value to use instead of the database value (Jy)
    highbandFlux: recently measured value to use instead of the database value (Jy)
    lowbandFrequency: frequency of lowbandFlux
    highbandFrequency: frequency of highbandFlux
    lowbandUncertainty: uncertainty of lowbandFlux
    highbandUncertainty: uncertainty of highbandFlux
    lowbandDate: date for lowbandFlux
    highbandDate: date for highbandFlux
    """
    fitSpectralIndexOptions = ['contemporaneous','closest','mean']
    if (fitSpectralIndex not in fitSpectralIndexOptions):
        print "fitSpectralIndex must be one of: ", fitSpectralIndexOptions
        return
    if (date == ''):
        date = getCurrentDate(delimiter='-')
    if (lowbandFlux is not None or lowbandFrequency is not None or lowbandUncertainty is not None or lowbandDate is not None):
        if (lowbandFlux == None or lowbandFrequency == None or lowbandUncertainty == None or lowbandDate == None):
            print "lowbandFlux, lowbandFrequency, lowbandUncertainty, lowbandDate must all be specified."
            return
        lowbandFrequency = parseFrequencyArgumentToHz(lowbandFrequency)
    if (highbandFlux is not None or highbandFrequency is not None or highbandUncertainty is not None or highbandDate is not None):
        if (highbandFlux == None or highbandFrequency == None or highbandUncertainty == None or highbandDate == None):
            print "highbandFlux, highbandFrequency, highbandUncertainty, highbandDate must all be specified."
            return
        highbandFrequency = parseFrequencyArgument(highbandFrequency)
    if (type(frequency) == str):
        frequency = parseFrequencyArgumentToHz(frequency)
    if (frequency < 2000):
        frequency *= 1e9
    allresults = {}
    noLowBandMeasurement = True
    noHighBandMeasurement = True
    if (ignoreLowBand and ignoreHighBand):
        print "No measurements available."
        return
    for badPrefix in ['3C ', 'QSO ']:
        if verbose:
            print "Comparing: '%s' with '%s'" % (sourcename[:len(badPrefix)].upper(), badPrefix)
        if (sourcename[:len(badPrefix)].upper() == badPrefix):
            sourcename = sourcename[:len(badPrefix)-1] + sourcename[len(badPrefix):]
            if verbose:
                print "Stripping out extraneous space after ", sourcename[:len(badPrefix)-1]
            if sourcename[:3] == 'QSO':
                sourcename = sourcename[3:]
                if verbose:
                    print "Stripping out 'QSO'"
    for band in [lowband,highband]:
        if (band == lowband and ignoreLowBand): continue
        if (band == highband and ignoreHighBand): continue
        if (verbose):
            print "Calling searchFlux('%s', band=%s, date='%s', returnMostRecent=True, verbose=%s, searchAdjacentNames=%s)" % (sourcename, band, date, verbose, searchAdjacentNames)
        results = searchFlux(sourcename, band=band, date=date, returnMostRecent=True,
                             verbose=verbose, searchAdjacentNames=searchAdjacentNames, 
                             server=server, dayWindow=dayWindow, sourceBandLimit=sourceBandLimit)
        if (verbose):
            print "Band %d results = " % (band), results
        if (results == None): return None
        if (results == -1):
            if (not silent):
                print "No band %s measurements found for %s in the catalog" % (band,sourcename)
            continue  # source not found in catalog
        if (dayWindow < 0):
            results = [results]
        allresults[band] = {} # each key is an array of the same length
        allresults[band]['frequency'] = []
        allresults[band]['flux'] = []
        allresults[band]['uncertainty'] = []
        allresults[band]['age'] = []
        for result in results:
            if (type(result) == NoneType or simulateLowBand or simulateHighBand):
                if (type(result) == NoneType):
                    print "The calibrator database is not currently accessible."
                if (simulateLowBand or simulateHighBand):
                    if (simulateLowBand):
                        allresults[lowband]['frequency'].append(90e9)
                        allresults[lowband]['flux'].append(3)
                        allresults[lowband]['uncertainty'].append(0.3)
                        allresults[lowband]['age'].append(100)
                        noLowBandMeasurement = False
                    if (simulateHighBand):
                        allresults[lowband]['frequency'].append(340e9)
                        allresults[lowband]['flux'].append(1)
                        allresults[lowband]['uncertainty'].append(0.1)
                        allresults[lowband]['age'].append(100)
                        noHighBandMeasurement = False
                else:
                    return None
            elif (type(result) == int):
                print "No Band %d observation in the catalog for this source" % (band)
                if (band == highband):
                    if (noLowBandMeasurement):
                        print "No measurement in either band.  Cannot produce a flux density."
                        return None
            else:
                # Clean up the existing measurement, if necessary
                if (result['uncertainty'] == 0.0):
                    print "No uncertainty in the catalog for this measurement, assuming 10 percent."
                    result['uncertainty'] = 0.1*(result['flux'])
                if (result['flux'] <= 0):
                    print "WARNING: Found flux density = %f, discarding" % (result['flux'])
                    continue
                if (band==lowband):
                    noLowBandMeasurement = False
                else:
                    noHighBandMeasurement = False
                if (band==lowband and lowbandFlux is not None):
                    allresults[band]['frequency'].append(lowbandFrequency)
                    allresults[band]['flux'].append(lowbandFlux)
                    allresults[band]['age'].append(computeIntervalBetweenTwoDays(date,lowbandDate))
                    allresults[band]['uncertainty'].append(lowbandUncertainty)
                elif (band==highband and highbandFlux is not None):
                    allresults[band]['flux'].append(result['flux'])
                    allresults[band]['frequency'].append(highbandFlux)
                    allresults[band]['age'].append(computeIntervalBetweenTwoDays(date,highbandDate))
                    allresults[band]['uncertainty'].append(highbandUncertainty)
                else:
                    allresults[band]['frequency'].append(result['frequency'])
                    allresults[band]['flux'].append(result['flux'])
                    allresults[band]['uncertainty'].append(result['uncertainty'])
                    allresults[band]['age'].append(result['age'])
                if (not silent):
                    print "Closest Band %d measurement: %.3f +- %.3f (age=%+d days) %.1f GHz" % (band, allresults[band]['flux'][-1],
                                                            allresults[band]['uncertainty'][-1],
                                                            allresults[band]['age'][-1],
                                                            allresults[band]['frequency'][-1]*1e-9)
#                    print "   all ages relative to %s: " % (date), allresults[band]['age']
                        

        if (date != '' and dayWindow < 0):
            if (type(result) != int):
                futureDate = computeFutureDate(date,result['age'])
            else:
                futureDate = computeFutureDate(date,365*10) # look ahead 10 years
            futureResult = searchFlux(sourcename, band=band, date=futureDate,
                                      returnMostRecent=True, verbose=verbose, server=server,
                                      sourceBandLimit=sourceBandLimit)
            if (type(futureResult) != int):
                if (futureResult['date'] != result['date']):
                    # then the measurement after the observation date is closer in time than the one
                    # before, so use it
                    result = python_copy.deepcopy(futureResult)
                    if (result['uncertainty'] == 0.0):
                        print "No uncertainty in the catalog for this measurement, assuming 10 percent."
                        result['uncertainty'] = 0.1*(result['flux'])
                    allresults[band]['frequency'].append(result['frequency'])
                    allresults[band]['flux'].append(result['flux'])
                    allresults[band]['uncertainty'].append(result['uncertainty'])
                    allresults[band]['age'].append(result['age'])
    # end 'for' loop over band
    if (allresults == {}): return -1
    spectralIndex = defaultSpectralIndex
    spectralIndexUncertainty = defaultSpectralIndexUncertainty
    spectralIndexAgeSeparation = None
    if (noLowBandMeasurement or noHighBandMeasurement):
        if (noLowBandMeasurement):
            band = highband
        else:
            band = lowband
        interpolationBand = band
        freqs = [allresults[band]['frequency'][0]]
        fluxDensity = allresults[band]['flux'][0] * (frequency/allresults[band]['frequency'][0])**spectralIndex

        # The following does not account for uncertainty in the spectral index,
        # but prevents a crash when defining mydict later.
        fluxDensityUncertainty = fluxDensity * allresults[band]['uncertainty'][0]/allresults[band]['flux'][0]
        
        intercept = np.log10(fluxDensity) 
        # interceptUncertainty should simply be the flux density uncertainty on the log scale
        interceptUncertainty = 0.434*allresults[band]['uncertainty'][0]/allresults[band]['flux'][0]
        meanAge = allresults[band]['age'][0]
        meanOfLogX = np.log10(allresults[band]['frequency'][0]*1e-9) 
        ageDifference = 0
        if noHighBandMeasurement:
            # The fluxes[0] value is used later in the print statement below, so we must fill it.
            fluxes = allresults[lowband]['flux']
    else:
        # compute the mean interval in days between the science observation and the flux monitoring observation
        ageDifference = fabs(np.mean(allresults[lowband]['age']) - np.mean(allresults[highband]['age']))
        freqs = allresults[lowband]['frequency'] + allresults[highband]['frequency']
        fluxes = allresults[lowband]['flux'] + allresults[highband]['flux']
        errors = allresults[lowband]['uncertainty'] + allresults[highband]['uncertainty']
        if (fitSpectralIndex == 'contemporaneous'):
            meanAge = np.mean(np.abs([allresults[lowband]['age'] + allresults[highband]['age']]))
            if (verbose):
                print "Calling linfit().spectralindex(freqs=%s, fluxes=%s, errors=%s, showplot=%s, plotfile='%s', source='%s', silent=%s)" % (str(freqs),str(fluxes),str(errors),showplot,plotfile,sourcename,silent)
            mydict = linfit().spectralindex(freqs=freqs, fluxes=fluxes, errors=errors, showplot=showplot, 
                                            plotfile=plotfile, source=sourcename, silent=silent)
        else:
            dayWindow = 1800
            if (fitSpectralIndex == 'mean'):
                useMostRecent = False
            else:
                useMostRecent = True
            maxrows = 500
            if verbose:
                print "Calling au.getALMASpectralIndex('%s', '%s', %s, %s, '%s', %d, %d, %d, returnDict=True, useMostRecent='%s', verbose=%s)" % (sourcename, date, lowband, highband, server, sourceBandLimit, dayWindow, maxrows, useMostRecent, verbose)
            mydict = getALMASpectralIndex(sourcename, date, lowband, highband, server,
                                          sourceBandLimit, dayWindow, maxrows, returnDict=True,
                                          useMostRecent=useMostRecent, verbose=verbose,
                                          makeplot=makeSpectralIndexPlot)
            spectralIndexAgeSeparation = mydict['ageDifference']
            spectralIndexAgeOldest = mydict['oldest']
            spectralIndexAgeYoungest = mydict['youngest']
            spectralIndexNPairs = mydict['npairs']
            meanAge = np.mean(allresults[lowband]['age'])
        meanOfLogX = mydict['meanOfLogX']
        spectralIndex = mydict['spectralIndex']
        spectralIndexUncertainty = mydict['spectralIndexUncertainty']
        intercept = mydict['intercept']
        interceptUncertainty = mydict['interceptUncertainty']
        # Here we always interpolate from the lowband flux, since it is most likely to
        # have been measured most accurately and/or most recently.
        if interpolateFromBand == 'lowband':
            interpolationBand = lowband
        elif interpolateFromBand == 'highband':
            interpolationBand = highband
        elif interpolateFromBand in ['closestInTime', 'nearestInTime']:
            if np.abs(np.mean(allresults[lowband]['age'])) > np.abs(np.mean(allresults[highband]['age'])):
                interpolationBand = highband
            else:
                interpolationBand = lowband
        elif interpolateFromBand in ['closestInFrequency', 'nearestInFrequency']:
            lowFreq = np.mean(allresults[lowband]['frequency'])
            highFreq = np.mean(allresults[highband]['frequency'])
            lowbandRatio = np.abs(frequency-lowFreq)/np.mean([frequency,lowFreq])
            highbandRatio = np.abs(frequency-highFreq)/np.mean([frequency,highFreq])
            if lowbandRatio > highbandRatio:
                interpolationBand = highband
            else:
                interpolationBand = lowband
        else:
            print "**** Unrecognized value for interpolateFrom, assuming lowband"
            interpolationBand = lowband
        fluxDensity = np.mean(allresults[interpolationBand]['flux']) * (frequency/np.mean(allresults[interpolationBand]['frequency']))**spectralIndex
            
    logfit = True
    if (not noLowBandMeasurement and not noHighBandMeasurement):
        fluxDensityUncertainty, monteCarloFluxDensity = linfit().computeStdDevMonteCarlo(spectralIndex,
                                                        spectralIndexUncertainty,
                                                        intercept,
                                                        interceptUncertainty,
                                                        frequency*1e-9,
                                                        trials,logfit,meanOfLogX,
                                                        covar=mydict['covar'], silent=silent, returnMedian=True)
    else:
        # no monte carlo available, so just set it to the spectral index f.d.
        monteCarloFluxDensity = fluxDensity
    mydict = {'fluxDensity': fluxDensity, 'spectralIndex': spectralIndex,
              'spectralIndexUncertainty': spectralIndexUncertainty,
              'fluxDensityUncertainty': fluxDensityUncertainty, 
              'ageDifference': ageDifference, 'monteCarloFluxDensity': monteCarloFluxDensity}
    if spectralIndexAgeSeparation is not None:
        mydict['meanAge'] = meanAge
        mydict['spectralIndexAgeSeparation'] = spectralIndexAgeSeparation
        mydict['spectralIndexAgeOldest'] = spectralIndexAgeOldest
        mydict['spectralIndexAgeYoungest'] = spectralIndexAgeYoungest
        mydict['spectralIndexNPairs'] = spectralIndexNPairs
    else:
        mydict['meanAge'] = meanAge
    if (not silent):
        print "Result using spectral index of %.6f for %.3f GHz from %.3f Jy at %.3f GHz = %.6f +- %.6f Jy" % (spectralIndex, frequency*1e-9, np.mean(allresults[interpolationBand]['flux']), np.mean(allresults[interpolationBand]['frequency'])*1e-9, mydict['fluxDensity'], mydict['fluxDensityUncertainty'])
        if (meanAge > separationThreshold):
            print "WARNING: the mean time separation between the target date and the flux monitoring observations is %d days" % (meanAge)
        if (ageDifference > separationThreshold and fitSpectralIndex=='contemporaneous'):
            print "WARNING: the time separation between the Band %d and %d measurements is %d days" % (lowband,highband,ageDifference)
        if (spectralIndex > maximumSensibleSpectralIndex):
            print 'WARNING: The spectral index of %+.1f is unusual for a quasar. There may be a problem with the flux monitoring data.' % (spectralIndex)
    return(mydict)
    # sourcename

def convertSourceTypes(types):
    """
    Convert a list of calibrator catalog source types from string to 
    integer code.
    types: either a python list or array, or a comma-delimited string
    - Todd Hunter
    """
    mytypes = []
    sourceTypes = {'grid':25, 'line':4, 'point':1, 'polarization':24, 'flux': 64}
    if (type(types) == list or type(types) == np.ndarray):
        if (type(types[0]) == str):
            for t in types:
                if (t not in sourceTypes.keys()):
                    print "Illegal source type = ", t
                    return
                mytypes.append(sourceTypes[t])
        else:
            mytypes = types
    elif (type(types) == str):
        # Assume it is a comma-delimited string
        types = types.split(',')
        for t in types:
            if (t not in sourceTypes.keys()):
                    print "Illegal source type = ", t
                    return
            mytypes.append(sourceTypes[t])
    else:
        mytypes = [types]
    return mytypes

def searchFluxForMS(vis, band=None, maxrows=10, sourceBandLimit=500):
    """
    Runs searchFlux on all calibrators in a measurement set.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not open measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    allfields = mymsmd.fieldsforintent('*')
    if ('OBSERVE_TARGET#ON_SOURCE' in mymsmd.intents()):
        fields = mymsmd.fieldsforintent('OBSERVE_TARGET#ON_SOURCE')
    else:
        fields = []
    for field in allfields:
        if field not in fields:
            searchFlux(sourcename=mymsmd.namesforfields(field)[0], band=band, maxrows=maxrows, sourceBandLimit=sourceBandLimit)
    mymsmd.close()
    return
    
def searchFluxPolarization(sourcename='%', fLower=100e9, fUpper=105e9, verbose=False):
    """
    Search catalog for latest measurements of polarization calibrators.
    -Todd Hunter
    """
    searchFlux(sourcename=sourcename,types='polarization',sourceBandLimit=1,fLower=fLower,
               fUpper=fUpper,maxrows=100,verbose=verbose) 

def getALMAFluxSMA(sourcename, smafilename, interpolateFromBand='lowband'):
    """
    Takes an ASCII table of flux density measurements exported using the "data"
    link from the SMA calibrator database (sma1.sma.hawaii.edu/callist/calllist.html) 
    and runs getALMAFlux on all of the dates and determines the statistics of the 
    relative flux scale.
    smafilename: file format:
    ! lots of comment lines
    !BAND    UT DATE   TIME    OBSERV.   F(GHz)   FLUX(JY)   ERROR    FLUX P.I.
    1mm   01 Oct 2004 04:15   SMA       223.87   0.490 +/-  0.039    mgurwell 
    etc.
    interpolateFromBand: after determining spectral index from the ALMA data, this 
        parameter controls  which ALMA band's measurement to interpolate from. 
        Options: 'lowband', 'highband', 'closestInTime', or 'closestInFrequency' (by ratio)
    -Todd Hunter
    """
    if not os.path.exists(smafilename):
        print "Could not find SMA data file name."
        return
    f = open(smafilename,'r')
    lines = f.readlines()
    f.close()
    month = ['0','Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct',
             'Nov','Dec']
    alma = []
    sma = []
    for i,line in enumerate(lines):
        a = line.split()
        if (len(a) < 11): continue
        freq = float(a[6])
        date = '%s%02d%s' % (a[3],month.index(a[2]),a[1])
        print "Processing date %d/%d: %s" % (i+1,len(lines), date)
        mydict = getALMAFlux(sourcename, freq, date=date, interpolateFromBand=interpolateFromBand)
        if mydict == -1 or mydict == None:
            return
#      {'fluxDensity', 'spectralIndex','spectralIndexUncertainty','fluxDensityUncertainty', 'meanAge','ageDifference','monteCarloFluxDensity'}
        alma.append(mydict['fluxDensity'])
        sma.append(float(a[7]))
    alma = np.array(alma)
    sma = np.array(sma)
    print "Median of %d values: ALMA=%.3fJy, SMA=%.3fJy, median ratio ALMA/SMA=%.3f+-%.3f" % (len(sma),np.median(alma), np.median(sma), np.median(alma/sma), MAD(alma/sma))

def mjdsecToDDMonthYYYY(mjdsec, use_metool=True):
    """
    Converts a scalar value of MJD seconds to DD-Monthname-YYYY.
    -Todd Hunter
    """
    if (not casaAvailable or use_metool==False):
        jd = mjdToJD(mjdsec / 86400.)
        trialUnixTime = 1200000000
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        trialUnixTime -= diff*86400
        diff  = ComputeJulianDayFromUnixTime(trialUnixTime) - jd
        timeString = timeUtilities.strftime('%d-%B-%Y', 
                                            timeUtilities.gmtime(trialUnixTime))
    else:
        myme = createCasaTool(metool)
        today = myme.epoch('utc','today')
        myme.done()
        mjd = mjdsec / 86400.
        today['m0']['value'] =  mjd
        date = qa.splitdate(today['m0'])  # date is now a dict
        timeString = '%d-%s-%d'%(date['monthday'], datetime.date(1900,date['month'], 1).strftime('%B'), date['year'])
    return timeString

def calibratorService(sourcename, frequency, date='', verbose=0, 
                      url='https://almascience.eso.org/sc', 
                      result=0, weighted='true', model=0, download=False):
    """
    date: 10-August-2015 (native) or 2015-08-10
    frequency: in Hz, GHz or a string with units
    url: the server to use;  Note that the test server, which is sometimes more up-to-date
       in terms of capabilities, is:  'https://asa.hq.eso.org:8443/sc/jun/' (or similar)
    The following parameters select the algorithm used by the server. See ICT-1291 for 
    details.
    result: integer value
    weighted: string ('true' or 'false')
    verbose: integer (>0) value to send to server
    model: integer to send to server (0,1,2, other values yield same as 2)
         By default 0, calculate normal model goodness divided by (#measurement)^0.5, 
         if it is 1, calculate model goodness divided by (#measurement)^1.5.
         if it is 2, it is unclear what is happening.
    download: appears to have no effect
    """
    freq = parseFrequencyArgumentToHz(frequency)
    if date == '':
        date = getCurrentDate('-')
    if date[3].isdigit():
        mjdsec = dateStringToMJDSec(date)
        date = mjdsecToDDMonthYYYY(mjdsec)
    response = urllib2.urlopen(url+'/healthcheck')
    content = response.read()
    version = content.split('<version>')[1].split('</version>')[0]
    buildDate = content.split('<buildDate>')[1].split('</buildDate>')[0]
    print "version: %s, buildDate: %s" % (version,buildDate)
    url += '/flux?DATE=%s&FREQUENCY=%.1f&NAME=%s&WEIGHTED=%s&RESULT=%d&MODEL=%d&DOWNLOAD=%s'%(date,freq,sourcename,weighted,result,model,download)
    if verbose:
        url += '&VERBOSE=%d' % (verbose)
        print "Sending ", url
    response = urllib2.urlopen(url)
    content = response.read()
    lines = content.split('\n')
    if verbose:
       print "Response = ", content
    fields = []
    values = []
    mystring = []
    for i,line in enumerate(lines):
        if (line.find('<FIELD') >= 0):
            name = line.split('name="')[1].split('"')[0]
            fields.append(name)
        if (line.find('<TD>') >= 0):
            value = line.split('<TD>')[1].split('</TD>')[0]
            values.append(value)
            if len(values) == 11:
                mystring = parseCalibratorServiceWarning(int(value))
    response.close()
    for i in range(len(fields)):
        print '%18s: %s ' % (fields[i], values[i])
    if len(mystring) > 0:
        print "Warning code translation:"
        for i in mystring: print i

def parseCalibratorServiceWarning(value):
    """
    Generate informational values from the calibrator service as defined 
    in ICT-7842.
    value: 3-digit positive integer
    Return: a list of strings
    """
    firstDigit = value / 100
    mystr = []
    if firstDigit == 9:
        mystr.append("%d: Used %d (or more) measurements" % (firstDigit,firstDigit))
    else:
        mystr.append("%d: Used %d measurements" % (firstDigit,firstDigit))
    secondDigit = (value - firstDigit*100) / 10
    if secondDigit == 1:
        mystr.append("%d: Found measurement(s) within 7 days of the requested date."%(secondDigit))
    else:
        mystr.append("%d: Found no measurement(s) within 7 days of the requested date."%(secondDigit))
    thirdDigit = (value - firstDigit*100) - secondDigit*10
    if thirdDigit == 1:
        mystr.append("%d: Found two measurements in the same band bracketing the requested date within 14 days." % (thirdDigit))
    else:
        mystr.append("%d: Did not find two measurements in the same band bracketing the requested date within 14 days." % (thirdDigit))
    return mystr

def searchFlux(sourcename=None, date='', band=None, fLower=1e9, fUpper=1e12,
               tunnel=False, maxrows=10, limit=1000, debug=False,
               server='', dateCriteria=0, verbose=True, measurements=None,
               returnMostRecent=False, searchAdjacentNames=False,
               showDateReduced=False, dayWindow=-1, showPolarization=False,
               types=[1,4,25], sourceBandLimit=300, showAllCoordinates=False,
               returnPosition=False):
    """
    For help on the main parameters, type: help au.calDatabaseQuery.CalibratorCatalogUpdate.searchFlux
    For further information, see the DSO calibrator wiki: https://wikis.alma.cl/bin/view/DSO/CalibratorSurvey
    -Todd Hunter          

    A common option is:

    date: string, YYYYMMDD, e.g. '20120101' or '2012-01-01'
          or '2012/01/01'  where delimiter can be any non-integer character
          or YYYYmonDD or YYYY/mon/DD or YYYY-mon-DD where mon can be Jan/JAN/jan etc.

    Another usage is to find all line sources:  au.searchFlux('%',types=4,limit=1000)
              
    Additional options:
    searchAdjacentNames: if True, search nearby names (if given in format: [J]HHMM[+/-]DDM[M])
    server: '', 'external', 'internal', or full URL
    returnMostRecent: if True, return a dictionary describing the most 
             recent measurement
    dayWindow: if non-negative, and returnMostRecent is True, then return a 
          list of matches that are within this many days of the first find
    types: a list of integers: 25:grid_source, 4:line_source, 1:point_source,
              24: polarization_source, 64: flux_source, or a list of strings: 
              ['grid','line','point','polarization','flux']
    measurements: a dictionary of measurements (eg. as returned from wrapSearch)
    """
    from . import calDatabaseQuery  # used by searchFlux
    hostname = socket.gethostname()
    if (server.find('internal')>=0):
        server = 'http://sourcecat.osf.alma.cl/sourcecat/xmlrpc'
    if (server.find('external')>=0):
        server = 'http://asa.alma.cl/sourcecat/xmlrpc'
    if 'alma.cl' in hostname:
        if (server != ''):
            if (debug): print "Using server = ", server
            try:
                ccu = calDatabaseQuery.CalibratorCatalogUpdate(server=server)
            except:
                print "Error from xmlrpc service, possibly a gateway error (502)"
                return None
        else:
            server='http://sourcecat.osf.alma.cl/sourcecat/xmlrpc'
            # There was a time when internal server failed while external kept working, so always use it.
            #server = 'http://asa.alma.cl/sourcecat/xmlrpc'
            try:
                ccu = calDatabaseQuery.CalibratorCatalogUpdate(server=server)
            except:
                print "Error from xmlrpc service, possibly a gateway error (502)"
                return None
    else:
        if (server == ''):
            server = 'http://asa.alma.cl/sourcecat/xmlrpc'
        if (debug):
            print "Calling calDatabaseQuery.CalibratorCatalogUpdate(tunnel=%s,server='%s')" % (tunnel,server)
        try:
            ccu = calDatabaseQuery.CalibratorCatalogUpdate(tunnel=tunnel,server=server)
        except:
            print "Error from xmlrpc service, possibly a gateway error (502)"
            return None
    if (ccu.connectionFailed):
        return(None)
    date = replaceMonth(date)
    date = fillZerosInDate(date)
    mytypes = convertSourceTypes(types)
    status = ccu.searchFlux(sourcename,date,band,fLower,fUpper,tunnel,maxrows,
                            limit,debug,server,dateCriteria,verbose,measurements,
                            returnMostRecent,showDateReduced, 
                            sourceBandLimit=sourceBandLimit,
                            dayWindow=dayWindow, showPolarization=showPolarization,
                            types=mytypes, showAllCoordinates=showAllCoordinates,
                            returnPosition=returnPosition)
    if (status == -1):
        if (searchAdjacentNames):
            names = getAdjacentSourceNames(sourcename)
            if (names == []):
                print "This name is not an allowed format to search for adjacent names.  Must be: [J/B]HHMM+/-DDM[M]"
            else:
                for sourcename in names:
                    status = ccu.searchFlux(sourcename,date,band,fLower,fUpper,
                                            tunnel,maxrows,
                                            limit,debug,server,dateCriteria,
                                            verbose,measurements,
                                            returnMostRecent,showDateReduced,
                                            sourceBandLimit=sourceBandLimit,
                                            dayWindow=dayWindow,
                                            showPolarization=showPolarization,
                                            types=mytypes, returnPosition=returnPosition)
                    if (status != -1): break
        elif (verbose):
            if (maxrows>0):
                print "You could try setting searchAdjacentNames=True"
            else:
                print " "
    return(status)

def getAdjacentSourceNames(sourcename):
    """
    Takes a source name of the format [J/B]1924[+/-]242[9]
    and returns the four adjacent names:  1925+2429, 1923+2429, 1924-2430, 1924-2428
    -Todd Hunter
    """
    mymatch = re.match(r'.?[\d,%]{4}[+-]\d{3}',sourcename)
    sources = []
    if (mymatch is not None):
        if (re.match(r'[\d,%]{4}[+-]\d{3}',sourcename) == None):
            epoch = sourcename[0]
            radec = sourcename[1:]
        else:
            epoch = 'J'
            radec = sourcename
        if (len(radec.split('-')) > 1):
            mysign = '-'
        else:
            mysign = '+'
        ra,dec = radec.split(mysign)
        decdigits = len(dec)
        if (ra.find('%') < 0):
            ra2 = int(ra)+1
            # convert 1960 to 2000
            if (ra2%100 == 60): ra2 = (ra2/100 + 1)*100
            if (ra2==2400): ra2=0
            sources.append('%s%04d%c%s' % (epoch,ra2,mysign,dec))
            ra0 = int(ra)-1
            # convert 1999 to 1959
            if (ra0%100 == 99): ra0 = (ra0/100)*100 + 59
            if (ra0 < -1): ra0 = 2359
            sources.append('%s%04d%c%s' % (epoch,ra0,mysign,dec))
        if (dec.find('%') < 0):
            dec2 = int(dec)+1
            # convert 1960 to 2000
            if (dec2%100 == 60):
                dec2 = (dec2/100 + 1)*100
            dec0 = int(dec)-1
            # convert 1999 to 1959
            if (dec0%100 == 99): dec0 = (dec0/100)*100 + 59
            sources.append('%s%s%c%0*d' % (epoch,ra,mysign,decdigits,dec2))
            sources.append('%s%s%c%0*d' % (epoch,ra,mysign,decdigits,dec0))
        if (dec.find('%') < 0 and ra.find('%') < 0):
            sources.append('%s%04d%c%0*d' % (epoch,ra2,mysign,decdigits,dec2))
            sources.append('%s%04d%c%0*d' % (epoch,ra2,mysign,decdigits,dec0))
            sources.append('%s%04d%c%0*d' % (epoch,ra0,mysign,decdigits,dec2))
            sources.append('%s%04d%c%0*d' % (epoch,ra0,mysign,decdigits,dec0))
    return(sources)
         

def timeOnSourceSD(vis, obsid=0, spw=None, debug=False, ignore7m=True):
    """
    Determine the time spent on-source and off-source (per-antenna, and sum)
    for single-dish datasets. Flags are accounted for.
    spw: which spw to use to analyze times.  default=None=first non-WVR science spw
    Returns:
       the total on-source time in minutes
    Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find the measurement set"
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    allObsIDs = mytb.getcol('OBSERVATION_ID')
    obsIDs = np.unique(allObsIDs)
    nObsIDs = len(obsIDs)
    print "There are %d rows and %d OBSERVATION_IDs in this dataset = %s" % (len(allObsIDs), nObsIDs, str(obsIDs))
    if (nObsIDs > 1):
        print "Using only OBSERVATION_ID = %d" % (obsid)

    # Find the start and end time of the requested ObsID
    subtable = mytb.query('OBSERVATION_ID == %d' % (obsid))
    antennas = subtable.getcol('ANTENNA1')
    states = subtable.getcol('STATE_ID')
    if (debug):
        print "unique states = ", np.unique(states)
    datadesc = subtable.getcol('DATA_DESC_ID')  # same as spw for now.  See casa ticket on msmd.
    exposures = subtable.getcol('EXPOSURE')
    subtable.close()
    mytb.close()
    mytb.open(vis+'/STATE')
    obsMode = mytb.getcol('OBS_MODE')
    mytb.close()
    offSourceStateIDs = []
    onSourceStateIDs= []
    for o in range(len(obsMode)):
        if (obsMode[o].find('OBSERVE_TARGET#ON_SOURCE') >= 0):
            onSourceStateIDs.append(o)
        elif (obsMode[o].find('OBSERVE_TARGET#OFF_SOURCE') >= 0):
            offSourceStateIDs.append(o)
    offSourceStateIDs = np.array(offSourceStateIDs)
    onSourceStateIDs = np.array(onSourceStateIDs)
    clockTimeMinutes = computeClockTimeOfMS(vis=vis)
    uniqueAntennas = np.unique(antennas)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antennaNames = mymsmd.antennanames(uniqueAntennas)
    if (ignore7m):
        uniqueAntennas = []
        for name in antennaNames:
            if (name.find('CM') < 0):
                uniqueAntennas.append(mymsmd.antennaids(name)[0])
    spws = mymsmd.spwsforintent('OBSERVE_TARGET#ON_SOURCE')
    print "spws with observe_target = ", spws
    if (spw == None):
        if (casadef.subversion_revision >= casaRevisionWithAlmaspws):
            spws = np.setdiff1d(spws, mymsmd.almaspws(wvr=True))
        else:
            spws = np.setdiff1d(spws, mymsmd.wvrspws())
        spw = spws[0]
        print "Choosing spw=%d" % (spw)
    if (casadef.subversion_revision >= '26585'):
        try:
            matches1 = np.where(datadesc == mymsmd.datadescids(spw)[0])[0]
        except:
            print "If you see this message, then please email Todd Hunter the full output of this command."
            matches1 = np.where(datadesc == spw)[0]
    else:
        matches1 = np.where(datadesc == spw)[0]
    mymsmd.close()
    if (debug):
        print "%d rows have spw=%d" % (len(matches1),spw)
    allAntsOnSource = 0
    allAntsOffSource = 0
    mytb.open(vis)
    for antenna in uniqueAntennas:
        matches2 = np.where(antennas == antenna)[0]
        spw_ant_matches = np.intersect1d(matches1,matches2)
        if (debug):
            print "%d rows have antenna=%d" % (len(matches2), antenna)
            print "%d rows have both" % (len(spw_ant_matches))
            print "first = %d, state_id=%d" % (spw_ant_matches[0],states[spw_ant_matches[0]])
            print "on source state IDs = ", onSourceStateIDs
            print "off source state IDs = ", offSourceStateIDs
        offSourceMatches = []
        flaggedRowsOffSource = 0
        for o in offSourceStateIDs:
            rows = list(np.where(states == o)[0])
            if (len(rows) > 0):
                subtable = mytb.query('ANTENNA1 == %d AND STATE_ID == %d AND DATA_DESC_ID == %d' % (antenna, o, spw))
                flagcolumn = subtable.getcol('FLAG')
                if (len(flagcolumn) > 0):
                    flaggedFraction = computeFlaggedFraction(flagcolumn)
                else:
                    flaggedFraction = 0
                flaggedRowsOffSource += flaggedFraction*len(flagcolumn)
                subtable.close()
            offSourceMatches += rows
        offSourceMatches = np.array(sorted(offSourceMatches))
        offSourceMatches = np.intersect1d(spw_ant_matches,offSourceMatches)
        if (len(offSourceMatches) > 0):
            if (debug):
                print "%s: %d rows have spw=%d and an off_source state id (percent flagged=%.3f)" % (antennaNames[antenna],
                                                                                 len(offSourceMatches), spw,
                                                                                 flaggedRowsOffSource*100/len(offSourceMatches))
        if (debug):
            if (len(offSourceMatches) > 0):
                print "first = %d with id=%d" % (offSourceMatches[0], states[offSourceMatches[0]])
        onSourceMatches = []
        flaggedRowsOnSource = 0
        for o in onSourceStateIDs:
            rows = list(np.where(states == o)[0])
            if (len(rows) > 0):
                subtable = mytb.query('ANTENNA1 == %d AND STATE_ID == %d AND DATA_DESC_ID == %d' % (antenna, o, spw))
                flagcolumn = subtable.getcol('FLAG')
                if (len(flagcolumn) > 0):
                    flaggedFraction = computeFlaggedFraction(flagcolumn)
                else:
                    flaggedFraction = 0
                flaggedRowsOnSource += flaggedFraction*len(flagcolumn)
                subtable.close()
            onSourceMatches += rows
        onSourceMatches = np.array(sorted(onSourceMatches))
        onSourceMatches = np.intersect1d(spw_ant_matches,onSourceMatches)
        if (debug):
            print "%s: %d rows have spw=%d and an on_source  state id (percent flagged=%.3f)" % (antennaNames[antenna],
                                                                                       len(offSourceMatches), spw,
                                                                                       flaggedRowsOnSource*100/len(onSourceMatches))
        if (debug):
            print "first = %d with id=%d" % (onSourceMatches[0], states[onSourceMatches[0]])
            print "of total %d rows:  on-source=%d,  off-source=%d" % (len(exposures), len(onSourceMatches), len(offSourceMatches))
        if (len(offSourceMatches) > 0):
            offSourceExposures = exposures[offSourceMatches]
        else:
            offSourceExposures = []
        onSourceExposures = exposures[onSourceMatches]
        if (len(offSourceExposures) > 0):
            totalOffSource = np.sum(offSourceExposures) * (1-flaggedRowsOffSource/len(offSourceMatches))
        else:
            totalOffSource = 0
        totalOnSource = np.sum(onSourceExposures) * (1-flaggedRowsOnSource/len(onSourceMatches))
        print "%s:  on source time = %.1f sec = %.1f min" % (antennaNames[antenna],totalOnSource,
                                                             totalOnSource/60.)
        print "%s: off source time = %.1f sec = %.1f min" % (antennaNames[antenna],totalOffSource,
                                                             totalOffSource/60.)
        allAntsOnSource += totalOnSource
        allAntsOffSource += totalOffSource
    mytb.close()
    if (len(uniqueAntennas) > 1):
        print "sum of %d antennas:" % (len(uniqueAntennas))
        print " on source time = %.1f sec = %.1f min" % (allAntsOnSource, allAntsOnSource/60.)
        print "off source time = %.1f sec = %.1f min" % (allAntsOffSource, allAntsOffSource/60.)
        print "on-source efficiency = %.1f%%" % (100*allAntsOnSource/(60.*len(uniqueAntennas))/clockTimeMinutes)
    return(allAntsOnSource/60.)

def plotPointingTable(vis, antenna=0, timerange='', azplotrange=[0,0], 
                      elplotrange=[0,0]):
    """
    Plots the azimuth and elevation vs. timestamp of the entries in the POINTING
    table corresponding to one antenna.  Name of plotfile produced is:
          vis.plotPointing.DV01.png
    vis: the measurement set
    Optional parameters:
    antenna: can be an ID, a name, or a list of IDs or names, ''=all
    timerange: 'HH:MM HH:MM'
    azplotrange, elplotrange: in degrees
    If more than one antenna is requested, a PDF will be build of all plots produced.
    - Todd Hunter
    """
    if (timerange != ''):
        timerange = parseTimerangeArgument(timerange,vis)
    antennas = parseAntenna(vis,antenna)
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/POINTING')
    if mytb.nrows() < 1:
        mytb.close()
        print "The pointing table is empty."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    pngs = []
    maxElevation = []
    for antennaId in antennas:
        myt = mytb.query("ANTENNA_ID == %s" % antennaId)
        alltimes = myt.getcol('TIME')
        alldirections = myt.getcol('DIRECTION')
        myt.close()
        allazim = np.degrees(alldirections[0][0])
        allelev = np.degrees(alldirections[1][0])
        tSuccessiveDifferences = alltimes[1:] - alltimes[:-1]
        antennaName = mymsmd.antennanames(antennaId)[0]
        print "median sampling interval in POINTING table for %s = %f sec" % (antennaName,np.median(tSuccessiveDifferences))
        print "    min interval = %f sec,  max interval = %f sec" % (np.min(tSuccessiveDifferences), np.max(tSuccessiveDifferences))
        pb.clf()
        adesc = pb.subplot(211)
        pb.plot_date(pb.date2num(mjdSecondsListToDateTime(alltimes)), allazim, '.', 
                     markersize=2.0)
        pb.xlabel('Universal Time on %s' % (mjdsecToUT(alltimes[0]).split()[0]))
        pb.ylabel('Azimuth (degrees)')
        if (azplotrange != [0,0]):
            pb.ylim(azplotrange)
        adesc.xaxis.grid(True,which='major')
        if (timerange != ''):
            pb.xlim(pb.date2num(mjdSecondsListToDateTime(timerange)))
            x0 = timerange[0]
            x1 = timerange[1]
        else:
            x0 = np.min(alltimes)
            x1 = np.max(alltimes)
        setXaxisTimeTicks(adesc, x0, x1)
        pb.title(vis + '  ' + antennaName + '=ant%02d'%(antennaId))
    
        adesc = pb.subplot(212)
        pb.plot_date(pb.date2num(mjdSecondsListToDateTime(alltimes)), allelev, '.', 
                     markersize=2.0)
        pb.xlabel('Universal Time on %s' % (mjdsecToUT(alltimes[0]).split()[0]))
        pb.ylabel('Elevation (degrees)')
        if (elplotrange != [0,0]):
            pb.ylim(elplotrange)
        adesc.xaxis.grid(True,which='major')
        if (timerange != ''):
            pb.xlim(pb.date2num(mjdSecondsListToDateTime(timerange)))
            x0 = timerange[0]
            x1 = timerange[1]
        else:
            x0 = np.min(alltimes)
            x1 = np.max(alltimes)
        setXaxisTimeTicks(adesc, x0, x1)
        pb.draw()
        png = vis.rstrip('/')+'.pointingTable.%s.png'%(antennaName)
        pngs.append(png)
        pb.savefig(png)
        print "    Created ", png
        print "    Max Elevation = ", np.max(allelev)
        maxElevation.append(np.max(allelev))
    mytb.close()
    if (len(pngs) > 1):
        buildPdfFromPngs(pngs, pdfname=vis+'.pointingTable.pdf')
        print "Antenna  MaxElev"
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        antennaNames = mymsmd.antennanames()
        mymsmd.close()
        idx = np.argsort(maxElevation)
        for m in range(len(maxElevation)):
            print " %2d=%s   %.5f" % (idx[m], antennaNames[idx[m]], maxElevation[idx[m]])
    mymsmd.close()
    
def getMapBasis(vis):
    """
    Reads the mapping coordinate system from the POINTING table.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/POINTING')
    coordSys = mytb.getcolkeyword('DIRECTION',1)['Ref']
    mytb.close()
    return(coordSys)
    
def getOffSourceTimes(vis, intent='OBSERVE_TARGET'):
    """
    Get the timestamps when observing the OFF_SOURCE position.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/STATE')
    obsMode = mytb.getcol('OBS_MODE')
    offSourceStateIds = []
    for i,o in enumerate(obsMode):
        if (intent+'#OFF_SOURCE' in o or intent in o):
            offSourceStateIds.append(i)
#    print "State_IDs with OBSERVE_TARGET#OFF_SOURCE: ", offSourceStateIds
    mytb.close()
    mytb.open(vis)
    stateId = mytb.getcol('STATE_ID')
    indices = np.array([],dtype=int)
    for o in range(len(offSourceStateIds)):
        indices = np.append(indices,np.where(stateId == offSourceStateIds[o]))
    if (intent.find('#OFF_SOURCE') < 0 and intent.find('#ON_SOURCE') < 0):
        intent += '#OFF_SOURCE'
    print "Found %d/%d rows in the MS corresponding to %s#OFF_SOURCE" % (len(indices),len(stateId), intent)
    times = mytb.getcol('TIME')[indices]
    mytb.close()
    return(times)

def scansforfields(mymsmd, calAtmFields):
    scans = []
    for f in calAtmFields:
        scans += list(mymsmd.scansforfield(f))
    return(np.array(scans))

def ignoreMostCommonPosition(x,y):
    """
    Given two equal-lengths lists of coordinates, return the index of all pairs that
    *excludes* the most common pair.
    -Todd Hunter
    """
    roundedY = list(np.round(y))
    y_mode = max(set(roundedY), key=roundedY.count)
    threshold = max(1,abs(y_mode*0.005))
    idx1_ignoreOffPositionY = np.where(np.abs(np.round(y) - y_mode) > threshold)
    roundedX = list(np.round(x))
    x_mode = max(set(roundedX), key=roundedX.count)
    idx1_ignoreOffPositionX = np.where(np.round(x) != x_mode)
    idx1_ignoreOffPosition = np.intersect1d(idx1_ignoreOffPositionX[0], idx1_ignoreOffPositionY[0])
    return(idx1_ignoreOffPosition, idx1_ignoreOffPositionX, idx1_ignoreOffPositionY)

def fieldsForScans(mymsmd, scans='', intent=''):
    """
    Returns a list of fields observed in a list of scans.  Differs from msmd.fieldsforscans 
    in that it is not necessarily a unique list.
    scans: if blank then use all scans
    intent: if not blank, and scans is blank, then limit scans to this intent (wildcard appened)
    -Todd Hunter
    """
    if len(scans) == 0:
        if (len(intent) == 0):
            scans = mymsmd.scannumbers()
        else:
            scans = mymsmd.scansforintent('*'+intent+'*')
            print "Scanlist = ", scans
    if type(scans) == str:
        scans = [int(i) for i in scans.split(',')]
    fields = []
    for scan in scans:
        f = mymsmd.fieldsforscan(scan)
        if (len(f) == 1):
            f = f[0]
        fields.append(f)
    return fields

def fieldsfornames(mymsmd, names):
    """
    Use msmd.fieldsforname in a 'for' loop to implement fieldsfornames.
    names: ['A','B','C']  or 'A,B,C'
    -Todd Hunter
    """
    fields = []
    if (type(names) == str):
        names = names.split(',')
    for name in names:
        fields += list(mymsmd.fieldsforname(name))
    return fields

def getAntennaPadXYZ(vis, antennaId=0, mymsmd=''):
    """
    Returns the ITRF X,Y,Z geocentric position of the pad for the specified antenna
    in the specified measurement set.
    antennaId: integer ID
    -Todd Hunter
    """
    antennaId = int(antennaId)
    pads = getAntennaPads(vis, mymsmd=mymsmd)
    if antennaId >= len(pads):
        print "No such antenna ID in this dataset."
        return
    mydict = getPadPositions(vis) # does not use msmd
    if pads[antennaId] not in mydict:
        print "Pad not found in measurement set."
        return
    return mydict[pads[antennaId]]

def getTPSampling(vis, obsid=0, showplot=False, plotfile='', debug=False,
                  labelFirstNSamples=0, labelIncrement=1, convert=True,
                  field='auto', plotrange=[0,0,0,0], antenna=0, scan=None,
                  refractionCorrection=False, nutationCorrection=False, 
                  timerange=None, trimPointingData=True, showComponents=False,
                  pickFirstRaster=True, useApparentPositionForPlanets=False, 
                  connectDots=False, intent='OBSERVE_TARGET', findSubscans=False, 
                  magnification=0.3, ymodeThreshold=0.075, 
                  forceCardinalScanAngle=False, source=None, cofa='',
                  useAntennaAsCOFA=False, overlayOTPointings=''):
    """
    This function reads the main table of the ms, finds the
    start and end time of the specified observation ID, then
    read the POINTING table and extracts the pointing directions
    within that timerange.  It computes successive differences
    on both axes to determine which is the scan direction (RA or Dec)
    and what the sampling is in each axes, which it returns in
    units of arcseconds on-the-sky, i.e. corrected for the
    right ascension axis by multiplying by cos(declination).
    It also generates a png file showing the observed points
    in relative coordinates in units of arc seconds.
    Note: This function does not support arbitrary scanning angles!

    vis: the name of the measurement set
    obsid: the number of the OBSERVATION_ID to analyze
    showplot: set to True to generate an interactive plot of sampled positions
    plotfile: default='' -->  '<vis>.obsid0.sampling.png'
    labelFirstNSamples: put labels on the first N samples
    labelIncrement: the number of samples between labels
    convert: if True, convert AZELGEO coords to RA Dec in the plot
    field: plot the offset coordinates relative to this field ID (or name)
           default = 'auto' == the first field with the specified intent
    source: if specified, then use this source ID as (0,0) (int or string int)
    plotrange: set the plot axes ranges [x0,x1,y0,y1]
    pickFirstRaster: automatically set to True for major planets
        This avoids confusion due to the slowly changing source position.
    antenna: which antenna ID (or name) to use to determine the scan parameters
    scan: default: use all scans on the first target with the specified intent
    timerange: limit the data to this timerange,  e.g. '05:00:00 06:00:00'
            or  '05:00~06:00' or '2011/10/15-05:00:00 2011/10/15-06:00:00'
    trimPointingData: if False, then don't exclude data outside of scan times
    showComponents: if True, then also show X and Y vs. time on upper plot
    intent: the intent for which to pick the scans to use (up to the # sign)
    findSubscans: if True, then run class Atmcal to find subscan times
    cofa: if specifed as [x,y,z], use this ITRF position as array center
    useAntennaAsCOFA: if True, then use the position of the pad holding the
         specified antenna as the COFA instead of the value in CASA for the
         observatory, or the value specified by cofa parameter.
    overlayOTPpositions: if filename is specified, then assume it is an ASCII
        pointings file exported from the OT in relative coordinates (arcsec)
    
    Returns:
    xSampling, ySampling, largestDimension (all in units of arcsec)
    
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "The ms does not exist."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if overlayOTPointings != '':
        if not os.path.exists(overlayOTPointings):
            print "OT positions file not found."
            return
    if (field==''): field = None
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    allObsIDs = mytb.getcol('OBSERVATION_ID')
    obsIDs = np.unique(allObsIDs)
    nObsIDs = len(obsIDs)
    print "There are %d rows and %d OBSERVATION_IDs in this dataset = %s" % (len(allObsIDs), nObsIDs, str(obsIDs))

    subtable = mytb.query('OBSERVATION_ID == %d' % (obsid))
    mytb.close()
    times = subtable.getcol('TIME')
    subtable.close()
    if (len(times) < 1):
        print "No rows found for OBSERVATION_ID=%d" % (obsid)
        return

    startTime = np.min(times)
    stopTime = np.max(times)
    if (casadef.casa_version < casaVersionWithMSMD):
        print "This function requires casa >= 4.1.0."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    timeranges = {}
    timecenters = []
    intent = intent.split('#')[0]
    if (intent+'#ON_SOURCE' not in mymsmd.intents()):
        if ('MAP_ANTENNA_SURFACE#ON_SOURCE' in mymsmd.intents()):
            intent = 'MAP_ANTENNA_SURFACE'
        else:
            print "%s#ON_SOURCE is not an intent in this measurement set." % (intent)
            print "Available intents = ", mymsmd.intents()
            mymsmd.close()
            return
    scansOnSource = list(mymsmd.scansforintent(intent+'#ON_SOURCE'))
    if (intent+'#OFF_SOURCE' in mymsmd.intents()):
        scansOnSource += list(mymsmd.scansforintent(intent+'#OFF_SOURCE'))
    scansOnSource = np.unique(scansOnSource)
    if (scan is not None and scan != ''):
        scansToUse = [int(s) for s in str(scan).split(',')]
        for scan in scansToUse:
            if (scan not in scansOnSource):
                print "Scan %d is not an %s scan.  Available scans = %s" % (scan,intent,str(scansOnSource))
                mymsmd.close()
                return
        print "Using only the specified scans: %s" % (str(scansToUse))
    else:
        # should default to the first scan with specified intent
        if (len(scansOnSource) == 0):
            print "There are no scans on the with intent=%s to use." % (intent)
            print "Available intents = ", mymsmd.intents()
            print "Use the intent parameter to select one."
            mymsmd.close()
            return
        myfield = mymsmd.fieldsforscan(scansOnSource[0])[0]
        scansToUse = scansOnSource # mymsmd.scansforfield(myfield)
        print "Using only the %s#ON_SOURCE scans on the science target: %s" % (intent,str(scansToUse))

    calAtmTimes = []
    firstCalAtmScan = -1
    if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' in mymsmd.intents()):
        calAtmFieldNames = mymsmd.namesforfields(mymsmd.fieldsforintent(intent+'*'))
        calAtmFields = fieldsfornames(mymsmd, calAtmFieldNames)
        if debug: print "calAtmFields = ", calAtmFields
        scans1 = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE#ON_SOURCE')
        scans2 = np.unique(scansforfields(mymsmd,calAtmFields))
        if debug: print "scans1 = %s, scans2 = %s" % (scans1, scans2)
        calAtmScans = np.intersect1d(scans1,scans2)
        if (len(calAtmScans) > 0):
            firstCalAtmScan = calAtmScans[0]
            firstCalAtmScanMeanMJD = np.mean(mymsmd.timesforscan(firstCalAtmScan))/86400.
            calAtmField = mymsmd.fieldsforscan(firstCalAtmScan)[0]
            calAtmTimes = mymsmd.timesforscan(firstCalAtmScan)
            calAtmTimesMax = np.max(calAtmTimes)
            calAtmTimesMin = np.min(calAtmTimes)
            print "first AtmCal scan on target = %d has %d times (%s-%s)" % (firstCalAtmScan,len(calAtmTimes),
                                                                             plotbp3.utstring(calAtmTimesMin,3),
                                                                             plotbp3.utstring(calAtmTimesMax,3))
            if (findSubscans):
                ac = Atmcal(vis)
                skyTimes = ac.timestamps[firstCalAtmScan][ac.skysubscan]
                print "sky subscan has times (%s-%s)" % (plotbp3.utstring(np.min(skyTimes),3),
                                                         plotbp3.utstring(np.max(skyTimes),3))
        else:
            print "No AtmCals were done on a field with intent %s (%s)" % (intent,calAtmField)
            print "scans1 = ", scans1
            print "scans2 = ", scans2
    else:
        print "No AtmCals in this dataset."

    timesforscan = {}
    if (timerange is not None and timerange != ''):
        timerange = parseTimerangeArgument(timerange,vis)
        if (debug):
            print "timerange[0] = ", str(timerange[0])
            print "timerange[1] = ", str(timerange[1])
    for i in scansToUse:
        mytimes = mymsmd.timesforscan(i)
        if (timerange is not None and timerange != ''):
            idx1 = np.where(mytimes > timerange[0])[0]
            idx2 = np.where(mytimes < timerange[1])[0]
            mytimes = mytimes[np.intersect1d(idx1,idx2)]
        if (len(mytimes) > 0):
            timesforscan[i] = {'begin': np.min(mytimes), 'end': np.max(mytimes)}
            timeranges[i] = [np.min(mytimes),np.max(mytimes)]
            timecenters += list(mytimes)
        else:
            scansToUse = np.delete(scansToUse,list(scansToUse).index(i))
            if (debug):
                print "No times found for scan %d" % (i)
    timecenters = np.array(timecenters)
    tSuccessiveDifferences = timecenters[1:] - timecenters[:-1]
    medianSamplingIntervalDataTable = np.median(tSuccessiveDifferences)
    print "median sampling interval in data table with %s (scans=%s) = %f sec" % (intent, str(scansOnSource), medianSamplingIntervalDataTable)
    if (casadef.casa_version >= '4.2.0'):
        try:
            spw = np.intersect1d(mymsmd.spwsforintent(intent+'#ON_SOURCE'), mymsmd.almaspws(fdm=True,tdm=True))[0]
            pol = 0
            exposureTime = mymsmd.exposuretime(scan=scansToUse[0], spwid=spw, polid=pol)['value']
            print "Exposure time = %g in spw %d, pol %d" % (exposureTime,spw,pol)
            medianSamplingIntervalDataTable = exposureTime
        except:
            pass

    # find the name of the science field, and (if present) the scan numbers on it
    fieldName = None
    if (field == 'auto'):
        intent = intent + '#ON_SOURCE'
        if (intent not in mymsmd.intents()):
            print "No science target found.  Checking for amplitude or flux calibrator"
            if ('CALIBRATE_FLUX#ON_SOURCE' in mymsmd.intents()):
                intent = 'CALIBRATE_FLUX#ON_SOURCE'
            elif ('CALIBRATE_AMPLI#ON_SOURCE' in mymsmd.intents()):
                intent = 'CALIBRATE_AMPLI#ON_SOURCE'
            else:
                field = None
        if (field is not None):
            field = mymsmd.fieldsforintent(intent)
            if (len(field) < 1):
                field = None
            else:
                field = field[0]
                fieldName = mymsmd.namesforfields(field)[0]
                print "Found first source with %s intent = %d = %s" % (intent, field, fieldName)
    elif (field is not None):
        if (field in mymsmd.namesforfields(range(mymsmd.nfields()))):
            fieldName = field
            field = mymsmd.fieldsforname(fieldName)[0]
        elif (str(field) in [str(a) for a in range(mymsmd.nfields())]):
            fieldName = mymsmd.namesforfields(int(field))[0]
        else:
            print "Field %s is not in this dataset.  Available fields = %s" % (field,str(mymsmd.namesforfields(range(mymsmd.nfields()))))
            mymsmd.close()
            return
    if (field is not None):
        scansforfield = mymsmd.scansforfield(field)
    nantennas = mymsmd.nantennas()
    antennanames = mymsmd.antennanames(range(nantennas))
    
    mytb.open(vis+'/POINTING')
    coordSys = mytb.getcolkeyword('DIRECTION',1)['Ref']
    originalCoordSys = coordSys
    print "Map coordinate system from the POINTING table = ", coordSys
    alltimes = mytb.getcol('TIME')
    direction = mytb.getcol('DIRECTION')
    antenna_ids = mytb.getcol('ANTENNA_ID')
    uniqueAntennas = len(np.unique(antenna_ids))
    mytb.close()
    if (antenna not in antenna_ids):
        if (antenna not in antennanames):
            print "Antenna %s is not in the POINTING table" % (str(antenna))
            mymsmd.close()
            return
        else:
            antenna = mymsmd.antennaids(antenna)
    if useAntennaAsCOFA:
        cofa = getAntennaPadXYZ(vis, antenna)
        print "Using antenna %d pad position as COFA: " % (antenna), cofa
    matches = np.where(antenna_ids == antenna)[0]
    print "Picked %d/%d rows, which correspond to antenna %d=%s (of %d)" % (len(matches), len(antenna_ids), antenna, antennanames[antenna], uniqueAntennas)
    times = alltimes[matches]
    xdirection = direction[0][0][matches]
    ydirection = direction[1][0][matches]

    # make sure RA/azimuth is in positive units
    negatives = np.where(xdirection < 0)[0]
    print "RA was negative at %d points" % (len(negatives))
    xdirection[negatives] += 2*np.pi

    uniqueTimes, uniqueTimesIndices = np.unique(times, return_index=True)
    if (debug):
        print "Mean time: %f, MJD = %f =  %s" % (np.mean(uniqueTimes),np.mean(uniqueTimes)/86400.,
                                                 mjdSecondsToMJDandUT(np.mean(uniqueTimes))[1])
    timeSortedIndices = np.argsort(uniqueTimes)

    # single-antenna times (sorted by time)
    pointingTime = times[uniqueTimesIndices[timeSortedIndices]]
    xdirection = xdirection[uniqueTimesIndices[timeSortedIndices]]
    ydirection = ydirection[uniqueTimesIndices[timeSortedIndices]]
    tdirection = times[uniqueTimesIndices[timeSortedIndices]]

    totalTimes = len(pointingTime)

    # Keep only the points from the requested ObsID
    matches1 = np.where(pointingTime >= startTime)[0]
    matches2 = np.where(pointingTime <= stopTime)[0]
    matches = np.intersect1d(matches1,matches2)
    matchesObsID = matches[:]
    myTimes = len(matches)
    if (debug):
        print "Selected %d of %d unique times (i.e. from one spw) matching OBSERVATION_ID=%d" % (myTimes, totalTimes, obsid)
    if (myTimes == 0):
        mymsmd.close()
        return

    if (trimPointingData):
      # Trim off any pointing table entries not associated with an integration in the selected scan(s)
        scanmatches = []
        scanfieldmatches = []
        pointingTime = np.array(pointingTime)
        for match in matches:
          for i in timeranges.keys():
              if (pointingTime[match] > timeranges[i][0] and  pointingTime[match] < timeranges[i][1]):
                  scanmatches.append(match)
                  if (field is not None):
                      if (i in scansforfield):
                          scanfieldmatches.append(match)
                  break
        matches = np.array(scanmatches)  # times within any scan
        scanfieldmatches = np.array(scanfieldmatches)  # times within scans on the field
        myTimes = len(matches)
        if (debug):
            print "Selected %d times as being within a data scan (%s)" % (myTimes, scansToUse)
        if (myTimes == 0):
            mymsmd.close()
            return
        x = xdirection[matches]  # These are the longitude values in the pointing table for the selected scan
        y = ydirection[matches]  # These are the latitude values in the pointing table for the selected scan
        times = tdirection[matches]  # These are the timestamps in the pointing table for the selected scan
        if (firstCalAtmScan != -1):
            scanmatches = []
            for match in matchesObsID:
                if (pointingTime[match] > calAtmTimesMin and  pointingTime[match] < calAtmTimesMax):
                    scanmatches.append(match)
            matches = np.array(scanmatches)  
            xCalAtm = xdirection[matches]
            yCalAtm = ydirection[matches]
            timesCalAtmPointing = tdirection[matches]
            if (findSubscans):
                scanmatches = []
                for match in matchesObsID:
                    if (pointingTime[match] > np.min(skyTimes) and pointingTime[match] < np.max(skyTimes)):
                        scanmatches.append(match)
                matches = np.array(scanmatches)
                xCalAtmSky = xdirection[matches]
                yCalAtmSky = ydirection[matches]
                timesCalAtmSkyPointing = tdirection[matches]
    else:
        x = xdirection
        y = ydirection
        times = tdirection
    tSuccessiveDifferences = times[1:] - times[:-1]
    medianSamplingIntervalPointingTable = np.median(tSuccessiveDifferences)
    print "median sampling interval in POINTING table = %f sec" % (medianSamplingIntervalPointingTable)

    if (False):
        # Try to speed up the calculation by reducing the number of points.
        # Group the pointing table values into the correlator data time bins.
        # Does not yet work right.
        pointsPerIntegration = {}
        print "Assigning %d pointing table values to %d integrations" % (len(times),len(timecenters))
        for t in range(len(times)):
            mindiff = 1e30
            for integration in range(len(timecenters)):
                absdiff = abs(times[t]-timecenters[integration])
                if (absdiff < mindiff):
                    mindiff = absdiff
                    whichIntegration = integration
            if (whichIntegration not in pointsPerIntegration.keys()):
                pointsPerIntegration[whichIntegration] = {}
                pointsPerIntegration[whichIntegration]['x'] = []
                pointsPerIntegration[whichIntegration]['y'] = []
            pointsPerIntegration[whichIntegration]['x'].append(x[t])
            pointsPerIntegration[whichIntegration]['y'].append(y[t])
        xnew = []
        ynew = []
        times = timecenters
        for key in pointsPerIntegration.keys():
            xnew.append(np.median(pointsPerIntegration[key]['x']))
            ynew.append(np.median(pointsPerIntegration[key]['y']))
        x = np.array(xnew[:])
        y = np.array(ynew[:])
    
    # Keep a copy of the original values in radians
    xrad = x[:]
    yrad = y[:]

    if (source is not None):
        radec = getRADecForSource(vis, int(source))
        print "Getting RA,Dec for source %s: %s" % (str(source),radec)
        rightAscension, declination = radec2rad(radec)
    elif (field==None):
        rightAscension = np.median(x)
        declination = np.median(y)
        if (debug):
            print "Median coordinates = ", rightAscension, declination
    else:
        rightAscension, declination = getRADecForField(vis, field, forcePositiveRA=True, usemstool=True)
        if (debug):
            print "field coordinates in radians = %f, %f = %s" % (rightAscension, declination,
                                                                  rad2radec(rightAscension, declination))
        if (coordSys.find('AZEL') >= 0 and convert==False):
            rightAscension, declination = computeAzElFromRADecMJD([rightAscension,declination],
                                                                  mjd=np.median(times)/86400.,verbose=False,
                                                                  frame='AZELGEO', cofa=cofa)
            if (debug):
                print "field coordinates in az/el = ", rightAscension, declination

    apparentCoordinates = False
    offSourceTimes = getOffSourceTimes(vis, intent)
    if (len(offSourceTimes) < 1):
        print "No off source intent found in the MS."

    offSourceRA = []
    offSourceDec = []
    calAtmRA = []
    calAtmDec = []
    if (coordSys.find('AZEL') >= 0 and convert):
        coordSys = 'J2000'
        print "Converting %d coordinates from AZELGEO to J2000..." % (len(x))
        my_metool = createCasaTool(metool)
        for i in range(len(x)):
            if ((i+1) % 10000 == 0): print "%d/%d" % (i+1,len(x))
            ra,dec = computeRADecFromAzElMJD([xrad[i],yrad[i]], mjd=times[i]/86400.,
                                             verbose=False,my_metool=my_metool,
                                             refractionCorrection=refractionCorrection,
                                             nutationCorrection=nutationCorrection,
                                             frame='AZELGEO', cofa=cofa)
            if (ra < 0):
                ra += 2*pi
            x[i] = ra
            y[i] = dec
            if (times[i] in offSourceTimes):
                offSourceRA.append(ra)
                offSourceDec.append(dec)
        if (len(offSourceRA) > 0):
            xOffSource = np.median(offSourceRA)
            yOffSource = np.median(offSourceDec)
            print "     Field source position = %s" % (rad2radec(rightAscension, declination,verbose=False))
            separation = np.degrees(angularSeparationRadians(rightAscension, declination, xOffSource, yOffSource))
            print "Median off source position = %s (separation = %.1farcmin = %.1fdeg)" % (rad2radec(xOffSource, yOffSource, verbose=False), separation*60, separation)
        elif (len(offSourceTimes) > 0):
            print "No times in the POINTING table match the times of off source integrations."


        medianRA = np.median(x)
        medianDec = np.median(y)
        separation = []
        for i in range(len(x)):
            separation.append(angularSeparationRadians(medianRA,medianDec,x[i],y[i]))
        madSeparation = MAD(separation)
        if (debug):
            print "MAD of the separation of points from median (%s) = %f arcsec" % (rad2radec(medianRA,medianDec),madSeparation*180*3600/np.pi)

        if (firstCalAtmScan != -1):
            print "Converting %d coordinates (for AtmCal scan %d) from AZELGEO to J2000..." % (len(xCalAtm),firstCalAtmScan)
            for i in range(len(xCalAtm)):
                if ((i+1) % 10000 == 0): print "%d/%d" % (i+1,len(x))
                ra,dec = computeRADecFromAzElMJD([xCalAtm[i],yCalAtm[i]], mjd=timesCalAtmPointing[i]/86400.,
                                                 verbose=False,my_metool=my_metool,
                                                 refractionCorrection=refractionCorrection,
                                                 nutationCorrection=nutationCorrection,
                                                 frame='AZELGEO', cofa=cofa)
                calAtmRA.append(ra)
                calAtmDec.append(dec)
            if (len(calAtmRA) > 0):
                xCalAtm = np.median(calAtmRA)
                yCalAtm = np.median(calAtmDec)
                print "Median atm calib. position = %s" % (rad2radec(xCalAtm, yCalAtm, verbose=False))
                xCalAtm = np.mean(calAtmRA)
                yCalAtm = np.mean(calAtmDec)
                print "  Mean atm calib. position = %s" % (rad2radec(xCalAtm, yCalAtm, verbose=False))
            elif (len(calAtmTimes) > 0):
                print "No times in the POINTING table match the times of AtmCal integrations."
            else:
                print "There are no times found on AtmCal scans."
            if (findSubscans):
                calAtmSkyRA = []
                calAtmSkyDec = []
                for i in range(len(xCalAtmSky)):
                    if ((i+1) % 10000 == 0): print "%d/%d" % (i+1,len(x))
                    ra,dec = computeRADecFromAzElMJD([xCalAtmSky[i],yCalAtmSky[i]], mjd=timesCalAtmSkyPointing[i]/86400.,
                                                     verbose=False,my_metool=my_metool,
                                                     refractionCorrection=refractionCorrection,
                                                     nutationCorrection=nutationCorrection, frame='AZELGEO', cofa=cofa)
                    calAtmSkyRA.append(ra)
                    calAtmSkyDec.append(dec)
                if (len(calAtmSkyRA) > 0):
                    xCalAtmSky = np.median(calAtmSkyRA)
                    yCalAtmSky = np.median(calAtmSkyDec)
                    print "Median atmcal sky position = %s" % (rad2radec(xCalAtmSky, yCalAtmSky, verbose=False))
                    xCalAtmSky = np.mean(calAtmSkyRA)
                    yCalAtmSky = np.mean(calAtmSkyDec)
                    print "  Mean atmcal sky position = %s" % (rad2radec(xCalAtmSky, yCalAtmSky, verbose=False))
                
        my_metool.done()
        if (source is not None):
            radec = getRADecForSource(vis, int(source))
            print "Getting RA,Dec for source %s: %s" % (str(source),radec)
            rightAscension, declination = radec2rad(radec)
        elif (field == None):
            rightAscension = np.median(x)
            declination = np.median(y)
        else:
            newEphemerisTechnique = False
            if (casadef.casa_version >= '4.5'):
                if (getEphemeris(vis,verbose=False) != {}):
                     newEphemerisTechnique = True
            if (useApparentPositionForPlanets==False and fieldName.upper() in majorPlanets and 
                not newEphemerisTechnique):
                try:
                    rightAscension, declination = planet(fieldName,mjd=times[0]/86400.)['directionRadians']
                    if (firstCalAtmScan != -1):
                        rightAscensionCalAtm, declinationCalAtm = planet(fieldName,mjd=firstCalAtmScanMeanMJD)['directionRadians']
                except:
                    if (casadef.casa_version >= '4.0.0'):
                        print "Failed to contact JPL, reverting to using CASA ephemerides to get the J2000 position."
                        rightAscension, declination = planet(fieldName,mjd=times[0]/86400.,useJPL=False)['directionRadians']
                        if (firstCalAtmScan != -1):
                            rightAscensionCalAtm, declinationCalAtm = planet(fieldName,mjd=firstCalAtmScanMeanMJD, useJPL=False)['directionRadians']
                    else:
                        print "Failed to contact JPL, reverting to showing apparent position (from the ms)."
                        rightAscension, declination = getRADecForField(vis, field, forcePositiveRA=True, usemstool=True)
                        apparentCoordinates = True
                        if (firstCalAtmScan != -1):
                            rightAscensionCalAtm, declinationCalAtm = getRADecForField(vis, calAtmField, forcePositiveRA=True, usemstool=True)
            else:
                rightAscension, declination = getRADecForField(vis, field, forcePositiveRA=True, usemstool=True)
                if fieldName.upper() in majorPlanets:
                    apparentCoordinates = True
                if (firstCalAtmScan != -1):
                    rightAscensionCalAtm, declinationCalAtm = getRADecForField(vis, calAtmField, forcePositiveRA=True, usemstool=True)
        if (len(offSourceRA) > 0):
            separation, deltaRaRadians, deltaDecRadians, deltaRaRadiansCosdec = angularSeparationRadians(xOffSource, yOffSource,
                                                                                       rightAscension, declination,
                                                                                       returnComponents=True)
            print "Separation from the off source position in relative coordinates = (%+.1f, %+.1f) arcsec" % (deltaRaRadiansCosdec*3600*180/np.pi,
                                                                        deltaDecRadians*3600*180/np.pi)
        if (len(calAtmRA) > 0):
            separation, deltaRaRadians, deltaDecRadians, deltaRaRadiansCosdec = angularSeparationRadians(xCalAtm, yCalAtm,
                                                                                       rightAscensionCalAtm, declinationCalAtm,
                                                                                       returnComponents=True)
            print "Separation from mean atm calib position in relative coordinates = (%+.1f, %+.1f) arcsec" % (deltaRaRadiansCosdec*3600*180/np.pi,
                                                                        deltaDecRadians*3600*180/np.pi)
            if (findSubscans):
                separation, deltaRaRadians, deltaDecRadians, deltaRaRadiansCosdec = angularSeparationRadians(xCalAtmSky, yCalAtmSky,
                                                                                       rightAscensionCalAtm, declinationCalAtm,
                                                                                       returnComponents=True)
                print "Separation from mean atmcal sky position in relative coordinates = (%+.1f, %+.1f) arcsec" % (deltaRaRadiansCosdec*3600*180/np.pi,
                                                                        deltaDecRadians*3600*180/np.pi)
                
            
    # convert absolute coordinates to relative arcsec on-the-sky
    for i in range(len(x)):
        if (x[i] < 0):
            print "x is negative"
        if (rightAscension < 0):
            print "rightAscension is negative"
        separation, dx, dy, dxcosdec = angularSeparationRadians(x[i],y[i],rightAscension,declination,True)
#        if i == 0:
#            print "x-rA=%f y-dec=%f, dx=%f dy=%f dxcosdec=%f" % (x[i]-rightAscension, y[i]-declination,dx,dy,dxcosdec)
        x[i] = dxcosdec*180*3600/np.pi
        y[i] = dy*180*3600/np.pi
    totalOffset = (x**2 + y**2)**0.5

    # determine largest dimension of the map
    if (casadef.casa_version < '4.3.0'):
        idx1_ignoreOffPosition, idx1_ignoreOffPositionX, idx1_ignoreOffPositionY = ignoreMostCommonPosition(x,y)
    else:
        onSourceTimes = mymsmd.timesforintent(intent)
        idx1_ignoreOffPosition = np.nonzero(np.in1d(times, onSourceTimes))
        idx1_ignoreOffPositionX = idx1_ignoreOffPosition
        idx1_ignoreOffPositionY = idx1_ignoreOffPosition
        if (len(idx1_ignoreOffPosition[0]) > 0):
#            print "idx1_ignoreOffPosition = ", idx1_ignoreOffPosition
            xOnSource = x[idx1_ignoreOffPosition]
            yOnSource = y[idx1_ignoreOffPosition]
            xmad = MAD(xOnSource)
            ymad = MAD(yOnSource)
            xExtremeOffset = np.max(np.abs(xOnSource-np.median(xOnSource)))
            yExtremeOffset = np.max(np.abs(yOnSource-np.median(yOnSource)))
            if (xExtremeOffset > 5*xmad or yExtremeOffset > 5*ymad):
                # Resort to the old method if the identification by time has failed. - 2015-08-07
                # For example, for uid___A002_X9fa4e2_Xca8
                if (debug):
                    print "*********** xmad=%f, ymad=%f, xExtreme=%f, yExtreme=%f ********" % (xmad, ymad, xExtremeOffset, yExtremeOffset)
                idx1_ignoreOffPosition, idx1_ignoreOffPositionX, idx1_ignoreOffPositionY = ignoreMostCommonPosition(x,y)
        
            xOnSource = x[idx1_ignoreOffPosition]
            yOnSource = y[idx1_ignoreOffPosition]
        else:
            xOnSource = x
            yOnSource = y
    mymsmd.close()
    if (len(yOnSource) > 0):
        ymaxloc = yOnSource.argmax()
        yminloc = yOnSource.argmin()
        xmaxloc = xOnSource.argmax()
        xminloc = xOnSource.argmin()
        locs = [xminloc,xmaxloc,yminloc,ymaxloc]
        distances = []
        for l in range(3): # 0; 1; 2
            for i in range(l+1,4): # 1,2,3;  2,3;  3
                distance = ((xOnSource[locs[l]]-xOnSource[locs[i]])**2 + (yOnSource[locs[l]]-yOnSource[locs[i]])**2)**0.5
                distances.append(distance)
        largestDimension = round(np.max(distances))
    else:
        largestDimension = np.max([np.max(y)-np.min(y), np.max(x)-np.min(x)])
    
    # Determine the scan direction and sampling
    # It does not seem to be necessary to trim off the OFF position times for this 
    # algorithm to get the right answer
    xSuccessiveDifferences = x[1:] - x[:-1]
    ySuccessiveDifferences = y[1:] - y[:-1]
    successiveDifferences = (xSuccessiveDifferences**2 + ySuccessiveDifferences**2)**0.5

    # Find the axis with most rapidly changing values
    mybeam = primaryBeamArcsec(vis, showEquation=False)
    finestSampling = np.median(np.abs(successiveDifferences))
    xSampling = np.median(np.abs(xSuccessiveDifferences))
    ySampling = np.median(np.abs(ySuccessiveDifferences))
    if debug:
        print "xSuccessiveDifferences[:500]=", xSuccessiveDifferences[:500]
        print "ySuccessiveDifferences[:500]=", ySuccessiveDifferences[:500]
        print "xSampling = ", xSampling
        print "ySampling = ", ySampling
    arbitraryScanAngle = False
    if (np.round(abs(xSampling),2) < np.round(abs(finestSampling),2) and 
        np.round(abs(ySampling),2) < np.round(abs(finestSampling),2)):
        print "WARNING: This raster was scanned at some arbitrary position angle, not in RA or Dec."
        print "xSampling=%f, ySampling=%f, finestSampling=%f" % (xSampling,ySampling, finestSampling)
        xSampling = finestSampling * medianSamplingIntervalDataTable / medianSamplingIntervalPointingTable
        raScan = False
        arbitraryScanAngle = True
        defaultXSampling = xSampling
        defaultYSampling = mybeam/3.0
        print "Will return the default values of X=%f, Y=%f." % (defaultXSampling, defaultYSampling)
    elif (abs(xSampling-finestSampling) < abs(ySampling-finestSampling)):
        print "This raster was scanned along RA."
        raScan = True
    else:
        print "This raster was scanned along Dec."
        raScan = False
        swap = x[:]
        x = y[:]
        y = swap[:]
        swap = xSuccessiveDifferences[:]
        xSuccessiveDifferences = ySuccessiveDifferences[:]
        ySuccessiveDifferences = swap[:]
    print "The finest sampling (in the pointing table) = %.3f arcsec." % (finestSampling)
        
    xSampling = finestSampling
    # correct for the ratio of pointing table data interval (0.048s) to correlator data rate (0.144s)
    print "Scaling sampling from pointing table interval to visibility data table interval: *%f" % (medianSamplingIntervalDataTable / medianSamplingIntervalPointingTable)
    xSampling *= medianSamplingIntervalDataTable / medianSamplingIntervalPointingTable

    # Find where the scan reverses direction
    xReversalPoints = (np.diff(np.sign(np.round(magnification*xSuccessiveDifferences)/magnification)) != 0)*1
    yReversalPoints = (np.diff(np.sign(np.round(magnification*ySuccessiveDifferences)/magnification)) != 0)*1
    reversalPoints = xReversalPoints + yReversalPoints
    indices = np.where(reversalPoints > 0)[0]
    rowChanges = indices[1::2]
    if (debug):
        print "%d xReversalPoints = %s" % (len(np.where(xReversalPoints>0)[0]), str(xReversalPoints))
        print "%d yReversalPoints = %s" % (len(np.where(yReversalPoints>0)[0]), str(yReversalPoints))
        print "Found %d row changes = %s" % (len(rowChanges), str(rowChanges))

    successiveRowDifferences = (xSuccessiveDifferences[rowChanges]**2 + ySuccessiveDifferences[rowChanges]**2)**0.5
    if (debug):
        print "a) successiveRowDifferences = ", successiveRowDifferences
        print "a) median = ", np.median(successiveRowDifferences)
    ySampling = np.median(successiveRowDifferences)
    xAtRowChanges = x[rowChanges]
    yAtRowChanges = y[rowChanges]
    if (originalCoordSys.find('AZEL') >= 0):
        roundedRowChanges = list(np.round(yAtRowChanges))
        try:
            ymode = max(set(roundedRowChanges), key=roundedRowChanges.count)
        except:
            ymode = np.median(yAtRowChanges) # old method, did not always work 
        threshold = max(1,abs(ymode*ymodeThreshold))
        if (debug):
            print "abs(yAtRowChanges-ymode) = ", abs(yAtRowChanges - ymode)
            print "ymode = ", ymode
        keeprows = np.where(abs(yAtRowChanges - ymode) > threshold)[0]
        if (debug):
            print "1) yAtRowChanges = ", str(yAtRowChanges)
        yAtRowChanges = yAtRowChanges[keeprows]
        xAtRowChanges = xAtRowChanges[keeprows]
        if (debug):
            print "Kept %d/%d rows" % (len(yAtRowChanges), len(x[rowChanges]))
            print "2) yAtRowChanges = ", str(yAtRowChanges)
        successiveRowDifferences = abs(yAtRowChanges[1:] - yAtRowChanges[:-1])
        if (debug):
            print "b) successiveRowDifferences = ", successiveRowDifferences
            print "b) median = ", np.median(successiveRowDifferences)
        ySampling = np.median(successiveRowDifferences)

    if (fieldName is not None):  
        if (fieldName.upper() in majorPlanets):
            if (pickFirstRaster == False):
                print "Setting pickFirstRaster=True"
            pickFirstRaster = True

    if (pickFirstRaster and intent.find('TARGET')>=0):
        # Recalculate the y Sampling over only the first raster
        # Find the range of the raster rows
        maxYoffset = np.max(y[idx1_ignoreOffPositionY])
        minYoffset = np.min(y[idx1_ignoreOffPositionY])
        medianYoffset = np.median(y[idx1_ignoreOffPositionY])
        yrange = maxYoffset-minYoffset
        # idx1 = points within the upper part of the raster
        idx1 = np.where(y > maxYoffset-0.1*yrange)[0]
        idx1 = np.intersect1d(idx1, idx1_ignoreOffPositionY[0])
        idx1 = np.intersect1d(idx1, idx1_ignoreOffPositionX[0])
        if (debug):
            print "y[:400]=", y[:400]
            print "maxYoffset=%f, minYoffset=%f, yrange=%f, maxY-0.1*yrange=%f" % (maxYoffset, minYoffset,yrange,maxYoffset-0.1*yrange)
            print "idx1=upper_portion_of_map=%s" % (str(idx1))
        # idx2 = points within the lower part of raster
        idx2 = np.where(y < minYoffset+0.1*yrange)[0]
        idx2 = np.intersect1d(idx2,idx1_ignoreOffPositionY[0])
        if (debug):
            print "idx2=lower_portion_of_map=%s" % (str(idx2))
        # idx3 = overlap of upper with lower
        idx3 = np.where(idx2 > idx1[0])[0]  # assumes that idx1 is increasing on the first raster row
        if (debug):
            print "idx3=%s" % (str(idx3))
            if (len(idx3) > 0):
                print "idx2[idx3[0]] = ", idx2[idx3[0]]
        myx = x
        myy = y
        mytimes = times
        if (len(idx3) > 0):
            if (debug): print "We found a second raster. Clipping data to first raster."
            if (len(idx2)>idx3[0]):
                endOfFirstRaster = idx2[idx3[0]]
                if (debug): 
                    print "endOfFirstRaster = %d [(%f,%f),(%f,%f),(%f,%f)]" % (endOfFirstRaster,
                        x[endOfFirstRaster-1],y[endOfFirstRaster-1],
                        x[endOfFirstRaster],y[endOfFirstRaster],
                        x[endOfFirstRaster+1],y[endOfFirstRaster+1])
                myx = x[:endOfFirstRaster]
                myy = y[:endOfFirstRaster]
                mytimes = times[:endOfFirstRaster]
        else:
            if (debug): print "There is only one raster in this dataset."
    
        # determine the scan direction and sampling
        xSuccessiveDifferences = myx[1:] - myx[:-1]
        ySuccessiveDifferences = myy[1:] - myy[:-1]
        successiveDifferences = (xSuccessiveDifferences**2 + ySuccessiveDifferences**2)**0.5
    
        # Find where the scan reverses direction
        xReversalPoints = (np.diff(np.sign(np.round(magnification*xSuccessiveDifferences)/magnification)) != 0)*1
        yReversalPoints = (np.diff(np.sign(np.round(magnification*ySuccessiveDifferences)/magnification)) != 0)*1
        reversalPoints = xReversalPoints + yReversalPoints
        indices = np.where(reversalPoints > 0)[0]
        rowChanges = indices[1::2]
        if (debug):
            print "%d xReversalPoints = %s" % (len(np.where(xReversalPoints>0)[0]), str(xReversalPoints))
            print "%d yReversalPoints = %s" % (len(np.where(yReversalPoints>0)[0]), str(yReversalPoints))
            print "Found %d row changes = %s" % (len(rowChanges), str(rowChanges))
        successiveRowDifferences = (xSuccessiveDifferences[rowChanges]**2 + ySuccessiveDifferences[rowChanges]**2)**0.5
        if (debug):
            print "c) successiveRowDifferences at rowChanges = ", successiveRowDifferences
        myxAtRowChanges = myx[rowChanges]
        myyAtRowChanges = myy[rowChanges]
        if (not arbitraryScanAngle or forceCardinalScanAngle):
          if (originalCoordSys.find('AZEL') >= 0):
            roundedRowChanges = list(np.round(myyAtRowChanges))
            try:
                ymode = max(set(roundedRowChanges), key=roundedRowChanges.count)
            except:
                ymode = np.median(myyAtRowChanges)  # old method, did not always work
            if (debug):
                print "ymode = ", ymode
            threshold = max(1,abs(ymode*ymodeThreshold))
            keeprows = np.where(abs(myyAtRowChanges - ymode) > threshold)[0]
            if (debug):
                print "3) yAtRowChanges = ", str(myyAtRowChanges)
            myyAtRowChanges = np.array(sorted(myyAtRowChanges[keeprows]))  # note the sorted() which is essential
            myxAtRowChanges = myxAtRowChanges[keeprows]
            if (debug):
                print "4) yAtRowChanges = ", str(myyAtRowChanges)
            successiveRowDifferences = abs(myyAtRowChanges[1:] - myyAtRowChanges[:-1])
            if (debug):
                print "d) successiveRowDifferences = ", successiveRowDifferences
            roundedDiff = list(np.round(successiveRowDifferences))
            if len(roundedDiff) > 0:
                x_mode = max(set(roundedDiff), key=roundedDiff.count)
                print "x_mode = ", x_mode
                idx = np.where(np.round(successiveRowDifferences) == x_mode)
            else:
                idx = [[]]
            print "matches to the mode = ", len(idx[0])
            if (len(idx[0]) > len(successiveRowDifferences)/5):
                try:
                    ySampling = np.median(successiveRowDifferences[idx])
                except:
                    ySampling = np.median(successiveRowDifferences)  # old method which did not always work
            else:
                # if the most common value (the mode) does not appear more than 20% of the time, then
                ySampling = np.median(successiveRowDifferences) # fail over to the old method
          else:
            roundedDiff = list(np.round(successiveRowDifferences))
            x_mode = max(set(roundedDiff), key=roundedDiff.count)
            try:
                ySampling = np.median(successiveRowDifferences[np.where(np.round(successiveRowDifferences) == x_mode)])
            except:
                ySampling = np.median(successiveRowDifferences)  # old method which did not always work

    if (not raScan) and (not arbitraryScanAngle):
        swap = xSampling
        xSampling = ySampling
        ySampling = swap
        swap = x
        x = y
        y = swap
        swap = xAtRowChanges
        xAtRowChanges = yAtRowChanges
        yAtRowChanges = swap
    print "xSampling = %.3f arcsec (%.3f points per beam)" % (xSampling, mybeam/xSampling)
    print "ySampling = %.3f arcsec (%.3f points per beam)" % (ySampling, mybeam/ySampling)

    if (showplot or plotfile!=''):
        if (showplot == False):
            pb.ioff()
        mjdsec = getObservationStart(vis)
        obsdateString = mjdToUT(mjdsec/86400.)
        pb.clf()
        adesc = pb.subplot(211)
        lineStyleUpperPlot = '.'
        if (connectDots):
            lineStyle = '-'
        else:
            lineStyle = '.'
        pb.plot_date(pb.date2num(mjdSecondsListToDateTime(times)),totalOffset,
                     'k'+lineStyleUpperPlot,
                     markeredgecolor='k',markerfacecolor='k',markersize=2.0)
        pb.hold(True)
        if (showComponents):
            pb.plot_date(pb.date2num(mjdSecondsListToDateTime(times)),x,'r-')
            pb.plot_date(pb.date2num(mjdSecondsListToDateTime(times)),y,'g-')
        pb.xlabel('Universal Time on %s' % (mjdsecToUT(times[0]).split()[0]))
        pb.ylabel('Angle from origin (arcsec)')
        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M:%S'))
        setXaxisTimeTicks(adesc, np.min(times), np.max(times))
        y0,y1 = pb.ylim()
        for s in timesforscan.keys():
            b = timesforscan[s]['begin']
            pb.plot_date(pb.date2num(mjdSecondsListToDateTime([b,b])), [y0,y1], 'k-')
            e = timesforscan[s]['end']
            pb.plot_date(pb.date2num(mjdSecondsListToDateTime([e,e])), [y0,y1], 'k--')
            pb.text(pb.date2num(mjdSecondsListToDateTime([0.5*(b+e)]))[0], 0.8*(y1-y0)+y0,
                    'Scan '+str(s),size=8,rotation='vertical')
        if (timerange == None or timerange == ''):
            newStartTime = timesforscan[scansToUse[0]]['begin'] - 20
            newEndTime = timesforscan[scansToUse[-1]]['end'] + 20
            newlimits = pb.date2num(mjdSecondsListToDateTime([newStartTime, newEndTime]))
            pb.xlim(newlimits)
            setXaxisTimeTicks(adesc, newStartTime, newEndTime)
        else:
            pb.xlim(pb.date2num(mjdSecondsListToDateTime(timerange)))
            setXaxisTimeTicks(adesc, timerange[0], timerange[1])
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        if (field is not None):
            fieldString = "  (0,0)=%s" % (fieldName)
        else:
            fieldString = ""
        pb.title(os.path.basename(vis) + ', ' + antennanames[antenna] + ', ' + obsdateString +  ', OBS_ID=%d,  %s' % (obsid,fieldString), fontsize=10)
        if (debug):
            print "subplot 211 : xlim=%s, ylim=%s" % (str(pb.xlim()),str(pb.ylim()))
        
        adesc = pb.subplot(212)
        pb.plot(x,y,'b.')
        pb.plot(x,y,'b'+lineStyle)
        xlimits = pb.xlim()
        ylimits = pb.ylim()
        pb.hold(True)
        pb.plot(xAtRowChanges, yAtRowChanges, 'r.', x[0], y[0], 'ro')
        pb.xlim(xlimits)
        pb.ylim(ylimits)
        if (plotrange != [0,0,0,0]):
            if (plotrange[0] != 0 or plotrange[1] != 0):
                pb.xlim([plotrange[0],plotrange[1]])
            if (plotrange[2] != 0 or plotrange[3] != 0):
                pb.ylim([plotrange[2],plotrange[3]])
        else:
            pb.xlim([np.max(x), np.min(x)])
            pb.axis('equal')
        for i in range(np.min([labelFirstNSamples, len(x)/labelIncrement])):
            sample = i*labelIncrement
            pb.text(x[sample],y[sample],str(sample),size=8)
        if (coordSys.find('AZEL') >= 0):
            azimString = qa.formxxx('%frad'%(rightAscension), format='deg', prec=5)
            elevString = qa.formxxx('%frad'%(declination), format='deg', prec=5)
            pb.xlabel('Azimuth offset (arcsec) from %s deg' % azimString)
            pb.ylabel('Elevation offset (arcsec) from %s deg' % elevString)
            pb.xlim([np.min(x), np.max(x)])
        else:
            raString = qa.formxxx('%frad'%(rightAscension), format='hms', prec=2)
            decString = qa.formxxx('%frad'%(declination), format='dms', prec=0).replace('.',':',2).replace('-0','-').replace('+0','+')
            if (apparentCoordinates):
                basis = '(apparent)'
            else:
                basis = '(J2000)'
            pb.ylabel('Dec offset (arcsec) from %s' % (decString), size=10)
            if (convert):
                pb.xlabel('Right Ascension offset (arcsec) from %s %s' % (raString,basis))
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        if overlayOTPointings != '':
            f = open(overlayOTPointings,'r')
            lines = f.readlines()
            otx = []; oty = []
            for line in lines:
                token = line.split(',')
                if token[0] == 'RA ' or len(token)<4: continue
                otx.append(float(token[0]))
                oty.append(float(token[1]))
                if token[3] == 'ARCMINS':
                    otx[-1] *= 60
                    oty[-1] *= 60
            f.close()
            pb.plot(otx, oty, 'g+', ms=12)
        xlim = pb.xlim();  ylim = pb.ylim()
        pb.plot([0.025], [0.96], 'ro', transform=adesc.transAxes)
        pb.plot([0.025], [0.91], 'r.', transform=adesc.transAxes)
        pb.text(0.05, 0.93, 'start point', transform=adesc.transAxes)
        pb.text(0.05, 0.86, 'end stroke', transform=adesc.transAxes)
        # The following is require to restore the tight limits
        pb.xlim(xlim)
        pb.ylim(ylim)
        if (showplot):
            pb.draw()
        if (plotfile != ''):
            if (plotfile == True):
                plotfile = vis+'.obsid%d.sampling.png' % (obsid)
            if (os.path.exists(plotfile)):
                if (os.access(plotfile, os.W_OK) == False):
                    plotfile = '/tmp/' + os.path.basename(plotfile)
            else:
                mydir = os.path.dirname(plotfile)
                if (mydir == ''):
                    mydir = os.getcwd()
                if (os.access(mydir, os.W_OK) == False):
                    plotfile = '/tmp/' + os.path.basename(plotfile)
            pb.savefig(plotfile)
            print "Saved plot in %s" % (plotfile)
        if (showplot == False):
            pb.ion()
    else:
        print "To show a plot, re-run with parameter showplot=True"
    if (convert==False and coordSys.find('AZEL')>=0):
        print "To determine the reference position, re-run with convert=True"
    if (arbitraryScanAngle):
        print "Due to arbitraryScanAngle, returning the default values of X=%f, Y=%f." % (defaultXSampling, defaultYSampling)
        return defaultXSampling, defaultYSampling, largestDimension
    else:
        return xSampling, ySampling, largestDimension
    # end of getTPSampling
    
def imshift(img, rashift, decshift, copyimage=True, absolute=False, regrid='', output=''):
    """
    Uses imhead to shift a CASA image in RA/Dec.
    rashift: value in arcsec to subtract from CRPIX1
    decshift: value in arcsec to subtract from CRPIX2
    copyimage: if True, then first copy the image to *.imshift
    absolute: if True, then treat rashift and decshift as absolute degrees
              or, if they are strings, as HH:MM:SS and  DD:MM:SS
    regrid: if specified, then regrid the image to match the metadata of this image
    output: name of the output image (default: <img>.imshift)
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image: %s" % (img)
        return
    if (not os.path.isdir(img)):
        print "This is not a CASA image."
        return
    if (not absolute and (type(rashift) == str or type(decshift) == str)):
        print "You must use absolute=True if rashift and decshift are strings."
        return
    if (copyimage):
        if (output == ''):
            output = img+'.imshift'
        if (os.path.exists(output)):
            print "Removing existing image = %s" % output
            shutil.rmtree(output)
        os.system('cp -r %s %s'%(img,output))
        img = output
        print "Copied image to ", img
    if casadef.casa_version >= '4.6.0':
        imhistory(img, mode='append', message='au.imshift(rashift=%f, decshift=%f, copyimage=%s, absolute=%s)' % (rashift,decshift,copyimage,absolute))
    if (absolute):
        if (type(rashift) == str):
            rashift,decshift = radec2deg(rashift+' '+decshift)
        imhead(img, mode='put', hdkey='CRVAL1', hdvalue='%fdeg'%rashift)
        if casadef.casa_version >= '4.6.0':
            imhistory(img, mode='append', message="imhead(mode='put', hdkey='CRVAL1', hdvalue='%fdeg')" % rashift)
        imhead(img, mode='put', hdkey='CRVAL2', hdvalue='%fdeg'%decshift)
        if casadef.casa_version >= '4.6.0':
            imhistory(img, mode='append', message="imhead(mode='put', hdkey='CRVAL2', hdvalue='%fdeg')" % decshift)
    else:
        cdelt1 = headerToArcsec(imhead(img, mode='get', hdkey='CDELT1'))
        cdelt2 = headerToArcsec(imhead(img, mode='get', hdkey='CDELT2'))
        rapix = rashift/cdelt1
        decpix = decshift/cdelt2
        crpix1 = imhead(img, mode='get', hdkey='CRPIX1')
        crpix2 = imhead(img, mode='get', hdkey='CRPIX2')
        print "Shifting RA  by %+f arcsec = %+f pixels" % (rashift,rapix)
        imhead(img, mode='put', hdkey='CRPIX1', hdvalue=crpix1-rapix)
        if casadef.casa_version >= '4.6.0':
            imhistory(img, mode='append', message="imhead(mode='put', hdkey='CRPIX1', hdvalue='%f')" % (crpix1-rapix))
        print "Shifting Dec by %+f arcsec = %+f pixels" % (decshift,decpix)
        imhead(img, mode='put', hdkey='CRPIX2', hdvalue=crpix2-decpix)
        if casadef.casa_version >= '4.6.0':
            imhistory(img, mode='append', message="imhead(mode='put', hdkey='CRPIX2', hdvalue='%f')" % (crpix2-decpix))
    if (regrid != '' and regrid != False):
        if os.path.exists(regrid):
            output = img + '.regrid'
            if (os.path.exists(output)):
                shutil.rmtree(output)
            imregrid(img, template=regrid, output=output, axes=[0,1])
            print "Final image left in ", output

def readNonStandardHeader(image):
    """
    If restfreq is missing, then imhead(mode='list') will bomb (CAS-5901).
    This workaround function reads the other major items individually 
    and builds a dictionary for getFitsBeam.
    -Todd Hunter
    """
    a = {}
    a['beammajor'] = imhead(image,mode='get',hdkey='beammajor')
    if (type(a['beammajor']) == type(None)):
        a['beammajor'] = 0
        a['beamminor'] = 0
        a['beampa'] = 0
    else:
        a['beamminor'] = imhead(image,mode='get',hdkey='beamminor')
        a['beampa'] = imhead(image,mode='get',hdkey='beampa')
    a['shape'] = imhead(image,mode='get',hdkey='shape')
    for key in ['cdelt','cunit','crpix','ctype']:
        for i in range(len(a['shape'])):
            keyn = key+str(i+1)
            a[keyn] = imhead(image,mode='get',hdkey=keyn)
            if (type(a[keyn]) == dict):
                arcsec = a[keyn]['value']
# This conversion happens in getFitsBeam, so don't do it here.
#                if (a[keyn]['unit'].find('min') >= 0):
#                    arcsec *= 60
#                if (a[keyn]['unit'].find('deg') >= 0):
#                    arcsec *= 3600
#                if (a[keyn]['unit'].find('rad') >= 0):
#                    arcsec *= 180*3600/np.pi
                a[keyn] = arcsec
    return(a)
    
def getFitsDate(image):
    """
    Extracts and prints the date information from a FITS image.
    Todd Hunter
    """
    if (os.path.exists(image) == False):
        print "image not found"
        return
    if (pyfitsPresent == False):
        print "pyfits is not present"
        return
    if (os.path.isdir(image)):
        # Assume this is a CASA image
        a = imhead(image,mode = 'list')
        if (a == None):
            if (os.access(".",os.W_OK) == False):
                print "Change to a directory where you have write permission and try again."
                print "e.g. au.getFitsDate('%s/%s')" % (os.getcwd(),image)
                return
            else:
                try:
                    restfreq = imhead(image,mode='get',hdkey='restfreq')
                    if (restfreq['value'] <= 0.0):
                        a = readNonStandardHeader(image)
                        print "Reading non-standard header: ", a
                    else:
                        print "restfreq = ", restfreq
                except:
                    print "imhead returned NoneType."
                    print "This image header is not sufficiently standard."
                    return
        foundDate = 0
        for datekey in a.keys():
            if (datekey.lower().find('date') >= 0):
                foundDate += 1
                print "%s = %s" % (datekey, a[datekey])
        if (foundDate == 0): print "No date keys found in the header."
    else:
        f = pyfits.open(image)
        hdr = f[0].header
        bmaj = -1
        try:
            keys = hdr.ascardlist().keys()
        except:
            keys = hdr.keys()
        for datekey in ['DATE-OBS', 'DATE_OBS', 'DATE-END', 'DATE_END']:
            if (datekey in keys):
                print "%s = %s" % (datekey, hdr[datekey])
        f.close()

def imageRegister(goodImage, badImage, goodStars=[], badStars=[], fitradius=10,
                  residual=None, model=None,logfile=None,includepix=[],
                  excludepix=[], estimates='', runImshift='', dooff=False,
                  use_imfitparseCLB=False, regrid='', runImfit=True, outfile=''):
    """
    Runs imfit on a list of star positions in two images of the same field and
    determines the median pixel shift (in the badImage) that will bring them
    into alignment. It runs imfit on both images in small boxes centered on
    a list of the approximate RA/Dec positions (goodStars), e.g. as read by
    eye from the viewer on the goodImage.
    goodImage: a CASA image with good astrometry
    badImage: a CASA image with bad astrometery
    goodStars: a list of RA/Dec strings in J2000, e.g. ['17h45m32.0s +14.15.46.45']
      or ['17:45:32.0 +14:15:46.45'] (see help au.radec2rad for all accepted formats)
       if a blank list, then just use the peak pixel in the goodImage
    badStars: only need this to specify counterparts if the astrometry is way off
    fitradius: half the size of the box region to use (value in arcsec)
    runImshift: '', 'mean' or 'median'; if not blank, then run au.imshift on 
           badImage to create <badImage>.imshift using either mean or median
    runImfit: if False, then assume goodStars and badStars are accurate, and
           you only want to use the part of the algorithm that computes mean
           and MAD of the shift
    residual, model, logfile, includepix, excludepix, estimates: passed to imfit
       (probably only useful for doing one star at a time)
    regrid: if True, and runImshift is set, then regrid the shifted image 
            to match the metadata of the goodImage (useful for immath('spix'))
            can also specify the image name directly
    outfile: name of image to produce, default = <img>.imshift
    Returns:
    A dictionary of the 'median' and 'mean' shift to be applied in RA and Dec 
    (in units of pixels in badImage).
    -Todd Hunter
    """
    if not os.path.exists(goodImage):
        print "Could not find goodImage"
        return
    if not os.path.exists(badImage):
        print "Could not find badImage"
        return
    if len(goodStars)  == 0:
        goodStars = [imagePeak(goodImage, returnPosition='radec')[1]]
    if (badStars==[]):
        badStars = goodStars
    goodFit = []
    if runImfit:
        if use_imfitparseCLB:
            print 'fields =        RA         Dec    Ra+/-  Dec+/-  Peak  +/-  FluxDensity +/-  S/N  Major(")  Minor(") PA  +/-  +/-  +/- DeMajor(") DeMinor(") DePA +/- +/- +/-'
        else:
            print 'fields =        RA         Dec       FluxDensity +/-  S/N  Major(") +/-  Minor(") +/-  PA +/-'
    for i,star in enumerate(goodStars):
        if not runImfit:
            ra = star.split()[0]
            if ra.find('.') < 0:
                ra += '.'
            digits = len(ra[ra.find('.'):])
            if digits < 4:
                ra += '0'*(4-digits)
            dec = star.split()[1]
            if dec.find('.') < 0:
                dec += '.'
            digits = len(dec[dec.find('.'):])
            if digits < 3:
                dec += '0'*(3-digits)
        else:
            blc = radecOffsetToRadec(star, +fitradius, -fitradius, replaceDecDotsWithColons=False, verbose=False)
            trc = radecOffsetToRadec(star, -fitradius, +fitradius, replaceDecDotsWithColons=False, verbose=False)
            region = 'box [[%s],[%s]] coord=J2000' % (blc,trc)
    #        print "Running imfit('%s', region='%s')" % (goodImage, region)
            mydict = imfit(goodImage, region=region, residual=residual, logfile=logfile, 
                           model=model, excludepix=excludepix, includepix=includepix, 
                           estimates=estimates, dooff=dooff)
            if use_imfitparseCLB:
                result = imfitparseCLB(mydict, decprec=7, raprec=7)
                ra, dec, raUnc, decUnc, intensity, intensityUnc, snr, flux, fluxerr, majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr, deconvMajorArcsec, deconvMinorArcsec, deconvPosangle, deconvMajorUnc, deconvMinorUnc, deconvPosangleUnc = result.split()
            else:
                result = imfitparse(mydict, decprec=7, raprec=7)
                ra, dec, flux, fluxerr, snr, majorarcsec, majorarcsecerr, minorarcsec, minorarcsecerr, posangle, posangleerr = result.split()
            print "goodImage result %d = " % (i), result
        goodFit.append(ra + ' ' + dec)
        
    badFit = []
    for i,star in enumerate(badStars):
        if not runImfit:
            ra = star.split()[0]
            if ra.find('.') < 0:
                ra += '.'
            digits = len(ra[ra.find('.'):])
            if digits < 4:
                ra += '0'*(4-digits)
            dec = star.split()[1]
            if dec.find('.') < 0:
                dec += '.'
            digits = len(dec[dec.find('.'):])
            if digits < 3:
                dec += '0'*(3-digits)
        else:
            blc = radecOffsetToRadec(star, +fitradius, -fitradius, replaceDecDotsWithColons=False, verbose=False)
            trc = radecOffsetToRadec(star, -fitradius, +fitradius, replaceDecDotsWithColons=False, verbose=False)
            region = 'box [[%s],[%s]] coord=J2000' % (blc,trc)
            mydict = imfit(badImage, region=region, residual=residual, logfile=logfile, 
                           model=model, excludepix=excludepix, includepix=includepix, 
                           estimates=estimates, dooff=dooff)
            if use_imfitparseCLB:
                result = imfitparseCLB(mydict, decprec=7, raprec=7)
                ra, dec, raUnc, decUnc, intensity, intensityUnc, snr, flux, fluxerr, majorarcsec, minorarcsec, posangle, majorarcsecerr, minorarcsecerr, posangleerr, deconvMajorArcsec, deconvMinorArcsec, deconvPosangle, deconvMajorUnc, deconvMinorUnc, deconvPosangleUnc = result.split()
            else:
                result = imfitparse(mydict, decprec=7, raprec=7)
                ra, dec, flux, fluxerr, snr, majorarcsec, majorarcsecerr, minorarcsec, minorarcsecerr, posangle, posangleerr = result.split()
            print "badImage result %d = " % (i), result
        badFit.append(ra + ' ' + dec)
    result = getFitsBeam(badImage) # , omitBeam=True)
    raPixelSize = result[3]
    decPixelSize = result[4]
    raShift = []
    decShift = []
    print "\n goodImage fitted position       badImage fitted position    offsetArcsec(rao,deco)   offsets(pixels_in_bad_image)  meanFittedPosition"
    for fit in range(len(badFit)):
        sep, rao, deco, raoCosDec, pa = angularSeparationOfStrings(goodFit[fit], badFit[fit], returnComponents=True, verbose=False)
        raoArcsec = raoCosDec*3600
        decoArcsec = deco*3600
        raShift.append(raoArcsec/raPixelSize)
        decShift.append(decoArcsec/decPixelSize)
        meanPosition = getMeanPosition([goodFit[fit],badFit[fit]])
        print "%s   %s   %+f %+f   %+f %+f  %s" % (goodFit[fit], badFit[fit], raoArcsec, decoArcsec,
                                                   raShift[-1], decShift[-1], meanPosition)
    if runImshift != '':
        if (runImshift == 'mean'):
            raoArcsec = np.mean(raShift)*raPixelSize
            decoArcsec = np.mean(decShift)*decPixelSize
        elif (runImshift == 'median'):
            raoArcsec = np.median(raShift)*raPixelSize
            decoArcsec = np.median(decShift)*decPixelSize
        else:
            print "Unrecognized value for runImshift: must be '', 'mean' or 'median'."
            return
        if regrid == True:
            regrid = goodImage
        print "Running imshift('%s', %f, %f, copyimage=True, regrid='%s', output='%s')" % (badImage, raoArcsec, decoArcsec, regrid, outfile)
        imshift(badImage, raoArcsec, decoArcsec, copyimage=True, regrid=regrid, output=outfile)
    return({'median': (np.median(raShift), np.median(decShift)), 
            'mean': (np.mean(raShift), np.mean(decShift))})

def imagePad(img, npixels, value=0, padmask=True):
    """
    Pads a casa image and overwrites it.
    padmask: True = good (unmasked)
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    myia.pad(img, npixels=npixels, value=value, overwrite=True, padmask=padmask)
    myia.close()

def imageSum(images, outfile='imagesum'):
    """
    Adds a list of casa images and writes a summed image.
    -Todd Hunter
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    expr = ''
    for i in range(len(images)):
        if (i > 0): expr += '+'
        expr += 'IM%d' % i
    immath(imagename=images, mode='evalexpr',outfile=outfile,
           expr=expr)
    
def imageSmooth(images, template='', major='', minor='', pa='', targetres=True, overwrite=True, outfile=''):
    """
    Runs imsmooth on a list of images
    images: a list of strings, or a comma-delimited string, or a single string
        with the wildcard character (*)
    template: image from which to read the beam to convolve to
    major: e.g. '4arcsec' or 4.0
    minor: e.g. '3arcsec' or 3.0
    pa:  e.g. '20deg'
    targetres: Boolean
    outfile: if not specified, then append '.imsmooth' to the image name
    overwrite: if True, and output image already exists, then remove it first
    -Todd Hunter
    """
    if (template=='' and major==''):
        print "You must specify either a template image or a major axis."
        return
    if (template != ''):
        result = getFitsBeam(template)
        major = result[0]
        minor = result[1]
        pa = result[2]
        print "Got beam from template = %f x %f at %f" % (major, minor, pa) 
    if (type(major) != str):
        major = '%farcsec' % (major)
    if (type(minor) != str):
        minor = '%farcsec' % (minor)
    if (type(pa) != str):
        pa = '%fdeg' % (pa)
    if (minor==''):
        minor = major
    if (pa==''):
        pa = '0deg'
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    for i,img in enumerate(images):
        if (outfile == ''):
            myoutfile = img+'.imsmooth'
        else:
            myoutfile = outfile.split(',')[i]
        if (os.path.exists(myoutfile)):
            if (overwrite):
                print "Removing existing image"
                shutil.rmtree(myoutfile)
            else:
                print "Image exists, use overwrite=True to overwrite."
                return
        imsmooth(img, targetres=targetres, major=major, minor=minor, pa=pa,
                 outfile=myoutfile, overwrite=True)
        print "Wrote ", myoutfile

def setObject(imgname, objname):
    """
    setobject: set the OBJECT keyword in a FITS image (and FIELD, if present)
    imgname - name of the FITS image
    objname - new value of the OBJECT (and FIELD) keyword(s)
    - Dirk Petry
    """
    if type(imgname) != str or imgname == "":
        print "imgname must be a non-empty string"
        return
    if type(objname) != str or objname == "":
        print "imgname must be a non-empty string"
        return        
    if not pyfitsPresent:
        print "pyfits is not present"
        return
    try:
        fixFitsHeader(imgname)
    except:
        print "Attempt to fix some standard problems with aU.fixFitsHeader() failed."
        print "Will skip this."
    rval = True
    hdulist = pyfits.open(imgname, mode='update')
    prihdr = hdulist[0].header
    thekeys = prihdr.keys()
    if 'OBJECT' in thekeys:
        prihdr['OBJECT'] = objname
        print "The OBJECT keyword in file ",imgname
        print " was set to ", objname 
    else:
        print "ERROR: file ",imgname," has no OBJECT keyword!"
        rval=False
    if 'FIELD' in thekeys:
        prihdr['FIELD'] = objname
        print "The FIELD keyword in file ",imgname
        print " was set to ", objname 
    else:
        print "NOTE: file ",imgname," has no FIELD keyword."
    hdulist.close()
    return rval

def fixFitsHeader(img, newlines=True, duplicateKeywords=True, verbose=False):
    """
    Removes newline characters in all string-valued keywords of FITS images,
    such as the ORIGIN keyword written by CASA 4.7.
    Removes duplicate keyword entries for OBJECT and TELESCOP, which are
    written by tclean into the miscinfo keyword of the CASA image table.
    -Todd Hunter
    """
    if not os.path.exists(img):
        print "File not found"
        return
    if not pyfitsPresent:
        print "pyfits is not present"
        return
    if newlines:
        f = pyfits.open(img, memmap=True, mode='update')
        f.verify('fix')
        lines = 0
        for key in f[0].header.keys():
            value = f[0].header[key]
            if type(value) == str:
                if verbose: 
                    print "Checking for newline in ", value
                if ('\n' in value):
                    lines += 1
                    f[0].header[key] = value.replace('\n','')
        f.close()
        if lines == 0:
            print "No extraneous newlines found"
        else:
            print "Fixed %d lines." % (lines)
    if duplicateKeywords:
        f = pyfits.open(img, memmap=True, mode='update')
        keys = f[0].header.keys()
        values = f[0].header.values()
        if (len(keys) == len(values)):
            print "No duplicate keywords found."
            return
        lines = 0
        for keyword in ['OBJECT','TELESCOP']:
            if keyword in keys:
                location = keys.index(keyword)
                obj = f[0].header.pop(keyword)
                f[0].header.update(keyword, obj, after=keys[location-1])
                print "Removed duplicate keyword: ", keyword
        f.close()
        
def getFitsBeams(images):
    """
    Calls getFitsBeam for a list of images and prints a wiki table.
    images: a list of strings, or a comma-delimited string, or a single string
        with the wildcard character (*)
    -Todd Hunter
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
        if (len(images) < 1):
            print "No images found"
            return
        print "checking %d images" % (len(images))
    outline = ''
    pas = []
    bmins = []
    bmajs = []
    for img in images:
        bmaj, bmin, bpa, cdelt1, cdelt2, naxis1, naxis2, freq= getFitsBeam(img)
        outline += '| %s |  %.4f  |  %.4f  |  %+5.1f  |\n' %(img,bmaj,bmin,bpa)
        pas.append(bpa)
        bmins.append(bmin)
        bmajs.append(bmaj)
    print outline
    print "min: %f x %f,  max: %f x %f" % (np.min(bmaj), np.min(bmin),
                                           np.max(bmaj), np.max(bmin))
    print "pa: %f to %f,  mean: %f +- %f deg" % (np.min(pas), np.max(pas),
                                                 np.mean(pas), np.std(pas))

def imagePrimaryBeam(img, method='ia', header='', returnRadiusInPixels=True, 
                     fwhmfactor=None, verbose=False):
    """
    Reads the frequency from an image (CASA or FITS) and returns the
    primary beam FWHM in arcsec.  Uses table of antenna sizes (ACA, ALMA, SMA, VLA).
    returnRadiusInPixels: if True, then also return the radius of the beam in pixels
    header: only used if method=='header'
    verbose: if True, then show the frequency read from the header
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    result = getFitsBeam(img) #, omitBeam=True)
    if verbose: print "frequency = %f GHz" % (result[-1])
    diameter = imageAntennaDiameter(img, method, header)
    arcsec = primaryBeamArcsec(frequency=result[-1], showEquation=False, 
                               fwhmfactor=fwhmfactor, diameter=diameter)
    if returnRadiusInPixels:
        pixels = 0.5*abs(arcsec/result[4])
        return(arcsec, pixels)
    else:
        return(arcsec)

def getDiameterForObservatory(observatory):
    """
    Convert an observatory name to an antenna diameter. This is used to determine 
    primary beam size from an image, which contains only the name of the telescope 
    in the header, and no ANTENNA table.  Supported: ACA, ALMA, VLA, SMA
    Returns: value in meters
    -Todd Hunter
    """
    if (observatory.upper().find('ACA') >= 0):
        return 7.0
    if (observatory.upper().find('ALMA') >= 0):
        return 12.0
    if (observatory.upper().find('VLA') >= 0):
        return 25.0
    if (observatory.upper().find('SMA') >= 0):
        return 6.0

def imageAntennaDiameter(img, method='ia', header=''):
    """
    Attempt to infer the antenna diameter from an image, based on the 
    observatory name.
    header: only used if method=='header'
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    observatory = imageObservatory(img, method, header)
    if (observatory == ''):
        return 
    diameter = getDiameterForObservatory(observatory)
    return diameter

def imageObservatory(img, method='ia', header=''):
    """
    Attempt to infer the observatory name for an image.
    method: 'ia' (iatool, fastest method), 'header'
    header: only used if method=='header'
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    if method == 'ia' or method == '':
        myia = createCasaTool(iatool)
        myia.open(img)
        mycs = myia.coordsys()
        telescope = mycs.telescope()
        myia.close()
        return telescope
    elif method == 'header':
        if (header == ''):
            header = imheadlist(img, omitBeam=True)
        for k in ['telescope', 'observatory']:
            if (k in header):
                return(header[k])
            if (k.upper() in header):
                return(header[k.upper()])
    else:
        print "Unrecognized method for retrieving observatory name: ", method
    return ''

def readFitsMultiBeamTable(f):
    """
    Computes the median beam from a FITS beam table written by CASA.
    -Todd Hunter
    """
    f = np.array(f)
    return(np.median(f['BMAJ']), np.median(f['BMIN']), np.median(f['BPA']))

def parseImadvise(result):
    """
    Parses the tuple returned by imager.advis() into maximum recommended
    cellsize, in arcsec.
    -Todd Hunter
    """
    myqa = createCasaTool(qatool)
    success, pixels, cell, junk, icrs = result
    cell = myqa.getvalue(myqa.convert(cell, 'arcsec'))[0]
    myqa.done()
    return cell
    
def parseFitpsf(result):
    """
    Parses the tuple returned by imager.fitpsf() into major axis, minor axis, 
    and position angle, in units of arcsec, arcsec and deg.
    -Todd Hunter
    """
    success, bmaj, bmin, pa = result
    myqa = createCasaTool(qatool)
    bmaj = myqa.getvalue(qa.convert(bmaj, 'arcsec'))[0]
    bmin = myqa.getvalue(qa.convert(bmin, 'arcsec'))[0]
    pa = myqa.getvalue(qa.convert(pa,'deg'))[0]
    myqa.done()
    return bmaj, bmin, pa

def fitFitsBeam(img, centralFraction=0.1):
    """
    Runs imfit on the central portion of a psf image and reports 3 values:  
    major axis (arcsec), minor axis (Arcsec), and position angle (deg).
    See also getFitsBeam to read a beam from the header (if present).
    centralFraction: restrict fitted region to this fraction of the image center
    -Todd Hunter
    """
    xpix = getFitsBeam(img)[5]
    ypix = getFitsBeam(img)[6]
    box = '%d,%d,%d,%d' % (int(xpix*(0.5-centralFraction*0.5)), 
                           int(ypix*(0.5-centralFraction*0.5)),
                           int(xpix*(0.5+centralFraction*0.5)),
                           int(ypix*(0.5+centralFraction*0.5)))
    results = parseImfitShape(imfit(img,box=box)['results']['component0']['shape'])
    return results[:3]

def getFitsBeam(img, returnBunit=False, addHalfChannelWidth=False, 
                returnRestFreq=False, 
                returnVelocityWidth=False, verbose=False, warnNoBeam=True,
                referenceFrequency=None): 
    """
    Uses the ia.restoringbeam command for CASA images, which is faster than 
    the CASA task imhead. For a FITS image, it uses pyfits, so it can be run 
    from python (outside of CASA).
    Returns: bmaj, bmin, bpa, cdelt1, cdelt2, naxis1, naxis2, frequency (in GHz)
       Also returns bunit if returnBunit==True
       Angles are in arcseconds (bpa in degrees)
       Frequency is in GHz and is reference frequency (often channel 0 of cube)
       but see au.imageChannelFrequency to get a specific channel
       If beam is not present, then it returns zeros but still returns
       the rest of the values.
    returnRestFreq: if True, then also return restfreq in Hz (if present)
    returnVelocityWidth: if True, then also return the channel velocity width in +km/s
         returnRestFreq and returnVelocityWidth are mutually exclusive options
    addHalfChannelWidth: in the frequency calculation
    verbose: if True, print also the results for FITS image to terminal in human-readable form
    referenceFrequency: use this to compute velocity width instead of cs.referencevalue
    """
    if (os.path.exists(img) == False):
        print "image not found: ", img
        return
    if (returnVelocityWidth and returnRestFreq):
        print "Cannot specify both returnVelocityWidth and returnRestFreq"
        return
    if os.path.isdir(img):
        myia = createCasaTool(iatool)
        myia.open(img)
        mydict = myia.restoringbeam()
        if mydict == {} and warnNoBeam:
            print "No beam found. Will still return the other items."
    else:
        # It must be a FITS file, so let it fall through to the FITS code.
        mydict = {}
    cdelt1 = None # signal the later stages that this still needs to be read
    bmaj = None
    if 'major' in mydict.keys() or 'beams' in mydict.keys():
        # then a beam is present
        if 'major' in mydict.keys():
            # single beam case
            bmaj = qa.convert(mydict['major'], 'arcsec')['value']
            bmin = qa.convert(mydict['minor'], 'arcsec')['value']
            bpa = qa.convert(mydict['positionangle'], 'deg')['value']
        elif 'beams' in mydict.keys():
            # perplane beams
            beams = mydict['beams']
            major = []
            minor = []
            sinpa = []
            cospa = []
            for channel in beams.keys():
                pols = beams[channel].keys()
                for pol in pols:
                    major.append(qa.convert(beams[channel][pol]['major'],'arcsec')['value'])
                    minor.append(qa.convert(beams[channel][pol]['minor'],'arcsec')['value'])
                    sinpa.append(np.sin(qa.convert(beams[channel][pol]['positionangle'],'rad')['value']))
                    cospa.append(np.cos(qa.convert(beams[channel][pol]['positionangle'],'rad')['value']))
            bmaj = np.median(major)
            bmin = np.median(minor)
            bpa = np.degrees(np.arctan2(np.median(sinpa), np.median(cospa)))
            print "Computing median of per-plane beams."
        else:
            print "Unrecognized beam dictionary."
            return
    elif (not os.path.isdir(img)):
        # then it may very well be a FITS file
        if (not pyfitsPresent):
            print "ia.restoringbeam failed, and pyfits is not present"
            return
        else:
            # This (older) code is for running on FITS files outside of CASA (e.g. aplpy scripts).
            f = pyfits.open(img)
            imghdr = 0
            bmaj = -1
            for hdctr in range(len(f)): # support Herschel images (where the image is an extension)
                if bmaj > 0:
                    # But ignore later extensions if you have already found the beam.
                    break
                hdr = f[hdctr].header  # why is this sometimes an 'instance'  ?
                if (str(type(hdr)).find('instance') < 0):
                  if ('BMAJ' not in hdr.keys()):
                    # Check if the beam is channel-dependent
                    if ('CASAMBM' in hdr.keys()):
                        if (hdr['CASAMBM'] == True):
                            print "This image has multiple beams. Computing median from the FITS table."
                            bmaj, bmin, bpa = readFitsMultiBeamTable(f[1].data)
                            break
                    if ('HISTORY' not in hdr.keys()):
                        if (hdctr == len(f)-1):
                            print "A) Did not find BMAJ or CASAMBM=True in header, and there are no HISTORY keys."
                            hdr = f[imghdr].header
                            bmin = 0
                            bmaj = 0
                            bpa = 0
                            break
                        else:
                            if 'CDELT1' in hdr.keys():
                                # Take note of the image header, when you encounter it
                                imghdr = hdctr
                            continue
                    try: # older versions
                        keys = hdr.ascardlist().keys()
                        values = hdr.ascardlist().values()
                    except:  # newer versions
                        keys = hdr.keys()
                        values = hdr.values()
                    for key in range(len(keys)):
                        if ('HISTORY' == keys[key]):
                            value = values[key]
                            if (value.find('BMAJ') >= 0):
                                # Assume all are in one record.  If not, be careful of
                                # BPA being confused with BPASS.
                                tokens = value.split()
                                for t in range(len(tokens)):
                                    if (tokens[t].find('BMAJ') == 0):
                                        bmaj = float(tokens[t+1])*3600
                                        break
                                for t in range(len(tokens)):
                                    if (tokens[t].find('BMIN') == 0):
                                        bmin = float(tokens[t+1])*3600
                                        break
                                for t in range(len(tokens)):
                                    if (tokens[t].find('BPA') == 0):
                                        bpa = float(tokens[t+1].split('/')[0])
                                        break
                    if (bmaj < 0):
                        print "B) Did not find BMAJ or CASAMBM=True in header, nor in the HISTORY keys."
                        return
                  else:            
                      bmaj = hdr['BMAJ']*3600
                      bmin = hdr['BMIN']*3600
                      bpa = hdr['BPA']
                else:            
                    bmaj = hdr['BMAJ']*3600
                    bmin = hdr['BMIN']*3600
                    bpa = hdr['BPA']
                if verbose:
                    print "%g'' x %g'' at %+g deg" % (bmaj, bmin, bpa)
            naxis1 = hdr['NAXIS1']
            naxis2 = hdr['NAXIS2']
            cdelt1 = hdr['CDELT1']*3600
            cdelt2 = hdr['CDELT2']*3600
            ctype1 = hdr['CTYPE1'].split('-')[0]
            ctype2 = hdr['CTYPE2'].split('-')[0]
            if (returnBunit):
                if 'bunit' in hdr.keys():
                    bunit = hdr['BUNIT']
                else:
                    bunit = ''
            if verbose:
                print "Pixel size = %f by %f (%s by %s)" % (cdelt1,cdelt2,ctype1,ctype2)
            imgfreq = 0
            if (str(type(hdr)).find('instance') < 0):
              if ('CTYPE3' in hdr.keys()):
                ctype3 = hdr['CTYPE3']
                print "Found CTYPE3 in header: %s" % (ctype3)
                if (ctype3.upper().find('FREQ')>=0 or ctype3.upper().find('VRAD') >= 0):
                    crval3 = hdr['CRVAL3']
                    crpix3 = hdr['CRPIX3']
                    cdelt3 = hdr['CDELT3']
                    npix3 = hdr['NAXIS3']
                    imgfreq = crval3
                    if (addHalfChannelWidth):
                        imgfreq += cdelt3*(npix3/2.)
                    if (ctype3.upper().find('FREQ')>=0):
                        if verbose:
                            print "CRVAL3 = %g Hz at CRPIX = %g" % (crval3,crpix3)
                            print "central freq = %g Hz" % (imgfreq)
                        imgfreq *= 1e-9
                    else:
                        imgfreq *= 1e-3
                        if verbose:
                            print "CRVAL3 = %g VRAD at CRPIX = %g" % (crval3,crpix3)
                            print "central velocity = %g km/s VRAD" % (imgfreq)
              elif ('CTYPE4' in hdr.keys()):
                print "Found CTYPE4 in header"
                ctype3 = hdr['CTYPE4']
                if (ctype3.upper().find('FREQ')>=0 or ctype3.upper().find('VRAD') >= 0):
                    crval3 = hdr['CRVAL4']
                    crpix3 = hdr['CRPIX4']
                    cdelt3 = hdr['CDELT4']
                    npix3 = hdr['NAXIS4']
                    imgfreq = crval3
                    if (addHalfChannelWidth):
                        imgfreq += cdelt3*(npix3/2.)
                    if (ctype3.upper().find('FREQ')>=0):
                        if verbose:
                            print "CRVAL4 = %g Hz at CRPIX = %g" % (crval3,crpix3)
                            print "central freq = %g Hz" % (imgfreq)
                        imgfreq *= 1e-9
                    else:
                        imgfreq *= 1e-3
                        if verbose:
                            print "CRVAL3 = %g VRAD at CRPIX = %g" % (crval3,crpix3)
                            print "central velocity = %g km/s VRAD" % (imgfreq)
              if ('RESTFREQ' in hdr.keys()):
                  if verbose:
                      print "RESTFREQ = %g Hz" % (hdr['RESTFREQ'])
                      if (imgfreq == 0): imgfreq = hdr['RESTFREQ']
              frequencyGHz = imgfreq

    if cdelt1 is None:
        if bmaj is None:
            # Even when no beam is present, we still return the other values.
            bmaj = 0
            bmin = 0
            bpa = 0
        naxis1 = myia.shape()[0]
        naxis2 = myia.shape()[1]
        axis = findSpectralAxis(myia)
        mycs = myia.coordsys()
        restfreq = qa.convert(mycs.restfrequency(), 'Hz')['value'][0]
        cdelt1 = mycs.increment()['numeric'][0] * ARCSEC_PER_RAD
        cdelt2 = mycs.increment()['numeric'][1] * ARCSEC_PER_RAD
        deltaFreq = mycs.increment()['numeric'][axis]
        if referenceFrequency is None:
            frequency = mycs.referencevalue()['numeric'][axis]
        else:
            frequency = parseFrequencyArgumentToHz(referenceFrequency)
        frequencyGHz =  frequency * 1e-9
        if addHalfChannelWidth:
            frequency += 0.5*deltaFreq
        mycs.done()
        bunit = myia.brightnessunit()
        velocityWidth = abs(c_mks * 0.001 * deltaFreq / frequency)
        myia.close()
    if (returnBunit):
        if (returnRestFreq):
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz,bunit,restfreq])
        elif (returnVelocityWidth):
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz,bunit,velocityWidth])
        else:
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz,bunit])
    else:
        if (returnRestFreq):
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz,restfreq])
        elif (returnVelocityWidth):
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz,velocityWidth])
        else:
            return([bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,frequencyGHz])
                                                                
def gjincBeam(frequency, pixelsize=10, diameter=12.0, xSamplesPerBeam=5.0,
              ySamplesPerBeam=None, xSamplingArcsec=None, ySamplingArcsec=None,
              makeplot=False, taper=10, geometricMean=False, obscuration=0.75,
              widthMultiplier=1.0, useCasaJinc=False, testOption=False, 
              minlevels=[0], truncate=False, img=None, row=None, column=None, 
              stokes='XX',plotfile='',verbose=False, fwhmfactor=None,
              excludeBand3=True,excludeBand3Below=109.0):
    """
    This function calls the griddedBeam class to compute the effective restoring
    beam obtained from the casa command sd_imaging when using the GJINC
    gridding kernel assuming the GJINC specific parameters are left at
    their default values.
        
    frequency: floating point number in GHz (no units) or a string with units
    pixelsize: floating point number in arcseconds (no units)
    diameter: the diameter of the single dish antenna in meters (no units)
    xSamplesPerBeam: the number of sampled points per telescope FWHM beam
                     along the X axis
    ySamplesPerBeam: the number of sampled points per telescope FWHM beam
                     along the Y axis
    xSamplingArcsec: if not None, then use this value instead of xSamplesPerBeam
    ySamplingArcsec: if not None, then use this value instead of ySamplesPerBeam
    taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function as the antenna beam,
               otherwise it uses a Gaussian
    fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
    obscuration: diameter in m to pass to au.primaryBeamArcsec
    geometricMean: if True, return only the mean beamsize and mean
             Gaussian-fitted beamsize; otherwise, return:
             minorAxis,majorAxis,geometricMean,geometricMeanFit (if the
             sampling is provided in both axes)
    widthMultiplier: the value by which to multiply the default values of
                     gwidth/jwidth
    minlevels: a list of values above which to perform 1D Gaussian fits
    truncate: if taper=0, sets whether to truncate the Airy at the first null
        if taper>0, sets the intensity level at which to truncate the Gaussian
    img: if is not None, then use a row or column from this image as the beam model
         if 'ticraDA', 'ticraDV' or 'ticraPM' is specified, it will automatically use 
         the TICRA models distributed with au
    row: the row of img to use as the starting beam profile model
    column: the column of img to use as the starting beam profile model
    stokes: 'XX','YY' which Stokes to use in the img
    excludeBand3: if True, do not allow the Band 3 models to be chosen below
                  the frequency specified in excludeBand3Below
    excludeBand3Below: frequency in GHz below which to not use Band 3 patterns

    Returns:
       If only the X-axis sampling is given:
          the FWHM of the restoring beam
          the FWHM of a Gaussian fit to the restoring beam
       If both X and Y-axis sampling is given:
        If geometricMean=True:
          the FWHM of the restoring beam
          the FWHM of a Gaussian fit to the restoring beam
        If geometricMean=False:
          the minor axis of the restoring beam
          the major axis of the restoring beam
          the geometric mean of the restoring beam computed using findFWHM()
          the geometric mean of the FWHM of a Gaussian fit to the restoring beam
    - Todd Hunter
    """
    if (pyfits.__version__ < '2.1.1'):
        print "Your pyfits version (%s) is old."
        print "Check that your PYTHONPATH is not overriding the version of pyfits distributed with casa."
        return
    if (fwhmfactor is not None):
        if (fwhmfactor < 1.02 or fwhmfactor > 1.22):
            print "Invalid fwhmfactor (1.02<fwhmfactor<1.22)"
            return
    if (img is not None):
        if (img.lower().find('ticra') == 0):
            ticraDir = os.getenv("CASAPATH").split()[0]+"/data/alma/responses/"
            ticraImage = ticraDir + "ALMA_0_DA__0_0_360_0_45_90_602_602_631.5_GHz_ticra2007_EFP.im.square.normalized"
            if (not os.path.exists(ticraImage)):
                ticraDir = os.path.dirname(__file__) + '/TicraImages/'
                if (os.path.exists(ticraDir) == False):
                    print "The Ticra model images (squared) are not present in the analysisUtils area nor CASA."
                    return
            img = pickTicraImage(frequency,img,ticraDir,excludeBand3,
                                 excludeBand3Below)
            if (img == None): return
            if (verbose):
                print "Using TICRA image: %s" % (os.path.basename(img))
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
    if (plotfile != ''): makeplot = True
    if (ySamplesPerBeam == None and ySamplingArcsec == None):
        return(griddedBeam().gjincBeamOneAxis(frequency, pixelsize, diameter,
                                      xSamplesPerBeam, xSamplingArcsec,
                                      makeplot, taper, obscuration=obscuration,
                                      widthMultiplier=widthMultiplier,
                                      useCasaJinc=useCasaJinc,
                                      testOption=testOption,minlevels=minlevels,
                                      truncate=truncate, img=img, row=row,
                                      column=column, stokes=stokes,
                                      plotfile=plotfile,fwhmfactor=fwhmfactor))
    else:
        return(griddedBeam().gjincBeamTwoAxes(frequency, pixelsize, diameter,
                                        xSamplesPerBeam, ySamplesPerBeam,
                                        xSamplingArcsec, ySamplingArcsec,
                                        makeplot, taper, geometricMean,
                                        obscuration=obscuration,
                                        widthMultiplier=widthMultiplier,
                                        useCasaJinc=useCasaJinc,
                                        testOption=testOption,
                                        minlevels=minlevels, truncate=truncate,
                                        img=img, row=row, column=column,
                                        stokes=stokes,plotfile=plotfile,
                                        fwhmfactor=fwhmfactor))

def sfBeamRatio(frequency, pixelsizeMax=10, diameter=12.0, xSamplesPerBeam=None,
                ySamplesPerBeam=None, xSamplingArcsecMax=None, 
                convsupport=-1,makeplot=False,m=0,taper=10,geometricMean=False,
                obscuration=0.75, cmult=1.0,coffset=0.0,xmult=1.0,alpha=1.0,
                testOption=False, minlevels=[0], truncate=False, img=None,
                row=None, column=None, stokes='both', datafile='sfBeamRatio'):
    """
    Computes the ratio of predicted beam sizes for a grid of pixel sizes and 
    sampling sizes.
    """
    f = open(datafile+'.'+stokes+'.txt','w')
    for pixelsize in np.linspace(2,pixelsizeMax,1+(pixelsizeMax-2)/2):
        for xSamplingArcsec in np.linspace(2,xSamplingArcsecMax,1+(xSamplingArcsecMax-2)/2):
            result = sfBeam(frequency,pixelsize,diameter,xSamplesPerBeam,ySamplesPerBeam,
                            xSamplingArcsec,xSamplingArcsec,convsupport,
                            makeplot,m,taper,geometricMean,obscuration,cmult,coffset,xmult,alpha,
                            testOption,minlevels,truncate,None,row,column,stokes)
            resultImg = sfBeam(frequency,pixelsize,diameter,xSamplesPerBeam,ySamplesPerBeam,
                               xSamplingArcsec,xSamplingArcsec,convsupport,
                               makeplot,m,taper,geometricMean,obscuration,cmult,coffset,xmult,alpha,
                               testOption,minlevels,truncate,img,row,column,stokes)
            f.write('%d %d %f %f\n' % (pixelsize,xSamplingArcsec,result[1]/resultImg[1], result[3]/resultImg[3]))
            f.flush()
    f.close()
    print "Results left in %s" % (datafile)

def pickPixelSize(frequency, convsupport=5, sfratio=0.5):
    """
    Returns the best pixel size to use with the specified convsupport parameter
    for the SF option of sdimaging.
    frequency: string with units, or a floating point number in GHz
    sfratio: the desired ratio between the FWHM of the SF and the telescope beam
    - Todd Hunter
    """
    # Freq convsupport  pixelsize  SF FWHM  SF FWZI
    # 100    3          10        22.29       60
    # 100    4          10        29.72       80
    # 100    4           5        14.86       40
    # pixelsize = (best SF FWHM) * 1.34589 / convsupport
    # pixelsize = (beam * sfratio) * 1.34589 / convsupport
    beam = primaryBeamArcsec(frequency=frequency, showEquation=False)
    pixelsize = beam * sfratio * 1.34589/float(convsupport)
    return(pixelsize)

def antennaEfficiencyPlot(frequencyRange, surfaceRms=25, R0=0.72, plotfile='',
                          fontsize=18):
    """
    frequencyRange: [f0,f1] where f0 and f1 are in GHz
    surfaceRms: value in microns
    R0: efficiency at low frequency
    """
    increment = (frequencyRange[1]-frequencyRange[0])*0.01
    f = []
    e = []
    for freq in np.arange(frequencyRange[0],frequencyRange[1],increment):
        f.append(freq)
        e.append(antennaEfficiency(freq, surfaceRms, R0))
    pb.clf()
    pb.plot(f,e,'k-')
    pb.xlabel('Frequency (GHz)',fontsize=fontsize)
    pb.ylabel('Efficiency',fontsize=fontsize)
    pb.ylim([0,np.ceil(R0*10)*0.1])
    if plotfile == '':
        plotfile = 'efficiency.png'
    pb.savefig(plotfile)
    
def antennaEfficiency(frequency, surfaceRms, R0=0.72):
    """
    Compute the antenna aperture efficiency according to the formula
    in the ALMA technical handbook (R0 * Ruze formula).
        Cycle 2: page 114; Cycle 3: page 118; Cycle 4: page 130
    frequency: GHz or Hz, or string with units
    surfaceRms: in microns
    R0: initial efficiency factor (other than Ruze)
    returns: telescope efficiency (from 0..1)
    -Todd Hunter
    """
    frequency = parseFrequencyArgumentToHz(frequency)
    efficiency= R0*np.exp(-16*(np.pi**2)*(surfaceRms*1e-4)**2*(frequency/c)**2)
    return(efficiency)

def janskyPerKelvin(frequency, beamsize=None, diameter=12, obscuration=0.75,
                    surfaceRms=25, fwhmfactor=None):
    """
    Computes the theoretical Jy/K for an ALMA single dish image based on its
    measured beamsize.
    frequency: GHz
    beamsize: arcsec, if not specified, then the theoretical beam will be used
    diameter: m
    obscuration: m
    surfaceRms: micron
    fwhmfactor: value to pass to primaryBeamArcsec
    """
    frequency = parseFrequencyArgumentToHz(frequency)
    efficiency = antennaEfficiency(frequency, surfaceRms)
    print "efficiency = ", efficiency
    area = np.pi*(diameter*50)**2*efficiency
#    print "effective area = ", area
    jyPerK = (2*k/area) * 1e23
#    print "Jy/K of raw antenna beam = ", jyPerK
    if (beamsize is not None):
        jyPerK *= (beamsize/primaryBeamArcsec(frequency=frequency,diameter=diameter,obscuration=obscuration,showEquation=False,fwhmfactor=fwhmfactor))**2
    return(jyPerK)
    
def sfBeamWeightVariation(frequency=None, pixelsize=None, diameter=12.0, samplesPerBeam=5.0,
           samplingArcsec=None, convsupport=-1, m=0, taper=10, 
           obscuration=0.75, cmult=1.0, coffset=0.0,xmult=1.0,alpha=1.0,testOption=False,
           minlevels=[0], truncate=False, img=None, row=None, column=None, stokes='XX',
           plotfile='', tpdata=None, spw=None, pixelsPerBeam=None, excludeBand3=True,
           excludeBand3Below=109.0, verbose=True, ylimits=[-3,30], ylimits2=[24,42]):
    """
    Makes a plot of the gridded beamsize and weight variation vs. the pixelsize chosen
    for the image to be created by sdimaging with the SF gridding function.
    pixelsize: None -> default = 0.5 to 15 by 0.5 arcsec
    tpdata: if not None, then run getTPSampling on this dataset to find samplingArcsec
            (the maximum value of the two axes)
    taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function as the antenna beam,
               otherwise it uses a Gaussian
    truncate: if taper=0, sets whether to truncate the Airy at first null
              if taper > 0, and not False, sets intensity level to truncate Gaussian
    img: if not none, then use a row or column from this image as the beam model
    row: the row of img to use as the starting beam profile model
    column: the column of img to use as the starting beam profile model
    stokes: 'XX','YY' which Stokes to use in the img
    pixelsPerBeam: default=None --> np.arange(3.8,13.21,0.2)
    excludeBand3: pass to pickTicraImage
    excludeBand3Below: pass to pickTicraImage
    -Todd Hunter
    """
    if (type(frequency) == str):
        frequency = parseFrequencyArgument(frequency) * 1e-9
    makeplot = False
    if (frequency == None and (tpdata == None or spw == None)):
        print "You must specify either frequency or (tpdata and spw)"
        return
    if (tpdata is not None):
        if (os.path.exists(tpdata) == False):
            print "Dataset not found: %s" % (tpdata)
            return
        xSampling, ySampling, maxsize = getTPSampling(tpdata)
        samplingArcsec = max(xSampling,ySampling)
        if (frequency == None):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(tpdata)
            frequency = mymsmd.meanfreq(int(spw))*1e-9
            mymsmd.close()
    beamfwhm = primaryBeamArcsec(frequency=frequency, showEquation=False, taper=taper)
    if (img is not None):
        if (img.lower().find('ticra') == 0):
            ticraDir = os.getenv("CASAPATH").split()[0]+"/data/alma/responses/"
            ticraImage = ticraDir + "ALMA_0_DA__0_0_360_0_45_90_602_602_631.5_GHz_ticra2007_EFP.im.square.normalized"
            if (not os.path.exists(ticraImage)):
                ticraDir = os.path.dirname(__file__) + '/TicraImages/'
                if (os.path.exists(ticraDir) == False):
                    print "The Ticra model images (squared) are not present in the analysisUtils area nor CASA."
                    return
            img = pickTicraImage(frequency,img,ticraDir,excludeBand3,
                                 excludeBand3Below)
            if (img == None): return
            if (verbose):
                print "Using TICRA image: %s" % (os.path.basename(img))
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
        myxaxis, myfunction, row, column, imgfreq = extractCutFromImage(img,row=row,column=column,stokes=stokes,interpolate=True)
        beamfwhm = getfwhm2(img)*imgfreq*1e-9/frequency
    if (samplingArcsec == None):
        samplingArcsec = beamfwhm / float(samplesPerBeam)
    if (pixelsize==None):
        if (pixelsPerBeam == None):
            pixelsPerBeam = np.arange(3.8,13.21,0.2)
        pixelsize = beamfwhm/pixelsPerBeam
    pixelsPerBeam = beamfwhm / pixelsize
    if (convsupport == -1):
        convsupports = [3,4,5,6]
    elif (type(convsupport) == list):
        convsupports = convsupport
    else:
        convsupports = [convsupport]
    pb.clf()
    col = ['k','b','r','g']
    pix10conv6ratio = None
    for convsupport in convsupports:
        ratios = []
        fwhms = []
        for p in pixelsize:
            ratio, fwhm = sfWeightVariation(frequency, p, diameter, samplesPerBeam,
                                            samplingArcsec, convsupport, makeplot, m, taper, 
                                            obscuration, cmult, coffset,xmult,alpha,testOption,
                                            minlevels, truncate, img, row, column, stokes)
            ratios.append(ratio)
            fwhms.append(fwhm)
        pb.subplot(211)
        ratios = np.array(ratios)*100
        pb.plot(pixelsPerBeam,ratios,'k-',color=col[convsupport-3])
        pb.subplot(212)
        pb.plot(pixelsPerBeam,fwhms,'k-',color=col[convsupport-3])
        if (convsupport == 6):
            mindiff = 1e10
            target = 10.0
            for i,p in enumerate(pixelsPerBeam):
                if (abs(p-target) < mindiff):
                    mindiff = abs(p-target)
                    index = i
            myfwhm = fwhms[index]
            pix10conv6ratio = myfwhm/beamfwhm
    desc = pb.subplot(211)
    pb.ylim(ylimits)
    pb.xlim([np.min(pixelsPerBeam), np.max(pixelsPerBeam)])
    pb.ylabel('Weight variation (%)')
    pb.title('%g GHz, beam=%.2f", sampling=%.2f", convsupport =     ' % (frequency, beamfwhm, samplingArcsec),size=12)
    if (tpdata is not None):
        if (spw == None):
            pb.text(0.1,1.10,'%s' % (os.path.basename(tpdata)),transform=desc.transAxes)
        else:
            pb.text(0.1,1.10,'%s, spw=%d' % (os.path.basename(tpdata),spw),transform=desc.transAxes)
    majorLocator = MultipleLocator(1)
    desc.xaxis.set_major_locator(majorLocator)
    for convsupport in convsupports:
        pb.text(0.90+0.03*(convsupport-3), 1.03, str(convsupport), color=col[convsupport-3], transform=desc.transAxes, size=12)
    desc = pb.subplot(212)
    beamgrowths = [1.1, 1.2, 1.3]
    for beamgrowth in beamgrowths:
        pb.text(np.mean([np.mean(pb.xlim()),np.max(pb.xlim())]), (beamgrowth+0.01)*beamfwhm, '%.1f * beam' % (beamgrowth))
        pb.plot(pb.xlim(), [beamgrowth*beamfwhm]*2,'k--')
    pb.ylabel('FWHM (arcsec)')
    pb.xlabel('Pixels per beam')
    pb.xlim([np.min(pixelsPerBeam), np.max(pixelsPerBeam)])
    pb.ylim(ylimits2)
    majorLocator = MultipleLocator(1)
    desc.xaxis.set_major_locator(majorLocator)
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            if (tpdata == None):
                plotfile = 'sfBeamWeightVariation.png'
            else:
                plotfile = tpdata + '.sfBeamWeightVariation.png'
        pb.savefig(plotfile) #, bbox_inches='tight')  # This cuts off line above title
        print "Plot left in %s" % (plotfile)
    return(pix10conv6ratio)
                      
def sfWeightVariation(frequency, pixelsize, diameter=12.0, samplesPerBeam=5.0,
           samplingArcsec=None, convsupport=-1, makeplot=False, m=0, taper=10, 
           obscuration=0.75,cmult=1.0,coffset=0.0,xmult=1.0,alpha=1.0,testOption=False,
           minlevels=[0], truncate=False, img=None, row=None, column=None, stokes='XX',
           plotfile=''):
    """
    Returns two numbers:
    1) the ratio of the standard deviation to the mean of the pixel weights
    predicted along one axis of an image that will be created by sdimaging using
    the specified parameters with the SF gridding function.
    2) the predicted FWHM of the gridded beam
    
    - Todd Hunter
    """
    return(griddedBeam().sfComb(frequency, pixelsize, diameter, samplesPerBeam,
                                samplingArcsec, convsupport, makeplot, m, taper, 
                                obscuration, cmult, coffset, xmult, alpha, testOption,
                                minlevels, truncate, img, row, column, stokes,
                                plotfile))

def gjincBeamWeightVariation(frequency=None, pixelsize=None, diameter=12.0, 
                             samplesPerBeam=5.0, samplingArcsec=None, 
                             useCasaJinc=False, taper=10, widthMultiplier=[],
                             obscuration=0.75, testOption=False,
                             minlevels=[0], truncate=False, img=None, row='auto',
                             column='auto', stokes='XX', plotfile='', 
                             tpdata=None, spw=None, pixelsPerBeam = None, excludeBand3=True,
                             excludeBand3Below=109.0, verbose=True, ylimits=[-3,30],
                             ylimits2=[24,42]
                             ):
    """
    Makes a plot of the gridded beamsize and weight variation vs. the pixelsize
    chosen for the image to be created by sdimaging with the GJINC gridding 
    function.
    widthMultiplier: a list of values to use for the widthMultiplier parameter 
                     of gjincBeam
    pixelsize: None -> default = 0.5 to 15 by 0.5 arcsec
    tpdata: if not None, then run getTPSampling on this dataset to find 
            samplingArcsec (i.e. the maximum value of the two axes)
    pixelsPerBeam: default=None --> np.arange(3.8,13.21,0.2)
    excludeBand3: pass to pickTicraImage
    excludeBand3Below: pass to pickTicraImage
    img: if not none, then use a row or column from this image as the beam model
         if 'ticraDA', 'ticraDV' or 'ticraPM' is specified, it will 
            automatically use the TICRA models distributed with au
    row: the row of img to use as the starting beam profile model
    column: the column of img to use as the starting beam profile model
        if row and column are both 'auto', then it will use the mean of the
        peak row and peak column, shifted so that their peaks align
    Returns:
    the ratio of image FWHM to the intrinsic beam FWHM at 10 pix per beam
    -Todd Hunter
    """
    if (type(frequency) == str):
        frequency = parseFrequencyArgument(frequency) * 1e-9
    makeplot = False
    if (frequency is None and (tpdata is None or spw is None)):
        print "You must specify either frequency or (tpdata and spw)"
        return
    if (tpdata is not None):
        if (os.path.exists(tpdata) == False):
            print "Dataset not found: %s" % (tpdata)
            return
        xSampling, ySampling, maxsize = getTPSampling(tpdata)
        samplingArcsec = max(xSampling,ySampling)
        if (frequency is None):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(tpdata)
            frequency = mymsmd.meanfreq(int(spw))*1e-9
            mymsmd.close()
    beamfwhm = primaryBeamArcsec(frequency=frequency, showEquation=False, taper=taper)
    if (img is not None):
        if (img.lower().find('ticra') == 0):
            ticraDir = os.getenv("CASAPATH").split()[0]+"/data/alma/responses/"
            ticraImage = ticraDir + "ALMA_0_DA__0_0_360_0_45_90_602_602_631.5_GHz_ticra2007_EFP.im.square.normalized"
            if (not os.path.exists(ticraImage)):
                ticraDir = os.path.dirname(__file__) + '/TicraImages/'
                if (os.path.exists(ticraDir) == False):
                    print "The Ticra model images (squared) are not present in the analysisUtils area nor CASA."
                    return
            img = pickTicraImage(frequency,img,ticraDir,excludeBand3,
                                 excludeBand3Below)
            if (img is None): return
            if (verbose):
                print "Using TICRA image: %s" % (os.path.basename(img))
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
        myxaxis, myfunction, row, column, imgfreq = extractCutFromImage(img,row=row,column=column,stokes=stokes,interpolate=True)
        beamfwhm = getfwhm2(img)*imgfreq*1e-9/frequency
    if (samplingArcsec is None):
        samplingArcsec = beamfwhm / float(samplesPerBeam)
    if (pixelsize==None):
        if (pixelsPerBeam is None):
            pixelsPerBeam = np.arange(3.8,13.21,0.2)
        pixelsize = beamfwhm/pixelsPerBeam
    pixelsPerBeam = beamfwhm / pixelsize
    if (widthMultiplier == []):
        widthMultipliers = [1, 1.5, 2, 2.5]
    elif (type(widthMultplier) == list):
        widthMultipliers = widthMultiplier
    else:
        widthMultipliers = [widthMultiplier]
    pb.clf()
    col = ['k','b','r','g']
    for i, widthMultiplier in enumerate(widthMultipliers):
        ratios = []
        fwhms = []
        for p in pixelsize:
            ratio, fwhm = \
                gjincWeightVariation(frequency, p, diameter, samplesPerBeam,
                                     samplingArcsec, widthMultiplier, makeplot,
                                     taper, obscuration, useCasaJinc,testOption,
                                     minlevels, truncate, img, row, column, 
                                     stokes)
            ratios.append(ratio)
            fwhms.append(fwhm)
        pb.subplot(211)
        ratios = np.array(ratios)*100
        pb.plot(pixelsPerBeam,ratios,'k-',color=col[i])
        pb.subplot(212)
        pb.plot(pixelsPerBeam,fwhms,'k-',color=col[i])
        if (i == len(widthMultipliers)-1):
            mindiff = 1e10
            target = 10.0
            for i,p in enumerate(pixelsPerBeam):
                if (abs(p-target) < mindiff):
                    mindiff = abs(p-target)
                    index = i
            myfwhm = fwhms[index]
            pix10conv6ratio = myfwhm/beamfwhm
    desc = pb.subplot(211)
    pb.ylim(ylimits)
    pb.xlim([np.min(pixelsPerBeam), np.max(pixelsPerBeam)])
    pb.ylabel('Weight variation (%)')
    pb.text(0.05,1.04,'%g GHz, beam=%.2f", sampling=%.2f", widthMultiplier =     ' % (frequency, beamfwhm, samplingArcsec),size=12,transform=desc.transAxes)
    if (tpdata is not None):
        if (spw is None):
            pb.text(0.1,1.10,'%s' % (os.path.basename(tpdata)),transform=desc.transAxes)
        else:
            pb.text(0.1,1.10,'%s, spw=%d' % (os.path.basename(tpdata),spw),transform=desc.transAxes)
    majorLocator = MultipleLocator(1)
    desc.xaxis.set_major_locator(majorLocator)
    for i,widthMultiplier in enumerate(widthMultipliers):
        pb.text(0.85+0.05*(i), 1.03, '%g'%(widthMultiplier), color=col[i], transform=desc.transAxes, size=12)
    desc = pb.subplot(212)
    beamgrowths = [1.1, 1.2, 1.3]
    for beamgrowth in beamgrowths:
        pb.text(np.mean([np.mean(pb.xlim()),np.max(pb.xlim())]), (beamgrowth+0.01)*beamfwhm, '%.1f * beam' % (beamgrowth))
        pb.plot(pb.xlim(), [beamgrowth*beamfwhm]*2,'k--')
    pb.ylabel('FWHM (arcsec)')
    pb.xlabel('Pixels per beam')
    pb.xlim([np.min(pixelsPerBeam), np.max(pixelsPerBeam)])
    pb.ylim(ylimits2)
    majorLocator = MultipleLocator(1)
    desc.xaxis.set_major_locator(majorLocator)
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            if (tpdata is None):
                plotfile = 'gjincBeamWeightVariation.png'
            else:
                plotfile = tpdata + '.gjincBeamWeightVariation.png'
        pb.savefig(plotfile) #, bbox_inches='tight')  # This cuts off line above title
        print "Plot left in %s" % (plotfile)
    return(pix10conv6ratio)
                      
def gjincWeightVariation(frequency,pixelsize, diameter=12.0, samplesPerBeam=5.0,
                         samplingArcsec=None, widthMultiplier=-1, 
                         makeplot=False, taper=10, obscuration=0.75,
                         useCasaJinc=False,testOption=False, minlevels=[0], 
                         truncate=False, img=None, row=None, column=None,
                         stokes='XX', plotfile=''):
    """
    Returns two numbers:
    1) the ratio of the standard deviation to the mean of the pixel weights
    predicted along one axis of an image that will be created by sdimaging using
    the specified parameters with the GJinc gridding function.
    2) the predicted FWHM of the gridded beam
    
    - Todd Hunter
    """
    return(griddedBeam().gjincComb(frequency, pixelsize, diameter, samplesPerBeam,
                                   samplingArcsec, widthMultiplier, makeplot, taper, 
                                   obscuration, useCasaJinc, testOption,
                                   minlevels, truncate, img, row, column, stokes,
                                   plotfile))

def setImageUnits(img, value='deg'):
    """
    Read a CASA image, and set the units of the first two axes using imhead put.
    img: name of a CASA image.  If a wildcard (*) is included, then process 
         all matching files.
    value: the value to which to normalize the peak
    -Todd Hunter
    """
    if (img.find('*') >= 0):
        images = glob.glob(img)
    else:
        images = [img]
    for img in images:    
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
        imhead(img, mode='put', hdkey='cunit1', hdvalue=value)
        imhead(img, mode='put', hdkey='cunit2', hdvalue=value)

def subtractGaussianFromImage(img, peak=None, x=None, y=None, major=None, 
                              minor=None, pa=None, fitresult=None, component=0,
                              outfile='difference.image', convolve=False,
                              outgaussian=''):
    """
    Subtract a 2D Gaussian from a CASA image and create a difference image.
    peak: peak intensity in image brightness units (set to None to use value at xpeak,ypeak)
    x: x pixel of the peak of the Gaussian (set to None to use the image peak), 
       or sexagesimal string for Right Ascension,
    y: y pixel of the peak of the Gaussian, or sexagesimal string for Declination
    major: FWHM of major axis in pixels, or string with arcsec units (e.g. '1.2arcsec')
    minor: FWHM minor axis in pixels, or string with arcsec units 
    pa: position angle of major axis in floating point degrees
    fitresult: alternative input from imfit dictionary
    component: which component to use from fitresult
    convolve: if True, then convolve specified size with the beam before subtracting
              (Not yet implemented)
    outgaussian: the name of the Gaussian image to create
    -Todd Hunter
    """
    if (os.path.exists(img) == False):
        print "Could not find image = ", img
        return
    if fitresult is not None:
        d = imfitparseDict(fitresult, component=component)
        x,y = findRADec(img, d['ra'] + ' ' + d['dec'])
        myresults = getFitsBeam(img) # ,omitBeam=True)
        arcsecPerPixel = abs(myresults[3])
        peak = d['peak']
        major = float(d['major'].split('arcsec')[0])/arcsecPerPixel
        minor = float(d['minor'].split('arcsec')[0])/arcsecPerPixel
        pa = float(d['pa'].split('deg')[0])
    else:
        if (type(x) == str and type(y) == str):
            x,y = findRADec(img, x+' '+y)
        if (type(major)==str and type(minor)==str):
            myresults = getFitsBeam(img) # ,omitBeam=True)
            arcsecPerPixel = abs(myresults[3])
            major = float(major.split('arcsec')[0])/arcsecPerPixel
            minor = float(minor.split('arcsec')[0])/arcsecPerPixel
        if (type(pa)==str):
            pa = float(pa.split('deg')[0])
    print "Calling makeGaussianForImage('%s', %f, %f, %f, %f, %f, %f, %s)" % (img, peak, x, y, major, minor, pa, outgaussian)
    gimg = makeGaussianForImage(img, peak, x, y, major, minor, pa, outgaussian)
    if (gimg is None): return
    removeImageIfPresent(outfile)
    print "Running immath(['%s','%s'], outfile='%s', expr='IM0-IM1')" % (img, gimg, outfile)
    immath([img,gimg], outfile=outfile, expr='IM0-IM1')
    print "Created new image = ", outfile

def addGaussianToFITSImage(fits, peak, x, y, major, minor, pa, overwrite=False, output=''):
    """
    Add a 2D Gaussian to a FITS image and create a sum image.
    fits:  name of FITS image
    overwrite: if True, then overwrite any existing CASA image with the same name
    output: name of output image (default = *.sum.img)
    See help au.addGaussianToImage for other parameters.
    -Todd Hunter
    """
    if (not os.path.exists(fits)):
        print "Could not find FITS file"
        return
    img = fits.replace('.fits','.img')
    if (not os.path.exists(img) or overwrite):
        try:
            importfits(fits, img, overwrite=overwrite)
        except:
            print "Could not remove existing image.  Do you have it open in the viewer?"
            return
    else:
        print "Not importing FITS image!  re-run with overwrite=True"
    if (output == ''):
        outfile = img.replace('.img','.sum.img')
    else:
        outfile = output.replace('.img','.sum.img')

    newimage = addGaussianToImage(img, peak, x, y, major, minor, pa, outfile)
    if (newimage is None): return
    if (output == ''):
        outfile = outfile.replace('.img','.fits')
    else:
        outfile = output
    if (not os.path.exists(img) or overwrite):
        exportfits(newimage, outfile, overwrite=overwrite)
        print "Wrote new image = ", outfile
    else:
        print "Not exporting new image!  re-run with overwrite=True"
    return(outfile)

def addGaussianToImage(img, peak, x, y, major, minor, pa, outfile='sum.image',
                       outgaussian=''):
    """
    Add a 2D Gaussian to a CASA image and create a sum image.
    peak: peak intensity in image brightness units (set to None for value at xpeak,ypeak)
    xpeak: x pixel of the peak of the Gaussian (set to None for image peak)
    ypeak: y pixel of the peak of the Gaussian
    major: FWHM of major axis in pixels (or a string with units: '3.4arcsec')
    minor: FWHM minor axis in pixels (or a string with units: '3.4arcsec')
    pa: position angle of major axis in degrees
    outfile: the name of the new (sum) image 
    outgaussian: the name of the Gaussian image to create
    -Todd Hunter
    """
    if (os.path.exists(img) == False):
        print "Could not find image = ", img
        return
    if (type(major)==str and type(minor)==str):
        myresults = getFitsBeam(img) # ,omitBeam=True)
        arcsecPerPixel = abs(myresults[3])
        major = float(major.split('arcsec')[0])/arcsecPerPixel
        minor = float(minor.split('arcsec')[0])/arcsecPerPixel
    if outgaussian == '':
        newimage = outfile+'.gaussian'
    else:
        newimage = outgaussian
    gimg = makeGaussianForImage(img, peak, x, y, major, minor, pa, newimage)
    if (gimg is None): return
    if (removeImageIfPresent(outfile) is None): return
    print "Running immath(['%s','%s'], outfile='%s', expr='IM0+IM1')" % (img,gimg,outfile)
    immath([img,gimg], outfile=outfile, expr='IM0+IM1')
    print "Created new image = ", outfile
    return(outfile)

def imageClipAndRemove(img, threshold, outfile, overwrite=True):
    """
    Clip an image above a threshold, then remove the clipped image from
    the original.
    threshold: intensity value at which to clip
    outfile: name of new image to produce
       Will also produce (overwrite) img+'.clipped' along the way.
   -Todd Hunter
    """
    if (outfile == ''):
        outfile = img + '.clippedAndRemoved'
    removeImageIfPresent(img+'.clipped')
    imageClip(img, threshold, outfile=img+'.clipped')
    imhistory(img, mode='append', message="au.imageClip(img=%s, threshold=%s, outfile=%s)"%(img, threshold,img+'.clipped'))
    if overwrite:
        removeImageIfPresent(outfile)
    immath([img, img+'.clipped'], mode='evalexpr', expr='IM0-IM1', outfile=outfile)

def imageClip(img, threshold, outfile=''):
    """
    Uses immath to clip an image at a specified intensity level.
    outfile: default = img+'.clipped'
    -Todd Hunter
    """
    if (outfile == ''):
        outfile = img + '.clipped'
    immath(img, mode='evalexpr', expr='iif(IM0 < %f, IM0, %f)' % (threshold,threshold),
           outfile=outfile)

def removeImageIfPresent(newimage, verbose=False):
    """
    If the specified directory or file is present, then remove it.
    """
    if (os.path.exists(newimage)):
        if (os.path.isdir(newimage)):
            try:
                if verbose: print "shutil.rmtree(%s)" % (newimage)
                shutil.rmtree(newimage)
            except:
                print "Could not remove existing CASA image.  Do you have it open in the viewer?"
                cmd = "/usr/sbin/lsof +D %s" % (newimage)
                print "Running " + cmd
                os.system(cmd)
                print "You should quit or kill the offending process (if any)."
                return None
        else:
            try:
                if verbose: print "os.remove(%s)" % (newimage)
                os.remove(newimage)
            except:
                print "Could not remove existing FITS image.  Do you have it open in the viewer?"
                cmd = "/usr/sbin/lsof +D %s" % (newimage)
                print "Running " + cmd
                os.system(cmd)
                print "You should quit or kill the offending process (if any)."
                return None
    elif verbose:
        print "%s does not yet exist." % (newimage)
    return 0

def makeGaussiansForImage(img, fitresult, newimage='', 
                          makeSingleImageOnly=False, verbose=True, 
                          offsetComponentNumber=0, debug=False):
    """
    Take a CASA image as a template, and build an image with a multiple Gaussian
    components at the specified locations and widths, read from an imfit results
    dictionary.
    fitresult: an imfit results dictionary
    newimage: name of output image (default = *.gaussian)
    makeSingleImageOnly: if True, only produce 1 image w/sum of all components 
         otherwise, also produce individual images called: <newimage>.gaussianN
    Returns: the name of the image created
    -Todd Hunter
    """
    if (os.path.exists(img) == False):
        print "Could not find image = ", img
        return
    if (newimage == ''):
        newimage = img + '.gaussian'
    if (removeImageIfPresent(newimage) is None): return
    os.system('cp -r %s %s' % (img,newimage))
    myresults = getFitsBeam(img) # ,omitBeam=True)
    arcsecPerPixel = abs(myresults[3])
    myia = createCasaTool(iatool)
    myia.open(newimage)
    pixels = myia.getregion()
    myia.close()
    if debug:
        oldmax = np.max(pixels)
    pixels *= 0
    xpixels = np.shape(pixels)[0]
    ypixels = np.shape(pixels)[1]
    if not makeSingleImageOnly:
        myia2 = createCasaTool(iatool)
    for c in range(fitresult['results']['nelements']):
        if not makeSingleImageOnly:
            newimage2 = newimage + '.gaussian%02d' % (c+offsetComponentNumber)
            if (removeImageIfPresent(newimage2) is None): return
            os.system('cp -r %s %s' % (img,newimage2))
            myia2.open(newimage2)
        mydict = fitresult['results']['component%d'%c]
        xpeak,ypeak = findRADec(img,[mydict['shape']['direction']['m0']['value'],
                                     mydict['shape']['direction']['m1']['value']], verbose=verbose)
        major = mydict['shape']['majoraxis']['value'] # assume arcsec
        minor = mydict['shape']['minoraxis']['value'] # assume arcsec
        positionAngle = mydict['shape']['positionangle']['value'] # assume deg
        pk = mydict['peak']['value']
        result = build2DGaussian(pk, xpeak, ypeak,
                                 major/arcsecPerPixel, minor/arcsecPerPixel, 
                                 positionAngle, xpixels, ypixels, pixels)
        if c == 0:
            if verbose:
                print "Placing component %d: %.6fJy at %.1f,%.1f"%(c+offsetComponentNumber,pk,xpeak,ypeak)
            newpixels = result
        else:
            if verbose:
                print "Summing component %d: %.6fJy at %.1f,%.1f"%(c+offsetComponentNumber,pk,xpeak,ypeak)
            newpixels += result
        if not makeSingleImageOnly:
            myia2.putregion(result)   
            myia2.close()
    if fitresult['results']['nelements'] > 0:
        if debug: 
            print "running putregion: max = %f, oldmax=%f" % (np.max(newpixels), oldmax)
        myia.open(newimage)
        myia.putregion(newpixels)
        myia.close()
    elif debug:
        print "Not running putregion"
    if verbose:
        print "New image created = ", newimage
    return(newimage)

def makeGaussianForImage(img, peak, xpeak, ypeak, major, minor, pa, newimage='',
                         verbose=True, peak2=None, xpeak2=None, ypeak2=None, 
                         major2=None, minor2=None, pa2=None):
    """
    Take a CASA image as a template, and build an image with a single Gaussian
    component at the specified location and width. See also makeGaussiansForImage to
    read multiple Gaussians from an imfit-returned dictionary.
    peak: peak intensity in image brightness units (set to None for value at xpeak,ypeak)
    xpeak: x pixel of the peak of the Gaussian (set to None for image peak)
    ypeak: y pixel of the peak of the Gaussian
      if xpeak and ypeak are RA/Dec strings, then use findRADec to convert to pixels
    major: FWHM of major axis in pixels (or a string with units: '3.4arcsec')
    minor: FWHM minor axis in pixels (or a string with units: '3.4arcsec')
    pa: position angle of major axis in degrees
    newimage: name of output image (default = *.gaussian)
    peak2, etc: parameters of optional second Gaussian to add
    Returns: the name of the image created
    -Todd Hunter
    """
    if (os.path.exists(img) == False):
        print "Could not find image = ", img
        return
    if (type(major)==str and type(minor)==str):
        myresults = getFitsBeam(img) # ,omitBeam=True)
        arcsecPerPixel = abs(myresults[3])
        major = float(major.split('arcsec')[0])/arcsecPerPixel
        minor = float(minor.split('arcsec')[0])/arcsecPerPixel
    if (newimage == ''):
        newimage = img + '.gaussian'
    if (removeImageIfPresent(newimage, verbose) is None): return
    os.system('cp -r %s %s' % (img,newimage))
    print "imagePeak = ", imagePeak(img)
    myia = createCasaTool(iatool)
    myia.open(newimage)
    pixels = myia.getregion() * 0
    xpixels = np.shape(pixels)[0]
    ypixels = np.shape(pixels)[1]
    if type(xpeak) == str and type(ypeak) == str:
        xpeak, ypeak = findRADec(img, ','.join([xpeak, ypeak]))
        if verbose:
            print "peak is at %f, %f" % (xpeak, ypeak)
    if (xpeak is None):
        xpeak, ypeak = np.unravel_index(np.argmax(pixels), np.shape(pixels))
        print "Peak pixel found at %d,%d" % (xpeak,ypeak)
    if (peak is None):
        peak = pixels[xpeak][ypeak]
        print "Using peak intensity found at %d,%d = %f" % (xpeak,ypeak,peak)
    newpixels = build2DGaussian(peak, xpeak, ypeak, major, minor, pa,
                                xpixels, ypixels, pixels)
    if verbose:
        print "peak(newpixels) = ", np.max(newpixels)
    if peak2 is not None:
        if type(xpeak2) == str and type(ypeak2) == str:
            xpeak2, ypeak2 = findRADec(img, ','.join([xpeak2, ypeak2]))
            if verbose:
                print "peak2 is at %f, %f" % (xpeak2, ypeak2)
        if (type(major2)==str and type(minor2)==str):
            major2 = float(major2.split('arcsec')[0])/arcsecPerPixel
            minor2 = float(minor2.split('arcsec')[0])/arcsecPerPixel
        newpixels += build2DGaussian(peak2, xpeak2, ypeak2, major2, minor2, pa2,
                                     xpixels, ypixels, pixels)
    myia.putregion(pixels=newpixels)
    myia.close()
    if verbose:
        print "New image created = ", newimage
    return(newimage)

def build2DGaussian(peak, xpeak, ypeak, major, minor, pa, xpixels, ypixels, 
                    pixels):
    """
    Builds a 2D array of pixels containing a 2D Gaussian component.
    peak: peak intensity in image brightness units
    xpeak: x pixel of the peak of the Gaussian
    ypeak: y pixel of the peak of the Gaussian
    major: FWHM of major axis in pixels
    minor: FWHM of minor axis in pixels
    pa: position angle of major axis in degrees
    xpixels: number of pixels in the x axis of the image
    ypixels: number of pixels in the y axis of the image
    pixels: a dummy 2D array of image pixel values
    -Todd Hunter
    """
    par = np.radians(90-pa)
    majorPixels = major
    minorPixels = minor
    major /= (8*np.log(2))**0.5
    minor /= (8*np.log(2))**0.5
    a = np.cos(par)**2/(2*major**2) + np.sin(par)**2/(2*minor**2)
    b = -np.sin(2*par)/(4*major**2) + np.sin(2*par)/(4*minor**2)
    c = np.sin(par)**2/(2*major**2) + np.cos(par)**2/(2*minor**2)
    mypixels = pixels*0
    # to speed up calc, only need to fill in the square out to say, +-4FWHM of major
    radii = 4
    x0 = int(xpeak - radii*majorPixels)
    x1 = int(np.ceil(xpeak + radii*majorPixels))
    if (x0 < 0):
        x0 = 0
    if (x1 > xpixels):
        x1 = xpixels
    y0 = int(ypeak - radii*majorPixels)
    y1 = int(np.ceil(ypeak + radii*majorPixels))
    if (y0 < 0):
        y0 = 0
    if (y1 > ypixels):
        y1 = ypixels
#    print "Computing Gaussian for %d out of %d pixels" % ((x1-x0)**2, xpixels*ypixels)
    for x in range(x0,x1):
        for y in range(y0,y1):
            mypixels[x][y] = peak*np.exp(-(a*(xpeak-x)**2 + 2*b*(ypeak-y)*(xpeak-x) + c*(ypeak-y)**2))
    return mypixels

def peakJanskyPerPixel(img):
    """
    Computes the peak Jy/pixel of an image that has units of Jy/beam, for use as the 
    inbright parameter of simobserve.
    -Todd Hunter
    """
    bunit = imhead(img,mode='get',hdkey='bunit')
    if (bunit.lower() != 'jy/beam'):
        print "Image is in %s, not Jy/beam" % (bunit)
        return
    peakJyPerBeam = imagePeak(img)
    jyPerPixel = peakJyPerBeam/pixelsPerBeam(img)
    return jyPerPixel

def pixelsPerBeamOld(img):
    """
    Determines the number of pixel areas per beam area of an image using
    getFitsBeam.  See also pixelsPerBeam() for a version that uses the ia tool and
    is much faster.
    -Todd Hunter
    """
    result = getFitsBeam(img)
    solidAngle = beamSolidAngle(result[0],result[1])
    pixelsPerBeam = solidAngle*ARCSEC_PER_RAD**2/(abs(result[3]*result[4]))
    return(pixelsPerBeam)

def pixelsPerBeam(img):
    """
    Determines the number of pixel areas per beam area of an image using
    the ia tool.
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    result = myia.commonbeam()
    mycs = myia.coordsys()
    inc = mycs.increment()['numeric']
    mycs.done()
    myia.close()
    major = qa.convert(result['major'], 'arcsec')['value']
    minor = qa.convert(result['minor'], 'arcsec')['value']
    solidAngle = beamSolidAngle(major, minor)
    pixelArea = abs(inc[0]*inc[1])
    pixelsPerBeam = solidAngle/pixelArea
    return(pixelsPerBeam)

def beamSolidAngle(major, minor=None):
    """
    Converts a Gaussian beam FWHM from arcsec into equivalent solid angle using
    the formula: pi*(theta**2)/(4ln(2)).  Returns: solid angle in steradian.
    -Todd Hunter
    """
    if (minor is None): minor = major
    solidAngle = np.radians(major/3600.)*np.radians(minor/3600.)*np.pi/(4*np.log(2))
    return(solidAngle)

def flattenMaskOld(mask, outfile='', overwrite=True):
    """
    Takes a multi-channel CASA image mask and propagates all pixels to a 
    new single plane image mask. 
    This version reads the whole cube at once, so will fail on large cubes.
    See flattenMask.
    outfile: default name = <mask>.flattened
    - Todd Hunter
    """
    if (not os.path.exists(mask)):
        print "Could not find mask image."
        return
    if (outfile == ''):
        outfile = mask + '.flattened'
    imsubimage(mask, outfile=outfile, chans='0', overwrite=overwrite)
    myia = createCasaTool(iatool)
    myia.open(mask)
    oldmask = myia.getregion()
    axis = findSpectralAxis(myia)
    myia.close()
    myia.open(outfile)
    newmask = propagateMaskToAllChannels(oldmask, axis=axis)
    myia.putregion(pixels=newmask)
    myia.close()
    return(outfile)

def flattenMask(mask, outfile='', overwrite=True, chanchunk=4000):
    """
    Takes a multi-channel CASA image mask and propagates all pixels to a 
    new single plane image mask. 
    outfile: default name = <mask>.flattened
    chanchunk: max number of channels to process at once
      Note: there is a bug report that using chanchunk<nchan misses some 
            regions, so I have set it to a large value by default. -2017-02-17
    - Todd Hunter
    """
    if (not os.path.exists(mask)):
        print "Could not find mask image."
        return
    if (outfile == ''):
        outfile = mask + '.flattened'
    myia = createCasaTool(iatool)
    myia.open(mask)
    axis = findSpectralAxis(myia)
    shape = myia.shape()
    nchan = shape[axis]
    imsubimage(mask, outfile=outfile, chans='0', overwrite=overwrite)
    if (nchan <= chanchunk): 
        # Do it all in one go.
        oldmask = myia.getregion()
        myia.close()
        myia.open(outfile)
        newmask = propagateMaskToAllChannels(oldmask, axis=axis)
        myia.putregion(pixels=newmask)
        myia.close()
    else:
        # Accumulate masks, one-chunk-at-a-time, store in last previously
        # read pixel, and overlap read chunks by one pixel.
        myrg = createCasaTool(rgtool)
        for start in range(0,nchan,chanchunk-1): # 0, 19, 38
            stop = start+chanchunk-1             # 19, 38, 57 etc.
            if (stop >= nchan):
                stop = nchan-1
            myregion = myrg.box(blc=[0,0,0,start], trc=[shape[0],shape[1],0,stop])
            oldmask = myia.getregion(region=myregion)
            if (start > 0):
                print "Processing channels %d - %d" % (start+1, stop)
                # stuff previous results into first channel, which was already
                # processed
                oldmask[:,:,0] = newmask
            else:
                print "Processing channels %d - %d" % (start, stop)
            newmask = propagateMaskToAllChannels(oldmask, axis=axis)
        myia.close()
        myrg.done()
        myia.open(outfile)
        myia.putregion(pixels=newmask)
        myia.close()
    return(outfile)

def findOffsetAxis(img, name='Offset', returnLength=False):
    """
    Finds the Offset axis number of an impv image tool instance, or
    an image. Generally it is zero.
    if returnLength = True, then return number of pixels along it, instead.
    -Todd Hunter
    """
    if (type(img) == str):
        myia = createCasaTool(iatool)
        myia.open(img)
    else:
        myia = img
    mycs = myia.coordsys()
    if name not in mycs.names():
        if name.lower() == 'offset' or name.lower() == 'right ascension':
            iax = 0
        else:
            iax = 1
        print "ERROR: can't find %s axis.  Assuming it is %d." % (name,iax)
    else:
        iax = mycs.findaxisbyname(name)
    mycs.done()
    if returnLength:
        iax = myia.shape()[iax]
    if (type(img) == str):
        myia.close()
    return iax
    
def findSpectralAxis(img, name='spectral', returnLength=False):
    """
    Finds the spectral axis number of an image tool instance, or
    an image.
    """
    if (type(img) == str):
        myia = createCasaTool(iatool)
        myia.open(img)
    else:
        myia = img
    mycs = myia.coordsys()
    try:
        iax = mycs.findaxisbyname(name)
    except:
        if len(myia.shape()) > 3:
            print "ERROR: can't find spectral axis.  Assuming it is 3."
            iax = 3
        elif len(myia.shape()) > 2:
            print "ERROR: can't find spectral axis.  Assuming it is 2."
            iax = 2
        elif len(myia.shape()) == 2:
            print "No spectral axis found"
            iax = -1
    mycs.done()
    if returnLength:
        iax = myia.shape()[iax]
    if (type(img) == str):
        myia.close()
    return iax

def findStokesAxis(img):
    """
    Finds the spectral axis number of an image tool instance, or
    an image.
    """
    if (type(img) == str):
        myia = createCasaTool(iatool)
        myia.open(img)
    else:
        myia = img
    mycs = myia.coordsys()
    try:
        iax = mycs.findaxisbyname("stokes")
    except:
        print "ERROR: can't find stokes axis.  Assuming it is 2."
        iax = 2
    mycs.done()
    if (type(img) == str):
        myia.close()
    return iax

def countUnmaskedPixels(img, useImstat=True):
    """
    Returns number of unmasked pixels in an image, i.e. where the internal mask is True.
    Todd Hunter
    """
    if useImstat:
        return imstat(img)['npts']
    else:
        myia = createCasaTool(iatool)
        myia.open(img)
        maskdata = myia.getregion(getmask=True)
        myia.close()
        idx = np.where(maskdata==0)[0]
        maskedPixels = len(idx)
        pixels = np.prod(np.shape(maskdata))
        return pixels-maskedPixels

def countMaskedPixels(img):
    """
    The mask internal to an image will have a value of False where masked, and True where not masked.
    To count non-zero pixels in a clean 1/0 mask, use au.nonzeroPixels.
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    maskdata = myia.getregion(getmask=True)
    myia.close()
    idx = np.where(maskdata==0)[0]
    maskedPixels = len(idx)
    pixels = np.prod(np.shape(maskdata))
    print "%d/%d pixels (%f%%) are masked" % (maskedPixels,pixels,100.*maskedPixels/pixels)
    return maskedPixels

def maskChannel(img, channel, belowValue=None, setToZero=False, maskValue=True):
    """
    Mask a channel or range of channels in a CASA image cube.
    -Todd Hunter
    channel: integer or integer list or comma-delimited string, or a twiddle
             delimited range; or semicolon-delimited lists thereof
        i.e.    4      [4,5,6]   '4,5,6'   '4~6'   '4~6;8~10;15'
    belowValue: if specified, only mask pixels below this value
    setZero: if True, then also set the value of the pixel to zero
        i.e.    4      [4,5,6]   '4,5,6'   '4~6'   '4~6;8~10;15'
    maskValue: value to set the mask to (use False for images, True for clean masks)
    """
    if (not os.path.exists(img)):
        print "Image not found."
        return
    if (type(channel) == str):
        channels = channel.split(';')
        channelLists = []
        for channel in channels:
            if channel.find('~') > 0:
                channelList = range(int(channel.split('~')[0]), int(channel.split('~')[1])+1)
            else:
                channelList = str(channel).split(',')
            channelLists.append(channelList)
    elif (type(channel) != list):
        channelList = [channel]
        channelLists = [channelList]
    else:
        channelList = channel
        channelLists = [channelList]
    shape = imhead(img, mode='get', hdkey='shape')
    myrg = createCasaTool(rgtool)
    myia = createCasaTool(iatool)
    myia.open(img)
    for channelList in channelLists:
        for channel in channelList:
            myregion = myrg.box(blc=[0,0,0,channel], trc=[shape[0],shape[1],0,channel])
            pixels = myia.getregion(region=myregion)
            mask = myia.getregion(region=myregion, getmask=True)
            if belowValue is None:
                print "Masking all pixels in channel ", channel
                mask[:,:,:,0] = maskValue
                if setToZero:
                    pixels[:,:,:,0] = 0.0
            else:
                idx = np.where(pixels < belowValue)
                print "Masking %d pixels in channel %d that are < %f" % (np.shape(idx)[1], channel, belowValue)
                print "shape(idx)=%s, shape(idx[0])=%s, idx=" % (np.shape(idx), np.shape(idx[0])), idx
                # shape(idx) should be (pixelspec,npixels)= (4,N)
                mask[idx] = maskValue
                if setToZero:
                    pixels[idx] = 0.0
            myia.putregion(pixels=pixels, pixelmask=mask, region=myregion)
    myia.close()
    myrg.done()

def maskChannelOld(img, channel):
    """
    Mask a channel or range of channels in a CASA image cube.
    This version reads the whole cube at once, so will fail on large cubes.
    -Todd Hunter
    channel: integer or integer list or comma-delimited string, or a twiddle
             delimited range; or semicolon-delimited lists thereof
        i.e.    4      [4,5,6]   '4,5,6'   '4~6'   '4~6;8~10;15'
    """
    if (not os.path.exists(img)):
        print "Image not found."
        return
    myia = createCasaTool(iatool)
    myia.open(img)
    pixels = myia.getregion()
    mask = myia.getregion(getmask=True)
    if (type(channel) == str):
        channels = channel.split(';')
        channelLists = []
        for channel in channels:
            if channel.find('~') > 0:
                channelList = range(int(channel.split('~')[0]), int(channel.split('~')[1])+1)
            else:
                channelList = str(channel).split(',')
            channelLists.append(channelList)
    elif (type(channel) != list):
        channelList = [channel]
        channelLists = [channelList]
    else:
        channelList = channel
        channelLists = [channelList]
    for channelList in channelLists:
        for channel in channelList:
            print "Masking channel ", channel
            mask[:,:,:,int(channel)] = True
            pixels[:,:,:,int(channel)] = 0.0
    myia.putregion(pixels=pixels, pixelmask=mask)
    myia.close()

def propagateMaskToAllChannels(mask, axis=3):
    """
    Takes a spectral mask array, and propagates every masked spatial pixel in
    any channel to a new 2D mask.
    -Todd Hunter
    """
    if (type(mask) == str):
        print "The mask must be an array.  Use au.flattenMask to operate on a cube."
        return
    newmask = np.sum(mask,axis=axis)
    newmask[np.where(newmask>0)] = 1
    return(newmask)

def imageStokes(img):
    """
    Reads the Stokes values of an image
    """
    axis = findStokesAxis(img)
    stokes = imhead(img, mode='get', hdkey='crval'+str(axis+1))
    return stokes

def imagePeaks(images, pixelRadius=None, returnPosition=None, applymask=False,
               sort=False, verbose=True):
    """
    Runs imagePeak on a list of images.  Requires to be run from inside CASA since
    it uses the imhead task.
    -Todd Hunter
    Inputs:
    images: a list of strings, or a comma-delimited string, or a single string
            with the wildcard character (*)
    pixelRadius: limit the region searched to a box of this radius (in pixels)
    returnPosition: None, 'pixel', 'radec', 'radec_hms', 'arcsec', 'mas'
          the latter two are relative to the reference pixel
          'radec' means colon-delimited
    applymask: if True, then also read the mask associated with the image and
          ignore pixels where the mask is set to False.
    sort: if True, then sort in order of increasing brightness
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    images = np.array(images)
    if sort:
        peaks = []
        for img in images:
            peaks.append(imagePeak(img, pixelRadius, returnPosition, applymask))
        idx = np.argsort(peaks)
    else:
        idx = np.array(range(len(images)))
    peaks = []
    positions = []
    for img in images[idx]:
        peak = imagePeak(img, pixelRadius, returnPosition, applymask)
        peaks.append(peak)
        if (returnPosition is not None):
            if (returnPosition.find('radec')>=0):
                peak, position = peak
                positions.append(position)
                if verbose:
                    print "%s:  %f  %s" % (img, peak, position)
            else:
                peak, [x, y] = peak
                positions.append([x,y])
                if verbose:
                    print "%s:  %f  %+.3f %+.3f" % (img, peak, x, y)
        else:
            if verbose:
                print "%s:  %f" % (img, peak)
    if (returnPosition is not None):
        return peaks, positions
    else:
        return peaks

def imageHistogram(img, region='', applymask=False, maskzeros=False, 
                   mask='', bins=20, plotfile='', xlim=[0,0], 
                   sigmaimage='', pbimage='', pblevel=0.5, 
                   markzero=True, markNegativeSigma=True,
                   markSigma=[1.0], xunits='mJy', debug=False):
    """
    Plot a histogram of pixels of a CASA 2D image. 
    img: the CASA image to read pixel values from
    region: the region of img to use
    applymask: if True, read the mask inside img and apply it
    maskzeros: if True, then igore zero values in img
    mask: a CASA mask to read and apply to img
    bins: number of bins in the histogram
    plotfile: png to produce
    xlim: the xlimits to use on the histogram plot ([0,0]==automatic,
           which will extend to +-(0.5+max(markSigma))
    sigmaimage: the image from which to compute the std. deviation (outside
                the mask of the mask image and above the pblevel) for drawing 
                the sigma vertical dashed lines
    pbimage: image from which to read the pb response to apply to sigmaimage
    pblevel: value above which to use in the pbimage
    markzero: if True, draw a solid vertical line at x=0
    markNegativeSigma: if True, draw dashed verticle lines at -markSigma
    markSigma: multiplicative values of sigma to draw as vertical dashed lines
    xunits: if 'mJy', scale pixels by 1000, otherwise use the raw values
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    mymask = myia.getregion(region=region, getmask=True)
    pixels = myia.getregion()
    myia.close()
    if applymask:
        pixels = pixels[np.where(mymask==True)]
    if maskzeros:
        pixels = pixels[np.where(pixels != 0)]
    autoMode = False
    if (mask != ''):
        if (mask == 'auto'):
            mask = img.replace('.residual','.mask')
        myia.open(mask)
        mymask = myia.getregion(region=region)
        myia.close()
        pixels = pixels[np.where(mymask>0.5)]
        if (sigmaimage != ''):
            if (sigmaimage == 'auto'):
                sigmaimage = img.replace('.residual','.image')
            myia.open(sigmaimage)
            sigmapixels = myia.getregion(region=region) 
            if debug:
                print "%s: has %d pixels" % (os.path.basename(img),len(sigmapixels.flatten()))
            myia.close()
            if (pbimage != ''):
                if (pbimage == 'auto'):
                    pbimage = img.replace('.residual','.pb').replace('.residual','.flux')
                myia.open(pbimage)
                pbpixels = myia.getregion(region=region) 
                myia.close()
                if debug:
                    print "%s: has %d pixels" % (os.path.basename(pbimage),len(pbpixels.flatten()))
                    print "%s: computing stdev outside mask and above pb=%f" % (os.path.basename(img),pblevel)
                    print "There are %d pixels outside mask" % (len(sigmapixels[np.where(mymask<0.5)].flatten()))
                    print "There are %d pixels above pblevel" % (len(sigmapixels[np.where(pbpixels>pblevel)].flatten()))
                sigmapixels = sigmapixels[np.where((mymask<0.5)*(pbpixels>pblevel))]
            else:
                if debug:
                    print "computing stdev outside mask"
                sigmapixels = sigmapixels[np.where(mymask<0.5)]
            sigmapixels = sigmapixels.flatten()
            if (len(sigmapixels) > 2):
                if debug:
                    print "%s: computing stdev in %d pixels" % (os.path.basename(img),len(sigmapixels))
                mystd = np.std(sigmapixels)
            else:
                mystd = 0
            print "mystd = ", mystd
    if (xunits.lower().count('mjy') > 0):
        pixels = pixels.flatten() * 1000
        mystd *= 1000
    mymin = np.min(pixels)
    mymax = np.max(pixels)
    bins = np.linspace(mymin,mymax,bins)
    pb.clf()
    nr = pb.hist(pixels, bins=bins)
    if (mask != ''):
        pb.ylabel('Number of pixels (out of %d within the mask)'%len(pixels))
    else:
        pb.ylabel('Number of pixels (out of %d)'%len(pixels))
    pb.xlabel('Intensity (mJy/beam)')
    pb.title(os.path.basename(img), size=12)
    if (xlim != [0,0]):
        pb.xlim(xlim)
    else:
        initialXlim = pb.xlim()
        # widen the limit to +-2.5 sigma if necessary
        xmin = np.min([-(np.max(markSigma)+0.5)*mystd,initialXlim[0]])
        xmax = np.max([(np.max(markSigma)+0.5)*mystd, initialXlim[1]])
        if (abs(xmax)>abs(xmin)):
            xmin = -abs(xmax)
        elif (abs(xmin)>abs(xmax)):
            xmax = abs(xmin)
        pb.xlim([xmin, xmax])
    xmin,xmax = pb.xlim()
    if (sigmaimage != '' and mystd > 0):
        for mS in markSigma:
            pb.plot([mS*mystd,mS*mystd],pb.ylim(),'k--')
            if (mS*mystd > xmin and mS*mystd < xmax):
                pb.text(mS*mystd, pb.ylim()[1], '+%.0f$\sigma$ in image'%(mS), 
                        ha='left',rotation='vertical',va='top')
        if markNegativeSigma:
            for mS in markSigma:
                pb.plot([-mS*mystd,-mS*mystd],pb.ylim(),'k--')
                if (-mS*mystd > xmin and -mS*mystd < xmax):
                    pb.text(-mS*mystd, pb.ylim()[1], '-%.0f$\sigma$ in image'%(mS), 
                             ha='left',rotation='vertical',va='top')
    if markzero:
        pb.plot([0,0],pb.ylim(),'k-')
    pb.draw()
    if (plotfile != ''):
        if (plotfile==True):
            plotfile = img + '.histogram.png'
        pb.savefig(plotfile)
        print "plot saved in ", plotfile
    return plotfile, pb.xlim()
        
def nonzeroPixels(img, applymask=True, returnPositiveNegativeCounts=False):
    """
    Counts the number of pixels with non-zero values.
    Should *not* be run on a large cube!  Will run out of memory.
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    myia = createCasaTool(iatool)
    myia.open(img)
    pixels = myia.getregion()
    if (applymask):
        mask = myia.getregion(getmask=True)
        pixels[np.where(mask==False)] = 0
    myia.close()
    npixels = len(np.where(pixels < 0)[0].flatten())
    ppixels = len(np.where(pixels > 0)[0].flatten())
    if returnPositiveNegativeCounts:
        return ppixels, npixels
    else:
        return ppixels+npixels

def countZeroPixels(img, applymask=False):
    """
    Counts the number of pixels of value equal to 0.
    Should *not* be run on a large cube!  Will run out of memory.
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    myia = createCasaTool(iatool)
    myia.open(img)
    pixels = myia.getregion()
    if (applymask):
        mask = myia.getregion(getmask=True)
        idx = np.where(mask==False)
        pixels[idx] = 0
        print "Setting %d pixels to zero because they are masked in the internal mask." % (len(idx[0]))
    myia.close()
    zpixels = len(np.where(pixels == 0)[0].flatten())
    npixels = np.prod(np.shape(pixels))
    percent = zpixels*100./npixels
    print "There are %d/%d pixels (%f%%) that are equal to zero. %f%% are non-zero." % (zpixels,npixels,percent,100-percent)
    return zpixels

def imagePeakPerChannel(img, channels='', axes='', useImstat=False):
    """
    Returns an array of the peak value per channel of a CASA cube.
    See also imageStdPerChannel which can accept a region, box or annulus.
    axes: passed to imstat, if not specified, determines it automatically
    channels: passes to imstat via the chans parameter
    -Todd Hunter
    """
    if axes == '':
        mylist = imheadlist(img,omitBeam=True)
        bunit = mylist['bunit']
        myshape = mylist['shape']
        axes = range(len(myshape))
        axis = findSpectralAxis(img)
        axes.remove(axis)
    if channels == '':
        nchan = numberOfChannelsInCube(img)
        channels = range(nchan)
    else:
        channels = range(int(channels.split('~')[0]), int(channels.split('~')[1])+1)
    peaks = []
    if useImstat:
        return imstat(img, axes=axes, chans=channels)['max']
    else:
        for channel in channels:
            if channel % 50 == 0: print "working on channel ", channel
            peaks.append(imagePeak(img, channel=channel))
        return peaks

def imageSource(img):
    """
    Returns the name of the source from an image as read from the 
    ia tool's miscinfo method.  The keyword 'OBJECT' is used.
    If not present, it tries the 'field' keyword.  Both are typically written
    in pipeline CASA images, only 'field' typically appears in pipeline FITS
    images, while only 'OBJECT' can appear in manual images.
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    mydict = myia.miscinfo()
    myia.close()
    object = ''
    if 'OBJECT' in mydict:
        object = mydict['OBJECT']
    elif 'field' in mydict:
        object = mydict['field']
    return object
    
def imagePeak(img, pixelRadius=None, returnPosition=None, applymask=True, 
              delimiter=' ', channel='', verbose=False):
    """
    Returns the peak pixel value of a CASA image. For a cube, it operates
    channel-by-channel to avoid memory overflow.  See also imageMin.
    Requires to be run from inside CASA since it uses the imhead task.    
    If you are interested only in the full image, note that you can also 
    simply use:  imhead(img, mode='get', hdkey='datamax')
    If there are multiple pixels with the same peak value, then it takes
    the mean of the xpixels and the mean of the ypixels.
    -Todd Hunter
    Inputs:
    pixelRadius: limit the region searched to a box of this radius (in pixels)
             around the image center
    channel: restrict to one channel or a range of channels, e.g. 'c0~c1'
    returnPosition: None, 'pixel', 'radec', 'radec_hms', 'arcsec', 'mas'
          the latter two are relative to the reference pixel
          'radec' means a sexagesimal string
          Only works correctly for 2D (single-Stokes, single-channel) images
    applymask: if True, then also read the mask associated with the image and
       ignore pixels where the mask is set to False (by setting value to -1e10)
    delimiter: used to separate RA from Dec for returnPosition='radec'
    verbose: if True, then print the call to au.findPixel
    """
    if (not os.path.exists(img)):
        print "imagePeak: Could not find image: ", img
        return
    shape = imhead(img, mode='get', hdkey='shape')
    myia = createCasaTool(iatool)
    myia.open(img)
    axis = findSpectralAxis(myia)
    if axis < 0:
        channels = [0]
    else:
        if channel == '':
            channels = range(shape[axis])
        elif type(channel) == str:
            channels = channels.split('~')
            if (len(channels) == 1):
                channels = [int(channels[0])]
            else:
                channels = range([int(channels[0]), int(channels[1])+1])
        else:
            channels = [int(channel)]
    myrg = createCasaTool(rgtool)
    peak = None
    if (pixelRadius is None):        
        if axis < 0:
            myblc = [0,0]
            mytrc = [shape[0],shape[1]]
        else:
            myblc = np.zeros(len(shape))
            mytrc = np.zeros(len(shape))
            mytrc[0] = shape[0]
            mytrc[1] = shape[1]
        xmean = -1
        ymean = -1
        for channel in channels:
            if verbose: print "axis=%d, channel=%d " % (axis, channel)
            if axis >= 0:
                myblc[axis] = channel
                mytrc[axis] = channel
            myregion = myrg.box(blc=myblc, trc=mytrc)
            pixels = myia.getregion(region=myregion)
            if (applymask):
                mask = myia.getregion(getmask=True,region=myregion)
                pixels[np.where(mask==False)] = -1e10
            if peak is None:
                peak = np.max(pixels)
                idx = np.where(pixels == peak)
#                print "Peak = %f, idx=%s" % (peak,idx)
                if len(idx[0]) == 1:
                    result = list(np.unravel_index(np.argmax(pixels),np.shape(pixels)))
                    xmean = result[0]
                    ymean = result[1]
                else:
                    xmean = np.round(np.mean(idx[0]))
                    ymean = np.round(np.mean(idx[1]))
            else:
                peak = np.max([peak,np.max(pixels)])
                if peak == np.max(pixels):
                    idx = np.where(pixels == peak)
                    xmean = np.round(np.mean(idx[0]))
                    ymean = np.round(np.mean(idx[1]))
        xoffset = 0
        yoffset = 0
    else:
        bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,freq = getFitsBeam(img)
        xcen = naxis1/2
        ycen = naxis2/2
        blc = [xcen-pixelRadius, ycen-pixelRadius]
        trc = [xcen+pixelRadius, ycen+pixelRadius]
        xoffset = blc[0]
        yoffset = blc[1]
        if (xoffset < 0):
            print "Warning, pixelRadius greater than image radius in x.  Using whole image in x."
            xoffset = 0
        if (yoffset < 0):
            print "Warning, pixelRadius greater than image radius in y.  Using whole image in y."
            yoffset = 0
        myblc = blc + [0,0]
        mytrc = trc + [0,0]
        for channel in channels: # range(channels):
            myblc[axis] = channel
            mytrc[axis] = channel
            myregion = myrg.box(blc=myblc, trc=mytrc)
            pixels = myia.getregion(region=myregion)
            if (applymask):
                mask = myia.getregion(getmask=True, region=myregion)
                pixels[np.where(mask==False)] = -1e10
            if peak is None:
                peak = np.max(pixels)
                idx = np.where(pixels == peak)
                if len(idx[0]) == 1:
                    result = list(np.unravel_index(np.argmax(pixels),np.shape(pixels)))
                    xmean = result[0]
                    ymean = result[1]
                else:
                    xmean = np.round(np.mean(idx[0]))
                    ymean = np.round(np.mean(idx[1]))
            else:
                peak = np.max([peak,np.max(pixels)])
                if peak == np.max(pixels):
                    idx = np.where(pixels == peak)
                    xmean = np.round(np.mean(idx[0]))
                    ymean = np.round(np.mean(idx[1]))
    myrg.done()
    myia.done()
    if (returnPosition is not None):
#        pixel = list(np.unravel_index(np.argmax(pixels),np.shape(pixels)))
        pixel = [xmean, ymean]
        pixel[0] += xoffset
        pixel[1] += yoffset
        if (returnPosition=='radec'):
            if verbose:
                print "Calling au.findPixel('%s',pixel=%s,delimiter='%s')" % (img,str(pixel),delimiter)
            position = findPixel(img,pixel=pixel,verbose=False,delimiter=delimiter,format='sexagesimal_colon')
        elif (returnPosition=='radec_hms'):
            if verbose:
                print "Calling au.findPixel('%s',pixel=%s,delimiter='%s')" % (img,str(pixel),delimiter)
            position = findPixel(img,pixel=pixel,verbose=False,delimiter=delimiter,format='sexagesimal_hms')
        elif (returnPosition=='pixel'):
            position = pixel
        elif (returnPosition=='arcsec' or returnPosition=='mas'):
            hdr = imhead(img,mode='list')
            position=[-(hdr['crpix1']-pixel[0])*hdr['cdelt1']*ARCSEC_PER_RAD,
                      (hdr['crpix2']-pixel[1])*hdr['cdelt2']*ARCSEC_PER_RAD]
            if (returnPosition=='mas'):
                position = list(np.array(position)*1000)
        else:
            print "Invalid option for returnPosition. Must be: 'pixel', 'radec', 'radec_hms', 'arcsec', or 'mas'"
            return
        if verbose:
            print "imagePeak position = ", position
        return(peak, position)
    else:
        return(peak)

def imageFitComparedToCatalog(img, vis='', returnComponents=False):
    """
    Takes the image of quasar observed as science target or check source,
    fits a Gaussian to it, and compares with the FIELD position of the ms.
    vis: if not specified, uses the ALMA catalog position instead
    returnComponents: passed to angularSeparationOfStrings
    Returns: separation in arcsec
    -Todd Hunter
    """
    radec = imageFitFluxAtPhaseCenter(img, returnPosition=True)[3]
    field = imageSource(img)
    print "field = ", field
    mymsmd = createCasaTool(msmdtool)
    if vis != '':
        mymsmd.open(vis)
        catalog = direction2radec(mymsmd.phasecenter(fieldid=mymsmd.fieldsforname(field)[0]))
        mymsmd.close()
    else:
        catalog = searchFlux(field, returnPosition=True, verbose=False)
        print "Using catalog position = ", catalog
    separation = angularSeparationOfStrings(radec, catalog, returnComponents)
    if returnComponents:
        separation = np.array(separation)
    return separation*3600

def imageFitFluxAtPhaseCenter(img, radiusPixels=20, pngname=None, 
                              returnPosition=False):
    """
    Uses CASA imfit to fit the central portion of an image and report the
    flux density.  Called by plotGfluxscale.
    returns: 3 things:
        Gaussian fitted flux density, uncertainty, and flux in the box
    returnPosition: if True, then also return the RADec sexagesimal position
    -Todd Hunter
    """
    result = getFitsBeam(img)
    imsize = result[5]
    region='circle[[%dpix , %dpix], %dpix ]' % (imsize/2,imsize/2, radiusPixels)
    imagefit = imfitplot(img, region=region, pngname=pngname)      
    fitresults = imfitparse(imagefit)
    print "fitresults = ", fitresults
    if fitresults is not None:
        flux = float(fitresults.split()[2])
        fluxUncertainty  = float(fitresults.split()[3])
        if imagefit['percentageFluxRecovered'] > 0: 
            boxFlux = flux / (0.01*imagefit['percentageFluxRecovered'])
        else:
            boxFlux = 0
    else:
        flux = 0
        fluxUncertainty = 0
        boxFlux = 0
    if returnPosition:
        radec = ','.join(fitresults.split()[0:2]) 
        return flux, fluxUncertainty, boxFlux, radec
    else:
        return flux, fluxUncertainty, boxFlux

def imageMin(img, pixelRadius=None, returnPosition=None, applymask=True, 
             delimiter=' '):
    """
    Returns the minimum pixel value of a CASA image.  See also imagePeak.
    Requires to be run from inside CASA since it uses the imhead task.    
    If you are interested only in the full image, note that you can also 
    simply use:  imhead(img, mode='get', hdkey='datamin')
    -Todd Hunter
    Inputs:
    pixelRadius: limit the region searched to a box of this radius (in pixels)
    returnPosition: None, 'pixel', 'radec', 'radec_hms', 'arcsec', 'mas'
          the latter two are relative to the reference pixel
          'radec' means a sexagesimal string
    applymask: if True, then also read the mask associated with the image and
       ignore pixels where the mask is set to False (by setting value to +1e10)
    delimiter: used to separate RA from Dec for returnPosition='radec'
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    myia = createCasaTool(iatool)
    myia.open(img)
    if (pixelRadius is None):
        pixels = myia.getregion()
        if (applymask):
            mask = myia.getregion(getmask=True)
            pixels[np.where(mask==False)] = +1e10
        peak = np.min(pixels)
        xoffset = 0
        yoffset = 0
    else:
        bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,freq = getFitsBeam(img)
        xcen = naxis1/2
        ycen = naxis2/2
        blc = [xcen-pixelRadius, ycen-pixelRadius]
        trc = [xcen+pixelRadius, ycen+pixelRadius]
        xoffset = blc[0]
        yoffset = blc[1]
        myrg = createCasaTool(rgtool)
        region = myrg.box(blc=blc, trc=trc)
        pixels = myia.getregion(region = region)
        if (applymask):
            mask = myia.getregion(getmask=True, region=region)
            pixels[np.where(mask==False)] = +1e10
        peak = np.min(pixels)
        myrg.done()
    myia.done()
    if (returnPosition is not None):
        pixel = list(np.unravel_index(np.argmin(pixels),np.shape(pixels)))
        pixel[0] += xoffset
        pixel[1] += yoffset
        if (returnPosition=='radec'):
            print "Calling au.findPixel('%s',pixel=%s,delimiter='%s')" % (img,str(pixel),delimiter)
            position = findPixel(img,pixel=pixel,verbose=False,delimiter=delimiter,format='sexagesimal_colon')
        elif (returnPosition=='radec_hms'):
            print "Calling au.findPixel('%s',pixel=%s,delimiter='%s')" % (img,str(pixel),delimiter)
            position = findPixel(img,pixel=pixel,verbose=False,delimiter=delimiter,format='sexagesimal_hms')
        elif (returnPosition=='pixel'):
            position = pixel
        elif (returnPosition=='arcsec' or returnPosition=='mas'):
            hdr = imhead(img,mode='list')
            position=[-(hdr['crpix1']-pixel[0])*hdr['cdelt1']*ARCSEC_PER_RAD,
                      (hdr['crpix2']-pixel[1])*hdr['cdelt2']*ARCSEC_PER_RAD]
            if (returnPosition=='mas'):
                position = list(np.array(position)*1000)
        else:
            print "invalid option for returnPosition"
            return
        return(peak, position)
    else:
        return(peak)

def imageStds(images, blc=None, trc=None, applymask=False, sort=False, mad=False):
    """
    Calls imageStd on a list of images.
    images: a list of strings, or a comma-delimited string, or a single string
        with the wildcard character (*)
    blc: integer tuple for the noise measurement
    trc: integer tuple for the noise measurement
    sort: if True, then sort in order of increasing brightness
    Returns: a list of the values
    -Todd Hunter
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    images = np.array(images)
    if sort:
        peaks = []
        for img in images:
            peaks.append(imageStd(img, blc=blc, trc=trc, applymask=applymask, mad=mad))
        idx = np.argsort(peaks)
    else:
        idx = np.array(range(len(images)))
    mystds = []
    for img in images[idx]:
        mystd = imageStd(img, blc=blc, trc=trc, applymask=applymask, mad=mad)
        mystds.append(mystd)
        print "%s:  %.7f" % (img, mystd)
    return(mystds)

def imageStdVariation(img, maxvalue=0, boxes=100, verbose=False):
    """
    Measures the standard deviation of an image in lots of boxes, then computes
    statistics on the result.   Boxes with signal can be ignored using the
    maxvalue parameter.
    """
    result = getFitsBeam(img)
    xpix = result[5]
    ypix = result[6]
    width = int(round((xpix*ypix*1.0/boxes)**0.5))
    print "Box width = %d pixels = %f arcsec, pixels per box = %d, box area = %f sq arcsec" % (width, width*abs(result[3]), width**2, abs(width**2*result[3]*result[4]))
    mystds = []
    boxes = 0
    unmaskedBoxes = 0
    for left in range(0,xpix,width):
        for bottom in range(0,ypix,width):
            boxes += 1
#            print "Running au.imageStd('%s', blc=[%d,%d], trc=[%d,%d], alsoReturnPeak=True, applymask=True)" % (img,left,bottom,left+width,bottom+width)
            result = imageStd(img, blc=[left,bottom], trc=[left+width, bottom+width], 
                              alsoReturnPeak=True, applymask=True)
            if (result is None): continue
            mystd, peak, npix = result
            if (npix > 0.9*width**2):
                unmaskedBoxes += 1
                if (peak <= maxvalue or maxvalue <= 0):
                    if verbose: print "%d: std=%f, peak=%f" % (boxes,mystd,peak)
                    mystds.append(mystd)
    if (maxvalue > 0):
        print "%d of %d possible boxes have all values < %f." % (len(mystds), unmaskedBoxes, maxvalue)
    else:
        print "%d of %d possible boxes." % (len(mystds), unmaskedBoxes)
    if (len(mystds) == 0):
        return
    p = computePercentiles(mystds, [10,25,33,67,75,90])
    print "Peak st.dev = %f, mean = %f, median = %f" % (np.max(mystds), np.mean(mystds), np.median(mystds))
    print "Percentiles: 10: %f, 25: %f, 33: %f, 67: %f, 75: %f, 90: %f" % (p[10],p[25],p[33],p[67],p[75],p[90])

def computePercentiles(data, values=[10,25,50,75,90]):
    """
    Computes the requested percentiles of an array and returns them in a dictionary.
    -Todd Hunter
    """
    percentiles = {}
    for v in values:
        percentiles[v] = scoreatpercentile(data, v)
    return(percentiles)
    
def imageStd(img, innerRadius=None, outerRadius=None, blc=None, trc=None, 
             applymask=False, region='', alsoReturnPeak=False, mad=False):
    """
    Returns the standard deviation of pixel values of a CASA image, or None
    if all pixels are masked and applymask=True.  See also imageStdPerChannel.
    blc: integer tuple
    trc: integer tuple
    innerRadius: of square annulus in pixel units (not yet working)
    outerRadius: of square annulus in pixel units (not yet working)
    applymask: if True, then ignore pixels that are masked
    alsoReturnPeak: if True, then also return peak value and npixels considered
    mad: if True, then return the MAD instead
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image."
        return
    myia = createCasaTool(iatool)
    myia.open(img)
    if (innerRadius is None and outerRadius is None):
        if (blc==None and trc==None and region==''):
            pixels = myia.getregion()
        elif (region != ''):
            pixels = myia.getregion(region=region)
        else:
            myrg = createCasaTool(rgtool)
            if (type(blc) == str):
                blc = [int(i) for i in blc.split(',')]
            if (type(trc) == str):
                trc = [int(i) for i in trc.split(',')]
            region = myrg.box(blc, trc)
            pixels = myia.getregion(region=region)
            myrg.done()
            if (applymask):
                mymask = myia.getregion(region=region, getmask=True)
                pixels = pixels[np.where(mymask==True)]
    else:
        bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,freq = getFitsBeam(img)
        xcen = naxis1/2
        ycen = naxis2/2
        if (outerRadius is None):
            blc = [0,0]
            trc = [naxis1,naxis2]
        else:
            blc = [xcen-outerRadius, ycen-outerRadius]
            trc = [xcen+outerRadius, ycen+outerRadius]
        myrg = createCasaTool(rgtool)
        a = '%dpix  %dpix'%(blc[0],blc[1])
        b = '%dpix  %dpix'%(trc[0],trc[1])
        print "Running myrg.wbox('%s', '%s', [0,1])" % (a,b)
        outerRegion = myrg.wbox(a, b, [0,1])
        print "Done"
                                
        if (innerRadius is not None):
            blc = [xcen-innerRadius, ycen-innerRadius]
            trc = [xcen+innerRadius, ycen+innerRadius]
            innerRegion = myrg.wbox('%dpix %dpix'%(blc[0],blc[1]),
                                    '%dpix %dpix'%(trc[0],trc[1]), [0,1])
            region = myrg.difference(region1=outerRegion, region2=innerRegion)
        else:
            region = outerRegion
        pixels = myia.getregion(region = region)
        if (applymask):
            mymask = myia.getregion(region = region, getmask=True)
            pixels = pixels[np.where(mymask==True)]
        myrg.done()
    if (len(pixels) == 0):
        return None
    peak = np.max(pixels)
    if (mad):
        mystd = MAD(pixels)
    else:
        mystd = np.std(pixels)
    myia.done()
    if (alsoReturnPeak):
        return(mystd, peak, len(pixels))
    else:
        return(mystd)

def imageSnrs(images, blc=None, trc=None, applymask=False, sort=False, pixelRadius=None, mad=False):
    """
    Calls imageSnr on a list of images.
    images: a list of strings, or a comma-delimited string, or a single string
        with the wildcard character (*)
    blc: integer tuple for the noise measurement
    trc: integer tuple for the noise measurement
    sort: if True, then sort in order of increasing brightness
    pixelRadius: passed to imagePeak
    mad: passed to imageStd
    -Todd Hunter
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    images = np.array(images)
    if sort:
        peaks = []
        for img in images:
            peaks.append(imageSnr(img, blc, trc, applymask, verbose=False, pixelRadius=pixelRadius, mad=mad))
        idx = np.argsort(peaks)
    else:
        idx = np.array(range(len(images)))
    for img in images[idx]:
        mystd = imageSnr(img, blc, trc, applymask, verbose=False, pixelRadius=pixelRadius, mad=mad)
        print "%s:  %f" % (img, mystd)

def imageSnr(img, blc=None, trc=None, applymask=False, verbose=True, pixelRadius=None, mad=False):
    """
    Measures the peak over standard deviation of an image.
    blc: integer tuple for the noise measurement
    trc: integer tuple for the noise measurement
    verbose: if True, then also print the peak and std. dev.
    pixelRadius: passed to imagePeak
    Todd Hunter
    """
    peak = imagePeak(img, applymask=applymask, pixelRadius=pixelRadius)
    mystd = imageStd(img, blc=blc, trc=trc, applymask=applymask, mad=mad)
    if verbose:
        print "Peak +- st.dev = %f +- %f" % (peak,mystd)
    if (peak is None or mystd is None):
        return
    return(peak/mystd)
    
def normalizeImage(img, value=1.0, regrid=False, newimage='', ceiling=False,
                   round=False, floor=False, flatten=False):
    """
    Read a CASA image, and normalize the intensity scale to a specified value 
    (default=1.0).  
    img: name of a CASA image.  If a wildcard (*) is included, then process 
         all matching files.
    value: the value to which to normalize the peak
    regrid: calls convertImageToDirectionType after normalizing
    newimage: output image, default=img+'.normalized'.
    ceiling: if True, then instead of normalizing, round to next highest integer
    round: if True, then instead of normalizing, round to nearest integer
    floor: if True, then instead of normalizing, truncate to next lowest integer
    flatten: if True, then set all (unmasked) pixel values to the specified value
    -Todd Hunter
    """
    if (img.find('*') >= 0):
        images = glob.glob(img)
    else:
        images = [img]
    if (len(images) > 1 and newimage != ''):
        print "Cannot specify newimage parameter if img is a list."
        return
    for img in images:    
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
        if (newimage == ''):
            if (floor):
                newimage = img + '.floor'
            elif (ceiling):
                newimage = img + '.ceiling'
            elif (round):
                newimage = img + '.round'
            else:
                newimage = img + '.normalized'
        if (os.path.exists(newimage)):
            shutil.rmtree(newimage)
        os.system('cp -r %s %s' % (img,newimage))
        myia = createCasaTool(iatool)
        myia.open(newimage)
        pixels = myia.getregion()
        peak = np.max(pixels)
        print "Peak = ", peak
        if (floor):
            pixels = np.floor(pixels)
        elif (ceiling):
            pixels = np.ceil(pixels)
        elif (round):
            pixels = np.round(pixels)
        elif (flatten):
            pixels = pixels/pixels
            pixels *= value
        else:
            pixels *= value/peak
        myia.putregion(pixels=pixels)
        peak = np.max(pixels)
        print "New Peak = ", peak
        myia.close()
        print "New image = ", newimage
        if (regrid):
            convertImageToDirectionType(newimage,overwrite=True)
    return(newimage)

def complexToReal(filelist, regrid=False, outdir='', normalize=False, outfile=''):
    """
    Converts a complex image (or a list of images) into its square 
    (amplitude**2).  Useful for holography and TICRA model images.  
    normalize: if True, then normalize the peak to 1.0
    outdir: the output directory to write the new image
    regrid: if True, then rewrite the header with Direction coordinates (to allow imfit)
    - Todd Hunter
    """
    return(complexToOther(filelist, regrid, outdir,suffix='real',
                          expression='real()', normalize=normalize, outfile=outfile))

def complexToImaginary(filelist, regrid=False, outdir='', normalize=False, outfile=''):
    """
    Converts a complex image (or a list of images) into its imaginary 
    component.  Useful for holography and TICRA model images.  
    normalize: if True, then normalize the peak to 1.0
    outdir: the output directory to write the new image
    regrid: if True, then rewrite the header with Direction coordinates (to allow imfit)
    - Todd Hunter
    """
    return(complexToOther(filelist, regrid, outdir,suffix='imaginary', 
                          expression='imag()', normalize=normalize, outfile=outfile))

def complexToAmplitude(filelist, regrid=False, outdir='',normalize=False):
    """
    Converts a complex image (or a list of images) into its amplitude.
    Useful for holography and TICRA model images.  - Todd Hunter
    normalize: if True, then normalize the peak to 1.0
    outdir: the output directory to write the new image
    regrid: if True, then rewrite the header with Direction coordinates (to allow imfit)
    """
    return(complexToOther(filelist, regrid, outdir, suffix='amplitude', 
                          expression='amplitude()', normalize=normalize))

def complexToSquare(filelist, regrid=False, outdir='',normalize=False):
    """
    Converts a complex image (or a list of images) into its square 
    (i.e. amplitude**2).  Useful for holography and TICRA model images.  
    normalize: if True, then normalize the peak to 1.0
    outdir: the output directory to write the new image
    regrid: if True, then rewrite the header with Direction coordinates (to allow imfit)
    - Todd Hunter
    """
    return(complexToOther(filelist,regrid,outdir,
                          suffix='square', expression='pow(amplitude(),2)',
                          normalize=normalize))
        
def complexToOther(filelist, regrid=False, outdir='', suffix='square', 
                   expression='pow(amplitude(),2)', normalize=False, outfile=''):
    """
    Converts a complex-valued image (or a list of images) into a different 
    format. Useful for holography and TICRA model images.  - Todd Hunter
    normalize: if True, then normalize the peak to 1.0
    outdir: the output directory to write the new image
    suffix: the suffix to add to the input image name to name the new image
    regrid: if True, then rewrite the header with Direction coordinates (to allow imfit)
    """
    if (filelist.find('*') >= 0):
        filelist = glob.glob(filelist)
    elif (type(filelist) == str):
        filelist = [filelist]
    for f in filelist:
        f = f.rstrip('/')
        if (os.path.exists(f)==False):
            print "Image does not exist: ", f
            return
        myexpr = expression.replace("()","('%s')"%f)
        if (outfile == ''):
            if (f.find('complex') >= 0):
                outfile = f.replace('complex',suffix)
            else:
                outfile = f+'.'+suffix
        if (outdir != ''):
            outfile = outdir + '/' + os.path.basename(outfile)
        print "Running immath(imagename='%s',expr=\"%s\", outfile='%s')" % (f,myexpr,outfile)
        if (os.path.exists(outfile)):
            shutil.rmtree(outfile)
        immath(imagename=f, expr="%s"%(myexpr), outfile=outfile)
        if (normalize):
            outfile = normalizeImage(outfile)
        if (regrid):
            convertImageToDirectionType(outfile,overwrite=True)

def imsubimageOnePlane(img, newimage, plane=0, overwrite=True):
    """
    Equivalent to CASA task imsubimage on a 3-axis image, except that it works even if the 
    3rd axis is of undefined type, such as the images from SOFIA which are 3-plane "cubes" 
    where the image is in the first plane.
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    if os.path.exists(newimage) and overwrite:
        print "Removing ", newimage
        shutil.rmtree(newimage)
    myia.open(img)
    shape = myia.shape()
    bu = myia.brightnessunit()
    pixels = myia.getchunk(blc=[0,0,plane], trc=[shape[0]-1,shape[1]-1,plane])[:,:,0]
    csys = myia.coordsys(axes=[0,1])
    myia.done()
    im1 = myia.newimagefromarray(outfile=newimage, pixels=pixels, overwrite=True)
    im1.setcoordsys(csys.torecord())
    im1.setbrightnessunit(bu)
    im1.done()
    csys.done()

def addAxesToImage(img, outfile='', spectral=True, freq='230e9'):
    """
    Adds a Stokes axis (I) and (optionally) a spectral axis to a 2D casa image.
    outfile: name of 4D image to produce (default=<img>.4D.image)
    spectral: if True, then also add a spectral axis
    freq: frequency value in Hz, GHz, or a string with units.  Will be written to crval3 and restfreq
    Returns: name of new image
    -Todd Hunter
    """
    if outfile == '':
        outfile = img.replace('.image','.4D.image')
    myia = createCasaTool(iatool)
    im1 = myia.newimagefromimage(infile=img, overwrite=True)
    im2 = im1.adddegaxes(outfile=outfile, spectral=spectral, stokes='I', overwrite=True)
    im1.done()
    im2.done()
    if spectral:
        freqHz = parseFrequencyArgumentToHz(freq)
        imhead(outfile, mode='put', hdkey='crval3', hdvalue='%fHz'%(freqHz))
        imhead(outfile, mode='put', hdkey='restfreq', hdvalue='%fHz'%(freqHz))
    return outfile

def makeCasaImageFrom2DArrays(outfile, arraydict, frequency, order='', 
                              overwrite=True, zeroAzimuth=True, zeroElevation=True):
    """
    Makes a 4D CASA image from a list of 2D arrays per Stokes parameter
    arraydict: {'RealGainX': 2Darray, 'RealGainY': 2Darray, etc.}
    frequency: in Hz
    order: preferred order of the Stokes values
    zeroAzimuth: if True, then center the values at 0 for relative coordinates
    zeroElevation: if True, then center the values at 0 for relative coordinates
    """
    myia = createCasaTool(iatool)
    if os.path.exists(outfile) and overwrite:
        print "Removing ", outfile
        shutil.rmtree(outfile)
    pixels = []
    stokeslist = []
    if (type(order) == str):
        order = order.split(',')
    if (len(order) < len(arraydict.keys())):
        order = arraydict.keys()
    for array in order:
        pixels.append(arraydict[array])
        if (array == 'RealGainX' or array == 'RealDX'): stokes = 'XX'
        elif (array == 'RealGainY' or array == 'RealDY'): stokes = 'YY'
        elif (array == 'ImagGainY' or array == 'ImagDY'): stokes = 'YX'
        elif (array == 'ImagGainX' or array == 'ImagDX'): stokes = 'XY'
        else: stokes = 'I'
        stokeslist.append(stokes)
    pixels = [pixels]
#    pixels = np.transpose([pixels])
#    pixels = np.moveaxis(pixels, [0,1,2,3],[-1,-2,-3,-4])
    pixels = np.swapaxes(pixels, 0, 3)
    pixels = np.swapaxes(pixels, 1, 2)
    im1 = myia.newimagefromarray(outfile=outfile, pixels=pixels, overwrite=True)
    im1.done()
    myia.open(outfile)
    csys = myia.coordsys()
    csys.setreferencecode('AZELGEO')
    refval = csys.referencevalue()
    # AzimAxis=0, ElevAxis=1
    if zeroAzimuth:
        refval['numeric'][0] = 0
    if zeroElevation:
        refval['numeric'][1] = 0
    csys.setreferencevalue(refval)
    csys.setstokes(' '.join(stokeslist))
    csys.setspectral(frequencies=qa.quantity(frequency,'Hz'))
    myia.setcoordsys(csys.torecord())
    csys.done()
    myia.done()
    
def makeCasaImageFrom2DArray(outfile, pixels, overwrite=True):
    """
    Makes a 4D CASA image from a 2D array (degenerate Stokes and spectral axis)
    pixels: 2D array
    """
    myia = createCasaTool(iatool)
    if os.path.exists(outfile) and overwrite:
        print "Removing ", outfile
        shutil.rmtree(outfile)
    # If you want 4D, then pixels needs to be 4D
    # The transpose puts the spatial coordinates in the first 2 axes.
    im1 = myia.newimagefromarray(outfile=outfile, 
                                 pixels=np.transpose([[pixels]]), linear=False,
                                 overwrite=True)
    im1.done()
    myia.open(outfile)
    csys = myia.coordsys(axes=[0,1,2,3])
    csys.setreferencecode('AZELGEO')
    refval = csys.referencevalue()
    # Set azimuth to zero (AzimAxis=0, elev=1)
    refval['numeric'][0] = 0
    csys.setreferencevalue(refval)
    csys.setstokes('XX')
    myia.setcoordsys(csys.torecord())
    csys.done()
    myia.done()
    
    
def convertImageToDirectionType(img, overwrite=False, outputimage=''):
    """
    Converts an image with Linear coordinate system type to Direction.
    Useful for ALMA astroholography images output by CLIC.
    img: the input image
    overwrite: if True, then modify the input image
    outputimage: the name of the file to produce if overwrite==False
                 (the default is to append ".dirtype")
    -Todd Hunter
    """
    cdelt1 = imhead(img,mode='get',hdkey='cdelt1')
    cdelt2 = imhead(img,mode='get',hdkey='cdelt2')
    cunit1 = imhead(img,mode='get',hdkey='cunit1')
    cunit2 = imhead(img,mode='get',hdkey='cunit2')
    crpix1 = imhead(img,mode='get',hdkey='crpix1')
    crpix2 = imhead(img,mode='get',hdkey='crpix2')
    hol = createCasaTool(iatool)
    hol.open(img)
    myia = createCasaTool(iatool)
    if (outputimage == ''):
        outputimage = img+'.dirtype'
    if (os.path.exists(outputimage)):
        shutil.rmtree(outputimage)
    myia.fromshape(outputimage, hol.shape())
    myia.putchunk(hol.getchunk())
    hol.done()
    myia.done()
    if (overwrite):
        shutil.rmtree(img)
        os.rename(outputimage,img)
        outputimage = img
    imhead(outputimage,mode='put',hdkey='cdelt1',hdvalue=cdelt1)
    imhead(outputimage,mode='put',hdkey='cdelt2',hdvalue=cdelt2)
    imhead(outputimage,mode='put',hdkey='cunit1',hdvalue=cunit1)
    imhead(outputimage,mode='put',hdkey='cunit2',hdvalue=cunit2)
    imhead(outputimage,mode='put',hdkey='crpix1',hdvalue=crpix1)
    imhead(outputimage,mode='put',hdkey='crpix2',hdvalue=crpix2)

def headerToArcsec(mydict, unit=None):
    """
    Converts an angle quantity dictionary to the angle
    in arcsec.
    """
    if (unit is None):
        value = mydict['value']
    else:
        value = mydict
        mydict = {'value': mydict, 'unit': unit}
    if (mydict['unit'].find('rad') >= 0):
        value = 3600*np.degrees(value)
    elif (mydict['unit'].find('deg') >= 0):
        value *= 3600
    return(value)

def headerToDegree(mydict, unit=None):
    """
    Converts an angle quantity dictionary to the angle
    in degrees.
    """
    if (unit is None):
        value = mydict['value']
    else:
        value = mydict
        mydict = {'value': mydict, 'unit': unit}
    if (mydict['unit'].find('rad') >= 0):
        value = np.degrees(value)
    elif (mydict['unit'].find('arcsec') >= 0):
        value /= 3600.
    return(value)

def headerToRadian(mydict, unit=None):
    """
    Converts an angle quantity dictionary to the angle
    in radians.
    """
    if (unit is None):
        print "mydict = ", mydict
        value = mydict['value']
    else:
        value = mydict
        mydict = {'value': mydict, 'unit': unit}
    if (mydict['unit'] == 'arcsec'):
        value = np.radians(value/3600.)
    elif (mydict['unit'].find('deg') >= 0):
        value = np.radians(value)
    return(value)

def pickTicraImage(frequency, antennaType, ticraDir='', 
                   excludeBand3=True,excludeBand3Below=109.0,suffix='.square.normalized'):
    """
    Pick the appropriate TICRA image (the squared and normalized version) to 
    use for ALMA beamsize simulations as a function of frequency and antenna 
    type.
    frequency: floating point number in GHz (no units) or a string with units
    antennaType: string containing either 'DV', 'PM', or 'DA'
    ticraDir: the directory containing the *EFP.im.square.normalized images
    excludeBand3: if True, do not allow the Band 3 models to be chosen below
                  the frequency specified in excludeBand3Below
    excludeBand3Below: frequency in GHz below which to not use Band 3 patterns
    suffix: which image to pick (default = the squared version suitable for TP)
    -Todd Hunter
    """
    if (ticraDir == ''):
        ticraDir = os.getenv('CASAPATH').split()[0] + '/data/alma/responses/'
    antType = None
    for a in ['DV','DA','PM']:
        if (antennaType.upper().find(a) >= 0):
            antType = a
            if (antType == 'PM'): antType = 'DV'
    if (antType is None):
        print "Antenna type was not specified after '%s'" % (antennaType)
        return(None)
    ghz = parseFrequencyArgumentToGHz(frequency)
    upperBounds = [92,108,116, 134.5,153.5,163, 227,259,275, 299.5,348.5,373,
                   631.5,690.5,720]
    if (excludeBand3==True):
        upperBounds = upperBounds[3:]
    elif (excludeBand3 != False):
        upperBounds = list(np.array(upperBounds)[np.where(np.array(upperBounds) >= excludeBand3)])
    else:
        excludeBand3Below = 84-1e-9
#        print "upperBounds = ", upperBounds
    pick = None
    for u in upperBounds:
        if (ghz < u):
            if (ghz > excludeBand3Below and ghz < 120):
                if (ghz > 113 or excludeBand3Below>100):
                    ticraUpperFreq = 116  # measured at 116
                elif (ghz > 105 or excludeBand3Below>100):
                    ticraUpperFreq = 114  # measured at 110
                elif (ghz > 92.5 or excludeBand3Below>84):
                    ticraUpperFreq = 105  # measured at 100
                else:
                    ticraUpperFreq = 92  # measured at 85
#                old 2007 models
#                if (ghz > 108 or excludeBand3Below>100):
#                    ticraUpperFreq = 116
#                elif (ghz > 92 or excludeBand3Below>84):
#                    ticraUpperFreq = 108
#                else:
#                    ticraUpperFreq = 92
                pick = antType + '*' + '%d'%(ticraUpperFreq) + '_GHz_ticra2014_EFP.im'+suffix
            else:
                pick = antType + '*' + '%g'%(u) + '_GHz_ticra2007_EFP.im'+suffix
            break
    if (pick is None or (ghz < 70) or (ghz > 163 and ghz < 211)):
        # bands 1,2,5 not supported, set low bound to 70 for Crystal's Jy/K plot
        print "Frequency out of range of TICRA models"
        return
    dadv = glob.glob(ticraDir+'/*'+pick)
    if (len(dadv) < 1):
        print "TICRA image not found (%s/*%s)" % (ticraDir,pick)
        return
    pick = dadv[0]
    if (antType == 'DV' or antType == 'PM'):
        pick.replace('DA','DV')
    else:
        pick.replace('DV','DA')
    return(pick)

def sfBeam(frequency, pixelsize=10, diameter=12.0, xSamplesPerBeam=5.0,
           ySamplesPerBeam=None, xSamplingArcsec=None, ySamplingArcsec=None,
           convsupport=-1, makeplot=False, m=0, taper=10, geometricMean=False,
           obscuration=0.75,cmult=1.0,coffset=0.0,xmult=1.0,alpha=1.0,
           testOption=False, minlevels=[0], truncate=False, img=None, row=None,
           column=None, stokes='XX', plotfile='',verbose=False,fwhmfactor=None,
           excludeBand3=True, excludeBand3Below=109.0):
    """
    This function calls the griddedBeam class in order to compute the
    effective restoring beam obtained from the casa command sd_imaging
    when using the SF gridding kernel.
        
    frequency: floating point number in GHz (no units) or a string with units
    pixelsize: floating point number in arcseconds (no units)
    diameter: the diameter of the single dish antenna in meters (no units)
    xSamplesPerBeam: the number of sampled points per telescope FWHM beam
                     along the X axis
    ySamplesPerBeam: the number of sampled points per telescope FWHM beam
                     along the Y axis
    xSamplingArcsec: if not None, then use this value instead of xSamplesPerBeam
    ySamplingArcsec: if not None, then use this value instead of ySamplesPerBeam
    convsupport: radius in pixels, default=-1 --> 3 pixels: a support width of
                  7 points
    m: The value to pass as m & n to scipy.special.pro_ang1
    taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function as the antenna beam,
               otherwise it uses a Gaussian
    fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
    geometricMean: if True, return only the mean beamsize; otherwise, return
             minorAxis,majorAxis,geometricMean (if the sampling is provided in
             both axes)
    obscuration: diameter in m to pass to au.primaryBeamArcsec
    alpha: the exponent of the weighting function: (1-nu**2)**alpha
    testOption: if True, use CASA's method of building the convFunc
    minlevels: a list of values above which to perform 1D Gaussian fits
    truncate: if taper=0, sets whether to truncate the Airy at first null
              if taper > 0, and not False, sets intensity level to truncate 
                 the Gaussian
    img: if not none, then use a row or column from this image as the beam model
         if 'ticraDA', 'ticraDV' or 'ticraPM' is specified, it will 
            automatically use the TICRA models distributed with au
    row: the row of img to use as the starting beam profile model
    column: the column of img to use as the starting beam profile model
        if row and column are both 'auto', then it will use the mean of the
        peak row and peak column, shifted so that their peaks align
    stokes: 'XX','YY' which Stokes to use in the img
    excludeBand3: if True, then don't use Band 3 TICRA patterns below
                  excludeBand3Below'
    excludeBand3Below: frequency in GHz below which to not use Band 3 patterns
    Returns:
       If only the X-axis sampling is given:
          the FWHM of the restoring beam
          the FWHM of a Gaussian fit to the restoring beam
       If both X and Y-axis sampling is given:
       * If geometricMean=True:
          the FWHM of the predicted restoring beam
          the FWHM of a Gaussian fit to the predicted restoring beam
       * If geometricMean=False:
          the minor axis of the restoring beam
          the major axis of the restoring beam
          the geometric mean of the restoring beam computed using findFWHM()
          the geometric mean of the FWHM of a Gaussian fit to the restoring beam
       
    - Todd Hunter
    """
    if (fwhmfactor is not None):
        if (fwhmfactor < 1.02 or fwhmfactor > 1.22):
            print "Invalid fwhmfactor (1.02<fwhmfactor<1.22)"
            return
    if (img is not None):
        if (img.lower().find('ticra') == 0):
            ticraDir = os.getenv("CASAPATH").split()[0]+"/data/alma/responses/"
            ticraImage = ticraDir + "ALMA_0_DA__0_0_360_0_45_90_602_602_631.5_GHz_ticra2007_EFP.im.square.normalized"
            if (not os.path.exists(ticraImage)):
                ticraDir = os.path.dirname(__file__) + '/TicraImages/'
                if (os.path.exists(ticraDir) == False):
                    print "The Ticra model images (squared) are not present in the analysisUtils area nor CASA."
                    return
            img = pickTicraImage(frequency,img,ticraDir,excludeBand3,
                                 excludeBand3Below)
            if (img is None):
                return
            if (verbose):
                print "Using TICRA image: %s" % (os.path.basename(img))
        if (os.path.exists(img) == False):
            print "Could not find image = ", img
            return
    if (plotfile != ''): makeplot = True
    if (ySamplesPerBeam is None and ySamplingArcsec is None):
        return(griddedBeam().sfBeamOneAxis(frequency, pixelsize, diameter,
                                     xSamplesPerBeam, xSamplingArcsec,
                                     convsupport, makeplot, m, taper,
                                     obscuration=obscuration,cmult=cmult,
                                     coffset=coffset,xmult=xmult,alpha=alpha,
                                     testOption=testOption,minlevels=minlevels,
                                     truncate=truncate,img=img,row=row,
                                     column=column,stokes=stokes,
                                     plotfile=plotfile,fwhmfactor=fwhmfactor))
    else:
        return(griddedBeam().sfBeamTwoAxes(frequency, pixelsize, diameter,
                                     xSamplesPerBeam, ySamplesPerBeam,
                                     xSamplingArcsec, ySamplingArcsec,
                                     convsupport, makeplot, m, taper,
                                     geometricMean,obscuration=obscuration,
                                     cmult=cmult,coffset=coffset,xmult=xmult,
                                     alpha=alpha,testOption=testOption,
                                     minlevels=minlevels,truncate=truncate,
                                     img=img,row=row,column=column,
                                     stokes=stokes,plotfile=plotfile,
                                           fwhmfactor=fwhmfactor))
    
class griddedBeam:
    """
    This class contains functions to compute the effective restoring beam
    obtained from the casa sd_imaging task when using either the GJINC
    gridding kernel (assuming the GJINC specific parameters are left at
    their default values), or the SF gridding kernel.
    - Todd Hunter
    """
    def gjinc(self, x, gwidth, jwidth, useCasaJinc=False, normalize=False):
        if (useCasaJinc):
            result = self.grdjinc1(x,jwidth,normalize) * self.gjincGauss(x, gwidth)
        else:
            result = self.jinc(x,jwidth) * self.gjincGauss(x, gwidth)
        return result

    def sfComb(self, frequency, pixelsize, diameter=12.0, samplesPerBeam=5.0,
               samplingArcsec=None, convsupport=-1, makeplot=False, m=0, 
               taper=10, obscuration=0.75,cmult=1.0,coffset=0.0,xmult=1.0,
               alpha=1.0,testOption=False, minlevels=[0], truncate=False, 
               img=None, row=None, column=None, stokes='XX', plotfile=''):
        convolutionPixelSize = 0.02
        showPrimaryBeamEquation = False
        returnProfile = True
        showplot = makeplot
        makeplot = False
        if (convsupport == -1):
            convsupport = 3
        xaxis, sf, result, samplingArcsec, fwhm = \
            self.sfBeamPredict(frequency, pixelsize,diameter, samplesPerBeam, 
                               samplingArcsec,convsupport, makeplot, m, taper,
                               showPrimaryBeamEquation, obscuration,
                               convolutionPixelSize, cmult, coffset, xmult, 
                               alpha, testOption, minlevels, truncate, img, 
                               row, column, stokes,plotfile,returnProfile)
        pixels = np.arange(np.min(xaxis), np.max(xaxis), pixelsize)
        skyMeasurements= np.arange(np.min(xaxis), np.max(xaxis), samplingArcsec)
        mysf = scipy.interpolate.UnivariateSpline(xaxis, sf, s=0)
        pixelSum = np.zeros(len(pixels))
        for i in range(len(pixels)):
            for s in skyMeasurements:
                distance = abs(s-pixels[i])
                if (distance < convsupport*pixelsize):
                    weight = mysf(distance)
#                    if (len(pixels)/2 == i):
#                        print "weight = ", weight
                    pixelSum[i] += weight
        pixel = range(len(pixels))[convsupport:-convsupport]
        pixelSum = pixelSum[convsupport:-convsupport]
        ratio = np.std(pixelSum)/np.mean(pixelSum)
        print "Pixel weight profile: mean = %f, std = %f,  std/mean = %g" % (np.mean(pixelSum), np.std(pixelSum), ratio)
        if (showplot):
            pb.clf()
            pb.plot(pixel, pixelSum, 'k-')
            pb.draw()
            if (plotfile != ''):
                if (plotfile==True):
                    plotfile = 'sfbeam.png'
                pb.savefig(plotfile)
        return(ratio, fwhm)
    
    def gjincComb(self, frequency, pixelsize, diameter=12.0, samplesPerBeam=5.0,
                  samplingArcsec=None, widthMultiplier=-1, makeplot=False, 
                  taper=10, obscuration=0.75,useCasaJinc=False,testOption=False,
                  minlevels=[0], truncate=False, img=None, row=None, 
                  column=None, stokes='XX', plotfile=''):
        convolutionPixelSize = 0.02
        returnProfile = True
        showplot = makeplot
        xaxis, gjinc, result, samplingArcsec, fwhm, radiusOfFirstNull = \
               self.gjincBeamPredict(frequency, pixelsize,diameter,
                                     samplesPerBeam, 
                                     samplingArcsec, makeplot, taper,
                                     obscuration, widthMultiplier,
                                     convolutionPixelSize, useCasaJinc,
                                     testOption, minlevels, truncate, img, row,
                                     column, stokes,plotfile,returnProfile)
        pixels = np.arange(np.min(xaxis), np.max(xaxis), pixelsize)
        skyMeasurements= np.arange(np.min(xaxis), np.max(xaxis), samplingArcsec)
        mygjinc = scipy.interpolate.UnivariateSpline(xaxis, gjinc, s=0)
        pixelSum = np.zeros(len(pixels))
        for i in range(len(pixels)):
            for s in skyMeasurements:
                distance = abs(s-pixels[i])
                if (distance < radiusOfFirstNull*pixelsize):
                    weight = mygjinc(distance)
                    pixelSum[i] += weight
#        print "radiusOfFirstNull of the GJinc function itself = %f pixels" % (radiusOfFirstNull) # 1.89*widthMultiplier
        pixel = range(len(pixels))[int(np.round(radiusOfFirstNull)):-int(np.round(radiusOfFirstNull))]
        pixelSum = pixelSum[int(np.round(radiusOfFirstNull)):-int(np.round(radiusOfFirstNull))]
        ratio = np.std(pixelSum)/np.mean(pixelSum)
        if (len(pixelSum) > 0):
            print "Pixel weight profile: length=%d, mean=%f, std=%f,  std/mean=%g" % (len(pixelSum), np.mean(pixelSum), np.std(pixelSum), ratio)
        else:
            print "len(pixels)=%d, int(radiusOfFirstNull) = %d" % (len(pixels), int(radiusOfFirstNull))
        if (showplot):
            pb.clf()
            pb.plot(pixel, pixelSum, 'k-')
            pb.draw()
            if (plotfile != ''):
                if (plotfile==True):
                    plotfile = 'gjincbeam.png'
                pb.savefig(plotfile)
        if (type(fwhm) == dict):
            fwhm = fwhm[0]
        return(ratio, fwhm)
    
    def testsf(self, alphamax=0,mmax=0,increment=0.01):
        """
        Find the best match to Fred's grdsf function in aips/casa
        """
        xvalues = [0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]
        target = [0.941325231, 0.783323506, 0.571913258, 0.361065385, 0.192065331, 0.0820333956, 0.0253406856]
        minerr = 1e9
        for m in range(mmax+1):
            for alpha in range(1+alphamax):
                for c in np.arange(2,15,increment):
                    v = self.spheroidalWaveFunction(xvalues, m=m, n=m, c=c*pi/2., alpha=alpha)
                    err = np.sum((np.array(v)-np.array(target))**2)
                    if (err < minerr):
                        best = [m,alpha,c]
                        minerr = err
                        bestv = v
#                    print "%d %d %.1f  %f %f %f   ( %f )" % (m,alpha,c, v[0],v[1],v[2], err)
        print "fred=%s" % (str(target))
        print "best=%s, err=%f: m, alpha, c=%s, c*pi/2=%f" % (str(bestv),minerr, str(best),best[2]*pi/2.)

    def plotgrdsf(self, plotfile=''):
        """
        Make a comparison plot of grdsf.f and the closest match in scipy
        """
        y = []
        x = np.arange(0,1,0.001)
        for myx in x:
            y.append(self.grdsf(myx))
        c = 5.356*np.pi/2.0 # value obtained by matching Fred's grdsf.f output with scipy(m=0,n=0)
        swf = self.spheroidalWaveFunction(x, c=c)
        pb.clf()
        pb.subplot(211)
        pb.plot(x,y,'k-', x,swf,'r-')
        pb.ylabel('value')
        pb.title('Black: grdsf.f, red: scipy(c=%f*pi/2)' % (c*2/np.pi))
        pb.subplot(212)
        percent = 100*np.array(y-swf)
        pb.plot(x,percent,'k-')
        pb.ylabel('(grdsf-scipy) difference (%% of peak)')
        pb.xlabel('Radius')
        pb.draw()
        if (plotfile!=''):
            pb.savefig(plotfile)
            
    def plotcasajinc(self, plotfile='', xmax=3):
        """
        Make a comparison plot of the grdjinc1 (the Jinc approximation used in 
        casa), and scipy.
        """
        y = []
        x = np.arange(0,xmax,0.001)
        y = self.gjinc(x,gwidth=1.55,jwidth=2.52*sqrt(np.log(2)), useCasaJinc=True)
        swf = self.gjinc(x, gwidth=1.55,jwidth=2.52*sqrt(np.log(2)), useCasaJinc=False)
        pb.clf()
        pb.subplot(211)
        pb.plot(x,y,'k-', x,swf,'r-')
        pb.ylabel('value')
        pb.title('Black: grdjinc1 (casa), red: scipy  gwidth=1.55, jwidth=2.52sqrt(log(2))')
        pb.ylim([-0.05,0.51])
        pb.subplot(212)
        percent = 100*np.array(y-swf)
        pb.plot(x,percent,'k-')
        pb.ylabel('(grdjinc1-scipy) difference (%% of peak)')
        pb.xlabel('Radius')
        pb.draw()
        if (plotfile!=''):
            pb.savefig(plotfile)
            
    def grdsf(self, NU):
        """
        C Find Spheroidal function with M = 6, alpha = 1 using the rational
        C approximations discussed by Fred Schwab in Indirect Imaging.
        C This routine was checked against Fred's SPHFN routine, and agreed
        C to about the 7th significant digit.
        C The gridding function is (1-NU**2)*GRDSF(NU) where NU is the distance
        C to the edge. The grid correction function is just 1/GRDSF(NU) where NU
        C is now the distance to the edge of the image.
        """
        NP = 4
        NQ = 2
        P  = np.reshape([8.203343e-2, -3.644705e-1, 6.278660e-1, -5.335581e-1, 2.312756e-1,
                         4.028559e-3, -3.697768e-2, 1.021332e-1, -1.201436e-1, 6.412774e-2], (5,2), order="F")
        Q = np.reshape([1.0000000e0, 8.212018e-1, 2.078043e-1,1.0000000e0, 9.599102e-1, 2.918724e-1], (3,2), order="F")
        VAL = 0.0
        if ((NU>=0.0) and (NU<0.75)):
            PART = 1-1
            NUEND = 0.75
        elif ((NU>=0.75) and (NU<=1.00)):
            PART = 2-1
            NUEND = 1.00
        else:
            VAL = 0.0
            return(VAL)
        TOP = P[0][PART]
        DELNUSQ = NU**2 - NUEND**2
        for K in range(1,NP+1):
            TOP += P[K][PART] * DELNUSQ ** K
        BOT = Q[0][PART]
        for K in range(1,NQ+1):
            BOT += Q[K][PART] * DELNUSQ ** K
        if (BOT != 0.0):
            VAL = TOP/BOT
        else:
            VAL = 0.0
        return(VAL)
    
    def spheroidalWaveFunction(self, x, m=0, n=0, c=0, alpha=0):
        if (type(x) != list and type(x) != np.ndarray):
            returnScalar = True
            x = [x]
        else:
            returnScalar = False
        cv = scipy.special.pro_cv(m,n,c)  # get the eigenvalue
        result = scipy.special.pro_ang1_cv(m,n,c,cv,x)[0]
        for i in range(len(x)):
            nu = x[i] # (i-0.5*len(x))/(0.5*len(x))  # only true if x is symmetric about zero
            result[i] *= (1-nu**2)**alpha
        # The peak of this function is about 10000 for m=0,n=0,c=6
        if (returnScalar):
            return result[0]
        else:
            return result
    
    def plotsfBeam(self, m=0, n=0, pixelsize=10, convsupport=-1):
        """
        Plots a basic prolate spheroidal wave function with a
        default support width of 7 (i.e. radius = 3).
        pixelsize: in arcsec
        """
        if (convsupport==-1):
            convsupport = 3
        support = convsupport*2+1
        c = np.pi*support/2.
        inc = 0.001
        x = np.arange(-1+inc,1,inc)
        y = self.spheroidalWaveFunction(x,m,n,c)
        y = y/np.max(y)
        pb.clf()
        x = x*pixelsize*(convsupport)
        pb.plot(x,y,'b')
        pb.title('m=%d, n=%d, c=%f' % (m,n,c))
        pb.xlabel('Offset (arcsec)')
        pb.draw()
        pb.savefig('sfBeam.png')
    
    def grdjinc1(self, val, c, normalize=True):
        # Casa's function
        #// Calculate J_1(x) using approximate formula
        xs = np.pi * val / c
        result = []
        for x in xs:
          x = abs(x)  # I added this to make it symmetric
          ax = abs(x)
          if (ax < 8.0 ):
            y = x * x
            ans1 = x * (72362614232.0 + y * (-7895059235.0 \
                       + y * (242396853.1 + y * (-2972611.439 \
                       + y * (15704.48260 + y * (-30.16036606))))))
            ans2 = 144725228442.0 + y * (2300535178.0 \
                       + y * (18583304.74 + y * (99447.43394 \
                       + y * (376.9991397 + y * 1.0))))
            ans = ans1 / ans2
          else:
            z = 8.0 / ax
            y = z * z
            xx = ax - 2.356194491
            ans1 = 1.0 + y * (0.183105e-2 + y * (-0.3516396496e-4 \
                      + y * (0.2457520174e-5 + y * (-0.240337019e-6))))
            ans2 = 0.04687499995 + y * (-0.2002690873e-3 \
                      + y * (0.8449199096e-5 + y * (-0.88228987e-6  \
                      + y * (0.105787412e-6))))
            ans = sqrt(0.636619772 / ax) * (cos(xx) * ans1 - z * sin(xx) * ans2)
          if (x < 0.0):
            ans = -ans
          if (x == 0.0):
            out = 0.5
          else:
            out = ans / x
          if (normalize):
            out = out / 0.5
          result.append(out)
        return(result)

    def jinc(self, x, jwidth):
        """
        The peak of this function is 0.5.
        """
        argument = np.pi*np.abs(x)/jwidth
        np.seterr(invalid='ignore') # prevent warning for central point
        result = scipy.special.j1(argument) / argument 
        np.seterr(invalid='warn')
        for i in range(len(x)):
            if (abs(x[i]) < 1e-8):
                result[i] = 0.5
        return result

    def gjincGauss(self, x, gwidth):
        return (np.exp(-np.log(2)*(x/float(gwidth))**2))  

    def gaussfit_errfunc(self,parameters,x,y):
        return (y - self.gauss(x,parameters))

    def gaussfit(self, x, y, showplot=False, minlevel=0, verbose=False, 
                 title=None, truncate=False):
        """
        Fits a 1D Gaussian assumed to be centered at x=0 with amp=1 to the 
        specified data, with an option to truncate it at some level.   
        Returns the FWHM and truncation point.
        """
        fwhm_guess = findFWHM(x,y)
        if (truncate == False):
            parameters = np.asarray([fwhm_guess], dtype=np.float64)
        else:
            parameters = np.asarray([fwhm_guess,truncate], dtype=np.float64)
        if (verbose): print "Fitting for %d parameters: guesses = %s" % (len(parameters), parameters)
        xx = np.asarray(x, dtype=np.float64)
        yy = np.asarray(y, dtype=np.float64)
        lenx = len(x)
        if (minlevel > 0):
            xwidth = findFWHM(x,y,minlevel)
            xx = x[np.where(np.abs(x) < xwidth*0.5)[0]]
            yy = y[np.where(np.abs(x) < xwidth*0.5)[0]]
            if (verbose):
                print "Keeping %d/%d points, guess = %f arcsec" % (len(x),lenx,fwhm_guess)
        result = optimize.leastsq(self.gaussfit_errfunc, parameters, args=(xx,yy),
                                  full_output=1)
        bestParameters = result[0]
        infodict = result[2]
        numberFunctionCalls = infodict['nfev']
        mesg = result[3]
        ier = result[4]
        if (verbose):
            print "optimize.leastsq: ier=%d, #calls=%d, message = %s" % (ier,numberFunctionCalls,mesg)
        if (type(bestParameters) == list or type(bestParameters) == np.ndarray):
            fwhm = bestParameters[0]
            if verbose: print "fitted FWHM = %f" % (fwhm)
            if (truncate != False):
                truncate = bestParameters[1]
                print "optimized truncation = %f" % (truncate)
        else:
            fwhm = bestParameters
        if (showplot):
            pb.clf()
            xgrid = np.arange(np.min(x), np.max(x), (np.max(x)-np.min(x))/1000.)
            pb.plot(xgrid, self.gauss(xgrid, [fwhm, truncate]), 'r-', x,y,'ko')
            if (title is not None):
                pb.title(title, size=12)
            pb.draw()
        return(fwhm,truncate)
    
    def gauss(self, x, parameters):
        """
        Computes the value of the Gaussian function at the specified
        location(s) with respect to the peak (which is assumed to be at x=0).
        truncate: if not None, then set result to zero if below this value.
        -Todd Hunter
        """
        if (type(parameters) != np.ndarray and type(parameters) != list):
            parameters = np.array([parameters])
        if (len(parameters) < 2):
            parameters = np.array([parameters[0],0])
        fwhm = parameters[0]
        x = np.asarray(x, dtype=np.float64)
        sigma = fwhm/2.3548201
        result = np.exp(-(x**2/(2.0*sigma**2)))
        idx = np.where(result < parameters[1])[0]
        result[idx] = 0
        return result
    
    def trunc(self, result):
        """
        Truncates a list at the first null on both sides of the center,
        starting at the center and moving outward in each direction.
        Assumes the list is positive in the center, e.g. a Gaussian beam.
        -Todd Hunter
        """
        # casa default truncate=-1, which means truncate at radius of first null
        mask = np.zeros(len(result))
        truncateBefore = 0
        truncateBeyond = len(mask)
        for r in range(len(result)/2,len(result)):
            if (result[r]<0):
                truncateBeyond = r
                break
        for r in range(len(result)/2,0,-1):
            if (result[r]<0):
                truncateBefore = r
                break
        mask[truncateBefore:truncateBeyond] = 1
#        print "Truncating outside of pixels %d-%d (len=%d)" % (truncateBefore,truncateBeyond-1,len(mask))
        result *= mask
        return result
    
    def findFWHM(self, x, y):
        """
        Measures the FWHM of the specified profile.  This works
        well in a noise-free environment, such as this model.
        -Todd Hunter
        """
        halfmax = np.max(y)*0.5
        spline = scipy.interpolate.UnivariateSpline(x, y-halfmax, s=0)
        x0,x1 = spline.roots()
        return(abs(x1-x0))
    
    def buildBoxcar(self, xaxis, width):
        """
        Returns a box car function.
        width: width of the box car, in the same units as the xaxis
        """
        myboxcar = []
        for x in xaxis:
            if (abs(x) <= width/2.0):
                myboxcar.append(1)
            else:
                myboxcar.append(0)
        return(myboxcar)
        
    def gjincBeamOneAxis(self, frequency, pixelsize, diameter, xSamplesPerBeam,
                         xSamplingArcsec, makeplot, taper=12, obscuration=0.75,
                         widthMultiplier=1.0,useCasaJinc=False,testOption=False,
                         minlevels=[0.0], truncate=False, img=None, row=None,
                         column=None, stokes='XX',plotfile='',fwhmfactor=None):
        """
        This function calls gjincBeam for one axis on the sky.
        frequency: in GHz
        pixelsize: in arcsec
        diameter: in meters
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function truncated at the first
               null as the antenna beam, otherwise it uses a Gaussian.
        widthMultiplier: the value by which to multiply the default values of 
                         gwidth/jwidth
        truncate: if taper=0, sets whether to truncate Airy at the first null
                  if taper>0, sets the intensity at which to truncate Gaussian
        If xSamplingArcsec == None, then use the derived FWHM/xSamplesPerBeam
        Returns:  the FWHM and the FWHM of a Gaussian fit
        """
        if (stokes == 'both' and img  is not None):
            fwhmXX,alongScanXX,sampling,fittedFWHMXX,radiusOfNullOnPixels = \
                        self.gjincBeamPredict(frequency,pixelsize,diameter,
                                       xSamplesPerBeam,xSamplingArcsec,makeplot,
                                       taper, obscuration=obscuration,
                                       widthMultiplier=widthMultiplier,
                                       useCasaJinc=useCasaJinc,
                                       testOption=testOption,
                                       minlevels=minlevels,truncate=truncate,
                                       img=img, row=row, column=column,
                                       stokes='XX',plotfile=plotfile,
                                       fwhmfactor=fwhmfactor)
            fwhmYY,alongScanYY,sampling,fittedFWHMYY,radiusOfNullOnPixels = \
                        self.gjincBeamPredict(frequency,pixelsize,diameter,
                                      xSamplesPerBeam,xSamplingArcsec,makeplot,
                                      taper, obscuration=obscuration,
                                      widthMultiplier=widthMultiplier,
                                      useCasaJinc=useCasaJinc,
                                      testOption=testOption,
                                      minlevels=minlevels,truncate=truncate,
                                      img=img, row=row, column=column,
                                      stokes='YY',plotfile=plotfile,
                                      fwhmfactor=fwhmfactor)
            fwhm = np.mean([fwhmXX,fwhmYY])
            alongScan = np.mean([alongScanXX,alongScanYY])
            sampling = np.mean([samplingXX,samplingYY])
            fittedFWHM = {}
            for f in fittedFWHMXX:
                fittedFWHM[f] = np.mean([fittedFWHMXX[f],fittedFWHMYY[f]])
        else:
            fwhm,alongScan,sampling,fittedFWHM,radiusOfNullOnPixels = \
               self.gjincBeamPredict(frequency,pixelsize,diameter,
                                     xSamplesPerBeam,xSamplingArcsec,makeplot,
                                     taper, obscuration=obscuration,
                                     widthMultiplier=widthMultiplier,
                                     useCasaJinc=useCasaJinc,
                                     testOption=testOption,
                                     minlevels=minlevels,truncate=truncate,
                                     img=img, row=row, column=column,
                                     stokes=stokes,plotfile=plotfile, 
                                     fwhmfactor=fwhmfactor)
        if (False):
            print "Theoretical primary beam FWHP = %g arcsec" % (fwhm)
            print "Sampled every %g arcsec (%f points per beam)" % (sampling,fwhm/sampling)
            print "Expected effective restoring beam = %.4f arcsec" % (alongScan)
            for f in fittedFWHM:
                print "Gaussian fit to beam (data>%.3f) = %.4f arcsec" % (f,fittedFWHM[f])
        return(alongScan,fittedFWHM[0.0])

    def gjincBeamTwoAxes(self, frequency, pixelsize, diameter, xSamplesPerBeam,
                         ySamplesPerBeam, xSamplingArcsec, ySamplingArcsec,
                         makeplot, taper=12, geometricMean=False,
                         obscuration=0.75, widthMultiplier=1.0, 
                         useCasaJinc=False, testOption=False, minlevels=[0.0], 
                         truncate=False, img=None, row=None, column=None,
                         stokes='XX',plotfile='', fwhmfactor=None):
        """
        This function calls gjincBeam for each of two axes on the sky.
        frequency: in GHz
        pixelsize: in arcsec
        diameter: in meters
        widthMultiplier: the value by which to multiply the default values of 
                         gwidth/jwidth
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function
               as the antenna beam, otherwise it uses a Gaussian
        fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
        truncate: if taper=0, sets whether to truncate Airy at the first null
                  if taper>0, sets the intensity at which to truncate Gaussian
        If xSamplingArcsec == None, then use the derived FWHM/xSamplesPerBeam
        If ySamplingArcsec == None, then use the derived FWHM/ySamplesPerBeam
        """
        if (img is not None and ((row=='auto' and column=='auto') or (row==None and column==None))):
            xrow = 'auto'
            xcolumn = None
            yrow = None
            ycolumn = 'auto'
        else:
            xrow = row
            yrow = row
            xcolumn = column
            ycolumn = column
        if (img is not None and stokes == 'both'):
            fwhmXX,alongScanXX,xSamplingXX,fittedXFWHMXX,radiusOfNullOnPixels=\
              self.gjincBeamPredict(frequency,pixelsize,diameter,
                        xSamplesPerBeam, xSamplingArcsec, makeplot, taper,
                        obscuration=obscuration,widthMultiplier=widthMultiplier,
                        useCasaJinc=useCasaJinc, testOption=testOption,
                        minlevels=minlevels,truncate=truncate,
                        img=img, row=xrow, column=xcolumn,stokes='XX',
                        plotfile=plotfile, fwhmfactor=fwhmfactor)
            fwhmXX,betweenRowsXX,ySamplingXX,fittedYFWHMXX,radiusOfNullOnPixels = \
              self.gjincBeamPredict(frequency,pixelsize, diameter, 
                                 ySamplesPerBeam, ySamplingArcsec, makeplot,
                                 taper, obscuration=obscuration,
                                 widthMultiplier=widthMultiplier,
                                 useCasaJinc=useCasaJinc, testOption=testOption,
                                 minlevels=minlevels,truncate=truncate,
                                 img=img, row=yrow, column=ycolumn,stokes='XX',
                                 plotfile=plotfile, fwhmfactor=fwhmfactor)
            fwhmYY,alongScanYY,xSamplingYY,fittedXFWHMYY,radiusOfNullOnPixels=\
              self.gjincBeamPredict(frequency,pixelsize,diameter,
                                 xSamplesPerBeam, xSamplingArcsec, makeplot, 
                                 taper, obscuration=obscuration,
                                 widthMultiplier=widthMultiplier,
                                 useCasaJinc=useCasaJinc, testOption=testOption,
                                 minlevels=minlevels,truncate=truncate,
                                 img=img, row=xrow, column=xcolumn,stokes='YY',
                                 plotfile=plotfile, fwhmfactor=fwhmfactor)
            fwhmYY,betweenRowsYY,ySamplingYY,fittedYFWHMYY,radiusOfNullOnPixels = \
              self.gjincBeamPredict(frequency,pixelsize,diameter, 
                                 ySamplesPerBeam, ySamplingArcsec, makeplot, 
                                 taper, obscuration=obscuration,
                                 widthMultiplier=widthMultiplier,
                                 useCasaJinc=useCasaJinc, testOption=testOption,
                                 minlevels=minlevels,truncate=truncate,
                                 img=img, row=yrow, column=ycolumn, stokes='YY',
                                 plotfile=plotfile, fwhmfactor=fwhmfactor)
            fwhm = np.mean([fwhmXX,fwhmYY])
            alongScan = np.mean([alongScanXX,alongScanYY])
            betweenRows = np.mean([betweenRowsXX,betweenRowsYY])
            xSampling = np.mean([xSamplingXX,xSamplingYY])
            ySampling = np.mean([ySamplingXX,ySamplingYY])
            fittedXFWHM = {}
            for f in fittedXFWHMXX:
                fittedXFWHM[f] = np.mean([fittedXFWHMXX[f],fittedXFWHMYY[f]])
            fittedYFWHM = {}
            for f in fittedYFWHMXX:
                fittedYFWHM[f] = np.mean([fittedYFWHMXX[f],fittedYFWHMYY[f]])
        else:
            fwhm,alongScan,xSampling,fittedXFWHM,radiusOfNullOnPixels = \
              self.gjincBeamPredict(frequency,pixelsize,diameter,
                                    xSamplesPerBeam, xSamplingArcsec, makeplot,
                                    taper, obscuration=obscuration,
                                    widthMultiplier=widthMultiplier,
                                    useCasaJinc=useCasaJinc, 
                                    testOption=testOption, minlevels=minlevels,
                                    truncate=truncate, img=img, row=xrow, 
                                    column=xcolumn, stokes=stokes,
                                    plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhm,betweenRows,ySampling,fittedYFWHM,radiusOfNullOnPixels = \
              self.gjincBeamPredict(frequency,pixelsize, diameter, 
                                    ySamplesPerBeam, ySamplingArcsec, makeplot,
                                    taper, obscuration=obscuration,
                                    widthMultiplier=widthMultiplier,
                                    useCasaJinc=useCasaJinc, 
                                    testOption=testOption, minlevels=minlevels,
                                    truncate=truncate, img=img, row=yrow, 
                                    column=ycolumn, stokes=stokes,
                                    plotfile=plotfile, fwhmfactor=fwhmfactor)
        if (False):
            print "Theoretical primary beam FWHP = %g arcsec" % (fwhm)
            print "Sampled every %g arcsec (%g points per beam) in X" % (xSampling,fwhm/xSampling)
            print "Sampled every %g arcsec (%g points per beam) in Y" % (ySampling,fwhm/ySampling)
            print "Expected effective restoring beam along X = %.4f arcsec" % (alongScan)
            for f in fittedXFWHM:
                print "Gaussian fit to beam along X (data>%.3f) = %.4f arcsec" % (f,fittedXFWHM[f])
            print "Expected effective restoring beam along Y = %.4f arcsec" % (betweenRows)
            for f in fittedYFWHM:
                print "Gaussian fit to beam along Y (data>%.3f) = %.4f arcsec" % (f,fittedYFWHM[f])
        f = minlevels[0]
        geometricMeanDiameter = (alongScan*betweenRows)**0.5
        geometricMeanFit = (fittedXFWHM[f]*fittedYFWHM[f])**0.5
        if (False):
            print "Geometric mean of expected beam= %g arcsec" % (geometricMeanDiameter)
            print "Geometric mean of Gaussian fit = %g arcsec" % (geometricMeanFit)
        if (geometricMean):
            return(geometricMeanDiameter, geometricMeanFit)
        else:
            return(np.min([alongScan, betweenRows]),
                   np.max([alongScan, betweenRows]), geometricMeanDiameter, geometricMeanFit)

    def sfBeamOneAxis(self, frequency, pixelsize, diameter, xSamplesPerBeam,
                      xSamplingArcsec, convsupport, makeplot, m=0, taper=12,
                      obscuration=0.75, cmult=1.0,coffset=0.0,xmult=1.0,
                      alpha=1, testOption=False, minlevels=[0],truncate=False,
                      img=None,row=None,column=None,
                      stokes='XX',plotfile='',fwhmfactor=None):
        """
        This function calls sfBeam for one axis on the sky.
        frequency: in GHz
        pixelsize: in arcsec
        diameter: in meters
        convsupport: radius in pixels, default=-1 --> 3 pixels: a support width of 7 points
        m: The value to pass as m & n to scipy.special.pro_ang1 (0: alpha=0 in VLA memo 156)
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function truncated at the first null
               as the antenna beam, otherwise it uses a Gaussian.
        fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
        obscuration: diameter in m to pass to au.primaryBeamArcsec
        minlevels: a list of values above which to perform 1D Gaussian fits
        truncate: if taper=0, sets whether to truncate the Airy at the first null
                 if taper>0, sets the intensity level at which to truncate the Gaussian
        img: if not none, then use a row or column from this image as the beam model
        row: the row of img to use as the starting beam profile model
        column: the column of img to use as the starting beam profile model
            if row and column are both 'auto', then it will use the mean of the
            peak row and peak column, shifted so that their peaks align
        If xSamplingArcsec == None, then use the derived FWHM/xSamplesPerBeam
        Returns:
          the FWHM of the predicted restoring beam
          the FWHM of a Gaussian fit to the restoring beam
        """
#        support=6, pixelsPerBeam=4, fittedbeam=24.558
#        support=3, pixelsPerBeam=4, fittedbeam=18.811
        if (stokes == 'both' and img is not None):
            fwhmXX,alongScanXX,samplingXX,fittedFWHMXX = \
                self.sfBeamPredict(frequency,pixelsize,diameter,xSamplesPerBeam,
                                   xSamplingArcsec, convsupport, makeplot, m, 
                                   taper, obscuration=obscuration, cmult=cmult,
                                   coffset=coffset,xmult=xmult,alpha=alpha,
                                   testOption=testOption,minlevels=minlevels,
                                   truncate=truncate,img=img,row=row,
                                   column=column, stokes='XX',plotfile=plotfile,
                                   fwhmfactor=fwhmfactor)
            fwhmYY,alongScanYY,samplingYY,fittedFWHMYY = \
                self.sfBeamPredict(frequency,pixelsize,diameter,xSamplesPerBeam,
                                   xSamplingArcsec, convsupport, makeplot, m, 
                                   taper, obscuration=obscuration,cmult=cmult,
                                   coffset=coffset,xmult=xmult,alpha=alpha,
                                   testOption=testOption,minlevels=minlevels,
                                   truncate=truncate,img=img,row=row,
                                   column=column, stokes='YY',plotfile=plotfile,
                                   fwhmfactor=fwhmfactor)
            fwhm = np.mean([fwhmXX,fwhmYY])
#            print "sfBeamOneAxis: shape(alongScanXX) = ", np.shape(alongScanXX)
            alongScan = np.mean([alongScanXX,alongScanYY])
            sampling = np.mean([samplingXX,samplingYY])
            fittedFWHM = {}
            for f in fittedFWHMXX:
                fittedFWHM[f] = np.mean([fittedFWHMXX[f],fittedFWHMYY[f]])
        else:
            fwhm,alongScan,sampling,fittedFWHM = \
                self.sfBeamPredict(frequency,pixelsize,diameter,xSamplesPerBeam,
                                   xSamplingArcsec, convsupport, makeplot, m, 
                                   taper, obscuration=obscuration, cmult=cmult,
                                   coffset=coffset,xmult=xmult,alpha=alpha,
                                   testOption=testOption,minlevels=minlevels,
                                   truncate=truncate,img=img,row=row,
                                   column=column, stokes=stokes,
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
        if (False):
            print "Theoretical primary beam FWHP = %g arcsec" % (fwhm)
            print "Sampled every %g arcsec (%f points per beam)" % (sampling,fwhm/sampling)
            print "Expected effective restoring beam = %.4f arcsec" % (alongScan)
            for f in fittedFWHM:
                print "Gaussian fit to beam (data>%.3f) = %.4f arcsec" % (f,fittedFWHM[f])
        return(alongScan, fittedFWHM[0.0])

    def sfBeamTwoAxes(self, frequency, pixelsize, diameter, xSamplesPerBeam,
                      ySamplesPerBeam, xSamplingArcsec, ySamplingArcsec,
                      convsupport, makeplot, m=0, taper=12, geometricMean=False,
                      obscuration=0.75,cmult=1.0,coffset=0.0,xmult=1.0,alpha=1,
                      testOption=False,minlevels=[0.0],truncate=False,
                      img=None,row=None,column=None,stokes='XX',plotfile='',
                      fwhmfactor=None):
        """
        This function calls sfBeam for each of two axes on the sky.
        frequency: in GHz
        pixelsize: in arcsec
        diameter: in meters
        convsupport: radius in pixels, default=-1 --> 3 pixels: a support
                     width of 7 points
        m: The value to pass as m & n to scipy.special.pro_ang1 (0: alpha=0
           in VLA memo 156)
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function truncated at the first null
               as the antenna beam, otherwise it uses a Gaussian.
        fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
        obscuration: diameter in m to pass to au.primaryBeamArcsec
        geometricMean: if True, return only the mean beamsize; otherwise, return
             minorAxis,majorAxis,geometricMean (if the sampling is provided in
             both axes)
        truncate: if taper=0, sets whether to truncate the Airy at the first null
                  if taper>0, sets the intensity level at which to truncate the Gaussian
        row: the row of img to use as the starting beam profile model
        column: the column of img to use as the starting beam profile model
            if row and column are both 'auto', then it will use the mean of the
            peak row and peak column, shifted so that their peaks align

        If xSamplingArcsec == None, then use the derived FWHM/xSamplesPerBeam
        If ySamplingArcsec == None, then use the derived FWHM/ySamplesPerBeam
        Returns:
        If geometricMean=True:
          the FWHM of the restoring beam
          the FWHM of a Gaussian fit to the restoring beam
        If geometricMean=False:
          the minor axis of the restoring beam
          the major axis of the restoring beam
          the geometric mean of the restoring beam
          the geometric mean of the FWHM of a Gaussian fit to the restring beam
        """
        if (img is not None and (row==None and column==None)):
            xrow = 'auto'
            xcolumn = None
            yrow = None
            ycolumn = 'auto'
        else:
            xrow = row
            yrow = row
            xcolumn = column
            ycolumn = column
        if (img is not None and stokes == 'both'):
            fwhmXX,alongScanXX,xSamplingXX,fittedXFWHMXX = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   xSamplesPerBeam, xSamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   obscuration=obscuration,
                                   cmult=cmult,coffset=coffset,xmult=xmult,
                                   alpha=alpha, testOption=testOption,
                                   minlevels=minlevels,truncate=truncate,
                                   img=img,row=xrow,column=xcolumn,stokes='XX',
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhmYY,alongScanYY,xSamplingYY,fittedXFWHMYY = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   xSamplesPerBeam, xSamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   obscuration=obscuration,
                                   cmult=cmult,coffset=coffset,xmult=xmult,
                                   alpha=alpha, testOption=testOption,
                                   minlevels=minlevels,truncate=truncate,
                                   img=img,row=xrow,column=xcolumn,stokes='YY',
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhm = np.mean([fwhmXX,fwhmYY])
            alongScan = np.mean([alongScanXX,alongScanYY])
            xSampling = np.mean([xSamplingXX,xSamplingYY])
            fittedXFWHM = {}
            for f in fittedXFWHMXX:
                fittedXFWHM[f] = np.mean([fittedXFWHMXX[f],fittedXFWHMYY[f]])

            fwhmXX,betweenRowsXX,ySamplingXX,fittedYFWHMXX = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   ySamplesPerBeam,ySamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   showPrimaryBeamEquation=False,
                                   obscuration=obscuration,
                                   cmult=cmult,coffset=coffset,xmult=xmult,
                                   alpha=alpha,testOption=testOption,
                                   minlevels=minlevels,truncate=truncate,
                                   img=img,row=yrow,column=ycolumn,stokes='XX',
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhmYY,betweenRowsYY,ySamplingYY,fittedYFWHMYY = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   ySamplesPerBeam,ySamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   showPrimaryBeamEquation=False,
                                   obscuration=obscuration,
                                   cmult=cmult,coffset=coffset,xmult=xmult,
                                   alpha=alpha,testOption=testOption,
                                   minlevels=minlevels,truncate=truncate,
                                   img=img,row=yrow,column=ycolumn,stokes='YY',
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhm = np.mean([fwhmXX,fwhmYY])
            betweenRows = np.mean([betweenRowsXX,betweenRowsYY])
            ySampling = np.mean([ySamplingXX,ySamplingYY])
            fittedYFWHM = {}
            for f in fittedYFWHMXX:
                fittedYFWHM[f] = np.mean([fittedYFWHMXX[f],fittedYFWHMYY[f]])
        else:
            fwhm,alongScan,xSampling,fittedXFWHM = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   xSamplesPerBeam, xSamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   obscuration=obscuration,cmult=cmult,
                                   coffset=coffset,xmult=xmult,alpha=alpha, 
                                   testOption=testOption, minlevels=minlevels,
                                   truncate=truncate, img=img,row=xrow,
                                   column=xcolumn, stokes=stokes,
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
            fwhm,betweenRows,ySampling,fittedYFWHM = \
                self.sfBeamPredict(frequency,pixelsize,diameter,
                                   ySamplesPerBeam,ySamplingArcsec,
                                   convsupport, makeplot, m, taper,
                                   showPrimaryBeamEquation=False,
                                   obscuration=obscuration, cmult=cmult,
                                   coffset=coffset,xmult=xmult, alpha=alpha,
                                   testOption=testOption, minlevels=minlevels,
                                   truncate=truncate,img=img,row=yrow,
                                   column=ycolumn, stokes=stokes,
                                   plotfile=plotfile,fwhmfactor=fwhmfactor)
        f = minlevels[0]
        geometricMeanDiameter = (alongScan*betweenRows)**0.5
        geometricMeanFit = (fittedXFWHM[f]*fittedYFWHM[f])**0.5
        if (False):
            print "Theoretical primary beam FWHP = %g arcsec" % (fwhm)
            print "Sampled every %g arcsec (%g points per beam) in X" % (xSampling,fwhm/xSampling)
            print "Sampled every %g arcsec (%g points per beam) in Y" % (ySampling,fwhm/ySampling)
            print "Expected effective restoring beam along X = %.10f arcsec" % (alongScan)
            for f in fittedXFWHM:
                print "Gaussian fit to beam along X (data>%.3f) = %.10f arcsec" % (f,fittedXFWHM[f])
            print "Expected effective restoring beam along Y = %.10f arcsec" % (betweenRows)
            for f in fittedYFWHM:
                print "Gaussian fit to beam along Y (data>%.3f) = %.10f arcsec" % (f,fittedYFWHM[f])
            print "Geometric mean of expected beam= %g arcsec" % (geometricMeanDiameter)
            print "Geometric mean of Gaussian fit = %g arcsec" % (geometricMeanFit)
        if (geometricMean):
            return(geometricMeanDiameter, geometricMeanFit)
        else:
            return(np.min([alongScan, betweenRows]),
                   np.max([alongScan, betweenRows]), geometricMeanDiameter, geometricMeanFit)

    def rootAiryIntensity(self, myxaxis, epsilon=0.0, showplot=False):
        """
        This function computes 2*J1(x)/x, which can be squared to get an Airy disk.
        myxaxis: the x-axis values to use
        epsilon: radius of central hole in units of the dish diameter
        """
        if (epsilon > 0):
            a = (2*scipy.special.j1(myxaxis)/myxaxis - \
                 epsilon**2*2*scipy.special.j1(myxaxis*epsilon)/(epsilon*myxaxis)) / (1-epsilon**2)
        else:
            a = 2*scipy.special.j1(myxaxis)/myxaxis  # simpler formula for epsilon=0
        if (showplot):
            pb.clf()
            pb.plot(myxaxis, a**2, 'b-', myxaxis, simple**2, 'r-')
            pb.xlim([-20,20])
            pb.draw()
        return(a)
    
    def buildAiryDisk(self, fwhm, xaxisLimitInUnitsOfFwhm, convolutionPixelSize,
                      truncate=False, obscuration=0.75,diameter=12.0):
        """
        This function computes the Airy disk (with peak of 1.0) across a grid of points
        specified in units of the FWHM of the disk.
        fwhm: a value in arcsec
        xaxisLimitInUnitsOfFwhm: an integer or floating point unitless value
        truncate: if True, truncate the function at the first null (on both sides)
        obscuration: central hole diameter (meters)
        diameter: dish diameter (meters)
          obscuration and diameter are used to compute the blockage ratio (epsilon)
          and its effect on the pattern
        """
        epsilon = obscuration/diameter
#        print "Using epsilon = %f" % (epsilon)
        myxaxis = np.arange(-xaxisLimitInUnitsOfFwhm*fwhm,
                            xaxisLimitInUnitsOfFwhm*fwhm+0.5*convolutionPixelSize,
                            convolutionPixelSize)
        a = (self.rootAiryIntensity(myxaxis, epsilon))**2
        # Scale the Airy disk to the desired FWHM, and recompute on finer grid
        airyfwhm = self.findFWHM(myxaxis,a)
        ratio = fwhm/airyfwhm
        myxaxis = np.arange(-xaxisLimitInUnitsOfFwhm*fwhm/ratio,
                            (xaxisLimitInUnitsOfFwhm*fwhm+0.5*convolutionPixelSize)/ratio,
                            convolutionPixelSize/ratio)
        a = self.rootAiryIntensity(myxaxis, epsilon)
        if (truncate):
            a = self.trunc(a)
        a = a**2
        myxaxis *= ratio
        return(myxaxis, a)

    def sfBeamPredict(self, frequency, pixelsize=10, diameter=12.0, 
                      samplingFactor=2.5, samplingArcsec=None, convsupport=-1, 
                      makeplot=False, m=0, taper=10, showPrimaryBeamEquation=False,
                      obscuration=0.75, convolutionPixelSize=0.02, cmult=1.0,
                      coffset=0.0,xmult=1.0,alpha=1, testOption=False,
                      minlevels=[0.0], truncate=False,img=None,row=None,
                      column=None, stokes='XX',plotfile='',returnProfile=False,
                      fwhmfactor=None):
        """
        This function computes the effective restoring beam obtained from
        sd_imaging when using the SF gridding kernel.
        
        frequency: floating point number in GHz (no units) or a string with units
        pixelsize: of image = floating point number in arcseconds (no units)
        diameter: the diameter of the single dish antenna in meters (no units)
        samplingFactor: the number of sampled points per telescope FWHM
        samplingArcsec: if not None, then use this value instead of
               FWHM/samplingFactor
        convsupport: radius in pixels, default=-1 --> 3 pixels: a support
               width of 7 points
        m: The value to pass as m & n to scipy.special.pro_ang1
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec.
               if zero, then it uses an Airy function as the antenna beam,
               otherwise it uses a Gaussian
        fwhmfactor: if specified, pass this to primaryBeamArcsec, overriding taper
        obscuration: diameter in m to pass to au.primaryBeamArcsec
        convolutionPixelSize: size of pixels in the model (should be << samplingArcsec)
        alpha: the exponent of the weighting function: (1-nu**2)**alpha
        minlevels: a list of values above which to perform 1D Gaussian fits
        truncate: if taper=0, sets whether to truncate the Airy at first null
                  if taper > 0, sets the intensity level to truncate Gaussian

        Returns:
        if returnProfile == False, then 4 values (all in arcsec)
           fwhm: the FWHM size of the theoretical beam
           myfwhm: the effective restoring beam
           samplingArcsec: the sampling rate
           fittedFWHM: the Gaussian-fitted restoring beam
        If returnProfile == True, then 5 values:
           myxaxis: x-axis (angle)
           mysf: the spheroidal function used (intensity)
           result: y-axis after convolution with SF and the boxcar (intensity)
           samplingArcsec: the sampling rate
           myfwhm: the effective restoring beam
    
        - Todd Hunter
        """
        c = 5.356*np.pi/2.0 # value obtained by matching Fred's grdsf.f output with scipy(m=0,n=0)
        if (convsupport == -1):
            convsupport = 3
        supportwidth = (convsupport*cmult + coffset)   
        n = m  # For convolution, n=m are the only functions we care about.
        if (type(frequency) == str):
            frequency = parseFrequencyArgument(frequency)*1e-9
        if (img is not None):
            print "Using beam profile from image: extractCutFromImage('%s', row=%s, column=%s, stokes='%s', interpolate=True)" % (img, str(row), str(column), str(stokes))
            myxaxis, myfunction, row, column, imgfreq = extractCutFromImage(img,row=row,column=column,stokes=stokes,interpolate=True)
            if (frequency < 2000):
                frequencyHz = frequency*1.0e9
            else:
                frequencyHz = frequency
            if (imgfreq > 0):
                imgScaling = imgfreq/frequencyHz
                myxaxis *= imgScaling
                print "Scaling xaxis by %f/%f=%f" % (imgfreq, frequencyHz, imgScaling)
            fwhm = self.findFWHM(myxaxis,myfunction)
            if (samplingArcsec is None):
                samplingArcsec = fwhm/samplingFactor
#                print "Set samplingArcsec to %f/%f=%f" % (fwhm,samplingFactor,samplingArcsec)
            if (samplingArcsec < 5*convolutionPixelSize and samplingArcsec > 0):
                convolutionPixelSize = samplingArcsec / 5.0
        else:
            fwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter, taper=taper,
                                     showEquation=showPrimaryBeamEquation, 
                                     obscuration=obscuration,fwhmfactor=fwhmfactor)
            if (samplingArcsec is None):
                samplingArcsec = fwhm/samplingFactor
#                print "Set samplingArcsec to %f/%f=%f" % (fwhm,samplingFactor,samplingArcsec)
            if (samplingArcsec < 5*convolutionPixelSize and samplingArcsec > 0):
                convolutionPixelSize = samplingArcsec / 5.0
            if (taper < 0.1):
                print "Using Airy disk truncated at first null instead of Gaussian"
                myxaxis, myfunction = self.buildAiryDisk(fwhm, 3, convolutionPixelSize, truncate=truncate,
                                                         diameter=diameter, obscuration=obscuration)
            else:
                myxaxis = np.arange(-3*fwhm,3*fwhm+0.5*convolutionPixelSize, convolutionPixelSize)
                myfunction = self.gauss(myxaxis,[fwhm,truncate])
        initialFWHM = self.findFWHM(myxaxis,myfunction)
        # find indices of points less than +-35" (for pixelsize=10" and convsupport=3)
        # from VLA scientific memo 129 section 2.  We want function C_m to vanish for
        #  |u| > m delta_u/2,  where m = support width and delta_u = grid size
#        print "myxaxis,supportwidth,pixelsize,xmult = ", myxaxis,supportwidth,pixelsize,xmult
        sfaxis = myxaxis/float(supportwidth*pixelsize*xmult)

        # find indices of points less than +-30" (for pixelsize=10" and convsupport=3)
#        sfaxis = myxaxis/float((supportwidth-1)*pixelsize/2.0)
        indices = np.where(abs(sfaxis)<1)
        centralRegion = sfaxis[indices]
        centralRegionY = self.spheroidalWaveFunction(centralRegion, m=m, n=n, c=c, alpha=alpha)
        mysf = np.zeros(len(myxaxis))
        mysf[indices] += centralRegionY/np.max(centralRegionY)
        if (testOption):
            # emulate SDGrid.cc
            convSampling = 100
            convSize = convSampling*(4*convsupport+2)
            convFunc = np.zeros(convSize)
            nu = np.array(range(convSampling*convsupport)) / float(convsupport*convSampling)
            for i in range(len(nu)):
                convFunc[i] = self.spheroidalWaveFunction(nu[i], m=m, n=n, c=c, alpha=alpha)
            convFuncX = np.array(range(convSize)) / float(convsupport*convSampling)
            if (False):
                pb.clf()
                pb.plot(convFuncX,convFunc,'b-')
            s = 1
            convFuncX = np.append(-convFuncX[::-1],convFuncX[1:])
            convFuncX *= convsupport*pixelsize
            reversed = convFunc[::-1]
            convFunc = np.append(reversed[:-s-1],convFunc[s:])
            convFunc = np.append(np.zeros(s), convFunc)
            convFunc = np.append(convFunc, np.zeros(s))
            centralRegion = convFuncX
            myfunction = self.gauss(convFuncX,[fwhm,truncate])
            if (False):
                pb.plot(convFuncX,convFunc,'g-', convFuncX,myfunction,'k-')
                pb.ylim([-0.1,1.1])
                pb.hold(True)
            myxaxis = convFuncX
            mysf = convFunc
            centralRegionY = convFunc

#        print "max=%g, myxaxis = " % (np.max(myxaxis)), myxaxis
        sfFWHM = self.findFWHM(myxaxis,mysf)
        # convolve beam with SF gridding function
        gridded = spsig.convolve(myfunction, centralRegionY, mode='same')

        # normalize
        gridded = gridded/np.max(gridded)
#        print "FWHM of SF = %f,  SF/sampling=%f,   SF/pixel=%f" % (sfFWHM,sfFWHM/samplingArcsec,sfFWHM/pixelsize)
        griddedFWHM= self.findFWHM(myxaxis,gridded)
        myboxcar = self.buildBoxcar(myxaxis, samplingArcsec)
        boxcarFWHM = self.findFWHM(myxaxis,myboxcar)
        # convolve beam with sampling boxcar
        result = spsig.convolve(gridded, myboxcar, mode='same')
        # normalize
        result /= np.max(result)
        myfwhm = self.findFWHM(myxaxis,result)
        fittedFWHM = {}
        for minlevel in minlevels:
            # Fit a normal Gaussian, not a truncated one!
            fittedFWHM[minlevel], junk = self.gaussfit(myxaxis,result,minlevel=minlevel,truncate=False)
        if (makeplot):
            pb.clf()
            desc = pb.subplot(111)
            halfwidthOfPlot = 2*fwhm
            pb.plot(myxaxis,myfunction,'k',myxaxis,mysf,'b',myxaxis,myboxcar,'g',
                    myxaxis,gridded,'c', myxaxis,result,'r',
                    [-halfwidthOfPlot,halfwidthOfPlot],[0.5,0.5],'k:',
                    myxaxis,self.gauss(myxaxis,fittedFWHM[0.0]),'m')
            pb.xlabel('Offset (arcsec)')
            pb.xlim([-halfwidthOfPlot, halfwidthOfPlot])
            desc.yaxis.set_major_locator(MultipleLocator(0.1))
            desc.xaxis.set_minor_locator(MultipleLocator(2))
            pb.ylim([-0.02,1.02])
            mysize = 11
            if (img is not None):
                pb.text(0.5,1.06,os.path.basename(img), color='k', transform=desc.transAxes, ha='center')
                if (row is not None):
                    pb.text(0.021,0.95,'using image cut as beam (row=%d)'%(row),color='k', transform=desc.transAxes, size=mysize)
                else:
                    pb.text(0.021,0.95,'using image cut as beam (column=%d)'%(column),color='k', transform=desc.transAxes, size=mysize)
                pb.text(0.021,0.90,'unscaled FWHM of cut = %.3f"' % (initialFWHM/imgScaling), color='k', transform=desc.transAxes,size=mysize) 
            else:
                pb.text(0.021,0.95,'desired PB FWHM = %.2f"'%(fwhm), color='k', transform=desc.transAxes,size=mysize)
                if (truncate != False):
                    pb.text(0.021,0.90,'truncated at %.2f'%(truncate), color='k', transform=desc.transAxes,size=mysize)
                else:
                    pb.text(0.021,0.90,'not truncated', color='k', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.85,'achieved PB FWHM = %.3f"'%(initialFWHM), color='k', transform=desc.transAxes, size=mysize)
            pb.text(0.651,0.95,'pixel spacing = %.2f"'%(pixelsize), transform=desc.transAxes, size=mysize)
            pb.text(0.651,0.90,'frequency = %.2f GHz'%(frequency), transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.80,'SF FWHM = %.2f"'%(sfFWHM), color='b', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.75,'gridded FWHM = %.2f"'%(griddedFWHM), color='c', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.70,'desired sampling = %.2f"'%(samplingArcsec), color='g', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.65,'achieved sampling = %.2f"'%(boxcarFWHM), color='g', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.60,'final FWHM = %.2f"'%(myfwhm), color='r', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.55,'Gaussfit FWHM = %.2f"'%(fittedFWHM[0.0]), color='m', transform=desc.transAxes, size=mysize)
            pb.title('SF: m=%d, n=%d, c=%.2f$\pi$/2=%f' % (m,n,c*2/np.pi,c))
            pb.draw()
            if (plotfile == ''):
                png = 'sfBeam.png'
            else:
                png = plotfile
            pb.savefig(png)
            print "Plot left in %s" % (png)
        if (returnProfile):
            return(myxaxis, mysf, result, samplingArcsec, myfwhm)
        else:
            return(fwhm, myfwhm, samplingArcsec, fittedFWHM)
        
    def sfBeamSequence(self, c=7*np.pi/2., nvals=7):
        """
        Plots a sequence of prolate spheroidal wave functions at a given value
        of c for 7 values of m=n, starting at zero.
        """
        inc = 0.001
        x = np.arange(-1+inc,1,inc)
        pb.clf()
        desc = pb.subplot(111)
        pb.hold(True)
        col = ['k','b','c','g','y','r','m']
        col += col
        for m in range(nvals):
            n = m
            y = self.spheroidalWaveFunction(x,m=m,n=m,c=c)
            y = y/np.max(y)
            pb.plot(x,y,col[m])
#  Fred Schwab and I spot-checked values here with his Mathematica code.
#            for i in range(len(x)):
#                print "x[%d]=%f, y[%d]=%f" % (i,x[i],i,y[i])
            pb.text(0.1,0.9-m*0.1,'m=%d'%m,transform=desc.transAxes,color=col[m])
        pb.title('scipy.special.pro_ang1_cv(m=n, c=%.2f)' % (c))
        pb.draw()
        png = 'sfBeamSequence.png'
        pb.savefig(png)
        print "Plot left in %s" % (png)
    
    def gjincBeamPredict(self, frequency, pixelsize=10, diameter=12.0, 
                         samplingFactor=2.5, samplingArcsec=None, 
                         makeplot=False, taper=10, obscuration=0.75,
                         widthMultiplier=1.0, convolutionPixelSize=0.02, 
                         useCasaJinc=False, testOption=False, minlevels=[0],
                         truncate=False, img=None, row=None,
                         column=None, stokes='XX',plotfile='',
                         returnProfile=False, fwhmfactor=None):
        """
        This function computes the effective restoring beam obtained from
        sd_imaging when using the GJINC gridding kernel assuming the GJINC
        specific parameters are left at their default values.
        
        frequency: floating point number in GHz (no units) or string with units
        pixelsize: floating point number in arcseconds (no units)
        diameter: the diameter of the single dish antenna in meters (no units)
        samplingFactor: the number of sampled points per telescope FWHM
        samplingArcsec: if given, then use this instead of FWHM/samplingFactor
        taper: the illumination taper in dB to pass to au.primaryBeamArcsec
               if zero, then it uses an Airy function as the antenna beam,
               otherwise it uses a Gaussian
        obscuration: diameter in m to pass to au.primaryBeamArcsec
        widthMultiplier: the value by which to multiply the default values of 
                         gwidth/jwidth
        convolutionPixelSize: size of pixels in the model (if samplingArcsec 
                              is smaller than 5 times this default value, then 
                              the default value will be reduced accordingly)
        minlevels: a list of values above which to perform 1D Gaussian fits
        truncate: if taper=0, sets whether to truncate Airy at the first null
                  if taper>0, sets the intensity level at which to truncate 
                              the Gaussian

        Returns:
        if returnProfile == False, then 4 values (all in arcsec)
            the FWHM size of the theoretical beam,
            the effective restoring beam,
            the sampling rate,
            the 1D Gaussian-fitted FWHM
            the radius of the null of the GJinc function (in image pixels)
        If returnProfile == True, then 5 values:
           myxaxis: x-axis (angle)
           mygjinc: the function used (intensity)
           result: y-axis after convolution w/ GJinc and the boxcar (intensity)
           samplingArcsec: the sampling rate
           myfwhm: the effective restoring beam (dictionary keyed by minlevel, e.g. 0)
           radiusOfNullInPixels: the radius of the null of the GJinc function 
                                 (in image pixels)
    
        - Todd Hunter
        """
        if (type(frequency) == str):
            frequency = parseFrequencyArgument(frequency)*1e-9
        fwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter, 
                                 taper=taper, obscuration=obscuration, 
                                 showEquation=False, fwhmfactor=fwhmfactor)
        if (samplingArcsec is None):
            samplingArcsec = fwhm/(1.0*samplingFactor)
        if (samplingArcsec < 5*convolutionPixelSize and samplingArcsec > 0):
            convolutionPixelSize = samplingArcsec / 5.0
        jwidth = 1.55*pixelsize*widthMultiplier
        # casa default gwidth=-1, which means 2.52*sqrt(log(2)) * pixel
        gwidth = 2.52*pixelsize*widthMultiplier*(np.log(2)**0.5)
        if (img is not None):
#            print "Using beam profile from image"
            myxaxis, myfunction, row, column, imgfreq = extractCutFromImage(img,row=row,column=column,stokes=stokes,interpolate=True)
            frequencyHz = frequency*1.0e9
            if (imgfreq != 0):
                imgScaling = imgfreq/frequencyHz
                myxaxis *= imgfreq/frequencyHz
            npixels = len(myxaxis)
#            print "Peak=%f at x=%f" % (np.max(myfunction),myxaxis[np.argmax(myfunction)])
        elif (taper < 0.1):
            print "Using Airy disk truncated at first null instead of Gaussian"
            myxaxis, myfunction = self.buildAiryDisk(fwhm, 3, convolutionPixelSize, truncate=truncate,
                                                     diameter=diameter, obscuration=obscuration)
        else:
            myxaxis = np.arange(-3*fwhm,3*fwhm+0.5*convolutionPixelSize, convolutionPixelSize)
            myfunction = self.gauss(myxaxis,[fwhm,truncate])
        convSize = len(myxaxis)

        # for plotting purposes only
        initialFWHM = self.findFWHM(myxaxis,myfunction)
        casajinc = self.grdjinc1(myxaxis, jwidth, normalize=False)
        myjinc = self.jinc(myxaxis, jwidth)
        jincFWHM = self.findFWHM(myxaxis,myjinc)
        mygjincGauss = self.gjincGauss(myxaxis, gwidth)
        gjincGaussFWHM = self.findFWHM(myxaxis,mygjincGauss)

        mygjinc = self.trunc(self.gjinc(myxaxis, gwidth=gwidth, jwidth=jwidth, useCasaJinc=useCasaJinc, normalize=False))
        edgePixel = np.where(mygjinc > 0)[0][0]
        centerPixel = len(mygjinc)/2
        widthInPixels = 2*(centerPixel-edgePixel)
        print "gjincBeamPredict: radiusOfNullInPixels = (%d-%d)*%f/%f" % (centerPixel,edgePixel,convolutionPixelSize,pixelsize)
        radiusOfNullInPixels = (centerPixel-edgePixel)*convolutionPixelSize/pixelsize
        
        gjincFWHM = self.findFWHM(myxaxis, mygjinc)
        gridded = spsig.convolve(myfunction, mygjinc, mode='same')
        # normalize
        gridded /= np.max(gridded)
        griddedFWHM = self.findFWHM(myxaxis,gridded)
        myboxcar = self.buildBoxcar(myxaxis, samplingArcsec)
        boxcarFWHM = self.findFWHM(myxaxis, myboxcar)
        result = spsig.convolve(gridded, myboxcar, mode='same')
        # normalize
        result /= np.max(result)
        myfwhm = self.findFWHM(myxaxis,result)
        fittedFWHM = {}
        for minlevel in minlevels:
            # Fit a normal Gaussian, not a truncated one!
            fittedFWHM[minlevel], junk = self.gaussfit(myxaxis,result,minlevel=minlevel,truncate=False)
        if (makeplot):
            pb.clf()
            desc = pb.subplot(111)
            halfwidthOfPlot = 2*fwhm
            pb.plot(myxaxis,myfunction,'k', myxaxis,myjinc,'m', #  myxaxis,casajinc,'k',
                    myxaxis,mygjincGauss,'c', myxaxis,mygjinc,'b',
                    myxaxis,myboxcar,'g' ,myxaxis,gridded,'y', myxaxis,result,'r',
                    [-halfwidthOfPlot,halfwidthOfPlot],[0.5,0.5],'k:',
                    myxaxis,self.gauss(myxaxis,fittedFWHM[0.0]),'m')
            pb.xlabel('Offset (arcsec)')
            pb.xlim([-halfwidthOfPlot,halfwidthOfPlot])
            desc.yaxis.set_major_locator(MultipleLocator(0.1))
            desc.xaxis.set_minor_locator(MultipleLocator(2))
            mysize = 11
            pb.ylim([-0.1,1.02])
            pb.text(0.651,0.95,'pixel spacing = %.2f"'%(pixelsize), transform=desc.transAxes, size=mysize)
            pb.text(0.651,0.90,'frequency = %.2f GHz'%(frequency), transform=desc.transAxes, size=mysize)
            if (img is not None):
                pb.text(0.5,1.06,os.path.basename(img), color='k', transform=desc.transAxes, ha='center')
                if (row is not None):
                    pb.text(0.021,0.95,'using image cut as beam (row=%d)'%(row),color='k', transform=desc.transAxes,size=mysize)
                else:
                    pb.text(0.021,0.95,'using image cut as beam  (column=%d)'%(column),color='k', transform=desc.transAxes,size=mysize)
                pb.text(0.021,0.90,'unscaled FWHM of image = %.2f"' % (initialFWHM/imgScaling), color='k', transform=desc.transAxes,size=mysize) 
            else:
                pb.text(0.021,0.95,'desired PB FWHM = %.2f'%(fwhm), color='k', transform=desc.transAxes, size=mysize)
                if (truncate != False):
                    pb.text(0.021,0.90,'truncated at %.2f"'%(truncate), color='k', transform=desc.transAxes, size=mysize)
                else:
                    pb.text(0.021,0.90,'not truncated', color='k', transform=desc.transAxes, size=mysize)
            pb.text(0.021,0.85,'achieved PB FWHM = %.2f"'%(initialFWHM), color='k', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.80,'Jinc FWHM = %.2f"'%(jincFWHM), color='m', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.75,'Gauss FWHM = %.2f"'%(gjincGaussFWHM), color='c', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.70,'GJinc FWHM = %.2f"'%(gjincFWHM), color='b', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.65,'gridded FWHM = %.2f"'%(griddedFWHM), color='y', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.60,'desired sampling = %.2f"'%(samplingArcsec), color='g', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.55,'sampling = %.2f"'%(boxcarFWHM), color='g', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.50,'final FWHM = %.2f"'%(myfwhm), color='r', transform=desc.transAxes,size=mysize)
            pb.text(0.021,0.45,'Gaussfit FWHM = %.2f"'%(fittedFWHM[0.0]), color='m', transform=desc.transAxes,size=mysize)
            pb.title('GJinc: jwidth=%f, gwidth=%f' % (jwidth, gwidth))
            pb.draw()
            if (plotfile == ''):
                png = 'gjincBeam.png'
            else:
                png = plotfile
            pb.savefig(png)
            print "Plot left in %s" % (png)
        if (returnProfile):
            return(myxaxis, mygjinc, result, samplingArcsec, fittedFWHM, radiusOfNullInPixels)
        else:
            return(fwhm, myfwhm, samplingArcsec, fittedFWHM, radiusOfNullInPixels)

def effectiveTaper(fwhmFactor=1.16, diameter=12, obscuration=0.75, 
                   use2007formula=True):
    """
    The inverse of (Baars formula multiplied by the central
    obstruction factor).  Converts an observed value of the constant X in
    the formula FWHM=X*lambda/D into a taper in dB (positive value).
    if use2007formula == False, use Equation 18 from ALMA Memo 456     
    if use2007formula == True, use Equation 4.13 from Baars 2007 book
    -- Todd Hunter
    """
    cOF = centralObstructionFactor(diameter, obscuration)
    if (fwhmFactor < 1.02 or fwhmFactor > 1.22):
        print "Invalid fwhmFactor (1.02<fwhmFactor<1.22)"
        return
    if (baarsTaperFactor(10,use2007formula)*cOF<fwhmFactor):
        increment = 0.01
        for taper_dB in np.arange(10,10+increment*1000,increment):
            if (baarsTaperFactor(taper_dB,use2007formula)*cOF-fwhmFactor>0): break
    else:
        increment = -0.01
        for taper_dB in np.arange(10,10+increment*1000,increment):
            if (baarsTaperFactor(taper_dB,use2007formula)*cOF-fwhmFactor<0): break
    return(taper_dB)

def baarsTaperFactor(taper_dB, use2007formula=True):
    """
    Converts a taper in dB to the constant X
    in the formula FWHM=X*lambda/D for the parabolic illumination pattern.
    We assume that taper_dB comes in as a positive value.
    use2007formula:  False --> use Equation 18 from ALMA Memo 456.
                     True --> use Equation 4.13 from Baars 2007 book
    - Todd Hunter
    """
    tau = 10**(-0.05*taper_dB)
    if (use2007formula):
        return(1.269 - 0.566*tau + 0.534*(tau**2) - 0.208*(tau**3))
    else:
        return(1.243 - 0.343*tau + 0.12*(tau**2))

def goldsmithTaperFactor(taper_dB):
    """
    Equation 67 from Goldsmith 2002 single dish summer school lecture book.
    Converts a taper in dB to the constant X in the formula FWHM=X*lambda/D for
    Gaussian illumination pattern.  We assume that taper_dB comes in as a
    positive value.
    - Todd Hunter
    """
    return(1.02 + 0.0135*taper_dB)

def beamCorrectionFactor(beam, disk, gaussian=False):
    """
    Computes the correction factor for the measured antenna
    temperature for the weighting of a disk source distribution
    by a larger antenna beam.   From Gordon, Baars and Cocke.
    1992A&A 264, 337, equation 15
    beam: the FWHM of the Gaussian beam
    disk: angular diameter of a disk source
    gaussian: if True, then treat the second parameter as FWHM of another Gaussian
    -Todd Hunter
    """
    if (disk == 0): return(beam)
    x = (np.log(2))**0.5 * disk/beam
    if (gaussian):
        k = 1 + x**2
    else:
        k = x**2/(1-np.exp(-x**2))
    return(k)

def centralObstructionFactor(diameter=12.0, obscuration=0.75):
    """
    Computes the scale factor of an Airy pattern as a function of the
    central obscuration, using Table 10.1 of Schroeder's "Astronomical Optics".
    -- Todd Hunter
    """
    epsilon = obscuration/diameter
    myspline = scipy.interpolate.UnivariateSpline([0,0.1,0.2,0.33,0.4], [1.22,1.205,1.167,1.098,1.058], s=0)
    factor = myspline(epsilon)/1.22
    if (type(factor) == np.float64):
        # casapy 4.2
        return(factor)
    else:
        # casapy 4.1 and earlier
        return(factor[0])

def pickDishDiameter(vis, mixedAntenna='min', proposedDiameter=-1):
    """
    Picks a specified dish diameter from a dataset.
    mixedAntenna: statistic to use: 'min,max,median'
    -Todd Hunter
    """
    antennaTable = vis+'/ANTENNA'
    if not os.path.exists(antennaTable):
        print "Could not find ANTENNA table for measurement set."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(antennaTable)
    diameters = mytb.getcol('DISH_DIAMETER')
    if len(np.unique(diameters)) > 1:
        if mixedAntenna == 'median':
            diameter = np.median(tb.getcol('DISH_DIAMETER'))
        elif mixedAntenna == 'min':
            diameter = np.min(tb.getcol('DISH_DIAMETER'))
        elif mixedAntenna == 'max':
            diameter = np.max(tb.getcol('DISH_DIAMETER'))
        else:
            print "There are mixed antennas and you need to specify mixedAntenna to be one of 'median,min,max'."
            return
        print "%s dish diameter = %.1fm" % (mixedAntenna, diameter)
    else:
        if proposedDiameter > 0 and proposedDiameter != diameters[0]:
            obs = getObservatoryName(vis)
            if obs.find('ALMA') >= 0 or obs.find('ACA') >= 0:
                print "Requested dish diameter is not in this dataset.  Using value from the dataset: %.1fm" % (diameters[0])
        diameter = diameters[0]
    mytb.close()
    return diameter
    
def primaryBeamArcsec(vis='', spw='', frequency='',wavelength='',
                      diameter=12.0, taper=10.0, obscuration=0.75,
                      verbose=False, showEquation=True, use2007formula=True,
                      fwhmfactor=None, mixedAntenna='median', intent='OBSERVE_TARGET*'):
    """
    Implements the Baars formula: b*lambda / D.
      if use2007formula==False, use the formula from ALMA Memo 456        
      if use2007formula==True, use the formula from Baars 2007 book
        (see au.baarsTaperFactor)     
      In either case, the taper value is expected to be entered as positive.
        Note: if a negative value is entered, it is converted to positive.
    The effect of the central obstruction on the pattern is also accounted for
    by using a spline fit to Table 10.1 of Schroeder's Astronomical Optics.
    The default values correspond to our best knowledge of the ALMA 12m antennas.
      diameter: outer diameter of the dish in meters
      obscuration: diameter of the central obstruction in meters
      fwhmfactor: if given, then ignore the taper
      mixedAntenna: how to choose diameter if they are mixed: 'median','min','max'
    Specify one of the following combinations:
    0) vis and spw (uses median dish diameter)
    1) vis (uses median freq of the spws with the specified intent, and median dish diameter)
    2) frequency in GHz (assumes 12m) (overrides vis, but not spw)
    3) wavelength in mm (assumes 12m)
    4) frequency in GHz and diameter (m)
    5) wavelength in mm and diameter (m)
    For further help and examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/PrimaryBeamArcsec
    -- Todd Hunter
    """
    if (type(vis) != str):
        print "The first argument of primaryBeamArcsec is vis, which must be a string."
        print "Use frequency=100 or frequency='100GHz' to request 100 GHz."
        return
    if (fwhmfactor is not None):
        taper = effectiveTaper(fwhmfactor,diameter,obscuration,use2007formula)
        if (taper is None): return
    if (taper < 0):
        taper = abs(taper)
    if (obscuration>0.4*diameter):
        print "This central obscuration is too large for the method of calculation employed here."
        return
    if (vis != ''):
        diameter = pickDishDiameter(vis, mixedAntenna, proposedDiameter=diameter)
        if (spw != ''):
            try:
                spwTable = vis+'/SPECTRAL_WINDOW'
                tb.open(spwTable)
                num_chan = tb.getcol('NUM_CHAN')
                refFreqs = tb.getcol('REF_FREQUENCY')
                tb.close()
            except:
                print "Could not open table = %s" % antennaTable 
                return(0)
            frequencyHz = refFreqs[spw]
            frequency = frequencyHz*1e-9
            if (verbose):
                print "Found frequency = %f GHz and dish diameter = %.1fm" % (frequency,diameter)
        elif frequency=='': # only the vis was given
            frequencyHz = medianFrequencyOfIntent(vis, intent=intent)
            frequency = frequencyHz * 1e-9
            print "Median OBSERVE_TARGET frequency = %.3f GHz" % (frequency)
        else:
            frequency = parseFrequencyArgumentToGHz(frequency)
    else:
        if (frequency != '' and wavelength != ''):
            print "You must specify either frequency or wavelength, not both!"
            return(0)
    if (frequency != ''):
        if (type(frequency) == str):
            freqArg = frequency
            frequency = parseFrequencyArgument(frequency)
            if (frequency < 1000 and type(freqArg) == str):
                if (freqArg.lower().find('hz') < 0):
                    # convert '230.0' to 230e9
                    frequency *= 1e9
        elif (frequency < 10000):
            frequency *= 1e9
        lambdaMeters = c_mks/frequency
    elif (wavelength != ''):
        lambdaMeters = wavelength*0.001
    else:
        print "You must specify either frequency (in GHz or a string with units) or wavelength (in mm)"
        return(0)
#  print "wavelength = %.3f mm" % (lambdaMeters*1000)
    b = baarsTaperFactor(taper,use2007formula) * centralObstructionFactor(diameter, obscuration)
    if (showEquation):
        if (use2007formula):
            formula = "Baars (2007) Eq 4.13"
        else:
            formula = "ALMA memo 456 Eq. 18"
        print "Coefficient from %s for a -%.1fdB edge taper and obscuration ratio=%g/%g = %.3f*lambda/D" % (formula, taper, obscuration, diameter, b)
    return(b*lambdaMeters*3600*180/(diameter*math.pi))

def almaPrimaryBeamCorrection(frequency, radius, diameter=12.0, taper=10.0,
                              obscuration=0.75, verbose=False, showEquation=False,
                              use2007formula=True, fwhmfactor=None):
    """
    This function computes the ratio of the current CASA primary beam correction
    scheme (10.7m Airy disk) to the current best ALMA Gaussian primary beam model.
    Inputs:
    * frequency: in Hz or GHz (GHz assumed for values < 1000), float or string with untis
    * radius: in arcseconds from the phase center
    Parameters passed to au.primaryBeamArcsec:
    * diameter: meters
    * taper: dB
    * obscuration: meters
    * fwhmfactor: alternative to taper: fwhmfactor*lambda/D
    * use2007formula: Boolean
    * showEquation: Boolean
    * verbose: Boolean
    Returns:
    The value by which to scale a flux density measured at this radius
    in a CASA primary-beam corrected image.
    -Todd Hunter
    """
    GHz = parseFrequencyArgumentToGHz(frequency)
    trueGain = gaussianBeamResponse(radius, frequency=frequency, diameter=diameter,
                                    taper=taper, obscuration=obscuration, verbose=verbose,
                                    showEquation=showEquation, 
                                    use2007formula=use2007formula, 
                                    fwhmfactor=fwhmfactor)
    airyfwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter*10.7/12.0,
                                 taper=0, showEquation=showEquation)
    xaxisLimitInUnitsOfFwhm = 3
    airyX, airyProfile = griddedBeam().buildAiryDisk(airyfwhm, xaxisLimitInUnitsOfFwhm,
                                                     convolutionPixelSize=airyfwhm/50.,
                                                     truncate=True, obscuration=obscuration)
    myspline = scipy.interpolate.UnivariateSpline(airyX, airyProfile,s=0)
    casaAiryGain = myspline(radius)
    if (casaAiryGain < 0.10):
        print "The CASA Airy disk model is truncated below 0.10 of the central response."
        return(0)
    else:
        ratio = casaAiryGain/trueGain
        print "CASA Airy gain = %.3f, true gain = %.3f, ratio = %.3f" % (casaAiryGain,trueGain,ratio)
        print "After CASA primary beam correction, scale the flux of the source by the ratio."
        return(ratio)
    
def gaussianBeamOffset(response=0.5, fwhm=1.0):
    """
    Computes the radius at which the response of a Gaussian
    beam drops to the specified level.  For the inverse
    function, see gaussianBeamResponse.
    -Todd Hunter
    """
    if (response <= 0 or response > 1):
        print "response must be between 0..1"
        return
    radius = (fwhm/2.3548)*(-2*np.log(response))**0.5 
    return(radius)
    
def gaussianBeamResponse(radius, frequency=None, fwhm=None, diameter=12.0, 
                         taper=10.0,
                         obscuration=0.75, verbose=False, showEquation=False,
                         use2007formula=True, fwhmfactor=None):
    """
    Computes the gain at the specified radial offset from the center
    of a Gaussian beam. For the inverse function, see gaussianBeamOffset.
    -Todd Hunter
    Required inputs:
    radius: in arcseconds
    and one of the following:
    fwhm: in arcseconds
    frequency: in Hz or GHz (float or string with units)
       If frequency is specified, ALMA 12m parameters are assumed.
    Optional inputs:
    Passed to primaryBeamArcsec to modify the antenna parameters.
    """
    if (fwhm==None):
        if (frequency==None):
            print "You must specify either fwhm or frequency"
            return
        fwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter,
                                 taper=taper, obscuration=obscuration,
                                 verbose=verbose, showEquation=showEquation,
                                 use2007formula=use2007formula, fwhmfactor=fwhmfactor)
    elif (frequency!=None):
        print "Ignoring the frequency in favor of the fwhm specified."
    sigma = fwhm/2.3548
    gain = np.exp(-((radius/sigma)**2)*0.5)
    return(gain)
                   
def imageCentroids(images, threshold=0, axis3channel=None, axis4channel=None,
                   fractionalThreshold=None, aperture=None, crpixOffset=None,
                   verbose=False, normalize=False, radec=False, prec=3,
                   keepThresholdImage=False, sigmaThreshold=None, blc=None,
                   trc=None, radialThreshold=None):
    """
    Runs imageCentroid for a list of images, then computes mean and
    standard deviation.    -Todd Hunter
    threshold: the pixel value below which to ignore when finding the centroid
    fractionThreshold: threshold value with respect to the peak pixel value
    sigmaThreshold: set threshold to this number of sigma
    axis3channel: which channel to use on 3rd axis (default=all)
    axis4channel: which channel to use on 4th axis (default=all)
    aperture: diameter in arcsec within which to measure flux density
    crpixOffset: compute offset from ref pixel in units: 'pixel', 'arcsec', 'mas', or 'rad'
    verbose: if True, print all flux stats
    normalize: if threshold is set, then set all pixel values to 1.0
    radec: if True, return the centroid position in RA,Dec rather than pixels
    prec: digits of precision to display after the decimal
    keepThresholdImage: write a new image corresponding to the threshold
    radialThreshold: maximum radius in pixels from image center to consider
           when threshold is set (use this to avoid distant noise spikes)
    Returns:
    Nothing, unless crpixOffset is specified, in which case a list of
       these offsets is returned
    """
    if (type(images) == str):
        if (images.find('*') >= 0):
            images = sorted(glob.glob(images))
        else:
            images = images.split(',')
    crpixOffsets = []
    fluxes = []
    centroids = []
    for img in images:
        radecTrue = True
        result = imageCentroid(img, threshold, axis3channel, axis4channel,
                               fractionalThreshold, aperture, crpixOffset,
                               verbose, normalize, radecTrue, blc,trc,
                               keepThresholdImage, sigmaThreshold,
                               radialThreshold)
        if result==None: return
        if (aperture is not None):
            if (crpixOffset is not None):
                centroid, fluxDensity, offset = result
            else:
                centroid, fluxDensity = result
            fluxes.append(fluxDensity)
            crpixOffsets.append(offset)
        else:
            if (crpixOffset is not None):
                centroid, offset = result
                crpixOffsets.append(offset)
            else:
                centroid = result
        if radec:
            centroid = roundRadec(centroid, prec=prec)
        centroids.append(centroid)        
    for i,img in enumerate(images):
        if (crpixOffset is not None):
            print "%s: %s  %+.*f %+.*f" % (img, str(centroids[i]),prec,crpixOffsets[i][0],prec,crpixOffsets[i][1])
        else:
            print "%s: %s" % (img, str(centroids[i]))
    if (not radec):
        print "Mean centroid = (%f, %f) +- (%f, %f)" % (np.mean(np.transpose(centroids)[0]),  np.mean(np.transpose(centroids)[1]), np.std(np.transpose(centroids)[0]),  np.std(np.transpose(centroids)[1]))
    if (fluxes != []):
        print "Mean flux = %f +- %f" % (np.mean(fluxes), np.std(fluxes))
    if (crpixOffsets != []):
        print "Mean offset from ref pixel = (%f, %f) +- (%f, %f) %s" % (np.mean(np.transpose(crpixOffsets)[0]),  np.mean(np.transpose(crpixOffsets)[1]), np.std(np.transpose(crpixOffsets)[0]),  np.std(np.transpose(crpixOffsets)[1]), crpixOffset)
        print "Median offset from ref pixel = (%f, %f) +- (%f, %f) %s" % (np.median(np.transpose(crpixOffsets)[0]), np.median(np.transpose(crpixOffsets)[1]), MAD(np.transpose(crpixOffsets)[0]), MAD(np.transpose(crpixOffsets)[1]), crpixOffset)
    if (crpixOffset is not None):
        return(crpixOffsets)

def imageRotate(img, pa='90deg', overwrite=False):
    """
    Copy a CASA image and rotate it in the plane of the sky by the specified angle, using
    ia.rotate.
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Could not find image"
        return
    imgtemp = img+'.rotated'
    if (os.path.exists(imgtemp)):
        shutil.rmtree(imgtemp)
    myia = createCasaTool(iatool)
    myia.open(img)
    myia.rotate(pa=pa, outfile=imgtemp)
    myia.close()
    if overwrite:
        shutil.rmtree(img)
        os.rename(imgtemp,img)

def imageAreaAbovePB(pbimg, level=0.5):
    """
    Takes a .pb or .flux image and computes the area (in sq. arcsec)
    above the specified level.
    -Todd Hunter
    """
    if (not os.path.exists(pbimg)):
        print "Could not find image"
        return
    myia = createCasaTool(iatool)
    myia.open(pbimg)
    pixels = myia.getregion()
    npixels = len(np.where(pixels > level)[0].flatten())
    myia.close()
    results = getFitsBeam(pbimg) # ,omitBeam=True)
    pixelArea = abs(results[3]*results[4]) * npixels
    return pixelArea

def imageCenter(img, verbose=True, format='sexagesimal_colon'):
    """
    Report the RA Dec of the middle pixel of an image (or the point between
    middle pixels if an even number of pixels).
    verbose: if True, then also print the middle pixel
    format: 'sexagesimal_colon', 'sexagesimal_hms', 'sexagesimal_period', 'radians', or 'degrees'
        'sexagesimal_hms'    = XXhXXmXX.XXXs +XXdXXmXX.XXXs
        'sexagesimal_period' = XXhXXmXX.XXXs +XX.XX.XX.XXX
        'sexagesimal_colon'  = XX:XX:XX.XXXs +XX:XX:XX.XXX
    -Todd Hunter
    """
    shape = imhead(img,mode='get',hdkey='shape')
    x = (shape[0]-1)/2.0
    y = (shape[1]-1)/2.0
    if verbose:
        print "Finding RA,Dec of pixel: ", x, y
    return(findPixel(img, pixel='%.1f,%.1f'%(x,y), verbose=verbose, format=format))

def imageCentroid(imgfile, threshold=0, axis3channel=None, axis4channel=None,
                  fractionalThreshold=None, aperture=None, crpixOffset=None,
                  verbose=False, normalize=False, radec=False, blc=None,
                  trc=None, keepThresholdImage=False, sigmaThreshold=None,
                  radialThreshold=None, applyMask=True):
    """
    Computes the statistics and center of mass of a 2D casa image using
    scipy.ndimage.measurements.center_of_mass.
    threshold: the pixel value below which to ignore when finding the centroid
    fractionThreshold: threshold value with respect to the peak pixel value
    axis3channel: which channel to use on 3rd axis (default=all)
    axis4channel: which channel to use on 4th axis (default=all)
    aperture: diameter in arcsec within which to measure flux density
    crpixOffset: compute offset from ref pixel in units: 'pixel', 'arcsec', or 'rad'
    verbose: if True, print all flux stats
    normalize: if threshold is set, then set all pixel values to 1.0
    radec: if True, return the RA and Dec instead of the pixel coordinates
    blc,trc: define the region to assess sigma (via imageStd) for sigmaThreshold option
    keepThresholdImage: write a new image corresponding to the threshold
    radialThreshold: maximum radius in pixels from image center to consider
           when threshold is set (use this to avoid distant noise spikes). This is
           radius of a square box to use.
    Returns: 
    * a tuple of the X,Y (or RA,DeC) coordinates of the centroid
    * if aperture is specified: the flux density, 
    * if crpixOffset='pixel': offset from reference pixel in pixels
    * if crpixOffset='arcsec': offset from reference pixel in arcsec
    * if crpixOffset='radian': offset from reference pixel in radian
    So, there are 4 possibilities:
    * tuple of coordinates
    * tuple of coordinates and flux density
    * tuple of coordinates and offset
    * tuple of coordinates and flux density and offset
    -Todd Hunter
    """
    if (os.path.exists(imgfile) == False):
        print "Could not locate image file: ", imgfile
        return
    if (threshold < 0):
        print "Only zero or positive thresholds are supported."
        return
    myia = createCasaTool(iatool)
    myia.open(imgfile)
    if (axis3channel is None):
        allpixels = (myia.getchunk()).squeeze()
        if (applyMask):
            allmasks = (myia.getchunk(getmask=True)).squeeze()
            idx = np.where(allmasks==False)[0]
            if len(idx) == 0:
                print "There are no masked pixels to ignore."
            else:
                print "Ignoring %d masked pixels." % (len(idx))
            allpixels[idx] = 0
    else:
        ndim = len(np.shape(myia.getchunk()))
        blc = np.zeros(ndim)
        trc = np.zeros(ndim)
        trc[:2] = -1
        if (ndim > 2):
            blc[2] = axis3channel
            trc[2] = axis3channel
            if (ndim > 3):
                if (axis4channel is not None):
                    blc[3] = axis4channel
                    trc[3] = axis4channel
                else:
                    trc[3] = -1
        allpixels = myia.getchunk(blc,trc)
        if (applyMask):
            allmasks = myia.getchunk(blc,trc,getmask=True)
            allpixels[np.where(allmasks==False)] = 0

    myia.close()
    if (fractionalThreshold is not None):
        if (threshold != 0):
            print "Cannot set both threshold and fractionalThreshold"
            return
        if (fractionalThreshold >= 1.0):
            print "fractionThreshold is invalid (>1)"
            return
        threshold = fractionalThreshold*imagePeak(imgfile)
        print "Set threshold to %f" % (threshold)
    elif (sigmaThreshold > 0):
        if (threshold != 0):
            print "Cannot set both threshold and sigmaThreshold"
        mystd = imageStd(imgfile, blc=blc, trc=trc)
        print "found st.dev = ", mystd
        threshold = sigmaThreshold * mystd

    myshape = np.shape(allpixels)
    if (threshold > 0):
        allpixels -= threshold
        idx = np.where(allpixels < 0)
        idx2 = np.where(allpixels > 0)
        allpixels += threshold
        allpixels[idx] = 0
        if (normalize):
            allpixels[idx2] = 1000000*threshold
            if (keepThresholdImage):
                myia = createCasaTool(iatool)
                newimage = imgfile + '.threshold'
                if (os.path.exists(newimage)):
                    shutil.rmtree(newimage)
                os.system('cp -r %s %s' % (imgfile, newimage))
                myia.open(newimage)
                mypixels = myia.getchunk()
                mypixels = allpixels
                myia.putchunk(mypixels)
                myia.close()
                if (verbose):
                    print "Wrote image: ", newimage
    elif threshold == 0:
        idx = np.where(allpixels < 0)
        print "Ignoring all %d negative pixels. Using the other %d pixels." % (len(idx[0]), np.prod(myshape)-len(idx[0]))
        allpixels[idx] = 0
    else:
        print "threshold must be non-negative"
        reeturn

    if (radialThreshold is not None):
        if radialThreshold < 1:
            radialThreshold = int(radialThreshold*myshape[0])
            print "Using square radius of %d pixels about the image center" % (radialThreshold)
        idx = np.where(allpixels > 0)
        if (verbose):
            print "There are %d pixels above threshold (initially)" % (len(idx[0]))
        header = imhead(imgfile,mode='list')
        x0 = int(myshape[0]/2)-radialThreshold
        x1 = int(myshape[0]/2)+radialThreshold
        for x in range(0, x0):
            allpixels[x][:] = 0
        for x in range(x1, myshape[0]):
            allpixels[x][:] = 0
        y0 = int(myshape[0]/2)-radialThreshold
        y1 = int(myshape[0]/2)+radialThreshold
        print "ignoring: x=0-%d %d-%d" % (x0,x1,myshape[0])
        print "ignoring: y=0-%d %d-%d" % (y0,y1,myshape[1])
        for y in range(0, y0):
            allpixels[:][y] = 0
        for y in range(y1, myshape[1]):
            allpixels[:][y] = 0

    idx = np.where(allpixels > 0)
    if (verbose):
        print "%d pixels remain above the threshold." % (len(idx[0]))
    if (len(idx[0]) < 1):
        print "No pixels remain above the threshold."
        return
    if (verbose):
        print "Image statistics: mean=%f median=%f max=%f min=%f" % (np.mean(allpixels), np.median(allpixels),
                                                                 np.max(allpixels), np.min(allpixels))
    # setting pixels to zero *should* effectively remove their contribution to the center of mass
    # but who knows if this actually true
    result = ndimage.measurements.center_of_mass(allpixels)
    resultPixel = result
    if (verbose):
        print "resultPixel = ", resultPixel
    if (radec):
        result = findPixel(imgfile, pixel=result)
    if (crpixOffset is not None):
        header = imhead(imgfile,mode='list')
        if (crpixOffset == 'arcsec'):
            offset = (-(header['crpix1']-resultPixel[0])*header['cdelt1']*ARCSEC_PER_RAD,
                      (header['crpix2']-resultPixel[1])*header['cdelt2']*ARCSEC_PER_RAD)
            if (verbose): print offset, " arcsec" 
        elif (crpixOffset == 'mas'):
            offset = (-(header['crpix1']-resultPixel[0])*header['cdelt1']*ARCSEC_PER_RAD*1000,
                      (header['crpix2']-resultPixel[1])*header['cdelt2']*ARCSEC_PER_RAD*1000)
            if (verbose): print offset, " mas" 
        elif (crpixOffset == 'rad'):
            offset = (-(header['crpix1']-resultPixel[0])*header['cdelt1'],
                      (header['crpix2']-resultPixel[1])*header['cdelt2'])
        elif (crpixOffset == 'pixel'):
            offset = (header['crpix1']-resultPixel[0], header['crpix2']-resultPixel[1])
        else:
            print "Unrecognized unit: ", crpixOffset
            return
            
    if (aperture):
        if (verbose):
            print "Running imstat('%s', region='Circle[[%fpix,%fpix], %farcsec')" % (imgfile, resultPixel[0],resultPixel[1],aperture/2.)
        stats = imstat(imgfile, region='Circle[[%fpix,%fpix], %farcsec]' % (resultPixel[0],resultPixel[1],aperture/2.))
        if (verbose): print stats
        if (crpixOffset is not None):
            result = [result, stats['flux'][0], offset]
        else:
            result = [result, stats['flux'][0]]
    elif (crpixOffset is not None):
        result = [result, offset]
    return(result)
    # end of imageCentroid()
    
def getfwhm(imgfile,pkXmin='min',pkXmax='max',pkYmin='min',pkYmax='max',
            pixelSize=None, axis3channel=0, axis4channel=0, plotfile=None, 
            ignoreIdenticalZeros=True, plotrange=[0,0,0,0], gaussian=None, 
            showlog=False, plotrange2=[0,0,0,0]):
    """
    Directly estimate the actual FWHM of the CASA image provided, with no 
    assumption about shape except that the function has a well defined peak 
    and is approximately azimuthally symmetric.  It takes the average of two 
    median values: the median radius of the first 5 points above half-power, 
                   and the first 5 points below half-power.
    INPUT:
    imgfile - a CASA image
    OPTIONAL INPUT
    pk{X,Y}{min,max} - pixel coordinate range (integers) within which to search
         for peak and FWHM. so long as this region contains the peak and the 
         half max point, you should get reasonable results. (default is to 
         consider all pixels)
    pixelSize - if None, use value from image header (supports deg or rad units)
    axis3channel - which channel of the cube to use (if naxis>2) 
    axis4channel - which channel of the cube to use (if naxis>3)
    plotfile - if True, or a string, then write a png file
    plotrange2 - [xmin, xmax, ymin, ymax] 
    gaussian - the FWHM of a Gaussian profile to overlay on the plot
    showlog - show the log of the pixel values in a second panel
    plotrange2 - [xmin, xmax, ymin, ymax] for the log plot 
    RETURN
    full width half max in pixels (or in units of pixel size that was specified)
    SIDE EFFECTS
    opens an interactive matplotlib window
    
    EXAMPLE
    getfwhm('uid3/best.tp.image',pixelSize=0.2)
    
    v1 B.Mason 23aug2013
    """
    radiusUnits=''
    if (os.path.exists(imgfile) == False):
        print "Image not found"
        return
    if (pixelSize is None):
        radiusUnits='(arcsec)'
        try:
            f = imhead(imgfile, mode='list')
            units = f['cunit1']
            pixelSize = abs(f['cdelt1'])
            pixelSize2 = abs(f['cdelt2'])
        except:
            # if the image has no frequency axis, then this might still work
            units = imhead(imgfile,mode='get',hdkey='cunit1')
            pixelSize = abs(imhead(imgfile,mode='get',hdkey='cdelt1')['value'])
            pixelSize2 = abs(imhead(imgfile,mode='get',hdkey='cdelt2')['value'])
        arseconds=True
        if (units.lower().find('deg') >= 0):
            pixelSize *= 3600
            pixelSize2 *= 3600
        elif (units.lower().find('rad') >= 0):
            pixelSize *= 3600*180/np.pi
            pixelSize2 *= 3600*180/np.pi
        elif (units.lower().find('arcsec') < 0):
            print "Unrecognized pixel units in header: %s (assuming arcsec)" % (units)
        if (pixelSize != pixelSize2):
            print "WARNING: the pixels are not square!"
        pixelSize = (pixelSize*pixelSize2)**0.5
        print "Got pixelSize = %f arcsec" % (pixelSize)
    myia = createCasaTool(iatool)
    myia.open(imgfile)
    allpixels=(myia.getchunk()).squeeze()
    myia.close()
    naxis = len(np.shape(allpixels))
    naxis1 = np.shape(allpixels)[0]
    nx=(allpixels.shape)[0]
    ny=(allpixels.shape)[1]
    if pkXmin=='min':
        pkXmin=0
    if pkXmax=='max':
        pkXmax=nx-1
    if pkYmin=='min':
        pkYmin=0
    if pkYmax=='max':
        pkYmax=ny-1
    # restrict the set considered
    # --fix: squeeze out singleton dimensions of these arrays-
    if (naxis == 4):
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax,axis3channel:axis3channel+1,axis4channel:axis4channel+1]).squeeze()
    elif (naxis == 3):
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax,axis3channel:axis3channel+1]).squeeze()
    else:
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax]).squeeze()
    # this is code for an automatic edit that didn't work very
    # robustly - you're better off restricting the analyzed area
    #if cut > 0.0:
    # medval=np.median(pixels)
    # sigma=np.mean(np.abs( pixels - medval))
    # pixels[np.where( abs(pixels - medval) > cut*sigma)]=medval
    nx=(pixels.shape)[0]
    ny=(pixels.shape)[1]
    pkval=pixels.max()
    # construct an array of radius values from
    # the peak pixel
    coords=pixels
    xvals=(np.tile(np.arange(nx),(ny,1))).transpose()
    yvals=np.tile(np.arange(ny),(nx,1))
#    print "shape(xvals)=%s, shape(yvals)=%s shape(pixels)=%s" % (str(np.shape(xvals)), str(np.shape(yvals)), str(np.shape(pixels)))
    # allow for more than one pixel matching the peak value
    #indices = np.where(pixels == np.max(pixels))[0]
    # --fix:
    indices = np.where(pixels == np.max(pixels))
    xmax=np.median(xvals[indices])
    ymax=np.median(yvals[indices])
    # report physical coords in full image-
    print " Max found at pixel ",xmax+pkXmin," ",ymax+pkYmin
    r=np.sqrt( (xvals-xmax)**2 + (yvals-ymax)**2)*pixelSize
    # estimate two ways and average
    #fwhm= 2.0*0.5* (np.max( r[np.where(pixels > 0.5*pkval)[0]] ) + np.min( r[np.where(pixels < 0.5*pkval)[0]] ))
    # --fix:
    #fwhm= 2.0*0.5* (np.max( r[np.where(pixels > 0.5*pkval)] ) + np.min( r[np.where(pixels < 0.5*pkval)] ))
    # --fix2 (better estimate) - median of the 5 pixels on either size of 0.5xpeak
    rinner=np.sort(r[np.where(pixels>0.5*pkval)])
    if (ignoreIdenticalZeros):
        lowValues = np.where(np.logical_and(pixels<0.5*pkval, pixels!=0))
    else:
        lowValues = np.where(pixels<0.5*pkval)
    router=np.sort(r[lowValues])
    nValues = 5
    if (rinner.size > nValues and router.size > nValues):
        fwhm= 2.0*0.5* ( np.median(rinner[rinner.size-1-nValues:rinner.size-1]) + np.median(router[0:nValues]))
    print " peak = ", pkval
#    print "max r > 0.5*pk = ",np.max(r[np.where(pixels>0.5*pkval)])
#    print "min r < 0.5*pk = ",np.min(r[np.where(pixels<0.5*pkval)])
#    print "fwhm = ", fwhm
    # make a plot
    x = r.reshape(r.size)
    y = pixels.reshape(pixels.size)/pkval
#    print "shape(x)=%s, shape(y)=%s" % (str(np.shape(x)), str(np.shape(y)))
    plt.clf()
    if (showlog):
        fig = plt.gcf()
        ax = fig.add_subplot(1,2,1)
    p1 = plt.plot(x,y,'b.',[r.min(),r.max()],[0.5,0.5],'r',[fwhm*0.5,fwhm*0.5],[0.0,1.0],'g')
    if (plotrange[:2] != [0,0]):
        pb.xlim(plotrange[:2])
    else:
        pb.xlim([0,np.max(r)*1.15])
    if (gaussian is not None):
        plt.hold(True)
        gx = np.arange(0,pb.xlim()[1],pb.xlim()[1]*0.01)
        gy = np.exp(-gx**2/(2*(gaussian/2.35482)**2))
        plt.plot(gx,gy,'m-')
    if (plotrange[2:] != [0,0]):
        pb.ylim(plotrange[2:])
    else:
        pb.ylim([np.min([0,np.min(y)]), 1.05])        
    plt.xlabel('radius %s' % radiusUnits)
    plt.ylabel('pixel value')
    
    plt.title(os.path.basename(imgfile))
    if (showlog==False):
        plt.legend(p1,["data","0.5","estimated HWHM (FWHM=%.2f%s)"%(fwhm,radiusUnits.strip(')').strip('('))])
    else:
        plt.text(0.08,0.96,"estimated HWHM (FWHM=%.2f%s)"%(fwhm,radiusUnits.strip(')').strip('(')),size=9,transform=gca().transAxes,color='g')
        ax = fig.add_subplot(1,2,2)
        plt.subplots_adjust(wspace=0.3)
        p1 = plt.plot(x,y,'b.', [r.min(),r.max()],[0.5,0.5],'r', [fwhm*0.5,fwhm*0.5],[1e-5,1.0],'g')
        ax.set_yscale('log')
        plt.xlabel('radius %s' % radiusUnits)
        plt.ylabel('log(pixel value)')
        if (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        else:
            pb.xlim([0,np.max(r)*1.15])
        if (gaussian is not None):
            plt.hold(True)
            plt.text(0.5,0.92,'Gaussian %.2f"'%(gaussian),size=9,transform=gca().transAxes,color='m')
            x = np.arange(0,pb.xlim()[1],pb.xlim()[1]*0.01)
            y = np.exp(-x**2/(2*(gaussian/2.35482)**2))
            plt.plot(x,y,'m-')
            if (plotrange2[:2] != [0,0]):
                pb.xlim(plotrange2[:2])
            else:
                pb.xlim([0,np.max(r)*1.15])
            if (plotrange2[2:] != [0,0]):
                pb.ylim(plotrange2[2:])
            else:
                pb.ylim([np.min([0,np.min(y)]), 1.05])        

    if (plotfile is not None):
        if (plotfile == True):
            # automatic naming convention
            plotfile = '%s.getfwhm.png' % (os.path.basename(imgfile))
        plt.savefig(plotfile)
        print "Plot saved in %s" % (plotfile)
    return fwhm   

def averageTheRepeatedValues(x, y, median=False, returnStdev=False):
    """
    Accepts paired lists and averages the entries that have the same x value,
    where the x value can be a string or integer or float.
    median: if True, then take the median (and MAD) rather than mean (and stdev)
    returnStdev: if True, also return the standard deviation (or MAD)
    Returns: x, y, and optionally the standardDeviation (or MAD)
    -Todd Hunter
    """
    x = np.array(x)
    y = np.array(y)
    result_x = np.unique(x)
    lenx = len(result_x)
    result_y = np.empty(result_x.shape)
    if (returnStdev):
        stdev_y = np.empty(result_x.shape)
    for i, newx in enumerate(result_x):
#        if (i%100 == 0): print "done %d/%d" % (i,lenx)
        idx = np.where(x == newx)
        if (median):
            result_y[i] = np.median(y[idx])
            if (returnStdev):
                stdev_y[i] = MAD(y[idx])
        else:
            result_y[i] = np.mean(y[idx])
            if (returnStdev):
                stdev_y[i] = np.std(y[idx])
    if (returnStdev):
        return result_x, result_y, stdev_y
    else:
        return result_x, result_y
                        
def getfwhm2(imgfile,pkXmin='min',pkXmax='max',pkYmin='min',pkYmax='max',
             pixelSize=None, axis3channel=0, axis4channel=0, plotfile=None,
             ignoreIdenticalZeros=True, maxRadius=-1, plotrange=[0,0,0,0],
             initialPlot=False,s=0,gaussian=None,showlog=False,
             plotrange2=[0,0,0,0],centroid=False,threshold=0,showplot=False):
    """
    Directly estimate the actual FWHM of the CASA image provided, with no
    assumption about shape except that the function has a well defined peak
    and is approximately azimuthally symmetric.  It finds the peak, subtracts
    half, then solves for the zero crossing, and doubles the result.
    - Todd Hunter
    INPUT:
    imgfile - a CASA image
    OPTIONAL INPUT
    pk{X,Y}{min,max} - pixel coordinate range (integers) within which to search for peak
    and FWHM. So long as this region contains the peak and the half max point
    you should get reasonable results. (default is to consider all pixels)
    pixelSize - if None, use value from image header (supports deg or rad units)
    axis3channel - which channel of the cube to use (if naxis>2) 
    axis4channel - which channel of the cube to use (if naxis>3)
    plotfile - if True, or a string, then write a png file
    maxRadius - set this to limit the area searched for the half-power (in arcsec), 
                which is useful for large images of a small source
    initialPlot: stop after making an initial plot of the radially averaged data
    s: the positive smoothing factor to pass to scipy.interpolate.UnivariateSpline
    gaussian - the FWHM of a Gaussian profile to overlay on the plot
    showlog - show the log of the pixel values in a second panel
    plotrange2 - [xmin, xmax, ymin, ymax] for the log plot
    centroid - if True, call imageCentroid to find the (fractional) pixel
    threshold - value (in % of peak) below which to ignore in imageCentroid
    RETURN
    full width half max in pixels (or in units of the pixel size that was
    specified)
    SIDE EFFECTS
    opens an interactive matplotlib window
    
    EXAMPLE
    getfwhm2('uid3/best.tp.image',pixelSize=0.2)
    """
    radiusUnits=''
    if (os.path.exists(imgfile) == False):
        print "Image not found"
        return
    if (pixelSize is None):
        radiusUnits='(arcsec)'
        units = imhead(imgfile,mode='get',hdkey='cunit1')
        if (type(units) == 'dict'):
            units = units['value']
        pixelSize = abs(imhead(imgfile,mode='get',hdkey='cdelt1')['value'])
        pixelSize2 = abs(imhead(imgfile,mode='get',hdkey='cdelt2')['value'])
        arseconds=True
        print "units = ", units
        if (units.lower().find('deg') >= 0):
            pixelSize *= 3600
            pixelSize2 *= 3600
        elif (units.lower().find('rad') >= 0):
            pixelSize *= 3600*180/np.pi
            pixelSize2 *= 3600*180/np.pi
        elif (units.lower().find('arcsec') < 0):
            print "Unrecognized pixel units in header: %s (assuming arcsec)" % (units)
        if (pixelSize != pixelSize2):
            print "WARNING: the pixels are not square!"
        pixelSize = (pixelSize*pixelSize2)**0.5
        print "Got pixelSize = %f arcsec" % (pixelSize)
    myia = createCasaTool(iatool)
    myia.open(imgfile)
    allpixels=(myia.getchunk()).squeeze()
    myia.close()
    naxis = len(np.shape(allpixels))
    naxis1 = np.shape(allpixels)[0]
    nx=(allpixels.shape)[0]
    ny=(allpixels.shape)[1]
    if pkXmin=='min':
        pkXmin=0
    if pkXmax=='max':
        pkXmax=nx-1
    if pkYmin=='min':
        pkYmin=0
    if pkYmax=='max':
        pkYmax=ny-1
    # restrict the set considered
    # --fix: squeeze out singleton dimensions of these arrays-
    if (naxis == 4):
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax,axis3channel:axis3channel+1,axis4channel:axis4channel+1]).squeeze()
    elif (naxis == 3):
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax,axis3channel:axis3channel+1]).squeeze()
    else:
        pixels=(allpixels[pkXmin:pkXmax,pkYmin:pkYmax]).squeeze()
    nx=(pixels.shape)[0]
    ny=(pixels.shape)[1]
    pkval=pixels.max()
    # construct an array of radius values from
    # the peak pixel
    xvals=(np.tile(np.arange(nx),(ny,1))).transpose()
    yvals=np.tile(np.arange(ny),(nx,1))
#    print "shape(xvals)=%s, shape(yvals)=%s shape(pixels)=%s" % (str(np.shape(xvals)), str(np.shape(yvals)), str(np.shape(pixels)))
    if (centroid):
        threshold = pkval*threshold*0.01
        result = imageCentroid(imgfile,threshold,axis3channel,axis4channel)
        if (len(result) == 2):
            xmax, ymax = result
        elif (len(result) == 3):
            xmax, ymax, axis3max = result
        elif (len(result) == 4):
            xmax, ymax, axis3max, axis4max = result
        else:
            print "Too many axes in this image."
            return
    else:
        # allow for more than one pixel matching the peak value
        indices = np.where(pixels == np.max(pixels))
        xmax = np.median(xvals[indices])
        ymax = np.median(yvals[indices])
    # report physical coords in full image-
    print " Max found at pixel ",xmax+pkXmin," ",ymax+pkYmin
    r = np.sqrt( (xvals-xmax)**2 + (yvals-ymax)**2)*pixelSize
    x = r.reshape(r.size)
    y = pixels.reshape(pixels.size)/pkval
    order = np.argsort(x)
    x = np.array(sorted(x))
    y = np.array(y[order])
    allx = x[:]
    ally = y[:]
    if (maxRadius > 0):
        idx = np.where(x<maxRadius)
        x = x[idx]
        y = y[idx]
    if (True):
        keepRange = max(np.where(y != 0.0)[0])
        maxNonZero = x[keepRange]
        discard = len(x)-keepRange-1
        if (discard > 0):
            print "Discarding of %d/%d pixels because they are all zero beyond radius=%f" % (discard,len(x),maxNonZero)
        xNonZero = x[:keepRange]
        yNonZero = y[:keepRange]
    else:
        maxNonZero = x[-1]
        xNonZero = x[:]
        yNonZero = y[:]
    print "Averaging the values at the same radius."
    if (initialPlot):
        # Check that averageTheRepeatedValues worked
        plt.clf()
        plt.hold(True)
    x,y = averageTheRepeatedValues(xNonZero,yNonZero)
    print "%d points averaged into %d" % (len(xNonZero), len(x))
    if (initialPlot):
        plt.plot(x,y,'r.')
        plt.draw()
        if (plotrange[:2] != [0,0]):
            plt.xlim(plotrange[:2])
        else:
            plt.xlim([0,maxNonZero])
        if (plotrange[2:] != [0,0]):
            plt.ylim(plotrange[:2])
        else:
            plt.ylim([-0.1, 1.1])
        return
    #
    fwhm = findFWHM(x, y, s=s)
    if (showplot or plotfile is not None):
        if (showplot==False):
            pb.ioff()
        # make a plot
        pb.clf()
        if (showlog):
            fig = pb.gcf()
            ax = fig.add_subplot(1,2,1)
        p1 = pb.plot(allx,ally,'b.', x, y, 'r.',
                      [r.min(),r.max()],[0.5,0.5],'r-',
                      [fwhm*0.5,fwhm*0.5],[0.0,1.0],'g-')
        if (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        elif (maxRadius > 0):
            pb.xlim([0,maxRadius])
        else:
            pb.xlim([0,maxNonZero]) # np.max(r)*1.15])
        if (gaussian is not None):
            pb.hold(True)
            gx = np.arange(0,pb.xlim()[1],pb.xlim()[1]*0.01)
            gy = np.exp(-gx**2/(2*(gaussian/2.35482)**2))
            pb.plot(gx,gy,'m-')
        if (plotrange[2:] != [0,0]):
            pb.ylim(plotrange[2:])
        else:
            pb.ylim([np.min([0,np.min(y)]), 1.05])        
        pb.xlabel('radius %s' % radiusUnits)
        pb.ylabel('pixel value')
        if (len(os.path.basename(imgfile)) > 90):
            fontsize=8
        else:
            fontsize=10
        pb.title(os.path.basename(imgfile),fontsize=fontsize)
        if (showlog==False):
            pb.legend(p1,["data","0.5","estimated HWHM (FWHM=%.2f%s)"%(fwhm,radiusUnits.strip(')').strip('('))])
        else:
            plt.text(0.08,0.96,"estimated HWHM (FWHM=%.2f%s)"%(fwhm,radiusUnits.strip(')').strip('(')),size=9,transform=gca().transAxes,color='g')
            ax = fig.add_subplot(1,2,2)
            pb.subplots_adjust(wspace=0.3)
            p1 = pb.plot(x,y,'b.', [r.min(),r.max()],[0.5,0.5],'r', [fwhm*0.5,fwhm*0.5],[1e-5,1.0],'g')
            ax.set_yscale('log')
            pb.xlabel('radius %s' % radiusUnits)
            pb.ylabel('log(pixel value)')
            if (plotrange[:2] != [0,0]):
                pb.xlim(plotrange[:2])
            else:
                pb.xlim([0,np.max(r)*1.15])
            if (gaussian is not None):
                pb.hold(True)
                pb.text(0.5,0.92,'Gaussian %.2f"'%(gaussian),size=9,transform=gca().transAxes,color='m')
                x = np.arange(0,pb.xlim()[1],pb.xlim()[1]*0.01)
                y = np.exp(-x**2/(2*(gaussian/2.35482)**2))
                pb.plot(x,y,'m-')
                if (plotrange2[:2] != [0,0]):
                    pb.xlim(plotrange2[:2])
                elif (plotrange[:2] != [0,0]):
                    pb.xlim(plotrange[:2])
                else:
                    pb.xlim([0,np.max(r)*1.15])
                if (plotrange2[2:] != [0,0]):
                    pb.ylim(plotrange2[2:])
#   #            elif (plotrange[2:] != [0,0]):
#   #                pb.ylim([10*np.log10(plotrange[2]),10*np.log10(plotrange[3])])
                else:
                    pb.ylim([np.min([0,np.min(y)]), 1.05])        
    
        if (plotfile is not None):
            if (plotfile == True):
                # automatic naming convention
                plotfile = '%s.getfwhm.png' % (os.path.basename(imgfile))
            pb.savefig(plotfile)
            print "Plot saved in %s" % (plotfile)
        if (showplot==False):
            pb.ion()
    return fwhm 

def computeClockTimeOfMS(vis=None, vm=None, mymsmd=None):
    """
    Computes delta time from first to last scan in a dataset, either from
    the measurement set itself, or from its a ValueMapping structure.
    The ValueMapping method assumes that the times and scans are in ascending order.
    - Todd Hunter
    """
    if (vm is not None):
        times = vm.getTimesForScans(np.unique(vm.scans))
        mjdsecmin = 1e12
        mjdsecmax = 0
        for t in times:
            #  This is too slow:
            #        mjdsecmin = np.amin([np.amin(t),mjdsecmin])
            #        mjdsecmax = np.amax([np.amax(t),mjdsecmax])
            #  Assume the times are in ascending order:
            mjdsecmin = np.amin([t[0],mjdsecmin]) 
            mjdsecmax = np.amax([t[-1],mjdsecmax])
        #  Account for the first half of the first scan, and last half of the last scan
        deltaT = 0.5*(abs(np.min(times[0][np.where(times[0] > mjdsecmin)]) - mjdsecmin) + 
                      abs(np.max(times[-1][np.where(times[-1] < mjdsecmax)]) - mjdsecmax))
        [mjdmin,utmin] = mjdSecondsToMJDandUT(mjdsecmin)
        [mjdmax,utmax] = mjdSecondsToMJDandUT(mjdsecmax)
        clockTimeMinutes = (mjdmax-mjdmin+deltaT/86400.)*1440.
    elif (vis is not None):
        if mymsmd is None:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            needToClose = True
        else:
            needToClose = False
        times = mymsmd.timesforscans(mymsmd.scannumbers())
        if needToClose:
            mymsmd.close()
        mjdsecmin = np.min(times)
        mjdsecmax = np.max(times)
        deltaT = 0.5*(abs(np.min(times[np.where(times > mjdsecmin)]) - mjdsecmin) + 
                      abs(np.max(times[np.where(times < mjdsecmax)]) - mjdsecmax))
        clockTimeMinutes = (mjdsecmax - mjdsecmin + deltaT)/60.
    else:
        print "You must specify either vis or vm"
        return
    return(clockTimeMinutes)

def timeOnSource(ms='', field='', verbose=True,
                 asdm='', help=False, vm='', gapFactor=None, debug=False,
                 verboseComputeDuration=False, scienceSpwsOnly=False):
    """
    Uses ValueMapping to get the integration timestamps and computes a
    list of durations on the fields specified, attempting to detect and
    account for the inter-subscan latency.  
    Inputs:
    ms: measurement set
    field: integer ID or name
    vm: a pre-existing ValueMapping structure for this measurement set
    scienceSpwsOnly: by default (False) WVR is ignored, but not SQLD,
          set to True to extract times using only the first science spw

    Returns a dictionary indexed by the source ID integer:
    {0: {'num_of_subscans': 2,
         'scans': [5],
         'field_id': [0],
         'source_name': '3c279',
         'minutes_on_source': 58.716000556945801,
         'minutes_on_source_with_latency': 65.664000511169434
         },
     ...
     'clock_time': 120
     'minutes_on_science': 58.716
     'minutes_on_science_with_latency': 65.66
     'percentage_time_on_science': 20.40
    }

It also prints a string convenient to a wikitable of format:
| date | SB name | exec UID | UT start-end | LST start-end | Total time | Time on source | el range | med pwv | antennas | 

Notes on this string:
1) If the pointing table has been deleted it will print "pointing table empty" in the elevation range column.
2) If there is no on-source time, it will print "no onsource time" in the elevation range column.
3) If neither the CalWVR.xml nor ASDM_CALWVR files are present, it will print "unknown" in the pwv column.
4) The median pwv is over the entire dataset, not just the on-source scans.
5) For the number of antennas, it does not detect whether an antenna has been totally flagged!

    For further help and examples, see http://casaguides.nrao.edu/index.php?title=TimeOnSource
    -- Todd Hunter
    """
    if (os.path.exists(ms) == False):
        print "Could not open ms = %s" % (ms)
        return({})
#    if (usemsmd):
#        return(timeOnSourceMSMD(vis,field,verbose,asdm,gapFactor)
    if (vm==''):
#        Someday I should implement this:  au.timeOnSourceMSMD
        if (verbose):
            print "Running ValueMapping... (this may take a minute)"
        vm = ValueMapping(ms)
    tb.open(ms+'/FIELD')
    sourceIDs = tb.getcol('SOURCE_ID')
#    print "sourceIDs: ", sourceIDs
    tb.close()
    telescopeName = getObservatoryName(ms)
    mydict = {}
    if (field == ''):
        field = range(len(sourceIDs))
    elif (type(field) == int):
        field = [field]
    elif (type(field) == str):
        if (field.find(',') >= 0):
            field = field.split(',')
            fd = []
            for f in field:
                fd.append(int(f))
            field = fd
        else:
            try:
                field = int(field)
                field = [field]
            except:
                field = vm.getFieldIdsForFieldName(field)
                if (len(field) < 1):
                    print "No match for field name = " % (field)
                    return({})
    elif (type(field) == list):
        if (type(field[0]) == str):
            nf = []
            for f in field:
                nf.append(vm.getFieldIdsForFieldName(f))
            field = nf
    if (verbose):
        print "Considering non-CalAtmosphere, non-CalPointing, non-CalSideband scans."
        print "Total time on scans (including inter-subscan latency) in %s:" % (os.path.basename(ms))
    durations = []
    subscansAll = []
    fieldId = -1
    previousField = -1
    legend = "Field "
    multiField = False
    totalMinutes = 0
    scienceMinutesWithLatency = 0
    mydict = {}
    legend = ""
    multiFieldScansObserved = []
    if (casadef.casa_version >= casaVersionWithMSMD):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(ms)
    else:
        mymsmd = ''
    if debug: print "field = ", field
    times = {}
    for findex in range(len(field)):
        times[findex] = {}
        f = field[findex]
        durationWithLatency = 0
        scienceDurationWithLatency = 0
        scans = vm.getScansForField(f)
        if debug: 
            print scans, "= scans on field ", f
        scansObserved = []
        totalSubscans = 0
        multiField = False
        if (findex < len(field)-1):
          if (sourceIDs[f] == sourceIDs[field[findex+1]]): # and scans[0] == vm.getScansForField(field[findex+1])[0]):
              multiField = True
              legend += '%2d,' % (f)
#              print multiFieldScansObserved, scans, len(scans)
              for s in scans:
                  multiFieldScansObserved.append(s)
              continue
          else:
              legend += '%2d' % (f)
        else:
          if (sourceIDs[f] == sourceIDs[field[findex-1]]): #  and scans[0] == vm.getScansForField(field[findex-1])[0]):
              multiField = True
              for s in scans:
                  multiFieldScansObserved.append(s)
              legend += '%2d' % (f)
          else:
              legend += '%2d' % (f)
        subscansPerScan = []
        if (multiField):
            scans = np.unique(multiFieldScansObserved)
        if (debug):
            print "scans to check = ", scans
        for s in scans:
            intents = vm.getIntentsForScan(s)
            if debug: print "Scan %d intents = " % (s), intents
            skip = False
            for i in intents:
                if (i.find('CALIBRATE_ATMOSPHERE') >= 0 or 
                    i.find('CALIBRATE_POINTING') >= 0 or 
                    i.find('CALIBRATE_SIDEBAND') >= 0):
                    if debug: print "Skipping scan %d because it is calibration" % (s)
                    skip = True
                if (casadef.casa_version >= casaVersionWithMSMD):
                    if (s not in mymsmd.scansforfield(f)):
                        skip = False
            if (skip):
                if debug: 
                    if (s not in mymsmd.scansforfield(f)):
                        print "Skipping scan %d, since msmd says it is not on field %d" % (s,d)
                    else:
                        print "Skipping calibration scan %d" % (s)
                continue
            scansObserved.append(s)
            times[findex][s] = vm.getTimesForScans(s)
            # times will be a list of length 1 (because s is a single integer scan)
            for t in times[findex][s]: 
                (d,subscans) = computeDurationOfScan(s,None,verbose=verboseComputeDuration,gapFactor=gapFactor,
                                                     vis=ms, mymsmd=mymsmd, scienceSpwsOnly=scienceSpwsOnly)
                scanLength = np.max(t) - np.min(t)
                if (scanLength == 0):
                    # This happens with simulated data as it has no subscans
                    scanLength = d
                durationWithLatency += scanLength
                totalSubscans += subscans
                subscansPerScan.append(subscans)
                if ('OBSERVE_TARGET#ON_SOURCE' in intents or 'OBSERVE_TARGET.ON_SOURCE' in intents
                    or 'OBSERVE_TARGET#UNSPECIFIED' in intents or telescopeName == 'SMA'):
                    scienceDurationWithLatency += scanLength
        totalMinutes += durationWithLatency/60.
        scienceMinutesWithLatency += scienceDurationWithLatency/60.
        if (verbose):
            if (totalSubscans > 1 and multiField==False):
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s, %d subscans)" % (sourceIDs[f],
                   legend, vm.getFieldNamesForFieldId(f),
                   durationWithLatency, durationWithLatency/60.,
                   len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved, totalSubscans)
            else:
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s)" % (sourceIDs[f],
                   legend, vm.getFieldNamesForFieldId(f),
                   durationWithLatency, durationWithLatency/60.,
                   len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved)
        if (len(legend.split(',')) > 1):
            myfield = [int(x) for x in legend.split(',')]
        else:
            myfield = [f]
        mydict[sourceIDs[f]] = {'field_ids': myfield,
                     'source_name':vm.getFieldNamesForFieldId(f),
                     'scans': scansObserved,
                     'num_of_scans': len(scansObserved),
                     'num_of_fields': len(legend.split(',')),
                     'num_of_subscans': subscansPerScan,
                     'minutes_on_source_with_latency': durationWithLatency/60.,
                     'minutes_on_source': 0  # fill this in later
                     }
        legend = ""
    fullreport = True
    if (fullreport):
        [wikiline2,wikiline3,clockTimeMinutes,csvline] = lstrange(ms,verbose=False,vm=vm)
    else:
        clockTimeMinutes = computeClockTimeOfMS(ms,vm=vm)
    print "Clock time = %.2f min, Total time = %.2f min,  science time = %.2f min" % (clockTimeMinutes, totalMinutes, scienceMinutesWithLatency)
    csvline += ',%.2f,%.2f' % (totalMinutes, scienceMinutesWithLatency)
    ##################################################################################3
    if (verbose):
        print "\nMy attempt to detect and account for inter-subscan latency follows:"
    ##################################################################################3
    legend = ""
    multiField = False
    totalMinutes = 0
    scienceMinutes = 0
    fid = 0
    multiFieldScansObserved = []
    if (debug): print "for findex in ", range(len(field))
    for findex in range(len(field)):
        f = field[findex]
        # f is the field ID
        duration = 0
        scienceDuration = 0
        scans = vm.getScansForField(f)
        scansObserved = []
        totalSubscans = 0
        multiField = False
        if (findex < len(field)-1):
            if debug: print "on field = ", findex, field[findex]
            if (sourceIDs[f] == sourceIDs[field[findex+1]]): #  and scans[0] == vm.getScansForField(field[findex+1])[0]):
                # non-final fields
                multiField = True
                legend += '%2d,' % (f)
                for s in scans:
                    multiFieldScansObserved.append(s)
                # By continuing here, we effectively use the final field in the Field table as the
                # effective field.  Sometimes, the final field is never observed, so we need to
                # avoid that possibility, but only if the prior field is not entirely a CAL field.
                if (s in pickScansForField(mymsmd,f)):
                    # use fieldToUse unless it has no science scans
                    myintents = mymsmd.intentsforfield(f)
                    if ('OBSERVE_TARGET#ON_SOURCE' in myintents or
                        'OBSERVE_TARGET.ON_SOURCE' in myintents or
                        'OBSERVE_TARGET#UNSPECIFIED' in myintents):
                        fieldToUse = f
                if debug: print "On field %d, continuing before checking scans" % (f)
                continue
            else:
                legend += '%2d' % (f)
                fieldToUse = f
        else:
            # final field
            if debug: print "on final field = ", f
            if (findex > 0):
                # This is the same logic as the non-final fields, but in reverse sense
                if (sourceIDs[f] != sourceIDs[field[findex-1]]):
                    fieldToUse = f
                    if debug: print "final 2 source IDs not equal: Setting fieldToUse = ", f
                else:
                    myintents = mymsmd.intentsforfield(fieldToUse)
                    if ('OBSERVE_TARGET#ON_SOURCE' not in myintents and
                        'OBSERVE_TARGET.ON_SOURCE' not in myintents and
                        'OBSERVE_TARGET#UNSPECIFIED' not in myintents):
                        fieldToUse = f
                        if debug: print "Setting fieldToUse = ", f
            elif (s in pickScansForField(mymsmd,f)):
                if debug: print "final elif: set fieldToUse = ", f
                fieldToUse = f
            else:
                if debug: print "Not setting fieldToUse"
            if (sourceIDs[f] == sourceIDs[field[findex-1]]):
                multiField = True
                if debug: print "multiField=True" 
                legend += '%2d' % (f)
                for s in scans:
                    multiFieldScansObserved.append(s)
                if debug: print "multiFieldScansObserved=", multiFieldScansObserved
            else:
                legend += '%2d' % (f)
        
        if (multiField):
            scans = np.unique(multiFieldScansObserved)
        if debug: print "Checking fieldToUse=%d in scans = " % (fieldToUse), scans
        scienceMinutesPerScan = {}
        for s in scans:
            intents = vm.getIntentsForScan(s)
            skip = False
            for i in intents:
                if (i.find('CALIBRATE_ATMOSPHERE') >= 0 or 
                    i.find('CALIBRATE_POINTING') >= 0 or
                    i.find('CALIBRATE_SIDEBAND') >= 0):
                    skip = True
                    if debug:
                        print "Skipping calibration scan %d" % (s)
                if (casadef.casa_version >= casaVersionWithMSMD):
                    if (s not in pickScansForField(mymsmd,fieldToUse)):  # change f to fieldToUse Jun 29, 2015
                        skip = True
                        if debug:
                            print "Skipping scan %d because not in scans for field %d: %s" % (s, fieldToUse, pickScansForField(mymsmd,fieldToUse))
            if (skip):
                continue
            scansObserved.append(s)
            scienceDurationThisScan = 0
            # times[findex][s] will be a list of length 1 (because s is a single integer scan)
            for t in times[findex][s]: 
#                print "Running au.computeDurationOfScan(%d,%s,verbose=False,gapFactor=%g,vis='%s')" % (s,str(t),gapFactor,ms)
                (d,subscans) = computeDurationOfScan(s,None,verbose=False,gapFactor=gapFactor,vis=ms, 
                                                     mymsmd=mymsmd, scienceSpwsOnly=scienceSpwsOnly)
                duration += d
                totalSubscans += subscans
                if ('OBSERVE_TARGET#ON_SOURCE' in intents or 'OBSERVE_TARGET.ON_SOURCE' in intents
                     or 'OBSERVE_TARGET#UNSPECIFIED' in intents or telescopeName == 'SMA'):
                    scienceDurationThisScan += d
            scienceMinutesPerScan[s] = scienceDurationThisScan/60.
            scienceDuration += scienceDurationThisScan
        totalMinutes += duration/60.
        scienceMinutes += scienceDuration/60.
        if (verbose):
            fieldWarning = ""
            if (totalSubscans > 1 and multiField==False):
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s, %d subscans%s)" % (sourceIDs[f],
                 legend, vm.getFieldNamesForFieldId(f), duration, duration/60.,
                 len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved, totalSubscans, fieldWarning)
            else:
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s)" % (sourceIDs[f],
                    legend, vm.getFieldNamesForFieldId(f), duration, duration/60.,
                    len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved)
        legend = ""
        mydict[sourceIDs[f]]['minutes_on_source'] = duration/60.
        mydict['minutes_on_science'] = scienceMinutes
        mydict['minutes_on_science_per_scan'] = scienceMinutesPerScan
        mydict['minutes_on_science_with_latency'] = scienceMinutesWithLatency
        mydict['percentage_time_on_science'] = 100*scienceMinutes/clockTimeMinutes
        mydict['clock_time'] = clockTimeMinutes
        mydict['source_ids'] = list(sourceIDs)
        mydict['num_of_sources'] = len(sourceIDs)
# might add this someday        
#        elevs = csvline.split(',')
#        startElev = float(elevs[-2])
#        stopElev = float(elevs[-1])
#        mydict['elevation_range'] = [startElev,stopElev]
    if (fullreport):
        wikiline2 += '%.1f | %.1f | ' % (totalMinutes, scienceMinutes)
        wikiline2 += wikiline3
    # Now get the PWV if possible
    pwvmean = -1
    if (casadef.casa_version >= casaVersionWithMSMD):
        mymsmd.close()
    if (telescopeName.find('ALMA')>=0):
        if (os.path.exists('ASDM_CALWVR') or os.path.exists(ms+'/ASDM_CALWVR')):
            if (os.path.exists(ms+'/ASDM_CALWVR')):
                [pwvmean, pwvstd]  = getMedianPWV(ms)
            else:
                [pwvmean, pwvstd]  = getMedianPWV('.')
        elif (os.path.exists('ASDM_CALATMOSPHERE') or os.path.exists(ms+'/ASDM_CALATMOSPHERE')):
            if (os.path.exists(ms+'/ASDM_CALATMOSPHERE')):
                [pwvmean, pwvstd]  = getMedianPWV(ms)
            else:
                [pwvmean, pwvstd]  = getMedianPWV('.')
        elif (os.path.exists(ms+'/CalWVR.xml')):
            [pwvtime, pwv, antenna] = readpwv(ms)
            pwvmean = np.mean(pwv)
        elif (os.path.exists('CalWVR.xml')):
            [pwvtime, pwv, antenna] = readpwv('.')
            pwvmean = np.mean(pwv)
        else:
            print "No ASDM_CALWVR, ASDM_CALATMOSPHERE or CalWVR.xml table found.  You should importasdm with asis='*' or copy the CalWVR.xml file from your ASDM to your working directory (or your ms directory)."
    tb.open(ms+'/ANTENNA')
    nAntennas = len(tb.getcol('NAME'))
    tb.close()
    if (fullreport): 
        if (pwvmean < 0):
            wikiline2 += ' unknown_PWV | %d ' % (nAntennas)
        else:
            wikiline2 += ' %.2f | %d |' % (pwvmean, nAntennas)
        wikiline2 += '   |'   # Requested by Andreas Lundgren on 2012-05-23  
    print "Latency removed: Total time = %.2f min,   science time = %.2f min" % (totalMinutes, scienceMinutes)
    csvline += ',%.1f,%.1f' % (totalMinutes, scienceMinutes)
    if (fullreport): 
        print "wikiline = %s" % (wikiline2)
        print csvline
    print "WARNING: This task does not account for any flagging."
    return(mydict) 
    # end of timeOnSource  vm.

def timeOnSourceMSMDs(vis, exclude='target.ms', bins=10, plotfile=''):
    """
    Calls timeOnSourceMSMD for a list of datasets
    vis: python list of ms or a comma-delimited or wildcard string
    exclude: if specified, exclude any vis with this string in the name
    -Todd Hunter
    """
    if type(vis) == str:
        if (vis.find('*')>=0):
            viss = sorted(glob.glob(vis))
        else:
            viss = vis.split(',')
    else:
        viss = vis
    if len(viss) < 1:
        print "No datasets found"
        return
    percentLatency = {}
    latencies = []
    for vis in viss:
        if exclude != '':
            if vis.find(exclude) >= 0:
                continue
        print "Examining: ", vis
        mydict = timeOnSourceMSMD(vis)
        percentLatency[vis] = mydict['latency_percent']
        latencies.append(percentLatency[vis])
    pb.clf()
    pb.hist(latencies, bins)
    pb.xlabel('Percent latency')
    pb.ylabel('Number of occurrences')
    pb.draw()
    if plotfile == '':
        plotfile = 'timeOnSourceMSMDs.png'
    pb.savefig(plotfile)
    return percentLatency

def timeOnSourceMSMD(vis='', field='', verbose=True, gapFactor=None, 
                     scienceSpwsOnly=True):
    """
    NOT YET VALIDATED.
    Uses msmd to get the integration timestamps and computes a
    list of durations on the fields specified, attempting to detect and
    account for the inter-subscan latency.  Returns a dictionary indexed
    by the source ID integer:
    {0: {'num_of_subscans': 2,
         'scans': [5],
         'field_id': [0],
         'source_name': '3c279',
         'minutes_on_source': 58.716000556945801,
         'minutes_on_source_with_latency': 65.664000511169434
         },
     ...
     'clock_time': 120
     'minutes_on_science': 58.716
     'minutes_on_science_with_latency': 65.66
     'percentage_time_on_science': 20.40
    }

It also prints a string convenient to a wikitable of format:
| date | SB name | exec UID | UT start-end | LST start-end | Total time | Time on source | el range | med pwv | antennas | 

Notes on this string:
1) If the pointing table has been deleted it will print "pointing table empty" in the elevation range column.
2) If there is no on-source time, it will print "no onsource time" in the elevation range column.
3) If neither the CalWVR.xml nor ASDM_CALWVR files are present, it will print "unknown" in the pwv column.
4) The median pwv is over the entire dataset, not just the on-source scans.
5) For the number of antennas, it does not detect whether an antenna has been totally flagged!

    For further help and examples, see http://casaguides.nrao.edu/index.php?title=TimeOnSource
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not open ms = %s" % (vis)
        return({})
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    sourceIDs = range(mymsmd.nfields())
    telescopeName = mymsmd.observatorynames()[0]
    mydict = {}
    field = parseFieldArgument(vis, field, mymsmd=mymsmd)[0]
    if (verbose):
        print "Considering non-CalAtmosphere, non-CalPointing, non-CalSideband scans."
        print "Total time on scans (including inter-subscan latency):"
    durations = []
    subscansAll = []
    fieldId = -1
    previousField = -1
    legend = "Field "
    multiField = False
    totalMinutes = 0
    scienceMinutesWithLatency = 0
    mydict = {}
    legend = ""
    multiFieldScansObserved = []
    scansMeasured = []
    for findex in range(len(field)):
        f = field[findex]
        durationWithLatency = 0
        scienceDurationWithLatency = 0
        scans = mymsmd.scansforfield(f)
        scansObserved = []
        totalSubscans = 0
        multiField = False
        if (findex < len(field)-1):
          if (sourceIDs[f] == sourceIDs[field[findex+1]]):
              multiField = True
              legend += '%2d,' % (f)
              for s in scans:
                  multiFieldScansObserved.append(s)
              continue
          else:
              legend += '%2d' % (f)
        else:
          if (sourceIDs[f] == sourceIDs[field[findex-1]]):
              multiField = True
              for s in scans:
                  multiFieldScansObserved.append(s)
              legend += '%2d' % (f)
          else:
              legend += '%2d' % (f)
        subscansPerScan = []
        if (multiField):
            scans = np.unique(multiFieldScansObserved)
        scans = list(set(scans) - set(scansMeasured))
        for s in scans:
            scansMeasured.append(s)
            intents = mymsmd.intentsforscan(s)
            skip = False
            for i in intents:
                if (i.find('CALIBRATE_ATMOSPHERE') >= 0 or 
                    i.find('CALIBRATE_POINTING') >= 0 or 
                    i.find('CALIBRATE_SIDEBAND') >= 0):
                    skip = True
            if (skip):
#                print "Skipping calibration scan %d" % (s)
                continue
            scansObserved.append(s)
            times = mymsmd.timesforscan(s)
            for t in times[:1]:# changed on June 6, 2017
                (d,subscans) = computeDurationOfScan(s, None, verbose=False, mymsmd=mymsmd,
                                                     gapFactor=gapFactor, vis=vis, scienceSpwsOnly=scienceSpwsOnly)
                scanLength = np.max(t) - np.min(t)
                if (scanLength == 0):
                    # This happens with simulated data as it has no subscans
                    scanLength = d
                durationWithLatency += scanLength
                totalSubscans += subscans
                subscansPerScan.append(subscans)
                if ('OBSERVE_TARGET#ON_SOURCE' in intents or 'OBSERVE_TARGET.ON_SOURCE' in intents
                     or 'OBSERVE_TARGET#UNSPECIFIED' in intents):
                    scienceDurationWithLatency += scanLength
        totalMinutes += durationWithLatency/60.
        scienceMinutesWithLatency += scienceDurationWithLatency/60.
        if (verbose):
            if (totalSubscans > 1 and multiField==False):
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s, %d subscans)" % (sourceIDs[f],
                   legend, mymsmd.namesforfields(f),
                   durationWithLatency, durationWithLatency/60.,
                   len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved, totalSubscans)
            else:
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s)" % (sourceIDs[f],
                   legend, mymsmd.namesforfields(f),
                   durationWithLatency, durationWithLatency/60.,
                   len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved)
        if (len(legend.split(',')) > 1):
            myfield = [int(x) for x in legend.split(',')]
        else:
            myfield = [f]
        mydict[sourceIDs[f]] = {'field_ids': myfield,
                     'source_name':mymsmd.namesforfields(f),
                     'scans': scansObserved,
                     'num_of_scans': len(scansObserved),
                     'num_of_fields': len(legend.split(',')),
                     'num_of_subscans': subscansPerScan,
                     'minutes_on_source_with_latency': durationWithLatency/60.,
                     'minutes_on_source': 0  # fill this in later
                     }
        legend = ""
    fullreport = True
    if (fullreport):
        [wikiline2,wikiline3,clockTimeMinutes,csvline] = lstrange(vis,verbose=False,mymsmd=mymsmd)
    else:
        clockTimeMinutes = computeClockTimeOfMS(vis, mymsmd=mymsmd)
    print "Clock time = %.2f min, Total time = %.2f min,  science time = %.2f min" % (clockTimeMinutes, totalMinutes, scienceMinutesWithLatency)
    csvline += ',%.2f,%.2f' % (totalMinutes, scienceMinutesWithLatency)
    
    if (verbose):
        print "\nMy attempt to detect and account for inter-subscan latency follows:"

    legend = ""
    multiField = False
    totalMinutes = 0
    scienceMinutes = 0
    fid = 0
    multiFieldScansObserved = []
    scansMeasured = []
    for findex in range(len(field)):
        f = field[findex]
        # f is the field ID
        duration = 0
        scienceDuration = 0
        scans = mymsmd.scansforfield(f)
        scansObserved = []
        totalSubscans = 0
        multiField = False
        if (findex < len(field)-1):
          if (sourceIDs[f] == sourceIDs[field[findex+1]]):
            multiField = True
            legend += '%2d,' % (f)
            for s in scans:
                multiFieldScansObserved.append(s)
            continue
          else:
            legend += '%2d' % (f)
        else:
          if (sourceIDs[f] == sourceIDs[field[findex-1]]):
            multiField = True
            legend += '%2d' % (f)
            for s in scans:
                multiFieldScansObserved.append(s)
          else:
            legend += '%2d' % (f)
        
        if (multiField):
            scans = np.unique(multiFieldScansObserved)
        scans = list(set(scans) - set(scansMeasured))
        for s in scans:
            scansMeasured.append(s)
            intents = mymsmd.intentsforscan(s)
            skip = False
            for i in intents:
                if (i.find('CALIBRATE_ATMOSPHERE') >= 0 or 
                    i.find('CALIBRATE_POINTING') >= 0 or
                    i.find('CALIBRATE_SIDEBAND') >= 0):
                    skip = True
            if (skip):
#                print "Skipping calibration scan %d" % (s)
                continue
            scansObserved.append(s)
            times = mymsmd.timesforscan(s)
            for t in times[:1]: # changed on June 6, 2017
                (d,subscans) = computeDurationOfScan(s,None,verbose=False,gapFactor=gapFactor,vis=vis,
                                                     scienceSpwsOnly=scienceSpwsOnly,mymsmd=mymsmd)
                duration += d
                totalSubscans += subscans
                if ('OBSERVE_TARGET#ON_SOURCE' in intents or 'OBSERVE_TARGET.ON_SOURCE' in intents or 
                    'OBSERVE_TARGET#UNSPECIFIED' in intents):
                    scienceDuration += d
        totalMinutes += duration/60.
        scienceMinutes += scienceDuration/60.
        if (verbose):
            fieldWarning = ""
            if (totalSubscans > 1 and multiField==False):
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s, %d subscans%s)" % (sourceIDs[f],
                 legend, mymsmd.namesforfields(f), duration, duration/60.,
                 len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved, totalSubscans, fieldWarning)
            else:
                print "Source %2d = Field %s = %s: %.1f sec = %.2f min (%d scan%s: %s)" % (sourceIDs[f],
                    legend, mymsmd.namesforfields(f), duration, duration/60.,
                    len(scansObserved), 's' if len(scansObserved)>1 else '', scansObserved)
        legend = ""
        mydict[sourceIDs[f]]['minutes_on_source'] = duration/60.
        mydict['minutes_on_science'] = scienceMinutes
        mydict['total_subscans'] = totalSubscans
        mydict['minutes_on_science_with_latency'] = scienceMinutesWithLatency
        mydict['percentage_time_on_science'] = 100*scienceMinutes/clockTimeMinutes
        mydict['clock_time'] = clockTimeMinutes
        mydict['total_time'] = totalMinutes
        mydict['latency_percent'] = (clockTimeMinutes-totalMinutes)*100/clockTimeMinutes
        mydict['source_ids'] = list(sourceIDs)
        mydict['num_of_sources'] = len(sourceIDs)
# might add this someday        
#        elevs = csvline.split(',')
#        startElev = float(elevs[-2])
#        stopElev = float(elevs[-1])
#        mydict['elevation_range'] = [startElev,stopElev]
    if (fullreport):
        wikiline2 += '%.1f | %.1f | ' % (totalMinutes, scienceMinutes)
        wikiline2 += wikiline3
    # Now get the PWV if possible
    pwvmean = -1
    if (telescopeName.find('ALMA')>=0):
        if (os.path.exists('ASDM_CALWVR') or os.path.exists(vis+'/ASDM_CALWVR')):
            if (os.path.exists(vis+'/ASDM_CALWVR')):
                [pwvmean, pwvstd]  = getMedianPWV(vis)
            else:
                [pwvmean, pwvstd]  = getMedianPWV('.')
        elif (os.path.exists('ASDM_CALATMOSPHERE') or os.path.exists(vis+'/ASDM_CALATMOSPHERE')):
            if (os.path.exists(vis+'/ASDM_CALATMOSPHERE')):
                [pwvmean, pwvstd]  = getMedianPWV(vis)
            else:
                [pwvmean, pwvstd]  = getMedianPWV('.')
        elif (os.path.exists(vis+'/CalWVR.xml')):
            [pwvtime, pwv, antenna] = readpwv(vis)
            pwvmean = np.mean(pwv)
        elif (os.path.exists('CalWVR.xml')):
            [pwvtime, pwv, antenna] = readpwv('.')
            pwvmean = np.mean(pwv)
        else:
            print "No ASDM_CALWVR, ASDM_CALATMOSPHERE or CalWVR.xml table found.  You should importasdm with asis='*' or copy the CalWVR.xml file from your ASDM to your working directory (or your ms directory)."
    nAntennas = mymsmd.nantennas()
    mymsmd.close()
    if (fullreport): 
        if (pwvmean < 0):
            wikiline2 += ' unknown_PWV | %d ' % (nAntennas)
        else:
            wikiline2 += ' %.2f | %d |' % (pwvmean, nAntennas)
        wikiline2 += '   |'   # Requested by Andreas Lundgren on 2012-05-23  
    print "Latency removed: Total time = %.2f min,   science time = %.2f min" % (totalMinutes, scienceMinutes)
    csvline += ',%.1f,%.1f' % (totalMinutes, scienceMinutes)
    if (fullreport): 
        print "wikiline = %s" % (wikiline2)
        print csvline
    print "WARNING: This task does not account for any flagging."
    return(mydict) 
    # end of timeOnSourceMSMD

def pickTimesForScan(mymsmd, scan, scienceSpwsOnly=True, useTimesForSpwsIfAvailable=False):
    """
    Chooses whether to run msmd.timesforscan() or the aU workaround for the 
    bug in CASA 4.4 (CAS-7622).  Called only by computeDurationOfScan.
    -Todd Hunter
    """
    if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.5'):
        t = getTimesForScan(mymsmd, scan)
    else:
        t = mymsmd.timesforscan(scan)
        if scienceSpwsOnly:
            scienceSpws = getScienceSpws(mymsmd.name(), mymsmd=mymsmd, returnString=False)
            if len(scienceSpws) == 0:
                print "There are no science spws, so considering all spws instead."
                scienceSpwsOnly = False
        if scienceSpwsOnly:
            if useTimesForSpwsIfAvailable:
                try:
                    # available starting in 5.1.0-46
                    print "Calling msmd.timesforspws(%s)" % (str(scienceSpws[0]))
                    times = mymsmd.timesforspws(scienceSpws[0])
                    t = np.intersect1d(times, t)
                except:
                    mytb = createCasaTool(tbtool)
                    mytb.open(mymsmd.name())
                    print "Restricting times to first spw: %d" % (scienceSpws[0])
                    myt = mytb.query('DATA_DESC_ID == %d && SCAN_NUMBER == %d' % (scienceSpws[0], scan))
                    times = myt.getcol('TIME')
                    myt.close()
                    mytb.close()
                    idx = np.where((t >= np.min(times)) & (t <= np.max(times)))
                    print "Dropped %d points" % (len(t)-len(idx))
                    t = t[idx]
            else:
                    mytb = createCasaTool(tbtool)
                    mytb.open(mymsmd.name())
                    print "Restricting times to spw %d for scan %d" % (scienceSpws[0],scan)
                    myt = mytb.query('DATA_DESC_ID == %d && SCAN_NUMBER == %d' % (scienceSpws[0], scan))
                    times = myt.getcol('TIME')
                    myt.close()
                    mytb.close()
                    if False:
                        # This will include SQLD, and was the old version of the code
                        idx = np.where((t >= np.min(times)) & (t <= np.max(times)))
                        print "Dropped %d points" % (len(t)-len(idx))
                        t = t[idx]
                    else:
                        # This will not include SQLD.
                        t = np.unique(times)
    return (t)

def pickScansForField(mymsmd, field):
    """
    Chooses whether to run msmd.scansforfield() or the workaround for the 
    bug in CASA 4.4 (CAS-7622).
    field: should be an integer
    -Todd Hunter
    """
    if (casadef.casa_version >= '4.4' and casadef.casa_version < '4.5'):
        s = getScansForField(mymsmd, field)
    else:
        s = mymsmd.scansforfield(field)
    return(s)

def getTimesForScan(mymsmd,scan):
    """
    This function replaces msmd.timesforscan() in CASA 4.4 release, which 
    has a bug in that it does not find scans not in obs ID=0.
    It should not be necessary once CASA 4.5 is released.
    Returns a list in MJD seconds.
    -Todd Hunter
    """
    if (casadef.casa_version < '4.4' or casadef.casa_version >= '4.5'):
        t = mymsmd.timesforscan(scan)
        return(t)
    allscans = mymsmd.scansforintent('*')
    obsids = mymsmd.nobservations()
    t = []
    for o in range(obsids):
        scans = mymsmd.scannumbers(o)
        if scan in scans:
            t = mymsmd.timesforscan(scan, obsid=o)
    return(t)
    
def getScansForField(mymsmd, field):
    """
    This function replaces msmd.scansforfield() in CASA 4.4 release, which 
    has a bug in that it does not find scans not in obs ID=0.
    It should not be necessary once CASA 4.5 is released.
    -Todd Hunter
    """
    allscans = mymsmd.scansforintent('*')
    obsids = mymsmd.nobservations()
    t = []
    for o in range(obsids):
        scans = mymsmd.scannumbers(o)
        f = mymsmd.fieldsforscans(scans,obsid=o)
        if field in f:
            t += list(mymsmd.scansforfield(field, obsid=o))
    return(np.array(t))
    
def computeDurationOfScans(vis, scanNumbers=None, intent=None, verbose=False, 
                           gapFactor=None, includeDate=False, mymsmd=None,
                           includeSubscans=False, scienceSpwsOnly=False):
    """
    Runs computeDurationOfScan for a list of scans. 
    Returns: a dictionary keyed by scan number, each containing sub-dictionaries
             keyed by 'duration' (in seconds) and number of 'integrations'.
    includeSubscans: if True, include inferred number of 'subscans' (not always accurate)
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if (mymsmd is None):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        keepmymsmd = False
    else:
        keepmymsmd = True
    returnSubscanTimes = False
    mydict = {}
    if (scanNumbers is None):
        if (intent is None):
            scanNumbers = mymsmd.scannumbers()
        else:
            scanNumbers = mymsmd.scansforintent('*'+intent+'*')
            scienceSpws = mymsmd.almaspws(tdm=True, fdm=True)
    for scan in scanNumbers:
        spws = mymsmd.spwsforscan(scan)
        spw = np.intersect1d(spws, scienceSpws)[0]
        duration, subscans = computeDurationOfScan(scan, None, vis, returnSubscanTimes,
                                                   verbose, gapFactor, includeDate, mymsmd, scienceSpwsOnly)
        mydict[scan] = {'duration': duration}
        mydict[scan]['integrations'] = int(np.round(duration / mymsmd.exposuretime(scan, spw)['value'],0))
        if includeSubscans:
            mydict[scan]['subscans'] = subscans
    if (not keepmymsmd): mymsmd.close()
    return(mydict)

def computeDurationOfScan(scanNumber,t=None, vis=None, returnSubscanTimes=False,
                          verbose=False, gapFactor=None, includeDate=False, 
                          mymsmd=None, scienceSpwsOnly=False):
    """
    This function is used by timeOnSource() to empirically determine the number
    of subscans and the total duration of all the subscans of a particular scan.
    Inputs:
    scanNumber: the scan number, simply for generating a file list of timestamps
    t = a sequence of integration timestamps (optional for casa >= 4.1.0)
    vis = the measurement set (not necessary if t is given)
    mymsmd = an msmd instance (as an alternative to vis)
    gapFactor: default=2.75 for integrations<1sec, 2.0 otherwise
    Returns:
    1) duration in seconds
    2) the number of subscans
    and if returnSubscanTimes==True
    3) the begin/end timestamps of each subscan
    4) the begin/end timestampStrings of each subscan
    -- Todd Hunter
    """
    if (t is None and vis is None and (mymsmd is None or mymsmd=='')):
        print "You must specify either vis, mymsmd or t."
        return
    keepmymsmd = False
    if (t is None): 
        if (casadef.casa_version < casaVersionWithMSMD):
            print "For this version of casa, you must specify t rather than vis."
            return
        if (mymsmd is None or mymsmd == ''):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
        else:
            keepmymsmd = True
    elif (mymsmd is None or mymsmd==''):  # fix for CSV-2903 on 29-Apr-2016
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    else:
        keepmymsmd = True
    if (t is None): 
        t = pickTimesForScan(mymsmd, scanNumber, scienceSpwsOnly=scienceSpwsOnly)
    else:
        t = np.unique(t)
    if (len(t) <= 1):
        if (casadef.casa_version < casaVersionWithMSMD):
            print "This version of CASA is too old for this function to handle single-dump integrations."
            return(0,0)
        elif len(t) == 0:
            return(0,0)
        else:
            if (scanNumber==1):
                duration = np.min(pickTimesForScan(mymsmd, scanNumber+1, scienceSpwsOnly=scienceSpwsOnly)) - t[0]
            else:
                duration = t[0] - np.max(pickTimesForScan(mymsmd, scanNumber-1, scienceSpwsOnly=scienceSpwsOnly))
            if (not keepmymsmd): mymsmd.close()
            if (returnSubscanTimes):
                timestampsString = mjdsecToTimerange(t[0]-0.5*duration,t[0]+0.5*duration,
                                                     decimalDigits=1,includeDate=includeDate)
                return(duration,1,{0:t},{0:timestampsString})
            else:
                return(duration,1)
    else:
        if (mymsmd is not None and mymsmd != '' and not keepmymsmd): 
            mymsmd.close()
        d = np.max(t) - np.min(t)
        # initial estimate for interval
        diffs = np.diff(t)
        avgInterval = np.median(diffs)
        startTime = previousTime = t[0]
        subscans = 1
        if (gapFactor is None):
            if (avgInterval > 1):
                gapFactor = 2
            else:
                gapFactor = 2.75 # it was 3 for a long time, but failed on 2013-01-24 dataset (2014-09-23)
        startTime = previousTime = t[0]
        duration = 0
        tdiffs = []
        s = ''
        timestamps = {}
        timestampsString = {}
        droppedTimeTotal = 0
        daygaps = 0
        for i in range(1,len(t)):
            s += "%.2f " % (t[i]-t[0])
            tdiff = t[i]-previousTime
            tdiffs.append(tdiff)
            if (tdiff > gapFactor*avgInterval):
                droppedTime = t[i]-previousTime+avgInterval
                droppedTimeTotal += droppedTime
                if droppedTime > 12*3600:
                    daygaps += droppedTime
                if (verbose):
                    print "    ***********************"
                    print "    i=%d, Dropped %.1f seconds" % (i,droppedTime)
                subscanLength = t[i-1] - startTime + avgInterval
                duration += subscanLength
                if (subscanLength > 1.5*avgInterval):
                    # Don't count single point subscans because they are probably not real.
                    timestamps[subscans] = [startTime,t[i-1]]
                    timestampsString[subscans] = mjdsecToTimerange(startTime,t[i-1],decimalDigits=1,includeDate=includeDate)
                    if (verbose):
                        print "Scan %d: Subscan %d: %s, duration=%f" % (scanNumber,subscans,s,subscanLength)
                    s = ''
                    subscans += 1
                elif (verbose):
                    print "Scan %d: dropped a dump of length %f because it was between subscans" % (scanNumber,subscanLength)
                startTime = t[i]
            previousTime = t[i]
        if (droppedTimeTotal > 0 and verbose):
            print "+++++ Scan %d: total dropped time = %.1f seconds = %.1f minutes" % (scanNumber,droppedTimeTotal, droppedTimeTotal/60.)
        if daygaps > 0:
            print "+++++ Scan %d: large time gaps: %.1f sec = %.1f hrs = %.1f days" % (scanNumber,daygaps,daygaps/3600.,daygaps/86400.)
        duration += t[len(t)-1] - startTime
        timestamps[subscans] = [startTime,t[len(t)-1]]
        timestampsString[subscans] = mjdsecToTimerange(startTime,t[len(t)-1],decimalDigits=1,includeDate=includeDate)
    if (returnSubscanTimes):
        return(duration, subscans, timestamps, timestampsString)
    else:
        return(duration, subscans)

def plotWVRSolutions(caltable='',spw=[],field=[],subplot=22,sort='number',
                     antenna='',xrange=[0,0], yrange=[0,0],figfile='',
                     unwrap=False,xaxis='ut',interactive=True,ms='',
                     showFlaggedSolutions=False, usems=True,buildpdf=False,
                     pdfname='', autoExpandYrange=True):
    """
    Because running plotcal on WVR tables includes the common mode delay,
    it is not so useful, as all antennas often appear very similar.  In
    this function, we compute the phase difference for each baseline and
    plot this vs. time.  -  Todd Hunter
    Options:
    antenna: can be ID or name; single value, or list: 0,'0','0,1','DV04,DV05'
    field: must be field ID, or list of IDs, or comma-delimited string of IDs
    figfile: will append .0.png, .1.png, etc. for successive pages
    interactive: True or False (True will require user input after showing each page)
    ms: specify the ms name rather than look for it in the caltable
    sort: by baseline 'number',  or by baseline 'length'
    subplot:   valid values: 11,12,21,22,23,32,42  (any 3rd digit is ignored)
    unwrap: attempt to further unwrap the 360-deg phase wraps after
            Ed's algorithm
    xaxis: 'seconds' or 'ut' (default)
    xrange: min/max time to show:  specify in seconds if xaxis='seconds'
            or floating point UT hours if 'ut'.  The latter will 
            probably not work well if the data cross the 0/24 hour mark.
    yrange: min/max phase to show
    autoExpandYrange: if True, the override yrange until all data are shown
    showFlaggedSolutions: Boolean, default=False, if either antenna's
            WVR solution is flagged, then don't show it on the baseline plot
    usems: set to False if you don't want to risk disturbing someone else's use
           of the measurement set by causing a write-lock on the ms
    buildpdf: if True, then compile a multipage PDF of all the pngs.  Requires
           you to specify the figfile parameter.
    For further help and examples, see:
      https://safe.nrao.edu/wiki/bin/view/ALMA/PlotWVRSolutions
    --- Todd Hunter
    """
    plotctr = 0
    myhspace = 0.25
    mywspace = 0.25
    maxFieldsInLegend = 24
    if buildpdf and figfile == '':
        print "You must set figfile if you request buildpdf=True"
        return

    if (type(antenna) == str):
        if (antenna.find('&')>=0):
            print "The '&' character is not supported (yet)."
            return
    if (sort != '' and sort != 'length' and sort != 'number'):
        print "Invalid sort option.  Options are 'length' or 'number'."
        return
    if (xaxis != 'ut' and xaxis.find('sec')<0):
        print "Invalid xaxis option.  Options are 'ut' or 'seconds'."
        return

    validSubplots= [11,12,21,22,23,32,42]
    if (type(subplot) == str):
        subplot = int(subplot)
    if (subplot > 100):
        # allow 111, 221, etc. to be consistent with other casa commands
        subplot = int(subplot/10)
    if ((subplot in validSubplots) == False):
        print "Invalid subplot option.  Options are: ", validSubplots
        print "With an optional trailing digit that will be ignored."
        return
    xframe = xframeStart = subplot*10
    xframeStop = xframeStart + ((subplot%10)*int(subplot/10))
    # row column
    topRow = [111,121,122,211,221,222,231,232,233,321,322,421,422]
    bottomRow = [111,121,122,212,223,224,234,235,236,325,326,427,428]
    leftColumn = [111,121,211,212,221,223,231,234,321,323,325,421,423,425,427]
    subplotRows = int(subplot/10)
    
    if (subplot == 11):
        mysrcsize = 10
        mysize = 10
        titlesize = 12
    else:
        mysrcsize = 8
        mysize = 8
        titlesize = 10
        
    if (os.path.exists(caltable)):
        try:
            print "Opening cal table..."
            tb.open(caltable)
        except:
            print "Could not open caltable = ", caltable
            return
    else:
        print "Caltable does not exist = ", caltable
        return
    times = tb.getcol("TIME")
    antennas = tb.getcol("ANTENNA1")
    flags = tb.getcol("FLAG")[0][0]
    uniqueAntennaIds = np.unique(antennas)
    fields = tb.getcol("FIELD_ID")
    uniqueFields = np.unique(fields)
    names = tb.colnames()
    if ('SNR' not in names):
        print "This does not appear to be a cal table. Is it the .ms?"
        return
    if ('SPECTRAL_WINDOW_ID' in names):
        msName = tb.getkeyword('MSName')      
        cal_desc_id = tb.getcol("SPECTRAL_WINDOW_ID")
        spectralWindowTable = tb.getkeyword('SPECTRAL_WINDOW').split()[1]
        ParType = tb.getkeyword('ParType')    # string = 'Complex'
        if (ParType != 'Complex'):
            print "This does not appear to be a gain calibration table because the data type is %s." % (ParType)
            return
        gain = tb.getcol('CPARAM')[0][0]  # Here we must be assuming single-pol corrections
        tb.close()
#        tb.open(spectralWindowTable)
    else:  # old-style cal table
        cal_desc_id = tb.getcol("CAL_DESC_ID")
        gain = tb.getcol("GAIN")[0][0]  # Here we must be assuming single-pol corrections
        tb.open(caltable+'/CAL_DESC')
        msName = tb.getcell('MS_NAME',0)
        tb.close()
    if (ms != ''):
        msName = ms
    print "Running ValueMapping on %s... (this may take a minute)" % (msName)
    vm = False
    if (os.path.exists(msName) and usems):
        vm = ValueMapping(msName)
        msFound = True
    else:
        if (caltable.find('/')>=0):
            tokens = caltable.split('/')
            fname = ''
            for i in range(len(tokens)-1):
                fname += tokens[i] + '/'
            print "failed to open %s, will try %s" % (msName,fname+msName)
            if (os.path.exists(fname+msName) and usems):
                vm = ValueMapping(fname+msName)
                msFound = True
                msName = fname+msName
            else:
                msFound = False
        else:
            msFound = False
    
    # Continue to parse the command line
    if (type(figfile) == str):
        if (figfile.find('/')>=0):
            directories = figfile.split('/')
            directory = ''
            for d in range(len(directories)-1):
                directory += directories[d] + '/'
            if (os.path.exists(directory)==False):
                print "Making directory = ", directory
                os.system("mkdir -p %s" % directory)

    antlist = parseAntennaArgument(antenna, uniqueAntennaIds, msName)
    if (len(antlist) > 0):
        antennasToPlot = np.intersect1d(uniqueAntennaIds,antlist)
    else:
        antennasToPlot = uniqueAntennaIds
    print "antennasToPlot = ", antennasToPlot
    
    legend = ''
    for a in antennasToPlot:
        if (a != antennasToPlot[0]):
            legend += ', '
        if (msFound):
            legend += vm.getAntennaNamesForAntennaId(a)
    if (msFound):
        print "Baselines including these antennas will be plotted = ", legend

    spwlist = spw
    if (spwlist == []):
#        print "cal_desc_id = ", cal_desc_id
        spwlist = vm.spwInfo.keys()
    elif (type(spw) == int):
        spwlist = [spw]
    elif (type(spw) == str):
        if (str.isdigit(spw)):
            spwlist = [int(spw)]
        elif (spw.find(',')>=0):
            spwstrings = spw.split(',')
            spwlist = []
            for i in spwstrings:
                spwlist.append(int(i))
        else:
            spwlist = vm.spwInfo.keys()
#            print "spw is a blank string"
    else:
        print "Invalid spw"
        return
    if (msFound):
        print "spws in the dataset = ", vm.spwInfo.keys() # range(len(vm.spwInfo))
    print "spws to plot = ", spwlist
    if (msFound):
        for spw in spwlist:
            if (spw not in vm.spwInfo.keys() or spw < 0):
                print "spw %d is not in the dataset" % (spw)
                return
    if (len(spwlist) > 1):
        print "*** Note: WVR solutions for different spws differ only by the frequency ratio."
        print "*** So, examining only one of them is usually sufficient (and faster)."

    # Parse the field string to emulate plotms
    removeField = []
    if (type(field) == str):
     myValidCharacterListWithBang = ['~', ',', ' ', '*', '!',] + [str(m) for m in range(10)]
     if (len(field) == sum([m in myValidCharacterListWithBang for m in field])):
         # a list of field numbers was given
         tokens = field.split(',')
         fieldlist = []
         for token in tokens:
             if (token.find('*')>=0):
                 fieldlist = uniqueFields
                 break
             elif (token.find('!')==0):
                 fieldlist = uniqueFields
                 removeField.append(int(token[1:]))
             elif (len(token) > 0):
                 if (token.find('~')>0):
                     (start,finish) = token.split('~')
                     fieldlist +=  range(int(start),int(finish)+1)
                 else:
                     fieldlist.append(int(token))
         fieldlist = np.array(fieldlist)
         for rm in removeField:
             fieldlist = fieldlist[np.where(fieldlist != rm)[0]]
         fieldlist = list(fieldlist)
         if (len(fieldlist) < 1 and len(removeField)>0):
             print "Too many negated fields -- there are no fields left to plot."
             return(vm)
     else:
         # The field name (or list of names, or wildcard) was specified
         tokens = field.split(',')
         if (msFound):
             fieldlist = []
             removeField = []
             for token in tokens:
                 myloc = token.find('*')
                 if (myloc > 0):
                     for u in uniqueFields:
                         if (token[0:myloc]==vm.getFieldNamesForFieldId(u)[0:myloc]):
                             if (DEBUG):
                                 print "Found wildcard match = %s" % vm.getFieldNamesForFieldId(u)
                             fieldlist.append(u)
                         else:
                             if (DEBUG):
                                 print "No wildcard match with = %s" % vm.getFieldNamesForFieldId(u)
                 elif (myloc==0):
                     for u in uniqueFields:
                         fieldlist.append(u)
                 elif (token in vm.uniqueFields):
                     fieldlist = list(fieldlist)  # needed in case preceding field had ! modifier
                     fieldlist.append(vm.getFieldIdsForFieldName(token))
                 elif (token[0] == '!'):
                     if (token[1:] in vm.uniqueFields):
                         fieldlist = uniqueFields
                         removeField.append(vm.getFieldIdsForFieldName(token[1:]))
                     else:
                         print "Field %s is not in the ms. It contains: " % (token), vm.uniqueFields
                         return(vm)
                 else:
                     print "Field %s is not in the ms. It contains: " % (token), vm.uniqueFields
                     return(vm)
             fieldlist = np.array(fieldlist)
             for rm in removeField:
                 fieldlist = fieldlist[np.where(fieldlist != rm)[0]]
             fieldlist = list(fieldlist)
             if (len(fieldlist) < 1 and len(removeField)>0):
                 print "Too many negated fields -- there are no fields left to plot."
                 return(vm)
         else:
             print "Fields cannot be specified my name if the ms is not found."
             return(vm)
    elif (type(field) == list):
      # it's a list of integers
      fieldlist = field
    else:
      # It's a single, integer entry
      fieldlist = [field]

    if (len(fieldlist) > 0):
      fieldsToPlot = np.intersect1d(uniqueFields,np.array(fieldlist))
      if (len(fieldsToPlot) < 1):
          print "Source not found in ms"
          return(vm)
    else:
      fieldsToPlot = uniqueFields  # use all fields if none are specified

    if (msFound):
        print "fields in the dataset = ", range(len(vm.uniqueFields))
    print "Fields to plot = ", fieldsToPlot
    if (msFound):
        for x in fieldsToPlot:
            if (x < 0 or x >= len(vm.uniqueFields)):
                print "Field %d is not in the dataset" % (x)
                return

    # Fill the array of baselineLengths
    baselines = []
    if (msFound):
        baselineLength = np.zeros([len(uniqueAntennaIds), len(uniqueAntennaIds)])
        for i in uniqueAntennaIds:
            for j in antennasToPlot:
                if (i != j): 
                    baselineLength[i][j] = getBaselineLength(msName,i,j,verbose=False)[0]
                    baselineLength[j][i] = baselineLength[i][j]
                    if (i in antennasToPlot or j in antennasToPlot):
                        baselines.append([np.min([i, j]), np.max([i,j]), baselineLength[i][j]])
    else:
        for i in range(len(uniqueAntennaIds)):
            for j in antennasToPlot:
                if (i != j): # and (i in antennasToPlot) and (j in antennasToPlot)):
                    baselines.append([np.min([i,j]), np.max([i,j]), 0])
    sortedBaselines = baselines
    # sort the baselineLengths of the antennas to plot
    if (sort.find('length')>=0 and msFound):
        for i in range(1,len(sortedBaselines)):
            for j in range(1,len(sortedBaselines)):
                if (sortedBaselines[j][2] < sortedBaselines[j-1][2]):
                    swap = sortedBaselines[j-1]
                    sortedBaselines[j-1] = sortedBaselines[j]
                    sortedBaselines[j] = swap
    pb.ion()  # Added on April 26, 2012 to address Crystal's problem
    pb.clf()
    pngs = []
    for s in range(len(spwlist)):
        spw = spwlist[s]
        matchField = np.where(cal_desc_id == spw)[0]
        index = 0
        for myi in range(len(baselines)):
            if (sort.find('length')<0):
                i = baselines[myi][0]
                j = baselines[myi][1]
            else:
                i = sortedBaselines[myi][0]
                j = sortedBaselines[myi][1]
            matches = np.intersect1d(matchField,np.where(antennas==i)[0])
            antenna1 = antennas[matches]
            time1 = times[matches]
            gain1 = gain[matches]
            flags1 = flags[matches]
            fields1 = fields[matches]
            matches2 = np.intersect1d(matchField,np.where(antennas==j)[0])
            gain2 = gain[matches2]
            flags2 = flags[matches2]
            if (not showFlaggedSolutions):
                idx1 = np.where(flags1 == False)[0]
                idx2 = np.where(flags2 == False)[0]
                unflaggedPoints = np.intersect1d(idx1,idx2)
                time1 = time1[unflaggedPoints]
                fields1 = fields1[unflaggedPoints]
                antenna1 = antenna1[unflaggedPoints]
                
# This was only needed to check that times agreed, and they do.
#            antenna2 = antennas[matches2]
#            time2 = times[matches2]
#            fields2 = fields[matches2]
#            (agreement, failures) = checkTimeAgreement(i,j,time1,time2,fid=0)
#            if (agreement == False):
#                print "Time mismatch at baseline %d-%d, " % (antenna1[0],antenna2[0])
#                continue
            if (len(time1) > 0):
                startTime = time1[0]
                if (xaxis.find('sec')>=0):
                    timeplot = time1 - startTime
                else:
    #                print "converting starting MJD seconds (%f) to UT hours" % (startTime)
                    timeplot = 24*(time1/86400. - floor(time1[0]/86400.))
            else:
                timeplot = time1
            phasediff = np.arctan2(np.imag(gain1), np.real(gain1)) - np.arctan2(np.imag(gain2),np.real(gain2))
            if (not showFlaggedSolutions):
                phasediff = phasediff[unflaggedPoints]
            phasediff = phaseUnwrap(phasediff)
            posvalues = phasediff[np.where(phasediff>0)[0]]
            if (len(posvalues) > 0):
                if (np.median(posvalues) > math.pi/2.):
                    phasediff -= np.median(posvalues)
                else:
                    phasediff -= np.median(phasediff)
            elif (len(phasediff) > 0):
                phasediff -= np.median(phasediff)
            if (unwrap):
                  for i in range(len(phasediff)):
                    while (phasediff[i] > math.pi):
                        phasediff[i] -= 2*math.pi
                    while (phasediff[i] < -math.pi):
                        phasediff[i] += 2*math.pi
            phasediff *= 180/np.pi
            xframe += 1
            if (xframe > xframeStop):
                if (len(fieldsToPlot) <= maxFieldsInLegend and len(fieldsToPlot) < len(overlayColors)):
                    DrawSourceLegend(yrange, fieldsToPlot, msFound, vm, subplotRows, mysrcsize)
                if (interactive):
                    pb.draw()
                    myinput = raw_input("Press return for next page (q to quit): ")
                else:
                    if (figfile!=''):
                        print "Plotting page %d" % (plotctr)
                    myinput = ''
                if (figfile!=''):
                    if (figfile == True):
                        png = caltable+'.plotWVRSolutions.%03d.png'%plotctr
                    else:
                        png =  figfile.split('.png')[0]+'.%03d.png'%plotctr
                    pb.savefig(png, density=108)
                    plotctr += 1
                    pngs.append(png)
                if (myinput.find('q')>=0):
                    return
                pb.clf()
                xframe = xframeStart+1
#            print "Plotting baseline %d-%d (%s-%s) on spw %d" % (i,j,
#                    vm.getAntennaNamesForAntennaId(i),vm.getAntennaNamesForAntennaId(j),spw)
            adesc = pb.subplot(xframe)
            pb.hold(True)
            resizeFonts(adesc,mysize)
            if ((xrange[0] != 0 or xrange[1] != 0) and yrange[0] ==0 and yrange[1]==0):
                # recalculate the y limits for the displayed range
                tmatches1 = np.where(timeplot > xrange[0])[0]
                tmatches2 = np.where(timeplot <= xrange[1])[0]
                tmatches = np.intersect1d(tmatches1,tmatches2)
                phasediff -= np.median(phasediff[tmatches])
                ylim = [np.min(phasediff[tmatches]), np.max(phasediff[tmatches])]
                myyrange = ylim[1]-ylim[0]
                ylim = [ylim[0]-0.1*myyrange,ylim[1]+0.1*myyrange]
            else:
                ylim = pb.ylim()
            list_of_date_times = mjdSecondsListToDateTime(time1)
            timeplotMatches = pb.date2num(list_of_date_times)
            if (len(time1) > 0):
              for f in range(len(fieldsToPlot)):
                field = fieldsToPlot[f]
                matches = np.where(fields1 == field)[0]
                if (xaxis.find('ut') >= 0):
                    pdesc = adesc.plot_date(timeplotMatches[matches],phasediff[matches],'.')
                    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
                    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
                    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
                    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
                    RescaleXAxisTimeTicks(pb.xlim(), adesc)
                else:
                    pdesc = pb.plot(timeplot[matches],phasediff[matches],'.')
                if (len(fieldsToPlot) < len(overlayColors)):
                    pb.setp(pdesc, color=overlayColors[field])
                    pb.setp(pdesc, markeredgewidth=0)  # prevent black border on each point
                else:
                    pb.setp(pdesc, color='b')
                    pb.setp(pdesc, markeredgewidth=0)  # prevent black border on each point
            if (xframe in bottomRow):
                if (xaxis.find('sec')>=0):
                    pb.xlabel("Time since start (sec)", size=mysize)
                else:
                    if (len(time1) > 0):
                        pb.xlabel("Time (UT on %s)"%(plotbp3.utdatestring(startTime)), size=mysize)
            if (xframe in leftColumn):
                pb.ylabel("Phase difference (deg)", size=mysize)
            titleString = 'No unflagged solutions on this baseline'
            if (msFound):
                if (len(matches2) > 0 and len(antenna1) > 0):
                    if (len(antennas[matches2]) > 0):
                        titleString = '%.0fm Baseline %d-%d=%s-%s, spw%d=%.1fGHz' % (baselineLength[antenna1[0]][antennas[matches2][0]],
                           antenna1[0], antennas[matches2][0],
                           vm.getAntennaNamesForAntennaId(antenna1[0]),
                           vm.getAntennaNamesForAntennaId(antennas[matches2][0]),spw,
                           np.mean(getFrequencies(msName,spw)*1e-9))
            else:
                if (len(matches2) > 0 and len(antenna1) > 0):
                    if (len(antennas[matches2]) > 0):
                        titleString = 'Baseline %d-%d, spw %d' % (antenna1[0], antennas[matches2][0], spw)
            pb.title(titleString, size=mysize)

            pb.subplots_adjust(hspace=myhspace, wspace=mywspace)
            yFormatter = ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            if (xrange[0] != 0 or xrange[1] != 0):
                if (xaxis.find('sec')>=0):
                    pb.xlim(xrange)
                else:
                    avgdatetime = num2date(np.mean(timeplotMatches[matches]))
                    avgdate = datetime.datetime.date(avgdatetime)
                    d1 = pb.date2num(avgdate) + xrange[0]/24.
                    d2 = pb.date2num(avgdate) + xrange[1]/24.
                    pb.xlim([d1,d2])
                pb.ylim(ylim)
            else:
                if (xaxis.find('sec')>=0):
                    pb.xlim(0, np.max(times)-np.min(times))

            xlim = pb.xlim()
            if (len(time1) < 1):
                print "No unflagged points on this baseline: %d-%d" % (i, j)
                pb.xticks([])
            else:
                if (xlim[1] - xlim[0] < 10/1440.):
                    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
                    adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,30)))
                elif (xlim[1] - xlim[0] < 0.5/24.):
                    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
                    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
                elif (xlim[1] - xlim[0] < 1/24.):
                    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
                    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,2)))
                
            if (yrange[0] != 0 or yrange[1] != 0):
                my_yrange = yrange[:]
                if (len(phasediff) > 0 and autoExpandYrange):
                    # check if data go outside, then expand range (for current panel only)
                    if (np.max(phasediff) > yrange[1] or np.min(phasediff) < yrange[0]):
                        my_yrange = [-360,360]
                        if (np.max(phasediff) > my_yrange[1] or np.min(phasediff) < my_yrange[0]):
                            my_yrange = [-540,540]
                            if (np.max(phasediff) > my_yrange[1] or np.min(phasediff) < my_yrange[0]):
                                my_yrange = [-720,720]
                pb.ylim(my_yrange)
                
            if (xframe in leftColumn and xframe in topRow):
                (xlim,ylim,myxrange,myyrange) = GetLimits()
                pb.text(0, 1.12, caltable+' computed for '+msName.split('/')[-1],
                        size=titlesize, transform=adesc.transAxes)
        if (len(fieldsToPlot) <= maxFieldsInLegend and len(fieldsToPlot) < len(overlayColors)):
            DrawSourceLegend(yrange, fieldsToPlot, msFound, vm, subplotRows, mysrcsize)
                        
    pb.draw()
    if (figfile!=''):
        if (figfile == True):
            try:
                png = caltable+'.plotWVRSolutions.%03d.png'%plotctr 
#                print "Running savefig('%s', density=108)" % (png)
                pb.savefig(png, density=108)
                pngs.append(png)
            except:
                print "WARNING1:  Could not save plot file.  Do you have write permission here?"
        else:
            try:
                png = figfile+'.%03d.png'%plotctr
                pb.savefig(png, density=108)
                pngs.append(png)
            except:
                print "WARNING2:  Could not save plot file.  Do you have write permission here?"
        if (buildpdf):
            if (pdfname == ''):
                if (figfile == True):
                    pdfname = caltable+'.plotWVRSolutions.pdf'
                else:
                    pdfname = figfile + '.pdf'
            else:
                if (pdfname.lower().find('.pdf') < 0):
                    pdfname += '.pdf'
            buildPdfFromPngs(pngs, pdfname)

# end of plotWVRSolutions()

def plotWVRSolutions2(caltable='',spw=[],field=[],subplot=22,sort='number',
                     antenna='',xrange=[0,0], yrange=[0,0],figfile='',
                     unwrapMethod='fomalont',help=False,xaxis='ut',interactive=True,
                     ms='', buildpdf=False, pdfname='', removeMedian=False):
    """
    Test version, which uses msmd instead of ValueMapping

    Because running plotcal on WVR tables includes the common mode delay,
    it is not so useful, as all antennas often appear very similar.  In
    this function, we compute the phase difference for each baseline and
    plot this vs. time.  -  Todd Hunter
    Options:
    antenna: can be ID or name; single value, or list: 0,'0','0,1','DV04,DV05'
    field: must be field ID, or list of IDs, or comma-delimited string of IDs
    figfile: will append .0.png, .1.png, etc. for successive pages
    interactive: True or False (True will require user input after showing each page)
    ms: specify the ms name rather than look for it in the caltable
    sort: by baseline 'number',  or by baseline 'length'
    subplot:   valid values: 11,12,21,22,23,32,42  (any 3rd digit is ignored)
    unwrapMethod: 'fomalont', 'extrapolate', 'differences', 'interpolate'
    xaxis: 'seconds' or 'ut' (default)
    xrange: min/max time to show:  specify in seconds if xaxis='seconds'
            or floating point UT hours if 'ut'.  The latter will 
            probably not work well if the data cross the 0/24 hour mark.
    yrange: min/max phase to show
    For further help and examples, see:
      https://safe.nrao.edu/wiki/bin/view/ALMA/PlotWVRSolutions
    --- Todd Hunter
    """
    unwrapMethods = ['','fomalont','extrapolate','differences','interpolate']
    if (unwrapMethod not in unwrapMethods):
        print "Invalid unwrap method.  Must be one of: ", str(unwrapMethods)
        return
    plotctr = 0
    myhspace = 0.25
    mywspace = 0.25
    maxFieldsInLegend = 24
    pngs = []
    if (type(antenna) == str):
        if (antenna.find('&')>=0):
            print "The '&' character is not supported (yet)."
            return
    if (sort != '' and sort != 'length' and sort != 'number'):
        print "Invalid sort option.  Options are 'length' or 'number'."
        return
    if (xaxis != 'ut' and xaxis.find('sec')<0):
        print "Invalid xaxis option.  Options are 'ut' or 'seconds'."
        return

    validSubplots= [11,12,21,22,23,32,42]
    if (type(subplot) == str):
        subplot = int(subplot)
    if (subplot > 100):
        # allow 111, 221, etc. to be consistent with other casa commands
        subplot = int(subplot/10)
    if ((subplot in validSubplots) == False):
        print "Invalid subplot option.  Options are: ", validSubplots
        print "With an optional trailing digit that will be ignored."
        return
    xframe = xframeStart = subplot*10
    xframeStop = xframeStart + ((subplot%10)*int(subplot/10))
    # row column
    topRow = [111,121,122,211,221,222,231,232,233,321,322,421,422]
    bottomRow = [111,121,122,212,223,224,234,235,236,325,326,427,428]
    leftColumn = [111,121,211,212,221,223,231,234,321,323,325,421,423,425,427]
    subplotRows = int(subplot/10)
    
    if (subplot == 11):
        mysrcsize = 10
        mysize = 10
        titlesize = 12
    else:
        mysrcsize = 8
        mysize = 8
        titlesize = 10
        
    if (os.path.exists(caltable)):
        try:
            print "Opening cal table..."
            mytb = createCasaTool(tbtool)
            mytb.open(caltable)
        except:
            print "Could not open caltable = ", caltable
            return
    else:
        print "Caltable does not exist = ", caltable
        return
    times = mytb.getcol("TIME")
    antennas = mytb.getcol("ANTENNA1")
    uniqueAntennaIds = np.unique(antennas)
    fields = mytb.getcol("FIELD_ID")
    uniqueFieldsInTable = np.unique(fields)
    names = mytb.colnames()
    if ('SNR' not in names):
        print "This does not appear to be a cal table. Is it the .ms?"
        return
    if ('SPECTRAL_WINDOW_ID' in names):
        msName = mytb.getkeyword('MSName')      
        cal_desc_id = mytb.getcol("SPECTRAL_WINDOW_ID")
        spectralWindowTable = mytb.getkeyword('SPECTRAL_WINDOW').split()[1]
        ParType = mytb.getkeyword('ParType')    # string = 'Complex'
        if (ParType != 'Complex'):
            print "This does not appear to be a gain calibration table because the data type is %s." % (ParType)
            return
        gain = mytb.getcol('CPARAM')[0][0]  # Here we must be assuming single-pol corrections
        mytb.close()
    else:  # old-style cal table
        cal_desc_id = mytb.getcol("CAL_DESC_ID")
        gain = mytb.getcol("GAIN")[0][0]  # Here we must be assuming single-pol corrections
        mytb.open(caltable+'/CAL_DESC')
        msName = mytb.getcell('MS_NAME',0)
        mytb.close()
    if (ms != ''):
        msName = ms
    mymsmd = None
    vm = None
    if (os.path.exists(msName)):
        if (casadef.casa_version >= casaVersionWithMSMD):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(msName)
        else:
            print "Running ValueMapping on %s... (this may take a minute)" % (msName)
            vm = ValueMapping(msName)
        msFound = True
    else:
        if (caltable.find('/')>=0):
            tokens = caltable.split('/')
            fname = ''
            for i in range(len(tokens)-1):
                fname += tokens[i] + '/'
            print "failed to open %s, will try %s" % (msName,fname+msName)
            if (os.path.exists(fname+msName)):
                if (casadef.casa_version >= casaVersionWithMSMD):
                    mymsmd = createCasaTool(msmdtool)
                    mymsmd.open(fname+msName)
                else:
                    print "Running ValueMapping on %s... (this may take a minute)" % (msName)
                    vm = ValueMapping(fname+msName)
                msFound = True
                msName = fname+msName
            else:
                msFound = False
        else:
            msFound = False

    # Continue to parse the command line
    if (type(figfile) == str):
        if (figfile.find('/')>=0):
            directories = figfile.split('/')
            directory = ''
            for d in range(len(directories)-1):
                directory += directories[d] + '/'
            if (os.path.exists(directory)==False):
                print "Making directory = ", directory
                os.system("mkdir -p %s" % directory)

    if (msFound):
        if (mymsmd is None):
            uniqueAntennaIds = range(len(vm.uniqueAntennas))
        else:
            uniqueAntennaIds = mymsmd.antennaids()
    
    antlist = parseAntennaArgument(antenna, uniqueAntennaIds, msName)
    if (len(antlist) > 0):
        antennasToPlot = np.intersect1d(uniqueAntennaIds,antlist)
    else:
        antennasToPlot = uniqueAntennaIds
#    print "antlist=%s\n antennasToPlot=%s\n uniqueAntennaIds=%s" % (str(antlist), str(antennasToPlot), str(uniqueAntennaIds))
    legend = ''
    for a in antennasToPlot:
        if (a != antennasToPlot[0]):
            legend += ', '
        if (msFound):
            if (mymsmd is None):
                legend += vm.getAntennaNamesForAntennaId(a)
            else:
                legend += mymsmd.antennanames(a)[0]
    if (msFound):
        print "Baselines including these antennas will be plotted = ", legend

    uniqueFieldsInVis = getFields(msName)
    if (mymsmd is None):
        allspws = vm.spwInfo.keys()
    else:
        allspws = range(mymsmd.nspw())
    spwlist = spw
    if (spwlist == []):
        spwlist = allspws
    elif (type(spw) == int):
        spwlist = [spw]
    elif (type(spw) == str):
        if (str.isdigit(spw)):
            spwlist = [int(spw)]
        elif (spw.find(',')>=0):
            spwstrings = spw.split(',')
            spwlist = []
            for i in spwstrings:
                spwlist.append(int(i))
        else:
            spwlist = allspws
#            print "spw is a blank string"
    else:
        print "Invalid spw"
        return
    print "spws in the dataset = ", allspws # vm.spwInfo.keys() # range(len(vm.spwInfo))
    print "spws to plot = ", spwlist
    
    for spw in spwlist:
        if (spw not in allspws or spw < 0):
            print "spw %d is not in the dataset" % (spw)
            return
    if (len(spwlist) > 1):
        print "*** Note: WVR solutions for different spws differ only by the frequency ratio."
        print "*** So, examining only one of them is usually sufficient (and faster)."

    # Parse the field string to emulate plotms
    removeField = []
    if (type(field) == str):
     myValidCharacterListWithBang = ['~', ',', ' ', '*', '!',] + [str(m) for m in range(10)]
     if (len(field) == sum([m in myValidCharacterListWithBang for m in field])):
         # a list of field numbers was given
         tokens = field.split(',')
         fieldlist = []
         for token in tokens:
             if (token.find('*')>=0):
                 fieldlist = uniqueFieldsInTable
                 break
             elif (token.find('!')==0):
                 fieldlist = uniqueFieldsInTable
                 removeField.append(int(token[1:]))
             elif (len(token) > 0):
                 if (token.find('~')>0):
                     (start,finish) = token.split('~')
                     fieldlist +=  range(int(start),int(finish)+1)
                 else:
                     fieldlist.append(int(token))
         fieldlist = np.array(fieldlist)
         for rm in removeField:
             fieldlist = fieldlist[np.where(fieldlist != rm)[0]]
         fieldlist = list(fieldlist)
         if (len(fieldlist) < 1 and len(removeField)>0):
             print "Too many negated fields -- there are no fields left to plot."
             return(vm)
     else:
         # The field name (or list of names, or wildcard) was specified
         tokens = field.split(',')
         if (msFound):
             fieldlist = []
             removeField = []
             for token in tokens:
                 myloc = token.find('*')
                 if (myloc > 0):
                     for u in uniqueFieldsInTable:
                         if (mymsmd is None):
                             uFieldName = vm.getFieldNamesForFieldId(u)
                         else:
                             uFieldName = mymsmd.namesforfields(u)[0]
                         if (token[0:myloc]==uFieldName[0:myloc]):
                             if (DEBUG):
                                 print "Found wildcard match = %s" % uFieldName
                             fieldlist.append(u)
                         else:
                             if (DEBUG):
                                 print "No wildcard match with = %s" % uFieldName
                 elif (myloc==0):
                     for u in uniqueFieldsInTable:
                         fieldlist.append(u)
                 elif (token in uniqueFieldsInVis):
                     fieldlist = list(fieldlist)  # needed in case preceding field had ! modifier
                     if (mymsmd is None):
                         fieldlist.append(vm.getFieldIdsForFieldName(token))
                     else:
                         fieldlist.append(mymsmd.fieldsforname(u)[0])
                 elif (token[0] == '!'):
                     if (token[1:] in uniqueFieldsInVis):
                         fieldlist = uniqueFieldsInTable
                         if (mymsmd is None):
                             removeField.append(vm.getFieldIdsForFieldName(token[1:]))
                         else:
                             removeField.append(mymsmd.fieldsforname(token[1:])[0])

                     else:
                         print "Field %s is not in the ms. It contains: " % (token), uniqueFieldsInVis
                         return(vm)
                 else:
                     print "Field %s is not in the ms. It contains: " % (token), uniqueFieldsInVis
                     return(vm)
             fieldlist = np.array(fieldlist)
             for rm in removeField:
                 fieldlist = fieldlist[np.where(fieldlist != rm)[0]]
             fieldlist = list(fieldlist)
             if (len(fieldlist) < 1 and len(removeField)>0):
                 print "Too many negated fields -- there are no fields left to plot."
                 return(vm)
         else:
             print "Fields cannot be specified my name if the ms is not found."
             return(vm)
    elif (type(field) == list):
      # it's a list of integers
      fieldlist = field
    else:
      # It's a single, integer entry
      fieldlist = [field]

    if (len(fieldlist) > 0):
      fieldsToPlot = np.intersect1d(uniqueFieldsInTable,np.array(fieldlist))
      if (len(fieldsToPlot) < 1):
          print "Source not found in ms"
          return(vm)
    else:
      fieldsToPlot = uniqueFieldsInTable  # use all fields if none are specified

    print "fields in the dataset = ", uniqueFieldsInVis
    print "Fields to plot = ", fieldsToPlot
    for x in fieldsToPlot:
        if (x < 0 or x >= len(uniqueFieldsInVis)):
            print "Field %d is not in the dataset" % (x)
            return

    # Fill the array of baselineLengths
    baselines = []
    if (msFound):
        baselineLength = np.zeros([len(uniqueAntennaIds), len(uniqueAntennaIds)])
        for index, i in enumerate(antennasToPlot): # range(len(uniqueAntennaIds)):
            for j in antennasToPlot[index:]:
                if (i != j): # and (i in antennasToPlot) and (j in antennasToPlot)):
                    baselineLength[i][j] = getBaselineLength(msName,i,j,verbose=False)[0]
                    if (i in antennasToPlot or j in antennasToPlot):
                        baselines.append([i,j,baselineLength[i][j]])

    sortedBaselines = baselines
    # sort the baselineLengths of the antennas to plot
    if (sort.find('length')>=0):
        for i in range(1,len(sortedBaselines)):
            for j in range(1,len(sortedBaselines)):
                if (sortedBaselines[j][2] < sortedBaselines[j-1][2]):
                    swap = sortedBaselines[j-1]
                    sortedBaselines[j-1] = sortedBaselines[j]
                    sortedBaselines[j] = swap
    pb.ion()  # Added on April 26, 2012 to address Crystal's problem
    pb.clf()
    for s in range(len(spwlist)):
        spw = spwlist[s]
        matchField = np.where(cal_desc_id == spw)[0]
        index = 0
        for myi in range(len(baselines)):
            if (sort.find('length')<0):
                i = baselines[myi][0]
                j = baselines[myi][1]
            else:
                i = sortedBaselines[myi][0]
                j = sortedBaselines[myi][1]
            matches = np.intersect1d(matchField,np.where(antennas==i)[0])
            antenna1 = antennas[matches]
            time1 = times[matches]
            gain1 = gain[matches]
            fields1 = fields[matches]
            matches2 = np.intersect1d(matchField,np.where(antennas==j)[0])
            gain2 = gain[matches2]
# This was only needed to check that times agreed, and they do.
#            antenna2 = antennas[matches2]
#            time2 = times[matches2]
#            fields2 = fields[matches2]
#            (agreement, failures) = checkTimeAgreement(i,j,time1,time2,fid=0)
#            if (agreement == False):
#                print "Time mismatch at baseline %d-%d, " % (antenna1[0],antenna2[0])
#                continue
            startTime = time1[0]
            if (xaxis.find('sec')>=0):
                timeplot = time1 - startTime
            else:
#                print "converting starting MJD seconds (%f) to UT hours" % (startTime)
                timeplot = 24*(time1/86400. - floor(time1[0]/86400.))
            phasediff = np.arctan2(np.imag(gain1), np.real(gain1)) - np.arctan2(np.imag(gain2),np.real(gain2))
            # Now we place all phase differences into -pi..pi so that the
            # phase unwrap algorithms can work properly.
            wrapPhase(phasediff)

            # Now we attempt a phase unwrap, if requested
            if (unwrapMethod == 'fomalont'):
                phasediff = phaseUnwrap(phasediff)
            elif (unwrapMethod == 'differences'):
                phasediff = phaseUnwrapDifferences(phasediff)
            elif (unwrapMethod == 'extrapolate'):
                phasediff = phaseUnwrapExtrapolate(phasediff)

            if (removeMedian):
                posvalues = phasediff[np.where(phasediff>0)[0]]
                if (len(posvalues) > 0):
                    if (np.median(posvalues) > math.pi/2.):
                        phasediff -= np.median(posvalues)
                    else:
                        phasediff -= np.median(phasediff)
                else:
                    phasediff -= np.median(phasediff)
            phasediff *= 180/np.pi
            xframe += 1
            if (xframe > xframeStop):
                if (len(fieldsToPlot) <= maxFieldsInLegend and len(fieldsToPlot) < len(overlayColors)):
                    DrawSourceLegend(yrange, fieldsToPlot, msFound, vm, subplotRows, mysrcsize, mymsmd)
                if (interactive):
                    pb.draw()
                    myinput = raw_input("Press return for next page (q to quit): ")
                else:
                    if (figfile!=''):
                        print "Plotting page %03d" % (plotctr)
                    myinput = ''
                if (figfile!=''):
                    if (figfile == True):
                        png = caltable+'.plotWVRSolutions.%03d.png'%plotctr
                    else:
                        png = figfile.split('.png')[0]+'.%03d.png'%plotctr
                    pb.savefig(png, density=108)
                    pngs.append(png)
                    plotctr += 1
                if (myinput.find('q')>=0):
                    return
                pb.clf()
                xframe = xframeStart+1
            adesc = pb.subplot(xframe)
            pb.hold(True)
            resizeFonts(adesc,mysize)
            if ((xrange[0] != 0 or xrange[1] != 0) and yrange[0] ==0 and yrange[1]==0):
                # recalculate the y limits for the displayed range
                tmatches1 = np.where(timeplot > xrange[0])[0]
                tmatches2 = np.where(timeplot <= xrange[1])[0]
                tmatches = np.intersect1d(tmatches1,tmatches2)
                phasediff -= np.median(phasediff[tmatches])
                ylim = [np.min(phasediff[tmatches]), np.max(phasediff[tmatches])]
                myyrange = ylim[1]-ylim[0]
                ylim = [ylim[0]-0.1*myyrange,ylim[1]+0.1*myyrange]
            else:
                ylim = pb.ylim()
            list_of_date_times = mjdSecondsListToDateTime(time1)
            timeplotMatches = pb.date2num(list_of_date_times)
            for f in range(len(fieldsToPlot)):
                field = fieldsToPlot[f]
                matches = np.where(fields1 == field)[0]
                if (xaxis.find('ut') >= 0):
                    pdesc = adesc.plot_date(timeplotMatches[matches],phasediff[matches],'.')
                    adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,30)))
                    adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
                    adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
                    adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
                    RescaleXAxisTimeTicks(pb.xlim(), adesc)
                else:
                    pdesc = pb.plot(timeplot[matches],phasediff[matches],'.')
                if (len(fieldsToPlot) < len(overlayColors)):
                    pb.setp(pdesc, color=overlayColors[field])
                    pb.setp(pdesc, markeredgewidth=0)  # prevent black border on each point
                else:
                    pb.setp(pdesc, color='b')
                    pb.setp(pdesc, markeredgewidth=0)  # prevent black border on each point
            if (xframe in bottomRow):
                if (xaxis.find('sec')>=0):
                    pb.xlabel("Time since start (sec)", size=mysize)
                else:
                    pb.xlabel("Time (UT on %s)"%(plotbp3.utdatestring(startTime)), size=mysize)
            if (xframe in leftColumn):
                pb.ylabel("Phase difference (deg)", size=mysize)
            if (msFound):
                if (mymsmd is None):
                    ant1string = vm.getAntennaNamesForAntennaId(antenna1[0])
                    ant2string = vm.getAntennaNamesForAntennaId(antennas[matches2][0])
                else:
                    ant1string = mymsmd.antennanames(antenna1[0])[0]
                    ant2string = mymsmd.antennanames(antennas[matches2][0])[0]
                pb.title('%.0fm Baseline %d-%d=%s-%s, spw%d=%.1fGHz' % (baselineLength[antenna1[0]][antennas[matches2][0]],
                        antenna1[0], antennas[matches2][0],
                        ant1string,
                        ant2string,spw, np.mean(getFrequencies(msName,spw)*1e-9)),
                        size=mysize)
            else:
                pb.title('Baseline %d-%d, spw %d' % (antenna1[0], antennas[matches2][0], spw), size=mysize)

            pb.subplots_adjust(hspace=myhspace, wspace=mywspace)
            yFormatter = ScalarFormatter(useOffset=False)
            adesc.yaxis.set_major_formatter(yFormatter)
            adesc.xaxis.grid(True,which='major')
            adesc.yaxis.grid(True,which='major')
            if (xrange[0] != 0 or xrange[1] != 0):
                if (xaxis.find('sec')>=0):
                    pb.xlim(xrange)
                else:
                    avgdatetime = num2date(np.mean(timeplotMatches[matches]))
                    avgdate = datetime.datetime.date(avgdatetime)
                    d1 = pb.date2num(avgdate) + xrange[0]/24.
                    d2 = pb.date2num(avgdate) + xrange[1]/24.
                    pb.xlim([d1,d2])
                pb.ylim(ylim)
            else:
                if (xaxis.find('sec')>=0):
                    pb.xlim(0, np.max(times)-np.min(times))

            xlim = pb.xlim()
            if (xlim[1] - xlim[0] < 10/1440.):
                adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
                adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,30)))
            elif (xlim[1] - xlim[0] < 0.5/24.):
                adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
                adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
            elif (xlim[1] - xlim[0] < 1/24.):
                adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
                adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,2)))
                
            if (yrange[0] != 0 or yrange[1] != 0):
                pb.ylim(yrange)
                
            if (xframe in leftColumn and xframe in topRow):
                (xlim,ylim,myxrange,myyrange) = GetLimits()
                pb.text(0, 1.12, caltable+' computed for '+msName.split('/')[-1],
                        size=titlesize, transform=adesc.transAxes)
        if (len(fieldsToPlot) <= maxFieldsInLegend and len(fieldsToPlot) < len(overlayColors)):
            DrawSourceLegend(yrange, fieldsToPlot, msFound, vm, subplotRows, mysrcsize, mymsmd)
                        
    pb.draw()
    if (figfile != ''):
        if (figfile == True):
            try:
                png = caltable+'.plotWVRSolutions.%03d.png'%plotctr
                pb.savefig(png, density=108)
                pngs.append(png)
            except:
                print "WARNING:  Could not save plot file.  Do you have write permission here?"
        else:
            try:
                png = figfile.split('.png')[0]+'.%03d.png'%plotctr
                pb.savefig(png, density=108)
                pngs.append(png)
            except:
                print "WARNING:  Could not save plot file.  Do you have write permission here?"
        if (buildpdf):
            if (pdfname == ''):
                pdfname = figfile + '.pdf'
            else:
                if (pdfname.lower().find('.pdf') < 0):
                    pdfname += '.pdf'
            buildPdfFromPngs(pngs, pdfname)
# end of plotWVRSolutions2()

def DrawSourceLegend(yrange, fieldsToPlot, msFound, vm, subplotRows, mysrcsize, mymsmd=None):
    (xlim,ylim,myxrange,myyrange) = GetLimits()
    if (yrange[0] == 0 and yrange[1] == 0):
        # Make space for source labels at the bottom of the plot
        pb.ylim([ylim[0] - myyrange*0.25, ylim[1]])
        (xlim,ylim,myxrange,myyrange) = GetLimits()
    for f in range(len(fieldsToPlot)):
        field = fieldsToPlot[f]
        if (msFound):
            if (mymsmd is None):
                myfieldstring = '%d: %s' % (field, vm.getFieldNamesForFieldId(field))
            else:
                myfieldstring = '%d: %s' % (field, mymsmd.namesforfields(field)[0])
        else:
            myfieldstring = 'field %d' % (field)
        if (f < (1+len(fieldsToPlot))/2):
            myxpos = 0.05
            myypos = (f+0.3)*0.03*subplotRows  # 0.02, 0.078 0.137
        else:
            myxpos = 0.50
            myypos = (f-int((1+len(fieldsToPlot))/2)+0.3)*0.03*subplotRows
        pb.text(myxpos, myypos, myfieldstring, color=overlayColors[field],
                size=mysrcsize, transform=pb.gca().transAxes)

def GetLimits():
    """
    Gets the current plot limits and ranges and returns them.
    -- Todd Hunter
    """
    xlim = pb.xlim()
    ylim = pb.ylim()
    myxrange = xlim[1]-xlim[0]
    myyrange = ylim[1]-ylim[0]
    return(xlim,ylim,myxrange,myyrange)

def wrapPhase(phase):
    """
    This is meant to be run after taking the difference between two
    -pi..pi phase streams, so that the difference remains in -pi..pi,
    so that subsequent phase unwrap algorithms will work properly.
    -Todd Hunter
    """
    idx = np.where(phase > np.pi)
    phase[idx] -= 2*np.pi
    idx = np.where(phase < -np.pi)
    phase[idx] += 2*np.pi
    return(phase)

def phaseUnwrapDifferences(phase):
    """
    Algorithm from Richard Hills called from plotWVRSolutions. Accepts angle
    in radians, and returns angle in radians.
    Method: successive differences
    WARNING: still under development!
    - Todd Hunter
    """
    for i in range(1,len(phase)):
        testwrap = phase[i] - phase[i-1] 
        if (testwrap < -np.pi):
            phase[i] += np.pi*2
        elif (testwrap > np.pi):
            phase[i] -= np.pi*2
    return(phase)

def phaseUnwrapExtrapolate(phase, f=0.3, requireTwo=False):
    """
    Algorithm from Richard Hills called from plotWVRSolutions. Accepts angle
    in radians, and returns angle in radians.
    Method: extrapolate from past to future
    Inputs:
    requireTwo: if True, two successive points must agree to indicate a wrap
    WARNING: still under development!
    - Todd Hunter
    """
    for i in range(1,len(phase)-2):
        # e.g.  150, 170, -170 --> -170-(170+0.3*(170-150)) --> -170-(176)=-346
        #  so, one would add 360 to -170 = +190
        testwrap = phase[i+1] - (phase[i] + f*(phase[i]-phase[i-1]))
        testwrap2 = phase[i+2] - (phase[i] + f*(phase[i]-phase[i-1]))
        if (testwrap < -np.pi and (testwrap2 < -np.pi or requireTwo==False)):
            phase[i+1:] += np.pi*2
        elif (testwrap > np.pi and (testwrap2 > np.pi or requireTwo==False)):
            phase[i+1:] -= np.pi*2
    return(phase)

def phaseUnwrapInterpolate(phase, g=0.4):
    """
    Algorithm from Richard Hills called from plotWVRSolutions. Accepts angle
    in radians, and returns angle in radians.
    Method: extrapolate from past to future
    g: for smooth data g should be 0.5;  for noisy data, 0.3
    WARNING: still under development!
    - Todd Hunter
    """
    for i in range(1,len(phase)-2):
        testwrap = (phase[i+1] - g*(phase[i+2] - phase[i+1])) - (phase[i]+g*(phase[i]-phase[i-1]))
        if (testwrap < -np.pi):
            phase[i+1:] += np.pi*2
        elif (testwrap > np.pi):
            phase[i+1:] -= np.pi*2
    return(phase)

def phaseUnwrap(phase):
   """
   Algorithm from Ed Fomalont called from plotWVRSolutions.  Accepts angle in radians.
   Take phase difference, adds 4.5 turns, mods by 1 turn, subtract 0.5 turns. 
   - Todd Hunter
   """
   for i in range(1,len(phase)):
       phaseDiff = phase[i]-phase[i-1]
       pd = np.mod(phaseDiff + 4.5*(2*np.pi), 2*np.pi) - np.pi
       phase[i] = phase[i-1]+pd
   return(phase)
   
def checkTimeAgreement(a,b,t1,t2, fid):
    """
    Initially used by plotWVRSolutions to confirm that times match between antennas.
    But not currently used.  -- Todd Hunter
    """
    failures = []
    for i in range(len(t1)):
        if (fid != 0):
            fid.write('%2d %2d %.2f %.2f\n'%(a,b,t1[i],t2[i]))
        if (np.abs(t1[i] - t2[i]) > 1):
            failures.append(i)
    if (len(failures) > 0):
        return(False, failures)
    else:
        return(True, failures)

def scaleWeightSpectrum(vis, wtfac=1.0, antenna='', square=False, 
                        squareroot=False, spw='', obsid=-1):
    """
    scaleWeightSpectrum: scale data weight spectrum column by a user supplied 
          factor (or square or square root them).  See also scaleweights.
    Note: this function assumes equivalence between spw and data_descriptor_id.
         If this is not the case for your data, email the maintainer.         
    * wtfac =  multiplicative weight factor
    * antenna = restrict scaling to baselines including this single 
                        antenna ID (int or string)
    * square = Boolean, if True, then square the weights 
    * squareroot = Boolean, if True, then take the square root of the weights 
    * spw = integer or string or list of spws to process
    * obsid = integer or string or comma-delimited list of obsids to process
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)
    if type(wtfac) is not types.FloatType and type(wtfac) is not types.IntType:
        print 'ERROR: wtfac must be a float or integer'
        return(1)
    if (square == False and squareroot == False):
        print 'Will scale weights by a factor of '+str(wtfac)
    elif (square and squareroot):
        print "You cannot select both square and squareroot"
        return
    elif (square):
        print "Will square the existing weights"
    elif (squareroot):
        print "Will square root the existing weights"
    if (obsid != -1):
        obsidlist = [int(i) for i in str(obsid).split(',')]
    else:
        obsidlist = []
    # Find number of data description IDs
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()
    #
    ntotrow=0
    ntotpts=0
    spw = parseSpw(vis,spw)
    print "Will process spws = ", spw
    mytb.open(vis,nomodify=False)
    for idd in range(ndd):
      if (idd in spw):
        # Find number of correlations in this DD
        pid = ddpollist[idd]
        ncorr = ncorlist[pid]
        # Select this DD (after reset if needed)
        if (len(obsidlist) > 0):
            myt = mytb.query('DATA_DESC_ID==%d && OBSERVATION_ID in %s'%(idd,str(obsidlist)))
        else:
            myt = mytb.query('DATA_DESC_ID==%d'%(idd))
        nwchan=0
        # get the weights
        recw = myt.getcol("WEIGHT_SPECTRUM")
        antenna1 = myt.getcol('ANTENNA1')
        antenna2 = myt.getcol('ANTENNA2')
        if (len(recw.shape) < 3):
            myt.close()
            mytb.close()
            if (len(obsidlist) > 0):
                print "No matching data found for this combination of ObsID and spw."
            else:
                print "No matching data found for this spw."
            continue
        (npol,nchan,ni) = recw.shape
        doscale = False
        if (antenna == ''):
            doscale = True
        elif (str(antenna) == str(antenna1[j]) or str(antenna) == str(antenna2[j])):
            doscale = True
        if (doscale):
            if (square):
                recw = np.square(recw)
            elif (squareroot):
                recw = np.sqrt(recw)
            else:
                recw *= wtfac
            nwchan += nchan*ni
        myt.putcol("WEIGHT_SPECTRUM", recw)
        myt.close()
        ntotrow += ni
        ntotpts += nwchan
        print 'Scaled '+str(nwchan)+' spectral points in '+str(ni)+' rows in DD='+str(idd)
    #
    print 'Scaled Total '+str(ntotpts)+' spectral points in '+str(ntotrow)+' rows'
    mytb.close()
    return

def scaleModel(vis, field, antenna='', toCorrected=True, factor=None, spw='', datacolumn='model', 
               stat='median', verbose=False):
    """
    Scales a column of a dataset for a specified field, optionally to match the median of the 
    corrected column, using the task visstat.
    WARNING: does not (yet) perform the scaling!
    datacolumn: column to scale
    stat: which visstat statistic to use
    field: list of names or IDs
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if spw == '':
        spwlist = getScienceSpws(vis, mymsmd=mymsmd, returnString=False)
    else:
        spwlist = parseSpw(vis, spw, mymsmd)
    scaleFactor = {}
    ids, names = parseFieldArgument(vis, field, mymsmd=mymsmd)
    mymsmd.close()
    field = ','.join([str(i) for i in ids])
    print "Processing field: '%s'" % (field)
    for spw in spwlist:
        scaleFactor[spw] = factor
    if toCorrected:
        for spw in spwlist:
            if verbose:
                print "running visstat('%s', datacolumn='corrected', field='%s', antenna='%s', spw='%s')" % (vis, field, antenna, str(spw))
            value = visstat(vis, datacolumn='corrected', field=field, antenna=antenna, spw=str(spw))['CORRECTED'][stat]
            if verbose:
                print "running visstat('%s', datacolumn='model', field='%s', antenna='%s', spw='%s')" % (vis, field, antenna, str(spw))
            model = visstat(vis, datacolumn='model', field=field, antenna=antenna, spw=str(spw))['MODEL'][stat]
            print "spw %d %s corrected=%f  %s=%f" % (spw, stat, value, datacolumn, model)
            scaleFactor[spw] = model/value
    return
    for spw in spwlist:
        # Need to restrict to field!
        print "Applying scaleFactor = %f for spw %d" % (scaleFactor[spw], spw)
        scaleweights(vis, scaleFactor[spw], antenna=antenna, spw=spw, column='model')

def scaleWeightsPerAntenna(vis, weightDict, spw='', column='weight', verbose=True):
    """
    Calls scaleweights for each antenna in a dataset using the supplied dictionary
    of scaling factors.
    weightDict: e.g. {'ea01': 1.23, ...}
    """
    names = getAntennaNames(vis)
    antennas = range(len(names))
    myms = createCasaTool(mstool)    
    myms.open(vis,nomodify=False)
    mymsmd = createCasaTool(msmdtool)    
    mymsmd.open(vis)
    for antenna in antennas:
        if names[antenna] in weightDict:
            print "Scaling antenna %d: %s by %f" % (antenna, names[antenna], weightDict[names[antenna]])
            scaleweights(vis, weightDict[names[antenna]], antenna, spw=spw, column=column, verbose=verbose, 
                         myms=myms, mymsmd=mymsmd)
        else:
            print "Antenna %d: %s not in scaling dictionary" % (antenna, names[antenna])
    myms.close()
    mymsmd.close()

def scaleweights(vis, wtfac=1.0, antenna='', square=False, squareroot=False,
                 spw='', column='weight', verbose=True, myms=None, mymsmd=None):
    """
    scaleweights:  scale data weights by a user supplied factor (or square or 
                   square root them).  See also scaleWeightSpectrum.
    Originally created by S.T. Myers 2011-08-23  v1.0 from flagaverage.py 
                     (CAS-2422)
    Improved and maintained by Todd Hunter 2014
    Note: this function assumes equivalence between spw and data_descriptor_id.
         If this is not the case for your data, email the maintainer.         
    Inputs:
    * vis: measurement set
    * wtfac =  multiplicative weight factor
    * antenna = restrict scaling to baselines including this single 
                        antenna ID (int or string)
    * square = Boolean, if True, then square the weights 
    * squareroot = Boolean, if True, then take the square root of the weights 
    * spw = integer or string or list of spws to process
    For examples, see https://safe.nrao.edu/wiki/bin/view/ALMA/Scaleweights
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)
    if type(wtfac) is not types.FloatType and type(wtfac) is not types.IntType:
        print 'ERROR: wtfac must be a float or integer'
        return(1)
    if (square == False and squareroot == False):
        print 'Will scale weights by a factor of '+str(wtfac)
    elif (square and squareroot):
        print "You cannot select both square and squareroot"
        return
    elif (square):
        print "Will square the existing weights"
    elif (squareroot):
        print "Will square root the existing weights"
    needToClose = False
    if mymsmd is None:
        mymsmd = createCasaTool(msmdtool)    
        try:
            mymsmd.open(vis)
            needToCloseMSMD = True
        except:
            print "ERROR: failed to open ms tool on file "+vis
            mymsmd.close()
        return(4)
    spw = parseSpw(vis,spw,mymsmd)
    if needToClose:
        myms.close()
    needToClose = False
    if myms is None:
        myms = createCasaTool(mstool)    
        try:
            myms.open(vis,nomodify=False)
            needToClose = True
        except:
            print "ERROR: failed to open ms tool on file "+vis
            myms.close()
        return(3)
    # Find number of data description IDs
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    if verbose:
        print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()
    #
    ntotrow=0
    ntotpts=0
    if verbose:
        print "Will process spws = ", spw
    for idd in range(ndd):
        if (idd in spw):
            # Find number of correlations in this DD
            pid = ddpollist[idd]
            ncorr = ncorlist[pid]
            # Select this DD (after reset if needed)
            if idd>0: myms.selectinit(reset=True)
            myms.selectinit(idd)
            #myms.selecttaql('SUM(WEIGHT)<'+str(wtcut))
            nwchan=0
            #recf = myms.getdata(["flag"])
            #(nx,nc,ni) = recf['flag'].shape
            # get the weights
            recw = myms.getdata([column])
            antenna1 = myms.getdata(['ANTENNA1'])['antenna1']
            antenna2 = myms.getdata(['ANTENNA2'])['antenna2']
            (nx,ni) = recw[column].shape
            for j in range(ni):
                doscale = False
                if (antenna == ''):
                    doscale = True
                elif (str(antenna) == str(antenna1[j]) or str(antenna) == str(antenna2[j])):
                    doscale = True
                if (doscale):
                    for i in range(nx):
                        if (square):
                            recw[column][i,j] = np.square(recw[column][i,j])
                        elif (squareroot):
                            recw[column][i,j] = np.sqrt(recw[column][i,j])
                        else:
                            recw[column][i,j] *= wtfac
                        nwchan += 1
            myms.putdata(recw)
            ntotrow += ni
            ntotpts += nwchan
            print 'Scaled '+str(nwchan)+' spectral points in '+str(ni)+' rows in DD='+str(idd)
    #
    if verbose:
        print 'Scaled Total '+str(ntotpts)+' spectral points in '+str(ntotrow)+' rows'
    if needToClose:
        myms.close()
    if verbose:
        print "new median weight: %f" % (getMeanWeights(vis, antenna=antenna, reportMedian=True))
    return

def countVisibilities(vis):
    """
    Sums the number of visibilities in a measurement set, one spw at a time, and
    reports the total.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()
    #
    ntotrow=0
    ntotpts=0
    nvis = 0
    mytb.open(vis)
    for idd in range(ndd):
        print "Working on %d/%d" % (idd+1,ndd)
        myt = mytb.query('DATA_DESC_ID == %d' % idd)
        mycell = myt.getcell('DATA',0)
        myshape = np.shape(mycell)
        nvis += myt.nrows() * np.product(myshape)
        myt.close()
    mytb.close()
    return nvis

def scaleEffectiveBandwidth(vis, spw, factor=2.667):
    """
    Scales the effective bandwidth of a spectral window in the SPECTRAL_WINDOW
    table of a measurement set.  For test purposes only!  See also 
    scaleEffectiveResolution.
    spw: integer or string integer
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or at least its SPECTRAL_WINDOW table)."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW', nomodify=False)
    spw = int(spw)
    ebw = mytb.getcell('EFFECTIVE_BW', spw)
    mytb.putcell('EFFECTIVE_BW', spw, ebw*factor)
    print "Changed value from %f to %f" % (np.median(ebw), np.median(ebw)*factor)
    mytb.close()

def scaleEffectiveBandwidthASDM(asdm, spw, factor=2.667, 
                                keepOld=False, verbose=False):
    """
    Scales the effective bandwidth of a spectral window in the 
    SpectralWindow.xml file of an ASDM.  For test purposes only!
    spw: integer or string integer (as it would appear in measurement set)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    spwtable = asdm+'/SpectralWindow.xml'
    if (not os.path.exists(spwtable)):
        print "Could not find SpectralWindow.xml."
        return
    mydict = getSpwsFromASDM(asdm)
    if spw not in mydict.keys():
        print "spw %d is not in the ASDM" % (spw)
        return
    asdmspw = mydict[spw]['spectralWindowId']
    if verbose: print "Translated spw %d to asdm spw %d" % (spw, asdmspw)
    fin = open(spwtable,'r')
    lines = fin.readlines()
    fin.close()
    newspwtable = spwtable + '.new'
    fout = open(newspwtable,'w')
    lookingForEffectiveBW = False
    replaced = 0
    for line in lines:
        if lookingForEffectiveBW:
            loc = line.find('<effectiveBwArray>')
            loc2 = line.find('<effectiveBw>')
            if (loc >= 0):
                token = line[loc:].split('>')[1].split('<')[0].split()
                nchan = int(token[1])
                outline = line.split('<')[0] + '<effectiveBwArray>%s %s' % (token[0],token[1])
                for chan in range(nchan):
                    outline += ' %E' % (factor*float(token[chan+2]))
                outline += '</effectiveBwArray>\n'
                fout.write(outline)
                replaced += 1
                lookingForEffectiveBW = False
            elif (loc2 >= 0):
                token = line[loc2:].split('>')[1].split('<')[0]
                outline = line.split('<')[0] + '<effectiveBw>'
                outline += '%E</effectiveBw>\n' % (float(token)*factor)
                fout.write(outline)
                replaced += 1
                lookingForEffectiveBW = False
            else:
                fout.write(line)
        else:
            if (line.find('>SpectralWindow_%d<' % asdmspw) > 0):
                lookingForEffectiveBW = True
            fout.write(line)
    fout.close()
    if verbose: print "Replaced %d lines." % (replaced)
    if keepOld:
        os.rename(spwtable, spwtable+'.old')
    else:
        os.remove(spwtable)
    os.rename(newspwtable, spwtable)

def scaleChanwidth(vis,spw,factor=2.0):
    """
    Scales the channel width of a spectral window in the SPECTRAL_WINDOW
    table of a measurement set.  For test purposes only!
    spw: integer or string integer
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or at least its SPECTRAL_WINDOW table)."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW', nomodify=False)
    spw = int(spw)
    ebw = mytb.getcell('CHAN_WIDTH',spw)
    mytb.putcell('CHAN_WIDTH', spw, ebw*factor)
    print "Changed value from %f to %f" % (np.median(ebw), np.median(ebw)*factor)
    mytb.close()

def scaleEffectiveResolution(vis,spw,factor=2.0):
    """
    Scales the resolution of a spectral window in the SPECTRAL_WINDOW
    table of a measurement set.  For test purposes only!  See also 
    scaleEffectiveBandwidth.
    spw: integer or string integer
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or at least its SPECTRAL_WINDOW table)."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW', nomodify=False)
    spw = int(spw)
    ebw = mytb.getcell('RESOLUTION',spw)
    mytb.putcell('RESOLUTION', spw, ebw*factor)
    print "Changed value from %f to %f" % (np.median(ebw), np.median(ebw)*factor)
    mytb.close()

def scaleEffectiveResolutionASDM(asdm,spw,factor=2.0,
                                 keepOld=False, verbose=False):
    """
    Scales the effective resolution of a spectral window in the 
    SpectralWindow.xml file of an ASDM.  For test purposes only!
    See also scaleEffectiveBandwidthASDM.
    spw: integer or string integer (as it would appear in measurement set)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    spwtable = asdm+'/SpectralWindow.xml'
    if (not os.path.exists(spwtable)):
        print "Could not find SpectralWindow.xml."
        return
    mydict = getSpwsFromASDM(asdm)
    if spw not in mydict.keys():
        print "spw %d is not in the ASDM" % (spw)
        return
    asdmspw = mydict[spw]['spectralWindowId']
    if verbose: print "Translated spw %d to asdm spw %d" % (spw, asdmspw)
    fin = open(spwtable,'r')
    lines = fin.readlines()
    fin.close()
    newspwtable = spwtable + '.new'
    fout = open(newspwtable,'w')
    lookingForResolution = False
    replaced = 0
    for line in lines:
        if lookingForResolution:
            loc = line.find('<resolutionArray>')
            loc2 = line.find('<resolution>')
            if (loc >= 0):
                token = line[loc:].split('>')[1].split('<')[0].split()
                nchan = int(token[1])
                outline = line.split('<')[0] + '<resolutionArray>%s %s' % (token[0],token[1])
                for chan in range(nchan):
                    outline += ' %E' % (factor*float(token[chan+2]))
                outline += '</resolutionArray>\n'
                fout.write(outline)
                replaced += 1
                lookingForResolution = False
            elif (loc2 >= 0):
                token = line[loc2:].split('>')[1].split('<')[0]
                outline = line.split('<')[0] + '<resolution>'
                outline += '%E</resolution>\n' % (float(token)*factor)
                fout.write(outline)
                replaced += 1
                lookingForResolution = False
            else:
                fout.write(line)
        else:
            if (line.find('>SpectralWindow_%d<' % asdmspw) > 0):
                lookingForResolution = True
            fout.write(line)
    fout.close()
    if verbose: print "Replaced %d lines." % (replaced)
    if keepOld:
        os.rename(spwtable, spwtable+'.old')
    else:
        os.remove(spwtable)
    os.rename(newspwtable, spwtable)

def scaleTotalBandwidth(vis,spw,factor=2.0):
    """
    Scales the TOTAL_BANDWIDTH of a spectral window in the SPECTRAL_WINDOW
    table of a measurement set.  For test purposes only!
    spw: integer or string integer
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or at least its SPECTRAL_WINDOW table)."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW', nomodify=False)
    spw = int(spw)
    ebw = mytb.getcell('TOTAL_BANDWIDTH',spw)
    mytb.putcell('TOTAL_BANDWIDTH', spw, ebw*factor)
    print "Changed value from %f to %f" % (ebw, ebw*factor)
    mytb.close()

def updateSBSummaryMOUS(vislist, projectID, MOUS, sgfile='/lustre/naasc/sciops/comm/cbrogan/Pipeline_Imaging_Tests/sgfile.txt',
                        verbose=False):
    """
    Reads the science goal parameters from a text file and updates the ASDM_SBSUMMARY 
    table of each specified measurement set for the specified MOUS/project.
    vislist: a comma-delimited string, or a python list of strings
    projectID: e.g. '2015.1.01068.S'
    MOUS: uid name, either slash-delimited or underscore-delimited
    sgfile: name of text file to consult
    -Todd Hunter
    """
    if (not os.path.exists(sgfile)):
        print "Could not find file: ", sgfile
        return
    f = open(sgfile,'r')
    lines = f.readlines()
    f.close()
    pid = None
    everFoundProject = False
    if MOUS.find('/') > 0:
        MOUS2 = MOUS.replace('/','_').replace(':','_')
    else:
        MOUS2 = MOUS.replace('___','://').replace('_','/')
    for line in lines:
        if (line[0] == '#'):
            continue
        foundProject = line.find(projectID) >= 0
        if not everFoundProject: 
            everFoundProject = foundProject
        foundMous = line.find(MOUS) >= 0 or line.find(MOUS2) >= 0
        if (foundProject and foundMous):
            token = line.split()
            if (len(token) < 3):
                print "Invalidly formatted line: less than 3 tokens."
                continue
            if len(token) == 3:
                pid, mous, values = token
            else:
                pid, mous = token[:2]
                values = ','.join(token[2:])
            # values will now be a comma-delimited string
            break
    if (pid is None):
        if not everFoundProject:
            print "Did not find any entries for project %s in %s" % (projectID,sgfile)
        else:
            print "Saw project %s, but did not find MOUS %s in %s" % (projectID,MOUS,sgfile)
        return
    if (type(vislist) == str):
        vislist = vislist.split(',')
    scienceGoals = values.split(',')
    representativeFrequency = None 
    minAcceptableAngResolution = None 
    maxAcceptableAngResolution = None
    dynamicRange = None 
    representativeBandwidth = None
    representativeSource = None
    for sg in scienceGoals:
        value = sg.split('=')[1].replace("'","").replace('"','')
        if len(value) > 0:
            if sg.find('ource') >= 0:
                representativeSource = value
                if verbose: print "Setting source"
            elif sg.find('andwidth') >= 0:
                representativeBandwidth = value
                if verbose: print "Setting bandwidth"
            elif sg.find('requency') >= 0:
                representativeFrequency = value
                if verbose: print "Setting frequency"
            elif sg.find('minAngRes') >= 0:
                minAcceptableAngResolution = value
                if verbose: print "Setting minAng"
            elif sg.find('maxAngRes') >= 0:
                maxAcceptableAngResolution = value
                if verbose: print "Setting maxAng"
            elif sg.find('ynamicRange') >= 0:
                dynamicRange = value
                if verbose: print "Setting dynamicRange"
    for vis in vislist:
        if (not os.path.exists(vis)):
            print "Could not find ms ", vis
            continue
        print "Fixing %s" % (vis)
        updateSBSummary(vis, representativeFrequency, minAcceptableAngResolution, maxAcceptableAngResolution,
                        dynamicRange, representativeBandwidth, representativeSource)


def fixBandwidthsInMOUS(asdms, projectID, MOUS, ebwfile):
    """
    Corrects the effective bandwidth and resolution of the science
    spws in an ASDM.  
    Inputs:
    asdms: a list of ASDMs, either comma-delimited string, or a python list 
           of strings
    projectID: a string containing an ALMA project ID
    MOUS: the name of the MOUS to be fixed
         calibPipeIF-NA.py will pass in names with :// format
         but ebwfile can use either format at will
    ebwfile: the filename in which to find the specified projectID, MOUS,
             and spw info.  Required format is of each line:
         "projectID   MOUS   17,19,21,23    2,2,1,4"
     or  "MOUS   projectID   17,19,21,23    2,2,1,4"
    """
    if (not os.path.exists(ebwfile)):
        print "Could not find file: ", ebwfile
        return
    f = open(ebwfile,'r')
    lines = f.readlines()
    f.close()
    pid = None
    everFoundProject = False
    MOUS2 = MOUS.replace('/','_').replace(':','_')
    for line in lines:
        if (line[0] == '#'):
            continue
        foundProject = line.find(projectID) >= 0
        if not everFoundProject: 
            everFoundProject = foundProject
        foundMous = line.find(MOUS) >= 0 or line.find(MOUS2) >= 0
        if (foundProject and foundMous):
            token = line.split()
            if (len(token) < 3):
                print "Invalidly formatted line: less than 3 tokens."
                continue
            if len(token) == 3:
                pid, mous, spws = token
                if (spws.find('auto') < 0):
                    print "Invalidly formatted line: only 3 tokens and 3rd is not 'auto'."
                    return
            else:
                pid, mous, spws, Ns = token
            break
    if (pid is None):
        if not everFoundProject:
            print "Did not find any entries for project %s in %s" % (projectID,ebwfile)
        else:
            print "Saw project %s, but did not find MOUS %s in %s" % (projectID,MOUS,ebwfile)
        return
    if (type(asdms) == str):
        asdms = asdms.split(',')
    if (spws.find('auto') < 0):
        spwlist = [int(i) for i in spws.split(',')]
        Nlist = [int(i) for i in Ns.split(',')]
        spws = {}
        for i,spw in enumerate(spwlist):
            spws[spw] = Nlist[i]
    else:
        spws = {}
    for asdm in asdms:
        if (not os.path.exists(asdm)):
            print "Could not find ASDM = ", a
            continue
        print "Fixing spws=%s in %s" % (spws,asdm)
        fixBandwidthsInASDM(asdm, spws)

def fixBandwidthsInASDM(asdm, spws={}, window='hanning'):
    """
    For pre-Cycle 3 ASDMs, fixes the effective bandwidth and
    effective resolution of a science spw (if they are still equal
    to each other).   If no dictionary is provided, then it tries 
    to surmise the level of online channel averaging automatically.
    spws: a dictionary of format {spwID: N} where N = 1,2,4,8,16
    window: string passed to au.windowFunction to determine the factor to apply
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm+'/ExecBlock.xml')):
        print "Could not find ASDM's ExecBlock.xml"
        return
    cycle = surmiseCycleFromASDM(asdm)
    if (cycle > 2):
        print "No fixes are necessary because this is a Cycle %d dataset." % (cycle)
        return
    if (len(spws.keys()) > 0):
        keepOld = True
        for spw in spws.keys():
            N = spws[spw]
            # First I should check to see if EffBw==ChanWidth
            if (effectiveBandwidthASDM(asdm,spw) != 
                effectiveResolutionASDM(asdm,spw)):
                print "The effective BW does not equal the resolution in spw %d in this ASDM.  Not attempting a correction since it may have already been done." % (spw)
                continue
            else:
                factor = windowFunction(window,N,'EffectiveBW')/N
                print "Scaling spw %d bandwidth by %f" % (spw, factor)
                scaleEffectiveBandwidthASDM(asdm, spw, factor, keepOld)
                keepOld = False
                factor = windowFunction(window,N,'FWHM')/N
                print "Scaling spw %d resolution by %f" % (spw, factor)
                scaleEffectiveResolutionASDM(asdm, spw, factor, keepOld)
    else:
        mydict = getSpwsFromASDM(asdm, minnumchan=64, dropExtraWVRSpws=True)
        spws = mydict.keys()
        nspw = len(spws)
        print "Will need to fix %d spws: %s" % (nspw,mydict.keys())
        print "But automatic method not yet implemented!!!!!!!!!!!!!!!!!"

def getMeanWeightsPerAntenna(vis, spw='', reportMedian=False):
    """
    Calls getMeanWeights once per each antenna in a dataset
    * spw = integer or string or list of spws to process
    * reportMedian: if True, then compute median instead of mean
    Returns: dictionary keyed by antenna name
    -Todd Hunter
    """
    weights = {}
    names = getAntennaNames(vis)
    antennas = range(len(names))
    for antenna in antennas:
        weights[names[antenna]] = getMeanWeights(vis, spw, antenna, reportMedian=reportMedian)
        print names[antenna], weights[names[antenna]]
    return weights
    
def getMeanWeights(vis, spw='', antenna='', verbose=False, reportMedian=False):
    """
    Gets the mean value of the weight of a measurement set
    * vis = name of measurement set
    * spw = integer or string or list of spws to process
    * antenna: single antenna name or ID, default='' --> mean over all
    * reportMedian: if True, then compute median instead of mean
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)
    # Find number of data description IDs
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    spw = parseSpw(vis, spw, mymsmd)
    if antenna != '':
        antenna = parseAntenna(vis, antenna, mymsmd)[0]
        if verbose:
            print "antenna = ", antenna
    mymsmd.close()
    myms = createCasaTool(mstool)
    try:
        myms.open(vis)
    except:
        print "ERROR: failed to open ms tool on file "+vis
        return(3)
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    if verbose:
        print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()
    print "Will process spws = ", spw
    means = []
    for idd in range(ndd):
        if (idd in spw):
          # Find number of correlations in this DD
          pid = ddpollist[idd]
          ncorr = ncorlist[pid]
          # Select this DD (after reset if needed)
          if idd>0: myms.selectinit(reset=True)
          myms.selectinit(idd)
          if antenna != '':
              myms.selecttaql('ANTENNA1==%d || ANTENNA2==%d' % (antenna,antenna))
          nwchan=0
          recw = myms.getdata(["weight"])
          (nx,ni) = recw['weight'].shape
          for j in range(ni):
              if reportMedian:
                  means.append(np.median(recw['weight'][:,j]))
              else:
                  means.append(np.mean(recw['weight'][:,j]))
    #
    myms.close()
    if reportMedian:
        return(np.median(means))
    else:
        return(np.mean(means))

def getObservationIDs(vis):
    """
    Gets the list of unique obs IDs from a measurement set by examining the OBSERVATION_ID 
    column of the main table.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    obsid = list(np.unique(mytb.getcol('OBSERVATION_ID')))
    mytb.close()
    return(obsid)
    
def getArrayIDs(vis):
    """
    Gets the list of unique array IDs from a measurement set by examining the ARRAY_ID 
    column of the main table.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    arrayid = list(np.unique(mytb.getcol('ARRAY_ID')))
    mytb.close()
    return(arrayid)
    
def resetweights(msfile,wtval=1.0,spw=''):
    """
    resetweights:  set data weights to a user supplied value
    Usage:
    au.resetweights(msfile,wtval)
    * msfile = name of measurement set
    * wtval =  new weight value
    * spw = integer or string or list of spws to process
    -- Todd Hunter
    """
    if (os.path.exists(msfile) == False):
        print "Could not find ms file = ", msfile
        return(2)

    if type(wtval) is not types.FloatType and type(wtval) is not types.IntType:
        print 'ERROR: wtval must be a float or integer'
        return(1)

    print 'Will set weights to '+str(wtval)
    myms = mstool()
    try:
        myms.open(msfile,nomodify=False)
    except:
        print "ERROR: failed to open ms tool on file "+msfile
        return(3)
    # Find number of data description IDs
    tb.open(msfile+"/DATA_DESCRIPTION")
    ddspwlist=tb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist=tb.getcol("POLARIZATION_ID")
    tb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id
    tb.open(msfile+"/POLARIZATION")
    ncorlist=tb.getcol("NUM_CORR")
    tb.close()
    #
    ntotrow=0
    ntotpts=0
    spw = parseSpw(msfile,spw)
    print "Will process spws = ", spw
    for idd in range(ndd):
        if (idd in spw):
            # Find number of correlations in this DD
            pid = ddpollist[idd]
            ncorr = ncorlist[pid]
            # Select this DD (after reset if needed)
            if idd>0: myms.selectinit(reset=True)
            myms.selectinit(idd)
            #myms.selecttaql('SUM(WEIGHT)<'+str(wtcut))
            nwchan=0
            #recf = myms.getdata(["flag"])
            #(nx,nc,ni) = recf['flag'].shape
            # get the weights
            recw = myms.getdata(["weight"])
            (nx,ni) = recw['weight'].shape
            for j in range(ni):
                for i in range(nx):
                    recw['weight'][i,j] = wtval*recw['weight'][i,j]/recw['weight'][i,j]
                    nwchan+=1
            myms.putdata(recw)
            ntotrow+=ni
            ntotpts+=nwchan
            print 'Set '+str(nwchan)+' spectral points in '+str(ni)+' rows in DD='+str(idd)
    #
    print 'Set Total '+str(ntotpts)+' spectral points in '+str(ntotrow)+' rows'
    myms.close()
    return

def resetVisibilities(vis,newval=1.0,spw=''):
    """
    Set all visibilities to a single user-supplied value.
    Inputs:
    * vis = name of measurement set
    * newval =  new complex value
    * spw = integer or string or list of spws to process
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)

    if type(newval) is not types.FloatType and type(newval) is not types.IntType:
        print 'ERROR: newval must be a float or integer'
        return(1)

    print 'Will set data to '+str(newval)
    myms = mstool()
    try:
        myms.open(vis,nomodify=False)
    except:
        print "ERROR: failed to open ms tool on file "+vis
        return(3)
    # Find number of data description IDs
    tb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist=tb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist=tb.getcol("POLARIZATION_ID")
    tb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id
    tb.open(vis+"/POLARIZATION")
    ncorlist=tb.getcol("NUM_CORR")
    tb.close()
    #
    ntotrow=0
    ntotpts=0
    spw = parseSpw(vis,spw)
    print "Will process spws = ", spw
    for idd in range(ndd):
        if (idd in spw):
          print "Working on spw "+str(idd)
          # Find number of correlations in this DD
          pid = ddpollist[idd]
          ncorr = ncorlist[pid]
          # Select this DD (after reset if needed)
          if idd>0: myms.selectinit(reset=True)
          myms.selectinit(idd)
          nwpts = 0
          recw = myms.getdata(["data"])
          result = recw['data'].shape
          print "shape = ", result
          (nx,ni,nr) = result
          for p in range(nr):  # rows
              for j in range(ni):  # channels
                  for i in range(nx):  # pols
                      recw['data'][i,j,p] = np.complex(newval)
                      nwpts += 1
        myms.putdata(recw)
        ntotrow += ni
        ntotpts += nwpts
        print 'Set '+str(nwpts)+' spectral points in '+str(nx)+' pols in '+str(ni)+' channels in DD='+str(idd)
    #
    print 'Set Total '+str(ntotpts)+' spectral points in '+str(ntotrow)+' channels'
    myms.close()
    return  

def copyflags(vis,outputvis):
    """
    Copies the flag column from one measurement set to another.
    They must have the same number of data descriptor IDs (i.e. spws*pols), but
    the outputvis can have empty tables (the copy will be skipped for these).
    Usage:
    * vis: source ms
    * outputvis: destination ms
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find source ms file = ", vis
        return
    if (os.path.exists(outputvis) == False):
        print "Could not find destination ms file = ", outputvis
        return

    # Find number of data description IDs
    mytb = createCasaTool(tbtool)
    try:
        mytb.open(vis+"/DATA_DESCRIPTION")
    except:
        print "ERROR: failed to open source table ", vis
        return
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ndd = ddspwlist.__len__()
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()

    try:
        mytb.open(outputvis+"/DATA_DESCRIPTION")
    except:
        print "ERROR: failed to open source table ", outputvis
        return
    ddspwlist2 = mytb.getcol("SPECTRAL_WINDOW_ID")
    if (any(ddspwlist2 != ddspwlist)):
        print "The two measurement sets differ in spw numbers"
        print "      vis: ", str(ddspwlist)
        print "outputvis: ", str(ddspwlist2)
        mytb.close()
        return

    myms = createCasaTool(mstool)
    try:
        myms.open(vis)
    except:
        print "ERROR: failed to open source ms ", vis
        return
    outputms = createCasaTool(mstool)

    try:
        outputms.open(outputvis, nomodify=False)
    except:
        print "ERROR: failed to open output ms ", outputvis
        return

    print 'Found '+str(ndd)+' DataDescription IDs'
    for idd in range(ndd):
        # Find number of correlations in this DD
        print "Working on %2d" % (idd)
        pid = ddpollist[idd]
        ncorr = ncorlist[pid]
        # Select this DD (after reset if needed)
        if (idd > 0):
            myms.selectinit(reset=True)
            outputms.selectinit(reset=True)
        myms.selectinit(idd)
        flags = myms.getdata(['flag','flag_row'])
        outputms.selectinit(idd)
        if (outputms.range('time') == {}):
            print "  Skipping this descriptor (%2d)" % (idd)
            continue
        outputms.putdata(flags)
    myms.close()
    outputms.close()
    return

def testFlagRowColumn(vis):
    """
    Tests whether the FLAG_ROW column is consistent with the FLAG column.
    Returns True if consistent, False if inconsistent.
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    nrows = mytb.nrows()
    print "Performing test 1/2"
    selq="SELECT from "+vis+" WHERE FLAG_ROW==TRUE && NOT ALL(FLAG)==TRUE"
    seltbl = mytb.taql(selq)
    nrow = seltbl.nrows()

    # second test
    print "Performing test 2/2"
    selq="SELECT from "+vis+" WHERE FLAG_ROW==FALSE && ALL(FLAG)==TRUE"
    seltbl = mytb.taql(selq)
    nrow2 = seltbl.nrows()
    seltbl.close()
    mytb.close()
    if (nrow + nrow2 == 0):
        print "The FLAG and FLAG_ROW columns are consistent on all %d rows." % (nrows)
        return(True)
    else:
        print "WARNING!!!! The FLAG and FLAG_ROW columns are inconsistent on %d/%d rows." % (nrow,nrows)
        print "Test 1 had %d failures (flag_row=True where not all channels flalged)" % (nrow)
        print "Test 2 had %d failures (flag_row=False where all channels flagged)"% (nrow2)
        if (nrow == 0):
            print "Since test 1 passed, the issue probably does not represent a problem."
        return(False)

def splitListIntoContiguousListsAndRejectNarrow(channels, fraction=0.05):
    """
    Split a list of channels into contiguous lists, and reject those that
    have a small number of channels relative to the total channels in 
    all lists.
    Returns: a new single list
    """
    length = len(channels)
    mylists = splitListIntoContiguousLists(channels)
    channels = []
    for mylist in mylists:
        if (len(mylist) <= fraction*length):
            continue
        channels += mylist
    return(np.array(channels))

def splitListIntoContiguousLists(mylist, trim=0, recombine=False):
    """
    Called by copyweights. See also splitListIntoHomogenousLists.
    Converts [1,2,3,5,6,7] into [[1,2,3],[5,6,7]], etc.
    trim: will trim this many values from each side of each contiguous list before recombining
    -Todd Hunter
    """
    mylists = []
    if (len(mylist) < 1):
        return(mylists)
    newlist = [mylist[0]]
    for i in range(1,len(mylist)):
        if (mylist[i-1] != mylist[i]-1):
            if (trim == 0):
                mylists.append(newlist)
            elif (len(newlist) > 2*trim):
                mylists.append(newlist[trim:-trim])
            newlist = [mylist[i]]
        else:
            newlist.append(mylist[i])
    if (trim == 0):
        mylists.append(newlist)
    elif (len(newlist) > 2*trim):
        mylists.append(newlist[trim:-trim])
    if recombine:
        mylists = [j for i in mylists for j in i]
    return(mylists)
    
def splitListIntoHomogeneousLists(mylist):
    """
    Converts [1,1,1,2,2,3] into [[1,1,1],[2,2],[3]], etc.
    See also splitListIntoContiguousLists.
    -Todd Hunter
    """
    mylists = []
    newlist = [mylist[0]]
    for i in range(1,len(mylist)):
        if (mylist[i-1] != mylist[i]):
            mylists.append(newlist)
            newlist = [mylist[i]]
        else:
            newlist.append(mylist[i])
    mylists.append(newlist)
    return(mylists)
    
def compareTables(table1, table2, column='', verbose=False):
    """
    Checks whether all the columns are equal in two measurement sets, requiring 
    that both have the same number of rows. 
    verbose: if True, then print per-spw results even when columns are identical.
    table2: if blank, then assume the matching table is in the current working directory
    column: if blank, then check all columns
    - Todd Hunter
    """
    import hashlib
    if (not os.path.exists(table1)):
        print "Can not find table = ", table1
        return
    if table2 == '':
        table2 = os.path.basename(table1.rstrip('/'))
        print "Set table2 = ", table2
    if (not os.path.exists(table2)):
        print "Can not find table2 = ", table2
        return
    if table1[-1] != '/': table1 += '/'
    if table2[-1] != '/': table2 += '/'
    files = glob.glob(table1+'*')
    for fname in files:
        if os.path.isdir(fname): continue
        hash_md5 = hashlib.md5()
        with open(fname, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        h1 = hash_md5.hexdigest()
        hash_md5 = hashlib.md5()
        if len(os.path.dirname(table2)) > 0:
            fname = os.path.dirname(table2)+'/'+os.path.basename(fname)
        else:
            fname = os.path.basename(fname)
        with open(fname, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        h2 = hash_md5.hexdigest()
        if (h1 == h2):
            print "md5 sums match for %s" % (os.path.basename(fname))
        else:
            print "md5 sums do not match for %s" % (os.path.basename(fname))
    mytb = createCasaTool(tbtool)
    mytb2 = createCasaTool(tbtool)
    mytb.open(table1)
    mytb2.open(table2)
    nrows = len(mytb.getcol('TIME'))
    nrows2 = len(mytb2.getcol('TIME'))
    if (nrows != nrows2):
        mytb.close()
        mytb2.close()
        print "These tables have an unequal number of rows."
        return
    if column == '':
        columns = mytb.colnames()
    elif type(column) == str:
        columns = column.split()
    else:
        columns = column
    if 'SPECTRAL_WINDOW_ID' in mytb.colnames():
        spws = np.unique(mytb.getcol('SPECTRAL_WINDOW_ID'))
        for column in columns:
            diff = 0
            for spw in spws:
                myt = mytb.query('SPECTRAL_WINDOW_ID == %d' % spw)
                myt2 = mytb2.query('SPECTRAL_WINDOW_ID == %d' % spw)
                try:
                    wt = myt.getcol(column)
                    wt2 = myt2.getcol(column)
                    check = (wt==wt2)
                    if (check.all()):
                        if verbose:
                            print "The %s columns are identical for spw %d." % (column,spw)
                    else:
                        print "***** The %s columns are not identical for spw %d. *****" % (column, spw)
                        print "%g percent are the same." % (sum(check)*100.0/len(check))
                        diff += 1
                except:
                    print "Skipping empty column %s for spw %d" % (column,spw)
            if diff == 0:
                print "The %s columns are identical." % (column)
    else:
        for column in columns:
            try:
                wt = mytb.getcol(column)
                wt2 = mytb2.getcol(column)
                check = (wt==wt2)
                if (check.all()):
                    print "The %s columns are identical." % (column)
                else:
                    print "The %s columns are not identical." % (column)
                    print "%g percent are the same." % (sum(check)*100.0/len(check))
            except:
                print "Skipping empty column %s" % (column)
    mytb.close()
    mytb2.close()
    
def compareWeights(vis, vis2):
    """
    Checks whether the 'WEIGHT' columns are equal in two measurement sets, requiring 
    that both have the same number of rows. 
    - Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Can not find vis = ", vis
        return
    if (not os.path.exists(vis2)):
        print "Can not find vis2 = ", vis2
        return
    mytb = createCasaTool(tbtool)
    mytb2 = createCasaTool(tbtool)
    mytb.open(vis)
    mytb2.open(vis2)
    nrows = len(mytb.getcol('TIME'))
    nrows2 = len(mytb2.getcol('TIME'))
    if (nrows != nrows2):
        mytb.close()
        mytb2.close()
        print "These measurement sets have an unequal number of rows."
        return
    wt = mytb.getcol('WEIGHT')
    wt2 = mytb2.getcol('WEIGHT')
    check = (wt==wt2)
    if (check.all()):
        print "The weights are identical."
    else:
        print "The weights are not all the same."
        print "%g percent are the same." % (sum(check)*100.0/len(check))
    mytb.close()
    mytb2.close()

def fixConcatSigmaSpectrum(vis, inputvislist=[]):
    """
    Fix for CAS-9238, CAS-10221 (concat not copying the SIGMA_SPECTRUM column).
    Copies the sigma_spectrum column from a list of original measurement sets into
    their respective locations in a concat measurement set.
    vis: the concat measurement set (i.e. concatvis in the concat command)
    inputvislist: python list or comma-delimited string of the second, third, ... ms
       specified in the 'vis' parameter of concat.  Note, if you used 
       concat(timesort=True), be sure to put these ms in time order.
    """
    if type(inputvislist) == str:
        inputvislist == inputvislist.split(',')
    if not os.path.exists(vis):
        print "Could not find vis"
        return
    for v in inputvislist:
        if not os.path.exists(v):
            print "Could not find inputvis: ", v
            return
    obsids = getObservationIDs(vis)
    if len(inputvislist) >= len(obsids):
        print "Not enough input measurement sets supplied for %d obs_IDs in the concat ms." % (len(obsids))
        return
    for i,obsid in enumerate(obsids[1:]):
        print "Working on obsID: ", obsid
        transferSigmaSpectrum(inputvislist[i], vis, obsid)

def transferSigmaSpectrum(vis, concatvis, obsid=0):
    """
    Copies the sigma_spectrum column from an original measurement set to its location in a
    concat measurement set.
    vis: original measurement set
    concatvis: the measurement set with multiple obsIDs
    obsid: the obsid of vis in concatvis
    """
    if not os.path.exists(vis):
        print "Could not find vis"
        return
    if not os.path.exists(concatvis):
        print "Could not find concatvis"
        return
    # Find number of data description IDs
    mytb_in = createCasaTool(tbtool)
    mytb_in.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb_in.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb_in.getcol("POLARIZATION_ID")
    mytb_in.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    mytb_in.open(vis)
    dd_in = np.unique(mytb_in.getcol('DATA_DESC_ID'))

    mytb_out = createCasaTool(tbtool)
    mytb_out.open(concatvis,nomodify=False)
    myt = mytb_out.query('OBSERVATION_ID==%d'%(obsid))
    dd_out = np.unique(myt.getcol('DATA_DESC_ID'))
    myt.close()
    if (len(dd_in) != len(dd_out)):
        mytb_in.close()
        mytb_out.close()
        print "Mismatch of spws (%d in input, %d in output)" % (len(dd_in), len(dd_out))
        return
    for i in range(len(dd_in)):
        myt = mytb_in.query('DATA_DESC_ID==%d' % (dd_in[i]))
        recw = myt.getcol("SIGMA_SPECTRUM")
        uvw_in = np.transpose(myt.getcol('UVW'))
        antenna1_in = myt.getcol('ANTENNA2')
        antenna2_in = myt.getcol('ANTENNA2')
        time_in = myt.getcol('TIME')
        myt.close()
        myt = mytb_out.query('DATA_DESC_ID==%d && OBSERVATION_ID==%d'%(dd_out[i],obsid))
        uvw_out = np.transpose(myt.getcol('UVW'))
        antenna1_out = myt.getcol('ANTENNA2')
        antenna2_out = myt.getcol('ANTENNA2')
        time_out = myt.getcol('TIME')
        if True:
            idx1 = np.where(antenna1_in != antenna2_out)[0]
            idx2 = np.where(antenna2_in != antenna2_out)[0]
            idx = np.union1d(idx1,idx2)
            print "Warning: baseline mismatch on %d of %d rows (OK if antennas moved between observations)" % (len(idx), len(antenna1_out))
        if not np.array_equal(time_in,time_out):
            print "time column does not match for spw %d (input) = %d (output). Not copying data!" % (dd_in[i], dd_out[i])
            print "in %d rows: row=%d: %.2f, %.2f" % (len(idx), idx[0], time_in[idx[0]], time_out[idx[0]])
            myt.close()
            continue
        if not np.array_equal(np.abs(uvw_in),np.abs(uvw_out)):
            print "uvw column does not match for spw %d (input) = %d (output). Not copying data!" % (dd_in[i], dd_out[i])
            idx = np.where(uvw_in != uvw_out)[0]
            j = idx[0]
            print "uvw_in[%d]=%s  uvw_out[%d]=%s" % (j, str(uvw_in[j]), j, str(uvw_out[j]))
        myt.putcol('SIGMA_SPECTRUM', recw)
        myt.close()
    mytb_in.close()
    mytb_out.close()
    
def transferWeights(vis, outputvis):
    """
    Copies the weights from one ms to another ms, requiring that both have
    the same number of rows.  This is useful for copying weights from a
    continuum-subtracted dataset to the corresponding continuum dataset.
    vis: the measurement set from which to read the weights
    outputvis: the measurement set to which to write the weights
    - Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Can not find vis = ", vis
        return
    if (not os.path.exists(outputvis)):
        print "Can not find outputvis = ", outputvis
        return
    mytb = createCasaTool(tbtool)
    mytb2 = createCasaTool(tbtool)
    mytb.open(vis)
    mytb2.open(outputvis, nomodify=False)
    nrows = len(mytb.getcol('TIME'))
    nrows2 = len(mytb2.getcol('TIME'))
    if (nrows != nrows2):
        mytb.close()
        mytb2.close()
        print "These measurement sets have an unequal number of rows."
        return
    print "Reading weights"
    wt = mytb.getcol('WEIGHT')
    print "Writing weights"
    mytb2.putcol('WEIGHT', wt)
    mytb.close()
    mytb2.close()

def transferWeightsWithinMS(vis, fromspw, tospw, dryrun=False):
    """
    Copies the WEIGHT and SIGMA values from one spw to one or more other 
    spws, requiring that both have the same number of rows.  This is 
    useful for copying weights in a VLA dataset from a line-free spw 
    to a line-full spw (for which statwt could not be run).
    vis: the measurement set from which to read/write the weights
    fromspw: integer or string integer
    tospw: integer or list of integers or comma-delimited string
    Example: if these were fit: 0,1,5,6,7,8,9,10,15
          fromspw=1, tospw=[2,3]
          fromspw=5, tospw=[4]
          fromspw=10,tospw=[11,12,13,14] (since 15 is an edge spw)
    - Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Can not find vis = ", vis
        return
    fromspw = int(fromspw)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    idd = mymsmd.datadescids(spw=fromspw)[0]
    if (type(tospw) == str):
        tospw = [int(i) for i in tospw.split(',')]
    elif (type(tospw) != list):
        tospw = [tospw]
    to_ddid = []
    for spw in tospw:
        to_ddid.append(mymsmd.datadescids(spw=spw)[0])
    mymsmd.close()
    mytb = createCasaTool(tbtool)
    mytb.open(vis, nomodify=False)
    myt = mytb.query('DATA_DESC_ID==%d'%(idd))
    wt = myt.getcol('WEIGHT')
    sigma = myt.getcol('SIGMA')
    myt.close()
    # First check that all target spws have same number of rows as source spw.
    for i,idd in enumerate(to_ddid):
        myt = mytb.query('DATA_DESC_ID==%d'%(idd))
        oldwt = myt.getcol('WEIGHT')
        myt.close()
        if (len(oldwt) != len(wt)):
            print "Length of fromspw(%d)=%d does not match tospw %d=%d" % (fromspw,len(wt),tospw[i],len(oldwt))
            mytb.close()
            return
    for i,idd in enumerate(to_ddid):
        myt = mytb.query('DATA_DESC_ID==%d'%(idd))
        if not dryrun:
            myt.putcol('WEIGHT', wt)
            myt.putcol('SIGMA', sigma)
        myt.close()
    mytb.close()

def copyweights(msfile):
    """
    copyweights copies the WEIGHT column to the WEIGHT_SPECTRUM column by
    using the same value for all channels in the spectrum (on a 
    per-polarization basis).
    
    Usage: copyweights(msfile)
    -- Todd Hunter
    """
    if (os.path.exists(msfile) == False):
        print "Could not find ms file = ", msfile
        return(2)
    mytb = createCasaTool(tbtool)
    mytb.open(msfile)
    colnames = mytb.colnames()
    mytb.close()
    """
    myms = createCasaTool(mstool)
    try:
        myms.open(msfile,nomodify=False)
    except:
        print "ERROR: failed to open ms tool on file "+msfile
        return(3)
    """
    # Find number of data description IDs
    mytb.open(msfile+"/DATA_DESCRIPTION")
    ddspwlist=mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist=mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(msfile+"/POLARIZATION")
    ncorlist=mytb.getcol("NUM_CORR")
    mytb.close()
    mytb.open(msfile, nomodify=False)
    #
    ntotrow=0
    ntotpts=0
    for idd in range(ndd):
        print "working on data descriptor %d/%d" % (idd+1,ndd)
        myms = mytb.getcol('DATA_DESC_ID')
        indices = np.where(myms == idd)[0]
        mylists = splitListIntoContiguousLists(indices)
        for m in range(len(mylists)):
            mylist = mylists[m]
            startrow = mylist[0]
            stoprow = mylist[-1]
            nrow = stoprow-startrow+1
            data = mytb.getvarcol("DATA", startrow, nrow)
            recw = mytb.getvarcol("WEIGHT", startrow, nrow)
            recws = mytb.getvarcol("WEIGHT_SPECTRUM", startrow, nrow)
            for row in recws.keys():
                datarow = np.real(data[row])/np.real(data[row])
                for pol in range(len(datarow)):
                    multiplier = recw[row][pol]
                    datarow[pol] *= multiplier
                recws[row] = datarow
            mytb.putvarcol('WEIGHT_SPECTRUM', recws, startrow, nrow)

    mytb.close()
    return

def getDataShapes(vis):
    """
    Finds and returns the number of polarizations in non-WVR (BBC 0) spws.
    Return value can be [1], [1,2], [1,2,4], [2,4], [1,4], [4]
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find ms file = ", vis
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    # Find number of data description IDs
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist=mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist=mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
#    print 'Found '+str(ndd)+' DataDescription IDs'
    # Now the polarizations (number of correlations in each pol id)
    mytb.open(vis+"/POLARIZATION")
    ncorlist = mytb.getcol("NUM_CORR")
    mytb.close()
    ncorrs = []
    for idd in range(ndd):
        # Find number of correlations in this DD
        pid = ddpollist[idd]
        ncorr = ncorlist[pid]
        if (ncorr == 1):
#            print "Single-pol spw = ", ddspwlist[idd]
            if (getBasebandNumber(vis, ddspwlist[idd]) == 0):  # WVR is always BBC 0
                continue
        ncorrs.append(ncorr)
    #
    ncorrs = np.unique(ncorrs)
#    print "unique sizes of correlations = ", ncorrs
    return(ncorrs)

def getObservationStop(vis, obsid=-1, verbose=False):
    """
    Read the stop time of the observation and report it in MJD seconds.
    obsid: if -1, return the stop time of the latest obsID
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "vis does not exist = %s" % (vis)
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mytb = createCasaTool(tbtool)
    try:
        mytb.open(vis+'/OBSERVATION')
    except:
        print "ERROR: failed to open OBSERVATION table on file "+vis
        return(3)
    time_range = mytb.getcol('TIME_RANGE')
    mytb.close()
    if verbose:  print time_range
    # the first index is whether it is starttime(0) or stoptime(1) 
    time_range = time_range[1]
    if (obsid >= len(time_range)):
        print "Invalid obsid"
        return
    if obsid >= 0:
        time_range = time_range[obsid]
    elif (type(time_range) == np.ndarray):
        time_range = np.max(time_range)
    return(time_range)

def getObservationStopDate(vis, obsid=0):
    """
    Read the stop time of the observation and reports the date.
    '2013-01-31 07:36:01 UT'
    -Todd Hunter
    """
    mjdsec = getObservationStop(vis, obsid)
    if (mjdsec is None): return
    obsdateString = mjdToUT(mjdsec/86400.)
    return(obsdateString)

def getObservationStart(vis, obsid=-1, verbose=False):
    """
    Reads the start time of the observation from the OBSERVATION table and reports it in MJD seconds.
    obsid: if -1, return the start time of the earliest obsID
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "vis does not exist = %s" % (vis)
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        print "Use au.getObservationStartDateFromASDM()."
        return
    mytb = createCasaTool(tbtool)
    try:
        mytb.open(vis+'/OBSERVATION')
    except:
        print "ERROR: failed to open OBSERVATION table on file "+vis
        return(3)
    time_range = mytb.getcol('TIME_RANGE')
    mytb.close()
    if verbose:  print "time_range: ", str(time_range)
    # the first index is whether it is starttime(0) or stoptime(1) 
    time_range = time_range[0]
    if verbose:  print "time_range[0]: ", str(time_range)
    if (obsid >= len(time_range)):
        print "Invalid obsid"
        return
    if obsid >= 0:
        time_range = time_range[obsid]
    elif (type(time_range) == np.ndarray):
        time_range = np.min(time_range)
    return(time_range)

def getObservationStartDates(vislist):
    """
    Runs getObservationStartDate for a list of measurement sets
    vislist: python list or comma-delimited string of the second, third, ... ms
    """
    if (type(vislist) == str):
        if vislist.find('*') >= 0:
            vislist = sorted(glob.glob(vislist))
        else:
            vislist = vislist.split(',')
    dates = []
    for vis in vislist:
        dates.append(getObservationStartDate(vis))
    return dates
    
def getObservationStartDate(vis, obsid=0, delimiter='-', measuresToolFormat=False):
    """
    Uses the tb tool to read the start time of the observation and reports the date.
    Returns: '2013-01-31 07:36:01 UT'
    measuresToolFormat: if True, then return '2013/01/31/07:36:01'
    -Todd Hunter
    """
    mjdsec = getObservationStart(vis, obsid)
    if (mjdsec is None):
        return
    obsdateString = mjdToUT(mjdsec/86400.)
    if (delimiter != '-'):
        obsdateString = obsdateString.replace('-', delimiter)
    if measuresToolFormat:
        return(obsdateString.replace(' UT','').replace(delimiter,'/').replace(' ','/'))
    else:
        return(obsdateString)

def timeShift(vis='', seconds=''):
    """
    Shift the observation time of an ms by a specified number of seconds in
    the OBSERVATION table TIME_RANGE column.
    This is simply a debugging tool and is not meant to correct a dataset!
    Todd Hunter
    """

    if (os.path.exists(vis) == False):
        print "vis does not exist = %s" % (vis)
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    try:
        tb.open(vis+'/OBSERVATION',nomodify=False)
    except:
        print "ERROR: failed to open OBSERVATION table on file "+vis
        return(3)

    time_range = tb.getcol('TIME_RANGE')
    print "Time range changed from: %f - %f (%s - %s)" % (time_range[0], time_range[1],
                                                          plotbp3.utstring(time_range[0]),
                                                          plotbp3.utstring(time_range[1]))
    time_range[0] += seconds
    time_range[1] += seconds
    tb.putcol('TIME_RANGE',time_range)
    tb.close()
    print "                     to: %f - %f (%s - %s)" % (time_range[0], time_range[1],
                                                          plotbp3.utstring(time_range[0]),
                                                          plotbp3.utstring(time_range[1]))

def dateStringDifference(date1, date2):
    """
    Computes difference between 2 date strings YYYY-MM-DD HH:MM:SS
    and returns the value in minutes. - Todd Hunter
    """
    days = abs(dateStringToMJD(date1,verbose=False) - dateStringToMJD(date2,verbose=False))
    return days*1440

def timeDifferenceASDM(asdm1, asdm2):
    """
    Find the difference in observation start time between two ASDM.
    Returns the value in seconds.
    Todd Hunter
    """
    t1 = getObservationStartDateFromASDM(asdm1)[1]
    t2 = getObservationStartDateFromASDM(asdm2)[1]
    print "Time difference (asdm2-asdm1) = %f sec = %f days" % (t2-t1, (t2-t1)/86400.)
    return(t2-t1)
    

def timeDifference(vis, vis2):
    """
    Find the difference in observation start time between two ms.
    using the OBSERVATION table TIME_RANGE column.
    Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "vis does not exist = %s" % (vis)
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  vis1 does not appear to be an ms."
        return
    if (os.path.exists(vis2) == False):
        print "vis2 does not exist = %s" % (vis2)
        return(2)
    if (os.path.exists(vis2+'/table.dat') == False):
        print "No table.dat.  vis2 does not appear to be an ms."
        return
    try:
        tb.open(vis+'/OBSERVATION')
    except:
        print "ERROR: failed to open OBSERVATION table on file "+vis
        return(3)
    time_range = tb.getcol('TIME_RANGE')
    tb.close()
    try:
        tb.open(vis2+'/OBSERVATION')
    except:
        print "ERROR: failed to open OBSERVATION table on file "+vis2
        return(3)
    time_range2 = tb.getcol('TIME_RANGE')
    tb.close()
    print "Time difference (vis2-vis1) = %f sec = %f days" % (time_range2[0]-time_range[0], 
                                                              (time_range2[0]-time_range[0])/86400.)

def uvwDifference(vis='', vis2=''):
    """
    Find the difference in uvw's between two (nearly) identical ms.
    Useful for confirming that fixvis did the right thing.
    Todd Hunter
    """

    if (os.path.exists(vis) == False):
        print "vis does not exist = %s" % (vis)
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  vis does not appear to be an ms."
        return
    if (os.path.exists(vis2) == False):
        print "vis2 does not exist = %s" % (vis2)
        return(2)
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  vis2 does not appear to be an ms."
        return
    try:
        tb.open(vis)
    except:
        print "ERROR: failed to open file "+vis
        return(3)
    uvw1 = tb.getcol('UVW')
    tb.close()
    try:
        tb.open(vis2)
    except:
        print "ERROR: failed to open file "+vis2
        return(3)
    uvw2 = tb.getcol('UVW')
    field = tb.getcol('FIELD_ID')
    tb.close()
    if (len(uvw1) != len(uvw2)):
        print "These ms differ in their number of rows (%d vs. %d)." % (len(uvw1),len(uvw2))
        return
    else:
        print "Boths ms have %d rows. Good." % (len(uvw1))
    fields = []
    differences = 0
    u = []
    v = []
    w = []
    for i in range(len(uvw1)):
        deltaU = uvw1[i][0]-uvw2[i][0]
        deltaV = uvw1[i][1]-uvw2[i][1]
        deltaW = uvw1[i][2]-uvw2[i][2]
        if (abs(deltaU)>0 or abs(deltaV)>0 or abs(deltaW)>0):
            u.append(abs(deltaU))
            v.append(abs(deltaV))
            w.append(abs(deltaW))
            fields.append(field[i])
            differences += 1
    fields = np.unique(fields)
    print "Found %d rows that differ." % (differences)
    if (differences > 0):
        print "Fields that differ: ", fields
        print "Median absolute differences: %f,%f,%f" % (np.median(u),np.median(v),np.median(w))

def getRADecStringForField(vis, myfieldId, usemstool=False, forcePositiveRA=False):
    """
    Returns an RA/Dec sexagesimal string for the specified field in the specified ms.
    myfieldId can be integer or string integer
    """
    return(rad2radec(getRADecForField(vis,myfieldId,usemstool,forcePositiveRA)))

def makePtgfile(vis, field, repeats=1, ptgfile='', phaseCenterOffset=None):
    """
    Generates a ptgfile from an existing measurement set
    suitable for reading into simobserve.
    field: name of field for which to get all pointings
    phaseCenterOffset: if specified, insert another field at this offset [RA_arcsec, Dec_arcsec]
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    allfields = mymsmd.namesforfields()
    if (field not in allfields):
        print "%s is not in the list of fields of this ms." % (field)
        return
    fields = mymsmd.fieldsforname(field)
    mymsmd.close()
    pos = getRADecForFields(vis)
    if (ptgfile == ''):
        ptgfile = vis.rstrip('.ms')+'.ptg'
    o = open(ptgfile,'w')
    o.write('#Epoch     RA          DEC      TIME(optional)\n')
    total = len(fields)
    for f in range(len(allfields)):
        if (f in fields):
            ra, dec = rad2radec(pos[0][0][f], pos[1][0][f], hmdm=True, verbose=False).split(',')
            for r in range(repeats):
                o.write('J2000 %s %s\n' % (ra,dec))
    if (phaseCenterOffset is not None):
        radec = np.array([pos[0][0][0],pos[1][0][0]]) + np.radians(np.array(phaseCenterOffset)/3600.)
        ra,dec = rad2radec(list(radec),hmdm=True,verbose=False).split(',')
        o.write('J2000 %s %s\n' % (ra,dec))
    o.close()
    print "Wrote %d fields to %s" % (total, ptgfile)
    return(ptgfile)

def getRADecForFields(vis, usemstool=True, forcePositiveRA=False, blendByName=True):
    """
    Returns a list of [RA,Dec] in radians for all fields in the specified ms.
    -- Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    nfields = mymsmd.nfields()
    # emulate the structure returned by tb.getcol('PHASE_DIR')
    mylist = np.array([[np.zeros(nfields)],[np.zeros(nfields)]])
    for field in range(nfields):
        ra,dec = getRADecForField(vis, field, blendByName=blendByName, mymsmd=mymsmd)
        mylist[0][0][field] = ra
        mylist[1][0][field] = dec
    mymsmd.close()
    return(mylist)

def getEquinoxForField(vis, field, usemstool=True, blendByName=True, myms='', mytb='', mymsmd=''):
    """
    Returns the equinox (J2000, B1950, ICRS) for the specified field in an ms.
    -Todd Hunter
    """
    mydir, referenceFrame = getRADecForField(vis, field, usemstool, blendByName=blendByName, 
                                             myms=myms, mytb=mytb, mymsmd=mymsmd, returnReferenceFrame=True)
    return referenceFrame

def getRADecForField(vis, field, usemstool=True, forcePositiveRA=False, verbose=False,
                     blendByName=True, myms='', mytb='', returnReferenceFrame=False, 
                     mymsmd='', hms=False):
    """
    Returns array([[RA,Dec]]) in radians for the specified field in the specified 
            measurement set using the ms.getfielddirmeas method.
    vis: measurement set
    field: can be integer or string integer or string name.  
    blendByName: if True, then get fields for name after translating from ID.
    myms: an existing ms tool instance (if available) only relevant if usemstool=True
    mytb: an existing tb tool instance (if available) only relevant if usemstool=False
    mymsmd: an existing msmd tool instance (if available)
    hms: if True, the return a colon- and comma-delimited sexagesimal string:
              HH:MM:SS.SSSSSS, +DD:MM:SS.SSSSS
    -- Todd Hunter
    """
    try:
#        exists = os.path.exists(vis)  # this fails in CASA 5.x when called from Atmcal
        exists = os.path.isdir(vis)    # this fails in CASA 5.x when called from Atmcal
        if (not exists):
            print "Could not find measurement set"
            return
    except:
#        print "os.path.exists failed, proceeding anyway"
        print "os.path.isdir failed, proceeding anyway"
        pass
    if (casadef.casa_version >= '4.2.0' and usemstool):
        result = parseFieldArgument(vis, field, blendByName, mymsmd)
        if (result is None): return
        idlist, namelist = result
#        print "blendByName=%s, field=%s, idlist = " % (blendByName,str(field)), idlist
        needToClose = False
        if myms == '':
            myms = createCasaTool(mstool)
            myms.open(vis)
            needToClose = True
        if (type(field) == str):
            if (not field.isdigit()):
                field = idlist[0]
            field = int(field)
        if verbose: print "running myms.getfielddirmeas(fieldid=%d)" % (field)
        myd = myms.getfielddirmeas(fieldid=field) # dircolname defaults to 'PHASE_DIR'
        mydir = np.array([[myd['m0']['value']], [myd['m1']['value']]]) # emulates tb.getcell
        refer = myd['refer']
        if returnReferenceFrame:
            mydir = [mydir, myd['refer']]
        if needToClose:
            myms.close()
    else:
        needToClose = False
        if mytb=='':
            mytb = createCasaTool(tbtool)
            try:
                mytb.open(vis+'/FIELD')
            except:
                print "Could not open FIELD table for ms=%s" % (vis)
                return([0,0])
            needToClose = True
        mydir = mytb.getcell('DELAY_DIR',int(field))
        refer = mytb.getcell('DelayDir_Ref',int(field))
        if needToClose:
            mytb.close()
    if (forcePositiveRA):
        if (mydir[0] < 0):
            mydir[0] += 2*math.pi
    if hms:
        radec = rad2radec(mydir, verbose=verbose)
        if returnReferenceFrame:
            return radec, refer
        else:
            return radec
    else:
        return mydir 

def angularSeparationOfFieldsFromSource(vis, source='', field='', returnComponents=False,
                                        verbose=False, smallAngleError=False):
    """
    Computes the angular separation of all fields associated with a source ID, 
    from the source position.
    source: the ID or name of the source position to use (from SOURCE table)
            if left blank, then pick the science target fields
    field: the field ID (integer or string) to use, or '' for all.
    returnComponents: if True, also return the RA, Dec components of separation
    smallAngleError: if True, then also compute the error that would have been
         caused by using the small angle (1/cos(dec)) approximation instead of
         the complete Euler angle formula
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Measurement set not found"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    fieldsToFindSource = mymsmd.fieldsforintent('OBSERVE_TARGET*')
    if source == '':
        usingScienceTarget = True
        source = mymsmd.sourceidforfield(fieldsToFindSource[0])
        print "Choosing source %s" % (source)
    else:
        usingScienceTarget = False
    if (type(field) != list):
        if (field != ''):
            result = parseFieldArgument(vis,field,blendByName=False)
            if (result is None): return
            ids, fields = result
        elif usingScienceTarget:
            ids = mymsmd.fieldsforintent('OBSERVE_TARGET*')
            fields = mymsmd.namesforfields(ids)
        else:
            fields = mymsmd.fieldnames()
            ids = range(mymsmd.nfields())
    else:
        ids = field
        fields = mymsmd.namesforfields(ids)
    if (type(field)==str):
        if (field.isdigit()):
            ids = [int(i) for i in field.split(',')]
            fields = mymsmd.namesforfields(ids)
    mymsmd.close()
    sourceRadec = getRADecForSource(vis, source)
    print "Source direction = ", sourceRadec
    separations = {}
    if smallAngleError: 
        returnComponents=True
    error = []
    for i,f in enumerate(fields):
        fieldRadec = rad2radec(getRADecForField(vis, ids[i], blendByName=False), verbose=False)
        if (verbose):
            print f, fieldRadec
        separation = angularSeparationOfStrings(sourceRadec, fieldRadec, returnComponents, 
                                                verbose=False)
        if returnComponents:
            rao = separation[1]*3600
            deco = separation[2]*3600
            line = "Field %2d: %s separation: %.3f arcsec (dRA=%.3f, dDec=%.3f)" % (ids[i], fieldRadec,separation[0]*3600,rao,deco)
            if smallAngleError: 
                correctDirection = radecOffsetToRadec(sourceRadec, -rao, -deco, verbose=False)
                badDirection = radecOffsetToRadec(sourceRadec, -rao, -deco, useEulerAngles=False, verbose=False)
                separation = angularSeparationOfStrings(correctDirection,badDirection,returnComponents=True,verbose=False)
                dra = separation[1]*3600; ddec = separation[2]*3600
                error.append(separation[0]*3600)
                line += "  Small angle error: %.4f arcsec (RA=%.4f, Dec=%.4f)" % (separation[0]*3600,dra,ddec)
            print line
        else:
            print "Field %d = %s: %.6f deg = %.3f arcsec" % (ids[i], str(f),separation,separation*3600)
        separations[f] = separation
    if smallAngleError and len(error)>1: 
        print "small angle error: min=%.3f  max=%.3f  mean=%.3f arcsec, max=%.3f synth.beams" % (np.min(error), np.max(error), np.mean(error), np.max(error)/estimateSynthesizedBeam(vis))
    return separations

def getRADecForSourceTable(vis, fieldname='', sourceid='', prec=10, radians=True):
    """
    Reads the SOURCE table of a measurement set and prints the unique
    RA/Dec to great precision and compares to the phaseDir values in
    the FIELD table.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SOURCE')
    direction = np.transpose(mytb.getcol('DIRECTION'))
    fieldnames = mytb.getcol('NAME')
    ids = mytb.getcol('SOURCE_ID')
    mytb.close()
    if (fieldname != ''):
        if (sourceid != ''):
            print "Specify only one of: fieldname, sourceid"
            return
        idx = np.where(fieldnames == fieldname)[0]
    elif (sourceid != ''):
        idx = np.where(ids == int(sourceid))[0]
    else:
        idx = range(len(direction))
    if (len(idx) < 1):
        print "No entries found."
    if False:
        dirs = np.unique(direction)
        idx = []
        for mydir in dirs:
            for i,d in enumerate(direction):
                print "mydir=%s, d=%s" % (mydir,d)
                if (mydir == d):
                    idx.append(i)
                    break
    for i in idx:
        if radians:
            position = '%.*f, %.*f' % (prec,direction[i][0],prec,direction[i][1])
        else:
            position = rad2radec(direction[i], prec=prec, verbose=False)
        print "line#%3d, field=%s, ID=%d: %s" % (i,fieldnames[i],ids[i],
                                                 position)

def getRADecForSource(vis, source, verbose=False, firstAppearance=True):
    """
    Calls msmd.sourcedirs or msmd.refdir and extracts the RA/Dec for the 
    specified source ID, and returns the value as a sexagesimal string,
    such as: '10:37:16.07974, -029:34:02.813200'
    vis: measurement set
    source: source ID (integer or string integer) or source name
    firstAppearance: if multiple source IDs for the same source name, then
       return the first one;  else return the final one
    -Todd Hunter
    """
    if (casadef.casa_version < '4.5'):
        print "This function is not available until CASA 4.5"
        return
    if (not os.path.exists(vis)):
        print "Measurement set not found."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    try:
        mydict = mymsmd.sourcedirs()
        sourceids = mymsmd.sourceidsfromsourcetable()
        if verbose:
            print "sourceids = ", sourceids
        refdir = False
    except:
        refdir = True
        mydict = mymsmd.refdir(source)
#    print "type(source) = ", type(source)
    if (type(source) == str or type(source) == np.string_):
        if (not source.isdigit()):
            sourceName = source
            sourcenames = mymsmd.sourcenames()
            if verbose:
                print "Found %d sources (%d unique names)" % (len(sourcenames), len(np.unique(sourcenames)))
            if firstAppearance:
                source = sourcenames.index(sourceName)
            else: # find the final appearance of this source name
                source = (len(sourcenames)-1)-sourcenames[::-1].index(sourceName)
            print "%s is source ID %d" % (sourceName,sourceids[source])
            source = sourceids[source]
    if (refdir):
        return(direction2radec(mydict))
    else:
        idx = np.where(sourceids == source)[0]
        directions = []
        for i in idx:
            directions.append(direction2radec(mydict[str(i)]))
        directions = np.unique(directions)
        if firstAppearance:
            return directions[0]
        else:
            return directions[-1]

def getRADecForFieldFromASDM(asdm, field, forcePositiveRA=False,
                             sexagesimal=False, verbose=False):
    """
    Reads the RA, Dec for a specified field in an ASDM
    Returns: RA and Dec in radians
    field: field ID integer or string, or field name string; 
         it will check the Ephemeris.xml and use it if the specified field
         (ID or name) is a solar system object.
    sexagesimal: if True, return a string in HH:MM:SS rather than radians
    -Todd Hunter
    """
    if (os.path.exists(asdm) == False):
        print "Could not find file = ", asdm
        return
    field = str(field)
    ra = None
    if (not field.isdigit()):
        ephemerisFields = getEphemerisFieldsFromASDM(asdm, keyBy='name', verbose=False)
        if ephemerisFields is None: ephemerisFields = []
        mydict = getFieldsFromASDM(asdm)[0]
        if verbose: print "mydict = ", mydict
        if (field not in mydict.values()):
            print "Field %s not found in ASDM.  Fields = " % (field), mydict.values()
            return
        mydict = readscans(asdm)[1]
        for key in mydict:
            if field == mydict[key]['source']:
                if field in ephemerisFields:
                    radec = ephemerisFields[field]['direction']
                    ra,dec = radec2rad(radec)
                else:
                    ra = mydict[key]['ra']
                    dec = mydict[key]['dec']
    else:
        ephemerisFields = getEphemerisFieldsFromASDM(asdm, keyBy='fieldID')
        field = int(field)
        xmlfields = minidom.parse(asdm+'/Field.xml')
        rowlist = xmlfields.getElementsByTagName("row")
        fields = []
        for rownode in rowlist:
            rownumLO = rownode.getElementsByTagName("fieldId")
            fieldId = int(str(rownumLO[0].childNodes[0].nodeValue).split('_')[1])
            fields.append(fieldId)
            if (fieldId == field):
                if field in ephemerisFields:
                    radec = ephemerisFields[field]['direction']
                    ra,dec = radec2rad(radec)
                else:
                    rownumLO = rownode.getElementsByTagName("phaseDir")
                    ra = float(str(rownumLO[0].childNodes[0].nodeValue).split(' ')[3])
                    dec = float(str(rownumLO[0].childNodes[0].nodeValue).split(' ')[4])
                break
    if (ra is None):
        print "Field not found.  Fields = ", fields
        return
    if (forcePositiveRA and ra < 0):
        ra += 2*np.pi
    if (sexagesimal):
        return(rad2radec(ra,dec,verbose=False))
    else:
        return(ra, dec)

def datasetsForMOUS(mous,wget='wget',verbose=False,overwrite=False,
                   sevenMeter=True, twelveMeter=True, totalPower=True,
                   status='', sb='', exactStatus=True):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    executions for an OUS.  See also datasetsForProjectCode and getOUS.
    mous: MOUS code
    wget: the full path to the wget executable
    verbose: if True, then print complete information 
    overwrite: if True, then download new copy of the table (fstoehr.txt)
    status: '' or 'Pass' or 'Fail' or 'SemiPass' or 'None' (case-insensitive)
    exactStatus: if True, then prepend a 'tab' character to status 
                 (e.g. to differentiate between Pass and SemiPass)
    sb: '' or name of sb to match
    Returns: project code, SB name, MOUS, and region (all as strings)
    -Todd Hunter
    """
    mous = uidToUnderscores(mous.lstrip('MOUS_'))
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    if (status != '' and exactStatus):
        status = '\t'+status
    try:
        output = getFelixTable(wget, overwrite)
        executions = []
        if (verbose):
            print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME"
        for line in output.split('\n'):
            loc = line.find(mous)
            if (loc >= 0):
                lline = line.lower()
                if (((lline.find('7m"')>0 or lline.find('_ac"')>0) and sevenMeter) or
                    ((lline.find('_12m"')>0 or lline.find('_12m_')>0 or lline.find('12m ')>0 or lline.find('_te"')>0 or 
                      lline.find('_tc"')>0) and twelveMeter) or
                    (lline.find('_tp"')>0 and totalPower)):
                    if (status == '' or line.lower().find(status.lower())>=0):
                        if (sb == '' or line.find(sb)>=0):
                            tokens = line.split()
                            if (len(tokens) > 1): 
                                executions.append(tokens[5])
                                if (verbose):
                                    print line
        if (len(executions) < 1):
            return('This MOUS does not appear to be associated with a science project.')
        else:
            return executions
    except:
        return('Could not reach the server.  Try again at a different time.')

def getOUSForUID(uid,wget='wget',verbose=False,overwrite=False):
    """
    Consults an online table on F. Stoehr's machine in order to locate the 
    OUS that an ASDM or measurement set is associated with.
    See also datasetsForProjectCode and getOUS.  (The latter works without
    an internet connection, but requires the ASDM on disk.)
    uid: ASDM or ms name
    wget: the full path to the wget executable
    verbose: if True, then print complete information 
    overwrite: if True, then download new copy of table even if it exists in PWD
    Returns: MOUS
    -Todd Hunter
    """
    uid = uidToUnderscores(uid.lstrip('MOUS_')).replace('.ms','')
    if (not cmd_exists(wget)): 
        wget = '/opt/local/bin/wget'
        if (not cmd_exists(wget)): 
            return('Could not find wget executable on this machine.')
    try:
        output = getFelixTable(wget, overwrite)
        mous = ''
        if (verbose):
            print "Project_code  Hidden_OUS  Science_Goal_OUS  Group_OUS  Member_OUS  EB  Obs_Date  SB_Status  SB_UID  SB_NAME"
        for line in output.split('\n'):
            loc = line.find(uid)
            if (loc >= 0):
                lline = line.lower()
                tokens = line.split()
                if (len(tokens) > 1): 
                    mous = line.split()[4]
                    if verbose:
                        print line
        if (len(mous) < 1):
            return('This uid does not appear to be associated with a science project.')
        else:
            return mous
    except:
        return('Could not reach the server.  Try again at a different time.')
    
def getOUS(asdm):
    """
    Find the OUS that an ASDM is associated with by reading the ExecBlock.xml table.
    -- Todd Hunter
    """
#  <EntityRef entityId="uid://A002/X314ea1/X239" partId="X00000000" entityTypeName="OUSStatus" documentVersion="1.0" />
    execblock = asdm.strip() + '/ExecBlock.xml'
    if (os.path.exists(execblock) == False):
        print "Could not open %s" % (execblock)
        return
    cmd = "grep OUSStatus %s" % execblock
    status, output = commands.getstatusoutput(cmd)
    tokens = output.split()
    if (tokens < 5):
        print "Unexpected result = ", output
        return('')
    ous = tokens[1].split('=')[-1]
    ous = ous[1:-1] # chop off the double quotes
    ousUnderscore = ous.replace(':','_').replace('/','_')
    if (1 == 0):
        # apparently, minidom cannot parse EntityRef's
        xmlscans = minidom.parse(execblock)
        rowlist = xmlscans.getElementsByTagName("row")
        row = rowlist[0].getElementsByTagName("sessionReference")
        ousEntity = str(row[0].childNodes[0].nodeValue)  # this comes out simply as '\n'
    print "ous = %s = %s" % (ous, ousUnderscore)
    print "Now, you might wish to run (from bash):  pipelineMakeRequest %s intents_hifa.xml procedure_hifacal.xml false" % (ous)
    return(ous)

def getSubscanTimesFromASDM(asdm, field=''):
    """
    Reads the subscan information from the ASDM's Subscan.xml file and
    returns a dictionary of form:
    {scan: {subscan: {'field': '3c273, 'integrationTime': 2.016,
                      'numIntegration': 5, 'subscanLength': 10.08}}}
    -- dbarkats
    """
    if (asdmLibraryAvailable == False):
        print "The ASDM bindings library is not available on this machine. Using minidom code instead."
        return(au_noASDMLibrary.getSubscanTimesFromASDM_minidom(asdm,field))
    a = ASDM()
    a.setFromFile(asdm,True)
    subscanTable = a.subscanTable().get()  

    # get the start time of the ASDM
    dateStart, dateStart_mjdSec = getObservationStartDateFromASDM(asdm)
    dateEnd, dateEnd_mjdSec = getObservationEndDateFromASDM(asdm)

    scandict = {}
    scanNumbers = 0
    subscanTotalTime= 0
    for row in subscanTable:
        scanNumber = row.scanNumber()
        subscanNumber = row.subscanNumber()
        startTime = row.startTime().get() *1e-9
        endTime = row.endTime().get() *1e-9
        numIntegration = row.numIntegration()
        fieldName = row.fieldName()
        if (field=='' or fieldName==field):
            subscanLength = (endTime-startTime)
            subscanTotalTime += subscanLength
            integrationTime = subscanLength / (1.0*numIntegration)
            if (scanNumber not in scandict):
                scandict[scanNumber] = {}
                scanNumbers += 1
            scandict[scanNumber][subscanNumber] = {'subscanLength': subscanLength, 'numIntegration': numIntegration, 'integrationTime': integrationTime, 'field': fieldName, 'startTime':startTime,'endTime':endTime}
    print "Found %d scans" % (scanNumbers)
    totalTime = (dateEnd_mjdSec - dateStart_mjdSec)
    print totalTime, subscanTotalTime
    latency = totalTime - subscanTotalTime
    print "Total latency = %g/%g seconds = %g percent" % (latency, totalTime, latency*100/totalTime)
    return(scandict)
      
    
def getCorrelatorNameFromMS(vis):
    """
    Returns the correlator used in the specified measurement set.
    -- Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "Could not find MS = ", vis
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    cmode = vis+'/ASDM_CORRELATORMODE'
    if (os.path.exists(cmode) == False):
        print "Cannot find the ASDM_CORRELATORMODE table.  You need to run importasdm with asis='CorrelatorMode'."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(cmode)
    corrName = mytb.getcol('correlatorName')[0]
    mytb.close()
    return corrName
    
def getCorrelatorName(asdm):
    """
    Returns the correlator used in the specified ASDM from the CorrelatorMode.xml file.
    -- Todd Hunter
    """
#    <correlatorName>ALMA_ACA</correlatorName> 
    execblock = asdm + '/CorrelatorMode.xml'
    if (os.path.exists(execblock) == False):
        print "Could not open %s" % (execblock)
        return
    xmlscans = minidom.parse(execblock)
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    row = rowlist[0].getElementsByTagName("correlatorName")
    myName = str(row[0].childNodes[0].nodeValue)
    return(myName)
        
def getObservatoryNameFromASDM(asdm):
    """
    Returns the observatory name in the specified ASDM.
    -- Todd Hunter
    """
#    uid___A002_X54d35d_X761/ExecBlock.xml:    <telescopeName>ALMA</telescopeName>
    execblock = asdm + '/ExecBlock.xml'
    if (os.path.exists(execblock) == False):
        print "Could not open %s" % (execblock)
        return
    xmlscans = minidom.parse(execblock)
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    row = rowlist[0].getElementsByTagName("telescopeName")
    myName = str(row[0].childNodes[0].nodeValue).strip(' ')
#    print "Observatory = ", myName
    return(myName)

def getObservationStartDateFromASDMs(asdmlist, outfile='asdm_dates.txt',
                                     getAntennas=False, getSBFrequencies=False):
    """
    For a list of ASDMs, writes a file containing the start date/time of each.
    asdmlist: either a list of strings, or a string containing a wildcard pattern
    getAntennas: if True, then also list the antennas
    -- Todd Hunter
    """
    if (type(asdmlist)==str):
        asdmlist = sorted(glob.glob(asdmlist))
    f = open(outfile,'w')
    for asdm in asdmlist:
        if (asdm.find('.ms') > 0): continue
        if (asdm.find('.txt') > 0): continue
        utdate, mjdsec = getObservationStartDateFromASDM(asdm)
        if (getAntennas):
            antennas = ','.join(readAntennasFromASDM(asdm))
        else:
            antennas = ''
        mf = getMeanFreqFromASDM(asdm)
        if (getSBFrequencies):
            lsb = str(np.round(mf['lsb']['meanfreq']*1e-9, 1))
            usb = str(np.round(mf['usb']['meanfreq']*1e-9, 1))
        else:
            lsb = ''
            usb =''
        f.write("%s %s %s %s %s\n" % (asdm,utdate,antennas,lsb,usb))
        
    f.close()
    print "Result left in %s" % (outfile)

def getObservationMJDSecRange(vis):
    """
    Returns 2 floating point values in MJD seconds.
    - Todd Hunter
    """
    return([getObservationStart(vis),getObservationStop(vis)])

def getObservationMJDSecRangeFromASDM(asdm):
    """
    Returns 2 floating point values in MJD seconds.
    - Todd Hunter
    """
    start = getObservationStartDateFromASDM(asdm)[1]
    stop = getObservationEndDateFromASDM(asdm)[1]
    return([start,stop])

def getObservationLength(vis):
    """
    Returns length of measurement set in minutes.
    -Todd Hunter
    """
    start, stop = getObservationMJDSecRange(vis)
    return (stop-start)/60.
    
def getObservationLengthFromASDM(asdm):
    """
    Returns length of ASDM in minutes.
    -Todd Hunter
    """
    start,stop=getObservationMJDSecRangeFromASDM(asdm)
    return (stop-start)/60.

def getObservationDateRangeFromASDM(asdm):
    """
    Returns a string: '2015-10-22 00:16:44 UT to 2015-10-22 01:14:31 UT'
    - Todd Hunter
    """
    start = getObservationStartDateFromASDM(asdm)[0]
    stop = getObservationEndDateFromASDM(asdm)[0]
    return(start + ' to ' + stop)

def getObservationSummaryFromASDM(asdm):
    """
    Information to send to Bill Shillue:
       antennas used, start and stop times
    -Todd Hunter
    """
    if (type(asdm) != list):
        if (asdm.find('*') >= 0):
            asdm = glob.glob(asdm)
        else:
            asdm = [asdm]
    mystring = []
    for a in asdm:
        try:
            antennas = readAntennasFromASDM(a, False, False)
        except:
            continue
        daterange = getObservationDateRangeFromASDM(a)
        mystring.append(daterange + ', ' + str(antennas))
    if (len(asdm) == 1):
        mystring = mystring[0]
    return(mystring)
        
def getObservationStartDateFromASDM(asdm):
    """
    Returns the start date/time and MJD seconds in the specified ASDM.
    example:  ('2016-05-12 07:14:19 UT', 4969754058.985001)
    -- Todd Hunter
    """
#    uid___A002_X54d35d_X761/ExecBlock.xml:    <startTime>ALMA</startTime>
    execblock = asdm + '/ExecBlock.xml'
    if (os.path.exists(execblock) == False):
        print "Could not open %s" % (execblock)
        return
    xmlscans = minidom.parse(execblock)
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    row = rowlist[0].getElementsByTagName("startTime")
    mjdsec = int(row[0].childNodes[0].nodeValue) * 1e-9
    utdate = mjdsecToUT(mjdsec)
    return(utdate, mjdsec)

def getObservationEndDateFromASDM(asdm):
    """
    Returns the end date/time and MJD seconds in the specified ASDM.
    --  based on getObservationStartDateFromASDM
    """
#    uid___A002_X54d35d_X761/ExecBlock.xml:    <startTime>ALMA</startTime>
    execblock = asdm + '/ExecBlock.xml'
    if (os.path.exists(execblock) == False):
        print "Could not open %s" % (execblock)
        return
    xmlscans = minidom.parse(execblock)
    rowlist = xmlscans.getElementsByTagName("row")
    fid = 0
    row = rowlist[0].getElementsByTagName("endTime")
    mjdsec = int(row[0].childNodes[0].nodeValue) * 1e-9
    utdate = mjdsecToUT(mjdsec)
    return(utdate, mjdsec)
        
def getObservatoryName(ms):
    """
    Returns the observatory name in the specified ms, using the tb tool.
    -- Todd Hunter
    """
    antTable = ms+'/OBSERVATION'
    try:
        mytb = createCasaTool(tbtool)
        mytb.open(antTable)
        myName = mytb.getcell('TELESCOPE_NAME')
        mytb.close()
    except:
        print "Could not open OBSERVATION table to get the telescope name: %s" % (antTable)
        myName = ''
    return(myName)

def computeAzElFromRADecLST(raDec, lst=None, observatory='ALMA', date=None, degrees=False,
                            verbose=False):
    """
    Computes the az/el for a specified source position, LST and observatory.
    raDec must either be a tuple in radians: [ra,dec],
           or a string of the form "hh:mm:ss.sss -dd:mm:ss.ss"
    date: YYYYMMDD or YYYY/MM/DD where '/' is any delimiting character or space
    lst: in Radians, or a string in "hh:mm:ss";  if lst is not specified, then 
         the date is interpreted as a full date+time string (see au.ComputeLST)
    degrees: if False, returns Az,El in radians;  otherwise degrees
    """
    if ((lst==None or lst=='') and (date==None or date=='')):
        print "Using current LST and date"
        lst = ComputeLST()
        date = getCurrentDate(delimiter='-')
    elif (lst==None or lst==''): # only date is specified
        lst = ComputeLST(date=date,hms=True)
        if verbose:
            print "Computed LST = ", lst
    elif (date==None or date==''): # only LST is specified
        date = getCurrentDate()
    elif (len(date) > 10):
        print "WARNING: Ignoring the time portion of the date (since lst has been specified)"
    mjd = lst2mjd(lst, date, longitudeDegrees=getObservatoryLatLong(observatory)[1], verbose=verbose)
    az,el = computeAzElFromRADecMJD(raDec, mjd, observatory)
    if (degrees):
        az *= 180/np.pi
        el *= 180/np.pi
    return([az,el])

def computeAzElForMS(vis, value='mean', forcePositiveAzim=True, verbose=False,
                     ignorePointingSBAtmScans=True):
    """
    Computes the min/max/mean or median azim and elev for a measurement set using
    the RA/Dec and MJD of each scan. Works for ALMA and VLA data.
    vis: measurement set
    value: 'min', 'max', 'mean' or 'median'
    verbose: if True, then print the per scan values
    Returns: 2 values (azim and elev)
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    scans = mymsmd.scannumbers()
    if (ignorePointingSBAtmScans):
        pointingScans = list(mymsmd.scansforintent('CALIBRATE_POINTING*'))
        sbScans = list(mymsmd.scansforintent('CALIBRATE_SIDEBAND*'))
        atmScans = list(mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*'))
        calscans = sorted(pointingScans + sbScans + atmScans)
        if (len(calscans) > 0):
            print "Dropping pointing+sideband+atmosphere scans: ", calscans
            scans = [x for x in scans if x not in calscans]
            if verbose:
                print "Kept scans: ", scans
    observatory = mymsmd.observatorynames()[0]
    func = np.mean
    if value == 'median':
        func = np.median
    elif value == 'min':
        func = np.min
    elif value == 'max':
        func = np.max
    az = []
    el = []
    for scan in scans:
        field = mymsmd.fieldsforscan(scan)[0]
        raDecString = direction2radec(mymsmd.phasecenter(field))
        tfs = mymsmd.timesforscan(scan)/86400.
        mjd =  np.min(tfs)
        az0,el0 = computeAzElFromRADecMJD(raDecString, mjd, observatory, 
                                          degrees=True, frame='AZELGEO',
                                          forcePositiveAzim=forcePositiveAzim)
        mjd =  np.max(tfs)
        az1,el1 = computeAzElFromRADecMJD(raDecString, mjd, observatory, 
                                          degrees=True, frame='AZELGEO',
                                          forcePositiveAzim=forcePositiveAzim)
        az.append(func([az0,az1]))
        el.append(func([el0,el1]))
        if verbose:
            print "scan %d = %s, az=%f, el=%f" % (scan, raDecString, az[-1], el[-1])
    mymsmd.close()
    return func(az), func(el)

def radecToEcliptic(radec, degrees=False):
    """
    Uses the CASA measures tool to convert from equatorial to ecliptic coords.
    radec: string of the form "hh:mm:ss.sss -dd:mm:ss.ss", or [ra,dec] in rad
    Returns: longitude and latitude in radians, unless degrees=True
    -Todd Hunter
    """
    if (type(radec) == str):
        # Then assume it is of the format "hh:mm:ss.sss -dd:mm:ss.ss"
        tokens = radec.split()
        if (len(tokens) < 2):
            tokens = radec.split(',')
            if (len(tokens) < 2):
                print "If you give a string, it must be of the format: hh:mm:ss.sss -dd:mm:ss.ss"
                return
        radec = radec2rad(radec)
    myme = createCasaTool(metool)
    mydir = myme.direction('J2000',qa.quantity(radec[0],'rad'), 
                           qa.quantity(radec[1],'rad'))
    mjd = getMJD() # this really does not matter
    observatory = 'ALMA' # this really does not matter 
    myme.doframe(myme.epoch('mjd',qa.quantity(mjd,'d')))
    myme.doframe(myme.observatory(observatory))
    mydir = myme.measure(mydir,'ECLIPTIC')
    longrad = mydir['m0']['value']
    if (longrad < 0): longrad += 2*np.pi
    latrad = mydir['m1']['value']
    if degrees:
        return np.degrees(longrad), np.degrees(latrad)
    else:
        return longrad, latrad

def radec2ra(radec):
    """
    Takes a sexagesimal RA string or RA,Dec (space or comma-delimited)
    and returns just the RA part.
    -Todd Hunter
    """
    return radec.split()[0].split(',')[0]

def transitTime(ra=None, vis=None, field=None, date='', observatory='ALMA'):
    """
    Computes the UT time of transit of a target on a specific date.
    ra: sexagesimal string of RA or RA, Dec
    vis: measurement set
    field: ID or name, use its sky position
    date: string of format YYYY-MM-DD, default = today
    -Todd Hunter
    """
    if ra is not None:
        ra = radec2ra(ra)
    elif vis is not None:
        if field is None:
            fields = getScienceTargets(vis)
            if len(fields) == 0:
                print "You must specify a field ID or name."
                return
            else:
                field = fields[0]
                print "Using first science target: ", field
        ra = radec2ra(getRADecForField(vis,field,hms=True))
    else:
        print "You must specify either ra or vis+field"
        return
    if date == '':
        date = getCurrentDate()
    hours = hmsToHours(ra)
    longitude = getObservatoryLongitude(observatory)
    ut = lstToUT(hours, date, longitude)[0]
    print     "  Transit time: ", ut
    mjd = dateStringToMJD(ut, verbose=False)
    if observatory == 'ALMA':
        print "    Chile time: ", mjdToChileTime(mjd)
    elif observatory == 'VLA':
        print " Mountain time: ", mjdToMountainTime(mjd)
    return ut

def computeAzElFromRADecDate(raDec, date, observatory='ALMA', verbose=False, 
                             degrees=True):
    """
    Computes the az/el for a specified J2000 RA/Dec, date and observatory using
    the CASA measures tool.
    Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                    or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                    or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
                    or 2011-10-15_05:00:00
    observatory: ALMA, VLA, SMA, etc.
    """
    mjd = dateStringToMJD(date)
    return computeAzElFromRADecMJD(raDec, mjd, observatory, verbose, degrees)

def computeAzElFromRADecMJD(raDec, mjd, observatory='ALMA', verbose=False, 
                            degrees=False, frame='AZEL', 
                            forcePositiveAzim=False):
    """
    Computes the az/el for a specified J2000 RA/Dec, MJD and observatory using
    the CASA measures tool.

    raDec must either be a tuple in radians: [ra,dec],
        or a string of the form "hh:mm:ss.sss -dd:mm:ss.ss"
    mjd must either be in days, or a date string of the form:
               2011/10/15 05:00:00  or   2011/10/15-05:00:00
            or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
    observatory: must be either a name recognized by the CASA me tool, or a JPL Horizons
                 ID listed in the JPL_HORIZONS_ID dictionary at the top of this module.
    degrees: if False, returns Az,El in radians;  otherwise degrees
    frame: 'AZEL' or 'AZELGEO'
    - Todd Hunter
    """
    if (observatory == 'MAUNAKEA'):
        # Convert from a value known to JPL Horizons to a value known to CASA
        observatory = 'SMA'
    elif (observatory in JPL_HORIZONS_ID.values()):
        observatory = JPL_HORIZONS_ID.keys()[JPL_HORIZONS_ID.values().index(str(observatory))]
    if (observatory.lower().find('geo') == 0):
        observatory = 'geo'
    me = createCasaTool(metool)
    if (type(raDec) == str):
        # Then assume it is of the format "hh:mm:ss.sss -dd:mm:ss.ss"
        tokens = raDec.split()
        if (len(tokens) < 2):
            tokens = raDec.split(',')
            if (len(tokens) < 2):
                print "If you give a string, it must be of the format: hh:mm:ss.sss -dd:mm:ss.ss"
                return
        raDec = radec2rad(raDec)
        if (verbose):
            print "RA Dec in radians = ", raDec
    if (type(mjd) == str):
        mjd = dateStringToMJD(mjd)
        if (mjd is None):
            print "Invalid date string"
            return
        print "MJD = ", mjd
    mydir = me.direction('J2000', qa.quantity(raDec[0],'rad'), qa.quantity(raDec[1],'rad'))
    me.doframe(me.epoch('mjd', qa.quantity(mjd, 'd')))
    if observatory != 'geo':
        if verbose: 
            print "Calling me.observatory(%s)" % (observatory)
        me.doframe(me.observatory(observatory))
    else:
        if verbose: 
            print "Calling me.position('ITRF',0m,0m,0m)"
        geo = me.position('ITRF',qa.quantity([0],'m'),qa.quantity([0],'m'),qa.quantity([0],'m'))
        me.doframe(geo)
    myazel = me.measure(mydir,frame)
    myaz = myazel['m0']['value']
    myel = myazel['m1']['value']
    if (forcePositiveAzim and myaz < 0):
        myaz += 2*np.pi
    if (verbose):
        print "%s: Azim = %.6f deg   Elev = %.6f deg" % (observatory, myaz*180/np.pi, myel*180/np.pi)
    if (degrees):
        myaz *= 180/np.pi
        myel *= 180/np.pi
    return([myaz,myel])

def mjdToLocalTime(mjd, tz):
    """
    Converts an MJD to a local time as a datetime structure.
    tz: a string (See http://stackoverflow.com/questions/13866926/python-pytz-list-of-timezones)
    Examples: 'US/Eastern', 'US/Mountain', 'US/Hawaii', 'Chile/Continental'
    -Todd Hunter
    """
    utc = mjdListToDateTime([float(mjd)])[0]
    utc_dt = pytz.utc.localize(utc)
    local_dt = utc_dt.astimezone(pytz.timezone(tz))
    return(local_dt)
    
def mjdToChileTime(mjd=None):
    """
    Converts an MJD to Chile/Continental time as a datetime structure. 
    Default = now.
    -Todd Hunter
    """
    if (mjd==None): mjd=getMJD()
    localtime = mjdToLocalTime(float(mjd), 'Chile/Continental')
    if (mjd >= 57137 and mjd < 57523):  
        # as of 2015-04-26, no longer going back from -3h
        # but repealed before the change that happened on 2016-05-15
        localtime = mjdToLocalTime(float(mjd), 'America/Buenos_Aires')
    return(localtime)

def mjdToMountainTime(mjd):
    """
    Converts an MJD to US Mountain time as a datetime structure.  Default = now.
    -Todd Hunter
    """
    if (mjd==None): mjd=getMJD()
    return(mjdToLocalTime(float(mjd), 'US/Mountain'))

def mjdToEasternTime(mjd):
    """
    Converts an MJD to US Eastern time as a datetime structure.  Default = now.
    -Todd Hunter
    """
    if (mjd==None): mjd=getMJD()
    return(mjdToLocalTime(float(mjd), 'US/Eastern'))

def hoursToHM(hours):
    """
    Converts decimal hours into HH:MM.  See also hoursToHMS and hmsToHours.
    Todd Hunter
    """
    h,m,s = hoursToHMS(hours).split(':')
    return('%02d:%02d'%(int(h),int(m)))
    
def hoursToHMS(hours, prec=3):
    """
    Converts decimal hours (or a list of hours) into HH:MM:SS.    See also hmsToHours.
    Todd Hunter
    """
    if (type(hours) != list and type(hours) != np.ndarray):
        hrs = [hours]
    else:
        hrs = hours
    mystring = []
    for h in hrs:
        minutes = int(60*(h-int(h)))
        seconds = 3600*(h-int(h)-minutes/60.)
        mystring.append('%02d:%02d:%02.*f' % (int(h), minutes, prec, seconds))
    if (type(hours) != list and type(hours) != np.ndarray):
        mystring = mystring[0]
    return(mystring)
        
def hmsToDegrees(hms, delimiter=':'):
    """
    Convert RA string into floating point degrees. Uses 15*hmsToHours(hms)
    -Todd Hunter
    """
    return 15*hmsToHours(hms, delimiter)

def hmsToHours(hms, delimiter=':'):
    """
    Converts string (or list of strings) of "HH", "HH:MM", "HH:MM:SS" or
    "HH:MM:SS.S" (with any number of trailing digits) into
    floating point hours.  Also works for converting dmsToDegrees.  
    If delimiter is not found in dms, then if there is more than one '.' in 
    dms, it will automatically set delimiter to '.'; otherwise, set it to ' '.
    See also hoursToHMS.
    -Todd Hunter
    """
    if delimiter not in hms:
        if hms.count('.')>1:
            delimiter = '.'
        else:
            delimiter = ' '
    if (type(hms) == str):
        h = [hms]
    else:
        h = hms
    hours = []
    for x in h:
        myhours = sum(abs(float(t)) * 60 ** (2-i) for i,t in enumerate(x.split(delimiter)[:3]))/3600.
        if x.count(delimiter) >= 3:
            myhours += float('0.'+x.split(delimiter)[3])/3600.
        else:
            print "x.count('%s') = %d" % (delimiter, x.count(delimiter))
        if (x.find('-')>=0):
            myhours = -myhours
        hours.append(myhours)
    if (type(hms) == str):
        hours = hours[0]
    return(hours)
        
def dmsToDegrees(dms, delimiter=':'):
    """
    Converts string (or list of strings) of "DD", "DD:MM", "DD:MM:SS" or
    "DD:MM:SS.S" (with any number of trailing digits) into
    floating point degrees.  Note that it simply calls au.hmsToHours().
    If delimiter is not found in dms, then if there is more than one '.' in 
    dms, it will automatically set delimiter to '.'; otherwise, set it to ' '.
    -Todd Hunter
    """
    if delimiter not in dms:
        if dms.count('.')>1:
            delimiter = '.'
        else:
            delimiter = ' '
    return hmsToHours(dms, delimiter)
        
def computeLSTForElevation(elevation, radec=None, date='', mjd=0, observatory='ALMA',
                           intervalMinutes=5, vis=None, field=None, useJPL=False):
    """
    Computes the LST that an object passes the specified elevation at the specified
    observatory.
    -Todd Hunter
    """
    value = computeUTForElevation(elevation, radec, date, mjd, observatory,
                                  intervalMinutes, vis, field, useJPL)
    if (value == [] or value is None): return
    riseTime, setTime = value
    riseLST = ComputeLST(riseTime, longitude=getObservatoryLatLong(observatory)[1][0])
    setLST = ComputeLST(setTime, longitude=getObservatoryLatLong(observatory)[1][0])
    print "LST of rise = %f = %s" % (riseLST, hoursToHMS(riseLST,prec=0))
    print "LST of set  = %f = %s" % (setLST, hoursToHMS(setLST,prec=0))
    return(riseLST, setLST)

def getUT():
    """
    Returns the current UT in hours.
    """
    return(mjdVectorToUTHours(getMJD()))

def computeUTForElevation(elevation, radec=None, date='', mjd=0,
                          observatory='ALMA',
                          intervalMinutes=15, vis=None, field=None,
                          useJPL=False, verbose=True,
                          finestSearch=1.0):
    """
    For a specified RA/Dec, date/MJD, and elevation, compute the UT time that the
    object will cross that point.
    raDec must either be a tuple in radians: [ra,dec],
        or a string of the form: hh:mm:ss.sss -dd:mm:ss.ss
    mjd: modified Julian date (optional, default = today)
    date: string date (optional)
        Either of these formats is valid: 2011/10/15, 2011-10-15
    The time portion is optional.
    elevation: in degrees
    observatory: location to run the calculation for
    intervalMinutes: initial grid size to use in the search
    finestSearch: final grid to use (in minutes)
    vis: the measurement set from which to read the field coordinates
    field: the field ID or name in the measurement set to use, or name of a planet
            if a planet, then find its position on the specified date (or today)
    useJPL: if True, query JPL Horizons for planets instead of casa ephemerides
    Returns:
    [riseTime,setTime] as MJD seconds
    -Todd Hunter
    """
#    startTime = timeUtilities.time()
    mindiffRising = 1e9
    mindiffSetting = 1e9
    if (mjd==0 and date==''):
        mjd = getMJD()
    elif (date != ''):
        mjd = dateStringToMJD(date, verbose=False)
    previousEl = None
    if (radec is None):
        if (vis==None and field is None):
            print "You must specify either radec, field or (vis and field)"
            return
        if (field is None):
            print "If you specify vis, then you must also specify field ID or field name."
            return
        if (vis is None):
            print "Since vis has not been specified, I will assume that %s is a planet." % (field)
            radec = planet(field,mjd=mjd,useJPL=useJPL)['directionRadians']
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            try:
                field = int(field)
                fieldname = mymsmd.namesforfields(field)[0]
            except:
                fieldname = field
                if (fieldname not in mymsmd.namesforfields()):
                    print "%s is not in the measurement set" % (fieldname)
                    return
                field = mymsmd.fieldsforname(field)[0]
            mymsmd.close()
            myms = createCasaTool(mstool)
            myms.open(vis)
            radec = direction2radec(myms.getfielddirmeas(fieldid=field))
            myms.close()
            print "Got field %d = %s at %s" % (field,fieldname,radec)
    for m in np.arange(mjd, mjd+1, intervalMinutes/1440.):
        az,el = computeAzElFromRADecMJD(radec, m, observatory, verbose=False)
        diff = abs(elevation-np.degrees(el))
        if (previousEl is not None):
            if (el > previousEl):
                if (diff < mindiffRising):
                    mindiffRising = diff
                    mjdAtMinDiffRising = m
            else:
                if (diff < mindiffSetting):
                    mindiffSetting = diff
                    mjdAtMinDiffSetting = m
        previousEl = el
    if (mindiffRising < finestSearch): # degrees
        # Now find a rising value accurate to 1 minute
        mindiffRising = 1e9
        previousEl = np.pi
        for m in np.arange(mjdAtMinDiffRising-(finestSearch+0.5*intervalMinutes)/1440.,
                           mjdAtMinDiffRising+(finestSearch+0.5*intervalMinutes)/1440., 1.0/1440.):
            az,el = computeAzElFromRADecMJD(radec, m, observatory, verbose=False)
            diff = abs(elevation-np.degrees(el))
            if (previousEl < np.pi):
                if (el > previousEl):
                    if (diff < mindiffRising):
                        mindiffRising = diff
                        mjdAtMinDiffRising = m
            previousEl = el
        # Now find a setting value accurate to 1 minute
        mindiffSetting = 1e9
        previousEl = np.pi
        for m in np.arange(mjdAtMinDiffSetting-(finestSearch+0.5*intervalMinutes)/1440.,
                           mjdAtMinDiffSetting+(finestSearch+0.5*intervalMinutes)/1440., finestSearch/1440.):
            az,el = computeAzElFromRADecMJD(radec, m, observatory, verbose=False)
            diff = abs(elevation-np.degrees(el))
            if (previousEl < np.pi):
                if (el < previousEl):
                    if (diff < mindiffSetting):
                        mindiffSetting = diff
                        mjdAtMinDiffSetting = m
            previousEl = el

        if (observatory == 'ALMA'):
            local_dt = mjdToChileTime(mjdAtMinDiffRising)
            localrise = " = %s Chile time" % (local_dt.strftime('%H:%M'))
            local_dt = mjdToChileTime(mjdAtMinDiffSetting)
            localset = " = %s Chile time" % (local_dt.strftime('%H:%M'))
        elif (observatory.find('VLA') >= 0):
            local_dt = mjdToMountainTime(mjdAtMinDiffRising)
            localrise = " = %s Mountain time" % (local_dt.strftime('%H:%M'))
            local_dt = mjdToMountainTime(mjdAtMinDiffSetting)
            localset = " = %s Mountain time" % (local_dt.strftime('%H:%M'))
        elif (observatory.find('GBT') >= 0):
            local_dt = mjdToEasternTime(mjdAtMinDiffRising)
            localrise = " = %s Eastern time" % (local_dt.strftime('%H:%M'))
            local_dt = mjdToEasternTime(mjdAtMinDiffSetting)
            localset = " = %s Eastern time" % (local_dt.strftime('%H:%M'))
        else:
            localrise = ''
            localset = ''
        riseTime = mjdsecToUTHM(mjdAtMinDiffRising*86400)
        setTime = mjdsecToUTHM(mjdAtMinDiffSetting*86400)
        if verbose:
            print " rising: %s UT %s" % (riseTime, localrise)
            print "setting: %s UT %s" % (setTime, localset)
                
        return([mjdAtMinDiffRising*86400, mjdAtMinDiffSetting*86400])
    else:
        print "mindiffRising = ", mindiffRising
        maxElevation = 90-abs(radec2deg(radec)[1] - getObservatoryLatLong(observatory)[0])
        if (maxElevation < elevation):
            print "Object never crosses that elevation.  Highest = %f deg" % (maxElevation)
        else:
            print "maxElevation=%f >= el=%f" % (maxElevation,elevation)
            print "Object does not remain above that elevation for more than %d minutes." % (intervalMinutes)
        return([])
    
def nutation(radec=None, mjdsec=None, vis=None, fieldId=None):
    """
    Computes the effect of nutation on celestial equatorial coordinates, based on the formula
    of Hohenkerek et al. 1992 (see Rick Fisher's home page), which is good to about an arc
    second.
    inputs:
       radec: a tubple in radians or a sexagesimal string ('hh:mm:ss.s +dd:mm:ss.s')
       mjdsec: time in MJD seconds (default = now)
    returns:
       deltaRa and deltaDec in arc seconds
    -Todd Hunter
    """
    if (radec is not None):
        if (type(radec) == str):
            ra,dec = radec2rad(radec)
            radec = [ra,dec]
        if (mjdsec is None):
            mjdsec = getCurrentMJDSec()
    elif (vis is None):
        print "You must either give radec or vis+fieldId"
        return
    else:
        radec = getRADecForField(vis, fieldId, usemstool=True)
        ra = radec[0][0]
        dec = radec[1][0]
        radec = [ra,dec]
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        mjdsec = np.mean(mymsmd.timesforfield(fieldId))
        mymsmd.close()

    d = mjdToJD(mjdsec/86400) - 2451545.0
    dL = -17.3 * np.sin((125.0 - 0.5295*d)*np.pi/180.) - 1.4*np.sin((200.0 + 1.97129*d)*np.pi/180.)
    dE = 9.4 * np.cos((125-0.05295*d)*np.pi/180) + 0.7*np.cos((200.0 + 1.97129*d)*np.pi/180.)
    dRA = (0.9175 + 0.3978*np.sin(radec[0])*np.tan(radec[1]))*dL - np.cos(radec[0])*np.tan(radec[1])*dE
    dDec = 0.3978*np.cos(radec[0])*dL + np.sin(radec[0])*dE
    return([dRA, dDec])
                        
def refraction(elevationDegrees, pressure=563, temperature=273, RH=20):
    """
    Computes the radio refraction angle in arc seconds,
    using the formula of Ulich (1981) and Brussaard & Watson (1995).
    Should add the formulae from CSV-2934 once it is resolved.
    Inputs:
    elevationDegrees: in degrees
    temperature: in Kelvin
    pressure: in mbar
    RH: in percentage
    -Todd Hunter
    """
    Pdry = pressure
    T = temperature
    esat = 6.105*np.exp(25.22*(T-273)/T - 5.31*np.log(T/273))
    Pw = 0.01*RH/esat
    elev = elevationDegrees*np.pi/180
    f = np.cos(elev)/(np.sin(elev) + 0.00175*np.tan(87.5-elev))
    Ro = 16.01*Pdry/T - 1.15*Pw/T + (7.734937e4)*Pw/(T**2)
    Rsec = Ro*f
    return(Rsec)

def computeRADecFromAzElUnixtime(filename, outname=None, timeColumn=1,
                                 azimuthColumn=2, elevationColumn=3,
                                 observatory='ALMA', cofa=''):
    """
    Reads an ASCII file with unixtime, azimuth and elevation as columns
    and produces a new file with UT, right ascension, hour angle and
    declination.
    timeColumn: the column number containing time (columns start at zero)
                in unix time (seconds since 1970)
    azimuthColumn: the column number containing azimuth in degrees
    elevationColumn: the column number containing elevation in degrees
    observatory: the name of the observatory for the azimuth, elevation values.
                 Must be either a name recognized by the CASA me tool, or a
                 JPL Horizons ID listed in the JPL_HORIZONS_ID dictionary at
                 the top of this module.
    cofa: if specifed as [x,y,z], use this ITRF position as array center
    - Todd Hunter
    """
    f = open(filename,"r")
    if (outname is None):
        outname = filename + ".radec"
    o = open(outname,'w')
    unixtime = []
    azimuth = []
    elevation = []
    ra = []
    dec = []
    o.write('# Minutes  UnixTime(sec)  Az(degree) El(degree)  MJD  UT(hrs)  RA(hours) Dec(degree) HA(hours)\n')
    [latitude, longitude, obs] = getObservatoryLatLong(observatory)  
    for line in f.readlines():
        tokens = line.split()
        if (len(tokens) < max([timeColumn,azimuthColumn,elevationColumn])):
            continue
        unixtime.append(float(tokens[timeColumn]))
        azimuth.append(float(tokens[azimuthColumn])*np.pi/180.)
        elevation.append(float(tokens[elevationColumn])*np.pi/180.)
        mjd = jdToMJD(ComputeJulianDayFromUnixTime(unixtime[-1]))
        ut = 24*(mjd-np.floor(mjd))
        LST = ComputeLST(mjd*86400, longitude)
        a,b = computeRADecFromAzElMJD([azimuth[-1], elevation[-1]],
                                      mjd, observatory=observatory,
                                      verbose=False, cofa=cofa)
        ra.append(a*12/np.pi)
        dec.append(b*180/np.pi)
        hourAngle = LST-ra[-1]
        if (hourAngle > 12): hourAngle -= 24
        o.write(line[:-1] + ' %.4f %.4f %.6f %.6f %.4f\n'%(mjd,ut,ra[-1],dec[-1],hourAngle))
    f.close()
    o.close()
    if (len(unixtime) < 1):
        print "No data found in file"
        return
    print "Results left in file = ", outname

def hourAngleForField(vis, field, verbose=True):
    """
    Computes the range of hour angles for a specified field
    in a measurement set.   - Todd Hunter
    vis: measurement set
    field: field ID or string name
    verbose: if True, then print the derived time range
    Returns: a dictionary of hour angles (in hours),
       keyed by 'min', 'max', and 'mean'
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (type(field) == str):
        if (field.isdigit()):
            field = int(field)
        else:
            fields = mymsmd.fieldsforname(field)
            field = fields[0]
            if (len(fields) > 1):
                print "This source has multiple fields. Picking first one: %d." % (field)
    nfields = mymsmd.nfields()
    if (field < 0 or field >= nfields):
        print "Invalid field ID.  There are only %d fields in ms." % (nfields)
        return
    direction = getRADecForField(vis, field, usemstool=True, forcePositiveRA=True)
    mjd = mymsmd.timesforfield(field) / 86400.
    minmjd = np.min(mjd)
    meanmjd = np.mean(mjd)
    maxmjd = np.max(mjd)
    minLST = ComputeLST(minmjd*86400, observatory=getObservatoryName(vis))
    maxLST = ComputeLST(maxmjd*86400, observatory=getObservatoryName(vis))
    minHourAngle = minLST - direction[0][0]*12/np.pi
    maxHourAngle = maxLST - direction[0][0]*12/np.pi
    mydict = {'min': minHourAngle, 'max': maxHourAngle, 
              'mean': 0.5*(minHourAngle+maxHourAngle)}
    return(mydict)

def getFeedTableTimes(vis, subtractValue=0):
    """
    Prints the unique values in the TIME column of the FEED table of a measurement set.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    feed = vis + '/FEED'
    if (not os.path.exists(feed)):
        print "Could not find FEED table."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(feed)
    times = np.unique(mytb.getcol('TIME')) - subtractValue
    mytb.close()
    for t in times:
        print "%f = %s" % (t, mjdSecondsToMJDandUT(t))
    return(times)

def fixFeedTableTimes(vis):
    """
    Copies the time in the first row of a FEED table to all rows.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    feed = vis + '/FEED'
    if (not os.path.exists(feed)):
        print "Could not find FEED table."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(feed, nomodify=False)
    times = mytb.getcol('TIME')
    times = times[0] * np.ones(len(times))
    mytb.putcol('TIME',times)
    print "Wrote %f to all rows" % (times[0])
    mytb.close()

def fixReceptorAngles(vis, antenna='', angles=[]):
    """
    In the FEED table of the specified measurement set, replace RECEPTOR_ANGLEs 
    of [0,90] with the specified value, or the median of all the non-[0,90] values.
    antenna: limit any changes to the specified antenna list (ID or name)
    angles: if specified, use this tuple as the new feed angle [X,Y]
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (angles == []):
        angles = receptorAngles(vis, verbose=False)
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FEED', nomodify=False)
    currentAngles = np.transpose(mytb.getcol('RECEPTOR_ANGLE'))
    antennaIDs = mytb.getcol('ANTENNA_ID')
    uniqueAntennaIDs = np.unique(antennaIDs)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antennaNames = mymsmd.antennanames(uniqueAntennaIDs)
    mymsmd.close()
    antennaIDsToFix = parseAntenna(vis, antenna)
    if (antennaIDsToFix is None): return
    fixed = 0
    for i,a in enumerate(antennaIDs):
        if (currentAngles[i][0] == 0 and currentAngles[i][1] == 90):
            if (antenna == '' or a in antennaIDsToFix):
                currentAngles[i][0] = angles[0]
                currentAngles[i][1] = angles[1]
                fixed += 1
    mytb.putcol('RECEPTOR_ANGLE', np.transpose(currentAngles))
    mytb.close()
    print "Fixed %d rows" % (fixed)

def dropZeroNinety(angles):
    """
    Takes a list of N feed angles (of shape = 2, N), and returns the index of 
    entries that are not [0,90] and not [0,pi/2].  Called by receptorAngles.
    -Todd Hunter
    """
    t_angles = np.transpose(angles)
    idx1 = np.where(angles[0] == 0.0)[0]
    idx2 = np.where(angles[1] == 90.0)[0]
    idx3 = np.where(angles[1] == pi/2.0)[0]
    idxA = np.intersect1d(idx1,idx2)
    idxB = np.intersect1d(idx1,idx3)
    idx = np.union1d(idxA,idxB)
    nondefault = np.ones(len(t_angles))
    nondefault[idx] = 0
    idx = np.where(nondefault == 1)[0]
    return(idx)

def receptorAngles(vis, verbose=True):
    """
    Reads and prints the RECEPTOR_ANGLE column of the FEED table of a
    measurement set.  Returns the median value as an array of 2 values,
    unless that median is [0,90] or [0,pi/2] in which case it
    returns None.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    if (not os.path.exists(vis+'/FEED')):
        print "Could not find FEED table.  Is this a measurement set?"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FEED')
    angles = mytb.getcol('RECEPTOR_ANGLE')
    t_angles = np.transpose(angles)
    antennaIDs = mytb.getcol('ANTENNA_ID')
    uniqueAntennaIDs = np.unique(antennaIDs)
    mytb.close()
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antennaNames = mymsmd.antennanames(uniqueAntennaIDs)
    mymsmd.close()
    if verbose:
        print "Antenna Receptor_angle (= converted to degrees)"
    for a in uniqueAntennaIDs:
        idx = np.where(antennaIDs == a)[0]
        a_angles = t_angles[idx]
        angle = np.unique(a_angles)
        degrees = np.degrees(angle)
        if verbose:
            print "%2d %4s %s ( = %s)" % (a,antennaNames[a],angle, degrees)
    idx = dropZeroNinety(angles)
    if (len(idx) < 1):
        print "All values are default, so you need to set the angles parameter."
        return(None)
    medianValue = np.median(t_angles[idx], axis=0)
    return(medianValue)

def parallacticAngleForField(vis, field, verbose=True):
    """
    Computes the range of parallactic angles for a specified field
    in a measurement set.   - Todd Hunter
    vis: measurement set
    field: field ID or string name
    verbose: if True, then print the derived time range
    Returns: a dictionary of parallactic angles (in degrees),
       keyed by 'min', 'max', 'mean', and 'range'
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (type(field) == str):
        if (field.isdigit()):
            field = int(field)
        else:
            fields = mymsmd.fieldsforname(field)
            field = fields[0]
            if (len(fields) > 1):
                print "This source has multiple fields. Picking first one: %d." % (field)
    nfields = mymsmd.nfields()
    if (field < 0 or field >= nfields):
        print "Invalid field ID.  There are only %d fields in ms." % (nfields)
        return
    direction = getRADecForField(vis, field, usemstool=True, forcePositiveRA=True)
    mjd = mymsmd.timesforfield(field) / 86400.
    minmjd = np.min(mjd)
    meanmjd = np.mean(mjd)
    maxmjd = np.max(mjd)
    if verbose:
        print "MJD: %f-%f = %s-%s UT" % (minmjd, maxmjd, 
                                         mjdToUT(minmjd).split()[1],
                                         mjdToUT(maxmjd).split()[1])
    mymsmd.close()
    myme = createCasaTool(metool)
    mydir = myme.direction('J2000',qa.quantity(direction[0],'rad'), 
                         qa.quantity(direction[1],'rad'))
    hadec_pole = myme.direction('J2000', '0deg', '+90deg')
    myme.doframe(myme.observatory(getObservatoryName(vis)))
    myme.doframe(myme.epoch('mjd', qa.quantity(minmjd,'d')))
    mydir_azel = myme.measure(mydir, 'AZEL')
    hadec_pole_azel = myme.measure(hadec_pole, 'AZEL')
    minParAngle = headerToDegree(myme.posangle(mydir_azel, hadec_pole_azel))
    myme.doframe(myme.epoch('mjd', qa.quantity(maxmjd,'d')))
    mydir_azel = myme.measure(mydir, 'AZEL')
    maxParAngle = headerToDegree(myme.posangle(mydir_azel, hadec_pole_azel))
    myme.doframe(myme.epoch('mjd', qa.quantity(meanmjd,'d')))
    mydir_azel = myme.measure(mydir, 'AZEL')
    # The pole does not move very much, but may as well recompute it.
    hadec_pole_azel = myme.measure(hadec_pole, 'AZEL')
    meanParAngle = headerToDegree(myme.posangle(mydir_azel, hadec_pole_azel))
    myme.done()
    parAngleRange = maxParAngle-minParAngle
    if (parAngleRange > 180):
        parAngleRange = 360-parAngleRange
    mydict = {'min': minParAngle, 'mean': meanParAngle, 'max': maxParAngle, 'range': parAngleRange}
    return(mydict)

def J2000ToICRSgrid(ra_inc=0.5, dec_inc=5, separation=5.0):
    """
    Computes a grid of conversions and provides statistics.
    ra_inc: increment of RA grid in hours
    dec_inc: increment of Dec grid in degrees
    separation: angle to calibrator (at random p.a.) for computing diff
    -Todd Hunter
    """
    mas = []
    delta = []
    for ra in np.arange(0,24,ra_inc):
        for dec in np.arange(-90,90,dec_inc):
            radec = hours2radec(ra,dec, verbose=False)
            icrs = J2000ToICRS(radec, verbose=False)
            mas1 = angularSeparationOfStrings(radec, icrs, verbose=False) * 3600000 # deg2mas
            mas.append(mas1)
            pa = 2*np.pi*random.random()
            delta_ra = separation*np.cos(pa)/(15.0/np.cos(np.radians(dec)))  # hours
            delta_dec = separation*np.sin(pa)
            radec2 = hours2radec(ra+delta_ra,dec+delta_dec, verbose=False)
            icrs2 = J2000ToICRS(radec2, verbose=False)
            mas2 = angularSeparationOfStrings(radec2, icrs2, verbose=False) * 3600000 # deg2mas
            delta.append(np.abs(mas1-mas2))
    print "Grid of %d directions: Max=%f, Min=%f, Median=%f, Mean=%f mas" % (len(mas),np.max(mas),np.min(mas),np.median(mas),np.mean(mas))
    print "Deltas for %.1f deg offset: Max=%f, Min=%f, Median=%f, Mean=%f mas" % (separation,np.max(delta),np.min(delta),np.median(delta),np.mean(delta))
    
def J2000ToICRS(radec, date='', verbose=True):
    """
    Converts a direction from J2000 to ICRS and computes the angular separation.
    radec: sexagesimal string format
    date: optional -- CASA shows no date dependence in this calculation!
      Any of these formats is valid: 2011/10/15 05:00:00
    (The time portion is optional.)  2011/10/15-05:00:00
                                     2011-10-15 05:00:00
                                     2011-10-15T05:00:00
                                     2011-Oct-15T05:00:00
    -Todd Hunter
    """
    if (not radec[0].isdigit()):
        print "radec parameter must be a sexagesimal string.  Maybe you want au.imageHeaderToICRS?"
        return
    direction = radec2rad(radec)
    myme = createCasaTool(metool)
    mjd = dateStringToMJD(date, verbose=False)
    myme.doframe(myme.epoch('mjd', qa.quantity(mjd,'d')))
    mydir = myme.direction('J2000',qa.quantity(direction[0],'rad'), 
                           qa.quantity(direction[1],'rad'))
    mydir_icrs = myme.measure(mydir, 'ICRS')
    newradec = direction2radec(mydir_icrs)
    sep = angularSeparationOfStrings(radec, newradec, verbose=verbose)
    return(newradec)

def ICRSToJ2000(radec, date='', verbose=True):
    """
    Converts a direction from ICRS to J2000 and computes the angular separation.
    radec: sexagesimal string format
    date: optional -- CASA shows no date dependence in this calculation!
      Any of these formats is valid: 2011/10/15 05:00:00
    (The time portion is optional.)  2011/10/15-05:00:00
                                     2011-10-15 05:00:00
                                     2011-10-15T05:00:00
                                     2011-Oct-15T05:00:00
    -Todd Hunter
    """
    if (not radec[0].isdigit()):
        print "radec parameter must be a sexagesimal string.  Maybe you want au.imageHeaderToJ2000?"
        return
    direction = radec2rad(radec)  # convert sexagesimal to radians
    myme = createCasaTool(metool)
    mydir = myme.direction('ICRS',qa.quantity(direction[0],'rad'), 
                           qa.quantity(direction[1],'rad'))
    mjd = dateStringToMJD(date, verbose=False)
    myme.doframe(myme.epoch('mjd', qa.quantity(mjd,'d')))
    mydir_icrs = myme.measure(mydir, 'J2000')
    newradec = direction2radec(mydir_icrs)  # convert direction object to sexagesimal
    sep = angularSeparationOfStrings(radec, newradec, verbose=verbose)
    return(newradec)

def imageHeaderToJ2000(img, outfile='', overwrite=True):
    """
    Uses imhead to set the equinox in a CASA image to J2000.  It sets the header value
    as well as: ia.torecord()['coordsys']['coordsys']['direction0']['conversionSystem']
    outfile: if set, then first copy the image to this name (True=<img>.J2000.image)
    Returns: name of new image
    -Todd Hunter
    """
    if not os.path.exists(img):
        print "Could not find image"
        return
    if outfile != '':
        if outfile==True:
            outfile = img + '.J2000.image'
            outfile = outfile.replace('image.J2000','J2000').replace('ICRS','')
        if overwrite:
            removeImageIfPresent(outfile)
        else:
            print "outfile already exists.  Set overwrite=True to replace it."
            return
        shutil.copytree(img, outfile)
        img = outfile
    imhead(img, mode='put', hdkey='equinox', hdvalue='J2000')
    myia = iatool()
    myia.open(img)
    record = myia.torecord()
    if (record['coordsys']['coordsys']['direction0']['conversionSystem'] == 'J2000'):
        print "ia.torecord()['coordsys']['coordsys']['direction0']['conversionSystem'] is already J2000."
    else:
        record['coordsys']['coordsys']['direction0']['conversionSystem'] = 'J2000'
        myia.setcoordsys(record['coordsys'])
    myia.close()
    if outfile != '':
        return img

def imageHeaderToICRS(img, outfile='', overwrite=True):
    """
    Uses imhead to set the equinox in a CASA image to ICRS.  It sets the header value
    as well as: ia.torecord()['coordsys']['coordsys']['direction0']['conversionSystem']
    outfile: if set, then first copy the image to this name (True=<img>.J2000.image)
    Returns: name of new image
    -Todd Hunter
    """
    if not os.path.exists(img):
        print "Could not find image"
        return
    if outfile != '':
        if outfile==True:
            outfile = img + '.J2000.image'
            outfile = outfile.replace('image.J2000','J2000').replace('ICRS','')
        if overwrite:
            removeImageIfPresent(outfile)
        else:
            print "outfile already exists.  Set overwrite=True to replace it."
        shutil.copytree(img, outfile)
        img = outfile
    imhead(img, mode='put', hdkey='equinox', hdvalue='ICRS')
    myia = iatool()
    myia.open(img)
    record = myia.torecord()
    if (record['coordsys']['coordsys']['direction0']['conversionSystem'] == 'ICRS'):
        print "ia.torecord()['coordsys']['coordsys']['direction0']['conversionSystem'] is already ICRS."
    else:
        record['coordsys']['coordsys']['direction0']['conversionSystem'] = 'ICRS'
        myia.setcoordsys(record['coordsys'])
    myia.close()
    if outfile != '':
        return img

def plotParallacticAngle(radec, mjd=None, date=None, observatory='ALMA',
                         incrementMinutes=3.0, xaxis='lst', haRange=None,
                         lstRange=None, verbose=True):
    """
    Plot the parallactic angle track of a source vs. MJD or LST.
    radec: a sexagesimal string or a float list: [raRad, decRad]
    mjd: MJD to use 
    date: date/time string to use   
    xaxis: 'mjd', 'lst', or 'ut'
    haRange: if specified, then limit the hour angle to specified range
    lstRange: if specified, then limit the hour angle to specified range
    If no date is specified, it uses the current date/time.
    -Todd Hunter
    """
    if (mjd is None and date is None):
        print "No date/time given.  Assuming current time."
        mjd = getMJD()
    elif (mjd is None):
        if (type(date) != str):
            print "The date argument must be a string."
            return
        mjd = dateStringToMJD(date)
    hours = []  # since the start mjd specified (not the same as UT)
    parang = []
    lst = []  
    MJD = []
    for m in np.arange(mjd, mjd+1.0, incrementMinutes/1440.0):
        hours.append(24*(m-mjd))
        MJD.append(m)
        lst.append(ComputeLST(m*86400, observatory=observatory))
        parang.append(parallacticAngle(radec, mjd=m, observatory=observatory))
    pb.clf()
    lst = np.array(lst)
    parang = np.array(parang)
    hours = np.array(hours)
    MJD = np.array(MJD)
    if (haRange is not None or lstRange is not None):
        if (haRange is not None):
            if (type(haRange)==str):
                # support the string format: '-1.3~2.3'
                haRange = [float(i) for i in haRange.split('~')]
            if (type(radec) == str):
                raHours = radec2deg(radec)[0]/15.0
            else:
                raHours = np.degrees(radec[0])/15.0
            idx1 = np.where(lst-raHours >= haRange[0])[0]
            idx2 = np.where(lst-raHours <= haRange[1])[0]
        else:
            if (type(lstRange)==str):
                # support the string format: '17~19'
                lstRange = [float(i) for i in lstRange.split('~')]
            idx1 = np.where(lst >= lstRange[0])[0]
            idx2 = np.where(lst <= lstRange[1])[0]
        idx = np.intersect1d(idx1,idx2)
        lst = lst[idx]
        parang = parang[idx]
        MJD = MJD[idx]
        hours = hours[idx]
    lstRange = np.max(lst)-np.min(lst)
    parangRange1 = np.abs(parang[-1]-parang[0])
    if (lstRange > 12): lstRange = 24-lstRange
    if (parangRange1 > 180): parangRange1 = 360-parangRange1

    parangRange2 = np.max(parang) - np.min(parang)
    if (parangRange2 > 180): parangRange2 = 360-parangRange2
    parangRange = np.max([parangRange1,parangRange2])
    if verbose:
        print "LST range = %.1f hours, parallactic angle range = %f deg" % (lstRange,parangRange)
    adesc = pb.subplot(111)
    if (xaxis.lower() == 'lst'):
        pb.plot(lst, parang, 'k-')
        pb.xlabel('LST (hours)')
    elif (xaxis.lower() == 'ut'):
        ut = mjdVectorToUTHours(MJD)
        pb.plot(ut, parang, 'k-')
        datestring = mjdToUT(mjd).split()[0]
        pb.xlabel('UT (hours) on MJD=%g (%s)' % (mjd,datestring))
    else:
        pb.plot(hours, parang, 'k-')
        pb.xlabel('Time since MJD=%g (hours)' % (mjd))
    pb.ylabel('Parallactic angle at %s (deg)' % (observatory))
    if (haRange is not None or lstRange is not None):
        pb.title('Direction = %s,  parang range = %.1f deg' % (str(radec), parangRange))
    else:
        pb.title('Direction = %s' % str(radec))
    adesc.xaxis.grid(True,which='major')
    adesc.yaxis.grid(True,which='major')
    if (date is None):
        png = 'parang.%g.png' % (mjd)
    else:
        png = 'parang.%s.png' % (date)
    pb.savefig(png)
    if verbose:
        print "Plot left in ", png
    return parangRange

def parallacticAngle(radec, mjd=None, date=None, observatory='ALMA'):
    """
    Compute the instantaneous parallactic angle for a given RA/Dec.
    radec: a hexagesimal string, or list of floats: [RArad, Decrad]
    observatory: name of telescope (from CASA database)
    mjd: MJD to use 
    date: date/time string to use   
    If no date is specified, it uses the current date/time.
    Returns: value in degrees
    -Todd Hunter
    """
    if (mjd is None and date is None):
        print "No date/time given.  Assuming current time."
        mjd = getMJD()
    elif (mjd is None):
        if (type(date) != str):
            print "The date argument must be a string."
            return
        mjd = dateStringToMJD(date)
    myme = createCasaTool(metool)
    hadec_pole = myme.direction('J2000', '0deg', '+90deg')
    if (type(radec) == str):
        radec = radec2rad(radec)
    elif (type(radec) != list):
        print "radec argument must be a string or [RArad, Decrad]"
        return
    mydir = myme.direction('J2000', str(radec[0])+'rad', str(radec[1])+'rad')
    myme.doframe(myme.epoch('mjd', qa.quantity(mjd,'d')))
    myme.doframe(myme.observatory(observatory))
    mydir_azel = myme.measure(mydir, 'AZEL')
    hadec_pole_azel = myme.measure(hadec_pole, 'AZEL')
    parang = headerToDegree(myme.posangle(mydir_azel, hadec_pole_azel))
    myme.done()
    return(parang)
    
def computeRADecFromAzElMJD(azel, mjd, observatory='ALMA', verbose=True,
                            my_metool=None, refractionCorrection=False,
                            nutationCorrection=False, frame='AZEL',cofa=''):
    """
    Computes the J2000 RA/Dec for a specified AZELGEO coordinate, MJD and
    observatory.

    azel must be a tuple or list in radians, e.g. [az,el]
    mjd must either be in days, or a date string of the form:
               2011/10/15 05:00:00  or   2011/10/15-05:00:00
            or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
    observatory: must be either a name recognized by the CASA me tool, or a
         JPL Horizons ID listed in the JPL_HORIZONS_ID dictionary at the top
         of this module.
    refractionCorrection: subtract the (positive) refractionCorrection to the
         elevation prior to conversion
    nutationCorrection: apply the nutation correction after conversion
    frame: 'AZEL' or 'AZELGEO'
    cofa: if specifed as [x,y,z], use this ITRF position as array center
    returns the [RA,Dec] in radians
    - Todd Hunter
    """
    if (observatory == 'MAUNAKEA'):
        # Convert from a value known to JPL Horizons to a value known to CASA"
        observatory = 'SMA'
    elif (observatory in JPL_HORIZONS_ID.values()):
        observatory = JPL_HORIZONS_ID.keys()[JPL_HORIZONS_ID.values().index(str(observatory))]
    myme = my_metool
    if (my_metool is None):
        myme = createCasaTool(metool)
    if (type(mjd) == str):
        mjd = dateStringToMJD(mjd)
        if (mjd is None):
            print "Invalid date string"
            return
        print "MJD = ", mjd
    if (refractionCorrection):
        azel[1] -= refraction(azel[1]*180/np.pi) / (180*3600/np.pi)
    mydir = myme.direction(frame, qa.quantity(azel[0],'rad'), qa.quantity(azel[1],'rad'))
    myme.doframe(myme.epoch('mjd', qa.quantity(mjd, 'd')))
    if cofa == '':
        myme.doframe(myme.observatory(observatory))
    else:
        myme.doframe(myme.position('ITRF',str(cofa[0])+'m',str(cofa[1])+'m',str(cofa[2])+'m'))
    myradec = myme.measure(mydir,'J2000')
    myra = myradec['m0']['value']
    if (myra < 0):
        myra += 2*np.pi
    mydec = myradec['m1']['value']
    if (nutationCorrection):
        dRA, dDec = nutation([myra,mydec], mjdsec=mjd*86400.)
        myra += dRA*np.pi/180./3600.
        mydec += dDec*np.pi/180./3600.
    if (verbose):
        print "RA = %.6f hr   Dec = %.6f deg" % (myra*12/np.pi, mydec*180/np.pi)
    if (my_metool is None):
        myme.done()
    return([myra,mydec])

def unnormalize(vis='',spwID='', scan='', state=None):
    """
    Multiply the cross-correlation spectra by the autocorrelation.
    Under development....
    -- T. Hunter
    """
    antenna1 = '0'
    antenna2 = '1'
    data = Visibility(vis,antenna1=antenna1, antenna2=antenna2,spwID=spwID,scan=scan,state=state, cross_auto_all='all')
    data.setAntennaPair(antenna1,antenna2)
    data.getAmpAndPhase()
    data.getSpectralData()
    print "shape(specFreq, amp)", np.shape(data.specFreq), np.shape(data.amp[0])
    pb.plot(1e-9*data.specFreq,data.amp[0])
    pb.title('Scan %d, Antennas %s-%s' % (scan,antenna1,antenna2))
    pb.xtitle('Freq (GHz)')
    pb.draw()

def analyzeWeights(vis='',antenna1='', antenna2='',scan=''):
    """
    Compares the SIGMA and WEIGHT for the first row of the table and
    checks if weight = 1/sigma**2.  If no arguments are specified, it
    uses the antenna numbers and scan number in the first row.
    -- T. Hunter
    """
    tb.open(vis)
    pol = 0
    if (antenna1==''):
        antenna1 = tb.getcol('ANTENNA1')[0]
    if (antenna2==''):
        antenna2 = tb.getcol('ANTENNA2')[0]
    if (scan==''):
        scan = tb.getcol('SCAN_NUMBER')[0]
    queryString = "ANTENNA1==%d AND ANTENNA2==%d AND SCAN_NUMBER==%d"%(int(antenna1),int(antenna2),int(scan))
    print "Checking first row with %s." % (queryString)
    subtable = tb.query(queryString)
    npols = len(subtable.getcol('SIGMA')[:,0])
    for pol in range(npols):
      weight = subtable.getcol('WEIGHT')[pol][0]
      sigma = subtable.getcol('SIGMA')[pol][0]
      product = sigma*math.sqrt(weight)
      if (abs(product -1) > 1e-5):
        print "Pol%d: The weights differ from the 1/sigma**2 by a factor of %g." % (pol, product)
      else:
        print "Pol%d: The weights are equal to 1/sigma**2." % (pol)

def parseGencalAntpos(filename):      
    """
    Given a text file (such as a manual ALMA calibration script),
    find the gencal command of antpos and return the 'antenna'
    and 'parameter' parameters. Ignores lines that have '#' as the
    first non-space character.
    -Todd Hunter
    """
    f1 = open(filename,'r')
    reading = False
    antenna = 0
    parameter = 0
    foundGencal = False
    for line in f1.readlines():
        if (line.lstrip().find('#') == 0):
            continue
        if (line.find('caltype')>=0 and line.find('antpos')>=0):
            foundGencal = True
        if foundGencal:
            loc = line.find('parameter')
            endloc = line.find(']')
            antloc = line.find('antenna')
            if (loc >= 0):
                loc = line.find('[')
                parameter = line[loc+1:].split('#')[0].strip()
                if endloc < 0:
                    # we did not find the end of the line on the first line
                    reading = True
            elif (reading):
                parameter += line.split('#')[0].strip()
                if (endloc >= 0):
                    # We did find the end of the parameter line
                    parameter = parameter.rstrip(',').rstrip(']')
                    reading = False
                    if (antenna != 0): break
            elif (antloc >= 0):
                if (antenna == 0):
                    antenna = line[antloc:].split('=')[1].split(')')[0]
                if (parameter != 0): 
                    # both antenna and parameter have been read
                    foundGencal = False
                    break
    parameter = parameter.rstrip(')').rstrip(']')
    f1.close()
    return(antenna.strip().strip(',').strip("'").strip('"'), 
           [float(i) for i in parameter.split(',')])

def compareAntennaPositionCorrections(antenna1='', parameter1='',
                                      antenna2='', parameter2='',
                                      gencal1='', gencal2=''):
    """
    Computes the difference (in mm) between two antenna baseline solutions
    on a per antenna basis.  The input format is the same as for gencal.
    Returns dictionaries of the vector differences and magnitudes.
    Example:
    antenna1='DV03,DV04'
    antenna2='DV03,DV04'
    parameter1=[-0.00011,3.965e-08,0.000126, -0.0001939,-2.638e-05,0.0001716]
    parameter2=[-0.00012,3.966e-08,0.000136, -0.0001839,-2.648e-05,0.0002716]
    gencal1='filename1_with_gencal.txt'
    gencal2='filename2_with_gencal.txt'
    -- Todd Hunter
    """
    if ((antenna1=='' or antenna2=='' or parameter1=='' or parameter2=='') and (gencal1=='' or gencal2=='')):
        print "Usage: compareAntennaPositionCorrections(antenna1='', parameter1='', antenna2='', parameter2='', gencal1='', gencal2='')"
        return
    if (gencal1 != '' and gencal2 != ''):
        antenna1, parameter1 = parseGencalAntpos(gencal1)
        if (antenna1 == 0 or parameter1 == 0):
            print "Could not parse gencal command in file 1"
            return
        antenna2, parameter2 = parseGencalAntpos(gencal2)
        if (antenna2 == 0 or parameter2 == 0):
            print "Could not parse gencal command in file 2"
            return

    ant1 = antenna1.split(',')
    ant2 = antenna2.split(',')
    p1 = np.array(parameter1).reshape(len(parameter1)/3, 3)
    p2 = np.array(parameter2).reshape(len(parameter2)/3, 3)
    differences = {}
    magnitudes = {}
    mag = []
    antennas = np.unique(ant1+ant2)
    antennasPrinted = []
    for a1 in range(len(ant1)):
        ant = ant1[a1]
        differences[ant] = p1[a1]*1000
        if (ant in ant2):
            myindex = ant2.index(ant)
            antennasPrinted.append(ant)
            differences[ant] -= p2[myindex]*1000
        mag.append(sqrt(sum(np.array([differences[ant]])**2)))
        magnitudes[ant] = mag[-1]
        print "%s %+.3f %+.3f %+.3f   total = %+.3f mm" % (ant,
                                                        differences[ant][0],
                                                        differences[ant][1],
                                                        differences[ant][2],
                                                        magnitudes[ant]
                                                        )
    print "Standard deviation = %+.3f mm" % (np.std(mag))
    firstTime = True
    for ant in antennas:
        if (ant not in antennasPrinted):
            if (firstTime):
                print "Solutions present in only one argument:"
                firstTime = False
            if (ant in ant1):
                myindex = ant1.index(ant)
                magnitude = sqrt(sum(np.array([p1[myindex]])**2))*1000
                print "%s %+.3f %+.3f %+.3f   total = %+.3f mm" % (ant,
                                                        p1[myindex][0]*1000,
                                                        p1[myindex][1]*1000,
                                                        p1[myindex][2]*1000,
                                                        magnitude)
            else:
                myindex = ant2.index(ant)
                magnitude = sqrt(sum(np.array([p2[myindex]])**2))*1000
                print "%s %+.3f %+.3f %+.3f   total = %+.3f mm" % (ant,
                                                        p2[myindex][0]*1000,
                                                        p2[myindex][1]*1000,
                                                        p2[myindex][2]*1000,
                                                        magnitude)
                   
    return(differences, magnitudes)
        
def buildtarfile(path=os.path.dirname(__file__), outpath='~'):
    """
    Create a tar file with the minimum required files to distribute casa-related
    tools. Include a README file containing the date and time of creation, and
    user who built them.  For further help and examples, see
      https://safe.nrao.edu/wiki/bin/view/ALMA/Buildtarfile
    -- Todd Hunter
    """
    pathbits = path.split('/')
    datestring = datetime.date.today().strftime('%Y-%m-%d %h:%m:%s')
    if (pathbits[-1] == 'analysis_scripts'):
        inpath = ''
        for p in range(len(pathbits)-1):
            if (pathbits[p] != ''):
                inpath += '/'
            inpath += pathbits[p]
    else:
        inpath = path
    if inpath == '':
        inpath = os.path.dirname(os.getcwd()) 
    cmd = 'echo Built on %s by %s > %s/analysis_scripts/README' % (datetime.datetime.now().ctime(), os.getenv('USER'),inpath)
    print cmd
    os.system(cmd)
    cmd = 'echo CVS ID%s >>  %s/analysis_scripts/README' % (version(), inpath)
    print cmd
    os.system(cmd)
    # Now remove strategic sensitive lines from analysisUtils.py
    mydir = os.path.dirname(__file__)
    if mydir == '':
        mydir = os.getcwd()
    os.system('cp -f %s %s/analysisUtilsBackup.py' % (__file__,mydir))
    print "Extracting files from %s" % (inpath)
    tarfile = '%s/analysis_scripts.tar' % (outpath)
    cmd = "cd %s ; tar --exclude='CVS' -cvf %s" % (inpath,tarfile)
    files = ['analysisUtils.py','fileIOPython.py','mpfit.py','calDatabaseQuery.py','tmUtils.py',
             'plotbandpass3.py','readscans.py','XmlObjectifier.py','README','AOS_Pads_XYZ_ENU.txt',
             'au_noASDMLibrary.py','compUtils.py','rootFinder.py','CompareAntPosResults.py',
             'O2SounderPlayer.py','AntPosResult.py','checksource.py','tsysNormalize.py',
             'almahelpers_localcopy.py']
    for f in files:
        cmd += ' analysis_scripts/%s' % (f)
    print "Running: %s" % (cmd)
    os.system(cmd) 
    os.system('mv -f %s/analysisUtilsBackup.py %s' % (mydir,__file__))
    os.system('chmod o-r '+__file__)
    print "Tar file left at = %s" % (tarfile)
    print "To deploy to ftpsite, run: cp %s /home/ftp/pub/casaguides/" % (tarfile)

def findClosestTime(mytimes, mytime):
    myindex = 0
    mysep = np.abs(mytimes[0]-mytime)
    for m in range(1,len(mytimes)):
        if (np.abs(mytimes[m] - mytime) < mysep):
            mysep = np.abs(mytimes[m] - mytime)
            myindex = m
    return(myindex)

def getChanRangeFromFreqRange(vis=None, fieldid=0, spwid=None, minf=None, maxf=None, refframe='TOPO',verbose=True):

    """
    returns a list of the two channels in an SPW corresponding
       to the minimum and maximum frequency in the given ref frame
    
    vis - MS name
    fieldid - field id of the observed field (for reference frame calculations)
    spwid - id of the SPW in question
    minf - minimum freq in Hz
    maxf - maximum freq in Hz
    refframe - frequency reference frame

    written by Dirk Petry
    """

    if(vis==None or spwid==None or minf==None or maxf==None):
        raise Exception('getChanRangeFromFreqRange: need to provide values for vis, spwid, minf, and maxf')

    rval = [-1,-1]

    if(minf>maxf):
        return rval

    iminf = -1
    imaxf = -1
    myms = mstool()
    myms.open(vis)
    a = myms.cvelfreqs(fieldids=[fieldid],spwids=[spwid],mode='frequency', outframe=refframe)
    myms.close()

    maxc = len(a)-1

    ascending = True
    lowedge = a[0]
    ilowedge = 0
    upedge = a[maxc]
    iupedge = maxc
    if(maxc>0 and (a[maxc]<a[0])): # frequencies are descending
        if verbose: print "Frequencies are descending in spw ", spwid
        ascending = False
        lowedge = a[maxc]
        upedge = a[0]
        ilowedge = maxc
        iupedge = 0

    if(minf<lowedge):
        if(maxf>lowedge):
            if(maxf>upedge):
                iminf = ilowedge
                imaxf = iupedge
            else:
                iminf = ilowedge
                # use imaxf from below search
                imaxf = -2
        #else:
            # both imaxf and iminf are -1
    else:
        if(minf<upedge):
            if(maxf>=upedge):
                # take iminf from below search
                iminf = -2
                imaxf = iupedge
            else:
                #take both iminf and imaxf from above search 
                iminf = -2
                imaxf = -2
        #else:
            # both imaxf and iminf are -1

    if ascending:
        if iminf==-2:
            for i in xrange(0,len(a)):
                if a[i]>=minf:
                    if verbose: print "Found ",i," ",a[i]
                    iminf = i
                    break
        if imaxf==-2:
            for j in xrange(iminf,len(a)):
                if a[j]>=maxf:
                    if verbose: print "Found ",j," ",a[j]
                    imaxf = j
                    break
        rval = [iminf,imaxf]
    else:
        if iminf==-2:
            for i in xrange(len(a)-1, -1, -1):
                if a[i]>=minf:
                    if verbose: print "Found ",i," ",a[i]
                    iminf = i
                    break
        if imaxf==-2:
            for j in xrange(iminf,-1,-1):
                if a[j]>=maxf:
                    if verbose: print "Found ",j," ",a[j]
                    imaxf = j
                    break
        rval = [imaxf, iminf]

    return rval

def removeScanFromCaltable(caltable, scan):
    """
    Removes a scan from a caltable.
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "Could not find table."
        return
    scans = getTsysScans(caltable)
    scan = int(scan)
    if scan not in scans:
        print "Scan %d is not in this table" % (scan)
        return
    mytb = createCasaTool(tbtool)
    mytb.open(caltable, nomodify=False)
    t = mytb.query('SCAN_NUMBER == %d' % scan)
    mytb.removerows(t.rownumbers())
    mytb.close()

def removeAntennaFromCaltable(caltable, antenna):
    """
    Removes all rows in a caltable that correspond to a specific
    antenna.  Does not touch the antenna subtable.
    antenna: the name of the antenna whose solutions to remove
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "Could not find table."
        return
    antennaNames = getAntennaNamesFromCaltable(caltable)
    antennaIDs = range(len(antennaNames))
    if antenna not in antennaNames:
        print "Antenna %s is not in this table" % (antenna)
        return
    mytb = createCasaTool(tbtool)
    antennaID = list(antennaNames).index(antenna)
    mytb.open(caltable, nomodify=False)
    t = mytb.query('ANTENNA1 == %d' % antennaID)
    print "Removed %d rows" % (len(t.rownumbers()))
    mytb.removerows(t.rownumbers())
    mytb.close()

def getTsysScans(caltable):
    """
    Gets the scan numbers from a caltable.
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "Could not find table."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    scans = np.unique(mytb.getcol('SCAN_NUMBER'))
    mytb.close()
    return(scans)
    
def replaceTsysScan(calTable, antenna, spw, pol, fromscan, toscan,
                    newvalue=None, verbose=True):
    """
    This is a utility to replace the Tsys spectrum from one combination
    of antenna+spw+pol+scan with the value from a different scan of the same
    antenna+spw+pol. The spw number should be the original number in the
    parent ms.  It automatically detects and processes
    old cal tables (casa 3.3) or new cal tables (casa 3.4).
        antenna:  the ID (integer or string integer) or the name
        spw: integer or string integer, or list of integers
        pol: 'X' or 'Y'
        fromscan: integer or string integer
        toscan: integer or string integer
        newvalue: if specified, put this value into all channels
                  (in this case, set fromscan=toscan)
    Returns: the number of rows replaced, and if newvalue is specfied, the
              median factor by which the values changed
    - Todd Hunter
    """
    fromscan = int(fromscan)
    if (fromscan < 0):
        print "Invalid fromscan number"
        return
    toscan = int(toscan)
    if (toscan < 0):
        print "Invalid toscan number"
        return
    mytb = createCasaTool(tbtool)
    if (type(antenna) != int):
        if (antenna.isdigit()):
            antenna = int(antenna)
        else:
            mytb.open(calTable)
            keywords = mytb.getkeywords()
            if ('MSName' not in keywords):
                print "This does not appear to be a cal table"
                return
            vis = keywords['MSName']
            mytb.close()
            availableAntennas = parseAntenna(vis,antenna)
            if (availableAntennas is None):
                return
            antenna = availableAntennas[0]
    if (type(spw) == list):
        spwsToFix = spw
    else:
        spwsToFix = [int(spw)] # Original spw ids
    scaleFactor = 1.0
    pols = ['X', 'Y']  # for now, assume this is always true
    if (pol not in pols):
        print "pol must be one of: ", pols
        return
    pol = pols.index(pol)
    mytb.open(calTable,nomodify=False)
    antennas = mytb.getcol('ANTENNA1')
    scans = mytb.getcol('SCAN_NUMBER')
    names = mytb.colnames()
    fromlist = []
    if ('CAL_DESC_ID' not in names):
        spws = mytb.getcol('SPECTRAL_WINDOW_ID')
        newCalTable = True
    else:
        spws = mytb.getcol('CAL_DESC_ID')  # These start at zero
        mytb.close()
        newCalTable = False
        mytb.open(calTable+'/CAL_DESC')
        truespws = list(mytb.getcol('SPECTRAL_WINDOW_ID')[0])
        mytb.close()
        mytb.open(calTable,nomodify=False)

    change = []
    for i in range(len(antennas)):
        for spw in spwsToFix:
            if (newCalTable):
                myspw = spw
                colname = 'FPARAM'
            else:
                myspw = truespws.index(spw)
                colname = 'GAIN'
            if (antennas[i] == antenna and spws[i] == myspw and
                scans[i] == fromscan):
                if (verbose):
                    print "Reading from row %d" % (i)
                gain = mytb.getcell(colname,i)
                if (newvalue is None):
                    fromlist.append(gain[pol] * scaleFactor)
                else:
                    mymedian = np.median(np.ma.masked_array(gain[pol], np.isnan(gain[pol])))
                    change.append(newvalue / mymedian)
                    if (verbose):
                        print change[-1], newvalue, mymedian
                    fromlist.append(newvalue * (gain[pol]/gain[pol]))

    replaced = 0
    for i in range(len(antennas)):
        for spw in spwsToFix:
            if (newCalTable):
                myspw = spw
                colname = 'FPARAM'
            else:
                myspw = truespws.index(spw)
                colname = 'GAIN'
            if (antennas[i] == antenna and spws[i] == myspw and
                scans[i] == toscan):
                if (verbose):
                    print "Writing to row %d" % (i)
                gain = mytb.getcell(colname,i)
                gain[pol] = fromlist[replaced]
                mytb.putcell(colname,i,gain)
                replaced += 1
    if (verbose):
        print "Replaced %d rows for antenna=%d, spw=%s, pol=%s, scan=%d" % (replaced,antenna,str(spw),pol,toscan)
    mymedian = 0
    if (newvalue is not None and replaced>0):
        mymedian = np.median(np.ma.masked_array(change, np.isnan(change)))
        if (verbose):
            print "The median change in value was a factor of %f" % (mymedian)
    mytb.close()
    if (newvalue is not None):
        return(replaced, mymedian)
    else:
        return(replaced)

def createCasaTool(mytool):
    """
    A wrapper to handle the changing ways in which casa tools are invoked.
    Relies on "from taskinit import *" in the preamble above.
    Todd Hunter
    """
    if (type(casac.Quantity) != type):  # casa 4.x
        myt = mytool()
    else:  # casa 3.x
        myt = mytool.create()
    return(myt)

def parseSpw(vis, spw, mymsmd=None):
    """
    Parse the spw argument (integer or string or list) to emulate 
    plotms selection.
    vis: name of the measurement set to get the valid spw list from
    spw: integer or string or list
    Returns:
    an integer list of spw IDs
    Todd Hunter
    """
    needToClose = False
    if mymsmd is None:
        needToClose = True
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    uniqueSpws = range(mymsmd.nspw())
    if needToClose:
        mymsmd.close()
    return(parseSpwArgument(spw,  uniqueSpws))

def parseSpwArgument(spw, uniqueSpwsInCalTable):
    """
    Parse the antenna argument (integer or string or list) to emulate 
    plotms selection.
    spw: integer or string or list
    uniqueSpwsInCalTable: list or comma-delimited string
    Returns:
    an integer list of spw IDs
    Todd Hunter
    """
    if (type(uniqueSpwsInCalTable) == str):
        uniqueSpwsInCalTable = uniqueSpwsInCalTable.split(',')
    if (type(spw) == str):
        if len(spw) == 0:
            return(uniqueSpwsInCalTable)
    if (type(spw) == str):
        tokens = spw.split(',')
        spwsToPlot = []
        removeSpw = []
        for token in tokens:
            if (len(token) > 0):
                if (token.find('*')>=0):
                    spwsToPlot = uniqueSpwsInCalTable
                    break
                elif (token.find('!')==0):
                    spwsToPlot = uniqueSpwsInCalTable
                    removeSpw.append(int(token[1:]))
                elif (token.find('~')>0):
                    (start,finish) = token.split('~')
                    spwsToPlot +=  range(int(start),int(finish)+1)
                else:
                    spwsToPlot.append(int(token))
            spwsToPlot = np.array(spwsToPlot,dtype=int)
            removeSpw = np.array(removeSpw,dtype=int)
            for rm in removeSpw:
                spwsToPlot = spwsToPlot[np.where(spwsToPlot != rm)[0]]
            spwsToPlot = list(spwsToPlot)
            if (len(spwsToPlot) < 1 and len(removeSpw)>0):
                print "Too many negated spws -- there are no spws left."
                return
    elif (type(spw) == list or type(spw) == np.ndarray):
        spwsToPlot = np.sort(spw)
        spwsToPlot = [int(i) for i in spwsToPlot]  
    else:
        spwsToPlot = [spw]
    return(spwsToPlot)

def parseTimerangeArgument(timerange, vis):
    """
    Converts 'HH:MM HH:MM' to [MJDsec1, MJDsec2] for a measurement set.
    """
    timerange = timerange.replace('~',' ').split()
    timerange[0] = timerange[0].replace('-',' ')
    timerange[1] = timerange[1].replace('-',' ')
    if (len(timerange[0].split())<2):
        # only the UT was given, so insert the date
        timerange[0] = getObservationStartDate(vis).split()[0] + ' %s' % (timerange[0])
    if (len(timerange[1].split())<2):
        timerange[1] = getObservationStartDate(vis).split()[0] + ' %s' % (timerange[1])
    timerange[0] = dateStringToMJDSec(timerange[0], verbose=False)
    timerange[1] = dateStringToMJDSec(timerange[1], verbose=False)
    return(timerange)

def parseBasebandArgument(basebands):
    if (type(basebands) == str):  # '1,2'
        basebands = [int(i) for i in basebands.split(',')]
    elif (type(basebands) != list and type(basebands) != np.array):  # 1
        basebands = [basebands]
    else:  # ['1','2'] or [1,2]
        basebands = [int(i) for i in basebands]

    return(basebands)

def parseAntenna(vis, antenna, mymsmd=''):
    """
    Parse an antenna argument (integer or string or list) to emulate 
    plotms selection, given a measurement set.
    Returns: an integer list of antenna IDs:
    antenna='' will return all antenna IDs; to exclude 2 antennas:
           antenna='!ea01,!ea08'
    Todd Hunter
    """
    msmdCreated = False
    if (casadef.casa_version >= casaVersionWithMSMD):
        if (mymsmd == ''):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            msmdCreated = True
        if (casadef.subversion_revision >= '27137'):
            uniqueAntennaIds = mymsmd.antennaids()
        else:
            uniqueAntennaIds = range(mymsmd.nantennas())
    else:
        print "Running ValueMapping to translate antenna names"
        vm = ValueMapping(vis)
        uniqueAntennaIds = range(vm.numAntennas)
    if type(antenna) == str:
        if len(antenna) == 0:
            return(uniqueAntennaIds)
    result = parseAntennaArgument(antenna, uniqueAntennaIds, vis, mymsmd=mymsmd)
    if msmdCreated:
        mymsmd.close()
    return(result)

def parseAntennaArgument(antenna, uniqueAntennaIds, msname='', verbose=False, mymsmd=''):
    """
    Parse an antenna argument (integer or string or list) to emulate 
    plotms selection, given a list of unique antenna IDs present in
    the dataset.
    antenna: can be string, list of integers, or single integer
    uniqueAntennaIds: list of integers, or comma-delimited string
    Todd Hunter
    """
    myValidCharacterListWithBang = ['~', ',', ' ', '*', '!',] + [str(m) for m in range(10)]
    if (type(uniqueAntennaIds) == str):
        uniqueAntennaIds = uniqueAntennaIds.split(',')
    if (type(antenna) == str):
        if (len(antenna) == sum([m in myValidCharacterListWithBang for m in antenna])):
            # a simple list of antenna numbers was given 
            tokens = antenna.split(',')
            antlist = []
            removeAntenna = []
            for token in tokens:
                if (len(token) > 0):
                    if (token.find('*')==0 and len(token)==1):
                        antlist = uniqueAntennaIds
                        break
                    elif (token.find('!')==0):
                        antlist = uniqueAntennaIds
                        removeAntenna.append(int(token[1:]))
                    elif (token.find('~')>0):
                        (start,finish) = token.split('~')
                        antlist +=  range(int(start),int(finish)+1)
                    else:
                        antlist.append(int(token))
            antlist = np.array(antlist,dtype=int)
            removeAntenna = np.array(removeAntenna,dtype=int)
            for rm in removeAntenna:
                antlist = antlist[np.where(antlist != rm)[0]]
            antlist = list(antlist)
            if (len(antlist) < 1 and len(removeAntenna)>0):
                print "Too many negated antennas -- there are no antennas left."
                return
        else:
            # The antenna name (or list of names) was specified
            if (verbose): print "name specified"
            tokens = antenna.split(',')
            if (msname != ''):
                if (casadef.casa_version < casaVersionWithMSMD):
                    print "Running ValueMapping to translate antenna names"
                    vm = ValueMapping(msname)
                    uniqueAntennas = vm.uniqueAntennas
                else:
                    if mymsmd == '':
                        mymsmd = createCasaTool(msmdtool)
                        mymsmd.open(msname)
                        needToClose = True
                    else:
                        needToClose = False
                    if (casadef.subversion_revision >= '27137'):
                        uniqueAntennas = mymsmd.antennanames()
                    else:
                        uniqueAntennas = getAntennaNames(msname)
                antlist = []
                removeAntenna = []
                for token in tokens:
                    if (token in uniqueAntennas):
                        antlist = list(antlist)  # needed in case preceding antenna had ! modifier
                        if (casadef.casa_version < casaVersionWithMSMD):
                            antlist.append(vm.getAntennaIdsForAntennaName(token))
                        else:
                            antlist.append(mymsmd.antennaids(token)[0])
                    elif (token[0] == '!'):
                        if (token[1:] in uniqueAntennas):
                            antlist = uniqueAntennaIds
                            if (casadef.casa_version < casaVersionWithMSMD):
                                removeAntenna.append(vm.getAntennaIdsForAntennaName(token[1:]))
                            else:
                                removeAntenna.append(mymsmd.antennaids(token[1:]))
                        else:
                            print "Antenna %s is not in the ms. It contains: " % (token), uniqueAntennas
                            return
                    else:
                        print "Antenna %s is not in the ms. It contains: " % (token), uniqueAntennas
                        return
                antlist = np.array(antlist,dtype=int)
                removeAntenna = np.array(removeAntenna,dtype=int)
                for rm in removeAntenna:
                    antlist = antlist[np.where(antlist != rm)[0]]
                antlist = list(antlist)
                if (len(antlist) < 1 and len(removeAntenna)>0):
                    print "Too many negated antennas -- there are no antennas left."
                    return
                if (casadef.casa_version >= casaVersionWithMSMD and needToClose):
                    mymsmd.close()
            else:
                print "Antennas cannot be specified my name if the ms is not found."
                return
    elif (type(antenna) == list or type(antenna) == np.ndarray):
        # it's a list or array of integers
        if (verbose): print "converting int to list"
        antlist = list(antenna)
    else:
        # It's a single, integer entry
        if (verbose): print "converting int to list"
        antlist = [antenna]
    return(antlist)

def parseAntennaASDM(asdm, antenna, verbose=False):
    """
    Parse an antenna argument (integer or string or list) to emulate 
    plotms selection, given a list of unique antenna IDs present in
    the ASDM.
    antenna: can be string, list of integers, or single integer
    Todd Hunter
    """
    uniqueAntennas = readAntennasFromASDM(asdm, verbose=False)
    uniqueAntennaIDs = range(len(uniqueAntennas))
    myValidCharacterListWithBang = ['~', ',', ' ', '*', '!',] + [str(m) for m in range(10)]
    if (type(antenna) == str):
        if (antenna.strip() == ''):
            antlist = uniqueAntennaIDs
        elif (len(antenna) == sum([m in myValidCharacterListWithBang for m in antenna])):
            # a simple list of antenna numbers was given 
            tokens = antenna.split(',')
            antlist = []
            removeAntenna = []
            for token in tokens:
                if (len(token) > 0):
                    if (token.find('*')==0 and len(token)==1):
                        antlist = uniqueAntennaIds
                        break
                    elif (token.find('!')==0):
                        antlist = uniqueAntennaIds
                        removeAntenna.append(int(token[1:]))
                    elif (token.find('~')>0):
                        (start,finish) = token.split('~')
                        antlist +=  range(int(start),int(finish)+1)
                    else:
                        antlist.append(int(token))
            antlist = np.array(antlist,dtype=int)
            removeAntenna = np.array(removeAntenna,dtype=int)
            for rm in removeAntenna:
                antlist = antlist[np.where(antlist != rm)[0]]
            antlist = list(antlist)
            if (len(antlist) < 1 and len(removeAntenna)>0):
                print "Too many negated antennas -- there are no antennas left."
                return
        else:
            # The antenna name (or list of names) was specified
            if (verbose): print "name specified"
            tokens = antenna.split(',')
            antlist = []
            removeAntenna = []
            for token in tokens:
                if (token in uniqueAntennas):
                    antlist = list(antlist)  # needed in case preceding antenna had ! modifier
                    antlist.append(uniqueAntennas.index(token))
                elif (token[0] == '!'):
                    if (token[1:] in uniqueAntennas):
                        antlist = uniqueAntennaIDs
                        removeAntenna.append(uniqueAntennas.index(token[1:]))
                    else:
                        print "Antenna %s is not in the asdm. It contains: " % (token), uniqueAntennas
                        return
                else:
                    print "Antenna %s is not in the asdm. It contains: " % (token), uniqueAntennas
                    return
            antlist = np.array(antlist,dtype=int)
            removeAntenna = np.array(removeAntenna,dtype=int)
            for rm in removeAntenna:
                antlist = antlist[np.where(antlist != rm)[0]]
            antlist = list(antlist)
            if (len(antlist) < 1 and len(removeAntenna)>0):
                print "Too many negated antennas -- there are no antennas left."
                return
    elif (type(antenna) == list or type(antenna) == np.ndarray):
        # it's a list or array of integers (or strings)
        antlist = list(antenna)
        if (type(antlist[0]) == str): # strings
            tokens = antlist[:]
            antlist = []
            removeAntenna = []
            for token in tokens:
                if (token in uniqueAntennas):
                    antlist = list(antlist)  # needed in case preceding antenna had ! modifier
                    antlist.append(uniqueAntennas.index(token))
                elif (token[0] == '!'):
                    if (token[1:] in uniqueAntennas):
                        antlist = uniqueAntennaIDs
                        removeAntenna.append(uniqueAntennas.index(token[1:]))
                    else:
                        print "Antenna %s is not in the asdm. It contains: " % (token), uniqueAntennas
                        return
                else:
                    print "Antenna %s is not in the asdm. It contains: " % (token), uniqueAntennas
                    return
            antlist = np.array(antlist,dtype=int)
            removeAntenna = np.array(removeAntenna,dtype=int)
            for rm in removeAntenna:
                antlist = antlist[np.where(antlist != rm)[0]]
            antlist = list(antlist)
            if (len(antlist) < 1 and len(removeAntenna)>0):
                print "Too many negated antennas -- there are no antennas left."
                return
    else:
        # It's a single, integer entry
        antlist = [antenna]
    return(antlist)

def insertBracketsIntoFlaglist(textfile):
    """
    Inserts square brackets around the quoted timerange of each line of a flag list.
    See http://www.aoc.nrao.edu/~sbhatnag/misc/msselection/TimeSelection.html#x10-80002
    Returns: the name of the new textfile, which has '.brackets' appended
    -Todd Hunter
    """
    f = open(textfile,'r')
    lines = f.readlines()
    f.close()
    textfile += '.brackets'
    f = open(textfile,'w')
    for line in lines:
        loc = line.find('timerange=')
        if (loc >= 0):
            line = line.replace("timerange='","timerange='[")
            closeQuote = loc+12+line[loc+12:].find("'")
            line = line[:closeQuote] + "]'" + line[closeQuote+1:]
        f.write(line)
    f.close()
    return textfile
    
def flagReasonStats(vis, tbuff='', useapplied=False, returnFullDictionary=False,
                    verbose=True, copyvis=False, intent='', includeQA0TrxTsys=False,
                    globalUnflagEachTime=True, pipelineDeterministicFlags=False,
                    onlineFlags=True, insertBrackets=False):
    """
    Writes an ASCII file of online flag commands, then applies them one at a time
    (after clearing the flags each time) recording the statistics of data flagged 
    by them.  The flagmanager is used to restore the flags to the prior state. But
    if you are paranoid, you can set copyvis=True to copy the dataset and it 
    will first copy it to your working directory and operate on it there.
    Inputs:
    * vis: name of measurement set
    * tbuff: value (or tuple) in seconds to pass to flagdata
    * useapplied: Boolean to pass to the initial flagcmd to generate the flag list
    * returnFullDictionary: if True, return full dictionary; otherwise just the percent
    * intent: passed to amc.getFlagdict to limit statistics to the specified intent
    * globalUnflagEachTime: remove all flags before analysis (this is safest, but do 
        not use if you want the BDF flags to be included in each of the statistics)
    * pipelineDeterministicFlags: if True, then also apply each of the following
        one-at-a-time and report the statistics: autocorr, shadow, calAtm, 
          calPointing, edge (on Tsys science spws only)
    Returns: a dictionary of percentage values keyed by reason code string
    -Todd Hunter
    """
    import analyzemscal as amc
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if (copyvis):
        oldvis = vis[:]
        vis = os.path.basename(vis)+'.fresh'
        print "Copying ms to your working directory."
        os.system('cp -r %s %s' % (oldvis,vis))
    outfile = vis+'.flaglist'
    a = flagcmd(vis,inpmode='table',action='list',savepars=True,outfile=outfile,useapplied=useapplied)
    if insertBrackets:
        outfile = insertBracketsIntoFlaglist(outfile)
    reasons = flagReasons(outfile, useapplied, includeQA0TrxTsys)
    print "found reasons = ", reasons
    mydict = {}
    if (not onlineFlags and not pipelineDeterministicFlags):
        print "You must set at least one of: onlineFlags, pipelineDeterministic."
        return
    print "Saving current flags as the initial state."
    flagmanager(vis, mode='save', versionname='preFlagStatReasons')
    if (reasons is not None and onlineFlags):
        for i,r in enumerate(reasons):
            if verbose and i==0:
                print "Working on reason = ", r
            if globalUnflagEachTime:
                print "Removing all flags"
                flagdata(vis, mode='unflag', flagbackup=False)
            else:
                flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
            flagdata(vis, reason=r, action='apply',
                     tbuff=tbuff, mode='list', inpfile=outfile, flagbackup=False)
            mydict[r] = amc.getFlagdict(vis, intent=intent)
            percent = mydict[r]['percent']
            if (not returnFullDictionary):
                mydict[r] = percent
            print "%s: %f" % (r, percent)
        r = 'allOnline'
        flagdata(vis, action='apply', tbuff=tbuff, mode='list', inpfile=outfile, flagbackup=False)
        mydict[r] = amc.getFlagdict(vis, intent=intent)
        percent = mydict[r]['percent']
        if (not returnFullDictionary):
            mydict[r] = percent
        print "%s: %f" % (r, percent)

    if pipelineDeterministicFlags:
        if globalUnflagEachTime:
            print "Removing all flags"
            flagdata(vis, mode='unflag', flagbackup=False)
        else:
            flagmanager(vis, mode='restore', versionname='preFlagStatReasons')

        r = 'autocorr'
        flagdata(vis, mode='manual', autocorr=True, flagbackup=False)
        mydict[r] = amc.getFlagdict(vis, intent=intent)
        percent = mydict[r]['percent']
        if (not returnFullDictionary):
            mydict[r] = percent
        print "%s: %f" % (r, percent)

        if globalUnflagEachTime:
            print "Removing all flags"
            flagdata(vis, mode='unflag', flagbackup=False)
        else:
            flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
        r = 'shadow'
        flagdata(vis, mode='shadow', flagbackup=False)
        mydict[r] = amc.getFlagdict(vis, intent=intent)
        percent = mydict[r]['percent']
        if (not returnFullDictionary):
            mydict[r] = percent
        print "%s: %f" % (r, percent)

        if globalUnflagEachTime:
            print "Removing all flags"
            flagdata(vis, mode='unflag', flagbackup=False)
        else:
            flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
        r = 'calAtmosphere'
        flagdata(vis, mode='manual', intent='CALIBRATE_ATMOSPHERE#AMBIENT', flagbackup=False)
        flagdata(vis, mode='manual', intent='CALIBRATE_ATMOSPHERE#HOT', flagbackup=False)
        flagdata(vis, mode='manual', intent='CALIBRATE_ATMOSPHERE#OFF_SOURCE', flagbackup=False)
        mydict[r] = amc.getFlagdict(vis, intent=intent)
        percent = mydict[r]['percent']
        if (not returnFullDictionary):
            mydict[r] = percent
        print "%s: %f" % (r, percent)

        if globalUnflagEachTime:
            print "Removing all flags"
            flagdata(vis, mode='unflag', flagbackup=False)
        else:
            flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
        r = 'pointing'
        flagdata(vis, mode='manual', intent='CALIBRATE_POINTING#ON_SOURCE', flagbackup=False)
        mydict[r] = amc.getFlagdict(vis, intent=intent)
        percent = mydict[r]['percent']
        if (not returnFullDictionary):
            mydict[r] = percent
        print "%s: %f" % (r, percent)

        tdmSpws = getScienceSpws(vis, fdm=False, returnString=False)
        if (len(tdmSpws) > 0):
            if globalUnflagEachTime:
                print "Removing all flags"
                flagdata(vis, mode='unflag', flagbackup=False)
            else:
                flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
            r = 'edge'
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            for tdmSpw in tdmSpws:
                nchan = mymsmd.nchan(tdmSpw)
                nflag = int(np.round(nchan*0.0625))
                spwSelection = '%d:0~%d;%d~%d' % (tdmSpw,nflag-1,nchan-nflag,nchan-1)
                print "Calling flagdata(spw='%s')" % (spwSelection)
                flagdata(vis, mode='manual', spw=spwSelection)
            mymsmd.close()
            mydict[r] = amc.getFlagdict(vis, intent=intent)
            percent = mydict[r]['percent']
            if (not returnFullDictionary):
                mydict[r] = percent
            print "%s: %f" % (r, percent)

    print "Restoring flags to initial state."
    flagmanager(vis, mode='restore', versionname='preFlagStatReasons')
    return(mydict)

def flagcmdplot(vis, useapplied=True):
    """
    Runs flagcmd(action='plot') once per reason code and generates pngs and a big PDF.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find file"
        return
    flagcmdtxt = vis.strip('.ms') + '_cmd.txt'
    if (not os.path.exists(flagcmdtxt)):
        print "Generating text file"
        flagcmd(vis, action='list', savepars=True, outfile=flagcmdtxt, useapplied=useapplied)
    reasons = flagReasons(flagcmdtxt, useapplied)
    pngs = []
    for i,reason in enumerate(reasons):
        print "Working on reason %d of %d" % (i+1,len(reasons))
        reasonpng = reason.replace('(','').replace(')','').replace('%','percent').replace('>','gt').replace('<','lt').rstrip('.')
        png = vis+'.%s.png' % reasonpng
        flagcmd(vis, action='plot', reason=reason, plotfile=png, useapplied=useapplied)
        pngs.append(png)
        print "Wrote ", png
    buildPdfFromPngs(pngs, pdfname=vis+'.flagcmdplot.pdf')

def flagDurations(vis, listThresholdMinutes='half', verbose=False):
    """
    Reads the FLAG_CMD table of a measurement set and computs the time durations of each
    flag, returning them as a list of rows sorted by longest duration first.
    listThresholdMinutes: list any flags longer than this duration; either a value in minutes, 
            or 'half' for half the length of the dataset
    vis: measurement set  (for ASDM version, use au.qa0flags)
    verbose: if True, show whole commands
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    flagcmd = vis + '/FLAG_CMD'
    mytb = createCasaTool(tbtool)
    mytb.open(flagcmd)
    cmds = mytb.getcol('COMMAND')
    reasons = mytb.getcol('REASON')
    mytb.close()
    minutes = []
    for cmd in cmds:
        if cmd.find('timerange') >= 0:
            dateStrings = cmd.split("timerange='")[1].split("'")[0].split('~')
            minutes.append(dateStringDifference(dateStrings[0], dateStrings[1]))
        else:
            minutes.append(0)
    minutes = np.array(minutes)
    if listThresholdMinutes == 'auto':
        listThresholdMinutes = getObservationLength(vis)
    idxThreshold = np.where(minutes >= listThresholdMinutes)[0]
    tsys = 0
    tsysAntennas = []
    tsysBasebands = []
    tsysPols = []
    trx = 0
    trxAntennas = []
    trxBasebands = []
    trxPols = []
    totalAntennas = len(getAntennaNames(vis))
    for i in idxThreshold:
        print "Long flag: %g minutes (row %d: %s)" % (minutes[i],i,reasons[i])
        if reasons[i].find('AFD05') > 0:
            if reasons[i].find('TSYS') > 0:
                tsys += 1
                tsysAntennas.append(reasons[i].split('Ant_')[1].split('_')[0])
                tsysBasebands.append(int(reasons[i].split('(BB_')[1].split(')')[0]))
                tsysPols.append(reasons[i].split('_Pol_')[1].split('_')[0])
            elif reasons[i].find('TRX') > 0:
                trx += 1
                trxAntennas.append(reasons[i].split('Ant_')[1].split('_')[0])
                trxBasebands.append(int(reasons[i].split('(BB_')[1].split(')')[0]))
                trxPols.append(reasons[i].split('_Pol_')[1].split('_')[0])
        if verbose:
            print "   ",cmds[i]
    idx = np.argsort(minutes)[::-1]
    if (len(idxThreshold) < 1):
        print "Longest flag = %g minutes (row %d: %s)" % (minutes[idx[0]],idx[0],reasons[idx[0]])
        print "Shortest flag = %g minutes (row %d: %s)" % (minutes[idx[-1]],idx[-1],reasons[idx[-1]])
    else:
        tsysAntennas = np.unique(tsysAntennas)
        trxAntennas = np.unique(trxAntennas)
        tsysBasebands = np.unique(tsysBasebands)
        trxBasebands = np.unique(trxBasebands)
        tsysPols = np.unique(tsysPols)
        trxPols = np.unique(trxPols)
        print "Num. of long Tsys flags: %d, unique antennas: %d/%d, basebands: %s %s" % (tsys,len(tsysAntennas),totalAntennas,tsysBasebands,tsysPols)
        print "Num. of long Trx  flags: %d, unique antennas: %d/%d, basebands: %s %s" % (trx,len(trxAntennas),totalAntennas,trxBasebands,trxPols)
    return idx

def flagReasons(filename, useapplied=True, includeQA0TrxTsys=True):
    """
    Parses a flag command file and returns a list of the unique reason codes.
    file: can be a text file or a measurement set.  If the latter, then
        flagcmd(action='list') will be run.
    -Todd Hunter
    """
    if (not os.path.exists(filename)):
        print "Could not find file"
        return
    if (os.path.isdir(filename)):
        if (os.path.isdir(filename + '/ANTENNA')):
            vis = filename
            filename = vis.strip('.ms') + '_cmd.txt'
            print "Running flagcmd to generate text file"
            flagcmd(vis, action='list', savepars=True, outfile=filename, useapplied=useapplied)
        else:
            print "This does not appear to be a measurement set or a text file."
            return
    if (not os.path.exists(filename)):
        print "Could not find the flag command text file"
        return
    f = open(filename,'r')
    reason = []
    lines = f.readlines()
    for line in lines:
        if (line.find('QA0') < 0 or (line.find('TSYS')<0 and line.find('TRX')<0) or includeQA0TrxTsys):
            reason.append(line.split("reason='")[1].split("'")[0])
    reason = [str(a) for a in (np.unique(reason))]
    return(reason)
    
def flagTsysTable(caltable='', antenna='', spw='', time='', debug=False):
    """
    Flags a Tsys cal table, because flagdata can not yet flag caltables when
    selecting on time or scan.
    antenna: can be ID or name or list thereof
    spw: integer or list
    time: MJDseconds or '2011/10/15 05:00:00' or '2011/10/15-05:00:00'
          or a list of datetimes: '2011/10/15 05:00:00,2011/10/15-05:00:00'
          or a list of times: '05:00:00,06:00:00' on start date of first row
    pols: is not an argument:  all pols will be flagged!
    """
    if (os.path.exists(caltable) == False):
        print "Could not locate file: %s" % (caltable)
        return
    mytb = createCasaTool(tbtool)
    mytb.open(caltable,nomodify=False)
    times = mytb.getcol('TIME')
    if ('SPECTRAL_WINDOW_ID' not in mytb.colnames()):
        print "This function does not operate on old-style cal tables."
        mytb.close()
        return
    if (type(time) == str):
        if (time != ''):
            tokens = time.split(',')
            mydate = mjdsecToUT(times[0]).split()[0].replace('-','/')
            if (len(tokens) > 1):
                mytimes = []
                for t in tokens:
                    t = t.strip()
                    if (len(t) < 9):
                        t = mydate + ' ' + t
                        print "Prepending date (%s): %s" % (mydate,t)
                    mytimes.append(dateStringToMJDSec(t))
            else:
                if (len(time) < 9):
                    time = mydate + ' ' + time
                    print "Prepending date (%s): %s" % (mydate,time)
                mytimes = [dateStringToMJDSec(time)]
        else:
            mytimes = ''
    elif (type(time) != list):
        # single MJDsec
        mytimes = [time]
    elif (type(time[0]) == str):
        mytimes = []
        for t in range(len(time)):
            if (len(time[t].strip()) < 9):
                time[t] = mydate + ' ' + time[t].strip()
                print "Prepending date (%s): %s" % (mydate,time[t])
            mytimes.append(dateStringToMJDSec(time[t].strip()))
    else: # 
        mytimes = time
    antennas = mytb.getcol('ANTENNA1')
    uniqueAntennaIds = np.unique(antennas)
    msname = mytb.getkeyword('MSName')      
    antenna = parseAntennaArgument(antenna, uniqueAntennaIds, msname)
    print "Antenna list = ", antenna
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    uniqueSpws = np.unique(spws)
    spw = parseSpwArgument(spw, uniqueSpws)
    print "spw list = ", spw
    uniqueTimes = np.unique(times)
    print "unique times in table: ", uniqueTimes.astype(int)
    print "unique times in table: ", plotbp3.mjdsecArrayToUTString(uniqueTimes)
    print "mytimes to flag = ", mytimes
    flags = mytb.getcol('FLAG')
    npol = np.shape(flags)[0]
    nchan = np.shape(flags)[1]
    nrows = np.shape(flags)[2]
    threshold = 10 # seconds
    rowsToFlag = []
    rowsFlagged = []
    for i in range(nrows):
        if (mytimes == ''):
            timeMatch = True
        else:
            timeMatch = plotbp3.sloppyMatch(times[i], mytimes, threshold, debug)
        if ((antennas[i] in antenna or len(antenna)==0) and (spws[i] in spw or len(spw)==0) and timeMatch):
            myflag = mytb.getcell('FLAG', i)
            rowsToFlag.append(i)
            for p in range(npol):
                for ch in range(nchan):
                    if (myflag[p][ch] == False):
                        if (len(rowsFlagged) == 0):
                            rowsFlagged.append(i)
                        elif (rowsFlagged[-1] != i):
                            rowsFlagged.append(i)
                        myflag[p][ch] = True
            mytb.putcell('FLAG',i,myflag)
    mytb.close()
    alreadyFlagged = list(set(rowsToFlag).difference(set(rowsFlagged)))
    print "Flagged %d/%d rows: %s" % (len(rowsFlagged), nrows, str(rowsFlagged))
    print "%d/%d rows were already flagged: %s" % (len(rowsToFlag)-len(rowsFlagged), len(rowsToFlag), alreadyFlagged)

def removeTsysSpike(calTable='', antenna=-1, spw=-1, startchan=-1, endchan=-1):
    """
    This is a utility to interpolate across a spike in the Tsys values for
    one antenna, one spw, both polarizations. The spw number should be the
    original number in the parent ms.  It automatically detects and processes
    old cal tables (casa 3.3) or new cal tables (casa 3.4).
    - Todd Hunter
    """
    antenna = int(antenna)
    spw = int(spw)
    tb.open(calTable,nomodify=False)
    antennas = tb.getcol('ANTENNA1')
    names = tb.colnames()
    if ('CAL_DESC_ID' not in names):
        spws = tb.getcol('SPECTRAL_WINDOW_ID')
        newCalTable = True
    else:
        spws = tb.getcol('CAL_DESC_ID')  # These start at zero
        tb.close()
        newCalTable = False
        tb.open(calTable+'/CAL_DESC')
        truespws = list(tb.getcol('SPECTRAL_WINDOW_ID')[0])
        tb.close()
        tb.open(calTable,nomodify=False)

    replaced = 0
    for i in range(len(antennas)):
        if (newCalTable):
            myspw = spw
            colname = 'FPARAM'
        else:
            myspw = truespws.index(spw)
            colname = 'GAIN'
        if (antennas[i] == antenna and spws[i] == myspw):
            print "Replacing row %d" % (i)
            gain = tb.getcell(colname, i)
            for j in range(len(gain)):
                for chan in range(startchan,endchan):
                    gain[j][chan] = 0.5*(gain[j][startchan-1] + gain[j][endchan])
            tb.putcell(colname,i,gain)
            replaced += 1
    #
    tb.close() 
    print "Replaced %d rows" % (replaced)

def removePhasecalsFromSyscalTable(vis, intent='CALIBRATE_PHASE'):
    """
    Removes the rows associated with the phase calibrator(s) from the SYSCAL
    table of a measurement set.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SYSCAL', nomodify=False)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    si = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
    atmFields = mymsmd.fieldsforscans(si)
    phasecals = mymsmd.fieldsforintent('*'+intent+'*')
    fields = np.intersect1d(atmFields, phasecals)
    scandict = mymsmd.scansforfields()
    scans = []
    for field in fields:
        scans += list(scandict[str(field)])
    if len(fields) < 1:
        mymsmd.close()
        mytb.close()
        print "No %s scans are in the SYSCAL table." % (intent)
        return
    print "There are entries for field %s to be removed." % (fields)
    mytimes = mytb.getcol('TIME')
    intervals = mytb.getcol('INTERVAL')
    mytimes = mytimes - 0.5*intervals
    nrows = len(mytimes)
    removeRows = []
    for row in range(nrows):
        myscan = nearestCalScanForTime(mymsmd, mytimes[row])
        if myscan in scans:
            removeRows.append(row)
    mymsmd.close()
    print "Will remove %d/%d rows" % (len(removeRows), nrows)
    mytb.removerows(removeRows)
    mytb.close()

def flagTsysFeature(vis, spw, startchan, endchan, field='', antenna='', newValue=-1.0, 
                    backup=False, doplot=True, edge=4, colname='TSYS_SPECTRUM'):

    """
    This is a utility to edit the SYSCAL table of a measurement set, which is what
    gencal reads when it creates a Tsys caltable.  Default is to set the value to -1,
    which gencal will interpret as a flag.  It operates on one antenna, one spw, both 
    polarizations. The spw number should be the original number in the parent ms.  It can 
    make a backup of the table before proceeding.
    Inputs:
    vis: measurement set
    spw: string or integer string (cannot be a list)
    startchan: first channel to set
    endchan: last channel to set
    antenna: antenna ID, or list of IDs; blank or -1 means all antennas
    field: field ID or name; blank or -1 means all fields
    newValue: floating point value to place into these channels (for both polarizations)
    backup: if True, then make SYSCAL.backup before editing SYSCAL
    doplot: if True, then display the before and after Tsys curves for each modified spectrum
    edge: when plotting, skip this many channels on each edge of the spectrum
    - Todd Hunter
    """
    spw = int(spw)
    startchan = int(startchan)
    endchan = int(endchan)
    calTable = vis + '/SYSCAL'
    if backup:
        os.system('cp -r %s %s.backup' % (calTable,calTable))
        print "Wrote backup table: %s.backup" % (calTable)
    mytb = createCasaTool(tbtool)
    mytb.open(calTable, nomodify=False)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    si = mymsmd.scansforintent('CALIBRATE_ATMOSPHERE*')
    if field < 0 or field == '': 
        fieldIDs = range(mymsmd.nfields())
    else:
        fieldIDs = parseFieldArgument(vis,field, mymsmd=mymsmd)[0]
    sf = []
    for fieldID in fieldIDs:
        sf += list(mymsmd.scansforfield(fieldID))
    sf = np.unique(sf)
    scans = np.intersect1d(si,sf) # list of scans to be processed
    print "Will process solutions from field IDs: ", fieldIDs
    print "Will process solutions from time-identified scans: ", scans
    antennas = mytb.getcol('ANTENNA_ID')
    times = mytb.getcol('TIME')
    if antenna == -1 or antenna == '':
        antennaList = np.unique(antennas)
    elif type(antenna) != list and type(antenna) != np.ndarray:
        antennaList = [int(antenna)]
    else:
        antennaList = antenna
    names = mytb.colnames()
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    mytb.close()
    if spw not in spws:
        print "spw not in caltable (available spws = %s)" % (np.unique(spws))
        return
    replaced = 0
    nrows = len(antennas)
    print "There are %d total rows in SYSCAL table." % (nrows)
    mytb.open(calTable, nomodify=False)
    for antenna in antennaList:
        print "Flagging antenna %2d spw %2d" % (antenna, spw)
        myt = mytb.query('ANTENNA_ID == %d && SPECTRAL_WINDOW_ID == %d' % (antenna,spw))
        gain = myt.getcol(colname)
        mytimes = myt.getcol('TIME')
        intervals = myt.getcol('INTERVAL')
        # the 
        mytimes = mytimes - 0.5*intervals
        npols = len(gain)
        nscans = np.shape(gain)[2]
        for row in range(nscans):
            myscan = nearestCalScanForTime(mymsmd, mytimes[row])
            if myscan in scans:
                if doplot:
                    pb.clf()
                    pb.plot(edge+np.arange(len(gain[0,:,row][edge:-edge])), 
                            gain[0,:,row][edge:-edge], 'b--') 
                    if np.shape(gain)[0] > 1:
                        pb.hold(True)
                        pb.plot(edge+np.arange(len(gain[1,:,row][edge:-edge])),
                                gain[1,:,row][edge:-edge], 'g--')
                for j in range(npols):
                    gain[j,:,row][startchan:endchan+1] = newValue
                if doplot:
                    pb.plot(edge+np.arange(len(gain[0,:,row][edge:-edge])), 
                            gain[0,:,row][edge:-edge], 'b-') 
                    if np.shape(gain)[0] > 1:
                        # dual pol
                        pb.plot(edge+np.arange(len(gain[1,:,row][edge:-edge])), 
                                gain[1,:,row][edge:-edge], 'g-')
                    pb.title('antenna %d  spw %d  row %d' % (antenna, spw, row))
                    pb.xlabel('Channel')
                    pb.ylabel(colname+' (K)')
                    pb.draw()
        myt.putcol(colname,gain)
        myt.close()
        replaced += nscans
    print "Replaced %d rows." % (replaced)
    mytb.close() 
    mymsmd.close()

def removePhasecalsFromTsysTable(caltable, vis=None):
    """
    Remove Tsys solutions associated with the phase calibrator(s).
    If vis is not specified, it is read from caltable, but must exist.
    -Todd Hunter
    """
    if vis is None:
        vis = getMeasurementSetFromCaltable(caltable)
    field = getPhaseCalibrators(vis)
    if len(field) == 0:
        print "No phase calibrator in this dataset"
        return
    for f in field:
        print "Removing solutions on field ", f
        removeFieldFromTsysTable(caltable, f)

def getPhaseCalibrators(vis, mymsmd='', intent='CALIBRATE_PHASE#ON_SOURCE', 
                        byname=False):
    """
    Gets the field IDs for the phase calibrators in a measurement set.
    vis: string, can contain a wildcard, in which case first match in glob.glob
         that doesn't contain '_target' is used
    -Todd Hunter
    """
    if vis.find('*') > 0:
        viss = glob.glob(vis)
        for i,v in enumerate(viss):
            if v.find('_target') < 0 or i+1==len(viss):
                vis = v
                break
    if not os.path.exists(vis):
        print "Could not find vis: ", vis
        return []
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    phasecals = mymsmd.fieldsforintent(intent)
    if byname:
        phasecals = mymsmd.namesforfields(phasecals)
    if needToClose:
        mymsmd.close()
    return phasecals

def removeFieldFromTsysTable(caltable, field):
    """
    Removes all rows associated with a field ID or field name from a Tsys table.
    field: integer or string integer or string name (single value)
    -Todd Hunter
    """
    names = getFieldNamesFromCaltable(caltable)
    result = parseSingleFieldArgumentFromLists(field, range(len(names)), names)
    if result is None:
        return
    mytb = createCasaTool(tbtool)
    mytb.open(caltable, nomodify=False)
    field, names = result
    fieldID = mytb.getcol('FIELD_ID')
    rows = np.where(fieldID == field)[0]
    mytb.removerows(rows)
    print "Removed %d rows." % (len(rows))
    mytb.close()

def replaceTsys(calTable, antenna, spw, frompol='X', topol='Y',
                scaleFactor=1.0):
    """
    This is a utility to copy a scaled version of the Tsys values for one
    antenna, one spw, one polarization, to another polarization.  The spw
    number should be the original number in the parent ms.  It automatically
    detects and processes old cal tables (casa 3.3) or new cal tables
    (casa 3.4).
      antenna: integer or string ID, or the name
      spw: integer or string
      frompol: the polarization to copy from
      to pol: the polarization to copy to
      scaleFactor: optional scale factor to apply when copying
    - Todd Hunter
    """
    if (type(antenna) != int):
        if (antenna.isdigit()):
            antenna = int(antenna)
        else:
            mytb = createCasaTool(tbtool)
            mytb.open(calTable)
            keywords = mytb.getkeywords()
            if ('MSName' not in keywords):
                print "This does not appear to be a cal table"
                return
            vis = keywords['MSName']
            mytb.close()
            availableAntennas = parseAntenna(vis,antenna)
            if (availableAntennas is None):
                return
            antenna = availableAntennas[0]
    spw = int(spw)
    pols = ['X', 'Y']  # for now, assume this is always true
    frompol = pols.index(frompol)
    topol = pols.index(topol)
    tb.open(calTable,nomodify=False)
    antennas = tb.getcol('ANTENNA1')
    names = tb.colnames()
    if ('CAL_DESC_ID' not in names):
        spws = tb.getcol('SPECTRAL_WINDOW_ID')
        newCalTable = True
    else:
        spws = tb.getcol('CAL_DESC_ID')  # These start at zero
        tb.close()
        newCalTable = False
        tb.open(calTable+'/CAL_DESC')
        truespws = list(tb.getcol('SPECTRAL_WINDOW_ID')[0])
        tb.close()
        tb.open(calTable,nomodify=False)
    replaced = 0
    if (spw not in spws):
        print "spw %d is not in the caltable (available = %s)" % (spw,str(np.unique(spws)))
        return
    for i in range(len(antennas)):
        if (newCalTable):
            myspw = spw
            colname = 'FPARAM'
        else:
            myspw = truespws.index(spw)
            colname = 'GAIN'
        if (antennas[i] == antenna and spws[i] == myspw):
            print "Replacing row %d" % (i)
            gain = tb.getcell(colname,i)
            if (len(gain) > 2):
                print "This file has more than two polarizations, for which this script has not been tested."
                tb.close()
                return
            if (len(gain) < 2):
                print "This file has less than two polarizations, for which this script cannot be used."
                tb.close()
                return
            gain[topol] = gain[frompol] * scaleFactor
            tb.putcell(colname,i,gain)
            replaced += 1
    #
    tb.close()
    print "Replaced %d rows" % (replaced)

def copyTsys(calTable, fromAntenna, toAntenna, spw='', scan='', scaleFactor=1.0, unflag=False):
    """
    This is a utility to copy a scaled version of the Tsys values from one
    antenna to another antenna.  It automatically detects and processes
    old cal tables (casa 3.3) or new cal tables (casa 3.4).
    Inputs:
      fromAntenna: integer ID or string ID or string name
      toAntenna: integer ID or string ID or string name
      spw: integer, list or integer string (to restrict to one or more spws), -1==>all
      scan: integer, list or integer string (to restrict to one or more scans), -1==>all
      scaleFactor: optional scale factor to apply when copying
      unflag: if True, then also use flagdata to unflag Tsys after copying
    - Todd Hunter
    """
    if (not os.path.exists(calTable)):
        print "Could not find cal table"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(calTable, nomodify=False)
    if (type(fromAntenna) != int):
        if (fromAntenna.isdigit()):
            fromAntenna = int(fromAntenna)
        else:
            vis = mytb.getkeywords()['MSName']
            fromAntenna = parseAntenna(vis,fromAntenna)[0]
    if (type(toAntenna) != int):
        if (toAntenna.isdigit()):
            toAntenna = int(toAntenna)
        else:
            vis = mytb.getkeywords()['MSName']
            toAntenna = parseAntenna(vis,toAntenna)[0]
    spwlist = spw
    if (type(spwlist) != list):
        spwlist = [int(spw)]
    scanlist = scan
    if (type(scanlist) != list):
        scanlist = [int(scan)]
    antennas = mytb.getcol('ANTENNA1')
    names = mytb.colnames()
    if ('CAL_DESC_ID' not in names):
        spws = mytb.getcol('SPECTRAL_WINDOW_ID')
        scans = mytb.getcol('SCAN_NUMBER')
        newCalTable = True
    else:
        spws = mytb.getcol('CAL_DESC_ID')  # These start at zero
        mytb.close()
        newCalTable = False
        mytb.open(calTable+'/CAL_DESC')
        truespws = list(mytb.getcol('SPECTRAL_WINDOW_ID')[0])
        mytb.close()
        mytb.open(calTable,nomodify=False)
    gain = {}
    if (len(np.intersect1d(spwlist, spws)) < 1):
        print "Spw %s not in caltable spws=%s" % (str(spwlist), str(np.unique(spws)))
        return
    if (newCalTable):
        if (len(np.intersect1d(scanlist, scans)) < 1):
            print "Scan %s not in caltable scans=%s" % (str(scanlist), str(np.unique(scans)))
            return
    for i in range(len(antennas)):
        if (newCalTable):
            myspw = spw
            colname = 'FPARAM'
        else:
            myspw = truespws.index(spw)
            colname = 'GAIN'
        if (antennas[i] == fromAntenna and (spws[i] in spwlist or spwlist==[-1])
            and (scans[i] in scanlist or scanlist==[-1])):
            print "Reading from row %d (antenna %d, scan %d, spw %d)" % (i,fromAntenna,scans[i],spws[i])
            if (spws[i] not in gain.keys()):
                gain[spws[i]] = {}
            gain[spws[i]][scans[i]] = mytb.getcell(colname,i)
    replaced = 0
    spwchannels = {}
    for i in range(len(antennas)):
        if (newCalTable):
            myspw = spw
            colname = 'FPARAM'
        else:
            myspw = truespws.index(spw)
            colname = 'GAIN'
        if (antennas[i] == toAntenna and (spws[i] in spwlist or spwlist==[-1])
            and (scans[i] in scanlist or scanlist==[-1])):
            print "Writing to row %d (antenna %d, scan %d, spw %d)" % (i,toAntenna,scans[i],spws[i])
            channels = len(gain[spws[i]][scans[i]][0])
            if (spws[i] not in spwchannels.keys()):
                spwchannels[spws[i]] = channels
            newgain = gain[spws[i]][scans[i]] * scaleFactor
            mytb.putcell(colname,i,newgain)
            replaced += 1
    #
    mytb.close()
    print "Replaced %d rows" % (replaced)
    if (unflag):
        spw = ','.join([str(i) for i in spwlist])
        scan = ','.join([str(i) for i in scanlist])
        print "Running flagdata('%s', mode='unflag', antenna='%d', spw='%s', scan='%s')" % (calTable,toAntenna,spw,scan)
        flagdata(calTable, mode='unflag', antenna=str(toAntenna), spw=spw, scan=scan)
        spwstr = ''
        for spwid in spwchannels.keys():
            if (spwchannels[spwid] <= 256):
                nedge = spwchannels[spwid]*8/128
                spwstr += '%d:0~%d;%d~%d' % (spwid,nedge-1,spwchannels[spwid]-nedge,spwchannels[spwid]-1)
        if (spwstr != ''):
            print "Running flagdata('%s', mode='manual', antenna='%d', spw='%s', scan='%s')" % (calTable,toAntenna,spwstr,scan)
            flagdata(calTable, mode='manual', antenna=str(toAntenna), spw=spwstr, scan=scan)
            

def printQA0Flags(reasons, allPossibleAntennas, verbose=False, 
                  flags=['AFD','PFD'], commands=[], calscans=0):
    """
    Given a list of QA0 reason strings, constructs and prints a summary.
    It is called by the higher-level command: qa0flags.
    -Todd Hunter
    """
    idx = np.where(np.array([x.find('QA0') for x in reasons]) >= 0)[0]
    if verbose:
        if (type(flags) == str):
            flags = flags.split(',')
        for i in idx:
            for f in flags:
                if (reasons[i].find(f) >= 0):
                    if (len(commands) > 0):
                        if (commands[i].find('spw') > 0):
                            # MS
                            print commands[i].split("' spw")[0].replace("antenna='",'').replace("timerange='","").replace("'",""), reasons[i]
                        else:
                            # ASDM
                            print commands[i], reasons[i]
                    else:
                        print reasons[i]
                    break
    print "There are %d QA0 flags in this dataset" % (len(idx))
    flags = ['AFD01','AFD02','AFD03','AFD04','AFD05','AFD06','AFD07','AFD08',
             'PFD01','PFD02','PFD03','PFD04','PFD05','PFD06','PFD07','PFD08','PFD09','PFD10','PFD11']
    descs = ['Trx > spec', 'Trx < 0 or > 1000',
             'Tsys < 0 or > 1e5', 'Tau < 0 or > 10', 
             'flag all scans due too many AFD01-04', 'median/MAD>3', 
             'Trx or Tsys worse than other antennas (> 2*median) ', 
             'Trx differs too much between polarizations (>67% of mean)',
             'Pointing offset > 4 arcsec', 'Pointing uncertainty >> offset',
             'Pointing uncertainty > 0.6 arcsec',
             'Pointing uncertainty > 1/10 beam', 'Systematic offset in pointing', 
             'Pointing offset > 1 MAD from centroid',
             'Pointing offset > 1 MAD from time average', 'Squint', 
             'Pol X offset > 1 MAD from time average',
             'Pol Y offset > 1 MAD from time average',
             'Offset>50% of beam for all scans (must be more than 1)']
             
    afd = len(np.where(np.array([x.find('AFD') for x in reasons[idx]]) > 0)[0])
    pfd = len(np.where(np.array([x.find('PFD') for x in reasons[idx]]) > 0)[0])
    print "%d Atmospheric flags (Trx/Tsys/Tau):" % (afd)
    idx = {}
    first = True
    for i,f in enumerate(flags):
        idx[f] = np.where(np.array([x.find(f) for x in reasons]) >= 0)[0]
        antennas = {}
        for row in idx[f]:
            tokens = reasons[row].split('_')
            for j,t in enumerate(tokens):
                for a in allPossibleAntennas:
                    if (t.find(a) == 0):
                        if (a not in antennas):
                            antennas[a] = {'total': 1}
                        else:
                            antennas[a]['total'] += 1
                        for k,u in enumerate(tokens[j+1:]):
                            if (u.find('(BB') == 0 or u.find('BB')==0):
                                # The next token will hold the baseband number, and possibly pol,scan
                                arg = tokens[j+2+k].rstrip(',').rstrip(')')
                                bbnum = int(arg.split(',')[0])
                                if ('BB%d'%bbnum not in antennas[a]):
                                    antennas[a]['BB%d'%(bbnum)] = 1
                                else:
                                    antennas[a]['BB%d'%(bbnum)] += 1
        if (f.find('PFD01') >= 0 and first):
            print "%d Pointing flags:" % (pfd)
            first = False
        if (len(idx[f]) > 0):
            spacing = 16
            print "%6d %s: %s" % (len(idx[f]), f, descs[i])
            if (f == 'AFD05'): 
                for j in range(len(idx[f])):
                    print '%s%s' % (spacing*' ',reasons[idx[f][j]])
            string = spacing*' '
            badAntennas = sorted(antennas.keys())
            if (calscans > 0):
                possible = '/%d' % (calscans)
            else:
                possible = ''
            for a in badAntennas:
                if (f.find('AFD') >= 0):
                    # if BB-related
                    string = spacing*' ' + '%3d '%(antennas[a]['total']) + a + ': '
                    for b in sorted(antennas[a].keys()):
                        if (b != 'total'):
                            string += b + ': %2d%s,  ' % (antennas[a][b],possible)
                    print string.rstrip(',')
                    string = ''
                else:    
                    # if not BB-related (i.e. pointing)
                    string += '%s: %2d,  ' % (a, antennas[a]['total']) 
                    if (len(string) > 68 and a != badAntennas[-1]): 
                        print string.rstrip().rstrip(',')
                        string = spacing*' '
            if (len(string.strip()) > 0): 
                print string.rstrip().rstrip(',')

def applyQA0FlagsToCaltable(caltable, vis='', tbuff=0.002):
    """
    Reads the FLAG_CMD column from a measurement set, writes an ASCII text
    file using the flagcmd task, filters out the non-QA0 flags from the file, 
    and then applies it to a caltable using the flagdata task.
    -Todd Hunter
    """
    if (not os.path.exists(caltable)):
        print "Could not find caltable"
        return
    if (vis == ''):
        vis = getMeasurementSetFromCaltable(caltable)
    if (not os.path.exists(vis)):
        print "Could not find associated measurement set = ", vis
        return
    flagtable = vis+'.flagcmd.txt'
    os.system('rm '+flagtable)
    flagcmd(vis, useapplied=True, action='list', savepars=True,
            outfile=flagtable, flagbackup=False)
    remaining = removeLines(flagtable, keys='QA0', negate=True)
    if (remaining > 0):
        flagdata(caltable, action='apply', inpfile=flagtable, 
                 flagbackup=False, tbuff=tbuff, mode='list')
    else:
        print "There were no QA0 flags in this dataset."

def atmcalScansFromASDM(asdm):
    """
    Returns a list of atmospheric calibration scans in an ASDM.
    -Todd Hunter
    """
    mydict = readscans(asdm)[0]
    scans = mydict.keys()
    calscans = []
    for scan in scans:
        if (mydict[scan]['intent'].find('ATMOSPHERE') >= 0):
            calscans.append(scan)
    return(calscans)

def numberOfPolarizationsInSyscalXML(asdm):
    """
    Reports the number of polarizations in the SysCal.xml file of the
    specified ASDM.
    -Todd Hunter
    """
    if os.path.exists(asdm+'/SysCal.xml'):
        mydict = getTsysFromSysCal(asdm)
        if mydict is None:
            return
        spws = mydict[0].keys()
        scans = mydict[0][spws[0]]['scans'].keys()
        npol = len(mydict[0][spws[0]]['scans'][scans[0]].keys())
    else:
        print "SysCal.xml does not exist.  Assuming 2 polarizations."
        npol = 2
    return npol

def numberOfPolarizationsInSyscalTable(vis):
    """
    Reports the number of polarizations in the SYSCAL table of the
    specified measurement set.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set."
        return
    mytb = createCasaTool(tbtool)
    syscal = vis
    if (vis.find('SYSCAL') < 0):
        syscal += '/SYSCAL'
    mytb.open(syscal)
    n = len(mytb.getcell('TSYS_SPECTRUM',0))
    mytb.close()
    return n

def qa0flags(dataset, verbose=False, flags=['AFD','PFD'], listThresholdMinutes='half', autoExport=True):
    """
    Summarizes the number of QA0 flags of different types in a measurement set.
    dataset: ASDM or measurement set
    verbose: if True, then print all of them to the screen, first.
    listThresholdMinutes: value in minutes, or 'half' for half the length of the dataset
    flags: restrict flags to show to those with names containing these strings
           (if verbose==True)
    Todd Hunter
    """
    if (not os.path.exists(dataset)):
        if autoExport:
            asdmExport(dataset,'-m')
            if (not os.path.exists(dataset)):
                print "Could not export dataset from archive."
                return
        else:
            print "Could not find dataset on disk."
            return
    if (not os.path.exists(dataset+'/Flag.xml')):  # measurement set
        if (not os.path.exists(dataset+'/table.dat')):
            print "This does not appear to be an ASDM nor a measurement set."
            return
        mytb = createCasaTool(tbtool)
        mytb.open(dataset+'/FLAG_CMD')
        commands = mytb.getcol('COMMAND')
        reasons = mytb.getcol('REASON')
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(dataset)
        allPossibleAntennas = mymsmd.antennanames()
        calscans = len(mymsmd.scansforintent('*ATMOSPHERE*'))
        npol = numberOfPolarizationsInSyscalTable(dataset)
        calscans *= npol
        mymsmd.close()
    else:  # ASDM
        flag = dataset + '/Flag.xml'
        xmlscans = minidom.parse(flag)
        rowlist = xmlscans.getElementsByTagName("row")
        reasons = []
        commands = []
        durations = []
        tsys = 0
        tsysAntennas = []
        tsysBasebands = []
        tsysPols = []
        trx = 0
        trxAntennas = []
        trxBasebands = []
        trxPols = []
        totalAntennas = len(readAntennasFromASDM(dataset, verbose=False))
        for i,rownode in enumerate(rowlist):
            rowStart = rownode.getElementsByTagName("startTime")
            rowEnd = rownode.getElementsByTagName("endTime")
            rowReason = rownode.getElementsByTagName("reason")
            reasons.append(str(rowReason[0].childNodes[0].nodeValue).strip().replace(' ','_'))
            if reasons[i].find('AFD05') > 0:
                if reasons[i].find('TSYS') > 0:
                    tsys += 1
                    tsysAntennas.append(reasons[i].split('Ant_')[1].split('_')[0])
                    tsysBasebands.append(int(reasons[i].split('(BB_')[1].split(')')[0]))
                    tsysPols.append(reasons[i].split('_Pol_')[1].split('_')[0])
                elif reasons[i].find('TRX') > 0:
                    trx += 1
                    trxAntennas.append(reasons[i].split('Ant_')[1].split('_')[0])
                    trxBasebands.append(int(reasons[i].split('(BB_')[1].split(')')[0]))
                    trxPols.append(reasons[i].split('_Pol_')[1].split('_')[0])
            startTime = mjdNanosecondsToMJDandUT(int(rowStart[0].childNodes[0].nodeValue),prec=9,delimiter='/')[1].rstrip(' UT')
            endTime = mjdNanosecondsToMJDandUT(int(rowEnd[0].childNodes[0].nodeValue),prec=9,delimiter='/')[1].rstrip(' UT')
            commands.append(startTime + '~' + endTime)
            durations.append(dateStringDifference(startTime, endTime))
        reasons = np.array(reasons)
        calscans = len(atmcalScansFromASDM(dataset))
        minutes = np.array(durations)
        if listThresholdMinutes == 'auto':
            listThresholdMinutes = 0.5*getObservationLengthFromASDM(dataset)
        idxThreshold = np.where(minutes >= listThresholdMinutes)[0]
        idx = np.argsort(minutes)[::-1]
        if (len(idxThreshold) < 1):
            print "Longest flag = %g minutes (row %d: %s)" % (minutes[idx[0]],idx[0],reasons[idx[0]])
            print "Shortest flag = %g minutes (row %d: %s)" % (minutes[idx[-1]],idx[-1],reasons[idx[-1]])
        else:
            tsysAntennas = np.unique(tsysAntennas)
            trxAntennas = np.unique(trxAntennas)
            tsysBasebands = np.unique(tsysBasebands)
            trxBasebands = np.unique(trxBasebands)
            tsysPols = np.unique(tsysPols)
            trxPols = np.unique(trxPols)
            print "Num. of long Tsys flags: %d, unique antennas: %d/%d, basebands: %s %s" % (tsys,len(tsysAntennas),totalAntennas,tsysBasebands,tsysPols)
            print "Num. of long Trx  flags: %d, unique antennas: %d/%d, basebands: %s %s" % (trx,len(trxAntennas),totalAntennas,trxBasebands,trxPols)
        npol = numberOfPolarizationsInSyscalXML(dataset)
        calscans *= npol
        allPossibleAntennas = readAntennasFromASDM(dataset, verbose=False)
    printQA0Flags(reasons, allPossibleAntennas, verbose, flags, commands, 
                  calscans)

def fixPythonScript(script, keeponly=['setjy']):
    """
    If a line does not end in a comma, then truncate at the prior comma,
    and insert the remainder on the next line.
    keeponly:  if set, then only keep the command calls in this list
    -Todd Hunter
    """
    f = open(script,'r')
    lines = f.readlines()
    f.close()
    f = open(script.replace('.py','_fixed.py'), 'w')
    removeSpaces = False
    skipToNextCommand = False
    for line in lines:
        if keeponly != '':
            if skipToNextCommand:
                if (line.find(')') >= 0):
                    skipToNextCommand = False
                continue
            elif (line.find('(') >= 0):
                command = line.lstrip().split('(')[0]
                if command not in keeponly:
                    skipToNextCommand = True
                    continue
        if (len(line) < 2):
            f.write(line)
        elif (line[-2] != ',' and line[-2] != ')'):
            print "Offending line: ", line
            tokens = line.split(",")
            finalToken = tokens[-1]
            f.write(line.split(finalToken)[0] + '\n')
            f.write(finalToken[:-1])
            removeSpaces = True
        else:
            if removeSpaces:
                line = line.lstrip()
            f.write(line)
            removeSpaces = False
    f.close()

def filterOutLines(filename, string):
    """
    Remove lines from a file that match a specified string.
    Does not attempt to make a backup, so please beware.  If you want
    that capability, see au.removeLines
    -Todd Hunter
    """
    import fileinput
    filtered = 0
    for line in fileinput.input(r'%s'%(filename), inplace = True):
        if not re.search(r'\b%s\b'%(string),line):
            print line,
        else:
            filtered += 1
    print "Removed %d lines" % (filtered)

def removeLines(filename, keys=['QA0','HIGH_RMS','HIGHER'], negate=False):
    """
    Remove the lines of an ASCII file that contain a specified string, or any
    string from a list of strings.  The original file is first copied to *.bak.
    keys: a single string, or a list of strings
    negate: if True, then remove lines that do NOT have these strings
    Returns: the number of lines remaining
    """
    if (not os.path.exists(filename)):
        print "Could not find file = ", filename
        return
    shutil.copyfile(filename, filename+'.bak')
    f = open(filename,'r')
    lines = f.readlines()
    f.close()
    f = open(filename,'w')
    removed = 0
    if (type(keys) != list):
        keys = [keys]
    for line in lines:
        found = False
        for key in keys:
            if (line.find(key) >= 0):
                found = True
                break
        if negate:
            if found:
                f.write(line)
            else:
                removed += 1
        else:
            if found:
                removed += 1
            else:
                f.write(line)
    f.close()
    print "Removed %d lines" % (removed)
    remaining = len(lines) - removed
    print "Remember to change the flagcmd in your script to: inpmode='list', inpfile='%s'" % (filename)
    return(remaining)

def pruneFilelist(filelist):
    """
    Reduce size of filenames in filelist to the extent that current working
    directory agrees with the path.
    """
    mypwd = os.getcwd() + '/'
    newfilelist = []
    for f in filelist:
        f = f.replace('//','/')
        fstart = 0
        if (f.find(mypwd) == 0):
            fstart = len(mypwd)
        newfilelist.append(f[fstart:])
    return(newfilelist)
    
def concatenatePDFs(filelist, pdfname, pdftk='pdftk', gs='gs', cleanup=False,
                    quiet=False, papersize='', writeCommand=False):
    """
    Takes a list or a string list of PDF filenames (space-delimited), and an
    output name, and concatenates them.
    It first tries pdftk (better quality), and if that fails, it tries
    ghostscript (more commonly installed).
    Todd Hunter
    """
    if (type(filelist) == list):
        filelist = ' '.join(filelist)
    cmd = '%s %s cat output %s' % (pdftk, filelist, pdfname)
    concatScript = pdfname+'_concatenate.sh'
    if writeCommand:
        f = open(concatScript,'w')
        f.write('#!/bin/sh\n')
        f.write(cmd+'\n')
        f.close()
        os.system('chmod +x %s'%concatScript)
    cmds = [cmd]
    pipeCharacterLimit = 131072
    if (len(cmd) >= pipeCharacterLimit): # character limit in linux pipe
        print "Command string argument too long (%d), splitting into multiple commands." % (len(cmd))
        filelist = filelist.split()
        splitCounter = 2
        chunk = int(round(len(filelist)/float(splitCounter)))
        myfilelist = [' '.join(filelist[:chunk]), ' '.join(filelist[chunk:])]
        nfiles = [len(filelist[:chunk]), len(filelist[chunk:])]
        withinBounds = True
        for i in range(splitCounter):
            if len(myfilelist[i]) +len(pdftk)+18 > pipeCharacterLimit:
                withinBounds = False
        while not withinBounds:
            splitCounter += 1
            chunk = int(round(len(filelist)/float(splitCounter)))
            myfilelist = []
            nfiles = []
            for i in range(splitCounter):
                if i < splitCounter-1:
                    myfilelist += [' '.join(filelist[i*chunk:(i+1)*chunk])]
                    nfiles += [len(filelist[i*chunk:(i+1)*chunk])]
                else:
                    # final one might not be as long as the rest
                    myfilelist += [' '.join(filelist[i*chunk:])]
                    nfiles += [len(filelist[i*chunk:])]
            withinBounds = True
            for i in range(splitCounter):
                if len(myfilelist[i]) +len(pdftk)+18 > pipeCharacterLimit:
                    withinBounds = False
        cmds = []
        finalConcat = ''
        for j in range(len(myfilelist)):
            cmds += ['%s %s cat output %d.pdf' % (pdftk, myfilelist[j], j)]
            print "Command %d has %d files (%d chars)" % (j, nfiles[j], len(cmds[j]))
            finalConcat += '%d.pdf ' % (j)
            if len(cmds[j]) > pipeCharacterLimit:
                print "Command string argument still too long (%d), need to modify au.concatenatePDFs to split job further." % (len(cmds[j]))
                return(-1)
        cmds += ['%s %s cat output %s' % (pdftk, finalConcat, pdfname)]
    mystatus = 0
    if writeCommand:
        f = open(concatScript,'w')
        f.write('#!/bin/sh\n')
    for i,mycmd in enumerate(cmds):
        if writeCommand:
            f.write(mycmd+'\n')
        if not quiet: 
            print "Running command = %s (%d of %d)" % (mycmd,i+1,len(cmds))
        mystatus += os.system(mycmd)
        if (i+1 == len(cmds) and i>0):
            for j in range(len(myfilelist)):
                if os.path.exists('%d.pdf'%j): os.remove('%d.pdf'%j)
    if writeCommand:
        f.close()
        os.system('chmod +x %s'%concatScript)
    if (mystatus != 0):
        # Try a different directory - this doesn't have the generic length solution yet.
        pdftk = '/opt/local/bin/pdftk'
        cmd = '%s %s cat output %s' % (pdftk, filelist, pdfname)
        cmds = [cmd]
        if (len(cmd) >= 131072): # character limit in linux pipe
            print "Command string argument too long (%d), splitting into two commands." % (len(cmd))
            cmds  = ['%s %s cat output 0.pdf' % (pdftk, filelist0)]
            cmds += ['%s %s cat output 1.pdf' % (pdftk, filelist1)]
            cmds += ['%s 0.pdf 1.pdf cat output %s' % (pdftk, pdfname)]
        mystatus = 0
        for i,cmd in enumerate(cmds):
            if not quiet: print "Running command = %s (%d of %d)" % (cmd, i+1, len(cmds))
            mystatus += os.system(cmd)
            if (i+1 == len(cmds) and i>0):
                if os.path.exists('0.pdf'): os.remove('0.pdf')
                if os.path.exists('1.pdf'): os.remove('1.pdf')
        if (mystatus != 0):
            if (gs == ''):
                print "Since os.system(%d chars) failed, trying to run from script: " % (len(cmd)), concatScript
                os.system('./'+concatScript)
                if os.path.exists(pdfname):
                    print "Success, setting mystatus=0"
                    mystatus = 0
            else:
                if (papersize != ''):
                    papersize = '-sPAPERSIZE='+papersize
                print "status = ", mystatus
                cmd = '%s -q %s -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=%s %s' % (gs,papersize,pdfname,filelist)
                print "Running command = %s" % (cmd)
                mystatus = os.system(cmd)
                if (mystatus != 0):
                    gs = '/opt/local/bin/gs'
                    cmd = '%s -q %s -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=%s %s' % (gs,papersize,pdfname,filelist)
                    print "Running command = %s" % (cmd)
                    mystatus = os.system(cmd)
                    if (mystatus != 0):
                        print "concatenatePDFs(): Both pdftk and gs are missing, no PDF created."
                        cleanup = False
    if (cleanup):
        os.system('rm %s' % filelist)
    return (mystatus)

def fixvisPermissions(vis, write=False, dryrun=False):
    """
    Adds read+execute permission to all subdirectories of a measurement set
    for all users (owner, group, other)
    write: if True, then add write permission as well (e.g. 'drwxrwxrwx')
    dryrun: if True, then only list the commands, do not run them
    -Todd Hunter
    """
    files = glob.glob(vis+'/*')
    for f in files:
        if os.path.isdir(f):
            if write:
                cmd = 'chmod +rx %s' % (f)
            else:
                cmd = 'chmod +rwx %s' % (f)
            print cmd
            if not dryrun:
                os.system(cmd)

def plotSomeBaselines(vis, spw, antenna, scan='', intent='*BANDPASS*', yaxis='amp', xaxis='time', 
                      ydatacolumn='data', avgchannel='8000', coloraxis='corr', plotfile='', 
                      pdfname='', overwrite=True):
    """
    Plots a list of baselines with one baseline per output png.
    antenna: should be a list of baselines:  'DA55&DA56;DA47&DA43', will be split on ;
    """
    baselines = antenna.split(';')
    pngs = []
    for baseline in baselines:
        if plotfile == '':
            myplotfile = vis+'_%s.png' % (baseline)
        elif (plotfile.find('.png') >= 0):
            myplotfile = plotfile.replace('.png','_%s.png'%baseline)
        else:
            myplotfile += '_%s.png'%baseline
        plotms(vis, spw=spw, antenna=baseline, scan=scan, intent=intent, xaxis=xaxis, yaxis=yaxis,
               ydatacolumn=ydatacolumn, avgchannel=avgchannel, coloraxis=coloraxis, plotfile=myplotfile, 
               showgui=False, overwrite=overwrite, title=vis+' spw%s %s' % (spw,baseline))
        pngs.append(myplotfile)
    if pdfname == '':
        pdfname = vis+'.pdf'
    buildPdfFromPngs(pngs, pdfname=pdfname)
    print "Wrote ", pdfname
                      
def plotBaselinesOneScan(vis, spw, scan, xaxis='time', yaxis='phase', 
                         correlation='', iteraxis='spw',coloraxis='corr',
                         plotrange=[0,0,0,0], pdfname='', antenna='',
                         debug=False, customflaggedsymbol=False,title='',
                         flaggedsymbolshape='nosymbol', avgchannel='10000',
                         xsharedaxis=False, ysharedaxis=False,showgui=False,
                         repeatBaselines=False, onlybuildpdf=False,
                         dropAntennas=[], overwritePdfs=True,gs='gs',gridcols=1,
                         avgtime='', antennaBased=False, maxAntennas=0):
    """
    A convenient wrapper for plotms to show all specified spws on a grid
    on one page (per baseline).
    antenna: a list of antenna names to include (default = all)
    repeatBaselines: if True, then show each baseline twice, in order in the
          list for both component antennas
    onlybuildpdf: if True, then assume that all the pngs already exist
           and so do not run plotms
    dropAntennas: do not display any baselines for these antennas
    overwritePdfs: overwrite single-page PDFs (passed to buildPdfFromPngs)
    antennaBased: if True, then only generate one plot per antenna
    gridcols: ignored if antennaBased==True, it is then calculated automatically
    iteraxis: ignored if antennaBased==True, it is set to blank
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not open measurement set"
        return
    overwrite = True
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    allAntennaNames = mymsmd.antennanames()
    if (antenna == '' or antenna == '*&*'):
        antennaNames = allAntennaNames
    else:
        antennaNames = antenna.split(',')
    pngs = []
    if (type(spw) == list):
        spwlist = spw
        spw = ','.join(spwlist)
    elif (type(spw) == str):
        spwlist = [int(i) for i in spw.split(',')]
    else:
        print "spw must be a comma-delimited string or an integer list"
        return
    nspw = len(spwlist)
    basebands = []
    for myspw in spwlist:
        basebands.append(mymsmd.baseband(myspw))
    mymsmd.close()
    if antennaBased:
        nAntennas = len(antennaNames)
        if maxAntennas > 0:
            nAntennas = maxAntennas
            antennaNames = antennaNames[:maxAntennas]
        gridcols = np.floor(sqrt(nAntennas))
        gridrows = int(np.ceil(nAntennas/gridcols))
        gridcols = int(gridcols)
        iteraxis = ''
        print "Plotting %d antennas on one page." % (len(antennaNames))
    else:
        gridrows = int(np.ceil(1.0*nspw/gridcols))
        print "Plotting %d spws on one page per baseline. Set antennaBased=True to plot 1 spw with all antennas on one page." % (nspw)
    plotindex = -1
    colindex = -1
    rowindex = 0
    for i,a1 in enumerate(allAntennaNames):
        if (a1 in antennaNames):
            if (repeatBaselines or antenna != ''):
                j = 0
            else:
                j = i+1
            if antennaBased:
                plotindex += 1 
                colindex += 1
                if colindex >= gridcols:
                    colindex = 0
                    rowindex += 1
                iterAntenna = '*'
                plotfile = vis + '.scan%s.png' % (str(scan))
                clearplots = False
                if plotfile not in pngs:
                    pngs.append(plotfile)
            else:
                plotindex = 0
                rowindex = 0
                plotindex = 0
                clearplots = True
                iterAntenna = allAntennaNames[j:]
            for a2 in iterAntenna:
                if (a2 != a1 and a1 not in dropAntennas and a2 not in dropAntennas):
                    if not antennaBased:
                        plotfile = vis + '.%s_%s.png' % (a1,a2)
                        fullplotfile = plotfile.replace('.png','_Spw%s.png'%spw)
                        if fullplotfile not in pngs:
                            pngs.append(fullplotfile)
                    if (not onlybuildpdf):
                        title = a1 + ' & ' + a2
                        if (a2 != '*'):
                            baselineLength = getBaselineLength(vis,a1,a2,verbose=False)[0]
                            title += ' (%dm)'% (int(np.round(baselineLength)))
                        print "Running plotms(vis='%s',spw='%s',xaxis='%s',yaxis='%s',correlation='%s',antenna='%s&%s',gridrows=%d,gridcols=%d,plotrange=%s,title='%s',xsharedaxis=%s,ysharedaxis=%s,scan='%s',coloraxis='%s',plotfile='%s',iteraxis='%s',overwrite=%s,showgui=%s,flaggedsymbolshape='%s',avgchannel='%s',avgtime='%s',clearplots=%s,plotindex=%d,rowindex=%d,colindex=%d)" % (vis,spw,xaxis,yaxis,correlation,a1,a2,gridrows,gridcols,plotrange,title,xsharedaxis,ysharedaxis,str(scan),coloraxis,plotfile,iteraxis,overwrite,showgui,flaggedsymbolshape,avgchannel,avgtime,clearplots or i==0,plotindex,rowindex,colindex)
                        plotms(vis=vis, spw=spw, xaxis=xaxis, yaxis=yaxis, correlation=correlation,
                           antenna='%s&%s'%(a1,a2), gridrows=gridrows, gridcols=gridcols, plotrange=plotrange,
                           title=title, xsharedaxis=xsharedaxis, ysharedaxis=ysharedaxis,
                           scan=str(scan), coloraxis=coloraxis,
                           plotfile=plotfile, customflaggedsymbol=customflaggedsymbol,
                           iteraxis=iteraxis, overwrite=overwrite, showgui=showgui,
                           flaggedsymbolshape=flaggedsymbolshape, avgchannel=avgchannel, 
                               avgtime=avgtime, clearplots=clearplots or i==0, plotindex=plotindex,
                               rowindex=rowindex, colindex=colindex)
        else:
            print "%s not in %s" % (a1, antennaNames)
    if (len(pngs) > 0):
        if (pdfname == ''):
            pdfname = vis + '.phase_vs_time.pdf'
        buildPdfFromPngs(pngs, pdfname=pdfname, overwritePdfs=overwritePdfs, gs=gs)

def plotBaselinesSorted(vis, plotfile, spw, scan='',xaxis='freq',yaxis='phase', 
                        correlation='XX', antenna='0&*', title='', 
                        iteraxis='baseline',overwrite=True,avgtime='1e8',avgscan=False,
                        plotrange=[0,0,-180,180], pdfname='', maxrows=4,
                        field='',debug=False,customflaggedsymbol=False,showgui=False,
                        coloraxis='', flaggedsymbolshape='nosymbol', avgchannel='',
                        maxpages=-1, maxplots=-1, sort=True, overwritePdfs=True,
                        projected=True,ydatacolumn='',exportTextFiles=False,
                        fitPhaseVsFrequency=False):
    """
    Runs plotms for every baseline, sorts by baseline and compiles into
    a PDF.
    antenna: ID; if set to '', then all baselines will be plotted
    overwrite: if True, then re-create an image if it already exists
    maxplots: maximum number of PNGs to create
    maxpages: maximum number of pages in the PDF to produce
    sort: if True, then sort by baseline length
    field: the field parameter to pass to plotms (string name or ID)
    projected: if True, then use the projected baseline length of the
               (first) specified field
    exportTextFiles: if True, then also export the plots to text files
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if (projected and field == ''):
        print "With option projected=True, you must specify a field."
        return
    originalAntenna = antenna
    originalPlotfile = plotfile
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    allAntennas = mymsmd.antennaids()
    antennanames = mymsmd.antennanames(allAntennas)
    mymsmd.close()
    if antenna == '':
        antennaList = allAntennas
    else:
        if (type(antenna) == str):
            if (antenna == '*&*'):
                antennaList = allAntennas
            else:  # assume '3&*'
                antennaList = parseAntenna(vis,antenna.split('&')[0])
        elif (type(antenna) == list):
            antennaList = antenna
        else:
            antennaList = [int(antenna)]
    pngs = []
    print "antennaList = ", antennaList
    baselineLengths = []
    if (type(scan) == list):
        scans = ','.join([str(i) for i in scan])
    else:
        scans = str(scan)
    if (type(field) != str):
        field = str(field)
    if (projected):
        mydict = getBaselineLengths(vis, field=field.split(',')[0])
    firstCommand = True
    avgchannel = str(avgchannel)
    if (fitPhaseVsFrequency):
        os.system('rm *.txt')
    for n,i in enumerate(antennaList):
        print "Starting antenna %s (%d of %d)" % (antennanames[i], n+1, len(antennaList))
        for j in allAntennas:
            if (i == j): continue
            if (len(antennaList) == len(allAntennas) and j<i): continue
            ant = '%02d&%02d' % (i,j)
            antname = '%s_with_%s' % (antennanames[i], antennanames[j])
            if (projected):
                ants = sorted([antennanames[i],antennanames[j]])
                baselineName = '%s-%s' % (ants[0], ants[1])
                if debug:
                    print "baselineName = ", baselineName
                    print "np.where() = ", np.where(np.array(mydict)[:,0] == baselineName)
                baselineLengths.append(mydict[np.where(np.array(mydict)[:,0] == baselineName)[0]][1])
            else:
                baselineLengths.append(getBaselineLength(vis, i, j, verbose=False)[0])
            title = antname + ' (%.0fm)' % (baselineLengths[-1])
            plotfile = originalPlotfile.rstrip('.png') + '_%s_%.0f.png' % (antname,baselineLengths[-1])
            if (correlation != ''):
                title += ' %s pol' % correlation
            if (not os.path.exists(plotfile) or overwrite):
                if (debug or firstCommand):
                    print "Running plotms('%s', spw='%s', xaxis='%s', yaxis='%s', correlation='%s', antenna='%s', plotrange=%s, title='%s', scan='%s', plotfile='%s', field='%s', customflaggedsymbol=%s, overwrite=%s, showgui=%s, flaggedsymbolshape='%s', avgchannel='%s', coloraxis='%s', ydatacolumn='%s', avgtime='%s', avgscan=%s)" % (vis, str(spw), xaxis, yaxis, correlation, ant, str(plotrange), title, scans, plotfile, field, customflaggedsymbol, overwrite, showgui, flaggedsymbolshape, avgchannel, coloraxis, ydatacolumn,avgtime,avgscan)
                    firstCommand = False
                plotms(vis, spw=str(spw), xaxis=xaxis, yaxis=yaxis, 
                       correlation=correlation, antenna=ant, coloraxis=coloraxis,
                       plotrange=plotrange, title=title, scan=scans,
                       plotfile=plotfile, field=field, customflaggedsymbol=customflaggedsymbol,
                       overwrite=overwrite, showgui=showgui, ydatacolumn=ydatacolumn,
                       flaggedsymbolshape=flaggedsymbolshape, avgchannel=avgchannel,
                       avgtime=avgtime,avgscan=avgscan)
            if (exportTextFiles or fitPhaseVsFrequency):
                textfile = plotfile.replace('.png','.txt') 
                if (not os.path.exists(textfile) or overwrite):
                    plotms(vis, spw=str(spw), xaxis=xaxis, yaxis=yaxis, 
                           correlation=correlation, antenna=ant, coloraxis=coloraxis,
                           plotrange=plotrange, title=title, scan=scans,
                           plotfile=textfile,
                           field=field, customflaggedsymbol=customflaggedsymbol,
                           overwrite=overwrite, showgui=showgui, ydatacolumn=ydatacolumn,
                           flaggedsymbolshape=flaggedsymbolshape, avgchannel=avgchannel,
                           avgtime=avgtime,avgscan=avgscan)
            if (os.path.exists(plotfile)):
                pngs.append(plotfile)    
                if (maxplots > 0 and len(pngs) == maxplots):
                    break
            else:
                print "No plot created for %s.  Are all data flagged?" % (antname)
        if (maxplots > 0 and len(pngs) == maxplots):
            break
    if (pdfname == ''):
        if originalAntenna != '':
            if (type(antenna) == str):
                antennaArg = antenna.replace('*','All').replace('&','with')
            else:
                antennaArg = antennanames[antenna]+'withAll'
            if (maxpages < 0):
                pdfname = vis+'.%s.scan%s.baselines_%ss.pdf' % (antennaArg,scan,yaxis)
            else:
                pdfname = vis+'.%s.scan%s.baselines_%ss.%dpages.pdf' % (antennaArg,scan,yaxis,maxpages)
        else:
            pdfname = vis+'.scan%s.baseline_%ss.pdf' % (scan,yaxis)
    if (len(pngs) > 0):
        pngs = np.array(pngs)
        if (sort):
            pngs = pngs[np.argsort(baselineLengths)]
        if (len(pngs) >= maxpages and maxpages > 0):
            pngs = pngs[:maxpages]
        buildPdfFromPngs(pngs, pdfname=pdfname, overwritePdfs=overwritePdfs)
    if (fitPhaseVsFrequency):
        print "Fitting txt files for phase vs. frequency"
        png = linfitFromFiles('*.txt', title=vis)
        print "Plot left in ", png
            
def plotBaselinesPerScan(vis, spw, scan=[], xaxis='freq', yaxis='phase', 
                         correlation='XX', antenna='0&*', gridrows=None,
                         gridcols=None, iteraxis='baseline',
                         plotrange=[0,0,-180,180], pdfname='', maxrows=4,
                         field='',allscansTogether=False, debug=False,
                         customflaggedsymbol=False, coloraxis='',
                         flaggedsymbolshape='nosymbol', avgchannel='',
                         xsharedaxis=False, ysharedaxis=False,showgui=False,
                         avgtime=''):
    """
    A convenient wrapper for plotms to show all baselines to a given antenna
    on one page.  
    scan: if more than one, it builds a multi-page pdf of one scan at a time
    allscansTogether: if True, then overlay all scans specified in the scan list
    antenna:  if '', then make build a multi-page pdf with each antenna on 
              successive pages
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not open measurement set"
        return
    overwrite = True
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    nantennas = mymsmd.nantennas()
    antennaNames = mymsmd.antennanames()
    scannumbers = mymsmd.scannumbers()
    if (scan == []):
        scans = scannumbers
    elif (type(scan) != list and type(scan) != np.ndarray and type(scan) != str):
        scans = [int(scan)]
    elif (type(scan) == str):
        if (scan.find('~') >= 0):
            scans = scan.split('~')
            if (scans[1] != ''):
                scans = range(int(scans[0]), int(scans[1])+1)
            else:
                scans = range(int(scans[0]), scannumbers[-1])
        else:
            scans = [int(i) for i in scan.split(',')]
    else:
        scans = scan
    mymsmd.close()
    if (gridrows==None):
        gridrows = int(sqrt(nantennas))
        if (gridrows > maxrows):
            gridrows = maxrows
        gridcols = int(np.ceil(nantennas / gridrows))
    pngs = []
    originalAntenna = antenna
    if (allscansTogether):
        scans = [','.join([str(s) for s in scans])]
    for s in scans:
        if (antenna == ''):
            antennas = [i+'&*' for i in antennaNames]
        else:
            antennas = [antenna]
        for i,antenna in enumerate(antennas):
            if debug:
                print "plotting antenna='%s', scan=%s" % (antenna,str(s))
            antennaArg = antenna.replace('*','All').replace('&','with')
            if (allscansTogether):
                scantext = 'all'
                title = 'all scans'
            else:
                scantext = str(s)
                title = 'Scan '+str(s)
            plotfile = vis + '.%s.scan%s.baseline_%ss.png' % (antennaArg,scantext,yaxis)
            if debug:
                print "Running plotms(vis='%s', spw='%s', xaxis='%s', yaxis='%s', correlation='%s', antenna='%s', \\" % (vis,str(spw),xaxis,yaxis,correlation,antenna)
                print "   gridrows=%d, gridcols=%d, plotrange=%s, title='%s', \\" % (gridrows, gridcols,str(plotrange), title)
                print "   xsharedaxis=%s, ysharedaxis=%s, scan='%s', plotfile='%s', \\" % (xsharedaxis, ysharedaxis, str(s), plotfile)
                print "   field='%s', customflaggedsymbol=%s, iteraxis='%s', overwrite=%s, \\" % (field,customflaggedsymbol, iteraxis, overwrite)
                print "   showgui=%s, flaggedsymbolshape='%s', avgchannel='%s', coloraxis='%s', avgtime='%s')" % (showgui,flaggedsymbolshape,avgchannel,coloraxis,avgtime)
            plotms(vis=vis, spw=str(spw), xaxis=xaxis, yaxis=yaxis, correlation=correlation,
               antenna=antenna, gridrows=gridrows, gridcols=gridcols, plotrange=plotrange,
                   title=title, xsharedaxis=xsharedaxis, ysharedaxis=ysharedaxis,
                   scan=str(s), coloraxis=coloraxis,
                   plotfile=plotfile, field=field,customflaggedsymbol=customflaggedsymbol,
                   iteraxis=iteraxis, overwrite=overwrite, showgui=showgui,
                   flaggedsymbolshape=flaggedsymbolshape, avgchannel=avgchannel, avgtime=avgtime)
            pngs.append(plotfile)
    if pdfname == '':
        if originalAntenna != '':
            pdfname = vis+'.%s.scan%s.baselines_%ss.pdf' % (antennaArg,scan,yaxis)
        else:
            pdfname = vis+'.scan%s.baseline_%ss.pdf' % (scan,yaxis)
    if (len(pngs) > 0):
        buildPdfFromPngs(pngs, pdfname=pdfname)

def plotSamplersWithTsys(vis, caltable=None, channels=20, scan=None, filter='',
                         skipPlotbandpass=False, skipPlotms=False, markersize=10,
                         showatm=False):
    """
    Runs Atmcal, checkSamplers, plotbandpass, plotms, and montageTwoPngLists
    in order to create side-by-side plots of the autocorrelation on the sky
    subscan of the first ATM calibration scan (or a specified scan) and the
    corresponding Tsys, near channel zero.
    channels: The number of channels to show on the x-axis
    scan: the scan number to use
    filter: an antenna name to skip (e.g. when Tsys has no solutions for it)
    skipPlotbandpass: do not remove or generate Tsys plots
    skipPlotms: do not generate autocorrelation amplitude plots
    markersize: size of the points in the plotbandpass plots
    showatm: pass this option to plotbandpass
    Todd Hunter
    """
    if (caltable is None):
        caltable = vis+'.tsys'
        if (os.path.exists(caltable) == False):
            gencal(vis, caltype='tsys', caltable=caltable)
    elif (os.path.exists(caltable) == False):
        print "Could not find caltable."
        return
    else:
        print "Found caltable."
    atmcal = Atmcal(vis)
    if (scan is None):
        scan = atmcal.scans[0]
    scans = str(scan)
    if (scan not in atmcal.scans):
        print "This scan is not an ATM cal scan.  Try: %s" % (str(atmcal.scans))
        return
    spwlist = ','.join(str(atmcal.spwsforscan_nonchanavg[scan]).strip('[').strip(']').split())
    if (skipPlotbandpass==False):
        os.system('rm %s*.png' % (caltable))
        print "Running plotbandpass('%s',xaxis='chan',scans='%s', interactive=False,subplot=11,figfile='%s.scan%s', buildpdf=True, plotrange=[-0.5,%d,0,0],showpoints=True,showBasebandNumber=True,spw='%s',markersize=%d,showatm=%s)" % (caltable,scans,caltable,scans,channels,spwlist,markersize,showatm)
        plotbandpass(caltable, xaxis='chan', scans=scans, interactive=False,subplot=11,markersize=markersize,
                     figfile=caltable+'.scan'+scans, buildpdf=True, plotrange=[-0.5,channels,0,0],showpoints=True,
                     showBasebandNumber=True,xcolor='b',ycolor='r',spw='%s'%(spwlist),showatm=showatm)
    tsysfiles = sorted(glob.glob(caltable+'.scan'+scans+'*.png'))
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    plotfiles = []
    if (skipPlotms == False):
        samplers = checkSamplers(vis, ac=atmcal)
    sky = 1
    timerange = atmcal.timestampsString[int(scans)][sky]
    antnames = mymsmd.antennanames(range(mymsmd.nantennas()))
    for a in antnames:
        for spw in atmcal.spwsforscan_nonchanavg[scan]:
            plotfile = vis+'.%s.spw%02d.autocorr.png'%(a,spw)
            if (skipPlotms == False):
                baseband = mymsmd.baseband(spw)
                plotms(vis, spw=str(spw)+':0~%d'%(channels), xaxis='chan', interactive=False, scan=scans, timerange=timerange,
                       yaxis='amp',coloraxis='corr', avgtime='10000', iteraxis='spw',antenna=a+'&&&',overwrite=True,
                       plotfile=plotfile, plotrange=[-0.5,channels,0,0],
                       title=vis+' scan %s %s BB%d chan 0 ratios: XX=%.2f, YY=%.2f'%(scans,a,baseband,samplers[a][baseband][0],samplers[a][baseband][1]))
            plotfiles.append(plotfile)
    mymsmd.close()
    pdfname = vis+'.scan%s.autocorrsky_tsys.%dchannels.pdf' % (scans,channels)
    montageTwoPngLists(plotfiles, tsysfiles, sidebyside=False, pdfname=pdfname, filter=filter)
    return(pdfname)

def pngWidthHeight(filename):
    """
    Reads the width and height (in pixels) of a png image or list of images.
    filename: string with wildcard, comma-delimited string, or list of files
    -Todd Hunter
    """
    if type(filename) == str:
        if filename.find('*') >= 0:
            filename = sorted(glob.glob(filename))
        else:
            filename = filename.split(',')
    for fname in filename:
        if not os.path.exists(fname):
            print "Cannot find file = ", fname
            return
        f = open(fname, 'rb')
        data = f.read()
        if (data[:8] == '\211PNG\r\n\032\n'and (data[12:16] == 'IHDR')):
            w, h = struct.unpack('>LL', data[16:24])
            width = int(w)
            height = int(h)
        else:
            raise Exception('not a png image: %s' % (filename))
        f.close()
        if len(filename) > 1:
            print "%d x %d: %s" % (width, height, fname)
    return width, height
                                            
def montage(pnglist, tile='2X2', geometry='1000x1000+0+0', plotfile='', 
            sort=True, background=None,trim=False, shave=None):
    """
    Calls the montage program with the specified arguments.
    pnglist: list of strings, or a string with a wildcard character.
    tile: number of columns X rows
    geometry: passed to the montage command
    plotfile: the name of the png file to produce
    sort: if True, and if pnglist is a string, then sort the output of glob.glob
    background: set the background color (e.g. #000000)
    trim: trim the blank areas around each image
    shave: geometry (e.g. '50x100' to remove 50 pixels from sides, 100 from top/bottom)
    """
    if (type(pnglist) == str):
        pnglist = glob.glob(pnglist)
        if (sort):
            pnglist = sorted(pnglist)
    pnglist = ' '.join(pnglist)
    if (plotfile == '' or plotfile==True):
        plotfile = 'montage.png'
    if (background is not None and background != ''):
        background = '-background ' + background
    else:
        background = ''
    if (shave is not None and shave != ''):
        shave = '-shave ' + shave
    else:
        shave = ''
    if (trim):
        trim = '-trim'
    else:
        trim = ''
    cmd = "montage -tile %s -geometry %s %s %s %s %s %s" % (tile,geometry,background,trim,shave,pnglist,plotfile)
    print "Running %s" % cmd
    os.system(cmd)
    print "Result left in %s" % (plotfile)

def montagePngs(png1, png2='', outname='', sidebyside=True, png3=None, geometry='auto',
                trim=True, spacing=2, background='black', png4=None,
                border2=None, montage='montage', crop2=None, splice2=None, 
                tile='', png5=None, png6=None, convert='convert', density='',
                labelImages=False, pointsize=36, labelBasename=True, font='',
                verbose=False, cleanup=True, labelOverwrite=False, 
                labelBackground='white', labelColor='black', addLabel='',
                png7=None, png8=None, filetype='png'):
    """
    Takes 2..8 pngs (or single-page PDFs, if filetype=='pdf'), and puts them onto one page.
    sidebyside: if False, then put them one atop the other.
    Note: Some of the options in this task require the source pngs to be in the current
          working directory (border, crop, splice) but that could be improved.
    outname: default = montagePngs.png
    geometry: the string to use in the '-geometry' option of the montage commands
           format =   'WidthOfSingleImage x HeightOfSingleImage + Xgap + Ygap'
             example = '900x600+20+20' for a 2x2 grid of imview square images
          default: 'auto', which for filetype=='png' uses the size of png1, 
                       (Use 'auto+10' to add 10x10 pixel gap)
                   and for filetype='pdf', it uses '1000x1000+2+2'
                 
    trim: if True, pass '-trim' to the montage commands
    spacing: the gap between pngs, in pixels (if geometry is not specified)
    background: the color to use in the '-background' option of the montage commands
    border2: use convert to add a border to the second image of this many pixels
    montage: the path to the montage command
    convert: the path to the convert command
    crop2: string for the convert -crop option, to be run after -border
    splice2: string for the convert -splice option, to be run after -crop
    tile: override the automatic tiling, e.g. '2X2' (ncolumns x nrows)
    density: e.g. 300, '300' or '300x200'
    labelImages: if True, print the name of the png file at the top of each panel
               if it is a list of strings, then use those strings instead
    labelBasename: if True, remove any leading directory from the label
    labelOverwrite: if True, then overwrite the original png with the labelled one
    pointsize: label size (used by labelImages and addLabel)
    addLabel: if specified, add this label to top of the whole frame
          if it is a filename, read the first line of text from it
    font: a string, like 'Utopia-Regular'
    -Todd Hunter
    """
    if outname == '':
        outname = 'montagePngs.'+filetype
    if png3 == '': png3 = None
    if png4 == '': png4 = None
    if png2 == '':
        if type(png1) == list:
            if len(png1) < 2:
                print "You must specify png2 or set png1 to a list of 2 or more files"
                return
        else:
            if png1.find('*') < 0 and png1.find(',') < 0:
                print "You must specify png2 or include a wildcard in png1."
                return
            if png1.find('*') >= 0:
                png1 = sorted(glob.glob(png1))
            else:
                png1 = png1.split(',')
        print "png1 = ", png1
        png = png1[:]
        if len(png) >= 2:
            png1 = png[0]
            png2 = png[1]
        if len(png) >= 3:
            png3 = png[2]
        if len(png) >= 4:
            png4 = png[3]
        if len(png) >= 5:
            png5 = png[4]
        if len(png) >= 6:
            png6 = png[5]
        if len(png) >= 7:
            png7 = png[6]
        if len(png) >= 8:
            png8 = png[7]
    elif os.path.isdir(png2):
        print "png2 is a directory, not an image file."
        return
    if (os.path.exists(png1) == False):
        print "Could not find file png1 = ", png1
        return
    if (os.path.exists(png2) == False):
        print "Could not find file png2 = ", png2
        return
    if (png3 is not None):
        if (png4 is not None):
            if (png6 is not None):
                if png7 is not None:
                    if png8 is not None:
                        npngs = 8
                    else:
                        npngs = 7
                    if tile == '':
                        tile = '2x4'
                elif (tile == ''):
                    tile = '2X3'
            else:
                npngs = 4
                if (tile == ''):
                    tile = '2X2'
        else:
            npngs = 3
            if (tile == ''):
                if (sidebyside):
                    tile = '3X1'
                else:
                    tile = '1X3'
    else:
        npngs = 2
        if (tile == ''):
            if (sidebyside):
                tile = '2X1'
            else:
                tile = '1X2'
    if (geometry is None or filetype=='pdf'):
        geometry = '1000x1000+%d+%d' % (spacing,spacing)
    elif (geometry.find('auto') >= 0):
        gap = 0
        if (geometry.find('+') > 0):
            gap = int(geometry.split('+')[1])
        geometry = 'x'.join([str(i) for i in pngWidthHeight(png1)])
        if gap != 0:
            geometry += '+%d+%d' % (gap,gap)
        print "geometry = ", geometry
    if (trim):
        trim = '-trim'
    else:
        trim = ''
    removeFiles = []
    if border2 is not None:
        cmd = "%s %s -bordercolor %s -border %d border_%s" % (convert, png2, background, border2, png2)
        if verbose: print "Running %s" % (cmd)
        os.system(cmd)
        png2 = "border_" + png2
        removeFiles.append(png2)
    if crop2 is not None:
        cmd = "%s %s -crop %s crop_%s" % (convert, png2, crop2, png2)
        if verbose: print "Running %s" % (cmd)
        os.system(cmd)
        png2 = "crop_" + png2
        removeFiles.append(png2)
    if splice2 is not None:
        cmd = "%s %s -background %s -splice %s splice_%s" % (convert, png2, background, splice2, png2)
        if verbose: print "Running %s" % (cmd)
        os.system(cmd)
        png2 = "splice_" + png2
        removeFiles.append(png2)
    if trim:
        path = os.path.dirname(png1)
        if len(path) > 0: path += '/'
        pcmd  = "%s -trim %s %s%s1.%s" % (convert, png1, path, filetype,filetype)
        if verbose: print "running trim: ", pcmd
        mystatus = os.system(pcmd)
        if mystatus != 0:
            convert = '/opt/local/bin/convert'
            print "Switching to ", convert
            pcmd  = "%s -trim %s %s%s1.%s" % (convert, png1, path, filetype, filetype)
            print "running: ", pcmd
            mystatus = os.system(pcmd)
        shutil.move('%s%s1.%s' % (path, filetype, filetype), png1)
        path = os.path.dirname(png2)
        if len(path) > 0: path += '/'
        pcmd  = "%s -trim %s %s%s2.%s" % (convert, png2, path, filetype, filetype)
        if verbose: print "running: ", pcmd
        mystatus = os.system(pcmd)
        shutil.move('%s%s2.%s' % (path, filetype, filetype), png2)
    if density != '':
        density = '-density %s' % (str(density))
    if labelImages != False and labelImages != '':
        if len(font) > 0:
            font = '-font ' + font
        if labelImages == True:
            if labelBasename:
                label = os.path.basename(png1)
            else:
                label = png1
        else:
            label = labelImages[0]
        if len(grep(png1,label)[0]) == 0:
            # Then we have not already labeled this png.
            newpng1 = png1.replace('.'+filetype,'_label.'+filetype)
            # Note: -pointsize argument must come before label argument
            pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png1, labelBackground, labelColor, font, pointsize, label, newpng1)
            if verbose: print "Running: ", pcmd
            os.system(pcmd)
            if labelOverwrite:
                os.remove(png1)
                os.rename(newpng1,png1)
            else:
                png1 = newpng1
        if labelImages == True:
            if labelBasename:
                label = os.path.basename(png2)
            else:
                label = png2
        else:
            label = labelImages[1]
        if len(grep(png2,label)[0]) == 0:
            # Then we have not already labeled this png.
            newpng2 = png2.replace('.'+filetype,'_label.'+filetype)
            pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png2, labelBackground, labelColor, font, pointsize, label, newpng2)
            if verbose: print "Running: ", pcmd
            os.system(pcmd)
            if labelOverwrite:
                os.remove(png2)
                os.rename(newpng2,png2)
            else:
                png2 = newpng2
    cmd = "%s %s %s -background %s -tile %s -geometry %s  %s %s "%(montage,trim,density,background,tile,geometry,png1,png2)
    if type(labelImages) == bool:
        nLabelImages = 2
        for i in [png3,png4,png5,png6,png7,png8]:
            if i is not None: nLabelImages += 1
    else:
        nLabelImages = len(labelImages)
    if (png3 is not None): 
        if trim:
            path = os.path.dirname(png3)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s3.%s" % (convert, png3, path, filetype, filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move('%s%s3.%s'%(path,filetype,filetype), png3)
        if labelImages and nLabelImages > 2:
            newpng3 = png3.replace('.'+filetype,'_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png3)
                else:
                    label = png3
            else:
                label = labelImages[2].replace('//','////')
            if len(grep(png3,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png3, labelBackground, labelColor, font, pointsize, label, newpng3)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png3)
                    os.rename(newpng3,png3)
                else:
                    png3 = newpng3
        cmd += png3 
    if (png4 is not None): 
        if trim:
            path = os.path.dirname(png4)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s4.%s" % (convert, png4, path, filetype, filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move('%s%s4.%s'%(path,filetype,filetype), png4)
        if labelImages and nLabelImages > 3:
            newpng4 = png4.replace('.'+filetype,'_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png4)
                else:
                    label = png4
            else:
                label = labelImages[3].replace('//','////')
            if len(grep(png4,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png4, labelBackground, labelColor, font, pointsize, label, newpng4)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png4)
                    os.rename(newpng4,png4)
                else:
                    png4 = newpng4
        cmd += ' ' + png4
    if (png5 is not None):
        if trim:
            path = os.path.dirname(png5)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s5.%s" % (convert, png5, path, filetype, filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move(path+filetype+'5.'+filetype, png5)
        if labelImages and nLabelImages > 4:
            newpng5 = png5.replace('.'+filetype,'_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png5)
                else:
                    label = png5
            else:
                label = labelImages[4]
            if len(grep(png5,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png5, labelBackground, labelColor, font, pointsize, label, newpng5)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png5)
                    os.rename(newpng5,png5)
                else:
                    png5 = newpng5

        cmd += ' ' + png5
    if (png6 is not None): 
        if trim:
            path = os.path.dirname(png6)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s6.%s" % (convert, png6, path, filetype, filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move(path+filetype+'6.'+filetype, png6)
        if labelImages and nLabelImages > 5:
            newpng6 = png6.replace('.'+filetype,'_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png6)
                else:
                    label = png6
            else:
                label = labelImages[5]
            if len(grep(png6,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png6, labelBackground, labelColor, font, pointsize, label, newpng6)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png6)
                    os.rename(newpng6,png6)
                else:
                    png6 = newpng6
        cmd += ' ' + png6
    if (png7 is not None): 
        if trim:
            path = os.path.dirname(png7)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s7.%s" % (convert, png7, path, filetype, filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move(path+'%s7.%s'%(filetype,filetype), png7)
        if labelImages and nLabelImages > 6:
            newpng7 = png7.replace('.'+filetype, '_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png7)
                else:
                    label = png7
            else:
                label = labelImages[6]
            if len(grep(png7,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png7, labelBackground, labelColor, font, pointsize, label, newpng7)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png7)
                    os.rename(newpng7,png7)
                else:
                    png7 = newpng7
        cmd += ' ' + png7
    if (png8 is not None): 
        if trim:
            path = os.path.dirname(png8)
            if len(path) > 0: path += '/'
            pcmd  = "%s -trim %s %s%s8.%s" % (convert, png8, path,filetype,filetype)
            if verbose: print "Running: ", pcmd
            mystatus = os.system(pcmd)
            shutil.move(path+'%s8.%s'%(filetype,filetype), png8)
        if labelImages and nLabelImages > 7:
            newpng8 = png8.replace('.'+filetype, '_label.'+filetype)
            if labelImages == True:
                if labelBasename:
                    label = os.path.basename(png8)
                else:
                    label = png8
            else:
                label = labelImages[7]
            if len(grep(png8,label)[0]) == 0:
                # Then we have not already labeled this png.
                pcmd = '%s %s -background %s -fill %s %s -pointsize %d label:"%s" +swap -gravity Center -append %s' % (convert, png8, labelBackground, labelColor, font, pointsize, label, newpng8)
                if verbose: print "Running: ", pcmd
                os.system(pcmd)
                if labelOverwrite:
                    os.remove(png8)
                    os.rename(newpng8,png8)
                else:
                    png8 = newpng8
        cmd += ' ' + png8
    cmd += ' ' + outname
    if verbose: print "Running %s" % (cmd)
    mystatus = os.system(cmd)
    if (mystatus != 0 and mystatus != 256):
        # MacOS location of montage
        print "Switching to /opt/local/bin/montage"
        cmd = cmd.replace('montage','/opt/local/bin/montage')
        if verbose: print "Running %s" % (cmd)
        mystatus = os.system(cmd)
    if addLabel != '' and addLabel != False:
        print "Calling addLabelToPng"
        if os.path.exists(addLabel):
            f = open(addLabel,'r')
            lines = f.readlines()
            f.close()
            for line in lines[::-1]:
                line = line.replace('#','')
                addLabelToPng(outname, line, pointsize, font='Courier-Bold', gravity='NorthWest')
    for png2 in removeFiles:
        os.remove(png2)
    
def montageTwoPdfs(pdf1, pdf2, pdf3='', pdf4='', sidebyside=True, pdfname='', 
                   cleanup=True, maxpages=-1, geometry=None, verbose=False):
    """
    Takes two (or 3) PDFs of equal page length, splits them into single pages,
    and places them side-by-side on each page.  Requires pdftk and ImageMagick.
    geometry: if None, it will use 800x600+10+10 if 4 pdfs are specified
    - Todd Hunter
    """
    pages1 = countPagesInPDF(pdf1)
    pages2 = countPagesInPDF(pdf2)
    if (pdf3 != ''):
        pages3 = countPagesInPDF(pdf3)
        if (pdf4 != ''):
            pages4 = countPagesInPDF(pdf4)
            n = np.min([pages1, pages2, pages3,pages4])
        else:
            n = np.min([pages1, pages2, pages3])
    else:
        n = np.min([pages1, pages2])
    if (maxpages > 0):
        n = np.min([n,maxpages])
    print "Will compare %d pages (out of %d and %d)" % (n, pages1, pages2)
    pdflist1 = []
    pdflist2 = []
    pdflist3 = []
    pdflist4 = []
    for i in range(n):
        print "Working on page %d/%d" % (i+1,n)
        page = i+1
        pdflist1.append('%s_page%03d.pdf' % (pdf1.replace('.pdf',''),page))
        pdflist2.append('%s_page%03d.pdf' % (pdf2.replace('.pdf',''),page))
        cmd = 'pdftk %s cat %d-%d output %s' % (pdf1, page, page, pdflist1[-1])
        if verbose: print cmd
        os.system(cmd)
        cmd = 'pdftk %s cat %d-%d output %s' % (pdf2, page, page, pdflist2[-1])
        os.system(cmd)
        if verbose: print cmd
        os.system(cmd)
        if (pdf3 != ''):
            pdflist3.append('%s_page%03d.pdf' % (pdf3.replace('.pdf',''),page))
            cmd = 'pdftk %s cat %d-%d output %s' % (pdf3, page, page, pdflist3[-1])
            if verbose: print cmd
            os.system(cmd)
            if (pdf4 != ''):
                pdflist4.append('%s_page%03d.pdf' % (pdf4.replace('.pdf',''),page))
                cmd = 'pdftk %s cat %d-%d output %s' % (pdf4, page, page, pdflist4[-1])
                if verbose: print cmd
                os.system(cmd)
    if (len(pdflist3) < 1):
        pdflist3 = None
    if (len(pdflist4) < 1):
        pdflist4 = None
    elif (geometry==None):
        geometry = '800x600+10+10'
    montageTwoPngLists(pdflist1, pdflist2, pdflist3, pdflist4, pdfname=pdfname, 
                       sidebyside=sidebyside, filetype='pdf', cleanup=cleanup,
                       geometry=geometry, verbose=verbose)

def montageTwoPngLists(pnglist1, pnglist2, pnglist3=None, pnglist4=None,
                       pdfname='', sidebyside=True, geometry='auto',
                       filter='', trim=True, spacing=2, background='black',
                       sourceFilter=[], maxpages=0, cleanup=True, filetype='png',
                       mode='identical',labelImages='',labelOverwrite=False, startpage=0, verbose=False):
    """
    Takes two lists of N pngs (or other image types), and puts them side-by-side on an N-page pdf.
    pnglist1 / pnglist2: either a python list of filenames, or a single string containing a directory
             name and/or a template filename with wildcards (e.g. 'DV*.png')
        pnglist2: can be: 'replace,X174,../Uranus_11Jul2015/X742' which will produce a list of
                  files common to two directories.
    pnglist3 / pnglist4: optional lists (if present, will make 2x2 plot on each page)
    pdfname: the name of the PDF to produce    
    sidebyside: True (place them left/right),  False (place the second above the first)
    filter: remove all pngs that include this string in the name (e.g. 'DV10')
    geometry: the string to use in the '-geometry' option of the montage commands
           format =   'WidthOfFinalImage x HeightOfSingleImage + Xgap + Ygap'
             example = '600x400+20+20'
    trim: if True, pass '-trim' to the montage commands
    background: the color to use in the '-background' option of the montage commands
    spacing: the gap between pngs, in pixels (if geometry is not specified)
    sourceFilter: only include pngs that contain one of the strings in this list
       Note: the sourceFilter option overrides the filter option
    cleanup: parameter passed to buildPdfFromPngs to remove individual plots
    mode: 'identical', 'truncate', 'match'
      'identical': length of pnglist1 must equal length of pnglist2
      'truncate': if lengths do not match, stop after the lesser of the two
      'match': process all of pnglist1 by finding matching filenames in pnglist2
    labelImages: if True, print the name of the png file at the top of each panel
               if it is a list of strings, then use those strings instead
             if it is 'dir', then print the directory name at the top of each panel
    labelOverwrite: if True, then overwrite the original png with the labelled one
    startpage: once a list is generated, start the montaging of plots at this page
    filetype: passed to buildPdfFromPngs
    - Todd Hunter
    """
    print "Received filetype='%s'" % (filetype)
    if (type(pnglist1) == str):
        # assume we want all pngs in this directory
        if (pnglist1.find('*') < 0):
            pnglist1 = sorted(glob.glob(pnglist1+'/*.'+filetype))
        else:
            png1 = pnglist1
            pnglist1 = sorted(glob.glob(pnglist1))
        print "Found %d plots for pnglist1: %s" % (len(pnglist1),png1)
        if len(pnglist1) == 0:
            return
    if (type(pnglist2) == str):
        # assume we want all pngs in this directory
        if (pnglist2.find('*') < 0):
            if (pnglist2.split(',')[0].find('replace') < 0):
                pnglist2 = sorted(glob.glob(pnglist2+'/*.'+filetype))
            else:
                # only use files in common between 2 paths
                newpnglist1 = []
                newpnglist2 = []
                for png in pnglist1:
                    png2 = png.replace(pnglist2.split(',')[1], pnglist2.split(',')[2])
                    if (os.path.exists(png2)):
                        newpnglist1.append(png)
                        newpnglist2.append(png2)
                pnglist1 = newpnglist1
                pnglist2 = newpnglist2
                print "Found %d = %d common files" % (len(pnglist1), len(pnglist2))
        else:
            png2 = pnglist2
            pnglist2 = sorted(glob.glob(pnglist2))
        print "Found %d plots for pnglist2: %s" % (len(pnglist2),png2)
        if len(pnglist2) == 0:
            return
    if (pnglist3 is not None):
        if (type(pnglist3) == str):
            # assume we want all pngs in this directory
            if (pnglist3.find('*') < 0):
                pnglist3 = sorted(glob.glob(pnglist3+'/*.'+filetype))
            else:
                pnglist3 = sorted(glob.glob(pnglist3))
    if (pnglist4 is not None):
        if (type(pnglist4) == str):
            # assume we want all pngs in this directory
            if (pnglist4.find('*') < 0):
                pnglist4 = sorted(glob.glob(pnglist4+'/*.'+filetype))
            else:
                pnglist4 = sorted(glob.glob(pnglist4))
        
    if (filter != '' or sourceFilter != []):
        newpnglist1 = []
        for png in pnglist1:
            if (sourceFilter != []):
                for src in sourceFilter:
                    if (png.find(src) >= 0):
                        newpnglist1.append(png)
            else:
                if (png.find(filter) < 0):
                    newpnglist1.append(png)
        pnglist1 = newpnglist1
        newpnglist2 = []
        for png in pnglist2:
            if (sourceFilter != []):
                for src in sourceFilter:
                    if (png.find(src) >= 0):
                        newpnglist2.append(png)
            else:
                if (png.find(filter) < 0):
                    newpnglist2.append(png)
        pnglist2 = newpnglist2
        if (pnglist3 is not None):
            newpnglist3 = []
            for png in pnglist3:
                if (sourceFilter != []):
                    for src in sourceFilter:
                        if (png.find(src) >= 0):
                            newpnglist3.append(png)
                else:
                    if (png.find(filter) < 0):
                        newpnglist3.append(png)
            pnglist3 = newpnglist3
        if (pnglist4 is not None):
            newpnglist4 = []
            for png in pnglist4:
                if (sourceFilter != []):
                    for src in sourceFilter:
                        if (png.find(src) >= 0):
                            newpnglist4.append(png)
                else:
                    if (png.find(filter) < 0):
                        newpnglist4.append(png)
            pnglist4 = newpnglist4
    if labelImages=='dir':
        labelImages = [os.path.dirname(pnglist1[0]), os.path.dirname(pnglist2[0])]
    l1 = len(pnglist1)
    l2 = len(pnglist2)
    if (l1 != l2):
        if mode == 'identical':
            print "The two lists are not of equal length (%d vs. %d). Set mode='truncate' or 'match'." % (l1, l2)
            return
        elif mode == 'truncate':
            if l1 > l2:
                pnglist1 = pnglist1[:l2]
            else:
                pnglist2 = pnglist2[:l1]
        elif mode == 'match':
            pnglist2basename = [os.path.basename(i) for i in pnglist2]
            newpnglist1 = []
            newpnglist2 = []
            list2idx = []
            for png1 in pnglist1:
                if os.path.basename(png1) not in pnglist2basename:
                    print "match failed for ", png1
                    continue
                newpnglist1.append(png1)
                list2idx.append(pnglist2basename.index(os.path.basename(png1)))
                match = pnglist2[list2idx[-1]]
                print "Found match: %s = %s" % (os.path.basename(png1), match)
                newpnglist2.append(match)
            unused = sorted(list(set(range(len(pnglist2basename))) - set(list2idx)))
            print "unused = ", unused
            if len(unused) > 0:
                for i in unused:
                    print "No match found for ", np.array(pnglist2basename)[i]
            pnglist1 = newpnglist1
            pnglist2 = newpnglist2
        else:
            print "unrecognized mode: ", mode
            return
    if (pnglist3 is not None):
        l3 = len(pnglist3)
        if (l1 != l3):
            print "The three lists are not of equal length (%d vs. %d vs. %d)" % (l1, l2, l3)
            return
    if (pnglist4 is not None):
        l4 = len(pnglist4)
        if (l1 != l4):
            print "The four lists are not of equal length (%d vs. %d vs. %d vs %d)" % (l1, l2, l3, l4)
            return
        
    plotfiles = []
    dirname = os.path.dirname(pdfname)
    if (dirname != ''):
        if (os.path.exists(dirname) == False):
            print "Creating directory: ", dirname
            os.mkdir(dirname)
        dirname += '/'
    png3 = None
    png4 = None
    if (maxpages == 0):
        npages = len(pnglist1)
    else:
        npages = maxpages
    print "Making %d-%d = %d pages" % (npages,startpage, npages-startpage)
    if (pdfname == ''):
        pdfname = '%dpages.pdf' % (npages)
    for i in range(startpage,npages):
        page =  dirname + os.path.basename(pdfname).rstrip('.pdf') + ".page%03d.%s" % (i,filetype)
        plotfiles.append(page)
        if (pnglist3 is not None):
            png3 = pnglist3[i]
        if (pnglist4 is not None):
            png4 = pnglist4[i]
        if verbose: 
            print "Calling montagePngs('%s','%s',outname='%s',filetype='%s',verbose=%s)" % (pnglist1[i],pnglist2[i],page,filetype,verbose)
        montagePngs(pnglist1[i], pnglist2[i], outname=page, background=background,
                    sidebyside=sidebyside, spacing=spacing, geometry=geometry, 
                    png3=png3, png4=png4, labelImages=labelImages, 
                    labelOverwrite=labelOverwrite,verbose=verbose, filetype=filetype)
        if ((i+1) % 10 == 0):
            print "Done page %d" % (i+1)
    buildPdfFromPngs(plotfiles, pdfname=pdfname, cleanup=cleanup, filetype=filetype)
    if cleanup:
        for i in plotfiles:
            if os.path.exists(i):
                os.remove(i)
    return(pdfname)

def plotcalCompare(caltable, caltable2, spw=0, xaxis='time', yaxis='phase', poln='X',
                   plotrange=[0,0,-180,180], sidebyside=True):
    """
    Places two sequences of plotcal plots side-by-side onto each page, and builds
    a PDF.  Useful for comparing G with GSPLINE solutions.
    Optional parameters:
    spw: This parameter is only for labeling the png files, it is not passed to plotcal.
    Creates a multi-page PDF called: caltable.compare.pdf with one antenna
    per page.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    antennas = sorted(np.unique(mytb.getcol('ANTENNA1')))
    mytb.close()
    png1 = []
    png2 = []
    for antenna in antennas:
        png = caltable + '.table1.spw%02d.ant%02d.png' % (int(spw),antenna)
        plotcal(caltable, xaxis=xaxis, yaxis=yaxis, poln=poln, figfile=png,
                plotrange=plotrange, antenna=str(antenna))
        png1.append(png)
    for antenna in antennas:
        png = caltable + '.table2.spw%02d.ant%02d.png' % (int(spw),antenna)
        plotcal(caltable2, xaxis=xaxis, yaxis=yaxis, poln=poln, figfile=png,
                plotrange=plotrange, antenna=str(antenna))
        png2.append(png)
    pdf = caltable+'spw%02d.compare.pdf' % (int(spw))
    montageTwoPngLists(png1, png2, pdfname=pdf, sidebyside=sidebyside)
    print "PDF = ", pdf
    
def countPagesInPDF(pdf, pdfinfo='pdfinfo'):
    """
    Counts the number of pages in a PDF.
    pdf: the name of the PDF file
    pdfinfo: the path to the pdfinfo executable
    -Todd Hunter
    """
    if (os.path.exists(pdf) == False):
        print "Could not find file ", pdf
        return 0
    cmd = pdfinfo + ' ' + pdf + '| grep Pages'
    status, output = commands.getstatusoutput(cmd)
    pages = output.split()
    if (len(pages) > 1):
        try:
            return(int(pages[1]))
        except:
            print "This is not a PDF!"
            return 0 
    else:
        return 0

def comparePdfs(pdf1, pdf2, maxPages=None, verbose=False, listminor=False, trim=True):
    """
    Takes two multi-page pdfs, and compares each pair of individual pages.
    maxPages: limit the comparison to the first N pages
    listminor: if True, then also write minor differences to log file
    Produces a file called 'comparePdfs.txt'
    -Todd Hunter
    """
    pages1 = countPagesInPDF(pdf1)
    pages2 = countPagesInPDF(pdf2)
    n = np.min([pages1, pages2])
    if maxPages is not None:
        n = np.min([n,maxPages])
    pdflist1 = []
    pdflist2 = []
    dB = []
    failures = 0
    minorFailures = 0
    f = open('comparePdfs.txt','w')
    for i in range(n):
        print "Working on page %d/%d" % (i+1,n)
        page = i+1
        pdflist1.append('%s_page%03d.pdf' % (pdf1.replace('.pdf',''),page))
        pdflist2.append('%s_page%03d.pdf' % (pdf2.replace('.pdf',''),page))
        cmd = 'pdftk %s cat %d-%d output %s' % (pdf1, page, page, pdflist1[-1])
        os.system(cmd)
        if verbose: print "Running ", cmd
        cmd = 'pdftk %s cat %d-%d output %s' % (pdf2, page, page, pdflist2[-1])
        if verbose: print "Running ", cmd
        os.system(cmd)
        if trim:
            for p in [pdflist1[-1],pdflist2[-1]]:
                cmd = 'convert -trim %s %s 2>/dev/null' % (p,p)
                if verbose: print "Running ", cmd
                os.system(cmd)
        mydB = comparePngs(pdflist1[i], pdflist2[i])
        dB.append(mydB)
        png = pdflist1[i]
        if (mydB >= 520):
            print "%s %d" % (png, mydB)
            f.write("%s %d\n" % (png, mydB))
            f.flush()
            failures += 1
        if (mydB > 0):
            if listminor:
                f_all.write("%s %d minor\n" % (png, mydB))
                f_all.flush()
            minorFailures += 1
    print "There were %d minor differences and %d total differences (major+minor)" % (minorFailures, failures)
    f.close()
    
def comparePngs(png1, png2, compare='compare', metric='AE', cleanup=True,
                verbose=False):
    """
    Compares two pngs images using the ImageMagick compare command.
    Returns 0 if identical, or positive integer if not.
    Writes difference images into the same directory as png1.
    compare: the path to the compare command
    cleanup: if True, remove the difference image even if there are differences
    """
    if (not os.path.exists(png1)):
        print "Could not find file ", png1
        return 0
    if (not os.path.exists(png2)):
        print "Could not find file ", png2
        return 0
    diffimage = png1.replace('.png','') + '.diff.png'
    # Check the imagemagick version
    cmd = compare + ' -version'
    status, output = commands.getstatusoutput(cmd)
    tokens = output.split()
    version = tokens[2].split('-')[0]
    if (version > '6.5.0'):
        if verbose: print "You have a newer version of ImageMagick (>6.5.0)"
        cmd = compare + ' -metric %s '%(metric) + png1 + ' ' + png2 + ' ' + diffimage
        if verbose: print "Running: ", cmd
        status, output = commands.getstatusoutput(cmd)
        try:
            dB = int(output.split()[0])
        except:
            print "Ran: ", cmd
            print "output:  ", output
            dB = 65000
        if (cleanup or dB==0):
            if os.path.exists(diffimage):
                os.remove(diffimage)
        else:
            print "Wrote image: ", diffimage
    else:
        if verbose: print "You have an older version of ImageMagick (<6.5.0)"
        cmd = compare + ' -verbose -metric %s '%(metric) + png1 + ' ' + png2 + ' ' + diffimage
        if verbose: print "Running: ", cmd
        status, output = commands.getstatusoutput(cmd)
        if (output.find('dB') >= 0):
            dB = int(output.split('dB')[0].split('\n')[-1])
            if (cleanup or dB==0):
                os.remove(diffimage)
            else:
                print "Wrote image: ", diffimage
        else:
            dB = -1
            print output
            print "Wrote image: ", diffimage
    return (dB)

def buildPdfFromPngs(pnglist=[],pdfname='',convert='convert',gs='gs',
                     pdftk='pdftk',maxcount=0,cleanup=True,quiet=False,
                     overwritePdfs=False, papersize='', filetype='png', density='',
                     resize='', writeCommand=False):
    """
    Will convert a list of PNGs into PDFs, then concatenate them into a multi-page PDF.
    Arguments:
    pnglist: list of PNG files ['a.png','b.png'], or a string which is assumed
             to be a directory in which all *.png's will be grabbed.  If this
             string contains a *, it will not assume that it is a wildcard
             string with which to identify files as pngs to grab.
    pdfname:  the filename to produce (default = my.pdf)
    convert: specify full path to ImageMagick's convert command (if necessary)
    gs:  specify the full path to ghostscript's gs command (if necessary)
    pdftk: specify the full path to the pdftk command (if necessary)
    maxcount: maximum number of files to include
    cleanup: remove the temporary single-page PDFs
    overwritePdfs: overwrite any existing single-page PDFs, False->only if png is newer
    papersize: 'letter' or 'a4' or '' for automatic
    density: e.g. 300, '300' or '300x200'
    resize: e.g. '500x500'
    writeCommand: Boolean passed to concatenatePDFs (for debugging)
    filetype: 'pdf' or 'png', if 'pdf', then first convert each pdf to a png
    """
    filelist = ''
    if (type(pnglist) == str):
        # assume we want all pngs in this directory
        if (pnglist.find('*') < 0):
            pnglist = sorted(glob.glob(pnglist+'/*.'+filetype))
        else:
            pnglist = sorted(glob.glob(pnglist))
            if not quiet: print "pnglist = ", pnglist
    if (len(pnglist) < 1):
        return("You must specify at least one file with pnglist=['myfile1','myfile2',...].")
    pnglist = pruneFilelist(pnglist)
    if not quiet: print "Pruned list = ", pnglist
    count = 0
    if (filetype == 'pdf'):
        # no conversion is necessary
        print "No conversion is necessary"
        filelist = ' '.join(pnglist)
    else:
        print "Converting from png to pdf"
        # do a conversion from pdf to png
        if density != '':
            density = '-density %s' % (str(density))
        if resize != '':
            resize = '-resize %s' % (str(resize))
        for p in pnglist:
            if (len(p) == 0):
                print "File number %d is a blank string" % (count)
                return
            # account for special characters (until CAS-7731 is implemented to prevent them in plotms)
            p = p.replace(' ','\ ').replace('&','\&')
            if (maxcount > 0 and count >= maxcount): break
            count += 1
            if (os.access(p,os.W_OK)):
                onepdf = '%s.pdf' % (p)
            else:
                onepdf = '/tmp/%s.pdf' % (p.split('/')[-1])
            mystatus = 0
            pngIsNewer = False
            if os.path.exists(onepdf):
                if os.path.getmtime(p) > os.path.getmtime(onepdf):
                    pngIsNewer = True
            if (overwritePdfs or not os.path.exists(onepdf) or pngIsNewer):
                cmd = '%s %s %s %s %s' % (convert,p,resize,density,onepdf)
                if not quiet: print "%d: Running command: " % (count-1), cmd
                mystatus = os.system(cmd)
            if (mystatus == 0):
                filelist += onepdf + ' '
            elif (mystatus == 256):
                return("Could not find one or more of the png files.")
            else:
                # MacOS location of convert
                convert = '/opt/local/bin/convert'
                cmd = '%s %s %s %s %s' % (convert,p,density,resize,onepdf)
                if not quiet: print "%d: Running command (/opt) = " % (count-1), cmd
                mystatus = os.system(cmd)
                if (mystatus == 0):
                    filelist += onepdf + ' '
                elif (mystatus == 256):
                    return("Could not find one or more of the png files.")
                else:
                    mystring = "ImageMagick's convert command is missing, no PDF created. You can set the full path to convert with convert=''"
                    return(mystring)
    if (pdfname == ''):
        pdfname = './my.pdf'
    if (os.path.dirname(pdfname) == ''):
        pdfname = './' + pdfname
    mypath = os.path.dirname(pdfname)
    print "Checking if I have write privilege on path=%s" % (mypath)
    if (os.access(mypath, os.W_OK) == False):
        pdfname = '/tmp/%s' % (os.path.basename(pdfname))
    else:
        pdfname = pruneFilelist([pdfname])[0]
        
    if (len(pnglist) > 1):
        mystatus = concatenatePDFs(filelist,pdfname,pdftk=pdftk,gs=gs,quiet=quiet,papersize=papersize, 
                                   writeCommand=writeCommand, cleanup=cleanup)
    else:
        cmd = 'cp %s %s' % (filelist,pdfname)
        print "Running command = %s" % (cmd)
        mystatus = os.system(cmd)
    if (mystatus == 0):
        print "PDF left in %s" % (pdfname)
        if (cleanup):
            os.system("rm -f %s" % filelist)
    else:
        print "No PDF created. status=%d. pdftk and gs (ghostscript) might both be missing" % mystatus
        print "If so, you can set the full path to pdftk with pdftk='', or to gs with gs=''"
    return('')
# end of buildPdfsFromPngs

def clearflags(caltable='', absoluteValue=False):
    """
    Clear all flags in a 3.4 tsys table, with an option to replace the
    FPARAM with the absolute value of the existing FPARAM.
    Todd Hunter
    """
    tb.open(caltable,nomodify=False)
    caltime = tb.getcol('TIME')
    for i in range(len(caltime)):
        flag = tb.getcell('FLAG',i)
        fparam = tb.getcell('FPARAM',i)
        c = 0
        for f in flag:
            lf = list(f)
            c += lf.count(1)
        if (c > 0):
            flag *= 0
            tb.putcell('FLAG',i,flag)
            if (absoluteValue):
                fparam = tb.getcell('FPARAM',i)
                fparam = np.abs(fparam)
                tb.putcell('FPARAM',i,fparam)
                print "Cleared %d flags in row %d and took absolute value of gain" % (c,i)
            else:
                print "Cleared %d flags in row %d" % (c,i)
    tb.close()

def countrows(vis, ignoreIntent=''):
    """
    Returns a dictionary keyed by scan number, with values equal to the
    number of rows in the measurement set. An additional key is 'total'
    which contains the total number of rows (sum of all scans).
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (ignoreIntent == ''):
        scans = mymsmd.scannumbers()
    else:
        scans = mymsmd.scannumbers()
        dropscans = mymsmd.scansforintent('*'+ignoreIntent+'*')
        scans = list(set(scans).difference(set(dropscans)))
        print "Using only scans = ", scans
    mymsmd.close()
    mytb = createCasaTool(tbtool)
    # Find number of data description IDs
    mytb.open(vis)
    rows = {}
    totalrows = 0
    for scan in scans:
        myscan = mytb.query('SCAN_NUMBER == %d' % scan)
        rows[scan] = len(myscan.getcol('TIME'))
        totalrows += rows[scan]
        myscan.close()
    mytb.close()
    print "total rows = ", totalrows
    rows['total'] = totalrows
    return(rows)
    
def countflags(vis):
    """
    Examine all data descriptors in an ms and report the
    number of flags, total points and percentage flagged in a dictionary.
    Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    # Find number of data description IDs
    mytb.open(vis+"/DATA_DESCRIPTION")
    ddspwlist = mytb.getcol("SPECTRAL_WINDOW_ID")
    ddpollist = mytb.getcol("POLARIZATION_ID")
    mytb.close()
    ndd = ddspwlist.__len__()
    print 'Found '+str(ndd)+' DataDescription IDs'
    rows = {}
    mytb.open(vis)
    for i in range(ndd):
        ddtable = mytb.query('DATA_DESC_ID == %d' % i)
        rows[i] = len(ddtable.getcol('TIME'))
        ddtable.close()
    mytb.close()

    myms = createCasaTool(mstool)
    myms.open(vis)
    totalflags = 0
    totalpoints = 0
    # loop over data descriptors
    mydict = {}
    for idd in range(ndd):
        # Select this DD (after reset if needed)
        if idd>0: myms.selectinit(reset=True)
        myms.selectinit(idd)
        if (myms.range('time') == {}):
            continue
        flags = myms.getdata(["flag"])
        flatflags = flags['flag'].flatten()
        myflags = len(np.where(flatflags == 1)[0])
        print "Examined DD%2d of %2d: %d/%d flags, %d rows" % (idd+1,ndd,myflags,len(flatflags),rows[idd])
        mydict[idd] = {'flagged': myflags, 'total': len(flatflags), 'percent': 100.0*myflags/len(flatflags)}
        totalflags += myflags
        totalpoints += len(flatflags)
    myms.close()
    percentage = 100*totalflags/(1.0*totalpoints)
    print "Found %d flags (%.4f%%) out of %d possible." % (totalflags, percentage, totalpoints)
    mydict['total'] = totalpoints
    mydict['flagged'] = totalflags
    mydict['percent'] = percentage
    return(mydict)

def listflagsSlow(ms='',maxrows=0, verbose=False, startrow=0):
    """
    Examine all rows in an ms that have flagged data, and report statistics.
    See also au.countflags (much faster), and fg.setflagsummary()
    verbose: if True, list all row numbers
    maxrows: if maxrows > 0, then stop after examining maxrows
    Todd Hunter
    """
    mytb = tbtool()
    mytb.open(ms)
    times = mytb.getcol('TIME')
    totalrows = 0
    totalflags = 0
    totalpoints = 0
    interval = 1000
    lt = len(times)/interval
    print "Total rows in ms = %d" % (len(times))
    rows = []
    fo = open(ms.split('/')[-1]+'.listflags','w')
    for i in range(startrow,len(times)):
        flags = mytb.getcell('FLAG',i)
        for f in flags:
            lf = list(f)
            c = lf.count(1)
            totalrows += 1
            if (c > 0):
                if (verbose):
                    print "Found %d flags in row %d" % (c,i)
                rows.append(i)
                fo.write('%d %d\n'%(i,c))
                totalflags += c
            totalpoints += len(lf)
        if (totalrows>=maxrows and maxrows>0): break
        if (i%lt == 0):
            print "Row %d: Done %.1f%% (%d flags found)" % (i,100.0*i/lt/interval, totalflags)
    mytb.close()
    print "This dataset has %d rows." % (len(times))
    fo.write("This dataset has %d rows.\n" % (len(times)))
    print "Found %d flags (%.4f%%) in %d different rows." % (totalflags, 100*totalflags/(1.0*totalpoints), totalrows)
    fo.write("Found %d flags (%.4f%%) in %d different rows.\n" % (totalflags, 100*totalflags/(1.0*totalpoints), totalrows))
    fo.close()

def getFields(vis):
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FIELD')
    fields = mytb.getcol('NAME')
    mytb.close()
    return(fields)
    
def getFieldsForTime(ft, time):
    """
    Return the field with an observation time closest to the specified time.
    Input: a ValueMapping structure (vm.fieldsForTimes), and an MJD_seconds time
    Output: field name
    Called by detectNegativeTsys()
    Todd Hunter
    """
    mindiff = 1e8
    myfield = 'None'
    for src in ft.keys():
        diff = ft[src] - time
        if (np.min(np.abs(diff)) < mindiff):
            mindiff = np.min(np.abs(diff))
            myfield = src
    return(myfield)

def parseFrequencyArgumentToGHz(bandwidth):
    """
    Converts a frequency string into floating point in GHz, based on the units.
    If the units are not present, then the value is assumed to be GHz if less
    than 1000.
    -Todd Hunter
    """
    value = parseFrequencyArgument(bandwidth)
    if (value > 1000):
        value *= 1e-9
    return(value)

def parseFrequencyArgumentToHz(bandwidth):
    """
    Converts a frequency string into floating point in Hz, based on the units.
    If the units are not present, then the value is assumed to be GHz if less
    than 1000 (in contrast to parseFrequencyArgument).
    -Todd Hunter
    """
    value = parseFrequencyArgumentToGHz(bandwidth) * 1e9
    return(value)

def parseFrequencyArgument(bandwidth):
    """
    Converts a string frequency (or dictionary) into floating point in Hz, based on 
    the units.  If the units are not present, then the value is simply converted to float.
    -Todd Hunter
    """
    if (type(bandwidth) == dict):
        bandwidth = str(bandwidth['value']) + bandwidth['unit']
    else:
        bandwidth = str(bandwidth)
    ghz = bandwidth.lower().find('ghz')
    mhz = bandwidth.lower().find('mhz')
    khz = bandwidth.lower().find('khz')
    hz = bandwidth.lower().find('hz')
    if (ghz>0):
        bandwidth = 1e9*float(bandwidth[:ghz])
    elif (mhz>0):
        bandwidth = 1e6*float(bandwidth[:mhz])
    elif (khz>0):
        bandwidth = 1e3*float(bandwidth[:khz])
    elif (hz>0):
        bandwidth = float(bandwidth[:hz])
    else:
        bandwidth = float(bandwidth)
    return(bandwidth)

def channelsForPreBandpass(vis, spw, bandwidth, verbose=False):
    """
    Determines the channel range at the center of the spw that corresponds
    to the specified bandwidth, centered on the spw.
    spw: integer or string
    bandwidth: floating point Hz, or string with specified units of GHz, MHz or Hz
    """
    if (os.path.exists(vis) == False):
        print "Could not find MS"
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    spw = int(spw)
    if (type(bandwidth) == str):
        bandwidth = parseFrequencyArgument(bandwidth)
    nchan = mymsmd.nchan(spw)
    chanwidth = abs(mymsmd.chanwidths(spw)[0])  # assume constant widths
    mymsmd.close()
    centralChannels = int(0.5+bandwidth/chanwidth)
    # 1000, 100    (1000-100)/2=450  1000-450=550
    startchan = int((nchan-centralChannels)/2)
    if (startchan < 0):
        startchan = 0
    endchan = nchan-startchan-1
    if (endchan-startchan+1 < centralChannels and endchan+1<nchan):
        endchan += 1
    actualChannels = endchan-startchan+1
    channelRange = '%d~%d' % (startchan,endchan)
    if (verbose):
        print "%d-%d=%d, %d channels: actual range = %f Hz" % (endchan,startchan, endchan-startchan,
                                                               actualChannels,actualChannels*chanwidth)
    return(channelRange)

def spwsForNames(vis, names):
    """
    inverse function of msmd.namesforspws.  Requested for msmd in CAS-8901.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (type(names) == str):
        names = names.split(',')
    allnames = list(mymsmd.namesforspws())
    spws = []
    for name in names:
        if name in allnames:
            spws.append(allnames.index(name))
        else:
            spws.append(-1)
    mymsmd.close()
    return spws

def spwsForFields(mymsmd, fields, matchByName=False):
    """
    msmd.spwsforfield only support single fields.  This function supports field lists.
    matchByName: if True, then translate fields IDs to names, then request all field IDs
                 that match each name, which is helpful for the case that the Tsys scan
                 is taken on a different field number from the observe_target scans.
    -Todd Hunter
    """
    spws = np.array([], dtype=int32)
    if (matchByName):
        newFields = []
        for field in fields:
            newFields += list(mymsmd.fieldsforname(mymsmd.namesforfields(field)[0]))
        fields = newFields
    for field in fields:
        spws = np.append(spws, mymsmd.spwsforfield(field))
    return(np.unique(spws))

def spwsForScan(mymsmd):
    """
    Return a dictionary keyed by scan number, with values equal to the non-chanavg, non-WVR,
    non-SQLD spws associated with that scan.
    -Todd Hunter
    """
    spws = {}
    for scan in mymsmd.scannumbers():
        spws[scan] = list(np.intersect1d(np.intersect1d(mymsmd.spwsforscan(scan), 
                                                        getNonWvrSpws(mymsmd)),
                                                        getNonChanAvgSpws(mymsmd)))
    return(spws)

def spwsforfield(vis, field):
    """
    This is a replacement for msmd.spwsforfield until the bug found on Oct 9, 2013
    (CAS-5706) has been fixed in casa.  It was fixed for release 4.3, but remains here
    as a useful shortcut, and is now used by bandwidthsForField.
    field: integer ID or string ID or string name of a single field
    - Todd Hunter 
    """
    if (os.path.exists(vis) == False):
        print "Could not find MS"
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    if (type(field) == str):
        if (not field.isdigit()):
            if (field not in mymsmd.namesforfields(range(mymsmd.nfields()))):
                print "Field %s is not in the MS" % (field)
                return
    if (type(field) != str):
        spws = mymsmd.spwsforfield(field)
    elif (field.isdigit()):
        spws = mymsmd.spwsforfield(int(field))
    else:
        fieldIds = mymsmd.fieldsforname(field)
        if (len(fieldIds) == 1):
            spws = mymsmd.spwsforfield(field)
        elif (len(fieldIds) == 0):
            print "This field is not in the MS"
            return
        else:
            spws = []
            for fid in fieldIds:
                spws += list(mymsmd.spwsforfield(fid))
            spws = np.unique(spws)
    mymsmd.close()
    return(spws)

def getScansForTime(ft, time):
    """
    Return the scan with an observation time closest to the specified time.
    Input: a ValueMapping structure (vm.scansForTimes), and an MJD_seconds time
    Output: field name
    Called by detectNegativeTsys()
    Todd Hunter
    """
    mindiff = 1e12
    myfield = 'None'
    for scan in ft.keys():
        diff = ft[scan] - time
        if (np.min(np.abs(diff)) < mindiff):
            mindiff = np.min(np.abs(diff))
            myscan = scan
    return(myscan)

def plotTsys(vis='', antenna = '', spw='', xaxis='freq', gs='gs',
             buildpdf=False, interactive=True, overlay='',
             plotrange=[0,0,0,0],pol='', figfile='', renumber=False,
             replace={}, showatm=False, scan='', verbose=False, fontsize=12,
             doplot=True, atmcal=None, returnMedians='median', grid=True, 
             warndiff=0.5, cleanup=True, returnFracDiff=False, 
             chanrange='92.1875%', mymsmd='', showtsky=False, 
             maxAltitude=48, dP=5.0, dPm=1.1, hanning='auto'):
    """
    Plot the Tsys from the SYSCAL table of the specified ms.  
    Produce a multi-page pdf.
    Inputs:
    xaxis: 'freq' (default) or 'chan'
    gs: full path to ghostscript's gs
    antenna: a single antenna ID (as integer or string) or name
    overlay: '' or 'antenna'
    pol: '' or 'X' or 'Y'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax]
    renumber: renumbers the spws to start at 0, default order: (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: overlay atmospheric transmission
    scan: limit the result to this single scan
    verbose: if True, then print median for each spw/antenna
    doplot: if False, then don't plot anything, just return the medians
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    chanrange: use this percentage of central channels to autoscale the y-axis
    maxAltitude: of the atmosphere, in km
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
    Consider moving this to class CalTableExplorer someday
    Todd Hunter
    """
    if (buildpdf and figfile==''):
        figfile = True
    result = plotTspectrum(vis=vis, antenna=antenna, spw=spw, xaxis=xaxis,t='tsys',gs=gs,
                      buildpdf=buildpdf, interactive=interactive,figfile=figfile,
                      overlay=overlay, plotrange=plotrange, pol=pol, renumber=renumber,
                      replace=replace, showatm=showatm, scan=scan, verbose=verbose, 
                      fontsize=fontsize, doplot=doplot, atmcal=atmcal, 
                      returnMedians=returnMedians, grid=grid, warndiff=warndiff, 
                      cleanup=cleanup, returnFracDiff=returnFracDiff, 
                      chanrange=chanrange, mymsmd=mymsmd, showtsky=showtsky,
                      maxAltitude=maxAltitude, dP=dP, dPm=dPm, hanning=hanning)
    return(result)

def plotTrx(vis='', antenna = '', spw='', xaxis='freq', gs='gs',
            buildpdf=False, interactive=True, overlay='',
            plotrange=[0,0,0,0],pol='',figfile='', renumber=False, replace={},
            showatm=False, scan='', verbose=False, fontsize=12, doplot=True,
            atmcal=None, returnMedians='median', grid=True, warndiff=0.5, 
            cleanup=True, returnFracDiff=False, chanrange='92.1875%',
            showSpec=True, baseband='', showtsky=False, atmlw=1, hanning='auto'):
    """
    Plot the Trx from the SYSCAL table of the specified ms.  
    and (optionally) produce a multi-page pdf.
    Inputs:
    xaxis: 'freq' (default) or 'chan'
    gs: full path to ghostscript's gs
    antenna: a single antenna ID (as integer or string) or name
    overlay: '' or 'antenna'
    pol: '' or 'X' or 'Y'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax] or simply [xmin,xmax]
    renumber: renumbers the spws to start at 0, in the original order (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: overlay atmospheric transmission
    scan: limit the result to this single scan
    verbose: if True, then print median for each spw/antenna
    doplot: if False, then don't plot anything, just return the medians
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    chanrange: use this percentage of central channels to autoscale the y-axis
    showSpec: also show the spec for 80 & 100% of the band as green lines
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
    Consider moving this to class CalTableExplorer someday
    - Todd Hunter
    """
    if (buildpdf and figfile==''):
        figfile = True
    result = plotTspectrum(vis=vis, antenna=antenna, spw=spw, xaxis=xaxis,t='trx',gs=gs,
                           buildpdf=buildpdf, interactive=interactive,figfile=figfile,
                           overlay=overlay, plotrange=plotrange, pol=pol, renumber=renumber,
                           replace=replace, showatm=showatm, scan=scan, verbose=verbose, 
                           fontsize=fontsize, doplot=doplot, atmcal=atmcal, 
                           returnMedians=returnMedians, grid=grid, warndiff=warndiff, 
                           cleanup=cleanup, returnFracDiff=returnFracDiff, 
                           chanrange=chanrange, showSpec=showSpec, baseband=baseband,
                           showtsky=showtsky, atmlw=atmlw, hanning=hanning)
    return result

def plotTcal(vis='', antenna = '', spw='', xaxis='freq', gs='gs',
            buildpdf=False, interactive=True, overlay='',
            plotrange=[0,0,0,0],pol='',figfile='', renumber=False, replace={},
            showatm=False, scan='', verbose=False, fontsize=12, doplot=True,
            atmcal=None,returnMedians='median', grid=True, warndiff=0.5, 
            cleanup=True, returnFracDiff=False, chanrange='92.1875%',
            showSpec=True, baseband='', showtsky=False, atmlw=1, hanning='auto'):
    """
    Plot the Tcal spectrum from the SYSCAL table of the specified ms.  
    and (optionally) produce a multi-page pdf.
    Inputs:
    xaxis: 'freq' (default) or 'chan'
    gs: full path to ghostscript's gs
    antenna: a single antenna ID (as integer or string) or name
    overlay: '' or 'antenna'
    pol: '' or 'X' or 'Y'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax] or simply [xmin,xmax]
    renumber: renumbers the spws to start at 0, in the original order (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: overlay atmospheric transmission
    scan: limit the result to this single scan
    verbose: if True, then print median for each spw/antenna
    doplot: if False, then don't plot anything, just return the medians
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    chanrange: use this percentage of central channels to autoscale the y-axis
    showSpec: show the spec for 80 & 100% of the band as green lines
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
    Consider moving this to class CalTableExplorer someday
    - Todd Hunter
    """
    if (buildpdf and figfile==''):
        figfile = True
    result = plotTspectrum(vis=vis, antenna=antenna, spw=spw, xaxis=xaxis,t='tcal',gs=gs,
                      buildpdf=buildpdf, interactive=interactive,figfile=figfile,
                      overlay=overlay, plotrange=plotrange, pol=pol, renumber=renumber,
                      replace=replace, showatm=showatm, scan=scan, verbose=verbose, 
                      fontsize=fontsize, doplot=doplot, atmcal=atmcal, 
                      returnMedians=returnMedians, grid=grid, warndiff=warndiff, 
                      cleanup=cleanup, returnFracDiff=returnFracDiff, 
                      chanrange=chanrange, showSpec=showSpec, baseband=baseband,
                           showtsky=showtsky, atmlw=atmlw, hanning=hanning)
    return result

def plotTant(vis='', antenna = '', spw='', xaxis='freq', gs='gs',
            buildpdf=False, interactive=True, overlay='',
            plotrange=[0,0,0,0],pol='',figfile='', renumber=False, replace={},
            showatm=False, scan='', verbose=False, fontsize=12, doplot=True,
            atmcal=None,returnMedians='median', grid=True, warndiff=0.5, 
            cleanup=True, returnFracDiff=False, chanrange='92.1875%',
             showSpec=True, baseband='', showtsky=False, atmlw=1, hanning='auto'):
    """
    Plot the Tant spectrum from the SYSCAL table of the specified ms.  
    and (optionally) produce a multi-page pdf.
    Inputs:
    xaxis: 'freq' (default) or 'chan'
    gs: full path to ghostscript's gs
    antenna: a single antenna ID (as integer or string) or name
    overlay: '' or 'antenna'
    pol: '' or 'X' or 'Y'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax] or simply [xmin,xmax]
    renumber: renumbers the spws to start at 0, in the original order (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: overlay atmospheric transmission
    scan: limit the result to this single scan
    verbose: if True, then print median for each spw/antenna
    doplot: if False, then don't plot anything, just return the medians
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    chanrange: use this percentage of central channels to autoscale the y-axis
    showSpec: show the spec for 80 & 100% of the band as green lines
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
    Consider moving this to class CalTableExplorer someday
    - Todd Hunter
    """
    if (buildpdf and figfile==''):
        figfile = True
    result = plotTspectrum(vis=vis, antenna=antenna, spw=spw, xaxis=xaxis,t='tant',gs=gs,
                      buildpdf=buildpdf, interactive=interactive,figfile=figfile,
                      overlay=overlay, plotrange=plotrange, pol=pol, renumber=renumber,
                      replace=replace, showatm=showatm, scan=scan, verbose=verbose, 
                      fontsize=fontsize, doplot=doplot, atmcal=atmcal, 
                      returnMedians=returnMedians, grid=grid, warndiff=warndiff, 
                      cleanup=cleanup, returnFracDiff=returnFracDiff, 
                      chanrange=chanrange, showSpec=showSpec, baseband=baseband,
                      showtsky=showtsky, atmlw=atmlw, hanning=hanning)
    return result

def plotTsky(vis='', antenna = '', spw='', xaxis='freq', gs='gs',
             buildpdf=False, interactive=True, overlay='',
             plotrange=[0,0,0,0],pol='',figfile='',renumber=False, replace={},
             showatm=False, scan='', verbose=False, fontsize=12, doplot=True,
             atmcal=None, returnMedians='median', grid=True, warndiff=0.5, 
             cleanup=True, returnFracDiff=False, chanrange='92.1875%',
             showtsky=False, maxAltitude=48, dP=5.0, dPm=1.1, atmlw=1, 
             atmcolor='m', atmls='-', atmmarker='', hanning='auto', 
             histogramBins=-1, atmType=1):
    """
    Plot the Tsky from the SYSCAL table of the specified ms.  
    Produce a multi-page pdf.
    Inputs:
    xaxis: 'freq' (default) or 'chan'
    antenna: a single antenna ID (as integer or string) or name, or list thereof
    gs: full path to ghostscript's gs
    overlay: '' or 'antenna'
    pol: '' or 'X' or 'Y'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax] or simply [xmin,xmax]
    renumber: renumbers the spws to start at 0, in the original order (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: overlay atmospheric transmission
    scan: limit the result to this single scan
    verbose: if True, then print median for each spw/antenna
    doplot: if False, then don't plot anything, just return the medians
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    chanrange: use this percentage of central channels to autoscale the y-axis
    dP: pressure step, has units of pressure (mb)
    dPm: pressure step factor (unitless) called PstepFact in TelCal
    maxAltitude: of the atmosphere, in km
    atmlw: linewidth of the atmospheric plot
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    histogramBins: desired number of bins for tskyOffset (if showtsky==True)
             default=-1 --> nSpectra/10
    atmType: 1, 2, or 3, default=1=tropical, 2=midLatSummer, 3=midLatWinter
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
    Consider moving this to class CalTableExplorer someday
    Todd Hunter
    """
    if (buildpdf and figfile==''):
        figfile = True
    result = plotTspectrum(vis, antenna, spw, xaxis, 'tsky', gs, buildpdf, interactive,
                           overlay, plotrange, pol, figfile, renumber, replace, showatm,
                           scan, verbose, fontsize, doplot, atmcal, returnMedians, grid, 
                           warndiff, cleanup, returnFracDiff, chanrange, showtsky=showtsky, 
                           maxAltitude=maxAltitude, dP=dP, dPm=dPm, atmlw=atmlw, atmcolor=atmcolor, 
                           atmls=atmls, atmmarker=atmmarker, hanning=hanning, 
                           histogramBins=histogramBins, atmType=atmType)
    return result

def plotspws(vis, intents=['*ATMOS*', '*PHASE*', '*BANDPASS*', '*TARGET*'], 
             tsystable='', plotfile=''):
    """
    Makes a plot summarizing the location of the non-channel-averaged TDM and FDM ALMA spws 
    in a dataset.
    intents: a list of strings, or a comma-delimited string
    tsystable: name of the Tsys table to use (default='*.tsys')
        if found, then it will run tsysspwmap and draw in red the spws 
        used for Tsys for the science spws
    -Todd Hunter
    """
    from recipes.almahelpers import tsysspwmap
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    try:
        almaspws = mymsmd.almaspws(tdm=True,fdm=True)
    except:
        print "This version of CASA is too old to support msmd.almaspws()."
        return
    sciencespws = []
    if (type(intents) == str):
        intents = intents.split(',')
    for intent in intents:
        intent = '*' + intent + '*'
        intentspws = mymsmd.spwsforintent(intent)
        spws = np.intersect1d(intentspws,almaspws)
        if (intent.find('TARGET')>=0):
            sciencespws = spws
    pb.clf()
    pb.subplot(211)
    pb.title(os.path.basename(vis) + '  -  Upper sideband')
    pb.ylabel('Spw')
    pb.hold(True)
    if (tsystable == ''):
        if (os.path.dirname(vis) != ''):
            tsystable = os.path.dirname(vis)+'/'
        tsystable += os.path.basename(vis)+'.tsys'
    if (os.path.exists(tsystable) and len(sciencespws) > 0):
        try:
            tsysmap = tsysspwmap(vis, tsystable)
            print "Science spws: ", sciencespws
            tsysmapstring = 'Tsys spw map: '
            for spw in sciencespws:
                tsysmapstring += '%d: %d,  ' % (spw,tsysmap[spw])
            print tsysmapstring.rstrip(',  ')
            sciencetsys = np.array(tsysmap)[sciencespws]
        except:
            sciencetsys = []
    else:
        print "Could not open tsystable = ", tsystable
        print "Will not color-code the Tsys windows as red."
        sciencetsys = []
    pb.subplot(212)
    pb.xlabel('Frequency (GHz)')
    pb.ylabel('Spw')
    pb.title('Lower sideband')
    mysize = 7
    print "This function takes awhile because msmd.intentsforspw() is slow."
    allspws = []
    sciencespws = []
    phasespws = []
    adesc = None
    bdesc = None
    for intent in intents:
        intent = '*' + intent + '*'
        print "Working on intent = ", intent
        intentspws = mymsmd.spwsforintent(intent)
        if (intent.find('TARGET') >= 0):
            sciencespws = intentspws
        elif (intent.find('PHASE') >= 0):
            phasespws = intentspws
        spws = np.intersect1d(intentspws,almaspws)
        allspws += list(spws)
        for spw in spws:
#            print "Working on spw = ", spw
            freqs = mymsmd.chanfreqs(spw) * 1e-9
            sideband = mymsmd.sideband(spw)
            if (sideband == -1):
                adesc = pb.subplot(212)
            else:
                bdesc = pb.subplot(211)
            color = 'k-'
            if (spw in sciencetsys):
                color = 'r' # color the Tsys windows chosen for science spws
            chanwidths = mymsmd.chanwidths(spw) * 1e-9
            pb.plot([np.min(freqs)-0.5*abs(chanwidths[0]), np.max(freqs)+0.5*abs(chanwidths[0])], [spw,spw], color)
            allintents = mymsmd.intentsforspw(spw)
            titleString = ''
            for allintent in allintents:
                for myintent in intents:
                    if (allintent.find(myintent.replace('*','')) >= 0):
                        if (titleString.find(myintent.replace('*','')) < 0):
                            titleString += myintent.replace('*','') + ','
            titleString = titleString.rstrip(',')
            pb.text(np.mean(freqs), spw+0.1, ' BB%d: %s'%(mymsmd.baseband(spw),titleString), size=mysize, ha='center')
    allspws = np.unique(allspws)
    mymsmd.close()
    if (sciencespws != []):
        aggregateBandwidth = computeAggregateBandwidth(vis, np.intersect1d(almaspws,sciencespws))
        print "Aggregate science bandwidth = %f GHz" % (aggregateBandwidth*1e-9)
    if (phasespws != []):
        aggregateBandwidth = computeAggregateBandwidth(vis, np.intersect1d(almaspws,phasespws))
        print "Aggregate phasecal bandwidth = %f GHz" % (aggregateBandwidth*1e-9)
    pb.subplot(211)
    pb.ylim([pb.ylim()[0]-0.5, pb.ylim()[1]+0.5])
    freqPad = 0.3
    pb.xlim([pb.xlim()[0]-freqPad, pb.xlim()[1]+freqPad])
    pb.subplot(212)
    pb.ylim([pb.ylim()[0]-0.5, pb.ylim()[1]+0.5])
    pb.xlim([pb.xlim()[0]-freqPad, pb.xlim()[1]+freqPad])
    if (adesc is not None):
        # LSB spws are present
        adesc.xaxis.grid(True,which='major')
        adesc.yaxis.grid(True,which='major')
        adesc.yaxis.set_major_locator(MultipleLocator(2))
        resizeFonts(adesc,mysize)
    if (bdesc is not None):
        # USB spws are present
        bdesc.yaxis.set_major_locator(MultipleLocator(2))
        bdesc.xaxis.grid(True,which='major')
        bdesc.yaxis.grid(True,which='major')
        resizeFonts(bdesc,mysize)
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = os.path.basename(vis.rstrip('/') + '.plotspws.png')
        pb.savefig(plotfile)
        print "Saved plot in ", plotfile

def plotTrxs(vis='', antenna = '', spw='', xaxis='freq', t='trx', gs='gs',
             buildpdf=False, interactive=True, overlay='', plotrange=[0,0,0,0],
             pol='', figfile='', renumber=False, replace={},
             showatm=False, scan='',verbose=False, fontsize=12, doplot=True, 
             atmcal=None, returnMedians='median', grid=False, pdfname='', showtsky=False):
    """
    Calls plotTspectrum(t='trx') repeatedly for a list of scans.
    -Todd Hunter
    """
    if (type(scan) != list):
        if type(scan) == str:
            scan = [int(i) for i in scan.split(',')]
        else:
            print "scan must be a list or a comma-delimited string."
            return
    figfilenames = []
    for s in scan:
        figfilenames.append(figfile.replace('.png','') + '.scan%02d.png'%s)
        print "Calling plotTspectrum(figfile='%s')" % (figfilenames[-1])
        result = plotTspectrum(vis=vis, antenna=antenna, spw=spw, xaxis=xaxis,
                          t='trx', gs=gs, buildpdf=False, 
                          interactive=interactive, figfile=figfilenames[-1],
                          overlay=overlay, plotrange=plotrange, pol=pol, 
                          renumber=renumber, replace=replace, showatm=showatm, 
                          scan=s, verbose=verbose, fontsize=fontsize, 
                          doplot=doplot, atmcal=atmcal, showtsky=showtsky,
                          returnMedians=returnMedians, grid=grid)
        atmcal = result[1]
    if (buildpdf):
        if (pdfname == ''):
            pdfname = vis+'.%s.pdf'%str(t)
        buildPdfFromPngs(figfilenames, pdfname=pdfname)
        print "PDF left in %s" % (pdfname)

def channelAverageChannels(channels):
    """
    Computes the list of channels used by TelCal for the channel-averaged spw, 
    whose bandwidth is 1781.25 MHz in TDM mode.
    -Todd Hunter
    """
    nchan = channels*0.890625
    start = int(np.round((channels - nchan)/2.0 - 1))
    end = int(np.round(start+nchan))
    return(range(start,end))

def bandforspw(spw, vis='', mymsmd=''):
    """
    Uses namesforspw and parses out the ALMA band name.
    Returns 0 for the WVR, otherwise 1..10
    Accepts either a measurement set name or an msmd instance.
    Works for CASA >= 4.3.0
    -Todd Hunter
    """
    spw = int(spw)
    if (vis == '' and mymsmd == ''):
        return
    elif (vis == ''):  # mymsmd has been specified
        name = mymsmd.namesforspws(spw)[0]
        if (name.find('ALMA_RB') < 0):
            if (spw in mymsmd.wvrspws()):
                return 0
            if (spw in mymsmd.almaspws(sqld=True)):
                baseband = mymsmd.baseband(spw)
                almaspws = mymsmd.almaspws(tdm=True,fdm=True)
                spwsforbaseband = mymsmd.spwsforbaseband(baseband)
                mylist = np.intersect1d(almaspws,spwsforbaseband)
                if (len(mylist) < 1):
                    print "No matching correlator spw found for this SQLD spw."
                    return -1
                else:
                    name = mymsmd.namesforspws(mylist[0])[0]
                    return(int(name.split('ALMA_RB_')[1].split('#')[0]))
            print "Not an ALMA spw."
            return None
        return(int(name.split('ALMA_RB_')[1].split('#')[0]))
    else: # vis has been specified
        if (mymsmd == ''):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            band = bandforspw(spw,mymsmd=mymsmd)  # uses recursion!
            mymsmd.close()
        else:
            band = bandforspw(spw,mymsmd=mymsmd)  # uses recursion!
        return band

def receiverTrxSpec(band, value='trx'):
    """
    Returns the receiver specification for a given quantity
    value: 'trx' (over 100% of the band) 'trx2' (over 80% of the band)
    Values are from ALMA-80.04.00.00-005-C-SPE, except for band 3, 
       for which the value is from ALMA-40.02.03.00-230-A-CRE
    -Todd Hunter
    """
    trx = {1:26, 2:47, 3:60, 4:82, 5:75, 6:136, 7:219, 8: 292, 9: 261, 10: 344}
    trx2 = {1:17, 2:30, 3:37, 4:51, 5:55, 6:83,  7:147, 8: 196, 9: 175, 10: 230}
    if (value.lower() == 'trx'):
        if (int(band) not in trx.keys()):
            print "Band not in ", trx.keys()
            return(0)
        return(trx[band])
    elif (value.lower() == 'trx2'):
        if (int(band) not in trx.keys()):
            print "Band not in ", trx.keys()
            return(0)
        return(trx2[band])
    else:
        print "Unrecognized quantity: ", value
        return 0 

def overlayAtmosphere(vis, antenna, scan, verbose, mymsmd, antennas, spw, maxAltitude, dP, dPm,
                      hanning, doplot, atmcolor, atmlw, atmls, atmmarker, showatm, showtsky, 
                      shownAtm, conditionDict, atmcal, plotrange, t, antennaNames, atmType):
    """
    With an existing plot active (e.g in plotTspectrum), this will overlay an atmospheric
    model curve. See plotTspectrum for definition of parameters, from which it was extracted.
    See au.plotAtmosphere for a standalone implementation.
    Returns: shownAtm and medianTsky
    """
    pwv, pwvstd = getMedianPWV(vis)
    if scan not in conditionDict:
        conditionDict[scan] = listconditions(vis, scan, verbose=False, mymsmd=mymsmd)
    conditions = conditionDict[scan]
    P = conditions['pressure']
    H = conditions['humidity']
    T = celsiusToKelvin(conditions['temperature'])
    siteAltitude_m = antennaEllipsoidalHeight(vis, antenna, mymsmd)
    padname = getAntennaPads(vis, mymsmd=mymsmd)[antennas[i]] # i is the index of the 'for' loop
    observatory = almaPadnameToObservatoryName(padname)
    airmass = conditions['airmass']
    elevation = conditions['elevation']
    if not shownAtm:
        print "conditions: height=%.0fm, P=%.0fmb, H=%.1f%%, T=%.1fK" % (siteAltitude_m, P, H, T)
    shownAtm = True
    net_sideband = sidebandToNetSideband(mymsmd.sideband(spw))
    chanfreqs = mymsmd.chanfreqs(spw)
    if (len(chanfreqs) < 2):
        print "This spw has only 1 channel"
        return
    refFreqInTable = chanfreqs[0] - 0.5*(chanfreqs[1]-chanfreqs[0])
    chans = range(len(chanfreqs))
    if hanning == 'auto':
        if atmcal is None:
            hanning = False
        else:
            hanning = atmcal.hanningSmoothed[spw]
    freq, chans, transmission, TebbSky, tau = CalcAtmosphere(chans,chanfreqs*1e-9,pwv,refFreqInTable,
                                                             net_sideband,P,H,T,airmass, maxAltitude=maxAltitude, 
                                                             dP=dP, dPm=dPm, hanning=hanning,atmType=atmType)
    medianTsky = np.median(TebbSky)
    if doplot: 
        if (plotrange[2] != 0 or plotrange[3] != 0):
            y0,y1 = plotrange[2:]
        else:
            y0,y1 = pb.ylim()
        yrange = y1-y0
        if showtsky:
            tstring = 'Tsky'
            if t=='tsky': 
                # direct overlay is best
                print "Calling plot(%s,lw='%s',ls='%s',marker='%s') with %d atm channels" % (atmcolor,atmlw,atmls,atmmarker,len(chans))
                pb.plot(freq, TebbSky, atmcolor, lw=atmlw, ls=atmls, marker=atmmarker)
            else:
                # scale to use full y-range
                if plotrange[:2] == [0,0]:
                    idx = np.range(len(tsys[0]))
                else:
                    idx = np.where((freq > plotrange[0]) * (freq < plotrange[1]))
                y0 = min(np.min(tsys[0][idx]),np.min(tsys[1][idx]))
                yrange = max(np.max(tsys[0][idx]),np.max(tsys[1][idx])) - y0
                # Center the Tsys spectrum along the y-axis, with a pad according 
                # to the difference between the mean Tsys of the X and Y pol
                ydiff = np.abs(np.median(tsys[1][idx])-np.median(tsys[0][idx]))
                # print "y0=%f, yrange=%f, ydiff=%f" % (y0,yrange,ydiff)
                pb.plot(freq, y0+0.5*ydiff+(TebbSky-min(TebbSky[idx]))/(max(TebbSky[idx])-min(TebbSky[idx]))*(yrange-ydiff),'m-', lw=atmlw)
        elif showatm:
            pb.plot(freq, y0+transmission*yrange,'m-')
            tstring = 'trans.'
        if (antennaNames[antennas[i]].find('CM')>=0):
            myString = tstring + " model: PWV=%.2fmm, maxAlt.=%d km, dP=%.0fmb, dPm=%.1f" % (pwv,maxAltitude,dP,dPm)
        else:
            myString = tstring + " model: med.PWV=%.2fmm, el=%.0f, maxAlt.=%d km, dP=%.0fmb, dPm=%.1f" % (pwv,elevation,maxAltitude,dP,dPm)
        pb.text(0.01,0.96,myString, transform=pb.gca().transAxes,color='m')
        myString = '%s: siteAltitude=%.0fm, P=%.1fmb, H=%.1f%%, T=%.1fK' % (observatory, siteAltitude_m, P, H, T)
        if hanning: myString += ', hanning'
        pb.text(0.01,0.92,myString, transform=pb.gca().transAxes,color='m')
        if showtsky and t != 'tsky':
            pb.text(0.01,0.88,'(vertically shifted and scaled)', transform=pb.gca().transAxes,color='m')
    return shownAtm, medianTsky
    
def plotTspectrum(vis='', antenna='', spw='', xaxis='freq', t='tsys', gs='gs',
                  buildpdf=False, interactive=True, overlay='', plotrange=[0,0,0,0],
                  pol='', figfile='', renumber=False, replace={},
                  showatm=False, scan='',verbose=False, fontsize=12, doplot=True, 
                  atmcal=None, returnMedians='median', grid=False, warndiff=0.5, 
                  cleanup=True, returnFracDiff=False, chanrange='92.1875%',
                  showSpec=True, mymsmd='', baseband='', showtsky=False, 
                  maxAltitude=48, dP=5.0, dPm=1.1, atmlw=1, atmcolor='m', atmls='-',
                  atmmarker='.', hanning='auto', histogramBins=-1, atmType=1,
                  doplotMedian=True):
    """
    Plot either the Tsys, Trx or Tsky from the SYSCAL table of the specified
    ms.  Can produce a multi-page pdf.
    Inputs:
    t: 'tsys' (default), 'trx' or 'tsky'
    xaxis: 'freq' (default) or 'chan'
    gs: full path to ghostscript's gs
    antenna: a single antenna ID (as integer or string) or name, or list thereof
    overlay: '' or 'antenna'
    pol: '' (for both pols), or 'X' or 'Y', or 0 or 1 or '0' or '1'
    spw: single value or list: '5' or 5 or [5]
    figfile:  '' (no png produced) or filename
    buildpdf: True or False
    interactive: True or False
    plotrange: [xmin, xmax, ymin, ymax] or simply [xmin,xmax]
    renumber: renumbers the spws to start at 0, in the original order (9,11,13,15-->0,1,2,3)
    replace: provide a dictionary for the renumbering, e.g. {9:0, 11:1, 13:2, 15:3}
    showatm: if True, then overlay atmospheric transmission
    showtsky: if True, then overlay atmospheric radiative temperature
    scan: limit the results to a single scan, multiple scans will generate separate pages
    verbose: if True, then print median for each spw/antenna
    atmcal: an instance of class Atmcal; if None, then run Atmcal
            if False, then first try the faster, less robust method
    warndiff: if the two pols differ by this fraction, print a warning
    cleanup: remove pngs and single page PDFs (only used if buildpdf==True) 
    returnFracDiff: if True, return a dictionary describing warndiff
    chanrange: use this percentage of central channels to autoscale the y-axis
    showSpec: show spec for 80 & 100% of band as green lines (only relevant to Trx)
    maxAltitude: of the atmosphere, in km
    doplot: if True, then show the plot of each combination
    doplotMedian: if returnMedians=='medianspectrum', this controls whether plot is shown
    returnMedians: 'median', 'mean', 'medianspectrum' (the latter generates plots)
       in option 'medianspectrum', you must set doplot=False to plot the median spectrum,
         and the pol parameter should not be used, since both spectra are always returned
    hanning: True, False, or 'auto'; applies to ATM model only (passed to CalcAtmosphere)
    histogramBins: desired number of bins for tskyOffset (if showtsky==True)
             default=-1 --> nSpectra/10
    atmType: 1, 2, or 3, default=1=tropical, 2=midLatSummer, 3=midLatWinter
    Returns:
       * a dictionary keyed by spw ID, with values = median 
       * the Atmcal instance
       * a dictionary with values: medians (if returnMedians=='median', else 'mean', 'medianspectrum')
       * a dictionary with values = percentage greater than warndiff (if returnFracDiff==True)
    Consider moving this to class CalTableExplorer someday
    Todd Hunter
    """
    if len(plotrange) < 4:
        # pad the list with zeros
        plotrange = list(plotrange) + list(np.zeros(4-len(plotrange)))
#    if returnMedians=='medianspectrum' and not doplot:
#        doplotMedian = True
#    else:
#        doplotMedian = False
    if returnMedians != 'medianspectrum' or doplot:
        doplotMedian = False
    medianValues = {}
    meanValues = {}
    medianSpectra = {}
    if (os.path.exists(vis) == False):
        print "The ms does not exist."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (os.path.exists(vis+'/SYSCAL') == False):
        print "The SYSCAL table for that ms does not exist."
        return
    t = t.lower()
    if (t not in ['tsys','trx','tsky','tcal','tant']):
        print "t must be either tsys, trx, tsky, tcal or tant"
        return
    if (overlay != '' and overlay != 'antenna'):
        print "You can only overlay 'antenna' or nothing ('')."
        return
    pol = str(pol).upper()
    if (pol not in ['','X','Y']):
        if (pol == '0' or pol == 0):
            pol = 'X'
        elif (pol == '1' or pol == 1):
            pol = 'Y'
        else:
            print "pol must be 'X' or 'Y' or '' or 0 or 1 or '0' or '1'"
            return
    msmdCreated = False
    if (casadef.casa_version >= casaVersionWithMSMD):
        if (mymsmd == ''):
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            msmdCreated = True
        elif verbose:
            print "plotTspectrum(): Using existing mymsmd instance"
    else:
        scanString = ''
    antenna = parseAntenna(vis,antenna, mymsmd)
    if (antenna is None):
        print "Antenna not found in dataset."
        return
    if doplot: 
        print "Antennas to show = ", np.unique(antenna)
    antennaNames = getAntennaNames(vis)  # does not use msmd
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SYSCAL')
    antennas = mytb.getcol('ANTENNA_ID')
    times = mytb.getcol('TIME')
    intervals = mytb.getcol('INTERVAL')
    times -= 0.5*intervals
    if (len(antennas) < 1):
        print "The SYSCAL table is blank"
        return
    if doplot: print "Antennas in data = ", np.unique(antennas)
    if (spw=='' and baseband != ''):
        spw = spwsforintent_nonwvr_nonchanavg(mymsmd,'CALIBRATE_ATMOSPHERE*')
        validSpws = getSpwsForBaseband(mymsmd, int(baseband))
        spw = np.intersect1d(spw,validSpws)
        print "Using spw = ", spw
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    basebands = {}
    bands = {}
    for s in np.unique(spws):
        basebands[s] = mymsmd.baseband(s)
        bands[s] = bandforspw(s, mymsmd=mymsmd)
    if (renumber):
        if (replace == {}):
            ctr = 0
            for u in np.unique(spws):
                replace[u] = ctr
                ctr += 1
        newspws = copy(spws)
        for k, v in replace.iteritems(): newspws[spws==k] = v
        spws = newspws
    uniqueAntennas = np.unique(antennas)
    mytb.close()
    if (verbose): print "spws = ", np.unique(spws)
    if (scan != ''):
        if (casadef.casa_version < casaVersionWithMSMD):
            print "The scan parameter is not supported in this casa version (<4.1.0)."
            return
    if (casadef.casa_version >= casaVersionWithMSMD):
        scans = []
        if (atmcal == False):
            # This was the old-fashioned way of doing things
            if (verbose): print "Matching %d times to scans..." % (len(times))
            timeBuffer = 30
            for i in range(len(times)):
                tol = 0
                myscans = mymsmd.scansfortimes(times[i]+timeBuffer,tol=tol)
                while (len(myscans) < 1 and tol<60):
                    tol += 1
                    myscans = mymsmd.scansfortimes(times[i]+timeBuffer,tol=tol)
                    if (scan != '' and tol<60):
                        if (int(scan) not in myscans):
                            myscans = []
                if (len(myscans) > 0):
                    scans.append(myscans[0])
        if (len(scans) == 0):
            if (atmcal==False):
                print "Could not match Tsys times to scan number using the quick method.  Using class Atmcal."
            if (atmcal == False or atmcal is None):
                atmcal = Atmcal(vis, verbose=verbose, warnIfNoLoadTemperatures=False, mymsmd=mymsmd, loadLOs=False)
            for i in range(len(antennas)):
                scans.append(atmcal.nearestCalScan(times[i]))
        uniqueScans = np.unique(scans)
        if (verbose):
            print "unique scans = ", uniqueScans
            print "len(scans)=%d, len(antennas)=%d" % (len(scans), len(antennas))
    pdfs = ''
    if pol == '':
        # only first two are ever used since there is no cross-pol Tsys
        if overlay == '':
            lines = ['-','-','..','-.']
        else:
            lines = ['-','--','..','-.']
    else:
        # only one pol specified, so draw a solid line in all cases
        lines = 4*['-']
    if doplot: 
        pb.clf()
        adesc = pb.subplot(111)
    if (spw == ''):
        # default to all spws
        spwlist = np.unique(spws)
    elif (type(spw) == list):
        if (type(spw[0]) == int):
            spwlist = spw
        else:
            spwlist = map(int, spw)
    elif (type(spw) == str):
        if (spw.find(',')>=0):
            intstrings = spw.split(',')
            spwlist = map(int, intstrings)
        else:
            if (spw.isdigit()):
                spwlist = [int(spw)]
            else:
                print "spw must be '' or an integer or integer string"
                return
    else:
        spwlist = [int(spw)]
    myinput = ''
    uniqueSpws = np.unique(spws)
#    print "spws to show = ", spwlist
    meansPerPol = {}
    if (type(scan) in [int,np.int32,np.int64,float,np.float64]):
        scanlist = [int(scan)]
    elif (type(scan) == str):
        if (scan == ''):
            scanlist = uniqueScans
        else:
            scanlist = [int(i) for i in scan.split(',')]
    else:
        scanlist = scan
    fracdiffs = {}
    conditionDict = {} # will be filled with scan numbers as keys.  Used to avoid recalculating conditions for multiple spws/antennas per scan.
    tskyOffset = []
    for scan in scanlist:
     if True or verbose: print "processing scan ", scan
     fracdiffs[scan] = {}
     if (len(scanlist) > 1):
         if (figfile != ''):
             print "Forcing automatic naming of png files including scan number."
             figfile = True  # force auto naming of multiple pngs
     medianTsky = {} # will be a dictionary keyed by spw if showtsky=True
     for spw in spwlist:
      if spw not in medianTsky:
          medianTsky[spw] = None
      if verbose: print "processing spw ", spw
      if returnMedians=='medianspectrum' and not doplot:
         lo1ghz = interpretLOs(vis, mymsmd=mymsmd)[spw] * 1e-9
      if (spw not in uniqueSpws):
          print "spw %d is not in the SYSCAL table: " % (spw), uniqueSpws
          continue
      colorctr = 0
      if (myinput == 'q'):
          break
      if doplot: 
          pb.clf()
          adesc = pb.subplot(111)
      medians = []
      means = []
      allspectra = []

      # figure out how many there will be
      ctr = 0
      for i in range(len(antennas)):
          if (spws[i] == spw):
              if (antennas[i] in antenna):
                  ctr += 1
              
      shownAtm = False
      meansPerPol[spw] = {0: [], 1: []}  # dictionary keyed by polarization number (0=X, 1=Y)
      for i in range(len(antennas)):
        if (antennas[0] == antennas[i]):
            colorctr = 0
        if (spws[i] == spw):
          if (antennas[i] in antenna):
            if (scan != ''):
                scan = int(scan)
                if (scan != scans[i]): continue
            if (overlay=='' and doplot):
                pb.clf()
                adesc = pb.subplot(111)
                mycolor = 'k'
            if (overlay=='' and (doplot or doplotMedian)):
                if pol == '':
                    mypolcolor = ['k','r']
                else:
                    mypolcolor = ['k','k']
            else:
                mycolor = overlayColors[antennas[i]]
            mytb.open(vis+'/SYSCAL')
            if (t == 'tsys'):
                tsys = mytb.getcell('TSYS_SPECTRUM',i)
                ylab = 'Tsys from Telcal (K)'
            elif (t == 'trx'):
                tsys = mytb.getcell('TRX_SPECTRUM',i)
                ylab = 'Trx from Telcal (K)'
            elif (t == 'tsky'):
                tsys = mytb.getcell('TSKY_SPECTRUM',i)
                ylab = 'Tsky from Telcal (K)'
            elif (t == 'tant'):
                if mytb.iscelldefined('TANT_SPECTRUM',i):
                    tsys = mytb.getcell('TANT_SPECTRUM',i)
                    ylab = 'Tant from Telcal (K)'
                else:
                    print "No data in this column"
                    return
            elif (t == 'tcal'):
                tsys = mytb.getcell('TCAL_SPECTRUM',i)
                ylab = 'Tcal from Telcal (K)'
            mytb.close()
            medians.append(np.median(tsys))
            means.append(np.mean(tsys))
            allspectra.append(tsys) # generally, this will be a list of two spectra, one per pol
            try:
                freq = getFrequencies(vis, spws[i])*1e-9  # does not use msmd
            except:
                print "spw %d is not in the ms=%s.  Try setting renumber=True." % (spws[i],vis)
                return
            if (xaxis=='freq'):
                for j in range(len(tsys)): # i.e. nPolarizations
                    centralChannels = channelAverageChannels(len(tsys[j]))
                    if (pol=='' or (pol=='X' and j==0) or (pol=='Y' and j==1)):
                        if (renumber and len(freq) != len(tsys[j])):
                            # resample freq back down to tsys
                            newIncrement =  (freq[-1]-freq[0])/(len(tsys[j])-1.0)
                            freq = np.mgrid[freq[0]:(freq[-1]+newIncrement):newIncrement]
                        if doplot: 
                            if (overlay == ''):
                                pb.plot(freq,tsys[j],'-', color=mypolcolor[j], ls=lines[j])
                            else:
                                pb.plot(freq,tsys[j],'-', color=mycolor, ls=lines[j])
                        meansPerPol[spw][j].append(np.mean(tsys[j][centralChannels]))
                        if (verbose):
                            if (casadef.casa_version >= casaVersionWithMSMD):
                                print "Scan %2d, spw %2d, ant %2d=%s: Mean of central 89%% channels for pol%d = %f" % (scans[i], spws[i], antennas[i], antennaNames[antennas[i]], j, np.mean(tsys[j][centralChannels]))
                            else:
                                print "Mean of central 89%% of channels for pol%d = %f" % (j,np.median(tsys[j]))
                    if doplot: pb.hold(True)
                if doplot: 
                    pb.xlabel('Frequency (GHz)', size=fontsize)
                    if (showSpec and t=='trx'):
                        percent = [100,80]
                        for i,value in enumerate(['trx','trx2']):
                            myspec = receiverTrxSpec(bands[spw],value)
                            if myspec < pb.ylim()[1]:
                                pb.plot(pb.xlim(), 2*[myspec], 'g-', lw=2)
                                pb.text(np.mean(pb.xlim()), myspec, 'specification (for %d%% of band %d)'%(percent[i],bands[spw]), va='bottom', ha='center', color='g')
                if ((showatm or showtsky) and (overlay=='' or not shownAtm)):
                    if doplot or medianTsky[spw] is None:
                        shownAtm, medianTsky[spw] = overlayAtmosphere(vis, antenna, scan, verbose, mymsmd, antennas, spw, maxAltitude, dP, dPm, 
                                                 hanning, doplot, atmcolor, atmlw, atmls, atmmarker, showatm, showtsky, 
                                                                      shownAtm, conditionDict, atmcal, plotrange, t, antennaNames, atmType)
                    if t == 'tsky':
                        for j in range(len(tsys)): # i.e. nPolarizations
                            tskyOffset.append(np.median(tsys[j]) - medianTsky[spw])
                            print "Tsky offset = ", tskyOffset[-1]
                else:
                    pass
#                   print "showatm=%s, i=%d" % (showatm,i)
            else: # xaxis='chan'
                chan = range(len(freq))
                for j in range(len(tsys)):
                    if (renumber and len(chan) != len(tsys[j])):
                        # resample freq back down to tsys
                        chan = range(len(tsys[j]))
                    centralChannels = channelAverageChannels(len(tsys[j]))
                    meansPerPol[spw][j].append(np.mean(tsys[j][centralChannels]))
                    if doplot: 
                        if (overlay == ''):
                            pb.plot(chan, tsys[j], '-', color=mypolcolor[j])
                        else:
                            pb.plot(chan, tsys[j], '-', color=mycolor)
                        pb.hold(True)
                    print "Mean for pol%d = %f" % (j,np.mean(tsys[j]))
                if doplot: 
                    pb.xlabel('Channel',size=10)
                    if (showSpec and t=='trx'):
                        percent = [100,80]
                        for i,value in enumerate(['trx','trx2']):
                            myspec = receiverTrxSpec(bands[spw],value)
                            if myspec < pb.ylim()[1]:
                                pb.plot(pb.xlim(), 2*[myspec], 'g-', lw=2)
                                pb.text(np.mean(pb.xlim()), myspec, 'specification (for %d%% of band %d)'%(percent[i],bands[spw]), va='bottom', ha='center', color='g')
            if doplot or doplotMedian:
                if (casadef.casa_version >= '4.1.0'):
                    scanString = 'scan%02d' % (scan)
                else:
                    scanString = ''
                spwString = 'spw %2d BB %d ' % (spws[i],basebands[spws[i]])
                (mjd, utstring) = mjdSecondsToMJDandUT(times[i])
                if (figfile == True):
                    if (pol == 'X'):
                        poln = '.X'
                    elif (pol == 'Y'):
                        poln = '.Y'
                    else:
                        poln = ''
                    png = vis + '.%s.spw%d.%s%s.%s.png' % (antennaNames[antennas[i]],spws[i],scanString.replace(' ',''),poln,t)
                    medianpng = vis + '.median.spw%d.%s.%s.png' % (spws[i],poln,t)
                else:
                    png = figfile
                    # png and medianpng will be blank strings if figfile is a blank string
                    medianpng = figfile.replace('.png','_median.png')
            if (doplot): 
              adesc.xaxis.grid(True,which='major')
              adesc.yaxis.grid(True,which='major')
              if (plotrange[0] != 0 or plotrange[1] != 0):
                  pb.xlim([plotrange[0],plotrange[1]])
              elif (xaxis=='freq'):
                  pb.xlim([np.min(freq), np.max(freq)])
              if (len(plotrange) > 2 or chanrange != ''):
                  if (plotrange[2] != 0 or plotrange[3] != 0):
                      pb.ylim([plotrange[2],plotrange[3]])
                  elif (chanrange != ''):
                      chanrangePercent = float(chanrange.strip('%'))
                      startFraction = (100-chanrangePercent)*0.5*0.01
                      stopFraction = 1-(100-chanrangePercent)*0.5*0.01
                      cr0 = int(np.round(len(tsys[0])*startFraction))
                      cr1 = int(np.round(len(tsys[0])*stopFraction))
                      plottedChannels = range(cr0,cr1)
                      minvalue = 1e20
                      maxvalue = -1e20
                      for j in range(len(tsys)):
                          minvalue = np.min([minvalue,np.min(tsys[j][plottedChannels])])
                          maxvalue = np.max([maxvalue,np.max(tsys[j][plottedChannels])])
                      pb.ylim([minvalue,maxvalue])
              if (os.access('.',os.W_OK) == False):
                  png = '/tmp/'+png
              if (overlay==''):
                pb.hold(False)
                yFormat = matplotlib.ticker.ScalarFormatter(useOffset=False)
                adesc.yaxis.set_major_formatter(yFormat)
                pb.ylabel(ylab,size=fontsize)
                adesc.xaxis.grid(True,which='major')
                adesc.yaxis.grid(True,which='major')
                if pol == 'X':
                    polstring = 'polX'
                elif pol == 'Y':
                    polstring = 'polY'
                else:
                    polstring = ''
                    pb.text(1.02,0.95,'X',color=mypolcolor[0],transform=adesc.transAxes)
                    pb.text(1.02,0.90,'Y',color=mypolcolor[1],transform=adesc.transAxes)
                pb.title('%s  antenna %d=%s  spw%d  BB%d  %s  %s  %s' % \
                         (vis.split('/')[-1], antennas[i], 
                          antennaNames[antennas[i]], spws[i], basebands[spws[i]], polstring, scanString,
                          utstring), size=10)
                if (overlay=='' or i==len(antennas)-1):
                    resizeFonts(adesc,fontsize)
                    if (figfile != ''):
                        print "Saving figure in %s" % (png)
                        pb.savefig(png)
                        if (buildpdf):
                            os.system('convert %s %s.pdf' % (png,png))
                            if (cleanup):
                                os.remove(png)
                            pdfs += png + '.pdf '
                    if (interactive):
                        pb.draw()
                        if (ctr > 1 and i<(len(antennas)-1)):
                            myinput = raw_input("Press return for next antenna (%d<%d) (q to quit): " % (i,len(antennas)-1))
                            if (myinput == 'q'):
                                break
            # end 'if' doplot
          # end 'for' loop over rows in the table
        # end 'if' my spw
      # end 'for' loop over antennas, for this scan and spw combination
      if (len(medians) > 0):
          if len(medians) > 1:
              print "Median %s value (over both pols) for spw %2d = %.2f K (mean = %.2f, MAD = %.2f)" % (t, spw, np.median(medians), np.mean(means), MAD(medians))
          else:
              print "Median %s value (over both pols) for spw %2d = %.2f K (mean = %.2f)" % (t, spw, np.median(medians), np.mean(means))
          for mypol in meansPerPol[spw].keys():
              if ((pol=='Y' and mypol==1) or (pol=='X' and mypol==0) or pol==''):
                  mylength = len(meansPerPol[spw][mypol])
                  if (mylength < 1):
                      print "   No values in meansPerPol[%d][%d]" % (spw,mypol)
                  elif (mylength == 1):
                      print "   Median %s (Pol%d) for spw %2d = %.2f K" % (t, mypol, spw, np.median(meansPerPol[spw][mypol]))
                  else:
                      print "   Median %s (Pol%d) for spw %2d = %.2f K  (MAD=%.2f K)" % (t, mypol, spw, np.median(meansPerPol[spw][mypol]), 
                                                                                         MAD(meansPerPol[spw][mypol]))
              if (mypol == 1):
                  # The median()'s below are only necessary because meansPerPol[spw][0] is a list (of length = N antennas)
                  fracdiff = abs(np.median(meansPerPol[spw][0]) - np.median(meansPerPol[spw][1])) / np.mean([np.median(meansPerPol[spw][0]),np.median(meansPerPol[spw][1])])
                  fracdiffs[scan][spw] = fracdiff*100
                  if (fracdiff > warndiff):
                      print "   The two polarizations differ by more than %.1f percent! (%.2f percent)" % (warndiff*100,fracdiff*100)
                      if (doplot): 
                          pb.text(0.1, 0.9, '%.1f%%'%(fracdiff*100),transform=adesc.transAxes)
                          pb.draw()
                          print "Overwriting figure in %s" % (png)
                          pb.savefig(png)  #  overwrite previous
                          if (buildpdf):
                              os.system('convert %s %s.pdf' % (png,png))
                              if (cleanup):
                                  os.remove(png)
                  if (fracdiff > warndiff*2):
                      print "   The two polarizations differ by more than %.1f percent! (%.2f percent)" % (warndiff*2*100,fracdiff*100)
          medianValues[spw] = np.median(medians)
          meanValues[spw] = np.mean(means)
          medianSpectra[spw] = np.median(allspectra,axis=0)
          if doplotMedian:
              pb.clf()
              adesc = pb.subplot(111)
              pb.subplots_adjust(top=0.85)
              if xaxis == 'freq':
                  for j in range(len(medianSpectra[spw])):
                      print "median spectrum for pol %d: min=%.1f, max=%.1f, freq:%.1f-%.1f" % (j, np.min(medianSpectra[spw][j]), np.max(medianSpectra[spw][j]), np.min(freq), np.max(freq))
                      pb.plot(freq, medianSpectra[spw][j],'-', color=mypolcolor[j], ls=lines[j])
                      pb.hold(True)
                  pb.xlabel('Sky frequency (GHz)', size=fontsize)
              else:
                  for j in range(len(medianSpectra[spw])):
                      print "median spectrum for pol %d: min=%.1f, max=%.1f" % (j, np.min(tsys[j]), np.max(tsys[j]))
                      pb.plot(chan, tsys[j], '-', color=mypolcolor[j])
                      pb.hold(True)
                  pb.xlabel('Channel',size=10)
              if (showSpec and t=='trx'):
                  percent = [100,80]
                  for i,value in enumerate(['trx','trx2']):
                      myspec = receiverTrxSpec(bands[spw],value)
                      if myspec < pb.ylim()[1]:
                          pb.plot(pb.xlim(), 2*[myspec], 'g-', lw=2)
                          pb.text(np.mean(pb.xlim()), myspec, 'specification (for %d%% of band %d)'%(percent[i],bands[spw]), va='bottom', ha='center', color='g')
              pb.ylabel('Median of %d spectral '%len(allspectra)+ylab,size=fontsize)
              pb.text(1.02,0.95,'X',color=mypolcolor[0],transform=adesc.transAxes)
              pb.text(1.02,0.90,'Y',color=mypolcolor[1],transform=adesc.transAxes)
              if (plotrange[2] != 0 or plotrange[3] != 0):
                  pb.ylim([plotrange[2],plotrange[3]])
              if (showatm or showtsky) and xaxis=='freq':
                  shownAtm, medianTsky[spw] = overlayAtmosphere(vis, antenna, scan, verbose, mymsmd, antennas, spw, maxAltitude, dP, dPm, 
                                               hanning, doplotMedian, atmcolor, atmlw, atmls, atmmarker, showatm, showtsky, 
                                                                shownAtm, conditionDict, atmcal, plotrange, t, antennaNames, atmType)
                  """
                  y0,y1 = pb.ylim()
                  yrange = np.abs(np.diff(pb.ylim()))*0.98
                  pb.plot(freq, y0+transmission*yrange,'m-')
                  pb.text(1.01,0.0,'0%',color='m',ha='left',va='center',transform=adesc.transAxes)
                  pb.text(1.01,0.98,'100%',color='m',ha='left',va='center',transform=adesc.transAxes)
                  tstring = 'transmission'
                  if (antennaNames[antennas[0]].find('CM')>=0):  # 7m antennas do not have WVRs and thus do not have PWV measurements
                      myString = tstring + " model: PWV=%.2fmm, maxAlt.=%d km, dP=%.0fmb, dPm=%.1f" % (pwv,maxAltitude,dP,dPm)
                  else:
                      myString = tstring + " model: med.PWV=%.2fmm, el=%.0f, maxAlt.=%d km, dP=%.0fmb, dPm=%.1f" % (pwv,elevation,maxAltitude,dP,dPm)
                  pb.text(0.01, 0.963, myString, transform=adesc.transAxes, color='m', size=10)
                  myString = '%s: siteAltitude=%.0fm, P=%.1fmb, H=%.1f%%, T=%.1fK' % (observatory, siteAltitude_m, P, H, T)
                  pb.text(0.01, 0.935, myString, transform=adesc.transAxes, color='m', size=10)
                  """
              if (plotrange[0] != 0 or plotrange[1] != 0):
                  pb.xlim([plotrange[0],plotrange[1]])
              else:
                  pb.xlim([np.min(freq), np.max(freq)])
              adesc.xaxis.grid(True,which='major')
              adesc.yaxis.grid(True,which='major')
              ax2 = adesc.twiny()
              ax2.set_xlim([np.abs(np.min(freq)-lo1ghz), np.abs(np.max(freq)-lo1ghz)])
              freqRange = np.max(freq) - np.min(freq)
              power = int(np.log10(freqRange))
              ax2.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(0.5*10**power))
              ax2.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.1*10**power))
              adesc.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.1))
              if (len(ax2.get_xticks()) < 2):
                  ax2.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(0.1*10**power))
                  ax2.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.02*10**power))
                  adesc.xaxis.set_minor_locator(matplotlib.ticker.MultipleLocator(0.02))
              ax2.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter(useOffset=False))
              pb.text(0.5, 1.06, 'Intermediate frequency (GHz)', ha='center', va='center', transform=adesc.transAxes, size=fontsize) 
              pb.text(0.5, 1.12, '%s  %s  %s   LO1=%.3f GHz' % (os.path.basename(vis), spwString, scanString, lo1ghz), 
                      size=12, va='center', transform=adesc.transAxes, ha='center')
              pb.draw() 
              if medianpng != '':
                  pb.savefig(medianpng)
                  print "Wrote plot of median: %s." % (medianpng)
      else:
          if (verbose or True):
              print "No data for this spw/scan combination. Available combinations are:"
              if (casadef.casa_version >= casaVersionWithMSMD):
                  for myscan in np.unique(scans):
                      print "Scan %2d has spws %s" % (myscan,str(mymsmd.spwsforscan(myscan)))
      if (doplot and overlay != ''):
          pb.ylabel(ylab,size=fontsize)
          if (overlay=='antenna'):
              pb.title('%s  %s  %s  time %s' % \
                       (vis.split('/')[-1], spwString, scanString, utstring),
                       size=10)
              for a in range(len(uniqueAntennas)):
                  if (a*0.06 > 1.02):
                      x = 1.02
                      y -= 0.03
                  else:
                      y = 1.05
                      x = a*0.06
                  pb.text(x, y, '%s'%antennaNames[uniqueAntennas[a]], 
                          color=overlayColors[a], transform=pb.gca().transAxes,
                          size=8)
              if png != '':
                  print "plotTspectrum: Saving figure in %s" % (png)
                  pb.savefig(png)
                  if (buildpdf):
                      os.system('convert %s %s.pdf' % (png,png))
                      if (cleanup):
                          os.remove(png)
                      pdfs += png + '.pdf '
      if (interactive and doplot):
          pb.draw()
          if (myinput != 'q'):
              if (spwlist[-1] != spw):
                  myinput = raw_input("Press return for next spw (q to quit): ")
              elif (scan == scanlist[-1]):
                  myinput = 'q'
          if (myinput == 'q'):
              break
     # end of loop over spws in spwlist
    # end of loop over scans in scanlist
    if (buildpdf and doplot):
        if (pol == ''):
            if (antenna == ''):
                pdf = vis + '.spw' + str(spw) + '.' + t + '.pdf'
            else:
                pdf = vis + '.' + antennaNames[antenna[0]] + '.spw' + str(spw) + '.' + t + '.pdf'
        else:
            if (antenna == ''):
                pdf = vis + '.spw' + str(spw) + '.' + pol + '.' + t + '.pdf'
            else:
                pdf = vis + '.' + antennaNames[antenna[0]] + '.spw' + str(spw) + '.' + pol + '.' + t + '.pdf'
        if (os.access('.',os.W_OK) == False):
            pdf = '/tmp/'+pdf
        cmd = '%s -q -sPAPERSIZE=letter -dNOPAUSE -dBATCH -sDEVICE=pdfwrite -sOutputFile=%s %s' % (gs,pdf,pdfs)
        print "Running command: %s" % (cmd)
        os.system(cmd)
        if (cleanup):
            for mypdf in pdfs.split():
                os.remove(mypdf)
    if (msmdCreated):
        mymsmd.close()
    if t == 'tsky' and showtsky:
        pb.clf()
        if histogramBins == -1:
            histogramBins = len(tskyOffset)/10
        pb.hist(tskyOffset, bins=histogramBins)
        pb.xlabel('Tsky median offset from ATM model (K)', size=20)
        pb.ylabel('Number of spectra', size=20)
        pb.title(vis, size=20)
        pb.draw()
        png = 'tskyOffset_histogram.png'
        pb.savefig(png, bbox_inches='tight')
        print "Wrote ", png
    if (returnMedians=='mean'):
        if (returnFracDiff):
            return(meanValues, atmcal, meanValues, fracdiffs)
        else:
            return(meanValues, atmcal, meanValues)
    elif (returnMedians=='median'):
        if (returnFracDiff):
            return(medianValues, atmcal, fracdiffs)  
        else:
            return(medianValues, atmcal)  
    else:
        if (returnFracDiff):
            return(medianSpectra, atmcal, fracdiffs)  
        else:
            return(medianSpectra, atmcal)  
    # end of plotTspecrum

def spwsforintent_nonwvr_nonchanavg(mymsmd, intent = 'OBSERVE_TARGET#ON_SOURCE', includeSQLD=False):
    """
    Uses the msmd tool to return the spws for the specified intent that are not WVR
    nor channel-averaged spws.  This is a good way to find science spws.
    - Todd Hunter
    """
    ignore = list(mymsmd.wvrspws()) + list(mymsmd.chanavgspws())
    if (includeSQLD):
        ignore = list(set(ignore) - set(mymsmd.almaspws(sqld=True)))
    spws = list(mymsmd.spwsforintent(intent))
    science_spws = [x for x in spws if x not in ignore]
    return(science_spws)

def checkOrder(inpFreq,inpData) :
    """
    Takes two lists, and if the first list is in decreasing order, then it inverts
    both lists.  Useful for forcing a spectrum to have increasing frequency vs. channel.
    -Todd Hunter
    """
    if ((inpFreq[1]-inpFreq[0]) > 0) :
        return inpFreq,inpData,0
    else :
        return inpFreq[::-1], inpData[::-1], 1

def getLoadTemperatures(vis, antenna = None, doplot=False,
                        warnIfNoLoadTemperatures=True, mymsmd=None):
    """
    Gets the load temperatures and timestamps from the ASDM_CALDEVICE
    table (if present), otherwise get them from the CALDEVICE table. 
    Returns a dictionary of all antennas 
    keyed by antenna name and ID, then by scan number.  
    doplot: if True, then draw a plot
    antenna: single antenna to plot (ID as integer or string or name) 
             if None, then plot all antennas
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "The measurement set is not found."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (casadef.casa_version < casaVersionWithMSMD):
        print "This version of CASA is too old.  It needs msmd (4.1 or newer)."
        return
    if (os.path.exists(vis+'/ASDM_CALDEVICE')):
        table = 'ASDM_CALDEVICE'
        asdm = True
    else:
        table = 'CALDEVICE'
        asdm = False
    mytable = vis+'/'+table
    needToClose = False
    if mymsmd is None:
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
    scans = mymsmd.scannumbers()
    antennas = range(mymsmd.nantennas())
    antennaNames = mymsmd.antennanames(antennas)
    mydict = {}
    for ant in antennas:
        mydict[ant] = {}
        mydict[antennaNames[ant]] = {}
    if (os.path.exists(mytable) == False):
        if (warnIfNoLoadTemperatures):
            print "The ASDM_CALDEVICE table is not present. You need to importasdm(asis='CalDevice') to get"
            print "correct load temperatures.  Will proceed using default temperature for the hot load and "
            print "ambient load, which is only a concern if you want to recalculate Tsys."
        for ant in antennas:
            for scan in scans:
                mydict[ant][scan] = {'hot':DEFAULT_HOTLOAD_TEMP, 'amb':DEFAULT_AMBLOAD_TEMP}
                mydict[antennaNames[ant]][scan] = {'hot':DEFAULT_HOTLOAD_TEMP, 'amb':DEFAULT_AMBLOAD_TEMP}
        if needToClose:
            mymsmd.close()
        return(mydict)
    # need to use default temperatures if table present, but empty.
    mytb = createCasaTool(tbtool)
    mytb.open(mytable)
    if (asdm):
        temperatureLoad = mytb.getcol('temperatureLoad')
        timeInterval = mytb.getcol('timeInterval')
        antennaIds = mytb.getcol('antennaId')
        calLoadNames = mytb.getcol('calLoadNames')
        antennaId = np.array([int(x.split('_')[1]) for x in antennaIds])
    else:
        temperatureLoad = mytb.getcol('TEMPERATURE_LOAD')
        timeInterval = mytb.getcol('INTERVAL')
        antennaIds = mytb.getcol('ANTENNA_ID')
        calLoadNames = mytb.getcol('CAL_LOAD_NAMES')
        antennaId = antennaIds
    if len(temperatureLoad) < 1:
        if (warnIfNoLoadTemperatures):
            print "The ASDM_CALDEVICE table is not present. You need to importasdm(asis='CalDevice') to get"
            print "correct load temperatures.  Will proceed using default temperature for the hot load and "
            print "ambient load, which is only a concern if you want to recalculate Tsys."
        for ant in antennas:
            for scan in scans:
                mydict[ant][scan] = {'hot':DEFAULT_HOTLOAD_TEMP, 'amb':DEFAULT_AMBLOAD_TEMP}
                mydict[antennaNames[ant]][scan] = {'hot':DEFAULT_HOTLOAD_TEMP, 'amb':DEFAULT_AMBLOAD_TEMP}
    if (antenna is not None):
        antennaIDs = parseAntenna(vis, antenna)
        if (antennaIDs is None):
            print "Antenna %s not in this dataset (0..%d)" % (str(antenna),np.max(antennaId))
            return
        singleAntennaID = antennaIDs[0]
    mytb.close()
    times = []
    hotLoadTemps = []
    ambLoadTemps = []
    antennaTempIDs = []
    for ant in antennas:
        for scan in scans:
            for row in range(len(antennaId)):
                if (ant==antennaId[row]):
                    meanscantime = np.mean(mymsmd.timesforscan(scan))
                    times.append(meanscantime)
                    amb = list(calLoadNames[:,row]).index('AMBIENT_LOAD')
                    hot = list(calLoadNames[:,row]).index('HOT_LOAD')
                    ambLoad = temperatureLoad[amb][row]
                    hotLoad = temperatureLoad[hot][row]
                    ambLoadTemps.append(ambLoad)
                    hotLoadTemps.append(hotLoad)
                    antennaTempIDs.append(ant)
                    mydict[antennaId[row]][scan] = {'hot':hotLoad,'amb':ambLoad}
                    mydict[antennaNames[antennaId[row]]][scan] = {'hot':hotLoad,'amb':ambLoad}
                    break
    if needToClose:
        mymsmd.close()
    times = np.array(times)
    antennaTempIDs = np.array(antennaTempIDs)
    hotLoadTemps = np.array(hotLoadTemps)
    ambLoadTemps = np.array(ambLoadTemps)
    if (antenna is not None):
        indices = np.where(antennaTempIDs == singleAntennaID)[0]
    else:
        indices = range(len(antennaTempIDs))
    if (doplot):
        pb.clf()
        timestamps = pb.date2num(mjdSecondsListToDateTime(times))
        pb.plot_date(timestamps[indices], ambLoadTemps[indices], 'k.')
        pb.hold(True)
        pb.plot_date(timestamps[indices], hotLoadTemps[indices], 'r.')
        pb.xlabel('Time (UT)')
        pb.ylabel('Temperature (K)')
        if (antenna is not None):
            pb.title(os.path.basename(vis) + ' antenna %s: Black = ambient, red = heated'%str(antenna),size=12)
        else:
            pb.title(os.path.basename(vis) + ': Black = ambient,  red = heated',size=12)
        pb.draw()
    return(mydict)

def defaultSBGainsForBand(band):
    """
    Accepts the ALMA band number and returns the signal and image sideband 
    gains. Returns the default sideband gains for the signal and image bands 
    used by TelCal.  Taken from AtmosphereScan.cpp of TelCal.
    - Todd Hunter
    """
    if (band <= 3):
        g_signal = 0.99
        g_image = 0.01
    elif (band <= 6):
        g_signal = 0.97
        g_image = 0.03
    elif (band <= 8):
        g_signal = 0.90
        g_image = 0.10
    else:
        g_signal = 0.5
        g_image = 0.5
    return(g_signal, g_image)

def CalcAtmosphere(chans, freqs, pwv, refFreqInTable=None, 
                   net_sideband=1,P=563,H=20,T=273,airmass=1.0,
                   verbose=False, atmType=1, siteAltitude_m=5059,
                   maxAltitude=48.0,   # i.e., top of atmosphere
                   h0=1.0,    # water vapor scale height in km
                   dP=5.0,    # model step to use in mbar
                   dPm=1.1,   # pressure step factor (unitless)
                   hanning=False
                   ):
    """
    Uses the at tool in CASA to compute atmospheric model.
    chans: all channels, regardless of whether they are flagged
    freqs: frequencies (in GHz) corresponding to chans
    refFreqInTable: frequency of the edge of the spw
    atmType: 1, 2, or 3, default=1=tropical, 2=midLatSummer, 3=midLatWinter
    dP: pressure step, has units of pressure (mb)
    dPm: pressure step factor (unitless) called PstepFact in TelCal
    maxAltitude: of the atmosphere, in km
    hanning: if True, then apply Hanning smoothing to the transmission, TebbSky and tau
    returns 5 arrays:
       freq, chans, transmission (0..1), TebbSky, tau
    """
    if refFreqInTable is None:
        refFreqInTable = freqs[0]
    if verbose:
        print "CalcAtmosphere: len chans, freqs = ", len(chans), len(freqs)
        print "Using zenith PWV=%.3fmm, airmass=%.3f, P=%.2fmb, H=%.2f%%, T=%.2fK..." % (pwv,airmass,P,H,T)
    numchan = len(freqs)
    reffreq = 0.5*(freqs[numchan/2-1]+freqs[numchan/2])  # frequency of the CENTER of the spw
    chansep = (freqs[-1]-freqs[0])/(numchan-1)
    resolution = chansep # this assumption appears to be built-in to the at tool, but not true for most ALMA data
    nbands = 1
    # from AtmosphereScan.cpp
    myqa = createCasaTool(qatool)
    maxAltitude = create_casa_quantity(myqa, maxAltitude,'km')
    h0 = create_casa_quantity(myqa, h0,'km')
    dP = create_casa_quantity(myqa, dP,'mbar')
    fCenter = create_casa_quantity(myqa, reffreq,'GHz')
    fResolution = create_casa_quantity(myqa, resolution,'GHz')
    fWidth = create_casa_quantity(myqa, numchan*chansep,'GHz')
    if verbose:
        diff = reffreq*1e9 - refFreqInTable
        print "reffreq= %f, refFreqInTable= %f, difference= %f" % (reffreq*1e9, refFreqInTable, diff)
    if (type(casac.Quantity) != type):  # casa 4.x
        myat = at # casac.atmosphere() # works, but it does not have a done() or a close()
    else:
        myat = at
    result = myat.initAtmProfile(humidity=H,temperature=create_casa_quantity(myqa, T,"K"),
                                 altitude=create_casa_quantity(myqa, siteAltitude_m,"m"),
                                 pressure=create_casa_quantity(myqa, P,'mbar'),atmType=atmType,
                                 dP=dP, maxAltitude=maxAltitude, h0=h0, dPm=dPm)
    if verbose: printNumberOfAtmosphericLayers(result)
    myat.initSpectralWindow(nbands,fCenter,fWidth,fResolution)
    myat.setUserWH2O(create_casa_quantity(myqa, pwv,'mm'))
    # This does not affect the opacity, but it does effect TebbSky, so do it manually.
    myat.setAirMass(airmass)
    if (casadef.casa_version < '4.0.0'):
        dry = np.array(myat.getDryOpacitySpec(0)['dryOpacity'])
        wet = np.array(myat.getWetOpacitySpec(0)['wetOpacity'].value)
        TebbSky = []
        for chan in range(numchan):  # do NOT use numchan here, use n
            TebbSky.append(myat.getTebbSky(nc=chan, spwid=0).value)
        TebbSky = np.array(TebbSky)
    else:
        dry = np.array(myat.getDryOpacitySpec(0)[1])
        wet = np.array(myat.getWetOpacitySpec(0)[1]['value'])
        TebbSky = myat.getTebbSkySpec(spwid=0)[1]['value']

    transmission = np.exp(-airmass*(wet+dry))
#    TebbSky *= (1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))

    numchan = len(transmission)
    chans = range(len(transmission))
    startFreq = myqa.convert(myat.getChanFreq(0),'GHz')['value']
    endFreq = myqa.convert(myat.getChanFreq(numchan-1),'GHz')['value']
    myqa.done()
    freq = np.linspace(startFreq, endFreq, numchan)
    if verbose:
        print "numchan=%d, abs(startFreq-endFreq) = %f" % (numchan, np.abs(startFreq - endFreq))
        idx = np.argmax(TebbSky)
        print "Peak Tsky=%f at freq=%f" % (TebbSky[idx], freq[idx])
        print "...median tau = %f, transmission = %f" % (np.median(airmass*(wet+dry)), np.median(transmission))
    if hanning:
        print "Applying Hanning smoothing to the ATM model output."
        transmission = casaHanning(transmission,padOutput=True)
        TebbSky = casaHanning(TebbSky,padOutput=True)
        wet = casaHanning(wet,padOutput=True)
        dry = casaHanning(dry,padOutput=True)
    return(freq, chans, transmission, TebbSky, airmass*(wet+dry))

def detectNegativeTsys(vis='', antenna = '', spw='', showfield=False,
                       vm='', pol='', edge=0, timerange=''):
    """
    Reads the SYSCAL table of the specified ms and searches for negative
    values of TSYS_SPECTRUM, printing a summary for each row as it finds
    them.  If an antenna is specified (ID or name), then only that antenna 
    will be displayed.  If an spw is specified (integer or string), then 
    only that spw will be displayed.  If edge is non-zero, then that many
    channels will be ignored on both edges of the spws.  timerange is an
    integer starting at 0, and represents each unique time in the solution.
    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "The ms does not exist."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (os.path.exists(vis+'/SYSCAL') == False):
        print "The SYSCAL table for that ms does not exist."
        return
    if (edge < 0):
        print "The value of edge must be >= 0."
        return
    if (type(antenna) == str):
        if (len(antenna) > 0):
            if (antenna.isdigit()==False):
                antennaName = antenna
                antenna = getAntennaIndex(vis, antenna)
            else:
                antenna = int(antenna)
                antennaName = getAntennaName(vis, antenna)
                
    else:
        antennaName = getAntennaName(vis, antenna)
    antennaNames = getAntennaNames(vis)
    mymsmd = ''
    if (showfield):
        if (casadef.casa_version < casaVersionWithMSMD):
            if (vm==''):
                print "Running ValueMapping (because showfield=True and vm=0)..."
                vm = ValueMapping(vis)
        elif (vm != ''):  # this is for testing vm in >=4.1.0
            print "Running ValueMapping (because showfield=True and vm!=0)..."
            vm = ValueMapping(vis)
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
    mytb = tbtool()
    mytb.open(vis+'/SYSCAL')
    antennas = mytb.getcol('ANTENNA_ID')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    times = mytb.getcol('TIME')
    intervals = mytb.getcol('INTERVAL')
    uniqueTimes = np.unique(times)
    total = 0
    totalPossible = 0
    maxFieldLength = 16
    if (showfield):
        header = "Row  Antenna  spw  time(interval)  scan(startTime)  fieldname   polarization"
    else:
        header = "Row  Antenna  spw  time(interval)  polarization"
    headerPrinted = False
    nrows = len(spws)
    for i in range(nrows):
        tsys = mytb.getcell('TSYS_SPECTRUM',i)
        for polarization in range(len(tsys)):
            negatives = np.where(tsys[polarization]<0)[0]
            neg = len(negatives)
            if (edge > 0):
                howManyNegatives = len(np.where(tsys[polarization][edge:-edge]<0)[0])
            else:
                howManyNegatives = neg
            possible = np.size(tsys[polarization])
            uniqueTime = list(uniqueTimes).index(times[i])
            if (antenna=='' or antennas[i]==int(antenna)):
                if (spw=='' or spws[i] == int(spw)):
                    if (pol=='' or polarization==int(pol)):
                        if (timerange=='' or timerange==uniqueTime):
                            totalPossible += possible
            if (howManyNegatives > 0):
                medianValue = np.median(tsys[polarization][negatives])
                if (antenna=='' or antennas[i]==int(antenna)):
                    if (spw=='' or spws[i] == int(spw)):
                        if (pol=='' or polarization==int(pol)):
                            if (timerange=='' or timerange==uniqueTime):
                                if (headerPrinted == False):
                                    print header
                                    headerPrinted = True
                                myhhmmss = mjdSecondsToMJDandUT(times[i])[1].split()[1]
                                if (float(intervals[i]) > 1e6):
                                    myhhmmss = '+%5dd(%.0fd)' % ((times[i]-times[0])/86400.,intervals[i]/86400.)
                                else:
                                    myhhmmss += '(%02d:%02.0f)' % (int(float(intervals[i])/60.),intervals[i]%60)
                                if (showfield):
                                    if (casadef.casa_version < casaVersionWithMSMD or mymsmd == ''):
                                        myscan = getScansForTime(vm.scansForTimes,times[i])
                                        intents = vm.getIntentsForScan(myscan)
                                        while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                            myscan -= 1
                                            intents = vm.getIntentsForScan(myscan)
                                        myscantimes = vm.getTimesForScan(myscan)
                                        myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                        myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                        myfield = vm.getFieldsForScan(myscan)[0]
                                    else:
                                        myscan = mymsmd.scansfortimes(times[i])
                                        if (len(myscan) < 1):
                                            myscan = mymsmd.scannumbers()[-1]
                                        else:
                                            myscan = myscan[0]
                                        intents = mymsmd.intentsforscan(myscan)
                                        while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                            myscan -= 1
                                            intents = mymsmd.intentsforscan(myscan)
                                        myscantimes = mymsmd.timesforscan(myscan)
                                        myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                        myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                        myfield = mymsmd.namesforfields(mymsmd.fieldsforscan(myscan)[0])[0]
                                    if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents):
                                        print "       WARNING: scan %d does not have CALIBRATE_ATMOSPHERE intent" % (myscan)
                                    if (len(myfield) < maxFieldLength):
                                        myfield += ' '*(maxFieldLength-len(myfield))
                                    if (len(myfield) > maxFieldLength):
                                        myfield = myfield[0:maxFieldLength]
                                    result = "%4d [%2d=%s, %2d, %d=%s, %2d (%s), %16s, %d) found %4d of %4d (median=%g)" % (i,antennas[i], antennaNames[antennas[i]], spws[i], uniqueTime, myhhmmss, myscan, myscanhhmmss0, myfield, polarization, neg, possible, medianValue)
                                else:
                                    result = "%4d [%2d=%s, %2d, %d=%s, %d], found %3d out of %3d (median=%g)" % (i,
                                            antennas[i], antennaNames[antennas[i]], spws[i], uniqueTime, myhhmmss,
                                            polarization, neg, possible, medianValue)
                                print result
                                total += neg
    mytb.close()
    if (total == 0):
        print "No negatives found!"
    else:
        print "A total of %d negative values encountered out of %d possible (%.4f%%)." % (total,totalPossible,(100.*total)/totalPossible)
    if (mymsmd != ''):
        mymsmd.close()
    return()

def getSpwFromPipelineImageName(img, verbose=False):
    """
    Extracts the spw ID from the pipeline image file name.
    """
    sourceName = os.path.basename(img.rstrip('/'))
    if verbose: print "A = ", sourceName
    if (sourceName.find('.mfs.') < 0):
        if (sourceName.find('.cube.') < 0):
            return 'sourcename'
        else:
            sourceName = sourceName.split('.cube.')[0]
    else:
        sourceName = sourceName.split('.mfs.')[0]
    if verbose: print "B = ", sourceName
    sourceName = sourceName.split('.spw')[1]
    if verbose: print "spw = ", sourceName
    if sourceName.isdigit():
        return int(sourceName)
    else:
        return None

def detectNegativeTrx(vis='', antenna = '', spw='', showfield=False, vm='',
                      pol='', edge=0, showAllRowsForAntenna=-1):
    """
    Reads the SYSCAL table of the specified ms and searches for negative
    values of TRX_SPECTRUM, printing a summary for each row as it finds
    them.  If an antenna is specified (ID or name), then only that antenna 
    will be displayed.  If an spw is specified (integer or string), then 
    only that spw will be displayed.  If edge is non-zero, then that many
    channels will be ignored on both edges of the spws.    -Todd Hunter
    """
    if (os.path.exists(vis) == False):
        print "The ms does not exist."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (os.path.exists(vis+'/SYSCAL') == False):
        print "The SYSCAL table for that ms does not exist."
        return
    if (edge < 0):
        print "The value of edge must be >= 0."
        return
    if (type(antenna) == str):
        if (len(antenna) > 0):
            if (antenna.isdigit()==False):
                antennaName = antenna
                antenna = getAntennaIndex(vis, antenna)
            else:
                antenna = int(antenna)
                antennaName = getAntennaName(vis, antenna)
                
    else:
        antennaName = getAntennaName(vis, antenna)
    antennaNames = getAntennaNames(vis)
    mymsmd = ''
    if (showfield):
        if (casadef.casa_version < casaVersionWithMSMD):
            if (vm == ''):
                print "Running ValueMapping (because showfield=True and vm=0)..."
                vm = ValueMapping(vis)
        elif (vm != ''):  # this is for testing vm in >=4.1.0
            print "Running ValueMapping (because showfield=True and vm!=0)..."
            vm = ValueMapping(vis)
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
    mytb = tbtool()
    mytb.open(vis+'/SYSCAL')
    antennas = mytb.getcol('ANTENNA_ID')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    times = mytb.getcol('TIME')
    intervals = mytb.getcol('INTERVAL')
    total = 0
    totalb = 0  # number of spw's with >50percent of channels negative
    totalPossible = 0
    maxFieldLength = 16
    if (showfield):
        header = "Row  Antenna  spw  time(interval)  scan(startTime)  fieldname   polarization"
    else:
        header = "Row  Antenna  spw  time(interval)  polarization"
    headerPrinted = False
    nrows = len(spws)
    for i in range(nrows):
        trx = mytb.getcell('TRX_SPECTRUM',i)
        for polarization in range(len(trx)):
            negatives = np.where(trx[polarization]<0)[0]
            neg = len(negatives)
            if (edge > 0):
                howManyNegatives = len(np.where(trx[polarization][edge:-edge]<0)[0])
            else:
                howManyNegatives = neg
            possible = np.size(trx[polarization])
            if (antenna=='' or antennas[i]==int(antenna)):
                if (spw=='' or spws[i] == int(spw)):
                    if (pol=='' or polarization==int(pol)):
                        totalPossible += possible
            if (howManyNegatives > 0 or antennas[i]==showAllRowsForAntenna):
                if (howManyNegatives > 0):
                    medianValue = np.median(trx[polarization][negatives])
                    medianString = '(median=%g)' % medianValue
                else:
                    medianString = ''
                if (antenna=='' or antennas[i]==int(antenna)):
                    if (spw=='' or spws[i] == int(spw)):
                        if (pol=='' or polarization==int(pol)):
                            if (headerPrinted == False):
                                print header
                                headerPrinted = True
                            myhhmmss = mjdSecondsToMJDandUT(times[i])[1].split()[1]
                            if (float(intervals[i]) > 1e6):
                                myhhmmss = '+%5dd(%.0fd)' % ((times[i]-times[0])/86400.,intervals[i]/86400.)
                            else:
                                myhhmmss += '(%02d:%02.0f)' % (int(float(intervals[i])/60.),intervals[i]%60)
                            if (showfield):
                                if (casadef.casa_version < casaVersionWithMSMD or mymsmd == ''):
                                    myscan = getScansForTime(vm.scansForTimes,times[i])
                                    intents = vm.getIntentsForScan(myscan)
                                    while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                        myscan -= 1
                                        intents = vm.getIntentsForScan(myscan)
                                    myscantimes = vm.getTimesForScan(myscan)
                                    myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                    myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                    myfield = vm.getFieldsForScan(myscan)[0]
                                else:
                                    myscan = mymsmd.scansfortimes(times[i])
                                    if (len(myscan) < 1):
                                        myscan = mymsmd.scannumbers()[-1]
                                    else:
                                        myscan = myscan[0]
                                    intents = mymsmd.intentsforscan(myscan)
                                    while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                        myscan -= 1
                                        intents = mymsmd.intentsforscan(myscan)
                                    myscantimes = mymsmd.timesforscan(myscan)
                                    myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                    myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                    myfield = mymsmd.namesforfields(mymsmd.fieldsforscan(myscan)[0])[0]
                                if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents):
                                    print "       WARNING: scan %d does not have CALIBRATE_ATMOSPHERE intent" % (myscan)
                                if (len(myfield) < maxFieldLength):
                                    myfield += ' '*(maxFieldLength-len(myfield))
                                if (len(myfield) > maxFieldLength):
                                    myfield = myfield[0:maxFieldLength]
                                result = "%4d [%2d=%s, %2d, %s, %2d (%s), %16s, %d] found %4d of %4d %s" % (i,antennas[i], antennaNames[antennas[i]], spws[i], myhhmmss, myscan, myscanhhmmss0, myfield, polarization, neg, possible, medianString)
                            else:
                                result = "%4d [%2d=%s, %2d, %s, %d], found %3d out of %3d (median=%g)" % (i,
                                   antennas[i],antennaNames[antennas[i]],spws[i], myhhmmss,
                                   polarization, neg, possible, medianValue)
                            print result
                            total += neg
                            if ((1.0*neg)/(1.0*possible) > 0.1):
                                totalb += 1
                                print "this spw has >10% of channels negative!!"
    mytb.close()
    if (total == 0):
        print "No negative Trx found!"
    else:
        print "A total of %d negative Trx values encountered out of %d possible (%.4f%%)." % (total, totalPossible,(100.*total)/totalPossible)
    if (totalb == 0):
        if (total > 0):
            print "But no spws with >10% negative Trx found. So most problems are probably edge channels"
    else:
        print "Warning: ", totalb, " spws had >10% negative Trx and have serious problems."
    if (mymsmd != ''):
        mymsmd.close()
    return(vm)

def detectLoadTemp(vis='', showfield=False, vm='',antenna=''):
    """
    Reads the CALDEVICE table of the specified ms and searches for unusual
    values of temperatureLoad, printing a summary for each row as it finds
    them.  Unusual is Tamb outside range 10-20C or Thot outside range 80-90C.
    -Bill Dent
    """
    Tamb_lo=10.0
    Tamb_hi=20.0
    Thot_lo=70.0
    Thot_hi=90.0

    if (os.path.exists(vis) == False):
        print "The ms does not exist."
        return
    if (os.path.exists(vis+'/table.dat') == False):
        print "No table.dat.  This does not appear to be an ms."
        return
    if (os.path.exists(vis+'/CALDEVICE') == False):
        print "The CALDEVICE table for that ms does not exist."
        return
    if (type(antenna) == str):
        if (len(antenna) > 0):
            if (antenna.isdigit()==False):
                antennaName = antenna
                antenna = getAntennaIndex(vis, antenna)
            else:
                antenna = int(antenna)
                antennaName = getAntennaName(vis, antenna)
                
    else:
        antennaName = getAntennaName(vis, antenna)
    antennaNames = getAntennaNames(vis)
    print "Antennas being checked: ", antennaNames
    if (showfield and vm==''):
        print "Running ValueMapping (because showfield=True)..."
        vm = ValueMapping(vis)
    tb.open(vis+'/CALDEVICE')
    antennas = tb.getcol('ANTENNA_ID')
    times = tb.getcol('TIME')
    intervals = tb.getcol('INTERVAL')
    times = times-0.5*intervals
    total = 0
    maxFieldLength = 1
    nrows=len(antennas)
    print 'nrows ', nrows
    for i in range(0,nrows):
       T_amb= tb.getcell('TEMPERATURE_LOAD',i)[0]
       T_hot= tb.getcell('TEMPERATURE_LOAD',i)[1]
       if(T_amb < Tamb_lo or T_amb > Tamb_hi):
           antbad=tb.getcell('ANTENNA_ID',i)
           times[0]=tb.getcell('TIME',i)
           if(showfield):
               myscan = getScansForTime(vm.scansForTimes,times[0])
               myfield = getFieldsForTime(vm.fieldsForTimes,times[0])
               print "Scan", myscan," field",myfield," Antenna:", antennaNames[antbad]," Ambient load out of range. T_amb:", T_amb
           else:
               print "Row ", i, " Ambient load out of range. T_amb: ", T_amb," Antenna: ", antennaNames[antbad]
           total += 1
       if(T_hot < Thot_lo or T_hot > Thot_hi):
           antbad=tb.getcell('ANTENNA_ID',i)
           times[0]=tb.getcell('TIME',i)
           if(showfield):
               myscan = getScansForTime(vm.scansForTimes,times[0])
               myfield = getFieldsForTime(vm.fieldsForTimes,times[0])
               print "Scan", myscan," field",myfield," Antenna:", antennaNames[antbad]," Hot load out of range. T_hot:", T_hot
           else:
               print "Row ", i, " Hot load out of range. T_hot: ", T_hot," Antenna:", antennaNames[antbad]
           total += 1

    tb.close()
    if (total == 0):
        print "No problems in load temperatures found!"
    else:
        print "A total of %d load temperature problems encountered." % (total)
    return(vm)

def nearestCalScanForTime(mymsmd, mytime, intent='CALIBRATE_ATMOSPHERE*'):
    """
    Finds the calibration scan with the central time nearest to the specified time.
    -Todd Hunter
    """
    scans = mymsmd.scansforintent(intent)
    timecenters = []
    for scan in scans:
        times = mymsmd.timesforscan(scan)
        timecenters.append(np.mean([np.min(times),np.max(times)]))
    timecenters = np.array(timecenters)
    idx = np.argmin(np.abs(timecenters-mytime))
    return scans[idx]

def nearestScanForTime(mymsmd, mytime):
    """
    An extension to mymsmd.scansfortimes()
    Todd Hunter
    """
    myscans = mymsmd.scansfortimes(mytime)
    if (len(myscans) > 0):
        return(myscans[0])
    # need to find the nearest scan
    if (np.min(mymsmd.timesforscan(1)) > mytime):
        return(1)
    if (np.max(mymsmd.timesforscan(mymsmd.nscans())) < mytime):
        return(mymsmd.nscans())
    # the time lies between 2 scans
    for s in range(1,mymsmd.nscans()):
        if ((np.max(mymsmd.timesforscan(s)) < mytime) and (np.min(mymsmd.timesforscan(s+1)) > mytime)):
            if (mytime - np.max(mymsmd.timesforscan(s)) >= np.min(mymsmd.timesforscan(s+1)) - mytime):
                return(s+1)
            else:
                return(s)
    print "Failed to find nearest scan to time %f.  Returning final scan." % (mytime)
    return(mymsmd.nscans())
    
def detectNaNTsys(caltable='', antenna = '', spw='', showfield=False, vm='',
                  pol='', edge=0, vis=''):
    """
    Reads a caltable and searches for NaN
    values of FPARAM, printing a summary for each row as it finds
    them.  If an antenna is specified (ID or name), then only that antenna 
    will be displayed.  If an spw is specified (integer or string), then 
    only that spw will be displayed.  If edge is non-zero, then that many
    channels will be ignored on both edges of the spws.
    -Todd Hunter
    """
    if (os.path.exists(caltable) == False):
        print "The caltable does not exist."
        return
    if (edge < 0):
        print "The value of edge must be >= 0."
        return
    if (vis == ''):
        mytb = createCasaTool(tbtool)
        mytb.open(caltable)
        try:
            vis = mytb.getkeyword('MSName')
        except:
            print "Not a valid cal table."
            return
        mytb.close()
    if (type(antenna) == str):
        if (len(antenna) > 0):
            if (antenna.isdigit()==False):
                antennaName = antenna
                antenna = getAntennaIndex(vis, antenna)
            else:
                antenna = int(antenna)
                antennaName = getAntennaName(vis, antenna)
                
    else:
        antennaName = getAntennaName(vis, antenna)
    antennaNames = getAntennaNames(vis)
    mymsmd = ''
    if (showfield):
        if (casadef.casa_version < casaVersionWithMSMD):
            if (vm == ''):
                print "Running ValueMapping (because showfield=True and vm=0)..."
                vm = ValueMapping(vis)
        elif (vm != ''):  # this is for testing vm in >=4.1.0
            print "Running ValueMapping (because showfield=True and vm!=0)..."
            vm = ValueMapping(vis)
        else:
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
    mytb.open(caltable)
    antennas = mytb.getcol('ANTENNA1')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    times = mytb.getcol('TIME')
    intervals = mytb.getcol('INTERVAL')
    total = 0
    maxFieldLength = 16
    if (showfield):
        header = "Row  Antenna  spw  time(interval)  scan(startTime)  fieldname   polarization"
    else:
        header = "Row  Antenna  spw  time(interval)  polarization"
    headerPrinted = False
    for i in range(len(spws)):
        tsys = mytb.getcell('FPARAM',i)
        for polarization in range(len(tsys)):
            negatives = []
            if (edge > 0):
                possible = np.size(tsys[polarization][edge:-edge])
                for t in range(possible):
                    if (tsys[polarization][t+edge] != tsys[polarization][t+edge]):
                        negatives.append(t+edge)
            else:
                possible = np.size(tsys[polarization])
                for t in range(possible):
                    if (tsys[polarization][t] != tsys[polarization][t]):
                        negatives.append(t)
            howManyNegatives = len(negatives)
            if (howManyNegatives > 0):
                medianValue = np.median(tsys[polarization][negatives])
                if (antenna=='' or antennas[i]==int(antenna)):
                    if (spw=='' or spws[i] == int(spw)):
                        if (pol=='' or polarization==int(pol)):
                            if (headerPrinted == False):
                                print header
                                headerPrinted = True
                            myhhmmss = mjdSecondsToMJDandUT(times[i])[1].split()[1]
                            if (float(intervals[i]) > 1e6):
                                myhhmmss = '+%5dd(%.0fd)' % ((times[i]-times[0])/86400.,intervals[i]/86400.)
                            else:
                                myhhmmss += '(%02d:%02.0f)' % (int(float(intervals[i])/60.),intervals[i]%60)
                            if (showfield):
                                if (casadef.casa_version < casaVersionWithMSMD or mymsmd == ''):
                                    myscan = getScansForTime(vm.scansForTimes,times[i])
                                    intents = vm.getIntentsForScan(myscan)
                                    while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                        myscan -= 1
                                        intents = vm.getIntentsForScan(myscan)
                                    myscantimes = vm.getTimesForScan(myscan)
                                    myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                    myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                    myfield = vm.getFieldsForScan(myscan)[0]
                                else:
                                    myscan = nearestScanForTime(mymsmd, times[i])
                                    intents = mymsmd.intentsforscan(myscan)
#                                    print "Scan %d has intent = %s" % (myscan,str(intents))
                                    while ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents and myscan>1):
                                        myscan -= 1
                                        intents = mymsmd.intentsforscan(myscan)
#                                        print "Scan %d has intent = %s" % (myscan,str(intents))
                                    myscantimes = mymsmd.timesforscan(myscan)
                                    myscanhhmmss0 = mjdSecondsToMJDandUT(np.min(myscantimes))[1].split()[1]
                                    myscanhhmmss1 = mjdSecondsToMJDandUT(np.max(myscantimes))[1].split()[1]
                                    myfield = mymsmd.namesforfields(mymsmd.fieldsforscan(myscan)[0])[0]
                                if ('CALIBRATE_ATMOSPHERE#ON_SOURCE' not in intents and 'CALIBRATE_ATMOSPHERE#HOT' not in intents):
                                    print "       WARNING: scan %d does not have CALIBRATE_ATMOSPHERE intent" % (myscan)
                                if (len(myfield) < maxFieldLength):
                                    myfield += ' '*(maxFieldLength-len(myfield))
                                if (len(myfield) > maxFieldLength):
                                    myfield = myfield[0:maxFieldLength]
                                result = "%4d [%2d=%s, %2d, %s, %2d (%s), %16s, %d] found %4d of %4d (median=%g)" % (i,antennas[i], antennaNames[antennas[i]], spws[i], myhhmmss, myscan, myscanhhmmss0, myfield, polarization, howManyNegatives, possible, medianValue)
                            else:
                                result = "%4d [%2d=%s, %2d, %s, %d), found %3d out of %3d (median=%g)" % (i,
                              antennas[i],antennaNames[antennas[i]],spws[i], myhhmmss, polarization, howManyNegatives, possible, medianValue)
                            print result
                            total += howManyNegatives
    mytb.close()
    if (total == 0):
        print "No NaNs found!"
    else:
        print "A total of %d NaN values encountered." % (total)
    if (mymsmd != ''):
        mymsmd.close()
    return(vm)

def listflagscal(caltable='',maxrows=0, verbose=False):
    """
    Examine all rows in a caltable that have flagged data, and report statistics.
    Options:
    verbose: if True, list all row numbers
    maxrows: if maxrows > 0, then stop after examining maxrows
    Todd Hunter
    """
    mytb = tbtool()
    mytb.open(caltable)
    times = mytb.getcol('TIME')
    fields = mytb.getcol('FIELD_ID')
    antennas = mytb.getcol('ANTENNA1')
    totalrows = 0
    totalflags = 0
    totalpoints = 0
    rows = []
    fo = open(caltable.split('/')[-1]+'.listflags','w')
    for i in range(len(times)):
        flags = mytb.getcell('FLAG',i)
        for f in flags:
            lf = list(f)
            c = lf.count(1)
            if (c > 0):
                if (verbose):
                    print "Found %d flags in row %d, antenna=%d, field=%d" % (c,i,antennas[i],fields[i])
                totalrows += 1
                rows.append(i)
                fo.write('%d %d\n'%(i,c))
                totalflags += c
            totalpoints += len(lf)
        if (totalrows>=maxrows and maxrows>0): break
    mytb.close()
    print "This caltable has %d rows." % (len(times))
    fo.write("This caltable has %d rows.\n" % (len(times)))
    print "Found %d flags (%.4f%%) in %d different rows." % (totalflags, 100*totalflags/(1.0*totalpoints), totalrows)
    fo.write("Found %d flags (%.4f%%) in %d different rows.\n" % (totalflags, 100*totalflags/(1.0*totalpoints), totalrows))
    fo.close()

def pickPWV(frequency, declination, useTable=False, config='alma.cycle5.1'):
    """
    Returns PWV (in mm) that will be chosen by the ALMA OT sensitivity 
    calculator for specified representative frequency in GHz.
    frequency: in GHz
    declination: of the target (in degrees)
    useTable: if False, then use the algorithm described in SCIREQ-1110,
          using simutil to compute the sensitivity in successive octiles.
       if True, then use the approximate table containing per-band values,
          with 2 entries for bands 4 and 7 (lower vs. upper end)
    config: does not actually matter, any valid one will do
    Note: if you want to change the T_rx assumed, you have to change the tabulated
       values in CASA, because simutil.sensitivity does not expose this parameter.
    -Todd Hunter
    """
    if useTable:
        if float(frequency) < 119:
            water_vap = 5.186  # Band 3               # 7th octile
        elif float(frequency) <= 153.1:
            water_vap = 2.748  # Band 4 (lower end)   # 6th octile
        elif float(frequency) < 163:
            water_vap = 1.796  # Band 4 (upper end)   # 5th octile
        elif float(frequency) < 211:
            water_vap = 1.5    # Band 5               # not yet defined
        elif float(frequency) < 275:
            water_vap = 1.262  # Band 6               # 4th octile
        elif float(frequency) < 349.5:
            water_vap = 0.913  # Band 7 lower         # 3rd octile
        elif float(frequency) < 370.5:
            water_vap = 0.658  # Band 7 upper (except for upper edge)  # 2nd octile
        elif float(frequency) < 500:
            water_vap = 0.472  # Band 8               # 1st octile
        elif float(frequency) < 720:
            water_vap = 0.472  # Band 9               # 1st octile
        else:
            water_vap = 0.472  # Band 10              # 1st octile
        return water_vap
    else:
        exposureTime = 1
        pwv = octile(1)
        elevationLimit = 3
        elevation = 90 - abs(declination - ALMA_LATITUDE)
        print "Using transit elevation = %.1f deg" % (elevation)
        if elevation < elevationLimit:
            print "Object does not rise above the antenna elevation limit of %.0f degrees." % (elevationLimit)
            return
        rms = sensitivity(frequency, 1, exposureTime, elevation, pwv,
                          config, verbose=False)
        print "Computed sensitivity for octile %d (%.3f mm): %f for time=%d" % (1,pwv,rms,int(exposureTime))
        if rms <= 0:
            print "simutil failed."
            return
        for proposedOctile in range(2,8):
            pwv = octile(proposedOctile)
            newExposureTime = 2*exposureTime
            newrms = sensitivity(frequency, 1, newExposureTime, elevation, pwv,
                                 config, verbose=False)
            print "Computed sensitivity for octile %d (%.3f mm): %f for time=%d" % (proposedOctile,pwv,newrms,int(newExposureTime))
            if newrms > rms:
                return octile(proposedOctile-1)
        return octile(7)

def recenterOTPointings(ptgfile, radec='', outfile='', img=''):
    """
    Reads a new-style (Cycle 4) OT pointings file and moves the center
    to a new source (RA Dec)
    radec: sexagesimal string, colon or space-delimited, e.g. HH:MM:SS DD:MM:SS
    outfile: if '', then set this to <ptgfile>.recentered
    img: if specified, use the midpoint of this image as the center of the pointings
    """
    if (img != ''):
        newra,newdec = radec2rad(imageCenter(img,verbose=False))
    else:
        newra,newdec = radec2rad(radec)
    oldradec = getMeanPositionFromOTPointings(ptgfile)
    oldra,olddec = radec2rad(oldradec)
    deltara = newra-oldra
    deltadec = newdec-olddec
    f = open(ptgfile,'r')
    lines = f.readlines()
    f.close()
    if (outfile == ''):
        outfile = ptgfile + '.recentered'
    f = open(outfile,'w')
    for line in lines:
        if (line.find('SEXAGESIMAL')>0):
            tokens = line.split(',')
            ra,dec = radec2rad(tokens[0]+' '+tokens[1])
            ra += deltara
            dec += deltadec
            f.write('%s,Absolute,SEXAGESIMAL\n'%(rad2radec(ra,dec,verbose=False,delimiter=',')))
        else:
            f.write(line)
    f.close()
    print "Wrote ", outfile
    return

def getMeanPosition(radecs):
    """
    Computes the mean RA and mean Dec of a list of RA/Dec coordinates
    radecs: a list or comma-delimited string of sexagesimal coordinates
        e.g. 'HH:MM:SS.SS +DD:MM:SS,HH:MM:SS.SS -DD:MM:SS'
    -Todd Hunter
    """
    if type(radecs) ==str:
        radecs = radecs.split(',')
    ras = []
    decs = []
    for radec in radecs:
        ra,dec = radec2rad(radec)
        ras.append(ra)
        decs.append(dec)
    meanRaDec = rad2radec(np.mean(ras), np.mean(decs), verbose=False)
    return meanRaDec

def getMeanPositionFromOTPointings(ptgfile, writeOldFormatFile=False):
    """
    Reads a new-style (Cycle 4) OT pointings file and computes the mean of all 
    pointings.
    Inputs:
    ptgfile: an ASCII file dumped from the OT in Cycle 4+
    writeOldFormatFile: if True, then also generate a matching old-format
          version (e.g. for use with simobserve in casa 4.5).
    Returns:
    a sexagesimal string of the mean position of all pointings
    -Todd Hunter
    """
    f = open(ptgfile,'r')
    lines = f.readlines()
    f.close()
    ras = []
    decs = []
    for line in lines:
        if (line.find('SEXAGESIMAL')>0):
            tokens = line.split(',')
            ra,dec = radec2rad(tokens[0]+' '+tokens[1])
            ras.append(ra)
            decs.append(dec)
    meanRaDec = rad2radec(np.mean(ras),np.mean(decs))
    meanRaDecForSimobserve = rad2radec(np.mean(ras),np.mean(decs),hmdm=True, delimiter=' ',prependEquinox=True)
    if (writeOldFormatFile):
        newptgfile = ptgfile+'.oldformat'
        f = open(newptgfile,'w')
        f.write('# Pointings for Source unknown (%s)\n' % (meanRaDecForSimobserve))
        f.write('# Epoch | RA | DEC |\n')
        for i in range(len(ras)):
            f.write('%s\n'%rad2radec(ras[i],decs[i],hmdm=True, delimiter=' ',prependEquinox=True))
        f.close()
        print "Wrote ", newptgfile
    return(meanRaDec)

def makeSimulatedImage(phasecenter='J2000 16h25m46.98000s -25d27m38.3300s',
                       sourcecenter='', flux=1.0, freq=100, field='', pointingspacing=2.0,
                       configuration='alma.out10.cfg', bandwidth='1GHz', niter=100,
                       imsize=256, mapsize='', integration='1min',
                       totaltime=None, cellsize='auto', threshold='10mJy/beam',
                       shape='point', majoraxis=0, minoraxis=0, positionangle=0,
                       refdate='2012/05/21', hourangle='transit', componentList=None,
                       writefits=False, normalize=False, verbose=False, analyze=True,
                       ptgfile='', levels=[0.5], weighting='natural', user_pwv='auto',
                       vis=None, phaseCenterOffset=None, add7mSinglePointing=False,
                       timeMultiplier7m=5
              ):
    """
    Create a simulated ALMA image of a point source or uniform disk at a 
    specified direction and flux density (in Janskys). Here are the parameters:

    phasecenter: required argument, example: 'J2000 06h00m00.00s -04d00m00.0s'
          if J2000 is missing, then it will be prepended.
          colon delimiters are also accepted. Set to 'auto' to read from ptgfile.
    sourcecenter: if not specified, then assumed to be same as phasecenter
    flux: flux density of point source (in Jy)
    freq: frequency (in GHz)
    field: field name to use for simobserve project directory name
    configuration: anything in /usr/lib64/casapy/data/alma/simmos/
    bandwidth: in GHz
    imsize: in pixels
    mapsize: '' or value in arcsec
    totaltime: e.g. '200min'  for 200 minutes (not '200m'); if not specified and
          ptgfile is given, then it will be set to Npointings * integration
    integration: e.g. '20s'  for 200 seconds (not '20sec')
    cellsize: floating point value or 'auto' (~4 pix per beam)
    pointingspacing: units of primary beam, default = 2.0 (i.e. no mosaic)
    threshold: for CLEAN
    user_pwv: for VLA config files, it uses 5mm; for others, it uses au.pickPWV
          'auto' or a floating point value in mm (passed to simobserve task)
    shape: 'point' or 'disk' or 'Gaussian'
    majoraxis: value in arcsec (or a string with units)
    minoraxis: value in arcsec (or a string with units)
    positionangle: value in degrees
    refdate:  'YYYY/MM/DD'
    hourangle: 'transit' or '-3h'
    componentList: use the componentList instead of phasecenter, shape & size
    writefits: if True, then run exportfits to create FITS versions of image & psf
    normalize: runs normalizeImage at the end to ensure peak flux of Gaussian
    analyze: if False, then don't run simanalyze (i.e. only create the ms)
    ptgfile: if specified, then set setpointing=False and pass to simobserve 
    levels: contour levels to show in the .flux image (for mosaics)
    weighting: 'natural' or 'briggs' (simanalyze uses robust=0.5)
    vis: if specified and phasecenter=='auto', then use the pointings of all
            field IDs in the measurement set with the specified field name.
         if specified and freq=='auto', use the representative frequency
         Also use the refdate and configuration of the vis.
    phaseCenterOffset: offset in [RA_arcsec, Dec_arcsec]

    --Todd Hunter
    """
    if not casaAvailable:
        print "You can only run au.makeSimulatedImage from inside CASA."
        return
    if totaltime is None:
        if ptgfile == '':
            print "You must specify a totaltime if you do not specify a ptgfile."
            return
    if (field == ''):
        field = 'makeimage'
        project = field
    else:
        project = field
        if (field.find('sim') < 0):
            project += '.sim'
    if os.path.exists(project):
        print "project path already exists: %s.  Use the field parameter to set a different one." % (project)
        return
    warning = ''
    if (phasecenter == 'auto'):
        if (ptgfile == '' and vis==None):
            print "phasecenter='auto' requires a ptgfile or vis"
            return
        if (vis is None):
            f = open(ptgfile,'r')
            if verbose: print "Opened pointing file"
            lines = f.readlines()
            f.close()
            for line in lines:
                if (line.find('J2000') >= 0):
                    # old format OT file: take the first pointing
                    phasecenter = line[line.find('J2000'):].split(')')[0]
                    print "Got phasecenter = %s." % (phasecenter)
                    break
                elif (line.find('SEXAGESIMAL') >= 0):
                    # new format OT file (Cycle 4), get the mean of all pointing
                    phasecenter = getMeanPositionFromOTPointings(ptgfile, writeOldFormatFile=True)
                    ptgfile = ptgfile+'.oldformat'
                    break
            npointings = len(lines)-2
            if integration.find('min')>0:
                if totaltime is None:
                    totaltime = str(npointings*int(integration.replace('min',''))) + 'min'
                elif totaltime.find('min')>0:
                    if (int(integration.replace('min','')) * npointings != int(totaltime.replace('min',''))):
                        warning = 'WARNING: total time (%s) is not a multiple of the number of pointings (%d) times integration (%s)' % (totaltime,npointings,integration)
                        print warning
                else:
                    print "integration and totaltime must use the same units"
                    return
            elif totaltime is None:
                print "You must set integration in minutes to use automatic totaltime."
                return
        else:
            if (not os.path.exists(vis)):
                print "Could not find measurement set"
                return
            mymsmd = createCasaTool(msmdtool)
            mymsmd.open(vis)
            # Assume the first field for the source name is phase center
            fieldname = field
            field = mymsmd.fieldsforname(fieldname)[0]
            mymsmd.close()
            phasecenter = rad2radec(getRADecForField(vis, field))
            if (freq == 'auto'): 
                freq = representativeFrequency(vis)
                print "Representative frequency = %f GHz" % (freq)
            refdate = getObservationStartDate(vis,delimiter='/').split()[0]
            configuration = vis.rstrip('.ms')+'.cfg'
            buildConfigurationFile(vis, output=configuration)
            ptgfile = makePtgfile(vis, fieldname, phaseCenterOffset=phaseCenterOffset)
    if (phasecenter[:5] != "J2000"):
        phasecenter = 'J2000 ' + phasecenter
    phasecenter = phasecenter.replace(',',' ')
    sourcecenter = sourcecenter.replace(',',' ')
    if (phasecenter.find(',') > 0):
        print "phasecenter must not have a comma"
        return
    if (sourcecenter.find(',') > 0):
        print "sourcecenter must not have a comma"
        return
    if (phasecenter.find(':') > 0):
        if (len(phasecenter.split(':')) != 5):
            print "phasecenter must be entered in this format: HHhMMmSS.SSs +DDdMMmSS.SSs"
            return
        else:
            phasecenter = phasecenter.replace(':','h',1).replace(':','m',1).replace(':','d',1).replace(':','m',1) + 's'
            phasecenter = phasecenter.split()[0] + ' ' + phasecenter.split()[1] + 's ' + phasecenter.split()[2]
    if (sourcecenter.find(':') > 0):
        print "sourcecenter must be entered in this format: HHhMMmSS.SSs +DDdMMmSS.SSs"
        return
    if (sourcecenter == ''):
        sourcecenter = phasecenter
    phaseCenterRADec = phasecenter.replace('J2000 ','')
    declinationDeg = radec2deg(phaseCenterRADec)[1]
    if (shape != 'point' and shape != 'disk' and shape != 'Gaussian' and componentList is None):
        print "The shape argument must be either 'point', 'Gaussian', or 'disk'."
        return
    mycl = createCasaTool(cltool)
    if (componentList is None):
        componentList = '%s.cl' % (field)
        if (os.path.exists(componentList)):
            if verbose: print "Running shutil.rmtree('%s')" % (componentList)
            shutil.rmtree(componentList)
        if (majoraxis != 0 and minoraxis == 0):
            print "Setting minor axis equal to major axis."
            minoraxis = majoraxis
        if (type(majoraxis) != str):
            majoraxis = '%farcsec' % majoraxis
        if (type(minoraxis) != str):
            minoraxis = '%farcsec' % minoraxis
        if verbose: print "Running mycl.addcomponent(dir='%s', flux=%f, fluxunit='Jy', freq='%.1fGHz', shape='%s', majoraxis='%s', minoraxis='%s', positionangle='%fdeg')" % (sourcecenter, flux, freq, shape, majoraxis, minoraxis, positionangle)
        mycl.addcomponent(dir=sourcecenter, flux=flux, fluxunit='Jy',
                        freq='%.1fGHz'%freq, shape=shape,
                        majoraxis='%s' % majoraxis,
                        minoraxis='%s' % minoraxis,
                        positionangle='%fdeg' % positionangle)
        if verbose: print "Running mycl.rename('%s')" % componentList
        mycl.rename(componentList)
        if verbose: print "Running mycl.close()"
    else:
        mycl.open(componentList)
        refdir = mycl.getrefdir(0)
        phasecenter = direction2radecForSimobserve(refdir)
    mycl.close()
    if (cellsize == 'auto'):
        result = getBaselineStats(config=configuration, verbose=verbose)
        if result is None:
            return
        baseline90percentile = result[10]
        baselineMax = result[2]
        cellsize = printBaselineAngularScale(baselineMax,freq,verbose=False) / 5.0
        if (analyze):
            print "Picked cellsize = ", cellsize
        else:
            print "You should use cellsize = ", cellsize
    else:
        if (type(cellsize) == str and analyze):
            print "Cellsize must be 'auto' or a floating point value."
            return
    graphics = 'none'
    config = configuration
    if (config.find('.cfg')>0):
        config = config[0:-4]
    imagename = '%s/%s.%s' % (project,project,config)
    if (type(mapsize) != str):
        mapsize = str(mapsize)+'arcsec'
    if (ptgfile == ''):
        setpointings = True
    else:
        setpointings = False
    if (user_pwv == 'auto'):
        if config.find('vla') >= 0:
            user_pwv = 5.0
        else:
            user_pwv = pickPWV(freq, declinationDeg)
        print "Picked PWV = ", user_pwv
    if (casadef.casa_version <= '3.3.0'):
#        halfpower = 0.4  # 12m Airy pattern is too narrow, so go further out
        simobserve(project=project,complist=componentList,
                   antennalist=configuration, totaltime=totaltime,
                   mapsize=[mapsize,mapsize],graphics=graphics,
                   compwidth=bandwidth,overwrite=True,
                   direction=phasecenter, integration=integration,
                   pointingspacing='%.2fPB'%(pointingspacing),
                   setpointings=setpointings, hourangle=hourangle, 
                   refdate=refdate, ptgfile=ptgfile, user_pwv=user_pwv)
    else:
#        halfpower = 0.5 # 10.7m Airy pattern is now used in CASA for ALMA
        if True:
            print "Running simobserve(project='%s',complist='%s',antennalist='%s'," % (project,componentList,configuration)
            print "            totaltime='%s', mapsize=['%s','%s'], graphics='%s'," % (totaltime,mapsize,mapsize,graphics)
            print "            obsmode='int', compwidth='%s', overwrite=True, direction='%s'," % (bandwidth,phasecenter)
            print "            integration='%s', pointingspacing='%.2fPB', setpointings=%s," % (integration,pointingspacing,setpointings)
            print "            hourangle='%s', refdate='%s', ptgfile='%s', user_pwv=%f)" % (hourangle,refdate,ptgfile,user_pwv)
        simobserve(project=project,complist=componentList,
                   antennalist=configuration, totaltime=totaltime,
                   mapsize=[mapsize,mapsize],graphics=graphics,
                   obsmode="int", compwidth=bandwidth,overwrite=True,
                   direction=phasecenter, integration=integration,
                   pointingspacing='%.2fPB'%(pointingspacing),
                   setpointings=setpointings, hourangle=hourangle, 
                   refdate=refdate, ptgfile=ptgfile,user_pwv=user_pwv)
        print "Done"
    if add7mSinglePointing:
        project7m = project + '_aca'
        totaltime = str(float(totaltime.replace('min',''))*timeMultiplier7m) + 'min'
        simobserve(project=project7m,complist=componentList,
                   antennalist='aca.cycle5.cfg', totaltime=totaltime,
                   graphics=graphics,
                   obsmode="int", compwidth=bandwidth,overwrite=True,
                   direction=phasecenter, integration=integration,
                   pointingspacing='%.2fPB'%(pointingspacing),
                   setpointings=True, hourangle=hourangle, 
                   refdate=refdate, ptgfile='',user_pwv=user_pwv)
        vis = '%s.%s.ms'%(project7m, config.rstrip('.ms'))
        if (os.path.exists(project7m+'/'+vis+'.listobs')):
            os.remove(project7m+'/'+vis+'.listobs')
        
    vis = '%s.%s.ms'%(project,config.rstrip('.ms'))
    if (os.path.exists(project+'/'+vis+'.listobs')):
        os.remove(project+'/'+vis+'.listobs')
    print "Running listobs(vis='%s/%s', listfile='%s/%s.listobs')" % (project,vis,project,vis)
    listobs(vis=project+'/'+vis, listfile=project+'/'+vis+'.listobs')
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(project+'/'+vis)
    nfields = mymsmd.nfields()
    print "There are %d fields." % (nfields)
    # simobserve creates a list file that is colon and decimal delimited.
    # Here we created one that is hms, dms delimited, and has the field ID as the final column
    ptgfilename = project+'/'+vis+'.pointings'
    ptgfile = open(ptgfilename, 'w')
    for myfield in range(nfields):
        radec = rad2radec(getRADecForField(project+'/'+vis, myfield, usemstool=True),hmsdms=True,
                          delimiter=' ',verbose=False)
        ptgfile.write('J2000 %s %d\n' % (radec,myfield))
    ptgfile.close()
    print "Pointing positions left in: %s" % (ptgfilename)
    mymsmd.close()
    if (analyze):
        print "Running simanalyze(project='%s',vis='%s',imsize=[%d,%d], imdirection='%s', cell='%.5farcsec',niter=%d,overwrite=True,analyze=False,threshold='%s',graphics='%s',weighting='%s')" % (project,vis,imsize,imsize,phasecenter,cellsize,niter,threshold,graphics,weighting)
        if (os.path.exists(imagename+'.image')):
            shutil.rmtree(imagename+'.image')
        simanalyze(project=project, vis=vis,
                   imsize=[imsize,imsize], imdirection=phasecenter,
                   cell='%.5farcsec'%(cellsize), niter=niter,overwrite=True,
                   analyze=False, threshold=threshold,graphics=graphics, 
                   weighting=weighting)
        if (normalize):
            normalizeImage(imagename+'.image', value=flux)
        if (writefits):
            print "Calling exportfits('%s','%s',overwrite=True)" % (imagename+'.image', imagename+'.image.fits')
            exportfits(imagename+'.image', imagename+'.image.fits',overwrite=True)
            print "Calling exportfits('%s','%s',overwrite=True)" % (imagename+'.psf', imagename+'.psf.fits')
            exportfits(imagename+'.psf', imagename+'.psf.fits',overwrite=True)
            
        imview(raster={'file':'%s.image' % (imagename), 'colorwedge':True},
               out='%s.image.png' % (imagename)
    #          , contour={'file':'%s.flux.pbcoverage' % (imagename),
    #                    'levels':[halfpower]}
               )
        imview(raster={'file':'%s.psf' % (imagename), 'colorwedge':True},
               out='%s.psf.png' % (imagename)
    #           ,contour={'file':'%s.flux.pbcoverage' % (imagename),
    #                    'levels':[halfpower]}
               )
        print "Images left in: %s.image and %s.psf" % (imagename,imagename)
        print "Sky model image left in: %s.compskymodel" % (imagename)
        if exportfits:
            print "FITS Images left in: %s.image.fits and %s.psf.fits" % (imagename,imagename)
        print "Pngs left in: %s.image.png and %s.psf.png" % (imagename,imagename)
    myms = project + '/' + vis
    print "Visibility data left in: %s" % (myms)
    listobs(myms, listfile=myms+'.listobs', overwrite=True)
    mymsmd.open(myms)
    nobsfields = mymsmd.nfields()
    nscans = mymsmd.nscans()
    print "There are %d/%d fields observed in %d scans." % (nobsfields, nfields, nscans)
    mymsmd.close()
    if (analyze):
        result = getFitsBeam(imagename+'.image')
        print "Beam = %f arcsec x %f arcsec at %f deg" % (result[0], result[1], result[2])
        if (nfields > 1):
            if (nobsfields != nfields or nscans != nobsfields):
                print "Uneven sensitivity in mosaic.  Set totaltime to be the correct multiple of integration."
            plotmosaic(myms, figfile=True)
            imview(contour={'file': '%s.flux' % (imagename), 'levels': levels},
                   out='%s.flux.png' % (imagename))
            print "Flux image left in: %s.flux" % (imagename)
            print "Calling exportfits('%s','%s',overwrite=True)" % (imagename+'.flux', imagename+'.flux.fits')
            exportfits(imagename+'.flux', imagename+'.flux.fits',overwrite=True)
            print "Contour plot of .flux image left in: %s.flux.png" % (imagename)
    if warning != '':
        print warning

def extractSpatialAxisValues(img, axis, decRadians=None):
    """
    Extracts an array of RA or Dec values (in radians) from an image in a way that
    is faster than a 'for' loop over each pixel in a strip using ia.coordmeasures()
    img: CASA or FITS image
    axis: 0 for RA, 1 for Dec
    decRadians: only used for axis=0, to get very highest accuracy when the
         resulting RA scale is to be used at a particular declination
    -Todd Hunter
    """
    myia = createCasaTool(iatool)
    myia.open(img)
    raunits = myia.coordmeasures()['measure']['direction']['m0']['unit']
    nrapixels = myia.shape()[axis]
    x = np.array(range(nrapixels))
    mycs = myia.coordsys()
    cdelt = mycs.increment()['numeric'][axis]
    if axis == 0:
        # correct the reported (on-sky) delta RA for cosine(dec)
        if decRadians is None:
            cdelt /= np.cos(mycs.referencevalue()['numeric'][1])
        else:
            cdelt /= np.cos(decRadians)
    crpix = mycs.referencepixel()['numeric'][axis]
    crval = mycs.referencevalue()['numeric'][axis]
    ra = crval + cdelt*(x-crpix)
    myia.close()
    return ra

def findRADec(image, radec='',round=False, getvalue=False, beam=None,
              fastMethod=True, verbose=False):
    """
    Takes an image and converts an RA/Dec into a pixel coordinate. It
    is the opposite of findPixel.
    radec: either a sexagesimal string or a tuple in radians
           the RA and Dec can be separated by a space or a comma
           the Dec string can be either colon or period-delimited
           the RA string must be colon-delimited
           It can also be a list of sexagesimal strings or a list of tuples.
           If it is a list of lists, then only the first list is used.
    round: round the result to the nearest integral pixel
    getvalue: if True, then also return the pixel value here 
    beam: if not None, then interpret this as the FWHM beam in arcsec, assume the
          image is in MJy/sr, and compute the Jy for this pixel
    fastMethod: if True, then use reference pixel and axis increment (fast);
                if False, then use ia.coordmeasures for every pixel (slow)
    Returns: a 2-element list: [x,y], or list of lists if radec is a list
          if getvalue==True, then return [[x,y], intensity]
    - Todd Hunter
    """
    if (os.path.exists(image) == False):
        print "Could not find image file"
        return
    if (radec == ''):
        print "You must specify a position as a sexagesimal string (or radian tuple) using the radec parameter."
        return
    if type(radec) != list:
        radecs = [radec]
    else:
        if type(radec[0]) == list:
            # if it is a list of lists, then just use the first list
            radecs = radec[0]
        elif type(radec[0]) == str:
            radecs = radec
        else: # float
            radecs = [radec]
    if fastMethod or getvalue:
        myia = createCasaTool(iatool)
        myia.open(image)
        if getvalue:
            values = []
    mylist = []
    for radec in radecs:
        if (type(radec) == str):
            # convert latex table format to space-delimited
            radec = radec2rad(radec.replace('&',' '))
        if fastMethod:
            if type(radec) == list:
                ra = extractSpatialAxisValues(image, 0, radec[1])
            else:
                print "radec = ", radec
                ra = extractSpatialAxisValues(image, 0, radec[1])
            dec = extractSpatialAxisValues(image, 1)
        else:
            # This old method is too slow - it computes each pixel at a time.
            raunits = myia.coordmeasures()['measure']['direction']['m0']['unit']
            decunits = myia.coordmeasures()['measure']['direction']['m1']['unit']
            nrapixels = myia.shape()[0]
            ndecpixels = myia.shape()[1]
            ra = []
            dec = []
            x = np.array(range(nrapixels))
            for i in x:
                myra = myia.coordmeasures([i,0,0,0])['measure']['direction']['m0']['value']
                ra.append(myra)
            ra = np.array(ra)
            if (raunits.find('deg') >= 0):
                ra = np.radians(ra)
            y = range(ndecpixels)
            for i in y:
                mydec = myia.coordmeasures([0,i,0,0])['measure']['direction']['m1']['value']
                dec.append(mydec)
            dec = np.array(dec)
            if (decunits.find('deg') >= 0):
                dec = np.radians(dec)
        
        raDiff = ra - radec[0]
        if (np.mean(raDiff) < -2*np.pi+0.1):
            raDiff += 2*np.pi
        if (np.mean(raDiff) > 2*np.pi-0.1):
            raDiff -= 2*np.pi
        x = range(len(raDiff))
        xpix = findZeroCrossing(x,raDiff)
        if (len(xpix) < 1):
            print "RA Coordinate is not within the image"
            print "Note that this function does not support ia.rotate-d images!"
            return

        decDiff = np.array(dec)-radec[1]
        if (np.mean(decDiff) < -2*np.pi+0.1):
            decDiff += 2*np.pi
        if (np.mean(decDiff) > 2*np.pi-0.1):
            decDiff -= 2*np.pi
        y = range(len(decDiff))
        ypix = findZeroCrossing(y, decDiff)
        if (len(ypix) < 1):
            print "Dec Coordinate is not within the image"
            return
        if (getvalue):
            myrg = createCasaTool(rgtool)
            blc = [int(np.round(xpix[0])), int(np.round(ypix[0]))]
            region = myrg.box(blc=blc, trc=blc)
            pixels = myia.getregion(region=region)
            if verbose:
                print "Pixel value = ", pixels[0][0]
            value = pixels[0][0]
            if (beam is not None):
                jansky = pixels[0][0]*1e6*np.pi*0.25*(beam/ARCSEC_PER_RAD)**2/np.log(2)
                if verbose:
                    print "Assuming MJy/sr, the flux density is %f Jy" % (jansky)
                value = jansky
        if (round):
            # cannot round a single array entry to int (it has no effect)
            xpix0 = int(np.round(xpix[0]))
            ypix0 = int(np.round(ypix[0]))
        else:
            xpix0 = xpix[0]
            ypix0 = ypix[0]
        mylist.append([xpix0, ypix0])
        if getvalue:
            for i in range(2):
                if type(value) == np.ndarray:
                    value = value[0]
            values.append(value)
    if fastMethod or getvalue:
        if getvalue:
            myrg.done()
        myia.close()
    if len(mylist) == 1:
        return mylist[0]
    else:
        if getvalue:
            return mylist, values
        else:
            return mylist

def findPixel(image, pixelfile='', pixel='', referencePosition=None, 
              precision=5, outputfile=None, getvalue=False, beam=None,
              format='sexagesimal_colon', verbose=True, delimiter=' '):
    """
    Takes an image and converts a pixel, or list of pixels read from a file
    into a list of RA,Decs, and (optionally) the separation from a reference
    position in arcseconds.
    image: should be recognizable to casa (FITS or casa native image or cube).
    pixel: either a comma-delimited string of 2 values, or a 2-element list.
        In either case, pixel values can be integers or floating point values.
    pixelfile: file containing lines in any of these formats:
      sourcename1 '243, 347'\n
      sourcename2 "243, 347"\n
      sourcename3 243, 347\n
      Ignores lines with '#' as the first character, and lines lacking a comma.
    [If you do not provide pixel or pixelfile, the reference pixel is used.]
    referencePosition: compute separation from this [RA,Dec] (in degrees)
    getvalue: if True, the return the pixel value here 
    beam: if not None, then interpret it as the FWHM beam in arcsec, assume the
          image is in MJy/sr, and compute the Jy for this pixel
    format: 'sexagesimal_colon', 'sexagesimal_hms', 'sexagesimal_period', 'radians', or 'degrees'
        'sexagesimal_hms'    = XXhXXmXX.XXXs +XXdXXmXX.XXXs
        'sexagesimal_period' = XXhXXmXX.XXXs +XX.XX.XX.XXX
        'sexagesimal_colon'  = XX:XX:XX.XXXs +XX:XX:XX.XXX
    delimiter: used by the format='sexagesimal_*'
    verbose: if True, print the result to the screen
    Returns:
    'sexagesimal':
       if one pixel: a single sexagesimal string:  HH:MM:SS.SSS +DD:MM:SS.SS
       if more than one pixel: a list of strings
    'radians' or 'degrees':
       if one pixel: [ra, dec]
       if more than one pixel: a list of [ra,dec] values
    - Todd Hunter
    """
    if (os.path.exists(image) == False):
        print "Could not find image file"
        return
    if casaAvailable:
        myia = createCasaTool(iatool)
        myia.open(image)
    elif (not os.path.isdir(image)):
        # use pyfits
        myia = pyfits.open(image)
        hdr = myia[0].header
    else:
        print "This function is not available for non-FITS images when run outside of CASA."
        return
        
    maxSourceNameLength = 0
    if (pixelfile == '' and pixel==''):
        print "Since you have not provided either a pixelfile or a single pixel, I will use the reference pixel."
        pixel = list(myia.coordsys().referencepixel()['numeric'][:2])
        pixels = [pixel]
        sourceNames = ['']
    else:
        if (pixelfile == ''):
            if (type(pixel) == list or type(pixel) == tuple):
                pixels = [pixel]
            else:
                pixels = pixel.split(',')
                pixels = [[float(pixels[0]), float(pixels[1])]]
            sourceNames = ['']
        else:
            if (not os.path.exists(pixelfile)):
                print "Could not find pixel file = %s" % (pixelfile)
                return
            p = open(pixelfile, 'r')
            lines = p.readlines()
            p.close()
            pixels = []
            sourceNames = []
            for line in lines:
                tokens = line.split(',')
                if (len(tokens) < 2): continue
                if (line.find('#') == 0): continue
                sourceNames.append(line.split()[0])
                if (len(sourceNames[-1]) > maxSourceNameLength):
                    maxSourceNameLength = len(sourceNames[-1])
                if (line.find("'") >= 0):
                    delimiter = "'"
                elif (line.find('"') >= 0):
                    delimiter = '"'
                else:
                    delimiter = ' '
                x = tokens[0].split(delimiter)[-1]
                y = tokens[1].split(delimiter)[0]
                pixels.append([float(x),float(y)])
    NAME = 'NAME' + ' '*(maxSourceNameLength - 4)
    outline = '%s    PIXEL        RA         DEC   ' %  (NAME)
    if (referencePosition is not None):
        outline += 'Separation (arcsec)'
    if (pixel == ''):
        if (outputfile is None):
            outputfile = pixelfile+'.radec'
        outfile = open(outputfile, 'w')
        outfile.write(outline+'\n')
    returnValues = []
    for i in range(len(pixels)):
        if casaAvailable:
            mypixel = np.zeros(len(myia.shape()))
        else:
            mypixel = np.zeros(hdr['NAXIS'])
        mypixel[0] = pixels[i][0]
        mypixel[1] = pixels[i][1]
        x = mypixel[0]
        y = mypixel[1]
        if casaAvailable:
            ra = myia.coordmeasures(mypixel)['measure']['direction']['m0']['value']
            dec = myia.coordmeasures(mypixel)['measure']['direction']['m1']['value'] 
            raDeg = np.degrees(ra)
            decDeg = np.degrees(dec)
        else:
            decDeg = hdr['CRVAL2'] + hdr['CDELT2']*(y-hdr['CRPIX2']+1)
            dec = np.radians(decDeg)
            raDeg = hdr['CRVAL1'] + hdr['CDELT1']*(x-hdr['CRPIX1']+1)/np.cos(dec)
            ra = np.radians(raDeg)
        if casaAvailable:
            raString = qa.formxxx('%.12frad' %(ra), format='hms', prec=precision+1)
            decString = qa.formxxx('%.12frad'%(dec),format='dms',prec=precision-1).replace('.',':',2)
        else:
            raString, decString = deg2radec([ra,dec],prec=precision).split(',')
        # Pad names with trailing spaces to align the output columns
        sourceNames[i] += ' ' * (maxSourceNameLength - len(sourceNames[i]))
        if (decString[1] == '0'):
            decString = decString[0] + decString[2:] # strip off leading zero in dec
        if (type(x) == str):
            outline = '%s   %s %s   %s %s' % (sourceNames[i], x, y, raString, decString)
        elif (x == int(float(x)) and y == int(float(y))):
            # integer pixels
            outline = '%s   %d %d   %s %s' % (sourceNames[i], x, y, raString, decString)
        else:
            # floating point pixels
            outline = '%s   %.6f %.6f   %s %s' % (sourceNames[i], x, y, raString, decString)
        if (referencePosition is not None):
            separation = angularSeparation(referencePosition[0], referencePosition[1], raDeg, decDeg)
            outline += '  %f' % (separation*3600)
        if verbose: print outline
        if (pixel == ''):
            outfile.write(outline+'\n')
        if (format.find('sexagesimal')>=0):
            if (format.find('hms')>=0):
                raString,decString = convertColonDelimitersToHMSDMS(raString+' '+decString).split()
            elif (format.find('period')>=0):
                raString,decString = convertColonDelimitersToHMSDMS(raString+' '+decString, usePeriodsForDeclination=True).split()
            returnValues.append(raString + delimiter + decString)
        elif (format.find('radians')>=0):
            returnValues.append([ra,dec])
        elif (format.find('degrees')>=0):
            returnValues.append([raDeg,decDeg])
        else:
            print "Unrecognized format type"
            
    if (pixel == ''):
        outfile.close()
        print "Output file = ", outputfile
    if (getvalue):
        if casaAvailable:
            myrg = createCasaTool(rgtool)
            blc = [int(pixel.split(',')[0]), int(pixel.split(',')[1])]
            region = myrg.box(blc=blc, trc=blc)
            pixels = myia.getregion(region=region)
            print "Pixel value = ", pixels[0][0]
            if (beam is not None):
                jansky = pixels[0][0]*1e6*np.pi*0.25*(beam/ARCSEC_PER_RAD)**2/np.log(2)
                print "Assuming MJy/sr, the flux density is %f Jy" % (jansky)
            myrg.done()
        else:
            print "getvalue option not available outside of CASA"
    myia.close()
    if (len(returnValues) == 1):
        returnValues = returnValues[0]
    return(returnValues)

def computeITRFCorrection(padPosition, position):
    """
    Computes the corrections to make to absolute geocentric coordinates
    XYZ (pad position) from an offset in local coordinates (antenna position).
    padPosition: vector [X,Y,Z] geocentric coords
    position: antenna position in local coords (e.g. from ASDM_ANTENNA table)
    Returns:
    the corrections to apply as dX, dY, dZ
    """
    result = xyz2long(padPosition[0], padPosition[1], padPosition[2], verbose=False)
    if (len(result) == 2):
        lat, long = result
    else:
        lat, long, height = result
    phi = lat*math.pi/180.
    lam = math.atan2(padPosition[1], padPosition[0])
    itrf_correction = []
    itrf_correction.append(-np.sin(lam)*position[0] \
                           -np.sin(phi)*np.cos(lam)*position[1] + \
                            np.cos(phi)*np.cos(lam)*position[2] + \
                           padPosition[0])
    itrf_correction.append(+np.cos(lam)*position[0] \
                           -np.sin(phi)*np.sin(lam)*position[1] + \
                            np.cos(phi)*np.sin(lam)*position[2] + \
                           padPosition[1])
    itrf_correction.append(+np.cos(phi)*position[1] + \
                            np.sin(phi)*position[2] + padPosition[2])
    correction = np.array(itrf_correction) - np.array(padPosition)
    return correction

def compareTMCDB(asdm, xmlfile=None, threshold=0.0, verbose=False,
                 searchPriorPads=True, updates=3, csvfile='antennapos.csv', overwrite=False):
    """
    Gets the current pad and antenna position values from the TMCDB, then
    compares them to what is in the ASDM xml tables for your observation.
    For each antenna, if its observed pad matches what is in TMCDB, it
    compares the positions of both.  If they differ, it prints the gencal
    command that you need to run to fix your ASDM to the current positions
    in TMCDB, and writes it to a file (ASDM.antpos_gencal.txt).  It also
    writes a csvfile (antennapos.csv), suitable for the pipeline.
    Input:
    asdm: a single string (with optional wildcard characters), or a
          comma-delimited string, or a list of strings.  If any full uid name
          does not exist in the current directory, it will be exported.
          The uid names can have underscores or colons & slashes.
    xmlfile: optional, a file exported by ExportPositionModel.py
    threshold: value in mm, don't include antenna in gencal command if
               change<value
    searchPriorPads: if True, then if an antenna is no longer on the pad it
        had in the ASDM, then extract the final position it had on that pad
        during the duration it was on the pad that includes the date of ASDM.
    verbose: show full information and print a log file of messages
    updates: in verbose mode, the number of recent updates to show for each antenna/pad
    overwrite: if True, then overwrite any existing antennapos.csv, else append
    NOTE: Currently, this command must be run on osf-red (or possibly an STE).
          It could eventually be executable on the scops cluster.
    -Todd Hunter
    """
#    scriptDir = os.path.dirname(os.path.dirname(__file__))+'/scripts/R10.4_WORKING'
#    if (sys.path[0] != scriptDir):
#        sys.path.insert(0, scriptDir)
    if (not asdmLibraryAvailable):
        print "You cannot run this function on this machine because it lacks the ASDM python bindings library. Try osf-red or red-osf."
        return
        
    import tmcdbPlayer as tP  # requires import asdm, which does not work on all machines
    from PositionEditor import PositionEditor  # used by averageAntPosResults and compareTMCDB
    if (type(asdm) == str):
        if (asdm.find('*')>=0):
            files = glob.glob(asdm)
            asdms = []
            for asdm in files:
                if (asdm.find('.')<0):
                    asdms.append(asdm)
                    print "Will process ", asdm
        else:
            asdms = asdm.split(',')
    else:
        asdms = asdm
    tmcdbHistoryFile = 'All_position_history_%s.xml' % (getCurrentDate(delimiter='-'))
    if (not os.path.exists(tmcdbHistoryFile)):
        cmd = "ExportPositionModel.py -y -f %s" % (tmcdbHistoryFile)
        if verbose:
            mystring = "Running: %s" % (cmd)
            print mystring
        os.system(cmd)
    if overwrite:
        filemode = 'w'
    else:
        filemode = 'a'
    antennaposcsv = open(csvfile,filemode)
    if overwrite:
        antennaposcsv.write('name,antenna,xoff,yoff,zoff,comment\n')
    for asdm in asdms:
        asdm = asdm.rstrip("/")
        asdm = uidToUnderscores(asdm)
        if (not os.path.exists(asdm)):
            print "Could not find ASDM. Exporting it."
            os.system('asdmExport -m '+asdm)
            if (not os.path.exists(asdm+'/ASDM.xml')):
                print "Could not export ASDM"
                return
        startdate = getObservationStartDateFromASDM(asdm)[0]
        mystring = "ASDM observation %s started on %s" % (asdm,startdate)
        print mystring
        gencalFilename = asdm + '.antpos_gencal.txt'
        gencalfile = open(gencalFilename, 'w')
        if verbose:
            logfilename = asdm + '.compareTMCDB.log'
            logfile = open(logfilename,'w')
            logfile.write(mystring + '\n')
        if (xmlfile==None):
            if (asdmLibraryAvailable):
                xmlfile = "All_PositionModel_%d.xml" % (int(timeUtilities.time()))
                cmd = "ExportPositionModel.py -f %s" % (xmlfile)
                if verbose:
                    mystring = "Running: %s" % (cmd)
                    print mystring
                    logfile.write(mystring + '\n')
                os.system(cmd)
            else:
                print "ExportPositionModel.py not available yet on this machine. Looking for an .xml file in au directory."
                mypath = os.path.dirname(__file__)
                files = os.glob.glob(mypath+'/All_PositionModel_*.xml')
                if (len(files) < 1):
                    print "Cannot find a suitable .xml file."
                    return
                xmlfile = files[0]
                print "Found xml file = ", xmlfile
        elif (xmlfile.find('*') >= 0):
            files = glob.glob(xmlfile)
            if (len(files) < 1):
                print "Did not find an xml file"
                return
            xmlfile = files[0]
        p = PositionEditor()
        p.getTmcdbPositionModel(xmlfile)
        asdmPadInfo = readStationFromASDMKeyedByAntennaName(asdm)
        asdmAntennaInfo = readAntennaPositionFromASDM(asdm)  # keyed by antenna name
        antennas = sorted(asdmPadInfo.keys())
        parameterCorrection = []
        antennaCorrection = ''
        padNames = []
        # get current pad for each antenna (from antennaMoves.txt)
        t = tP.tmcdbPlayer(analysisUtilsDirectory=os.path.dirname(os.path.dirname(__file__)))
        moves = t.readAntennaMovesTxt(cvsup=False)
        for antenna in antennas:
            if verbose:
                print "\n%s:" % (antenna)
                logfile.write("\n%s:\n" % (antenna))
            currentAntennaPosition = p.getTmcdbAntennaPosition(antenna)
            padname = asdmPadInfo[antenna]['name']
            if (moves[antenna].pad[-1] != padname):
                startDateString = "never?"
                endDateString = "never?"
                asdmdate = getObservationStartDateFromASDM(asdm)[0].split()[0]
                for i in range(2,len(moves[antenna].pad)+1):
                    if (moves[antenna].pad[-i] == padname and moves[antenna].start[-i] < asdmdate
                        and moves[antenna].end[-i] > asdmdate):
                        endDateString = moves[antenna].end[-i]
                        startDateString = moves[antenna].start[-i]
                        break
                mystring = "Antenna %s is no longer on pad %s. It is on %s since %s." % (antenna,padname,moves[antenna].pad[-1], moves[antenna].start[-i+1])
                print mystring
                if verbose: logfile.write(mystring+'\n')
                mystring = "  It was on pad %s from %s to %s which includes the date of your ASDM." % (padname,startDateString,endDateString)
                print mystring
                if verbose: logfile.write(mystring+'\n')
                antennaMoved = True
                if (searchPriorPads):
                    if (endDateString.find('ever') > 0):
                        mystring = "Cannot continue with this antenna.  Are you sure your antennaMoves.txt file is up to date? You might need to run cvs update."
                        print mystring
                        if verbose: logfile.write(mystring+'\n')
                        continue
                    else:    
                        endDateString = subtractDays(endDateString)
                        xmlfile2 = "All_PositionModel_%s.xml" % (endDateString)
                        if (not os.path.exists(xmlfile2)):
                            cmd = "ExportPositionModel.py -f %s -t %s" % (xmlfile2,endDateString)
                            if verbose: print "Running: ", cmd
                            os.system(cmd)
                        p2 = PositionEditor()
                        p2.getTmcdbPositionModel(xmlfile2)
                        currentPadPosition = p2.getTmcdbPadPosition(padname)
                        currentAntennaPosition = p2.getTmcdbAntennaPosition(antenna)
                else:
                    mystring = "  Set searchPriorPads=True and re-run if you want to search for a correction for %s." % (padname)
                    print mystring
                    if verbose: logfile.write(mystring+'\n')
                    continue
            else:
                antennaMoved = False
                currentPadPosition = p.getTmcdbPadPosition(padname)
            padDiff = np.array([0,0,0])
            if (asdmPadInfo[antenna]['position'] != list(currentPadPosition)):
                padDiff = np.array(currentPadPosition) - np.array(asdmPadInfo[antenna]['position'])
                if (verbose):
                    print "*** Pad position for %s in ASDM does not match TMCDB!" % (padname)
                    print "   ASDM: %s   TMCDB: %s" % (str(asdmPadInfo[antenna]['position']), str(currentPadPosition))
                    print "   difference = %s" % (str(padDiff))
                    print "   Dates of (up to) %d most recent position updates for %s:" % (updates,padname)
                    logfile.write("*** Pad position for %s in ASDM does not match TMCDB!\n" % (padname))
                    logfile.write("   ASDM: %s   TMCDB: %s\n" % (str(asdmPadInfo[antenna]['position']), str(currentPadPosition)))
                    logfile.write("   difference = %s\n" % (str(padDiff)))
                    logfile.write("   Dates of (up to) %d most recent position updates for %s:\n" % (updates,padname))
                    mydict = readTMCDBVersionPadHistory(padname, tmcdbHistoryFile)
                    if (mydict is None):
                        print "No TMCDBVersionPadHistory found for pad %s" % (padname)
                    else:
                        minUpdates = np.min([updates,len(mydict.keys())])
                        for key in mydict.keys()[-minUpdates:]:
                            mystring = "   %d: %s" % (key, mydict[key])
                            print mystring
                            logfile.write(mystring+'\n')
            elif (verbose or antennaMoved):
                mystring = "  %s position in ASDM matches TMCDB: %s" % (padname,str(currentPadPosition))
                print mystring
                if verbose: logfile.write(mystring+'\n')
            antennaDiff = np.array([0,0,0])
            if (asdmAntennaInfo[antenna]['position'] != list(currentAntennaPosition)):
                antennaDiff = np.array(currentAntennaPosition) - np.array(asdmAntennaInfo[antenna]['position']) 
                if (verbose):
                    mystring =  "Antenna position for %s in ASDM does not match TMCDB!" % (antenna)
                    print mystring
                    logfile.write(mystring+'\n')
                    mystring = "   ENU difference = %s" % (str(antennaDiff))
                    print mystring
                    logfile.write(mystring+'\n')
                # need to convert from an offset in local coords to an offset in geocentric coords
                antennaDiff = np.array(computeITRFCorrection(currentPadPosition, antennaDiff))
                if (verbose):
                    mystring = "   XYZ difference = %s" % (str(antennaDiff))
                    print mystring
                    logfile.write(mystring+'\n')
                    mystring = "   ASDM:  %+.7f, %+.7f, %+.7f   TMCDB: %+.7f, %+.7f, %+.7f" % (asdmAntennaInfo[antenna]['position'][0],
                                                                                      asdmAntennaInfo[antenna]['position'][1],
                                                                                      asdmAntennaInfo[antenna]['position'][2],
                                                                                      currentAntennaPosition[0],
                                                                                      currentAntennaPosition[1],
                                                                                      currentAntennaPosition[2]
                                                                                      )
                    print mystring
                    logfile.write(mystring+'\n')
                    mystring = "   Dates of (up to) %d most recent position updates for %s:" % (updates,antenna)
                    print mystring
                    logfile.write(mystring+'\n')
                    mydict = readTMCDBVersionAntennaHistory(antenna, tmcdbHistoryFile)
                    if (mydict is None):
                        print "No TMCDBVersionAntennaHistory found for antenna %s" % (antenna)
                    else:
                        minUpdates = np.min([updates,len(mydict.keys())])
                        for key in mydict.keys()[-minUpdates:]:
                            mystring = "   %d: %s" % (key, mydict[key])
                            print mystring
                            logfile.write(mystring+'\n')
            elif (verbose or antennaMoved):
                mystring = "  %s position in ASDM matches TMCDB: %s" % (antenna,str(currentAntennaPosition))
                print mystring
                if verbose: logfile.write(mystring+'\n')
                
            totalDiff = padDiff + antennaDiff
            if (totalDiff[0] != 0 or totalDiff[1] != 0 or totalDiff[2] != 0):
                if (antennaCorrection != ''):
                    antennaCorrection += ','
                antennaCorrection += antenna
                parameterCorrection += list(totalDiff)
                padNames.append(padname)  # store this to put in a comment in gencal command
                
        if (antennaCorrection == ''):
            mystring = "No gencal necessary"
            print mystring
            gencalfile.write(mystring+'\n')
            if verbose: logfile.write(mystring+'\n')
        else:
            mystring = "\n  gencal(vis = '%s.ms'," % (asdm)
            print mystring
            if verbose: logfile.write(mystring+'\n')
            gencalfile.write(mystring+'\n')
            mystring = "    caltable = '%s.ms.antpos'," % (asdm)
            print mystring
            if verbose: logfile.write(mystring+'\n')
            gencalfile.write(mystring+'\n')
            mystring = "    caltype = 'antpos',"
            print mystring
            gencalfile.write(mystring+'\n')
            prefix = "    parameter = ["
            antennaCorrection2 = ''
            for pc in range(0,len(parameterCorrection),3):
                change = np.linalg.norm(parameterCorrection[pc:pc+3]) * 1000 # convert to mm
                if (change >= threshold):
                    lastCorrection = pc
            for pc in range(0,len(parameterCorrection),3):
                ant = antennaCorrection.split(',')[pc/3]
                if (pc != lastCorrection):
                    comma = ','
                else:
                    comma = '],'
                change = np.linalg.norm(parameterCorrection[pc:pc+3]) * 1000 # convert to mm
                if (change >= threshold):
                    if (antennaCorrection2 != ''):
                        antennaCorrection2 += ','
                    antennaCorrection2 += ant
                    mystring = "%s%+.7f, %+.7f, %+.7f%s # %s on %s change=%.3fmm" % (prefix,parameterCorrection[pc],
                                                                              parameterCorrection[pc+1],
                                                  parameterCorrection[pc+2], comma, ant, padNames[pc/3], change)
                    print mystring
                    if verbose: logfile.write(mystring+'\n')
                    gencalfile.write(mystring+'\n')
                    antennaposcsv.write('%s.ms,%s,%+.7f,%+.7f,%+.7f,\n' % (asdm,ant,parameterCorrection[pc],parameterCorrection[pc+1],parameterCorrection[pc+2]))
                prefix = "                 "
            mystring = "    antenna = '%s')" % (antennaCorrection2)
            print mystring
            gencalfile.write(mystring+'\n')
            if verbose: logfile.write(mystring+'\n')
        gencalfile.close()
        antennaposcsv.close()
        print "gencal command left in %s" % (gencalFilename)
        print "also wrote %s" % (csvfile)
        if verbose:
            logfile.close()
            print "Logfile left in %s" % (logfilename)

def readTMCDBVersionAntennaHistory(antenna, historyfile=''):
    """
    Returns a dictionary of timestamps keyed by version number.
    The format is YYYY-MM-DDTHH:MM:SS.SSS-ZZ:00  where ZZ=timezone offset
    Must be run on osf-red.
    antenna: the antenna name string
    -Todd Hunter
    """
    if (os.getenv('HOSTNAME').find('osf-red') < 0 and os.getenv('HOSTNAME').find('red-osf') < 0):
        print "This function must be run on red-osf or osf-red.aiv.alma.cl."
        return
    if (historyfile == ''):
        posdir = '/users/ahales/trend_analysis/position_models/'
        historyfile = posdir + 'All_position_History.xml'
    xml = minidom.parse(historyfile)
    rowlist = xml.getElementsByTagName("AntennaPositionsHistory")
    mydict = {}
    for rownode in rowlist:
        if (rownode.getAttribute("antenna") == antenna):
            info = rownode.getElementsByTagName("HistoryRecord")
            for i in range(len(info)):
                version = int(info[i].getAttribute("version"))
                timestamp = str(info[i].getAttribute("timestamp"))
                mydict[version] = timestamp
    return(mydict)
    
def readTMCDBVersionPadHistory(pad, historyfile=''):
    """
    Returns a dictionary of timestamps keyed by version number.
    The format is YYYY-MM-DDTHH:MM:SS.SSS-ZZ:00  where ZZ=timezone offset
    Must be run on osf-red.
    pad: the pad name string
    -Todd Hunter
    """
    if (os.getenv('HOSTNAME').find('osf-red') < 0 and os.getenv('HOSTNAME').find('red-osf') < 0):
        print "This function must be run on red-osf or osf-red.aiv.alma.cl."
        return
    if (historyfile == ''):
        posdir = '/users/ahales/trend_analysis/position_models/'
        historyfile = posdir + 'All_position_History.xml'
    xml = minidom.parse(historyfile)
    rowlist = xml.getElementsByTagName("PadPositionsHistory")
    mydict = {}
    for rownode in rowlist:
        if (rownode.getAttribute("antenna") == pad): # xml file also uses 'antenna' key word for pad
            info = rownode.getElementsByTagName("HistoryRecord")
            for i in range(len(info)):
                version = int(info[i].getAttribute("version"))
                timestamp = str(info[i].getAttribute("timestamp"))
                mydict[version] = timestamp
    return(mydict)
    
def antposcorrmm(parameter=[], antenna='', sort='', correctionString=''):
    """
    Converts a list of antenna position corrections into human-readable
    millimeters.
    sort='name': will sort the output by antenna name
    sort='magnitude': will sort the output by the magnitude of the correction
    correctionString:  if specified, parse this string from es.correctMyAntennaPositions
            to get the values of parameter and antenna
    Todd Hunter
    """
    if (correctionString != ''):
        tokens = correctionString.split('\n')
        for token in tokens:
            if (token.find("antenna = ") >= 0):
                antenna = token.split()[2].strip(",").strip("'")
            elif (token.find("parameter = ") >= 0):
                parameter = token.strip("[").strip("]").split(",")[2:]
                parameter = [float(p.strip(')').strip(']')) for p in parameter]
    if (type(parameter) == list):
        if (len(parameter) < 3):
            print "Invalid parameter"
            return
    elif (type(parameter) == str):
        strings = parameter.split(',')
        parameter = map(float, strings)
    else:
        print "Parameter must be a list of floats, or a string list of floats"
        return
    if (type(antenna) == list):
        if (len(antenna) < len(parameter)/3):
            print "Mismatch between number of parameters (%d) and antennas (%d)" % (len(parameter), len(antenna))
            return
    elif (type(antenna) == str):
        if (antenna != ''):
            antstrings = antenna.split(',')
            if (len(antstrings) < len(parameter)/3):
                print "Mismatch between number of parameters (%d) and antennas (%d)" % (len(parameter), len(antstrings))
                return
        elif (sort != ''):
            print "You cannot sort if no antenna list is provided."
            return
    else:
        print "If specified, antenna must be a list of strings, or a string list of strings"
        return
    parameter = 1000*np.array(parameter)  # convert to mm
    totals = []
    if (antenna != ''):
        print "Antenna  X      Y      Z       Total"
    else:
        print "  X      Y      Z       Total"

    if (sort.find('name')>=0 or sort.find('antenna')>=0):
        sortedAntennas = []
        for s in antstrings:
            sortedAntennas.append(s)
        sortedAntennas.sort()
    elif (sort.find('mag')>=0):
        sortedAntennas = []
        sortedTotals = []
        for i in range(len(parameter)/3):
            total = (parameter[i*3]**2+parameter[i*3+1]**2+parameter[i*3+2]**2)**0.5
            sortedTotals.append(total)
        indices = np.argsort(sortedTotals)
        sortedAntennas = list(np.array(antstrings)[indices])
    elif (sort != ''):
        print "Unrecognized sorting scheme: ", sort
        sort = ''
    for j in range(len(parameter)/3):
        if (sort != ''):
            i = antstrings.index(sortedAntennas[j])
        else:
            i = j
        total=(parameter[i*3]**2+parameter[i*3+1]**2+parameter[i*3+2]**2)**0.5
        totals.append(total)
        outline = ''
        if (antenna != ''):
            outline += antstrings[i] + "  " # antstrings[i] + "  "
        outline += "%+.3f %+.3f %+.3f     %.3f mm" % (parameter[i*3],
                       parameter[i*3+1], parameter[i*3+2], total)
        print outline
    print "Abs(min), Abs(max) = %.3f/%.3f mm,  Median = %.3f mm   st.dev = %.3f mm" % (np.min(np.abs(totals)),np.max(np.abs(totals)),np.median(totals),np.std(totals))

def locateSciencePath(pathEnding):
    """
    This method will locate any file in the active analysisUtils
    "science" subdirectory tree. You need to call it with the
    trailing part of the path beyond the ~/AIV/science/ directory.
    e.g. 'PadData/almaAntPos.txt'
    -Todd Hunter
    """
    tokens = __file__.split('/')
    mypath = ''
    for i in range(len(tokens)-len(pathEnding.split('/'))):
        mypath += tokens[i] + '/'
    mypath += pathEnding
    return(mypath)
        
def getMostRecentMove(antenna, history=1, before=None):
    """
    Searches the antennaMoves.txt file for the most recent move(s) of the
    specified antenna name (e.g. 'DV01'), and returns a single string of 
    results.

    antenna: name string ('DV01')
    history: maximum number of moves to return
    before: date to search before 'YYYY-MM-DD' (default = today)
    
    Todd Hunter
    """
    mypath = locateSciencePath('PadData/antennaMoves.txt')
    if (before!=None and before!=''):
        result = os.popen('grep %s %s | tail -%d' % (antenna,mypath,100)).read()[:-1]
        results = result.split('\n')
        (y,m,d) = before.split('-')
        beforedate = datetime.date.today().replace(int(y),int(m),int(d))
        drop = 0
        # determine how many moves happened after the specified 'before' date
        for d in range(len(results)-1,-1,-1):
            datestring = results[d].split()[0]
            date = datestring.split('T')[0]
            (y,m,d) = date.split('-')
            obsdate = datetime.date.today().replace(int(y),int(m),int(d))
            if (obsdate > beforedate):
                drop += 1
        result = ''
        start = len(results)-drop-history
        if (start < 0):
            start = 0
        # reassemble the response
        for d in range(start, len(results)-drop):
            result += results[d] + '\n'
    else:
        result = os.popen('grep %s %s | tail -%d' % (antenna,mypath,history)).read()[:-1]
    return(result)

def grepAntennaMoves(antenna):
    """
    Searches the antennaMoves.txt file for an antenna name and prints the results.
    -Todd Hunter
    """
    mypath = locateSciencePath('PadData/antennaMoves.txt')
    print grep(mypath,antenna)[0]

def mostRecentMoves(vis, history=1, relativeToToday=False):
    """
    Reads the antenna names from an ms and checks the antennaMoves.txt file 
    for the most recent move with respect to today (not the observed date), 
    then sorts for most recent first.  Returns the antenna names in the
    order of the longest time since its previous move coming first.
    
    -Todd Hunter
    """
    names = getAntennaNames(vis)
    me = createCasaTool(metool)
    if (relativeToToday):
        mjdsec = me.epoch('mjd','today')['m0']['value'] * 86400
        now = "today"
    else:
        mjdsec = getObservationStart(vis)
        now = "this observation"
    obsdateString = mjdToUT(mjdsec/86400.)
    Y,M,D = obsdateString.split()[0].split('-')
    obsdate = datetime.date.today().replace(int(Y),int(M),int(D))
    before = obsdateString.split()[0]
    moves = []
    for antenna in names:
        moves.append(getMostRecentMove(antenna,history,before=before))
    m = sorted(moves,reverse=True)
    print "%s = Observation start" % (obsdateString)
    print "YYYY-MM-DD HH:MM Name From To"
    for move in m:
        if (len(move) > 0):
#            print "move = %s." % (move[:-1])
            y,m,d = move.split('T')[0].split('-')
            movedate = datetime.date.today().replace(int(y),int(m),int(d))
            diff = obsdate - movedate
            if (diff.days < 0):
                print "%-31s  %5d days after %s" % (move[:-1],abs(diff.days),now)
            else:
                print "%-31s  %5d days before %s" % (move[:-1],abs(diff.days),now)
    return ([move.split()[1] for move in sorted(moves)])


def checkAntennaPositionFiles(historyLength=6, antenna=''):
    """
    Shows how recently the antenna position files have been updated
    by displaying the most recent entries.    It finds these files
    (antennaMoves.txt and almaAntPos.txt) in the same directory tree
    as your analysisUtils was found.
    Optional: supply an antenna (or pad) name, and the antenna moves output 
              will be restricted to that antenna (or pad).
    -- Todd Hunter
    """
    mypath = locateSciencePath('PadData/antennaMoves.txt')
    print "Recent antenna moves (assumed to be in chronological order):"
    if (antenna == ''):
        os.system('tail -%d %s' % (historyLength,mypath))
    else:
        os.system('grep %s %s | tail -%d' % (antenna,mypath,historyLength))
    mypath = locateSciencePath('PadData/almaAntPos.txt')
    dates = []
    print "Recent baseline tracks (sorted by measTime):"
    for c in commands.getoutput('grep measTime %s' % mypath).split('\n'):
        dates.append(c.split()[1])
    dates.sort()
    for c in dates[-historyLength:]:
        print c

def sensitivity(freq, bandwidth, etime, elevation=None, pwv=None, 
#                telescope=None, diam=None, nant=None, 
                antennalist=None, doimnoise=None, mode='tsys-atm',
                integration=None, debug=None, t_amb=270, airmass=None,
                tau=None, tsys_only=False, t_rx=None, h0=1.0, 
                tau0=None, verbose=True):
    """
    This is a wrapper for simutil.sensitivity, for those who don't know 
    about it.  For ALMA, it also calculates the Tsys.
    -Todd Hunter

    Parameters:
    freq:      value in GHz, or string with units
    bandwidth: value in GHz, or string with units
    time:      string with units of seconds
    elevation: value in degrees, or string with units
    airmass:   airmass (alternative to specifying the elevation)
        (if neither elevation nor airmass is specified, then zenith is used)
    pwv:         value in mm
    antennalist: telescope antenna configuration file
    domimnoise:  default is None
    integration: length of individual integration (string with units)
    debug: T/F
    mode:      'tsys-atm' (default) or 'tsys-manual'
         for tsys-atm, also specify pwv
         for tsys-manual, also specify tau0 & t_sky (as t_atmosphere, e.g. 260K)
    tau:       opacity to use (instead of the atm model result)
    tau0:      zenith opacity to use (instead of the atm model result)
    t_amb:     physical temperature of atmosphere in K
    tsys_only: T/F, T=only compute and return the Tsys, not the sensitivity
    t_rx:      receiver temperature to use (instead of tabulated value) to predict Tsys
          WARNING: this is *not* used in the sensitivity calculation (in Jansky)
    h0:        water vapor scale height in km (default=1.0)

    Examples:
    au.sensitivity('660GHz', '3.75GHz', '60s', elevation='80deg', pwv=0.472,
            antennalist = 'alma_cycle1_2.cfg')
    au.sensitivity('22GHz', '1.0GHz', '60s', elevation='80deg', pwv=5,
            antennalist= 'vla.a.cfg')
    """
    # Check casa version
    casaVersionString = casalog.version()
    if (casadef.casa_version < '3.4' and not tsys_only):
        print "This function does not yet work in %s due to the cal table format" % casaVersionString
        print "change, unless tsys_only=True."
        return
    if (tau is not None and tau0 is not None):
        print "You can only specify one of: tau and tau0 (zenith)"
        return
    if (pwv==None and mode != 'tsys-manual'):
        print "You need to specify a PWV."
        return
    if (antennalist is None):
        print "For antennalist, you need to specify 'alma' or a configuration file, like alma.cycle1.1 or sma.compact"
        return
    if (antennalist.lower() == 'alma' and tsys_only == False):
        print "antennalist='alma' is only supported if tsys_only=True"
        print "Otherwise, give a real configuration file, like alma.cycle1.1"
        return
    if (elevation is None and airmass is None):
        elevation = 90
    if (elevation is not None):
        elevation = float(str(elevation).split('deg')[0])
        if (airmass is not None):
            print "Ignoring airmass because elevation was specified"
        airmass = 1/np.sin(elevation*np.pi/180.)
    else:
        if (airmass < 1 or airmass is None):
            print "Invalid airmass"
            return
        elevation = 180*math.asin(np.float(1)/airmass)/np.pi
    if verbose:
        print "elevation = %.2f, airmass = %.3f" % (elevation,airmass)
    elevation = '%fdeg' % elevation
    if (antennalist is not None and not tsys_only):
        if (antennalist.find('.cfg') < 0):
            antennalist += '.cfg'
        if (os.path.exists(antennalist) == False):
            repotable=os.getenv("CASAPATH").split()[0]+"/data/alma/simmos/"
            antennalist = repotable + antennalist
    elif not tsys_only:
        print "You need to provide an antennalist parameter, unless tsys_only=True"
        return
    telescope=None
    diam=None
    nant=None
    su = simutil.simutil()
    if (type(freq) == float):
        freq = '%fGHz' % freq
    elif (type(freq) == int):
        freq = '%dGHz' % freq

    if (type(bandwidth) == float):
        bandwidthGHz = bandwidth
        bandwidth = '%fGHz' % bandwidth
    elif (type(bandwidth) == int):
        bandwidthGHz = bandwidth
        bandwidth = '%dGHz' % bandwidth
    else:
        if (bandwidth.find('GHz') >= 0):
            bandwidthGHz = float(bandwidth.split('GHz')[0])
        elif (bandwidth.find('MHz') >= 0):
            bandwidthGHz = float(bandwidth.split('MHz')[0])*1e-3
        elif (bandwidth.find('kHz') >= 0):
            bandwidthGHz = float(bandwidth.split('kHz')[0])*1e-6
        elif (bandwidth.find('Hz') >= 0):
            bandwidthGHz = float(bandwidth.split('Hz')[0])*1e-9
        else:
            bandwidthGHz = float(bandwidth)
    casaVersion = int(casadef.subversion_revision)
    if (tsys_only == False):
        if (casaVersion >= 20186):
            jansky = simutil.simutil.sensitivity(su, freq, bandwidth, etime, elevation,
                                             pwv, telescope, diam, nant,
                                             antennalist, doimnoise, integration,
                                             debug, mode, tau0, t_amb)
        else:
            if (tau0 is not None or mode != 'tsys-atm'):
                print "The tau0 and mode options only work for casa version >= 20186"
                return
            jansky = simutil.simutil.sensitivity(su, freq, bandwidth, etime, elevation,
                                             pwv, telescope, diam, nant,
                                             antennalist, doimnoise, integration,
                                             debug)

    if (antennalist is None):
        thisIsAlma = False
    else:
        thisIsAlma = (antennalist.lower().split('/')[-1].find('alma') >= 0) \
            or (antennalist.lower().split('/')[-1].find('aca') >= 0)
    # Compute wavelength in microns
    if (freq.find('GHz') >= 0):
        wavelength = 1e4*c/(float(freq.split('GHz')[0])*1e9)
    elif (freq.find('MHz') >= 0):
        wavelength = 1e4*c/(float(freq.split('MHz')[0])*1e6)
    elif (freq.find('kHz') >= 0):
        wavelength = 1e4*c/(float(freq.split('kHz')[0])*1e3)
    elif (freq.find('Hz') >= 0):
        wavelength = 1e4*c/float(freq.split('Hz')[0])
    else:
        wavelength = 1e4*c/(float(freq)*1e9)
        freq = '%sGHz' % (freq)

    frequencyGHz = 1e-5*c/wavelength
    t_rx_casa = None
    if (thisIsAlma and t_rx==None):
        telescope = "ALMA"
        su.telescopename = telescope  # prevents crash of noisetemp()
        (eta_p, eta_s, eta_b, eta_t, eta_q, t_rx) = simutil.simutil.noisetemp(su, telescope, freq, diam)
        if verbose:
            print "Frequency: %f GHz    Bandwidth: %.9f GHz" % (frequencyGHz,bandwidthGHz)
            if antennalist != 'alma':
                nant = readPadConfigurationFile(antennalist)[3]
                print "Number of antennas:  %d" % (nant)
            if (wavelength > 0):
                microns = (-wavelength**2*np.log(eta_p)/(16*np.pi**2))**0.5
                print "Antenna Ruze efficiency:          eta_p=%.4f (%.1f um rms)" % (eta_p,microns)
            else:
                print "Antenna Ruze efficiency:          eta_p=%.4f" % (eta_p)
            print "Forward efficiency:               eta_s=%.4f" % (eta_s)
            print "Subreflector blockage efficiency: eta_b=%.4f" % (eta_b)
            print "Illumination efficiency:          eta_t=%.4f" % (eta_t)
            print "Aperture efficiency:              eta_p*s*b*t = eta_a=%.4f" % (eta_p*eta_s*eta_b*eta_t)
            print "Correlator quantum efficiency:    eta_q=%.4f" % (eta_q)
        t_rx_casa = t_rx
        if (frequencyGHz > 600):
            g = 1
            if (frequencyGHz > 750):
                if (t_rx > 300):
                    t_rx *= 0.5
            elif (t_rx > 160):
                t_rx *= 0.5
        else:
            g = 0
        if verbose:
            print "Using tabulated ALMA receiver temperature: T_rx = %.1fK" % (t_rx)
    else:
        eta_s = 0.95
        if (frequencyGHz > 600):
            g = 1
        else:
            g = 0
        if (t_rx is not None):
            print "Using user-specified receiver temperature: T_rx = %.1fK" % (t_rx)
        else:
            (eta_p, eta_s, eta_b, eta_t, eta_q, t_rx) = simutil.simutil.noisetemp(su, telescope, freq, diam)
            if verbose:
                print "Using tabulated receiver temperature in CASA: T_rx = %.1fK" % (t_rx)

    if (thisIsAlma or tsys_only==True):
        elevationDegrees = float(elevation.split('deg')[0])
        airmass = 1.0/math.sin(elevationDegrees*math.pi/180.)
        if (mode != 'tsys-manual'):
            my_tau, my_t_sky, my_t_sky_RJ = estimateALMAOpacity(pwv,frequencyGHz,airmass,h0,verbose=False,T=t_amb)
            if verbose:
                print "Computed tau=%f, tau0=%f, t_sky=%f (airmass=%f)" % (my_tau, my_tau/airmass, 
                                                                   my_t_sky,airmass)
        if (tau is None and tau0 is None):
            tau = my_tau
            tau0 = my_tau/airmass
        elif (tau is None):
            tau = tau0*airmass
        else:
            tau0 = tau/airmass
        if (mode != 'tsys-manual'):
            t_sky = my_t_sky
            t_sky_RJ = my_t_sky_RJ
        else:
            t_sky = t_amb*(1-np.exp(-tau))
            t_sky_RJ = 0
        if verbose:
            print "   Using tau=%f" % tau
            print "         tau0=%f" % tau0
            print "         t_amb=%f" % t_amb
            print "         t_sky=%f" % t_sky
            print "             g=%f" % g
            print "         eta_s=%f" % eta_s
            print "          t_rx=%f" % (t_rx)
        tsys = (1+g)*(t_rx + t_sky*eta_s + (1-eta_s)*t_amb) / \
                   (eta_s*np.exp(-tau*airmass))
        if verbose:
            if (t_sky_RJ == 0):
                print "Tsys_correct = %.2f K,  Tsky = %.2f K" % (tsys, t_sky)
            else:
                print "Tsys_correct = %.2f K,  Tsky = %.2f K (Rayleigh-Jean = %.2f K)" % (tsys, t_sky, t_sky_RJ)
        if (t_rx_casa is not None):
            tsys_casa = (t_rx_casa + t_sky*eta_s + (1-eta_s)*t_amb) / \
                        (eta_s*np.exp(-tau*airmass))
            tsys_casa2 = (t_rx_casa) / \
                         (eta_s*np.exp(-tau*airmass))
            if (casaVersion < 20000):
                print "Tsys_casa3.4 = %.2f K,  Tsky = %.2f K" % (tsys_casa, t_sky)
                print "Ratio (Tsys_correct/Tsys_casa) = %f" % (tsys /tsys_casa)

    if (tsys_only == False):
        if verbose:
            if (jansky > 0.1):
                print "Sensitivity = %g Jy" % (jansky)
            elif (jansky > 1e-4):
                print "Sensitivity = %g mJy" % (jansky*1000)
            elif (jansky > 1e-7):
                print "Sensitivity = %g uJy" % (jansky*1000000)
            else:
                print "Sensitivity = %g nJy" % (jansky*1000000000)
        return(jansky)
    else:
        return(tsys)

def testAtmosphere(temperature=270, altitude=5059, pressure=563, humidity=20, pwv=1.0, 
                   h0=1.0, airmass=1.0, dP=1.1, dPm=5.0):
    """
    Tests whether the fix inserted for ICT-7997 / CAS-9215 is in the current CASA in use.
    dP = 1.1 # pressure step factor unitless
    -Todd Hunter
    """
    latitudeClass = TROPICAL
    myqa = createCasaTool(qatool)
    numchan = 2
    chansep = 0.004 # GHz
    reffreq = 100.472# GHz
    fCenter = create_casa_quantity(myqa,reffreq,'GHz')
    fResolution = create_casa_quantity(myqa,chansep,'GHz')
    fWidth = create_casa_quantity(myqa,numchan*chansep,'GHz')
    dP = create_casa_quantity(myqa, dP,'mbar')
    at.initAtmProfile(humidity=humidity,temperature=create_casa_quantity(myqa,temperature,"K"),
                      altitude=create_casa_quantity(myqa,altitude,"m"),
                      pressure=create_casa_quantity(myqa,pressure,'mbar'),
                      h0=create_casa_quantity(myqa,h0,"km"),
                      atmType=latitudeClass, dP=dP, dPm=dPm)
    nbands = 1
    at.initSpectralWindow(nbands,fCenter,fWidth,fResolution)
    at.setUserWH2O(create_casa_quantity(myqa,pwv,'mm'))
    dry, wet, TebbSky, rf, cs = getAtmDetails(at)
    opacity = airmass*(wet+dry)
    transmission = np.exp(-opacity)*100
    TebbSky *= (1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))
    change = 100*abs(TebbSky[1] - TebbSky[0])/ TebbSky[0]
    if (change > 0.1):
        print "Failed: change=%f%% (should be 0.025%%)" % (change)
    else:
        print "Passed: change=%f%%" % (change)

def printNumberOfAtmosphericLayers(result):
    """
    Takes the list of strings output by at.initAtmProfile, and prints the 
    third from last, along with the altitude of the site.
    """
    altitude = ''
    lines = result.split('\n')
    for r in lines:
        if r.find('alti:') >= 0:
            altitude = r.split('alti:')[1].split()[0]
    # the 3rd from the end contains the words "Built atmospheric profile"
    print lines[-3][:-1] + ' for altitude %s m.' % (altitude )

def translateLatitudeClass(latitudeClass):
    """
    Translates atmosphere type from string to integer:
    'tropical' -> 1, 'midLatitudeWinter' -> 2, 'midLatitudeSummer' -> 3
    """
    if (latitudeClass is None):
        latitudeClass = TROPICAL
    elif (latitudeClass == 'tropical'):
        latitudeClass = TROPICAL
    elif (latitudeClass == 'midLatitudeWinter'):
        latitudeClass = MID_LATITUDE_WINTER
    elif (latitudeClass == 'midLatitudeSummer'):
        latitudeClass = MID_LATITUDE_SUMMER
    else:
        print 'Unrecognized latitude class. Must be one of: tropical, midLatitudeWinter, midLatitudeSummer '
        latitudeClass = None
    return latitudeClass
    
def plotAtmosphere(vis=None, spw=-1, scan=0, intent='OBSERVE_TARGET',
                   frequency=[0,1000],
                   pwv=None, bandwidth=None,telescope='ALMA',
                   temperature=None, altitude=None, latitudeClass=None,
                   pressure=None, humidity=None, numchan=1000, airmass=1.0,
                   elevation=0, plotfile='', plotrange=None, 
                   quantity='transmissionPercent', h0=None,
                   drawRectangles=[], drawVerticalBars = [], overlay=False,
                   fontsize=12, showgrid=False, linewidth=[1,1,1],
                   color=['b','b','b'], linestyle=['-','--',':'], 
                   drawWVR=False, verbose=False, outfile='', 
                   delimiter=' ', showplot=True, Trx=100.0, Feff=0.99, 
                   SBGain=0.99, Tamb=270.0, marker=['','',''], mymsmd=None,
                   dP=5.0, dPm=1.1, maxAltitude=60., resampleChan=0,
                   window=None):
    """
    Simple plotter of atmospheric transmission. You can enter either:
    a) vis ( + spw + scan)
    b) frequency
    frequency in GHz (either a single value, or a tuple for the range)
    vis: if specified, then use the specified spw (or first with specified intent)
    spw: integer or string
    scan: if specified (along with vis), then read the elevation for this scan
          if not specified, then use the first scan with specified intent
    numchan: this sets the resolution of the spectrum (if vis+spw is not given)
    pwv: in mm
    plotfile: if specified, then write a plot file; if True, use <vis>+'atm.png'
    verbose: if True, then print the spw and scan chosen
    bandwidth: in GHz (only used if frequency is a single value)
    temperature: in K
    altitude: in m
    latitudeClass: 'tropical', 'midLatitudeWinter'(default), or 'midLatitudeSummer'
    pressure: in mbar
    humidity: in percentage
    elevation: in degrees
    plotrange: for y axis, e.g. [0,100]
    telescope: if not '', then apply nominal values for 'ALMA' or 'EVLA' (ignored if vis is set)
    quantity: 'transmission', 'transmissionPercent', 'opacity', 'tsky', or 'tsys'
    h0: scale height of H2O in km (default is 1.0km for ALMA, 2.0km for others)
    dP: pressure step, has units of pressure (mb)
    dPm: pressure step factor (unitless) called PstepFact in TelCal
    drawRectangles: e.g. ([[x0,x1],[x2,x3],...])
    drawVerticalBars: e.g. ([x0,x1,...])
    overlay: if True, the show wet component, dry component and their sum (transmission or opacity only)
    fontsize: of tick labels and axis labels
    showgrid: if True, show dotted lines on major ticks
    linewidth: list of linewidths for each component: [sum, dry, wet]
    color: list of pylab colors for each component 
    marker: list of pylab marker for each component
    linestyle: list of pylab linestyles for each component
    outfile: if specified, then write an ASCII-format file with columns:
       freq, dryOpacity, wetOpacity, totalOpacity, transmission, Tsky
       (units of transmission are set by the quantity parameter)
    delimiter: the character to use as delimited in outfile
    showplot: if False, then do not show the plot
    Trx, Feff, SBGain, Tamb: values to use for computing Tsys.
    resampleChan: if specified, and quantity='tsky', then resample to this 
       number of channels using np.interp
    Note: uses the global physical constants: h and k
    --Todd Hunter
    """
    if (plotfile != '' and not showplot):
        print "if plotfile is set, then showplot must be True."
        return
    if (vis is not None):
        if type(vis) != str:
            print "First argument is vis, which must be a string."
            print "Frequency ranges are set with frequency=[211,275]"
            return
        if (not os.path.exists(vis)):
            print "Could not find measurement set"
            return
        needToClose = False
        if mymsmd is None:
            mymsmd = createCasaTool(msmdtool)
            if verbose: print "opening mymsmd"
            needToClose = True
            mymsmd.open(vis)
        scan = int(scan)
        spw = int(spw)
        scans = mymsmd.scannumbers()
        if (scan < 1 or spw < 0):
            if (intent not in mymsmd.intents()):
                if (intent not in [i.split('#')[0] for i in mymsmd.intents()]):
                    if (intent not in [i.split('#')[0].split('_')[1] for i in mymsmd.intents()]):
                        print "No scans with intent = ", intent
                        if needToClose: mymsmd.close()
                        return
        if (scan < 1):
            scans = mymsmd.scansforintent('*'+intent+'*')
            scan = scans[0]
            if verbose: print "Chose scan ", scan
        elif (scan not in scans):
            print "Scan %d not found. Available = " % (scan), scans
            if needToClose: mymsmd.close()
            return
        if verbose: print "running msmd.spwsforintent"
        spws = mymsmd.spwsforintent('*')
        telescope = mymsmd.observatorynames()[0]
        if (spw < 0):
            spws = mymsmd.spwsforintent('*'+intent+'*')
            if (telescope.find('ALMA') >=0):
                spws = np.intersect1d(spws,mymsmd.almaspws(tdm=True,fdm=True))
            if (len(spws) < 1):
                spws = mymsmd.spwsforscan(scan)
                spw = spws[-1]
            else:
                spw = spws[0]
            if verbose: print "Chose spw ", spw
        elif (spw not in spws):
            print "Spw %d not found. Available = " % (spw), spws
            if needToClose: mymsmd.close()
            return
        freqs = mymsmd.chanfreqs(spw)*1e-9
        numchan = len(freqs)
        frequency = [np.min(freqs), np.max(freqs)]
        pwv, stdev = getMedianPWV(vis)
        field = mymsmd.fieldsforscan(scan)[0]
        mjd = np.mean(mymsmd.timesforscan(scan))/86400.
        if verbose: print "running getWeather"
        mydict = getWeather(vis, scan=scan, mymsmd=mymsmd)
        if needToClose:
            if verbose: print "closing msmd"
            mymsmd.close()
        elevation = mydict[0]['elevation']
        humidity = mydict[0]['humidity']
        temperature = celsiusToKelvin(mydict[0]['temperature'])
        pressure = mydict[0]['pressure']
    if (elevation > 0):
        airmass = 1/np.sin(elevation*np.pi/180.)
    else:
        if (airmass < 1):
            print "Invalid airmass"
            return
        elevation = 180*math.asin(1/airmass)/np.pi
    latitudeClass = translateLatitudeClass(latitudeClass)
    if latitudeClass is None:
        return

    # Apply default weather conditions, if not specified
    if (telescope.find('ALMA') >= 0):
        if (temperature is None or temperature < 200):
            temperature_default = 270
            if temperature is not None:
                print "Temperature value from getWeather is odd (%s), using ALMA default of %.0fK" % (str(temperature),temperature_default)
            temperature = temperature_default
        if (altitude is None):
            altitude = 5059
        if (pressure is None or pressure < 450):
            pressure_default = 563
            if pressure is not None:
                print "Pressure value from getWeather is odd (%f), using ALMA default of %.0fmb" % (pressure, pressure_default)
            pressure = pressure_default
        if (humidity is None or humidity < 0):
            humidity_default = 20
            if humidity is not None:
                print "Humidity value from getWeather is odd (negative), using ALMA default of %.0f percent" % (humidity_default)
            humidity = humidity_default
        if (pwv is None):
            pwv = 1.0
        if (h0 is None):
            h0 = 1.0
    elif (telescope.find('VLA') >= 0):
        if (temperature is None):
            temperature = 280
        if (altitude is None):
            altitude = 2124
        if (pressure is None):
            pressure = 785.5
        if (humidity is None):
            humidity = 20
        if (pwv is None):
            pwv = 5.0
        if (h0 is None):
            h0 = 2.0
    elif (telescope.find('SMA') >= 0):
        latitudeClass = TROPICAL
        if (temperature is None):
            temperature = 280
        if (altitude is None):
            altitude = 4072
        if (pressure is None):
            pressure = 629.5
        if (humidity is None):
            humidity = 20
        if (pwv is None):
            pwv = 1.0
        if (h0 is None):
            h0 = 2.0
    else:
        if (temperature is None or altitude==None or pressure==None or humidity is None):
            print "telescope = ", telescope
            print "If telescope is not specified, then you must specify pwv, temperature,"
            print " altitude, barometric pressure and relative humidity."
            return
        if (h0 is None):
            h0 = 2.0

    if (type(frequency) == list):
        frequencyRange = frequency
    elif (bandwidth>0):
        if (numchan > 1):
            frequencyRange = [frequency-0.5*bandwidth, frequency+0.5*bandwidth]
        else:
            frequencyRange = [frequency]
    else:
        print "Bandwidth must be non-zero if frequency is a single value"
        return

    if showplot:
        pb.clf()
        desc = pb.subplot(111)

    reffreq = np.mean(frequencyRange)
    if type(numchan) != list:
        numchans = [numchan]
    else:
        numchans = numchan[:]

    # The following 'for' loop was used to debug the 1-channel offset problem
    # and I left it in place for convenience.
    for colorIndex,numchan in enumerate(numchans):
        chansep = (np.max(frequencyRange)-np.min(frequencyRange))/(float(numchan))
        nbands = 1
        if (numchan > 1):
            freqs = np.arange(frequencyRange[0], frequencyRange[1], chansep)
        else:
            freqs = frequencyRange

        myqa = createCasaTool(qatool)
        fCenter = create_casa_quantity(myqa,reffreq,'GHz')
        if (numchan > 1):
            fResolution = create_casa_quantity(myqa,chansep,'GHz')
            print "Set channel resolution to %f MHz" % (chansep*1000)
            fWidth = create_casa_quantity(myqa,numchan*chansep,'GHz')
        else:
            fResolution = create_casa_quantity(myqa,bandwidth,'GHz')
            fWidth = create_casa_quantity(myqa,bandwidth,'GHz')
        if verbose: 
            print "initializing atmProfile: h=%.1f%%, T=%.1fK, a=%.1fm, p=%.1fmb, h0=%.1fkm" % (humidity, temperature, altitude, pressure, h0)
        result = at.initAtmProfile(humidity=humidity,
                                   temperature=create_casa_quantity(myqa,temperature,"K"),
                                   altitude=create_casa_quantity(myqa,altitude,"m"),
                                   pressure=create_casa_quantity(myqa,pressure,'mbar'),
                                   h0=create_casa_quantity(myqa,h0,"km"), 
                                   maxAltitude=create_casa_quantity(myqa, maxAltitude,'km'),
                                   dP=create_casa_quantity(myqa,dP,'mbar'),
                                   atmType=latitudeClass, dPm=dPm)
        if verbose: 
            print result
        else:
            printNumberOfAtmosphericLayers(result)
        if verbose: print "initializing spectralWindow"
        at.initSpectralWindow(nbands,fCenter,fWidth,fResolution)
        at.setUserWH2O(create_casa_quantity(myqa,pwv,'mm'))
        dry, wet, TebbSky, rf, cs = getAtmDetails(at)
        numChan = at.getNumChan()
        chan0 = at.getChanFreq(0)
        chanlast = at.getChanFreq(numChan-1)
        
        # Account for the offset in the channel frequencies provided vs. the
        # channel frequencies requested
        freqs += fResolution['value']

        if verbose:
            print "chan0 = %f, freqs0=%f" % (chan0['value'], freqs[0])
        dryOpacity = airmass*dry
        wetOpacity = airmass*wet
        if (overlay):
            dryTransmission = np.exp(-dryOpacity)
            wetTransmission = np.exp(-wetOpacity)
            if (quantity == 'transmissionPercent'):
                wetTransmission *= 100
                dryTransmission *= 100
        opacity = airmass*(wet+dry)
        transmission = np.exp(-opacity)
        if (quantity.find('transmission') >= 0):
            print "Mean transmission: %f percent" % (100*np.mean(transmission))
            if (quantity == 'transmissionPercent'):
                transmission *= 100

        TebbSky *= (1-np.exp(-airmass*(wet+dry)))/(1-np.exp(-wet-dry))
        if resampleChan > 0:
            initialChanwidth = (freqs[-1]-freqs[0]) / (numchan-1)
            newChanwidth = initialChanwidth * numchan / resampleChan
            offset = 0.5*(newChanwidth-initialChanwidth)
            freqsResampled = np.arange(freqs[0]+offset, freqs[-1]-offset, newChanwidth)
            TebbSkyResampled = np.interp(freqsResampled, freqs, TebbSky)

        Tsys = (Feff*TebbSky + (1.0-Feff)*Tamb + Trx) * ((1.0 + (1.0-SBGain)) / (Feff*np.exp(-airmass*(wet+dry))))
        if showplot:
            if (type(linewidth) != list):
                linewidth = [linewidth]
            if (type(color) != list):
                color = [color]
            if (quantity == 'opacity'):
                if (numchan > 1):
                    pb.plot(freqs, opacity, ls=linestyle[0], lw=linewidth[0], color=color[colorIndex], marker=marker[colorIndex])
                    if (overlay):
                        pb.hold(True)
                        pb.plot(freqs, dryOpacity, ls=linestyle[1], lw=linewidth[1], color=color[1], marker=marker[1])
                        pb.plot(freqs, wetOpacity, ls=linestyle[2], lw=linewidth[2], color=color[2], marker=marker[2])
                else:
                    pb.plot(freqs, opacity, 'bo')
                ylabel = 'Opacity'
                if (plotrange is not None):
                    pb.ylim(plotrange) 
            elif (quantity.find('transmission') >= 0):
                if (numchan > 1):
                    pb.plot(freqs, transmission, ls=linestyle[0], lw=linewidth[0], color=color[colorIndex], marker=marker[colorIndex])
                    if (overlay):
                        pb.hold(True)
                        pb.plot(freqs, dryTransmission, ls=linestyle[1], lw=linewidth[1], color=color[1], marker=marker[1])
                        pb.plot(freqs, wetTransmission, ls=linestyle[2], lw=linewidth[2], color=color[2], marker=marker[2])
                else:
                    pb.plot(freqs, transmission, 'bo')
                ylabel = 'Transmission'
                if (plotrange is None):
                    if (quantity == 'transmissionPercent'):
                        plotrange = [0,105]
                    else:
                        plotrange = [0,1.05]
                pb.ylim(plotrange)
            elif (quantity == 'tsky'):
                if (numchan > 1):
                    pb.plot(freqs, TebbSky, ls=linestyle[0], marker=marker[0])
                    if resampleChan > 0:
                        pb.hold(True)
                        print "Channel 0: %f GHz" % (freqsResampled[0])
                        pb.plot(freqsResampled, TebbSkyResampled, 'r-', ls=linestyle[0], marker=marker[0])
                else:
                    pb.plot(freqs, TebbSky, 'bo')
                ylabel = 'Sky temperature (K)'
                if (plotrange is not None):
                    pb.ylim(plotrange)
            elif (quantity == 'tsys'):
                if (numchan > 1):
                    pb.plot(freqs, Tsys, ls=linestyle[0])
                else:
                    pb.plot(freqs, Tsys, 'bo', ls=linestyle[0])
                ylabel = 'System temperature (K)'
                pb.ylabel(ylabel, size=fontsize)
                if (plotrange is not None):
                    pb.ylim(plotrange)
            else:
                print "Unrecognized quantity: %s" % (quantity)
                return
        if (spw >= 0):
            pb.ylabel(ylabel+' (for scan %d)' % (scan), size=fontsize)
            pb.xlabel('Spw %d Frequency (GHz)' % (spw), size=fontsize)
        else:
            pb.ylabel(ylabel, size=fontsize)
            pb.xlabel('Frequency (GHz)', size=fontsize)
        resizeFonts(desc, fontsize)
        if (showgrid):
            desc.xaxis.grid(True,which='major')
            desc.yaxis.grid(True,which='major')
        title = ''
        y0,y1 = pb.ylim()
        gca = pb.gca()
        if (drawWVR):
            ifCenters = [1.25, 3.25, 5.5, 7.25]
            ifBandwidths = [1.5, 2.5, 2.0, 1.5]
            waterFreq = 183.31
            windows = []
            for i in range(len(ifCenters)):
                windows.append([waterFreq+ifCenters[i]-0.5*ifBandwidths[i],
                                waterFreq+ifCenters[i]+0.5*ifBandwidths[i]])
                windows.append([waterFreq-ifCenters[i]-0.5*ifBandwidths[i],
                                waterFreq-ifCenters[i]+0.5*ifBandwidths[i]])
            for bar in windows:
                gca.add_patch(Rectangle((bar[0],y0), bar[1]-bar[0], y1-y0, 
                                        facecolor=[0.9,0.9,0.9], edgecolor='k', 
                                        linewidth=2))
        for bar in drawRectangles:
            gca.add_patch(Rectangle((bar[0],y0), bar[1]-bar[0], y1-y0, 
                                    facecolor=[0.9,0.9,0.9], edgecolor='k', 
                                    linewidth=2))
        for bar in drawVerticalBars:
            pb.plot([bar,bar], [y0,y1], 'k--', linewidth=2)
        pb.xlim(frequencyRange)
        if (telescope != ''):
            title += '%s: ' % telescope
        pb.title('%sPWV=%.2fmm, alt.=%.0fm, h0=%.1fkm, elev=%.0fdeg, T=%.0fK, P=%.0fmb, H=%.0f%%' % (title,pwv,altitude,h0,elevation,temperature,pressure,humidity), size=12)
        pb.text(0.5,0.95,'dP=%.1fmb, dPm=%.1f, maxAltitude=%.0fkm' % (dP,dPm,maxAltitude), transform=desc.transAxes, ha='center')
        hvkT = h*np.mean(freqs)*1e9/(k*np.mean(TebbSky))
        J = hvkT / (np.exp(hvkT) - 1)
        if verbose:
            print "Mean opacity = %.4f, transmission = %.4f, Tsky = %.4f, Tsky_planck=%g, Tsys=%.4f" % (np.mean(opacity), np.mean(transmission), np.mean(TebbSky), np.mean(TebbSky) * J, np.mean(Tsys))
            print "Min/Max opacity = %.4f / %.4f   Min/Max transmission = %.4f / %.4f" % (np.min(opacity), np.max(opacity), np.min(transmission), np.max(transmission))
        pb.hold(True)
    # end loop over [numchans]
    pb.draw()
    if (plotfile != '' and plotfile != False):
        if plotfile == True:
            plotfile = vis + '.atm.png'
        pb.savefig(plotfile)
    if (outfile != ''):
        if (outfile == True):
            if vis is None:
                outfile = 'atmosphere_%d_%dGHz.txt' % (frequency[0],frequency[1])
            else:
                outfile = vis + '_atmosphere.txt'
        f = open(outfile,'w')
        f.write('# Frequency%sdryOpacity%swetOpacity%stotalOpacity%stransmission%sTsky\n' % (delimiter,delimiter,delimiter,delimiter,delimiter))
        for i in range(len(freqs)):
            f.write('%f%s%f%s%f%s%f%s%f%s%f\n' % (freqs[i], delimiter, dryOpacity[i], delimiter,
                                                  wetOpacity[i], delimiter, opacity[i], delimiter,
                                                  transmission[i], delimiter, TebbSky[i]))
        f.close()
        print "Wrote ", outfile
    return

def overlayHolographyCuts(images, plotfile='', plotrange=[0,0,-40,1], interpolate=False,
                          gaussian=None, overlay=6, interactive=True, skipCM=True,
                          subplot=22, asdmdir=None, titleString=None):
    """
    Extract a single row through the peak of a list of images and overlay them.
    Assumes that the frequencies match.
    plotfile: the name of the plotfile to produce.  ".png" will be appended if not present.
    interpolate: passes this parameter to au.extractCutFromImage
    gaussian: the FWHM of a Gaussian profile to overlay
    overlay: for subplot=22, the maximum number of cuts to overlay before incrementing the subpanel
    subplot: either 22 (default) or 11.  22 is meant for overlaying antennas, while 11
             is meant for overlaying different times for a single antenna
    asdmdir: if specified, then extract the ASDM name from the image name and read 
             the observation start date from the ASDM and print it in the figure.
    titleString: used only if subplot=11
    """
    if (type(images)==str):
        imgstring = images
        images = sorted(glob.glob(images))
    else:
        # assume it is a list
        imgstring = None
    pb.clf()
    panel = 1
    if (subplot%100==22):
        adesc = pb.subplot(2,2,panel)
    elif (subplot%100==11):
        adesc = pb.subplot(1,1,panel)
    else:
        print "invalid subplot value"
        return
    colors = ['k','r','b','c','m','g','y']
    col = colors[:overlay]
    page = 0
    ctr = 0
    aca = 0
    png = []
    if (imgstring is not None):
        if (subplot==22):
            pb.text(0, 1.09, imgstring, transform=adesc.transAxes)
        uid = imgstring.split('*')[0]
        uids = imgstring.replace('*','_')
        if (plotfile == True):
            plotfile = uids + '.profiles'
        if (os.path.exists('../data/'+uid)):
            uidDate = getObservationStartDateFromASDM('../data/'+uid)[0]
            pb.text(1.4, 1.09, uidDate, transform=adesc.transAxes)
    for i in range(0,len(images)):
        img = images[i]
        antenna = img.split('-')[1]
        if (antenna.find('CM') == 0 and skipCM):
            aca += 1
            continue
        xaxis1, intensity1, row1, column1, freqHz1 = extractCutFromImage(img,stokes='XX',interpolate=interpolate)
        xaxis2, intensity2, row2, column2, freqHz2 = extractCutFromImage(img,stokes='YY',interpolate=interpolate)
        pb.plot(xaxis1, 10*np.log10(intensity1), ls='-', color=col[ctr])
        pb.hold(True)
        pb.plot(xaxis2, 10*np.log10(intensity2), ls='--', color=col[ctr])
        if (panel in [3,4]):
            pb.xlabel('Offset from peak (arcsec)')
        if (panel in [1,3]):
            pb.ylabel('Relative intensity (dB)')
        pb.draw()
        if (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        if (plotrange[2:] != [0,0]):
            pb.ylim(plotrange[2:])
        if (subplot==11):
            pb.title(titleString)
            if (asdmdir is None):
                dateString = ''
            else:
                dateString = getObservationStartDateFromASDM(asdmdir+'/'+img.split('_APC')[0])[0]
                if (img.lower().find('usb') >= 0):
#                    print "Calling getMeanFreqFromASDM('%s')" % (asdmdir+'/'+img.split('_APC')[0])
                    dateString += ' %.1fGHz'%(getMeanFreqFromASDM(asdmdir+'/'+img.split('_APC')[0])['usb']['meanfreq']*1e-9)
                else:
                    dateString += ' %.1fGHz'%(getMeanFreqFromASDM(asdmdir+'/'+img.split('_APC')[0])['lsb']['meanfreq']*1e-9)
            pb.text(0.02, 0.02+ctr*0.03, img + ' ' + dateString, transform=adesc.transAxes,
                    size=8, color=col[ctr])
        else:
            pb.text(ctr*0.18, 1.02, antenna, color=col[ctr], transform=adesc.transAxes)
        ctr += 1
        if ((i+1-aca) % overlay == 0):
            panel += 1
            if (panel <= 4):
                adesc = pb.subplot(2,2,panel)
                ctr = 0
            else:
                if (interactive):
                    myinput = raw_input("Press return to continue or 'q' to quit")
                    if (myinput.find('q') >= 0):
                        return
                if (plotfile != ''):
                    panel = 1
                    pb.subplot(2,2,panel)
                    png.append('%s.page%d.png' % (plotfile,page))
                    pb.savefig(png[-1])
                    page += 1
                    pb.clf()
    if (panel > 1 or ctr > 0):
        if (plotfile != ''):
            if (page == 0):
                if (plotfile.find('.png') < 0):
                    plotfile += '.png'
                png.append('%s' % (plotfile))
            else:
                png.append('%s.page%d.png' % (plotfile,page))
            pb.savefig(png[-1])
            print "Wrote pngs: ", png
        
def overlayCuts(img1, img2, img3=None, row1=None, row2=None, row3=None,
                column1=None, column2=None, column3=None,
                stokes1='XX', plotfile='', plotrange=[0,0,0,0],
                frequency1=None, frequency2=None, frequency3=None,
                panels=1, interpolate=False,
                gaussian=None, scaleByFrequency=True, plotrange2=[0,0,0,0],
                scaleToArcsec=False, diameter=None, truncate=True,
                obscuration=0.75, convolve=None, showspec2=False, 
                fwhmfactor=None):
    """
    Extract a single row or column from two (or 3) CASA images and overlays them.
    If an image has multiple Stokes planes, then it must be the first image.
    img, row, column: these parameters are passed to au.extractCutFromImage
    scaleByFrequency: if True, then the xaxis of the first image (and 3rd) will be
           scaled to match the second by their frequency ratio.
    frequency1: the frequency of the first image (if not in header)
    frequency2: the frequency of the second image (if not in header)
    frequency3: the frequency of the third image (if not in header)
    panels: 1, 2, 3, or 4: 2 will also overlay in dB units,
            3: will overlay 45deg cut in dB
            4: will also show residuals w.r.t. img2
            5: will also show residuals of 45deg cut
    gaussian: the FWHM of a Gaussian profile to overlay
    scaleToArcsec: pass to extractCutFromImage
    diameter: the antenna diameter to use for the Airy profile to overlay
    truncate: if True, truncate the Airy profile at the first null
    obscuration: the central obstruction diameter for computing Airy (default = 0.75m)
    convolve: if specified, convolve the Gaussian and Airy by a Gaussian of this width in arcsec
    showspec2: if True, then also show the 10% specification level (in addition to 6%)
    -Todd Hunter
    """
    if (os.path.exists(img1) == False):
        ticraDir = os.path.dirname(__file__) + '/TicraImages/'
        if (os.path.exists(ticraDir+img1) == False):
            ticraDir = os.getenv("CASAPATH").split()[0]+"/data/alma/responses/"
            if (not os.path.exists(ticraDir+img1)):
                print "First image = %s does not exist" % (img1)
                return
        img1 = ticraDir + img1
    if (os.path.exists(img2) == False):
        holoDir = '/lustre/naasc/thunter/alma/SD/holography/'
        if (os.path.exists(holoDir+img2) == False):
            print "Second image = %s does not exist" % (img2)
            return
        img2 = holoDir + img2
    if (img3 is not None):
        if (os.path.exists(img3) == False):
            print "Third image = %s does not exist" % (img2)
            return
        img3 = img3.rstrip('/')
    img1 = img1.rstrip('/')
    img2 = img2.rstrip('/')
    if (stokes1 == 'both'):
        print "Calling au.extractCutFromImage('%s',row=%s,column=%s,stokes='XX',interpolate=%s, scaleToArcsec=%s)" % (img1, str(row1), str(column1), interpolate, scaleToArcsec)
        xaxis1, intensity1, row1, column1, freqHz1 = extractCutFromImage(img1,row=row1,column=column1,stokes='XX',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
        xaxis1yy, intensity1yy, row1, column1, freqHz1 = extractCutFromImage(img1,row=row1,column=column1,stokes='YY',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
    else:
        xaxis1, intensity1, row1, column1, freqHz1 = extractCutFromImage(img1,row=row1,column=column1,stokes=stokes1,interpolate=interpolate, scaleToArcsec=scaleToArcsec)

    xaxis2, intensity2, row2, column2, freqHz2 = extractCutFromImage(img2,row=row2,column=column2,interpolate=interpolate, scaleToArcsec=scaleToArcsec)

    if (img3 is not None):
        xaxis3, intensity3, row3, column3, freqHz3 = extractCutFromImage(img3,row=row3,column=column3,interpolate=interpolate, scaleToArcsec=scaleToArcsec)
        
    if (scaleByFrequency):
        if (freqHz1 <= 0):
            if (frequency1 is None):
                print "You need to specify the frequency of img1 with the frequency1 parameter, or set scaleByFrequency=False."
                return
            freqHz1 = parseFrequencyArgument(frequency1)
            if (freqHz1 < 2000): freqHz1 *= 1e9  # convert from floating point GHz to Hz
        if (freqHz2 <= 0):
            if (frequency2 is None):
                print "You need to specify the frequency of img2 with the frequency2 parameter, or set scaleByFrequency=False."
                return
            freqHz2 = parseFrequencyArgument(frequency2)
            if (freqHz2 < 2000): freqHz2 *= 1e9  # convert from floating point GHz to Hz
        frequencyRatio = freqHz1 / freqHz2
        xaxis1 *= frequencyRatio
        if (img3 is not None):
            if (freqHz3 <= 0):
                if (frequency3 is None):
                    print "You need to specify the frequency of img3 with the frequency3 parameter, or set scaleByFrequency=False."
                    return
                freqHz3 = parseFrequencyArgument(frequency3)
                if (freqHz3 < 2000): freqHz3 *= 1e9  # convert from floating point GHz to Hz
            frequencyRatio3 = freqHz3 / freqHz2
            xaxis3 *= frequencyRatio3
            
#    print "freq 1 = %f, freq 2 = %f" % (freqHz1, freqHz2)
    pb.clf()
    if (panels > 4):
        if (casadef.casa_version < '4.2.0'):
            print "pylab.subplot2grid is not available in this old version of casa."
            return
        rows = 3
        columns = 2
        pb.gcf().set_size_inches([6.5,8])
    elif (panels > 3):
        rows = 2
        columns = 2
        pb.gcf().set_size_inches([7,7])
    else:
        rows = 1
        columns = panels
    if (panels > 4):
        adesc = pb.subplot2grid((rows,columns),(0,0),colspan=2)
    else:
        adesc = pb.subplot(rows,columns,1)
    pb.plot(xaxis1, intensity1, 'k-', xaxis2, intensity2, 'r-')
    if (img3 is not None):
        pb.hold(True)
        pb.plot(xaxis3, intensity3, 'r--')
    y0,y1 = pb.ylim()
    pb.ylim([y0,y1*1.1])
    if (plotrange[0] == 0 and plotrange[1] != 0):
        xlabelpol = 0.05 # 0.45
        ylabelpol = 0.3 # 1
    elif (plotrange[0] != 0 and plotrange[1] != 0):
        xlabelpol = 0.40
        ylabelpol = 0.40
    else:
        xlabelpol = 0.05
        ylabelpol = 1
    xlabelpol2 = 0.35 # 2nd panel
    xlabelpol4 = 0.35 # 4th panel
    if (img3 is not None):
        polarizationLegend1 = 'XX, H: solid'
        polarizationLegend2 = 'YY, V: dashed'
    else:
        polarizationLegend1 = 'XX: solid'
        polarizationLegend2 = 'YY: dashed'
    if (stokes1 == 'both'):
        pb.hold(True)
        if (scaleByFrequency):
            xaxis1yy *= frequencyRatio
        pb.plot(xaxis1yy, intensity1yy, 'k--')
        pb.text(xlabelpol,ylabelpol-0.04*(rows+2),polarizationLegend1,transform=adesc.transAxes, size=9)
        pb.text(xlabelpol,ylabelpol-0.04*(rows+4),polarizationLegend2,transform=adesc.transAxes, size=9)
    if (convolve is not None):
        convolvingGaussian = griddedBeam().gauss(xaxis1, convolve)
    if (gaussian is not None):
        pb.hold(True)
        gauss = griddedBeam().gauss(xaxis1,gaussian)
        if (convolve is not None):
            gauss = spsig.convolve(gauss**0.5, convolvingGaussian, mode='same')
            gauss *= gauss
            gauss /= np.max(gauss)
        pb.plot(xaxis1, gauss,'g-')
    if (panels > 3):
        axisLabelSize = 9
    else:
        axisLabelSize = 11
    if (diameter is not None):
        pb.hold(True)
        if (frequency2 is None):
            print "In order to use the diameter parameter, you must set frequency2"
            return
        airyfwhm = primaryBeamArcsec(frequency=frequency2, diameter=diameter, 
                                     taper=0, showEquation=False)
        airyX, airyProfile = griddedBeam().buildAiryDisk(airyfwhm, np.max(xaxis1/airyfwhm),
                                                         convolutionPixelSize=airyfwhm/50.,
                                                         truncate=truncate, obscuration=obscuration)
        if (convolve is not None):
            airyProfile = spsig.convolve(airyProfile**0.5, convolvingGaussian, mode='same')
            airyProfile *= airyProfile
            airyProfile /= np.max(airyProfile)
        # look out for ancient pyfits versions in your path!
        pb.plot(airyX, airyProfile, 'b-')
    pb.ylabel('Relative intensity of horiz. cut',size=axisLabelSize)
    if (plotrange[:2] != [0,0]):
        pb.xlim(plotrange[:2])
    else:
        # restrict the x-axis to the overlap region of the two profiles
        pb.xlim([np.max([np.min(xaxis1),np.min(xaxis2)]), np.min([np.max(xaxis1), np.max(xaxis2)])])
    if (plotrange[2:] != [0,0]):
        pb.ylim(plotrange[2:])
    if (panels > 2):
        rowcolumn = ''
        rowcolumn2 = ''
    else:
        rowcolumn = " row=%s, column=%s" % (str(row1),str(column1))
        rowcolumn2 = " row=%s, column=%s" % (str(row1),str(column1))
    if (panels > 3):
        textArtist = pb.text(-0.2,1.02,os.path.basename(img1)+" (%.1fGHz) %s"%(freqHz1*1e-9,rowcolumn), transform=adesc.transAxes, color='k',size=12-panels,ha='left')
        if (img1 != img2):
            pb.text(0, -0.15, os.path.basename(img2)+" (%.1fGHz) %s"%(freqHz2*1e-9,rowcolumn2), transform=adesc.transAxes, color='r',size=12-panels)
    else:
        pb.text(0, 1+0.015*rows, os.path.basename(img1)+" (%.1fGHz) %s"%(freqHz1*1e-9,rowcolumn), transform=adesc.transAxes, color='k',size=8)
        pb.text(0, 1.04+(panels-2)*0.05, os.path.basename(img2)+" (%.1fGHz) %s"%(freqHz2*1e-9,rowcolumn2), transform=adesc.transAxes, color='r',size=8)
        
    if (scaleByFrequency):
        if (frequencyRatio != 1.0):
            if (panels > 4):
                pb.text(0.75, 0.99-0.04*rows, "X-axis scaled by %.4f" % (frequencyRatio), transform=adesc.transAxes, color='k',size=10, ha='center')
            else:
                pb.text(0.50, 1-0.04*rows, "X-axis scaled by %.4f" % (frequencyRatio), transform=adesc.transAxes, color='k',size=10, ha='center')
    if (panels < 4):
        pb.xlabel('Offset from peak (arcsec)',size=axisLabelSize)
    pb.setp(plt.gca().get_xmajorticklabels(), size=8)
    pb.setp(plt.gca().get_ymajorticklabels(), size=8)
    if (img3 is not None):
        intensityReference = 0.5*(intensity2+intensity3)
    else:
        intensityReference = intensity2
    if (panels > 3):
        # 3rd panel of a 2x2 grid
        adesc = pb.subplot(rows, columns, 1+columns+int(panels/5))
        xaxisResampled,int1,int2 = alignFunctions(xaxis1, intensity1, xaxis2, intensityReference)
        pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'k')
        pb.ylabel('Residuals of horizontal cut (%)',size=axisLabelSize)
        pb.xlabel('Offset from peak (arcsec)',size=axisLabelSize)
        if (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        pb.ylim([-27,27])
        if (diameter is not None):
            xaxisResampled,int1,int2 = alignFunctions(airyX, airyProfile, xaxis2, intensityReference)
            pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'b')
        if (gaussian is not None):
            xaxisResampled,int1,int2 = alignFunctions(xaxis1, gauss, xaxis2, intensityReference)
            pb.plot(xaxisResampled, 100*(int1-int2)/int2,'g-')
        if (stokes1 == 'both'):
            xaxisResampled,int1,int2 = alignFunctions(xaxis1, intensity1yy, xaxis2, intensityReference)
            pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'k--')
            
        pb.setp(plt.gca().get_xmajorticklabels(), size=8)
        pb.setp(plt.gca().get_ymajorticklabels(), size=8)
        adesc.yaxis.set_minor_locator(MultipleLocator(2))
        sixPercentLevel = 0.5*findFWHM(xaxis2,intensity2,level=0.06)
        spec = 6
        spec2 = 10
        pb.plot([sixPercentLevel,sixPercentLevel],[-spec,spec],'k:')
        if (pb.xlim()[0] == 0):
            x0 = 0
        else:
            x0 = -sixPercentLevel
            pb.plot([-sixPercentLevel,-sixPercentLevel],[-spec,spec],'k:')
            if (showspec2):
                pb.plot([-sixPercentLevel,-sixPercentLevel],[-spec2,-spec],'k--')
                pb.plot([-sixPercentLevel,-sixPercentLevel],[spec2,spec],'k--')
                pb.plot([sixPercentLevel,sixPercentLevel],[-spec2,-spec],'k--')
                pb.plot([sixPercentLevel,sixPercentLevel],[spec2,spec],'k--')
        pb.plot([x0,sixPercentLevel],[-spec,-spec],'k:')
        pb.plot([x0,sixPercentLevel],[spec,spec],'k:')
        if (showspec2):
            pb.plot([x0,sixPercentLevel],[-spec2,-spec2],'k--')
            pb.plot([x0,sixPercentLevel],[spec2,spec2],'k--')
        if (img3 is not None):
            pb.hold(True)
            # V polarization
            xaxisResampled,int1,int2 = alignFunctions(xaxis3, intensity3, xaxis2, intensityReference)
            pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'r--')
            # H polarization
            xaxisResampled,int1,int2 = alignFunctions(xaxis2, intensity2, xaxis2, intensityReference)
            pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'r-')
        else:
            # H polarization is the reference 
            pb.plot(pb.xlim(),[0,0],'r-')
        if (img1 == img2):
            rowAdjust = 0.5
        else:
            rowAdjust = 0
        pb.text(xlabelpol,ylabelpol-0.10*(rows-rowAdjust),polarizationLegend1,transform=adesc.transAxes, size=8)
        pb.text(xlabelpol,ylabelpol-0.10*(rows+0.6-rowAdjust),polarizationLegend2,transform=adesc.transAxes, size=8)
    if (panels > 1):
        if (panels > 3):
            if (img1 == img2):
                pb.subplots_adjust(wspace=0.3,hspace=0.1,top=0.65)
            else:
                pb.subplots_adjust(wspace=0.3,hspace=0.18,top=0.85,bottom=0.05) #,top=0.80)
        else:
            pb.subplots_adjust(wspace=0.3+(panels-2)*0.05)
        adesc = pb.subplot(rows,columns,2+int(panels/5))
        # second plot of a 2x2 grid
        if (panels != 4):
            pb.xlabel('Offset from peak (arcsec)',size=axisLabelSize)
        pb.plot(xaxis1, 10*np.log10(intensity1), 'k-', xaxis2, 10*np.log10(intensity2), 'r-')
        if (img3 is not None):
            pb.hold(True)
            pb.plot(xaxis3, 10*np.log10(intensity3), 'r--')
        if (stokes1 == 'both'):
            pb.hold(True)
            pb.plot(xaxis1yy, 10*np.log10(intensity1yy), 'k--')
            pb.text(xlabelpol2,ylabelpol-0.10*(rows-1),polarizationLegend1,transform=adesc.transAxes, size=8)
            pb.text(xlabelpol2,ylabelpol-0.10*(rows),polarizationLegend2,transform=adesc.transAxes, size=8)
        if (gaussian is not None):
            if (fwhmfactor is None): fwhmfactor = 1.131
            pb.hold(True)
            pb.plot(xaxis1, 10*np.log10(gauss),'g-')
            pb.text(0.5,0.97-0.03*(rows-1-panels/5),'GaussianFWHM: %.3f*L/D=%.2f"' % (fwhmfactor,gaussian),ha='center',
                    color='g', transform=adesc.transAxes, size=7)
        if (diameter is not None):
            pb.hold(True)
            # look out for ancient pyfits versions in your path!
            pb.plot(airyX, 10*np.log10(airyProfile), 'b-')
            pb.text(0.5,0.98-0.05*(rows-panels/5),'AiryFWHM: 1.023*L/%.1fm=%.2f"' % (diameter,airyfwhm),
                    color='b', transform=adesc.transAxes, size=7,ha='center')
        pb.ylabel('Rel. intensity of horiz. cut (dB)',size=axisLabelSize)
        if (plotrange2[:2] != [0,0]):
            pb.xlim(plotrange2[:2])
        elif (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        else:
            # restrict the x-axis to the overlap region of the two profiles
            pb.xlim([np.max([np.min(xaxis1),np.min(xaxis2)]), np.min([np.max(xaxis1), np.max(xaxis2)])])
        if (plotrange2[2:] != [0,0]):
            pb.ylim(plotrange2[2:])
        else:
            pb.ylim([-50,2.0])
        pb.setp(plt.gca().get_xmajorticklabels(), size=8)
        pb.setp(plt.gca().get_ymajorticklabels(), size=8)
        if (panels > 2):
            if (stokes1 == 'both'):
                if (row1 is None):
                    xaxis1diagonal, intensity1diagonal, row1diagonal, column1diagonal, freqHz1 = \
                        extractCutFromImage(img1,row=row1,column=-column1,stokes='XX',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                    xaxis1yydiagonal, intensity1yydiagonal, row1diagonal, column1diagonal, freqHz1 = \
                                  extractCutFromImage(img1,row=row1,column=-column1,stokes='YY',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                else:
                    xaxis1diagonal, intensity1diagonal, row1diagonal, column1diagonal, freqHz1 = \
                        extractCutFromImage(img1,row=-row1,column=column1,stokes='XX',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                    xaxis1yydiagonal, intensity1yydiagonal, row1diagonal, column1diagonal, freqHz1 = \
                                  extractCutFromImage(img1,row=-row1,column=column1,stokes='YY',interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                if (scaleByFrequency):
                    xaxis1yydiagonal *= frequencyRatio
            else:
#                print "Calling extractCutFromImage('%s',row=%d,column=%s,stokes='%s',interpolate=%s,scaleToArcsec=%s)" % (img1,-row1,column1,stokes1,interpolate,scaleToArcsec)
                if (row1 is None):
                    xaxis1diagonal, intensity1diagonal, row1diagonal, column1diagonal, freqHz1 = \
                        extractCutFromImage(img1,row=row1,column=-column1,stokes=stokes1,interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                else:
                    xaxis1diagonal, intensity1diagonal, row1diagonal, column1diagonal, freqHz1 = \
                        extractCutFromImage(img1,row=-row1,column=column1,stokes=stokes1,interpolate=interpolate, scaleToArcsec=scaleToArcsec)

            if (row2 is None):
                xaxis2diagonal, intensity2diagonal, row2diagonal, column2diagonal, freqHz2 = \
                    extractCutFromImage(img2,row=row2,column=-column2,interpolate=interpolate, scaleToArcsec=scaleToArcsec)
            else:
                xaxis2diagonal, intensity2diagonal, row2diagonal, column2diagonal, freqHz2 = \
                    extractCutFromImage(img2,row=-row2,column=column2,interpolate=interpolate, scaleToArcsec=scaleToArcsec)
            if (scaleByFrequency):
                xaxis1diagonal *= frequencyRatio

            if (img3 is not None):
                if (row3 is None):
                    xaxis3diagonal, intensity3diagonal, row3diagonal, column3diagonal, freqHz3 = \
                        extractCutFromImage(img3,row=row3,column=-column3,interpolate=interpolate, scaleToArcsec=scaleToArcsec)
                else:
                    xaxis3diagonal, intensity3diagonal, row3diagonal, column3diagonal, freqHz3 = \
                        extractCutFromImage(img3,row=-row3,column=column3,interpolate=interpolate, scaleToArcsec=scaleToArcsec)

                if (scaleByFrequency):
                    xaxis3diagonal *= frequencyRatio

            adesc = pb.subplot(rows,columns,panels)
            ##### FINAL PANEL of 2x2 grid
            pb.xlabel('Offset from peak (arcsec)',size=axisLabelSize)
            pb.plot(xaxis1diagonal, 10*np.log10(intensity1diagonal), 'k-',
                    xaxis2diagonal, 10*np.log10(intensity2diagonal), 'r-')
            if (img3 is not None):
                pb.hold(True)
                pb.plot(xaxis3diagonal, 10*np.log10(intensity3diagonal), 'r--')
            if (stokes1 == 'both'):
                pb.hold(True)
                pb.plot(xaxis1yydiagonal, 10*np.log10(intensity1yydiagonal), 'k--')
                pb.text(xlabelpol4,ylabelpol-0.10*(rows-1),polarizationLegend1,transform=adesc.transAxes, size=8)
                pb.text(xlabelpol4,ylabelpol-0.10*(rows),polarizationLegend2,transform=adesc.transAxes, size=8)
            if (gaussian is not None):
                pb.hold(True)
                pb.plot(xaxis1, 10*np.log10(gauss),'g-')
            if (diameter is not None):
                pb.hold(True)
                # look out for ancient pyfits versions in your path!
                pb.plot(airyX, 10*np.log10(airyProfile), 'b-')
            pb.ylabel('Rel. intensity of diagonal cut (dB)',size=axisLabelSize)
            if (plotrange2[:2] != [0,0]):
                pb.xlim(plotrange2[:2])
            elif (plotrange[:2] != [0,0]):
                pb.xlim(plotrange[:2])
            else:
                # restrict the x-axis to the overlap region of the two profiles
                pb.xlim([np.max([np.min(xaxis1),np.min(xaxis2)]), np.min([np.max(xaxis1), np.max(xaxis2)])])
            if (plotrange2[2:] != [0,0]):
                pb.ylim(plotrange2[2:])
            else:
                pb.ylim([-50,2.0])
            pb.setp(plt.gca().get_xmajorticklabels(), size=8)
            pb.setp(plt.gca().get_ymajorticklabels(), size=8)
            if (panels > 4):
                adesc = pb.subplot(rows,columns,6)
                xaxisResampled,int1,int2 = alignFunctions(xaxis1diagonal, intensity1diagonal, xaxis2diagonal, intensity2diagonal)
                pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'k')
                pb.ylabel('Residuals of diagonal cut (%)',size=axisLabelSize)
                pb.xlabel('Offset from peak (arcsec)',size=axisLabelSize)
                if (plotrange[:2] != [0,0]):
                    pb.xlim(plotrange[:2])
                pb.ylim([-27,27])
                if (diameter is not None):
                    xaxisResampled,int1,int2 = alignFunctions(airyX, airyProfile, xaxis2diagonal, intensity2diagonal)
                    pb.plot(xaxisResampled, 100*(int1-int2)/int2, 'b')
                if (gaussian is not None):
                    xaxisResampled,int1,int2 = alignFunctions(xaxis1, gauss, xaxis2diagonal, intensity2diagonal)
                    pb.plot(xaxisResampled, 100*(int1-int2)/int2,'g-')
                pb.setp(plt.gca().get_xmajorticklabels(), size=8)
                pb.setp(plt.gca().get_ymajorticklabels(), size=8)
                adesc.yaxis.set_minor_locator(MultipleLocator(2))
                sixPercentLevel = 0.5*findFWHM(xaxis2diagonal,intensity2diagonal,level=0.06)
                pb.plot([sixPercentLevel,sixPercentLevel],[-spec,spec],'k:')
                if (pb.xlim()[0] == 0):
                    x0 = 0
                else:
                    x0 = -sixPercentLevel
                    pb.plot([-sixPercentLevel,-sixPercentLevel],[-spec,spec],'k:')
                    pb.plot([-sixPercentLevel,-sixPercentLevel],[-spec2,-spec],'k--')
                    pb.plot([-sixPercentLevel,-sixPercentLevel],[spec2,spec],'k--')
                    pb.plot([sixPercentLevel,sixPercentLevel],[-spec2,-spec],'k--')
                    pb.plot([sixPercentLevel,sixPercentLevel],[spec2,spec],'k--')
                pb.plot([x0,sixPercentLevel],[-spec,-spec],'k:')
                pb.plot([x0,sixPercentLevel],[spec,spec],'k:')
                pb.plot([x0,sixPercentLevel],[-spec2,-spec2],'k--')
                pb.plot([x0,sixPercentLevel],[spec2,spec2],'k--')
                pb.plot(pb.xlim(),[0,0],'r-')
            # endif (panels > 4):
        # endif (panels > 2):
    # endif (panels > 1)
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            if (row1 is not None):
                cut1 = 'row%d' % (row1)
            else:
                cut1 = 'col%d' % (column1)
            if (row2 is not None):
                cut2 = 'row%d' % (row2)
            else:
                cut2 = 'col%d' % (column2)
            png = '%s_%s_%s_%s.png' % (img1,cut1,img2,cut2)
        else:
            png = plotfile
        eps = plotfile.replace('.png','.eps')
        if (panels == 5):
            if (png.find('5.png') < 0): 
                png = png.replace('.png', '5.png')
            if (eps.find('5.eps') < 0): 
                eps = eps.replace('.eps', '5.eps')
        pb.savefig(png)
        pb.savefig(eps,bbox_inches='tight',bbox_extra_artists=[textArtist])
        print "Plot saved to %s and %s" % (png,eps)
    # end of overlayCuts()
    
def extractCutsFromImage(myimage,row=None,column=None,stokes='XX', channel=0,
                         shiftPeakToCenter=True, scaleToArcsec=True):
    """
    Extract 5 rows of an image (centered on the specified row, or the peak row)
    and overlay them.
    Returns: nothing
    -Todd Hunter
    """
    pb.clf()
    xaxis, intensity, row, column, freqHz = extractCutFromImage(myimage, scaleToArcsec=scaleToArcsec,
                                                                shiftPeakToCenter=shiftPeakToCenter,
                                                                row=row,column=column)
    pb.plot(xaxis,intensity,'ro')
    pb.hold(True)
    rows = [row-2, row-1, row+1, row+2]
    for r in rows:
        xaxis, intensity, myrow, column, freqHz = extractCutFromImage(myimage,row=r,column=column)
        pb.plot(xaxis,intensity,'k-')
    pb.show()

def extractCutFromImage(myimage, row=None, column=None, stokes='XX', channel=0,
                        gaussfit=False, verbose=False, showplot=False,
                        interpolate=False, plotrange=[0,0,0,0],
                        scaleToArcsec=True, shiftPeakToCenter=True,
                        truncate=False, peakimage=None, normalize=True):
    """
    Extract a single row or column from a CASA image
    row: row to extract, default = center, if negative, then take 45deg cut from (0,0)-(n,n)
          row='auto' means to take the row through the peak
    column: column to extract, default = center, if negative, then take 45deg cut from (0,n)-(n,0)
          column='auto' means to take the column through the peak
      if row=None and column=None, then row is set to 'auto'
         
    gaussfit: if True, perform a Gaussian fit centered on the maximum pixel,
              with its amplitude normalized to one.
    showplot: show the resulting Gaussian fit in a graphics window
    verbose: pass this to griddedBeam().gaussfit
    truncate: pass this to griddedBeam().gaussfit
    interpolate: if True, return the spline interpolated model rather than the raw data
    peakimage: if specified, use the position of the peak from this image instead of myimage
    normalize: if True, divide the intensity by the maximum intensity
    Returns:
       the xaxis along the cut (in arcsec), the intensity data of the cut, the row,
       the column, and the frequency (in Hz)
    - Todd Hunter
    """
    stokesPixel = ['XX','XY','YX','YY'].index(stokes)
    if (os.path.exists(myimage) == False):
        print "Image does not exist = ", myimage
        return
    myia = createCasaTool(iatool)
    if (peakimage is not None):
        imageForPeak = peakimage
    else:
        imageForPeak = myimage
    print "Finding peak in %s" % (imageForPeak)
    myia.open(imageForPeak)
    imgPeak = myia.getregion()
    if ((row is None and column is None) or row == 'auto'):
        if (len(np.shape(imgPeak)) < 3):
            results = imstat(imageForPeak)['maxpos']
        else:
            results = imstat(imageForPeak,stokes=stokes,chans=str(channel))
            # imstat will bomb if you don't have write permission in the directory
            results = results['maxpos']
        if (verbose): print "Peak is at ", results
        row = results[0]
        if (verbose): print "Using row=%d" % (row)
        if (column == 'auto'):
            # Then both are auto, so it means to take the average of the two
            column = results[1]
            
    elif (column == 'auto'):
        if (len(np.shape(imgPeak)) < 3):
            results = imstat(imageForPeak)['maxpos']
        else:
            results = imstat(imageForPeak,stokes=stokes,chans=str(channel))['maxpos']
        if (verbose): print "Peak is at ", results
        column = results[1]
        if (verbose): print "Using column=%d" % (column)
    myia.close()
    myia.open(myimage)
    img = myia.getregion()
    header = imhead(myimage,mode='list')
    if (header is None):
        imgfreq = 0
    elif ('restfreq' in header.keys()):
        imgfreq = header['restfreq']
    else:
        imgfreq = 0
    myrg = createCasaTool(rgtool)
    if (len(np.shape(img)) < 3):
        if (header is None):
            try:
                myshape = imhead(myimage, mode='get', hdkey='shape')
                naxis1 = myshape[0]
                naxis2 = myshape[1]
                cdelt1 = headerToArcsec(imhead(myimage, mode='get', hdkey='cdelt1'))
                cdelt2 = headerToArcsec(imhead(myimage, mode='get', hdkey='cdelt2'))
            except:
                bmaj,bmin,bpa,cdelt1,cdelt2,naxis1,naxis2,imgfreq = getFitsBeam(myimage)
            trc = [naxis1,naxis2]
        else:
            trc = [header['shape'][0],header['shape'][1]]
        print "trc = ", trc
        region = myrg.box(blc=[0,0],trc=trc)
    else:
        region = myrg.box(blc=[0,0,stokesPixel,channel],trc=[header['shape'][0],header['shape'][1],stokesPixel,channel])
    img = myia.getregion(region=region)
    myrg.done()
    if (row is not None):
        if (header is None):
            arcsecPerPixel = cdelt1
        else:
            arcsecPerPixel = abs(headerToArcsec(header['cdelt1'], header['cunit1']))
        if (row >= 0):
            cut = img[row,:]
            if (column is not None):
                cut2 = img[:,column]
                print "Taking average of specified row (%d) and column (%d)" % (row,column)
                if (row < column):
                    cut2 = np.append(np.zeros(column-row),cut2[:-(column-row)])
                elif (column < row):
                    cut = np.append(np.zeros(row-column), cut[:-(row-column)])
                cut = 0.5*(cut + cut2)
        else:
            # Take a 45-degree cut
            if (peakimage is not None):
                if (len(np.shape(imgPeak)) < 3):
                    results = imstat(imageForPeak)['maxpos']
                else:
                    results = imstat(imageForPeak,stokes=stokes,chans=str(channel))['maxpos']
                peakrow = results[0]
                peakcolumn = results[1]
                print "Image peak is at %d,%d" % (peakrow,peakcolumn)
                # This will be zero if peak is at image center
                peakdiff = peakrow-peakcolumn
            else:
                peakdiff = 0
            cut = []
            n = np.shape(img)[1]
            for x in range(np.shape(img)[0]):
                idx = x-peakdiff 
                if (idx >= 0 and idx < n):
                    if (len(np.shape(cut)) == 3):
                        value = img[x,x-peakdiff,0]
                        cut.append(value)
                    else:
                        value = np.array(img[x,x-peakdiff]).flatten()[0]
                        cut.append(value)
            arcsecPerPixel *= 2**0.5
    elif (column is not None):
        if (header is None):
            arcsecPerPixel = cdelt2
        else:
            arcsecPerPixel = headerToArcsec(header['cdelt2'], header['cunit2'])
        if (column >= 0):
            cut = img[:,column]
        else:
            if (peakimage is not None):
                if (len(np.shape(imgPeak)) < 3):
                    results = imstat(imageForPeak)['maxpos']
                else:
                    results = imstat(imageForPeak,stokes=stokes,chans=str(channel))['maxpos']
                peakrow = results[0]
                peakcolumn = results[1]
                print "Image peak is at %d,%d" % (peakrow,peakcolumn)
                # This will be zero if peak is at image center
                peakdiff = peakrow-peakcolumn
            else:
                peakdiff = 0
            cut = []
            n = np.shape(img)[1]
            for x in range(np.shape(img)[0]):
                idx = n-x-1-peakdiff 
                if (idx >= 0 and idx < np.shape(img)[1]):
                    if (len(np.shape(cut)) == 3):
                        cut.append(img[x, n-x-1-peakdiff, 0])
                    else:
                        value = np.array(img[x, n-x-1-peakdiff]).flatten()[0]
                        cut.append(value)
            arcsecPerPixel *= 2**0.5
    if (verbose): print "arcsecPerPixel = ", arcsecPerPixel
    myia.close()
    if (len(np.shape(cut)) == 3):
        cut = cut[:,0,0]
    cut = cut/np.max(cut)
    xaxis = np.array(range(len(cut)), dtype=np.float)
    if (shiftPeakToCenter):
        xaxis -= np.argmax(np.abs(cut))
        if (verbose): print "removing %f from xaxis" % (np.argmax(cut))
    myspline = scipy.interpolate.UnivariateSpline(xaxis,cut,s=0)
    npixels = len(xaxis)
    if (shiftPeakToCenter):
        # we want this to be a regular grid including x=0
        xstart = round(np.min(xaxis))
        xend = abs(xstart)
        myxaxis = np.linspace(xstart, xend, 1+(100*npixels)/2)
        medianpixel = np.median(range(len(myxaxis)))
        if (medianpixel != round(medianpixel)):
            print "This error should never happen."
            return
    else:
        myxaxis = np.linspace(np.min(xaxis), np.max(xaxis), 50*(npixels-1))
    myfunction = myspline(myxaxis)
    if (normalize):
        myfunction = myfunction/np.max(myfunction)
    if (shiftPeakToCenter):
        if (verbose): print "Removing argmax=%d, x=%f" % (np.argmax(myfunction), myxaxis[np.argmax(myfunction)])
        xaxis -= myxaxis[np.argmax(myfunction)]
        myxaxis -= myxaxis[np.argmax(myfunction)]
        myspline = scipy.interpolate.UnivariateSpline(myxaxis,myfunction,s=0)
        # we want this to be a regular grid including x=0
        xstart = round(np.min(myxaxis))
        xend = abs(xstart)
        myxaxis = np.linspace(xstart, xend, 1+(100*npixels)/2)
        myfunction = myspline(myxaxis)
        if (normalize):
            myfunction = myfunction/np.max(myfunction)
    if (scaleToArcsec):
        xaxis *= arcsecPerPixel
        myxaxis *= arcsecPerPixel
    if (showplot and gaussfit==False):
        pb.clf()
        pb.plot(xaxis, cut, 'k-', myxaxis, myfunction,'r-')
        if (plotrange[:2] != [0,0]):
            pb.xlim(plotrange[:2])
        if (plotrange[2:] != [0,0]):
            pb.ylim(plotrange[2:])
        pb.title(myimage)
        pb.draw()
    if (gaussfit):
        fwhm,truncate = griddedBeam().gaussfit(xaxis, cut, verbose=verbose, showplot=showplot,
                                         title=myimage, truncate=truncate)
    if (interpolate):
        return(myxaxis,myfunction,row,column,imgfreq)
    else:
        return(xaxis,cut,row,column,imgfreq)

def findChannel(img, channel, img2):
    """
    Given a CASA cube and a channel, this function finds the nearest
    frequency channel in a second cube.
    -Todd Hunter
    """
    n0, firstfreq0, lastfreq0 = numberOfChannelsInCube(img, returnFreqs=True)
    cdelt0 = (lastfreq0-firstfreq0)/(n0-1)
    freq0 = firstfreq0 + (channel-0)*cdelt0
    n1, firstfreq1, lastfreq1 = numberOfChannelsInCube(img2, returnFreqs=True)
    cdelt1 = (lastfreq1-firstfreq1)/(n1-1)
    channel1 = (freq0-firstfreq1)/cdelt1
    print "channel = ", channel1
    return(int(np.round(channel1)))

def channelSelectionRangesToIndexArray(selection, separator=';'):
    """
    Convert a channel selection range string to integer array of indices.
    e.g.:  '3~8;10~11' -> [3,4,5,6,7,8,10,11]
    -Todd Hunter
    """
    index = []
    for s in selection.split(separator):
        a,b = s.split('~')
        index += range(int(a),int(b)+1,1)
    return(np.array(index))

def countChannelsInRanges(channels, separator=';'):
    """
    Counts the number of channels in one spw of a CASA channel selection string
    and return a list of numbers.    e.g. "5~20;30~40"  yields [16,11]
    -Todd Hunter
    """
    tokens = channels.split(separator)
    count = []
    for i in range(len(tokens)):
        c0 = int(tokens[i].split('~')[0])
        c1 = int(tokens[i].split('~')[1])
        count.append(c1-c0+1)
    return count

def countChannels(channels, subcounts=False):
    """
    Counts the number of channels in a CASA channel selection string.
    If multiple spws, then return a dictionary of counts
    e.g. "1:5~20;30~40"  yields 27; or  '6~30' yields 25
         "1:5~20;30~40,2:6~30" yields {1:27, 2:25}
    If subcounts=True, then return count of each range per spw:
    e.g. "1:5~20;30~40,2:6~30" yields {1:[16,11], 2:[25]}
    -Todd Hunter
    """
    tokens = channels.split(',')
    nspw = len(tokens)
    count = {}
    for i in range(nspw):
        string = tokens[i].split(':')
        if (len(string) == 2):
            spw,string = string
        else:
            string = string[0]
            spw = 0
        ranges = string.split(';')
        for r in ranges:
            c0 = int(r.split('~')[0])
            c1 = int(r.split('~')[1])
            if (c0 > c1):
                print "Invalid channel range: c0 > c1 (%d > %d)" % (c0,c1)
                return
        if (spw not in count.keys()):
            count[spw] = 0
        if subcounts:
            count[spw] += countChannelsInRanges(string)
        else:
            count[spw] += np.sum([1+int(r.split('~')[1])-int(r.split('~')[0]) for r in ranges])
    if (nspw == 1):
        count = count[spw]
    return(count)

def invertChannelRanges(invertstring, nchan=0, startchan=0, vis='', spw='', 
                        separator=';'):
    """
    Takes a CASA channel selection string and inverts it.
    -Todd Hunter
    """
    myspw = spw
    checkForMultipleSpw = invertstring.split(',')
    mystring = ''
    if (vis != ''):
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    for c in range(len(checkForMultipleSpw)):
      checkspw = checkForMultipleSpw[c].split(':')
      if (len(checkspw) > 1 and spw==''):
          spw = checkspw[0]
          checkForMultipleSpw[c] = checkspw[1]
      if (vis != ''):
          nchan = mymsmd.nchan(int(spw))
#          print "Setting nchan = %d for spw %s" % (nchan,str(spw))
      goodstring = checkForMultipleSpw[c]
      goodranges = goodstring.split(separator)
      if (str(spw) != ''):
          mystring += str(spw) + ':'
      if (int(goodranges[0].split('~')[0]) > startchan):
          mystring += '%d~%d%s' % (startchan,int(goodranges[0].split('~')[0])-1, separator)
      multiWindows = False
      for g in range(len(goodranges)-1):
          r = goodranges[g]
          s = goodranges[g+1]
          mystring += '%d~%d' % (int(r.split('~')[1])+1, int(s.split('~')[0])-1)
          multiWindows = True
          if (g < len(goodranges)-2):
              mystring += separator
      if (int(goodranges[-1].split('~')[-1]) < startchan+nchan-1):
          if (multiWindows):
              mystring += separator
          mystring += '%d~%d' % (int(goodranges[-1].split('~')[-1])+1, startchan+nchan-1)
      if (c < len(checkForMultipleSpw)-1):
          mystring += ','
      spw = myspw  # reset to the initial value
    if (vis != ''):
        mymsmd.close()
    return(mystring)

def shiftChannelSelection(selection, nchanToRemove=1):        
    """
    Takes a channel selection string and shifts it by the number
    of specified channels:
    nchanToRemove: positive value shifts left, e.g.'4~20;30~40' --> '3~19;29~39'
    -Todd Hunter
    """
    if nchanToRemove == 0: return selection
    newSelection = ''
    for piece in selection.split(';'):
        start,stop = piece.split('~')
        newpiece = '%d~%d;' % (int(start)-nchanToRemove,int(stop)-nchanToRemove)
        newSelection += newpiece
    newSelection = newSelection.rstrip(';')
    return(newSelection)
            
def numberOfChannelsInCube(img, returnFreqs=False, returnChannelWidth=False, 
                           verbose=False):
    """
    Finds the number of channels in a CASA image cube.
    returnFreqs: if True, then also return the frequency of the
           first and last channel (in Hz)
    returnChannelWidth: if True, then also return the channel width (in Hz)
    verbose: if True, then print the frequencies of first and last channel
    -Todd Hunter
    """
    if (not os.path.exists(img)):
        print "Image not found."
        return
    if (not casaAvailable):
        # Only works on FITS files
        if (os.path.isdir(img)):
            print "The function numberOfChannelsInCube is not available for non-FITS images when run outside of CASA."
            return
        myia = pyfits.open(img)
        hdr = myia[0].header
        nchan = hdr['NAXIS3']
        myia.close()
        return(nchan)
    myia = createCasaTool(iatool)
    myia.open(img)
    axis = findSpectralAxis(myia)
    naxes = len(myia.shape())
    nchan = myia.shape()[axis]
    mycs = myia.coordsys()
    cdelt = mycs.increment()['numeric'][axis]
    pixel = [0]*naxes
    firstFreq = mycs.toworld(pixel, format='n')['numeric'][axis]
    pixel[axis] = nchan-1
    lastFreq = mycs.toworld(pixel, format='n')['numeric'][axis]
    myia.close()
    if (returnFreqs):
        if (returnChannelWidth):
            return(nchan,firstFreq,lastFreq,cdelt)
        else:
            return(nchan,firstFreq,lastFreq)
    else:
        if (returnChannelWidth):
            return(nchan,cdelt)
        else:
            return(nchan)

def getChanwidthASDM(asdm, spw):
    """
    Returns the channel width of an spw in an ASDM.
    The spw is mapped from  measurement set space to ASDM space before retrieving it.
    An alternative to see this information for all spws at once, use 
       printLOsFromASDM(showEffective=True)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm+'/SpectralWindow.xml')):
        print "Could not find SpectralWindow.xml."
        return
    mydict = getSpwsFromASDM(asdm)
    if spw not in mydict.keys():
        print "spw %d is not in this ASDM" % (spw)
        return
    bw = mydict[spw]['chanWidth']
    return bw

def getChanWidths(mymsmd, spw=''):
    """
    Returns an array of channel widths in Hz for the specified
    msmd and spw (or spw list).
    mymsmd: an instance of msmd, or the name of a measurement set
    spw: integer or comma-delimited string
    -Todd Hunter
    """
    if (type(mymsmd) == str):
        vis = mymsmd
        if (not os.path.exists(vis)):
            print "measurement set not found"
            return
        mymsmd = createCasaTool(msmdtool)
        print "Opening msmd tool"
        mymsmd.open(vis)
    if (spw == '' or spw == []):
        spw = range(mymsmd.nspw())
    if (type(spw) == int):
        spw = [spw]
    elif (type(spw) == str):
        spw = [int(i) for i in spw.split(',')]
    chanwidths = []
    for myspw in spw:
        chanwidths.append(np.median(mymsmd.chanwidths(myspw)))
    return(np.array(chanwidths))

def getMeanFreqOfSpwSelection(vis, spw='', separator=';'):
    """
    Returns the mean of the mean frequencies of an arbitrary spw selection
    string (including specified channel ranges in multiple spws).
    spw: comma-delimited string of 'spw0:c0~c1;...;c(n-1)~c(n),spw1:...'
    returns: value in Hz
    -Todd Hunter
    """
    if type(spw) != str:
        spw = str(spw)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    checkForMultipleSpw = spw.split(',')
    freqs = []
    for c in range(len(checkForMultipleSpw)):
      checkspw = checkForMultipleSpw[c].split(':')
      if (len(checkspw) > 1):
          spw = int(checkspw[0])
          checkForMultipleSpw[c] = checkspw[1]
      goodstring = checkForMultipleSpw[c]
      goodranges = goodstring.split(separator)
      for r in goodranges:
          token = r.split('~')
          if (len(token) < 2):
              chanfreqs = mymsmd.chanfreqs(int(spw))
              freqs += list(chanfreqs)
          else:
              c0,c1 = token
              chanfreqs = mymsmd.chanfreqs(spw)
              for chan in range(int(c0),int(c1)+1):
                  freqs.append(chanfreqs[chan])
    meanfreq = np.mean(freqs)
    mymsmd.close()
    print "Mean of %d channels = %fGHz" % (len(freqs),meanfreq*1e-9)
    return(meanfreq)

def getMeanFreqOfSpwlist(vis, spw='', mymsmd=''):
    """
    Returns the mean of the mean frequencies of a list of spws (in Hz).
    spw: integer or comma-delimited string or list of integers or
         list of strings
    -Todd Hunter
    """
    needToClose = False
    if mymsmd == '':
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
    meanfreq = np.mean(getMeanFreqs(mymsmd,spw))
    if needToClose:
        mymsmd.close()
    return(meanfreq)

def getMeanFreqs(mymsmd, spw=''):
    """
    Returns an array of mean frequencies in Hz for the specified
    msmd and spw (or spw list).
    mymsmd: an instance of msmd, or the name of a measurement set
    spw: integer or comma-delimited string or list of integers or
         list of strings
    -Todd Hunter
    """
    needToClose = False
    if (type(mymsmd) == str):
        vis = mymsmd
        if (not os.path.exists(vis)):
            print "measurement set not found"
            return
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        needToClose = True
        spw = parseSpw(vis, spw)
    else:
        spw = parseSpw(mymsmd.name(), spw)
    meanfreqs = []
    for myspw in spw:
        meanfreq = mymsmd.meanfreq(int(myspw))
        meanfreqs.append(meanfreq)
    if needToClose:
        mymsmd.close()
    return(np.array(meanfreqs))

def effectiveBandwidthASDM(asdm, spw, kms=False, ratio=False):
    """
    Returns the effective bandwidth of a channel (in Hz and km/s)
    of the ASDM spw ID (or list of IDs).  The spw is mapped from 
    measurement set space to ASDM space before retrieving it.
    kms: if True, then return the value in km/s (otherwise Hz)
    ratio: if True, then divide the value by the physical bandwidth
    An alternative to see this information for all spws at once, use 
       printLOsFromASDM(showEffective=True)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm+'/SpectralWindow.xml')):
        print "Could not find SpectralWindow.xml."
        return
    mydict = getSpwsFromASDM(asdm)
    if spw not in mydict.keys():
        print "spw %d is not in this ASDM" % (spw)
        return
    effbw = mydict[spw]['effectiveBw']
    if ratio:
        phys = mydict[spw]['chanWidth']
        effbw /= phys
    elif kms:
        effbw = c_mks*0.001*effbw/mydict[spw]['centerFreq']
    return effbw

def physicalBandwidth(vis, spw, kms=False):
    """
    Returns the effective bandwidth of a channel (in Hz or km/s)
    of the specified measurement set and single spw ID.
    kms: if True, then return the value in km/s (otherwise Hz)
    -Todd Hunter
    """
    spw = int(spw)
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    result = getChanWidths(mymsmd, spw)[0] # Hz
    if kms:
        result = c_mks*0.001*result/mymsmd.meanfreq(spw)
    mymsmd.close()
    return result

def effectiveBandwidth(vis, spw, kms=False, ratio=False):
    """
    Returns the effective bandwidth of a channel (in Hz or km/s)
    of the specified measurement set and spw ID (or list of IDs).
    Mostly obsoleted in CASA 4.6 by msmd.chaneffbws.
    kms: if True, then return the value in km/s (otherwise Hz)
    ratio: if True, then divide the value by the physical bandwidth
    To see this information for an ASDM, use 
       printLOsFromASDM(showEffective=True)
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or its SPECTRAL_WINDOW table)."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW')
    if (type(spw) != list and type(spw) != np.ndarray):
        spws = [int(spw)]
    else:
        spws = [int(s) for s in spw]
    bws = []
    for spw in spws:
        bw = np.median(mytb.getcell('EFFECTIVE_BW', spw))
        if ratio:
            phys = abs(np.median(mytb.getcell('CHAN_WIDTH', spw)))
            bw /= phys
        elif kms:
            bw = c_mks*0.001*bw/np.median(mytb.getcell('CHAN_FREQ',spw))
        bws.append(bw)
    mytb.close()
    if (len(bws) == 1):
        bws = bws[0]
    return bws

def effectiveResolutionASDM(asdm, spw, kms=False, ratio=False):
    """
    Returns the effective resolution of a channel (in Hz or km/s)
    of the ASDM spw ID (or list of IDs).  The spw is mapped from 
    measurement set space to ASDM space before retrieving it.
    kms: if True, then return the value in km/s (otherwise Hz)
    ratio: if True, then divide the value by the physical bandwidth
    An alternative to see this information for all spws at once, use 
       printLOsFromASDM(showEffective=True)
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (not os.path.exists(asdm+'/SpectralWindow.xml')):
        print "Could not find SpectralWindow.xml."
        return
    mydict = getSpwsFromASDM(asdm)
    if spw not in mydict.keys():
        print "spw %d is not in this ASDM" % (spw)
        return
    effbw = mydict[spw]['resolution']
    if ratio:
        phys = mydict[spw]['chanWidth']
        effbw /= phys
    elif kms:
        effbw = c_mks*0.001*effbw/mydict[spw]['centerFreq']
    return effbw

def effectiveResolution(vis, spw='', kms=False, returnDictionary=False):
    """
    Returns the effective resolution of a channel (in Hz or km/s)
    of the specified measurement set and spw ID.
    Note: For ALMA, this will only be correct for cycle 3 data onward.
    kms: if True, then return the value in km/s (otherwise Hz)
    To see this information for an ASDM, use 
       printLOsFromASDM(showEffective=True)
    -Todd Hunter
    """
    if (not os.path.exists(vis+'/SPECTRAL_WINDOW')):
        print "Could not find ms (or its SPECTRAL_WINDOW table)."
        return
    if spw == '':
        spws = getScienceSpws(vis,returnString=False)
    elif (type(spw) != list and type(spw) != np.ndarray):
        spws = [int(spw)]
    else:
        spws = [int(s) for s in spw]
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/SPECTRAL_WINDOW')
    bws = []
    bwdict = {}
    for spw in spws:
        bw = np.median(mytb.getcell('RESOLUTION',spw))
        if kms:
            bw = c_mks*0.001*bw/np.median(mytb.getcell('CHAN_FREQ',spw))
        bws.append(bw)
        bwdict[spw] = bw
    mytb.close()
    if (len(bws) == 1):
        bws = bws[0]
    if returnDictionary:
        return bwdict
    else:
        return bws

def velocityResolution(vis, spw='', hanning=True):
    """
    Returns the value (or array) of velocity resolutions (in km/s) for the 
    specified measurement set and spw (or spw list), accounting for 
    online-Hanning smoothing.  Note: Hanning is assumed, it is not
    checked that it was turned on.  Use au.effectiveResolution for
    ALMA data from Cycle 3 onward.
    hanning: if False, then you will get the channel width in km/s
    -Todd Hunter
    """
    obs = getObservatoryName(vis)
    if obs in ['ALMA','ACA']:
        if surmiseCycle(vis) >= 3:
            print "Since these are ALMA data of cycle>=3, you should instead use au.effectiveResolution('%s',spw='%s',kms=True)." % (vis,str(spw))
            return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    chanwidths = getChanWidths(mymsmd, spw)
    meanfreqs = getMeanFreqs(mymsmd, spw)
    mymsmd.close()
    resolutions = np.abs(c_mks*0.001*chanwidths/meanfreqs)
    if (hanning):
        resolutions *= 2
    if (len(resolutions) == 1):
        resolutions = resolutions[0]
    return(resolutions)
    
def extractAzimuthalAverageFromImage(image1,image2=None,image3=None,center=None,
                                     binsize=1.0, xlimits=[0,0], panels=1,
                                     mirror=False, peakimage=None, channel=0,
                                     stokes='XX', showplot=True, outfile='',
                                     plotfile='', normalize=True,
                                     scaleToArcsec=True, useimfit=True,
                                     interpolateToZero=False, maxradius=180):
    """
    A front-end function for azimuthalAverage.  Used to create the ALMA beam
    radial profiles from the TICRA models that will be used in CASA 4.3. 
    image1: the image to analyze
    image2: an optional second image to include as another column in the output
    image3: an optional third image to include as another column in the output
    center: the point about which to compute the average (default = image center)
    binsize: passed to azimuthalAverage
    xlimits: the x-axis limits to use if showplot==True
    panels: if 2, then also show intensity in dB in a second plot panel
    mirror: reflect the profile about x=0
    peakimage: the image for which to automatically find the peak to use as center
    channel: the channel of the peakimage to use
    stokes: the polarization product of the peak image to use ('XX', 'XY, 'YX', or 'YY')
    showplot: if True, open a graphics window showing the profile
    outfile: the text file to write the profile to
    plotfile: the graphics file to generate
    normalize: if True, then divide profiles by peak of peakimage
    scaleToArcsec: if True, read cdelt2 from image1 and scale x-axis by this value in arcsec
    useimfit: if True, use imfit instead of imstat to find the peak of peakimage
    interpolateToZero: insert an entry at radius=0 as avg of 0th and 1st order extrapolation
    maxradius: stop writing to outfile beyond this point (in arcsec if scaleToArcsec==True)
    - Todd Hunter.
    """
    pp = ['XX','XY','YX','YY']
    if (stokes not in pp):
        print "Invalid stokes, must be one of: ", pp
        return
    stokesPlane = pp.index(stokes)
    if (peakimage is not None):
        myia = createCasaTool(iatool)
        myia.open(peakimage)
        imgPeak = myia.getregion()
        myia.close()
        if (len(np.shape(imgPeak)) < 3):
            if (useimfit):
                center = findRADec(peakimage, ' '.join(imfitparse(imfit(peakimage)).split()[:2]))
                x,z = azimuthalAverage(peakimage, center=center, binsize=binsize, returnradii=True,
                                       interpolateToZero=interpolateToZero)
                peak = np.nanmax(z)
            else:
                center = imstat(peakimage)['maxpos']
                peak = imstat(peakimage)['max']
        else:
            if (useimfit):
                center = findRADec(peakimage, ' '.join(imfitparse(imfit(peakimage,stokes=stokes,
                                                                        chans=str(channel))).split()[:2]))
                x,z = azimuthalAverage(peakimage, center=center, binsize=binsize, returnradii=True,
                                       axis3=stokesPlane, axis4=channel, interpolateToZero=interpolateToZero)
                peak = np.nanmax(z)
            else:
                center = imstat(peakimage)['maxpos']
                peak = imstat(peakimage,stokes=stokes,chans=str(channel))['max']
        print "Using center = ", center
    else:
        if (normalize):
            print "You must specify peakimage if normalize=True"
            return
    x,y = azimuthalAverage(image1, center=center, binsize=binsize, returnradii=True,
                           axis3=stokesPlane, axis4=channel, interpolateToZero=interpolateToZero)
    if (scaleToArcsec):
        header = imhead(image1,mode='list')
        arcsecPerPixel = headerToArcsec(header['cdelt2'], header['cunit2'])
        x *= arcsecPerPixel
        xaxisLabel = 'Radius (arcsec)'
    else:
        arcsecPerPixel = 1.0
        xaxisLabel = 'Radius (pixels)'        
    if (normalize):
        print "peak = ", peak
        y /= peak
    if (image2 is not None):
        x2,z = azimuthalAverage(image2, center=center, binsize=binsize, returnradii=True,
                                axis3=stokesPlane, axis4=channel, interpolateToZero=interpolateToZero)
        x2 *= arcsecPerPixel
        if (normalize):
            z /= peak
        if (np.array_equal(x,x2) == False):
            print "x1/x2 axes differ!"
        if (image3 is not None):
            x3,u = azimuthalAverage(image3, center=center, binsize=binsize,
                              returnradii=True, axis3=stokesPlane,
                              axis4=channel, interpolateToZero=interpolateToZero)
            x3 *= arcsecPerPixel
            if (normalize):
                u /= peak
            if (np.array_equal(x,x3) == False):
                print "x1/x3 axes differ!"
    if (mirror):
        idx = np.argsort(-x)
        y = np.array(list(y[idx]) + list(y[1:]))     # -3,-2,-1,0  + 1,2,3
        x = np.array(list(sorted(-x)) + list(x[1:])) # -3,-2,-1,0  + 1,2,3
    if (outfile == ''):
        outfile = image1.strip('.real').strip('.imag') + '.' + stokes + '.radialProfile'
    f = open(outfile,'w')
    if (image2 is None):
        f.write('R(arcsec)  Intensity\n')
    elif (image3 is None):
        f.write('R(arcsec)  Real  Imag\n')
    else:
        f.write('R(arcsec)  Real  Imag  Amplitude\n')
    for i in range(len(x)):
        if (x[i] < maxradius):
            if (image2 is None):
                f.write('%f %f\n' % (x[i],y[i]))
            elif (image3 is None):
                f.write('%f %f %f\n' % (x[i],y[i],z[i]))
            else:
                f.write('%f %f %f %f\n' % (x[i],y[i],z[i],u[i]))
    f.close()
    if (showplot):
        pb.clf()
        adesc = pb.subplot(panels,1,1)
        pb.plot(x,y,'bo-')
        pb.title(os.path.basename(image1), size=12, color='b')
        if (image2 is not None):
            pb.hold(True)
            pb.plot(x,z,'ro-')
            pb.text(0.0,1.045,os.path.basename(image2),transform=adesc.transAxes,
                    size=11,color='r')
        if (image3 is not None):
            pb.hold(True)
            pb.plot(x,u,'go-')
            pb.text(0.0,1.08,os.path.basename(image3),transform=adesc.transAxes,
                    size=11,color='g')
        pb.ylabel('Relative intensity of Stokes '+stokes)
        pb.xlabel(xaxisLabel)
        if (xlimits != [0,0]):
            pb.xlim(xlimits)
        if (panels > 1):
            pb.subplot(panels,1,2)
            pb.plot(x,10*np.log10(y),'bo-')
            pb.xlabel(xaxisLabel)
        if (xlimits != [0,0]):
            pb.xlim(xlimits)
        pb.draw()
        if (plotfile != ''):
            pb.savefig(plotfile)
    return(x,y)

def azimuthalAverage(myimage, center=None, stddev=False, returnradii=False,
                     return_nr=False, binsize=0.5, weights=None, steps=False,
                     interpnan=False, left=None, right=None,
                     mask=None, axis3=0, axis4=0, interpolateToZero=False):
    """
    Calculate the azimuthally averaged radial profile.
    Originally taken from Adam Ginsburg's agpy, but expanded to have the
    parameters axis3, axis4 and interpolateToZero.

    myimage - filename of 2D, 3D or 4D image, with sky coords as the first 2 axes
    axis3 - which pixel to use on the 3rd axis (default=0)
    axis4 - which pixel to use on the 4th axis (default=0)
    center - The [x,y] pixel coordinates used as the center. The default is 
             None, which then uses the center of the image (including 
             fractional pixels).
    stddev - if specified, return the azimuthal st.dev. instead of the average
    returnradii - if specified, return (radii_array,radial_profile)
    return_nr   - if specified, return number of pixels per radius *and* radius
    binsize - size of the averaging bin.  Can lead to strange results if
        non-binsize factors are used to specify the center and the binsize is
        too large
    weights - can do a weighted average instead of a simple average if this
              keyword parameter is set.  weights.shape must = image.shape.
              weighted stddev is undefined, so don't set weights and stddev.
    steps - if specified, will return a double-length bin array and radial
        profile so you can plot a step-form radial profile (which more accurately
        represents what's going on)
    interpnan - Interpolate over NAN values, i.e. bins where there is no data?
        left,right - passed to interpnan; they set the extrapolated values
    mask - can supply a mask (boolean array same size as image with True for OK
           and False for not) to average over only select data.

    If a bin contains NO DATA, it will have a NAN value because of the
    divide-by-sum-of-weights component.  I think this is a useful way to denote
    lack of data, but users let me know if an alternative is preferred...
    """
    # Calculate the indices from the image
    myia = createCasaTool(iatool)
    myia.open(myimage)
    img = myia.getregion()
    if (len(img.shape) == 3):
        img = img[:,:,axis3]
    if (len(img.shape) == 4):
        img = img[:,:,axis3,axis4]
    myia.close()
    y,x = np.indices(img.shape)

    if center is None:
        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])

    r = np.hypot(x - center[0], y - center[1])

    if weights is None:
        weights = np.ones(img.shape)
    elif stddev:
        raise ValueError("Weighted standard deviation is not defined.")

    if mask is None:
        mask = np.ones(img.shape,dtype='bool')
    # obsolete elif len(mask.shape) > 1:
    # obsolete     mask = mask.ravel()

    # the 'bins' as initially defined are lower/upper bounds for each bin
    # so that values will be in [lower,upper)  
    nbins = int(np.round(r.max() / binsize)+1)
    maxbin = nbins * binsize
    bins = np.linspace(0,maxbin,nbins+1)
    # but we're probably more interested in the bin centers than their left
    # or right sides...
    bin_centers = (bins[1:]+bins[:-1])/2.0

    # how many per bin (i.e., histogram)?
    # there are never any in bin 0, because the lowest index returned by
    # digitize is 1
    #nr = np.bincount(whichbin)[1:]
    nr = np.histogram(r,bins)[0]

    # recall that bins are from 1 to nbins (which is expressed in array terms
    # by arange(nbins)+1 or xrange(1,nbins+1) )
    # radial_prof.shape = bin_centers.shape
    if stddev:
        # Find out which radial bin each point in the map belongs to
        whichbin = np.digitize(r.flat,bins)
        # This method is still very slow; is there a trick to do this with histograms? 
        radial_prof = np.array([img.flat[mask.flat*(whichbin==b)].std() for b in xrange(1,nbins+1)])
    else: 
        radial_prof = np.histogram(r, bins, weights=(img*weights*mask))[0] / np.histogram(r, bins, weights=(mask*weights))[0]

    if interpnan:
        radial_prof = np.interp(bin_centers,bin_centers[radial_prof==radial_prof],radial_prof[radial_prof==radial_prof],left=left,right=right)

    if steps:
        xarr = np.array(zip(bins[:-1],bins[1:])).ravel() 
        yarr = np.array(zip(radial_prof,radial_prof)).ravel() 
        return xarr,yarr
    elif returnradii:
        if (interpolateToZero and bin_centers[0] != 0):
            if (False):
                myspline = scipy.interpolate.UnivariateSpline(bin_centers[:4],radial_prof[:4],s=0)
                intercept = myspline(0.0)
                print "intercept = ", intercept
            else:
                slope = (radial_prof[1]-radial_prof[0]) / (bin_centers[1]-bin_centers[0])
                intercept = radial_prof[1] - slope*bin_centers[1]
                intercept = 0.5*(intercept + radial_prof[0])  # avg of 0th and 1st order extrapolation
            bin_centers = np.append(np.array([0.0]),bin_centers)
            radial_prof = np.append(np.array([intercept]), radial_prof)
        return bin_centers,radial_prof
    elif return_nr:
        return nr,bin_centers,radial_prof
    else:
        return radial_prof

def framesPlot(ra="05:00:00", dec="-30:00:00", year=2016, observatory='ALMA',
               plotfile='lsrk-topo_vs_doy.png',increment=1.0,markdate='',
               markdate2='',prec=6, plotrange=[0,0,0,0], derivative=False):
    """
    Calls au.frames each day for a year and plots the result.
    increment: in days
    markdate, markdate2: only valid for derivative=False
       Input date format: 2011/10/15 05:00:00  or   2011/10/15-05:00:00
                       or 2011-10-15 05:00:00  or   2011-10-15-05:00:00
                       or 2011-10-15T05:00:00  or   2011-Oct-15 etc.
    -Todd Hunter
    """
    kmsec = []
    doys = np.arange(1,366,float(increment))
    myme = createCasaTool(metool)
    myqa = createCasaTool(qatool)
    for doy in doys:
        datestring = dateFromDoy(year, doy, hms=True)
        topo, vDiff, fDiff = frames(0,datestring,ra,dec,observatory=observatory,
                            prec=prec,verbose=False,myme=myme,myqa=myqa)
        kmsec.append(vDiff)
    pb.clf()
    amplitude = 0.5*(np.max(kmsec)-np.min(kmsec))
    desc = pb.subplot(111)
    if (derivative):
        incrementHours = increment*24.0
        kmsec = np.diff(kmsec)/incrementHours
        pb.plot(doys[:-1], kmsec, 'k-')
        pb.ylabel('Delta(LSRK-TOPO) (km/s/hr)')
    else:
        pb.plot(doys, kmsec, 'k-')
        pb.ylabel('LSRK-TOPO (km/s)')
    pb.xlabel('Day of year %d'%year)
    pb.xlim([doys[0],doys[-1]])
    if (markdate != '' and not derivative):
        marks = []
        diffs = []
        markdate = [markdate]
        marks.append(doyFromDate(markdate[0],fractional=True))
        print "markdate = ", marks[-1]
        topo, vdiff, fdiff = frames(0,markdate[0],ra,dec,observatory=observatory,
                            verbose=False,prec=prec,myme=myme,myqa=myqa)
        diffs.append(vdiff)
        if (markdate2 != ''):
            markdate.append(markdate2)
            marks.append(doyFromDate(markdate2,fractional=True))
            print "markdate2 = ", marks[-1]
            topo, vdiff, fdiff = frames(0,markdate2,ra,dec,observatory=observatory,
                                        verbose=False,prec=prec,myme=myme,myqa=myqa)
            diffs.append(vdiff)
        print "marks=", marks
        print "diffs=", diffs
        pb.plot(marks,diffs,'ko')
        for i,mark in enumerate(marks):
            pb.text(0.5,0.90-i*0.05,'%.2f = %s'%(mark,markdate[i]),
                    transform=desc.transAxes, ha='center')
    pb.title('RA=%s, Dec=%s from %s'%(ra,dec,observatory))
    pb.text(0.5,0.95,'annual amplitude=%.2fkm/s'%amplitude, ha='center', transform=desc.transAxes)
    if (plotrange[:2] != [0,0]):
        pb.xlim(plotrange[:2])
    if (plotrange[-2:] != [0,0]):
        pb.ylim(plotrange[-2:])
    pb.savefig(plotfile)
    pb.draw()
    myme.done()
    myqa.done()
    print "Plot left in ", plotfile

def topoToRest(topoFrequency, velocityLSRK, datestring, ra, dec, equinox='J2000', 
               observatory='ALMA', prec=4, verbose=False):
    """
    Converts a topocentric frequency, LSRK velocity, and observing date/direction
    to the corresponding rest frequency.
    Inputs:
    topoFrequency: floating point value in Hz or GHz, or a string with units
    velocityLSRK: floating point value in km/s
    datestring:  "YYYY/MM/DD/HH:MM:SS"
    ra: string "HH:MM:SS.SSSS"   or floating point value in radians
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    Returns: the rest frequency in Hz
    -Todd Hunter
    """
    if (type(dec) == str):
        if (dec.find(':') >= 0):
            dec = dec.replace(':','.')
            if verbose:
                print "Warning: replacing colons with decimals in the dec field."
    topoGHz = parseFrequencyArgumentToGHz(topoFrequency)
    myqa = createCasaTool(qatool)
    myme = createCasaTool(metool)
    velocityRadio = create_casa_quantity(myqa, velocityLSRK,"km/s")
    if (type(ra) != str):
        position = myme.direction(equinox, '%.12frad'%(ra), '%.12frad'%(dec))
    else:
        position = myme.direction(equinox, ra, dec)
    obstime = myme.epoch('TAI', datestring)
    dopp = myme.doppler("RADIO",velocityRadio)
    radialVelocityLSRK = myme.toradialvelocity("LSRK",dopp)
    myme.doframe(position)
    myme.doframe(myme.observatory(observatory))
    myme.doframe(obstime)
    rvelTopo = myme.measure(radialVelocityLSRK,'TOPO')
    doppTopo = myme.todoppler('RADIO', rvelTopo)
    freqRad = myme.torestfrequency(me.frequency('TOPO',str(topoGHz)+'GHz'), doppTopo)
    if verbose:
        print "REST freq = %s = %.13f GHz" % (myqa.tos(freqRad['m0'],prec=prec), freqRad['m0']['value']*1e-9)
    myqa.done()
    myme.done()
    return freqRad['m0']['value']

def restToTopo(restFrequency, velocityLSRK, datestring, ra, dec, equinox='J2000', 
               observatory='ALMA', veltype='radio', verbose=False):
    """
    Converts a rest frequency, LSRK velocity, and observing date/direction
    to the corresponding frequency in the TOPO frame.
    Inputs:
    restFrequency: floating point value in Hz or GHz, or a string with units
    velocityLSRK: floating point value in km/s
    datestring:  "YYYY/MM/DD/HH:MM:SS"
    ra: string "HH:MM:SS.SSSS"
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    Returns: the TOPO frequency in Hz
    -Todd Hunter
    """
    topoFreqHz, diff1, diff2 = frames(velocityLSRK, datestring, ra, dec, equinox, 
                                      observatory, verbose=verbose,
                                      restFreq=restFrequency, veltype=veltype)
    return topoFreqHz

def cubeFrame(img):
    """
    Uses imhead to return the velocity frame of a cube (e.g. LSRK)
    img: a CASA or FITS cube
    -Todd Hunter
    """
    header = imheadlist(img, omitBeam=True)
    if ('reffreqtype' in header.keys()):
        return header['reffreqtype'].upper()
    else:
        print "No reffreqtype entry in the header"
        return ''

def cubeTopoToLSRK(img, freqrange='', prec=4, verbose=False, force=False):
    """
    Reads the date of observation, central RA and Dec,
    and observatory from an image cube header and then calls topoToLSRK to
    return the corresponding frequency range in LSRK.
    freqrange: desired range of frequencies (empty string or list = whole cube)
          floating point list of two frequencies, or a delimited string 
          (delimiter = ',', '~' or space)
    prec: precision in fractions of Hz (only used to display the value 
          in subfunctions and only when verbose=True)
    force: do the calculation even if the cube appears to be in LSRK
    -Todd Hunter
    """
    header = imheadlist(img, omitBeam=True)
    if ('reffreqtype' in header.keys()):
        if (header['reffreqtype'].upper() == 'LSRK'):
            print "This cube is purportedly already in LSRK."
            if (not force): return
    nchan,f0,f1,chanwidth = numberOfChannelsInCube(img, returnFreqs=True, returnChannelWidth=True)
    if len(freqrange) == 0:
        # convert from edge channel center to edge channel center, to edge-to-edge
        startFreq = f0 - chanwidth/2.
        stopFreq = f1 + chanwidth/2.
    elif (type(freqrange) == str):
        if (freqrange.find(',') > 0):
            freqrange = [float(i) for i in freqrange.split(',')]
        elif (freqrange.find('~') > 0):
            freqrange = [float(i) for i in freqrange.split('~')]
        else:
            freqrange = [float(i) for i in freqrange.split()]
        startFreq, stopFreq = freqrange
    else:
        startFreq, stopFreq = freqrange
    ra,dec = rad2radec(header['crval1'], header['crval2'],
                       delimiter=' ', verbose=False).split()
    equinox = header['equinox']
    observatory = header['telescope']
    datestring = header['date-obs']
    f0 = topoToLSRK(startFreq, datestring, ra, dec, equinox, observatory, prec, verbose)
    f1 = topoToLSRK(stopFreq, datestring, ra, dec, equinox, observatory, prec, verbose) 
    return(np.array([f0,f1]))

def cubeLSRKToTopo(img, freqrange='', prec=4, verbose=False, force=False):
    """
    Reads the date of observation, central RA and Dec,
    and observatory from an image cube header and then calls lsrkToTopo to
    return the specified frequency range in TOPO.
    freqrange: desired range of frequencies (empty string or list = whole cube)
          floating point list of two frequencies, or a delimited string
          (delimiter = ',', '~' or space)
    prec: in fractions of Hz (only used to display the value when verbose=True)
    force: do the calculation even if the cube appears to be in TOPO
    -Todd Hunter
    """
    header = imheadlist(img, omitBeam=True)
    if ('reffreqtype' in header.keys()):
        if (header['reffreqtype'].upper() == 'TOPO'):
            print "This cube is purportedly already in TOPO."
            if (not force): return
    nchan,f0,f1,chanwidth = numberOfChannelsInCube(img, returnFreqs=True, returnChannelWidth=True)
    if len(freqrange) == 0:
        # convert from edge channel center to edge channel center, to edge-to-edge
        startFreq = f0 - chanwidth/2.
        stopFreq = f1 + chanwidth/2.
    elif (type(freqrange) == str):
        if (freqrange.find(',') > 0):
            freqrange = [float(i) for i in freqrange.split(',')]
        elif (freqrange.find('~') > 0):
            freqrange = [float(i) for i in freqrange.split('~')]
        else:
            freqrange = [float(i) for i in freqrange.split()]
        startFreq, stopFreq = freqrange
    else:
        startFreq, stopFreq = freqrange
    ra,dec = rad2radec(header['crval1'], header['crval2'],
                       delimiter=' ', verbose=False).split()
    equinox = header['equinox']
    observatory = header['telescope']
    datestring = header['date-obs']
    f0 = lsrkToTopo(startFreq, datestring, ra, dec, equinox, observatory, prec, verbose)
    f1 = lsrkToTopo(stopFreq, datestring, ra, dec, equinox, observatory, prec, verbose) 
    return(np.array([f0,f1]))

def spwToLSRK(vis, field='', spw='', intent='OBSERVE_TARGET#ON_SOURCE', 
              units='GHz'):
    """
    Returns a dictionary of the LSRK frequencies of the spws of a measurement
    set, keyed by spw ID, with values: 'mean', 'min', 'max'
    spw: integer, string ID, or python list of IDs
    units: 'Hz' or 'GHz'
    -Todd Hunter
    """
    if not os.path.exists(vis):
        print "Could not find measurement set."
        return
    mymsmd = createCasaTool(msmdtool)
    datestring = getObservationStartDate(vis, measuresToolFormat=True)
    mymsmd.open(vis)
    observatory = mymsmd.observatorynames()[0]
    if (field == ''):
        field = mymsmd.fieldsforintent(intent)
        if (len(field) == 0):
            print "No fields with that intent"
            return
        else:
            field = field[0]
            print "Using field %d" % field
    result = getRADecForField(vis, field, returnReferenceFrame=True)
    if result==None: return
    radec, equinox = result
    ra = radec[0][0]
    dec = radec[1][0]
    if (spw == ''):
        spw = mymsmd.spwsforintent(intent)
        almaspws = mymsmd.almaspws(tdm=True,fdm=True)
        if (len(almaspws) > 0):
            spw = np.intersect1d(spw,almaspws)
    elif type(spw) == str:
        spw = [int(i) for i in spw.split(',')]
    elif type(spw) != list and type(spw) != np.ndarray:
        spw = [spw]
    else:
        spw = [int(i) for i in spw]
    freq = {}
    if units == 'GHz':
        scale = 1e-9
    else:
        scale = 1
    for s in spw:
        freq[s] = {}
        freq[s]['mean'] = topoToLSRK(mymsmd.meanfreq(s), datestring, 
                                     ra, dec, equinox, observatory)*scale
        freq[s]['min'] = topoToLSRK(np.min(mymsmd.chanfreqs(s)), datestring, 
                                    ra, dec, equinox, observatory)*scale
        freq[s]['max'] = topoToLSRK(np.max(mymsmd.chanfreqs(s)), datestring, 
                                    ra, dec, equinox, observatory)*scale
        freq[s]['chanwidth'] = topoToLSRK((np.max(mymsmd.chanfreqs(s)) - np.min(mymsmd.chanfreqs(s)))/(mymsmd.nchan(s)-1), datestring, 
                                    ra, dec, equinox, observatory)*scale
    mymsmd.close()
    return freq

def topoChannelToLSRK(vis, spw, channel, field, restfreq=None, verbose=True):
    """
    Computes the LSRK frequency of the specified visibility channel for the
    specified field.
    field: can be integer or string intger or string name
    restfreq: if specified, then compute the LSRK velocity instead.
              Value can be floating point GHz or Hz, or a string with units.
    """
    if not os.path.exists(vis):
        print "Could not find ms"
        return
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    radec, equinox = getRADecForField(vis, field, hms=True, mymsmd=mymsmd, returnReferenceFrame=True)
    ra,dec = radec.split(',')
    datestring = getObservationStartDate(vis, measuresToolFormat=True) # uses tb tool
    freq = mymsmd.chanfreqs(spw)[channel]
    width = mymsmd.chanwidths(spw)[channel]
    observatory = getObservatoryName(vis) # uses tb tool
    lsrkFreq = topoToLSRK(freq, datestring, ra, dec, equinox, observatory)
    lsrkWidth = width * lsrkFreq/freq
    mymsmd.close()
    if verbose:
        print "TOPO: center= %.9f GHz, edges: ( %.9f - %.9f )" % (freq*1e-9, (freq-width)*1e-9, (freq+width)*1e-9)
        print "LSRK: center= %.9f GHz, edges: ( %.9f - %.9f )" % (lsrkFreq*1e-9, (lsrkFreq-lsrkWidth)*1e-9, (lsrkFreq+lsrkWidth)*1e-9)
    if restfreq is not None:
        restFreqHz = parseFrequencyArgumentToHz(restfreq)
        lsrkVelocity = c_mks*(1-lsrkFreq/restFreqHz)*0.001
        return lsrkVelocity
    else:
        return lsrkFreq

def topoToLSRK(topoFrequency, datestring, ra, dec, equinox='J2000', 
               observatory='ALMA', prec=4, verbose=False):
    """
    Converts a topocentric frequency and observing date/direction to the
    corresponding frequency in the LSRK frame. See topoChannelToLSRK to
    convert a specific channel in a measurement set.
    Inputs:
    topoFrequency: floating point value in Hz or GHz, or a string with units
    datestring:  "YYYY/MM/DD/HH:MM:SS" (format = image header keyword 'date-obs')
    ra: string "HH:MM:SS.SSSS"
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    equinox: typically 'J2000 or 'ICRS', see me.listcodes(me.direction()) for list
    Returns: the LSRK frequency in Hz
    -Todd Hunter
    """
    velocityLSRK = 0  # does not matter what it is, just needs to be same in both calls
    restFreqHz = topoToRest(topoFrequency, velocityLSRK, datestring, ra, dec, 
                            equinox, observatory, prec, verbose)
    lsrkFrequencyHz = restToLSRK(restFreqHz, velocityLSRK, datestring, ra, dec,
                                 equinox, observatory, prec, verbose)
    return lsrkFrequencyHz

def lsrkToTopo(lsrkFrequency, datestring, ra, dec, equinox='J2000', observatory='ALMA', 
               prec=4, verbose=False):
    """
    Converts an LSRKfrequency and observing date/direction
    to the corresponding frequency in the TOPO frame.
    Inputs:
    lsrkFrequency: floating point value in Hz or GHz, or a string with units
    datestring:  "YYYY/MM/DD/HH:MM:SS" (format = image header keyword 'date-obs')
    ra: string "HH:MM:SS.SSSS"
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    Returns: the TOPO frequency in Hz
    -Todd Hunter
    """
    velocityLSRK = 0  # does not matter what it is, just needs to be same in both calls
    restFreqHz = lsrkToRest(lsrkFrequency, velocityLSRK, datestring, ra, dec, equinox,
                            observatory, prec, verbose)
    topoFrequencyHz = restToTopo(restFreqHz, velocityLSRK, datestring, ra, dec, equinox, 
                                observatory, verbose=verbose)
    return topoFrequencyHz

def restToLSRK(restFrequency, velocityLSRK, datestring, ra, dec, 
               equinox='J2000', observatory='ALMA', prec=4, verbose=True):
    """
    Converts a rest frequency, LSRK velocity, and observing date/direction
    to the corresponding frequency in the LSRK frame.
    Inputs:
    restFrequency: floating point value in Hz or GHz, or a string with units
    velocityLSRK: floating point value in km/s
    datestring:  "YYYY/MM/DD/HH:MM:SS" (format = image header keyword 'date-obs')
    ra: string "HH:MM:SS.SSSS"
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    Returns: the LSRK frequency in Hz
    -Todd Hunter
    """
    if (type(dec) == str):
        if (dec.find(':') >= 0):
            dec = dec.replace(':','.')
            if verbose:
                print "Warning: replacing colons with decimals in the dec field."
    freqGHz = parseFrequencyArgumentToGHz(restFrequency)
    myqa = createCasaTool(qatool)
    myme = createCasaTool(metool)
    velocityRadio = create_casa_quantity(myqa,velocityLSRK,"km/s")
    if (type(ra) != str):
        position = myme.direction(equinox, '%.12frad'%(ra), '%.12frad'%(dec))
    else:
        position = myme.direction(equinox, ra, dec)
    obstime = myme.epoch('TAI', datestring)
    dopp = myme.doppler("RADIO",velocityRadio)
    radialVelocityLSRK = myme.toradialvelocity("LSRK",dopp)
    myme.doframe(position)
    myme.doframe(myme.observatory(observatory))
    myme.doframe(obstime)
    rvelRad = myme.measure(radialVelocityLSRK,'LSRK')
    doppRad = myme.todoppler('RADIO', rvelRad)
    freqRad = myme.tofrequency('LSRK', doppRad, me.frequency('REST',str(freqGHz)+'GHz'))
    if verbose:
        rvelTopo = myme.measure(radialVelocityLSRK,'TOPO')
        doppTopo = myme.todoppler('RADIO', rvelTopo)
        freqTopo = myme.tofrequency('TOPO', doppTopo, me.frequency('REST',str(freqGHz)+'GHz'))
        print myme.showframe()
        print "LSRK freq = %s = %.13f GHz" % (myqa.tos(freqRad['m0'],prec=prec), freqRad['m0']['value']*1e-9)
    #   print "LSRK doppshift = %s = %.7f km/s" % (myqa.tos(doppRad['m0'],prec=prec), doppRad['m0']['value']*0.001)
        print "TOPO freq = %s = %.13f GHz" % (myqa.tos(freqTopo['m0'],prec=prec), freqTopo['m0']['value']*1e-9)
        print "TOPO doppshift = %s = %.7f km/s" % (myqa.tos(doppTopo['m0'],prec=prec), doppTopo['m0']['value']*0.001)
    myqa.done()
    myme.done()
    return freqRad['m0']['value']

def lsrkToRest(lsrkFrequency, velocityLSRK, datestring, ra, dec, 
               equinox='J2000', observatory='ALMA', prec=4, verbose=True):
    """
    Converts an LSRK frequency, LSRK velocity, and observing date/direction
    to the corresponding frequency in the rest frame.
    Inputs:
    lsrkFrequency: floating point value in Hz or GHz, or a string with units
    velocityLSRK: floating point value in km/s
    datestring:  "YYYY/MM/DD/HH:MM:SS" (format = image header keyword 'date-obs')
    ra: string "HH:MM:SS.SSSS"   or floating point value in radians
    dec: string "DD.MM.SS.SSSS" or "DD:MM:SS.SSSS" (colons will be replaced with .)
    prec: only used to display the value when verbose=True
    Returns: the Rest frequency in Hz
    -Todd Hunter
    """
    if (type(dec) == str):
        if (dec.find(':') >= 0):
            dec = dec.replace(':','.')
            if verbose:
                print "Warning: replacing colons with decimals in the dec field."
    freqGHz = parseFrequencyArgumentToGHz(lsrkFrequency)
    myqa = createCasaTool(qatool)
    myme = createCasaTool(metool)
    velocityRadio = create_casa_quantity(myqa,velocityLSRK,"km/s")
    if (type(ra) != str):
        position = myme.direction(equinox, '%.12frad'%(ra), '%.12frad'%(dec))
    else:
        position = myme.direction(equinox, ra, dec)
    obstime = myme.epoch('TAI', datestring)
    dopp = myme.doppler("RADIO",velocityRadio)
    radialVelocityLSRK = myme.toradialvelocity("LSRK",dopp)
    myme.doframe(position)
    myme.doframe(myme.observatory(observatory))
    myme.doframe(obstime)
    rvelRad = myme.measure(radialVelocityLSRK,'LSRK')
    doppRad = myme.todoppler('RADIO', rvelRad)
    freqRad = myme.torestfrequency(me.frequency('LSRK',str(freqGHz)+'GHz'), dopp)
    myqa.done()
    myme.done()
    return freqRad['m0']['value']

def frames(velocity=286.7, datestring="2005/11/01/00:00:00",
           ra="05:35:28.105", dec="-069.16.10.99", equinox="J2000", 
           observatory="ALMA", prec=4, verbose=True, myme='', myqa='',
           restFreq=345.79599, veltype='optical'):
    """
    Converts an optical velocity into barycentric, LSRK and TOPO frames.
    Converts a radio LSRK velocity into TOPO frame.
    Inputs:
    velocity: in km/s
    datestring:  "YYYY/MM/DD/HH:MM:SS"
    ra: "05:35:28.105"
    dec: "-069.16.10.99"
    equinox: "J2000" 
    observatory: "ALMA"
    prec: precision to display (digits to the right of the decimal point)
    veltype: 'radio' or 'optical'
    restFreq: in Hz, GHz or a string with units
    Returns: 
    * TOPO frequency in Hz
    * difference between LSRK-TOPO in km/sec
    * difference between LSRK-TOPO in Hz
    - Todd Hunter
    """
    localme = False
    localqa = False
    if (myme == ''):
        myme = createCasaTool(metool)
        localme = True
    if (myqa == ''):
        myqa = createCasaTool(qatool)
        localqa = True
    
    if (dec.find(':') >= 0):
        dec = dec.replace(':','.')
        if verbose:
            print "Warning: replacing colons with decimals in the dec field."
    position = myme.direction(equinox, ra, dec)
    obstime = myme.epoch('TAI', datestring)

    if (veltype.lower().find('opt') == 0):
        velOpt = create_casa_quantity(myqa,velocity,"km/s")
        dopp = myme.doppler("OPTICAL",velOpt)
        # CASA doesn't do Helio, but difference to Bary is hopefully small
        rvelOpt = myme.toradialvelocity("BARY",dopp)
    elif (veltype.lower().find('rad') == 0):
        rvelOpt = myme.radialvelocity('LSRK',str(velocity)+'km/s')
    else:
        print "veltype must be 'rad'io or 'opt'ical"
        return

    myme.doframe(position)
    myme.doframe(myme.observatory(observatory))
    myme.doframe(obstime)
    myme.showframe()

    rvelRad = myme.measure(rvelOpt,'LSRK')
    doppRad = myme.todoppler("RADIO",rvelRad)       
    restFreq = parseFrequencyArgumentToGHz(restFreq)
    freqRad = myme.tofrequency('LSRK',doppRad,me.frequency('rest',str(restFreq)+'GHz'))

    lsrk = qa.tos(rvelRad['m0'],prec=prec)
    if verbose:
        if (veltype=='optical'):
            print "optical Doppler vel  = %.4f km/s" % velocity
            print "optical BARY velocity = %s" % qa.tos(rvelOpt['m0'],prec=prec)
        print "radio LSRK  velocity  = %s" % lsrk
        print "radio LSRK doppshift  = %s" % qa.tos(doppRad['m0'],prec=prec)
        print "radio LSRK frequency  = %s = %.13f GHz" % (qa.tos(freqRad['m0'],prec=prec),freqRad['m0']['value']*1e-9)

    rvelTop = myme.measure(rvelOpt,'TOPO')
    doppTop = myme.todoppler("RADIO",rvelTop)       
    freqTop = myme.tofrequency('TOPO',doppTop,me.frequency('rest',str(restFreq)+'GHz'))
    if (localme):
        myme.done()
    if (localqa):
        myqa.done()
    topo = qa.tos(rvelTop['m0'],prec=prec)
    if verbose:
        print "radio TOPO  velocity  = %s" % topo
        print "radio TOPO doppshift  = %s" % qa.tos(doppTop['m0'],prec=prec)
        print "radio TOPO frequency  = %s = %.13f GHz" % (qa.tos(freqTop['m0'],prec=prec),freqTop['m0']['value']*1e-9)
    velocityDifference = 0.001*(rvelRad['m0']['value']-rvelTop['m0']['value'])
    frequencyDifference = freqRad['m0']['value'] - freqTop['m0']['value']
    return(freqTop['m0']['value'], velocityDifference, frequencyDifference)

def airmassToElevation(airmass):
    """
    Converts airmass to elevation in degrees
    -Todd Hunter
    """
    return(180*math.asin(1.0/airmass)/np.pi)

def elevationToAirmass(elevation):
    """
    Converts elevation in degrees to airmass.
    -Todd Hunter
    """
    return(1/np.sin(elevation*np.pi/180.))

def create_casa_quantity(myqatool,value,unit):
    """
    A wrapper to handle the changing ways in which casa quantities are invoked.
    Todd Hunter
    """
    if (type(casac.Quantity) != type):  # casa 4.x
        myqa = myqatool.quantity(value, unit)
    else:  # casa 3.x
        myqa = casac.Quantity(value, unit)
    return(myqa)

def getAtmDetails(at):
    """
    A wrapper to handle the changing ways in which the at tool is accessed.
    Todd Hunter
    """
    if (type(casac.Quantity) == type):  # casa 3.x
        dry = np.array(at.getDryOpacitySpec(0)['dryOpacity'])
        wet = np.array(at.getWetOpacitySpec(0)['wetOpacity'].value)
        TebbSky = []
        n = at.getNumChan()
        for chan in range(n):  # do NOT use numchan here, use n
            TebbSky.append(at.getTebbSky(nc=chan, spwid=0).value)
        TebbSky = np.array(TebbSky)
        # readback the values to be sure they got set
        rf = at.getRefFreq().value
        cs = at.getChanSep().value
    else:  # casa 4.x
        dry = np.array(at.getDryOpacitySpec(0)[1])
        wet = np.array(at.getWetOpacitySpec(0)[1]['value'])
        TebbSky = at.getTebbSkySpec(spwid=0)[1]['value']
        # readback the values to be sure they got set
        rf = at.getRefFreq()['value']
        cs = at.getChanSep()['value']
    return(dry,wet,TebbSky,rf,cs)

def findNullForObservedPlanet(vis, spw='', amplitudeLevelForFirstNull=0.0,
                              intent='*FLUX*', verbose=True):
    """
    Finds the uvdistance (in meters) where the predicted visibility of an
    observed solar system object drops to a specified fractional level.
    vis: measurement set to extract information from
    spw: list of spws (default is all science spws)
    amplitudeLevelForFirstNull: fractional value: 0-1 (can be a list)
    intent: only consider solar system objects with this intent
    Returns: uvdistance (or a list of them)
    -Todd Hunter
    """
    if (type(spw) == str):
        if (len(spw) > 0):
            spw = spw.split(',')
    if (len(spw) == 0):
        spw = getScienceSpws(vis)
    ephemerisFields = getEphemerisFields(vis)
    if (len(ephemerisFields) > 0):
        # flux cal might be a planet
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        fields = mymsmd.fieldsforintent(intent)
        if (len(fields) < 1):
            print "No fields with that intent: ", intent
            return
        fluxcal = mymsmd.namesforfields(fields)[0]
        mymsmd.close()
        if (fluxcal in ephemerisFields):
            angularDiameterArcsec = planet(fluxcal, vis=vis)['angularDiameter']
            frequencyGHz = getMeanFreqOfSpwlist(vis,spw)*1e-9
            if (type(amplitudeLevelForFirstNull) != list):
                amplitudeLevelForFirstNull = [amplitudeLevelForFirstNull]
            uvmax = []
            for amp in amplitudeLevelForFirstNull:
                uvmax.append(findNull(angularDiameterArcsec, amplitude=amp, frequency=frequencyGHz, verbose=verbose))
            if len(uvmax) == 1:
                uvmax = uvmax[0]
            return uvmax
        else:
            print "%s not in %s" % (fluxcal, ephemerisFields)
    print "The flux calibrator is not an ephemeris object."
    return 

def findNull(angularDiameter,amplitude=0, wavelength=None, frequency=None, verbose=True):
    """
    Given an amplitude on a scale of 0..1, and an angularDiameter in
    arcseconds, determine the corresponding radius of the Besinc
    function within the first null (in units of kilowavelength). This
    is the function that describes the visibility amplitude of a uniform
    disk.
    If the wavelength (in mm) or frequency (in GHz) is given, then
    report the value in meters.
    Todd Hunter
    """
    radians = angularDiameter/ARCSEC_PER_RAD
    for B in np.arange(500,5e7):  #B = baseline length in lambda
        x = 2*np.pi*B*radians/2.0
        I = 2*scipy.special.j1(x)/x
        if (I < amplitude):
            break
    if (wavelength is not None):
        meters = B*wavelength*0.001
        if verbose:
            if (amplitude == 0):
                print "first null occurs at %g meters" % (meters)
            else:
                print "amplitude is %g*peak at %g meters" % (amplitude,meters)
        return(meters) 
    elif (frequency is not None):
        wavelength = 299.792458/frequency
        print "wavelength = %g mm" % (wavelength)
        meters = B*wavelength*0.001
        if verbose:
            if (amplitude == 0):
                print "first null occurs at %g meters" % (meters)
            else:
                print "amplitude is %g*peak at %g meters" % (amplitude,meters)
        return(meters)
    else:
        if verbose:
            if (amplitude == 0):
                print "first null occurs at %g kilolambda" % (B*0.001)
            else:
                print "amplitude is %g*peak at %g kilolambda" % (amplitude,B*0.001)
        return(B)

def waveNumberPerAtmosphereToMHzPerMillibar(value):
    """
    Convert pressure broadening factor from the units in the HITRAN database (in cm^-1 atm^-1)
    to MHz mb^-1 (using a conversion of 1013.25 mb per atmosphere)
    -Todd Hunter
    """
    value *= c_mks * 100 * 1e-6 # convert from wave number to frequency in MHz
    value /= 1013.25 # convert from atm^-1 to mb^-1
    return  value

def waveNumberToFrequency(wavenumber):
    """
    Converts wavenumber in cm^-1 to frequency in GHz
    -Todd Hunter
    """
    return c_mks * 1e-7 * wavenumber

def waitForPlotms():
    """
    The EVLA solution, from Claire, with some modifications by Todd.
    This will be obsoleted in casa 4.2 with the new options of plotms.
    """
    mylogfile = casalog.logfile()
    if (os.path.exists(mylogfile) == False):
        # someone may have deleted it
        print("waitForPlotms() is returning immediately because it cannot find the casa log file.")
        return
    countmax = 10
    countr = 0
    foundend = False
    searchText = 'End Task: plotms'
    # sometimes plotms never prints 'End Task: plotms', but instead prints 'END       Time:'
    # so also check for that string to signify the end of the process
    searchText2 = 'END       Time:'
    while not foundend and countr<countmax:
        timeUtilities.sleep(1)  
        #os.system('tail --lines=10 '+mylogfile)
        f = os.popen('tail --lines=10 '+mylogfile)
        fstrs = f.readlines()
        f.close()
        for fstr in fstrs:
            if (fstr.count(searchText)>0  or fstr.count(searchText2)>0):
                foundend=True
        if (foundend == False):
            print("Waiting for text: %s" % searchText)
        countr+=1
    return

def setScanNumbersToZero(vis):
    """
    Sets all scan numbers in a dataset to zero.
    -- Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis,nomodify=False)
    scans = mytb.getcol('SCAN_NUMBER')
    scans *= 0
    mytb.putcol('SCAN_NUMBER', scans)
    mytb.close()

def renameMsInCalTable(mytable, vis):
    """
    Change the name of the MSName keyword in the header of a caltable.
    -Todd Hunter
    """
    if (os.path.exists(mytable) == False):
        print "Could not find table = ", mytable
        return
    mytb = createCasaTool(tbtool)
    mytb.open(mytable, nomodify=False)
    msname = mytb.getkeyword('MSName')
    mytb.putkeyword('MSName',vis)
    mytb.close()
    
def fixScanNumbers(vis, update=True):
    """
    Detects times when the field name changes, and increments the scan number.
    Useful for SMA data converted with old version of sma2casa.  This uses a
    brute force row-by-row method. In this case, it's not clear if selecting
    by data descriptor would be much faster.
    -- Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    fields = mytb.getcol('FIELD_ID')
    scans = mytb.getcol('SCAN_NUMBER')
    datetimes = mytb.getcol('TIME')
    dds = mytb.getcol('DATA_DESC_ID')
    mytb.close()
    uniqueDDs = np.unique(dds)
    scanChange = dict.fromkeys(uniqueDDs, [])
    print "initialized scanChange = ", scanChange
    nrows = len(fields)
    for mydd in uniqueDDs:
        previousField = None
        for f in range(nrows):
            if (dds[f] == mydd):
                # We have found a row for the current data descriptor
                if (previousField is not None):
                    if (previousField != fields[f]):
#                        print "dd%d: Field change (%d to %d) at row %d" % (mydd,previousField,fields[f],f)
                        scanChange[mydd] = scanChange[mydd] + [f]
                previousField = fields[f]
        print "Found %d scan changes for dd%d" % (len(scanChange[mydd]), mydd)
                
    if (update):
        newDatetimes = datetimes
        mytb.open(vis, nomodify=False)
        for u in range(len(uniqueDDs)):
            mydd = uniqueDDs[u]
            # for each data descriptor, search through all rows
            n = 0
            for d in range(len(datetimes)):
                if (dds[d] == mydd):
                    if (n < len(scanChange[mydd])):
                        # We haven't seen all the field changes yet.
                        if (d >= scanChange[mydd][n]):
                            n += 1
                    scans[d] = n+1
            print "Done %d/%d: Setting scans = " % (u+1,len(uniqueDDs)), scans
        print "Updating measurement set..."
        mytb.putcol('SCAN_NUMBER', scans)
        mytb.close()

def plotObservatories(table='', hemisphere='north', list=False):
    """
    This function will plot a polar view of one or both hemisphere's worth of
    observatories with ITRF coordinates in the specified CASA repository table.
    The axes will be in XY coordinates, with latitude and longitude lines marked.
    The locations are first drawn in red, then in blue so that disagreements between
    the latitude/longitude (red) and the XYZ in the table (blue) will be apparent.
    table: if blank, then use os.getenv('CASAPATH').split()[0]+'/data/geodetic/Observatories'
    hemisphere: 'north', 'south', or 'both'
    list: print the longitude/latitude and XYZ values 
    -Todd Hunter
    """
    if table == '':
        table = os.getenv('CASAPATH').split()[0]+'/data/geodetic/Observatories'
    mytb = createCasaTool(tbtool)
    mytb.open(table)
    X = mytb.getcol('X') * 0.001
    Y = mytb.getcol('Y') * 0.001
    Z = mytb.getcol('Z') * 0.001
    Long = mytb.getcol('Long') 
    Lat = mytb.getcol('Lat') 
    Type = mytb.getcol('Type')
    Name = mytb.getcol('Name')
    if (hemisphere == 'north'):
        indices1 = np.where(Z>=0)[0]
    elif (hemisphere == 'south'):
        indices1 = np.where(Z<=0)[0]
    elif (hemisphere == 'both'):
        indices1 = range(len(X))
    else:
        print "hemisphere must be 'north', 'south', or 'both'"
        return
    indices2 = np.where(Type == 'ITRF')[0]
    indices  = np.intersect1d(indices1, indices2)
    pb.close()
    pb.figure(1,(8,8)) # make square figure

    # First draw a point at the Lat/Long coordinates in red
    earthRadius = 6.378164e3
    radius = earthRadius*cos(Lat*np.pi/180.)
    x = radius*np.cos(Long*np.pi/180)
    y = radius*np.sin(Long*np.pi/180)
    namesDrawn = []
    xyDrawn = len(indices) * [[0,0]]
    for j in range(len(indices)):
        i = indices[j]
        notAtZeroZero = (Lat[i]**2)>1
        if (notAtZeroZero):
            pb.plot(x[i], y[i], 'o', color='r')
            if (list): print "%s: %f, %f deg" % (Name[i],Long[i],Lat[i])
        if (Name[i] != 'SAO SMA' and Name[i] not in namesDrawn and notAtZeroZero):
            pb.text(x[i], y[i], Name[i], size = 9, color='k', ha='center')
            namesDrawn.append(Name[i])
            xyDrawn[j] = [x[i],y[i]]
            
    if (list): print "------------------------------------------"
    # Now draw a point at the XYZ coordinates in blue
    pb.plot(X[indices], Y[indices],'o',color='b')
    namesDrawn = []
    for j in range(len(indices)):
        i = indices[j]
        notAtNorthPole = (X[i]**2+Y[i]**2)>1000
        if (Name[i] != 'SAO SMA' and Name[i] not in namesDrawn and notAtNorthPole):
            difference = ((xyDrawn[j][0]-X[i])**2+(xyDrawn[j][1]-Y[i])**2)**0.5
            if (difference > 50):  # don't re-label the same observatory again
                pb.text(X[i], Y[i], Name[i], size = 9, color='k', ha='center')
            namesDrawn.append(Name[i])
            if (list): print "%s: %f, %f, %f km" % (Name[i],X[i],Y[i],Z[i])
    pb.xlim([-6.4e3, 6.4e3])
    pb.ylim([-6.4e3, 6.4e3])
    pb.xlabel('X (km)')
    pb.ylabel('Y (km)')
    cir = pb.Circle((0,0), radius=earthRadius, facecolor='w')
    pb.gca().add_patch(cir)
    # draw latitude lines
    for i in range(15,90,15):
        cir = pb.Circle((0,0), radius=earthRadius*cos(i*np.pi/180.), facecolor='w', ls='dotted')
        pb.gca().add_patch(cir)
        pb.text(-earthRadius*cos(i*np.pi/180.)-200,0,str(i))
    # draw longitude lines
    labelRadius = earthRadius*cos(67*np.pi/180.)
    inc = 15
    for i in range(-180+inc,180,inc):
        x = earthRadius*cos(i*np.pi/180.)
        y = earthRadius*sin(i*np.pi/180.)
        pb.plot([0,x],[0,y],':',color='k')
        pb.text(labelRadius*cos(i*np.pi/180.), labelRadius*sin(i*np.pi/180.), str(i))
    if (hemisphere in ['north','south']):
        pb.title('%sern observatories with ITRF coordinates in CASA repository' % (hemisphere))
    else:
        pb.title('Observatories with ITRF coordinates in CASA repository')
    pb.text(0, 7000, 'Viewed from the celestial pole', ha='center')
    pb.draw()
    if (os.access('./',  os.W_OK)):
        png = 'plotObservatories_%s.png' % (hemisphere)
    else:
        png = '/tmp/plotObservatories_%s.png' % (hemisphere)
    pb.savefig(png)
    print "Figure saved in %s" % (png)

def clearPointingTable(vis):
    """
    Removes all rows from the POINTING table of a measurement set.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+"/POINTING", nomodify=False)
    a = mytb.rownumbers()
    mytb.removerows(a)
    mytb.close()

def flipSignOfPosition(table='/usr/lib64/casapy/release/4.1.0/data/geodetic/Observatories',
                       axis='Y',observatory='SMA'):
    """
    This function will flip the sign of one axis of the position of an observatory in
    the CASA Observatories table, for testing purposes.
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(table, nomodify=False)
    Y=mytb.getcol(axis)
    Names=mytb.getcol('Name')
    index = numpy.where(Names==observatory)[0][0]
    Y[index] *= -1
    mytb.putcol(axis,Y)
    mytb.close()

def nanmedian(a, axis=0):
    """
    Takes the mean of an array, ignoring the nan entries
    """
    if (np.__version__ < '1.81'):
        return(scipy.stats.nanmedian(a,axis)) 
    else:
        return(np.nanmedian(a,axis))

def negateAntennaPosition(vis, column=1):
    """
    Negates one of the ITRF coordinate axes of the antenna positions.
    0=X, 1=Y, 2=Z
    Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/ANTENNA',nomodify=False)
    c = mytb.getcol('POSITION')
    c[column] *= -1
    mytb.putcol('POSITION', c)
    mytb.close()


def getListOfFilesFromFile(filename, appendms=True):
    """
    Reads a list of measurement set or asdm names from a text file, one per line,
    and return a list of measurement set names (with .ms appended if not present).
    Ignores lines containing beginning with a comment character (pound sign).
    Todd Hunter
    """
    fin = open(filename,'r')
    vislist = []
    for line in fin.readlines():
        if (line.find('#') == 0): continue
        myname = line.strip('\n').strip('\a').replace(':','_').replace('/','_').strip(' ')
        if (appendms):
            if (myname.find('.ms') < 0):
                myname += '.ms'
        vislist.append(myname)
    fin.close()
    return vislist

def checkDelaysForDatasets(vislist=[], intent='CALIBRATE_PHASE,CALIBRATE_BANDPASS',
                           outfile='delaySummary.txt', medianThreshold=0.2, minimumJump=1.0,
                           verbose=False, maxFiles=None, pdftk='pdftk', gs='/usr/bin/gs'):
    """
    Runs checkDelays.findDelayJumps on a list of datasets
    vislist: either a list of strings, or a single string specifying a filename from which to read the
       names of measurement sets on a line-by-line basis
    medianThreshold: value in nsec above which the median delay is considered to be large
    mininumJump: value in nsec above which outlier must be to be considered a jump
    -Todd Hunter
    """
    if (type(vislist) == str):
        vislist = getListOfFilesFromFile(vislist, appendms=True)
        vislistFile = vislist
    else:
        vislistFile = 'checkDelayForDatasets'
    f = open(outfile,'w')
    ctr = 0
    largeDelaysPdfnames = []
    delayJumpsPdfnames = []
    if (maxFiles is None):
        nfiles = len(vislist)
    else:
        nfiles = maxFiles
    for vis in vislist:
        ctr += 1
        if (maxFiles is not None):
            if (ctr > maxFiles):
                break
        print "Working on vis %d/%d = %s" % (ctr,nfiles,vis)
        asdm = vis.strip('.ms')
        if (os.path.exists(vis) == False):
            if (os.path.exists(asdm) == False):
                print "Running asdmExport %s" % (asdm)
                os.system('asdmExport ' + asdm)
            print "Running importasdm('%s',asis='*')" % (asdm)
            importasdm(asdm,asis='*')
        if (os.path.exists(vis+'.listobs') == False):
            listobs(vis,listfile=vis+'.listobs')
        c = checkDelays(vis)
        delayJumps, delayLarge, delayJumpsPdfname, largeDelaysPdfname = c.findDelayJumps(intent=intent, medianThreshold=medianThreshold,
                                                                                         minimumJump=minimumJump)
        if (delayJumpsPdfname != ''):
            delayJumpsPdfnames.append(delayJumpsPdfname)
        if (largeDelaysPdfname != ''):
            largeDelaysPdfnames.append(largeDelaysPdfname)
        dateString = getObservationStartDate(vis)
        correlator = getCorrelatorName(asdm)
        f.write(vis + '    %s   %s\ndelayJumps: %s\ndelayLarge: %s\n\n' % (dateString,correlator,str(delayJumps), str(delayLarge)))
        f.flush()
    f.close()
    print "Results left in %s" % (outfile)
    if (len(largeDelaysPdfnames) > 0):
        mystatus = concatenatePDFs(' '.join(largeDelaysPdfnames), vislistFile+'.largeDelays.pdf', pdftk=pdftk, gs=gs, cleanup=True)
        print "Results left in %s" % (vislistFile+'.largeDelays.pdf')
    if (len(delayJumpsPdfnames) > 0):
        mystatus = concatenatePDFs(' '.join(delayJumpsPdfnames), vislistFile+'.delayJumps.pdf', pdftk=pdftk, gs=gs, cleanup=True)
        print "Results left in %s" % (vislistFile+'.delayJumps.pdf')

def plotDelaySolutionsVsDistanceFromRefant(caltable, spw='', polarization=[0,1],
                                           absoluteValue=True, picoperkm=True,
                                           referencePad='', plotfile=''):
    """
    Plots delay solutions vs. baseline length from the reference antenna.
    This is meant to show the results from:  
        gaincal('phasecal.split.cal',field='0',gaintype='K',combine='scan')
    absoluteValue: if True, then fit/plot the abs of the delay
    picoperkm: do the fit in units of picosecond per km
    referencePad: if '', then use the refant's pad
    -Todd Hunter
    """
    if (spw == ''):
        uniqueSpws = getSpwsFromCaltable(caltable)
    elif (type(spw) != list):
        uniqueSpws = [int(i) for i in str(spw).split(',')]
    antennaNames = getAntennaNamesFromCaltable(caltable)
    pads = getAntennaStationsFromCaltable(caltable)
    lengthlist = []
    delaylist = []
    padlist = []
    alldelays = []
    alllengths = []
    for spw in uniqueSpws:
        print "working on spw %d of %s" % (spw,str(uniqueSpws))
        for pol in polarization:
            delays, spws, antennas, scans, fields, times, flags, refant = readDelaySolutions(caltable, spw, pol)
            refantName = antennaNames[refant]
            refantPad = pads[refant]
            length = []
            pad = []
            delay = []
            for i in range(len(delays)):
                if (antennaNames[i] != refantName and delays[i] != 0.0):
                    if (referencePad == ''):
                        referencePad = pads[refant]
                    if (referencePad != pads[i]):
                        length.append(getBaselineLengthForStations(pads[i],referencePad))
                        delay.append(delays[i])
                        pad.append(pads[i])
                        if (picoperkm):
                            length[-1] *= 0.001
                            delay[-1] *= 1000
            if (absoluteValue):
                delay = list(np.abs(delay))
            lengthlist.append(length)
            delaylist.append(delay)
            padlist.append(pad)
            alldelays += delay
            alllengths += length
    if (picoperkm):
        delayUnits = 'psec'
        lengthUnits = 'km'
    else:
        delayUnits = 'nsec'
        lengthUnits = 'm'
    print "means: length=%f, delay=%f" % (np.mean(alllengths), np.mean(alldelays))
    p = linfit().linfit(alllengths, alldelays, 0.1*np.array(alldelays), plot=True, plotfile='test.png')
    pb.clf()
    desc = pb.subplot(111)
    colors = overlayColors
    for i in range(len(lengthlist)):
        color = colors[i]
        pb.plot(lengthlist[i], delaylist[i], 'o', mfc=color, mec=color)
        pb.hold(True)
    if (absoluteValue):
        ylabel = 'absolute value of delay (%s)' % delayUnits
    else:
        ylabel = 'delay (%s)' % delayUnits
    pb.title(caltable)
    # slope will be in units of nsec/m
    pb.plot(pb.xlim(), p[0]*np.array(pb.xlim())+p[1], 'k-')
    pb.text(0.5,0.95,'fit = %g*x + %g' % (p[0],p[1]),transform=desc.transAxes,ha='center')
    if (refantPad == referencePad):
        pb.xlabel('baseline length (%s) from refant=%s (%s)'%(lengthUnits,refantName,refantPad))
    else:
        pb.xlabel('baseline length (%s) from pad=%s (no antenna)'%(lengthUnits,referencePad))
    pb.ylabel(ylabel)
    y0 = pb.ylim()[1] - 0.1*(pb.ylim()[1]-pb.ylim()[0])
    for i,mypad in enumerate(padlist[0]):
        pb.text(lengthlist[0][i], y0, mypad, rotation='vertical',size=10)
    pb.draw()
    if (plotfile == True):
        plotfile = caltable+'_delay_vs_baselineLength.%s.png' % (referencePad)
    if (plotfile != ''):
        pb.savefig(plotfile)
            
def readDelaySolutions(caltable, spw='', pol=0):
    """
    Reads a K solution table and returns lists of the:
    delays(nsec), spws, antennas, scans, fields, times(mjdsec), flags, refantID
    -Todd Hunter
    """
    mytb = createCasaTool(tbtool)
    mytb.open(caltable)
    delays = mytb.getcol('FPARAM')
    spws = mytb.getcol('SPECTRAL_WINDOW_ID')
    antennas = mytb.getcol('ANTENNA1')
    scans = mytb.getcol('SCAN_NUMBER')
    fields = mytb.getcol('FIELD_ID')
    times = mytb.getcol('TIME')
    flags = mytb.getcol('FLAG')
    pols = range(len(delays))
    mytb.close()
    if spw != '':
        idx = np.where(spws == int(spw))[0]
        refant = antennas[np.where((delays[pol,0,idx]==0) * (flags[pol,0,idx]==0))[0]][0]
        return delays[pol,0,idx], spws[idx], antennas[idx], scans[idx], fields[idx], times[idx], flags[pol,0,idx], refant
    else:
        refant = antennas[np.where((delays[pol,0,:]==0) * (flags[pol,0,:]==0))[0]][0]
        return delays[pol,0], spws, antennas, scans, fields, times, flags, refant

class checkDelays:
    """
    This class uses gaincal to search for delay jumps on an integration
    basis (or specified time interval).  
    If you already have a 'K' caltable, you can run checkDelaySolution,
    otherwise, use findDelayJumps which will run gaincal, and then
    checkDelaySolution.
    Todd Hunter
    """
    def __init__(self, vis, caltable=None, autorun=True, solint='',refant='0',field='',
                 intent='CALIBRATE_BANDPASS', spw='',sigma=5,edgeFraction=0.0625,
                 plotAll=False,phaseup_solint='',medianThreshold=0.2,
                 minimumJump=1.0, verbose=False, antenna='', scan=''):
        if (os.path.exists(vis) == False):
            print "Could not find MS"
            return
        if (os.path.exists(vis+'/table.dat') == False):
            print "No table.dat.  This does not appear to be an ms."
            return
        self.vis = vis
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(vis)
        antennas = range(mymsmd.nantennas())
        self.antennaIds = antennas  
        self.antennaNames = mymsmd.antennanames(antennas)
        mymsmd.close()
        if (autorun):
            if (caltable is None):
                self.findDelayJumps(solint,refant,field,intent,spw,sigma,caltable,edgeFraction,
                                    plotAll,
                                    phaseup_solint, medianThreshold,minimumJump,verbose)
            else:
                self.checkDelaySolution(caltable,antenna,spw,scan,sigma,verbose,plotAll,
                                        medianThreshold,minimumJump)
        
    def findDelayJumps(self, solint='', refant='0', field='', intent='CALIBRATE_BANDPASS',
                       spw='', sigma=5, caltable='', edgeFraction=0.0625, plotAll=False,
                       phaseup_solint='', medianThreshold=5.0, minimumJump=1.0, verbose=False):
        """
        Runs gaincal 'G' with calmode='p' to phase-up the array, followed by gaincal 'K'
        to find delay solutions, then calls checkDelaySolutions to check the resulting
        caltable for jumps.

        field: select a specific field name (or string ID) to check
        intent: select a specific intent to check (#ON_SOURCE is added to the end)
        sigma: threshold for declaring an outlier point (the value to multiply by the MAD)
        edgeFraction: the fraction of edge channels to avoid (on each side) in the solution
        phaseup_solint: the solution interval for the phase-up stage (default: 1 integration)
        solint: the solution interval for the 'K' solution (default: 1 integration)
        medianThreshold: value in nsec above which the median delay is considered to be large
        mininumJump: value in nsec above which outlier must be to be considered a jump

        Returns two dictionaries:
        1) delayJumps keyed by antenna, spw, scan, polarization ID, value = value in nsec
        2) delayMedian keyed by antenna, spw, polarization ID, value = value in nsec
        - Todd Hunter
        """
        if (refant not in self.antennaNames and str(refant) not in [str(id) for id in self.antennaIds]):
            print "Antenna %s is not in the dataset.  Available antennas = %s" % (refant, str(self.antennaNames))
            return
        if (caltable == '' or caltable==None):
            caltable = self.vis + '.K'
        mymsmd = createCasaTool(msmdtool)
        mymsmd.open(self.vis)
        if (intent != ''):
            intents = intent.split(',')
            intent = ''
            for myIntent in intents:
                if (myIntent != intents[0]): intent += ','
                intent += myIntent
                if (myIntent.find('#') < 0):
                    intent += '#ON_SOURCE'
            intents = intent.split(',')
            noData = True
            for myIntent in intents:
                if (myIntent not in mymsmd.intents()):
                    print "No data with intent = ", intent
                else:
                    noData = False
            if (noData):
                print "Available intents = %s" % str(mymsmd.intents())
                return
        if (spw == ''):
            if (casadef.subversion_revision >= casaRevisionWithAlmaspws):
                spwlist = mymsmd.almaspws(fdm=True,tdm=True)
            else:
                spwlist = np.setdiff1d(np.union1d(mymsmd.tdmspws(),mymsmd.fdmspws()), mymsmd.chanavgspws())
            if (intent != ''):
                intents = intent.split(',')
                spwsforintent = []
                for myIntent in intents:
                    spwsforintent += list(mymsmd.spwsforintent(myIntent))
                spwlist = np.intersect1d(spwlist,np.array(spwsforintent))
                if (len(spwlist) < 1):
                    print "No spws with intent = ", intent
                    return
            spw = ','.join([str(s) for s in spwlist])
            print "spws selected = ", spw
        myspw = int(spw.split(',')[0].split(':')[0])
#        print "myspw = ", myspw
        if (field != ''):
            idx1 = np.intersect1d(mymsmd.scansforspw(myspw),mymsmd.scansforfield(field))
        else:
            idx1 = mymsmd.scansforspw(myspw)
        if (intent != ''):
            intents = intent.split(',')
            idx2 = []
            for myIntent in intents:
                idx2 += list(mymsmd.scansforintent(myIntent))
            firstScan = np.intersect1d(idx1,np.array(idx2))
        else:
            firstScan = idx1
        print "scans for spw%d = " % (myspw), firstScan
        if (len(firstScan) < 1):
            print "mismatch in spw/intent"
            return
        firstScan = firstScan[0]                
        if (solint == ''):
            print "Calling getIntegrationTime('%s',spw='%s', scan=%d, intent='%s')" % (self.vis,myspw,
                                                                                       firstScan,intent)
            solint = getIntegrationTime(self.vis, spw=myspw, scan=firstScan, intent=intent)
            solint = '%.3fs' % (solint)
            print "Using solint = integration time for scan %d = %s" % (firstScan, solint)
        if (spw.find(':') > 0):
            spwchan = spw
        else:
            spwchan = ''
            spwList = spw.split(',')
            for s in spwList:
                nchan = mymsmd.nchan(int(s))
                startchan = int(nchan*edgeFraction)
                endchan = nchan-startchan
                spwchan += '%s:%d~%d' % (s,startchan,endchan)
                if (s != spwList[-1]): spwchan += ','
        mymsmd.close()
        if (os.path.exists(caltable)):
            print "Removing existing caltable = %s" % (caltable)
            os.system('rm -rf %s' % (caltable))
        
        print "Calling gaincal('%s',gaintype='G',solint='%s',field='%s',caltable='%s',refant='%s',intent='%s',spw='%s',selectdata=True)" % (self.vis,solint,field,caltable,refant,intent,spwchan)
        if (phaseup_solint == ''):
            phaseup_solint = '%.3fs' % (getIntegrationTime(self.vis, spw=myspw, scan=firstScan, intent=intent))
        gaincal(self.vis, gaintype='G', solint=phaseup_solint, field=str(field), caltable=caltable+'.phaseup',
                refant=refant, intent=intent, spw=spwchan, calmode='p', selectdata=True)
        print "Calling gaincal('%s',gaintype='K',solint='%s',field='%s',caltable='%s',refant='%s',intent='%s',spw='%s',gaintable='%s',selectdata=True)" % (self.vis,solint,field,caltable,refant,intent,spwchan,caltable+'.phaseup')
        gaincal(self.vis, gaintype='K', solint=solint, field=str(field), caltable=caltable,
                refant=refant, intent=intent, spw=spwchan, gaintable=caltable+'.phaseup',selectdata=True)
        result = self.checkDelaySolution(caltable, sigma=sigma, plotAll=plotAll,
                                             medianThreshold=medianThreshold,minimumJump=minimumJump,verbose=verbose)
        return(result)

    def checkDelaySolution(self, caltable='', antenna='', spw='', scan='', sigma=5,
                           verbose=False, plotAll=False, medianThreshold=5.0,
                           minimumJump=1.0, ylim=[0,0]):
        """
        Takes a K solution caltable and looks for delay jumps, and large values of delay.
        caltable: the solution table
        antenna: limit the search to a list of antenna IDs
        spw: limit the search to a list of spws
        scan: limit the search to a list of scans
        sigma: threshold for declaring an outlier point (the value to multiply by the MAD)
        mininumJump: value in nsec above which outlier must be to be considered a jump
        medianThreshold: value in nsec above which the median delay is considered to be large
        plotAll: if True, produce a plot for each combination, even if there are no delay
                 jumps found

        Returns: 2 dictionaries, which are filled only for combinations that show a problem
        1) delayJumps keyed by antenna, spw, polarization ID
        2) delayMax keyed by antenna, spw, polarization ID
        3) The name of the PDF produced, if any
        """
        if (caltable == ''):
            caltable = self.vis + '.K'  # check for automatic name
        if (os.path.exists(caltable) == False):
            print "Could not find caltable: %s" % (caltable)
            return
        delays, spws, antennas, scans, fields, times = readDelaySolutions(caltable)
        pols = len(delays)
        uniqueAntennas = np.unique(antennas)
        uniqueSpws = np.unique(spws)
        uniqueScans = np.unique(scans)
        uniqueFields = np.unique(fields)
        uniqueTimes = np.unique(times)
        # loop over solutions
        if (antenna == ''): antenna = uniqueAntennas
        if (spw == ''): spw = uniqueSpws
        if (scan == ''): scan = uniqueScans
        delayJumps = {}
        delayMax = {}
        delayJumpPngs = []
        largeDelayPngs = []
        dmax = np.max(delays)
        dmin = np.min(delays)
        dmax = np.max([abs(dmax), abs(dmin)])
        dmin = -dmax
        autoylim = [dmin,dmax]
        allpngs = []
        for a in antenna:
            if (verbose): print "working on antenna %d" % (a)
            for s in spw:
                if (verbose): print "working on spw %d" % (s)
                antSpwRows = []
                for sc in scan:
                    idx1 = np.where(antennas==a)[0]
                    idx2 = np.where(spws==s)[0]
                    idx3 = np.where(scans==sc)[0]
                    rows = np.intersect1d(np.intersect1d(idx1,idx2),idx3)
                    antSpwRows += list(rows)
                rows = antSpwRows[:]
                jumpSeen = False
                largeSeen = False
                for pol in pols:
                    if (verbose): print "shape(delays) = ", np.shape(delays)
                    if (verbose): print "shape(delays[pol]) = ", np.shape(delays[pol])
                    if (verbose): print "shape(delays[pol][0][rows]) = ", np.shape(delays[pol][0][rows])
                    if (verbose): print "delays[pol][0][rows] = %s" % (str(delays[pol][0][rows]))
                    if (verbose): print "rows = ", rows
                    delayMad = MAD(delays[pol][0][rows])
                    myMax = np.max(np.abs(delays[pol][0][rows]))
                    if (verbose): print "max= ", myMax
                    myDiff = delays[pol][0][rows] - myMax
                    outliers = np.where(myDiff > delayMad*sigma)[0]
                    outliers2 = np.where(myDiff > minimumJump)[0]
                    outliers = np.intersect1d(outliers,outliers2)
                    if (verbose): print "len(outliers) = %d" % (len(outliers))
                    nJumps = len(outliers)
                    if (fabs(myMax) > medianThreshold):
                        if (a not in delayMax.keys()): delayMax[a] = {}
                        if (s not in delayMax[a].keys()): delayMax[a][s] = {}
                        print "Ant%d=%s, spw%d, pol%d: found a large delay (nsec: %s)" % (a,self.antennaNames[a],s,pol,myMax)
                        delayMax[a][s][pol] = myMax
                        largeSeen = True
                    if (nJumps > 0):
                        if (a not in delayJumps.keys()): delayJumps[a] = {}
                        if (s not in delayJumps[a].keys()): delayJumps[a][s] = {}
                        delayJumps[a][s][pol] = nJumps
                        print "Ant%d=%s, spw%d, pol%d: found %d delay jumps (nsec: %s)" % (a,self.antennaNames[a],s,pol,nJumps,str(['%.1f'%(dd) for dd in myDiff[outliers]]))
                        jumpSeen = True
                if (jumpSeen or largeSeen or plotAll):
                    pb.clf()
                    adesc = pb.subplot(111)
                    timeStamps = pb.date2num(mjdSecondsListToDateTime(times[rows]))
                    c = ['black','red']
                    for pol in pols:
                        pb.plot_date(timeStamps, delays[pol][0][rows], 'o', color=c[pol])
                        pb.text(0.1,0.95-0.05*pol,'Pol '+str(pol),color=c[pol],transform=adesc.transAxes)
                        pb.hold(True)
                    if (np.max(times[rows]) - np.min(times[rows]) > 2000):
                        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,20)))
                        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,10)))
                        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
                        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
                    elif (np.max(times[rows]) - np.min(times[rows]) > 200):
                        adesc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,3)))
                        adesc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,1)))
                        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
                        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
                    else:
                        adesc.xaxis.set_major_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,20)))
                        adesc.xaxis.set_minor_locator(matplotlib.dates.SecondLocator(bysecond=range(0,60,5)))
                        adesc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M:%S'))
                        adesc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M:%S')
                    pb.xlabel('Universal Time on %s' % (mjdsecToUT(times[rows[0]]).split()[0]))
                    adesc.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))
                    pb.ylabel('Delay (nsec)')
                    if (ylim != [0,0]):
                        pb.ylim(ylim)
                    else:
                        pb.ylim(autoylim)
                    yFormatter = ScalarFormatter(useOffset=False)
                    if (jumpSeen):
                        details = '.%s.spw%02d.delayJump' % (self.antennaNames[a],s)
                    elif (largeSeen):
                        details = '.%s.spw%02d.largeDelay' % (self.antennaNames[a],s)
                    else:
                        details = '.%s.spw%02d' % (self.antennaNames[a],s)
                    pb.title(caltable + details.replace('.',' '))
                    png = caltable + details + '.png'
                    pb.savefig(png)
                    allpngs.append(png)
                    print "Figure saved to %s" % (png)
                    if (jumpSeen):
                        delayJumpPngs.append(png)
                    if (largeSeen):
                        largeDelayPngs.append(png)
            if (a in delayJumps.keys()):
                delayJumps[self.antennaNames[a]] = delayJumps[a]
            if (a in delayMax.keys()):
                delayMax[self.antennaNames[a]] = delayMax[a]
        delayJumpsPdfname = ''
        largeDelaysPdfname = ''
        if (plotAll):
            buildPdfFromPngs(pnglist=allpngs, pdfname=caltable+'.all.pdf')
        if (len(delayJumpPngs) > 1):
            delayJumpsPdfname = caltable+'.delayJumps.pdf'
            print "running buildPdfFromPngs(%s, '%s')" % (str(delayJumpPngs),delayJumpsPdfname)
            buildPdfFromPngs(pnglist=delayJumpPngs, pdfname=delayJumpsPdfname)
        if (len(largeDelayPngs) > 1):
            largeDelaysPdfname = caltable+'.largeDelays.pdf'
            print "running buildPdfFromPngs(%s, '%s')" % (str(largeDelayPngs),largeDelaysPdfname)
            buildPdfFromPngs(pnglist=largeDelayPngs, pdfname=largeDelaysPdfname)
        return delayJumps, delayMax, delayJumpsPdfname, largeDelaysPdfname

def membrane(vis):
    """
    This function was meant to be used with bandpass stability analysis so that
    a script could know which antennas have the new membrane.  It is probably
    not currently up-to-date.
    -Todd Hunter
    """
    mymsmd = createCasaTool(msmdtool)
    mymsmd.open(vis)
    antennaNames = mymsmd.antennanames(range(mymsmd.nantennas()))
    mymsmd.close()
    membraneType = {  # from Dashboard on Oct 11, 2013
        'CM01':'Goretex',
        'CM02':'Goretex',
        'CM03':'Goretex',
        'CM04':'Goretex',
        'CM05':'Goretex',
        'CM06':'Goretex',
        'CM07':'Goretex',
        'CM08':'Goretex',
        'CM09':'Goretex',
        'CM10':'Goretex',
        'CM11':'Goretex',
        'CM12':'Goretex',
        'DA41':'Goretex',
        'DA42':'Goretex',
        'DA43':'Goretex',
        'DA44':'Goretex',
        'DA45':'Goretex',
        'DA46':'Goretex',
        'DA47':'Goretex',
        'DA48':'Goretex',
        'DA49':'FEP',
        'DA50':'Goretex',
        'DA51':'Goretex',
        'DA52':'Goretex',
        'DA53':'Goretex',
        'DA54':'FEP',
        'DA55':'FEP',
        'DA56':'FEP',
        'DA57':'FEP',
        'DA58':'FEP',
        'DA59':'FEP',
        'DA60':'FEP',
        'DA61':'FEP',
        'DA62':'FEP',
        'DA63':'FEP',
        'DA64':'FEP',
        'DA65':'FEP',
        'DV01':'Goretex',
        'DV02':'Goretex',
        'DV03':'Goretex',
        'DV04':'Goretex',
        'DV05':'Goretex',
        'DV06':'Goretex',
        'DV07':'Goretex',
        'DV08':'FEP',
        'DV09':'FEP',
        'DV10':'Goretex',
        'DV11':'Goretex',
        'DV12':'FEP',
        'DV13':'Goretex',
        'DV14':'Goretex',
        'DV15':'Goretex',
        'DV16':'Goretex',
        'DV17':'Goretex',
        'DV18':'Goretex',
        'DV19':'Goretex',
        'DV20':'Goretex',
        'DV21':'Goretex',
        'DV22':'Goretex',
        'DV23':'Goretex',
        'DV24': 'FEP',
        'DV25': 'FEP',
        'PM01': 'Goretex',
        'PM02': 'Goretex',
        'PM03': 'FEP',
        'PM04': 'FEP'
        }
    fep = 0; fep7m = 0; fep12m = 0
    goretex = 0; goretex7m = 0; goretex12m = 0
    mydict = {}
    for antenna in antennaNames:
        mytype = membraneType[antenna]
        mydict[antenna] = mytype
        if (mytype.find('FEP')==0):
            fep += 1
            if (antenna.find('CM')==0):
                fep7m += 1
            else:
                fep12m += 1
        elif (mytype.find('Goretex')==0):
            goretex += 1
            if (antenna.find('CM')==0):
                goretex7m += 1
            else:
                goretex12m += 1
        else:
            print "Error in dictionary"
            return
    print "%d FEP, %d Goretex" % (fep,goretex)
    print " 7m: %d FEP, %d Goretex" % (fep7m,goretex7m)
    print "12m: %d FEP, %d Goretex" % (fep12m,goretex12m)
    return(mydict)

def fixpointing(vis):
    """
    Script extracted from CSV-2878 to convert MS POINTING table from commanded to actual
    coordinates using the ASDM_POINTING table.  This should only be run if the ASDM was
    loaded without the --with-pointing-correction option added to the trunk on Oct 25, 2013.
    Takeshi Nakazato
    """
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    keyword_names = mytb.keywordnames()

    # check whether ASDM_POINTING exists or not
    if not 'ASDM_POINTING' in keyword_names:
        print 'fixpointing: ASDM_POINTING is needed. Please re-import ASDM with asis option'
        mytb.close()
        return

    # check number of antennas
    mytb.open(os.path.join(vis, 'ANTENNA'))
    num_antenna = mytb.nrows()
    mytb.close()

    # for each antenna
    for antenna in xrange(num_antenna):
        # retrieve correction term from ASDM_POINTING
        mytb.open(os.path.join(vis, 'ASDM_POINTING'))
        tsel = mytb.query('antennaId == "Antenna_%s"'%(antenna), sortlist='timeOrigin')
        tracking_error = [tsel.getcell('encoder', irow) - tsel.getcell('pointingDirection', irow) for irow in xrange(tsel.nrows())]
        num_rows = sum([len(chunk) for chunk in tracking_error])
        tsel.close()
        mytb.close()

        # apply correction term to MS/POINTING
        mytb.open(os.path.join(vis, 'POINTING'), nomodify=False)
        tsel = mytb.query('ANTENNA_ID == %s'%(antenna), sortlist='TIME')

        if num_rows != tsel.nrows():
            print 'Antenna %s: Number of data records mismatch!'%(antenna)
            tsel.close()
            mytb.close()

        irow = 0
        for chunk in tracking_error:
            for _error in chunk:
                direction = tsel.getcell('DIRECTION', irow)
                direction[0][0] += _error[0]
                direction[1][0] += _error[1]
                tsel.putcell('DIRECTION', irow, direction)
                irow += 1
        tsel.close()
        mytb.close()

def scaleAutocorr(vis, scale=1., antenna='', spw='', field='', scan=''):
    """
    Scale the autocorrelation in a measurement set by a factor.

    Required inputs:
        vis: the measurement set to be modified
        scale: the scaling factor to be multiplied
    Optional inputs for selecting a subset of the data:
        antenna: antenna name(s) or ID(s)
        spw: spectral window ID(s)
        field: field name(s) or ID(s)
        scan: scan number(s)
    The optional inputs can be either scalar or list.  Their default
    value (empty string) means "all".  You may have to explicitly
    specify spw, as all the spws to be modified should have the same
    number of channels (e.g., full-resolution and channel-averaged spws
    cannot be processed at once).

    T. Sawada
    """

    if os.path.exists(vis) == False:
        print "Could not find MS."
        return
    if os.path.exists(vis+'/table.dat') == False:
        print "No table.dat.  This does not appear to be an MS."
        return

    mymsmd = createCasaTool(msmdtool)
    mytb = createCasaTool(tbtool)

    conditions = ["ANTENNA1==ANTENNA2"]

    mymsmd.open(vis)

    if antenna != '':
        if not isinstance(antenna, (list, tuple)):
            antenna = [antenna]
        antennaids = []
        for i in antenna:
            if re.match("^[0-9]+$", str(i)): # digits only: antenna ID
                antennaids.append(int(i))
            else: # otherwise: antenna name
                antennaids.append(mymsmd.antennaids(i)[0])
        conditions.append("ANTENNA1 in %s" % str(antennaids))
    if spw != '':
        if not isinstance(spw, (list, tuple)):
            spw = [spw]
        datadescids = []
        for i in spw:
            datadescids.append(mymsmd.datadescids(spw=int(i))[0])
        conditions.append("DATA_DESC_ID in %s" % str(datadescids))
    if field != '':
        if not isinstance(field, (list, tuple)):
            field = [field]
        fieldids = []
        for i in field:
            if re.match("^[0-9]+$", str(i)): # digits only: field ID
                fieldids.append(int(i))
            else: # otherwise: field name
                fieldids.append(mymsmd.fieldsforname(i)[0])
        conditions.append("FIELD_ID in %s" % str(fieldids))
    if scan != '':
        if not isinstance(scan, (list, tuple)):
            scan = [scan]
        scannumbers = [int(i) for i in scan]
        conditions.append("SCAN_NUMBER in %s" % str(scannumbers))

    mymsmd.close()

    datacolumn = getDataColumnName(vis)

    print "Multiplying %s to the dataset %s column %s." % \
        (str(scale), vis, datacolumn)
    print "The selection criteria are '%s'." % (" && ".join(conditions))

    mytb.open(vis, nomodify=False)
    subtb = mytb.query(" && ".join(conditions))
    try:
        data = subtb.getcol(datacolumn)
        print "Dimension of the selected data: %s" % str(data.shape)
        subtb.putcol(datacolumn, data*scale)
    except:
        print "An error occurred upon reading/writing the data."
    finally:
        print "Closing the table."
        mytb.flush()
        subtb.close()
        mytb.close()

def sidebandToNetSideband(sideband):
    """
    Convert from the [LSB,USB] = [-1,+1] convention to the [+1,+2] convention 
    that is stored in the NET_SIDEBAND column of the SPECTRAL_WINDOW table of 
    a measurement set.
    -Todd Hunter
    """
    if (sideband < 0):
        # ALMA writes 1 for LSB, 2 for USB into NET_SIDEBAND column
        net_sideband=1
    else:
        net_sideband=2
    return(net_sideband)

def fixASDM(asdm, restore=False):
    """
    In August 2015, the NA ARC experienced a problem where every .xml file exported from the
    archive was missing a newline character at the end of what should have been the first line.  
               <?xml version="1.0" encoding="UTF-8"?>
    This function fixes that problem.
    restore: if True, restore the .bak files from a previous execution that did something wrong
    -Todd Hunter
    """
    files = glob.glob(asdm+'/*.xml')
    for f in files:
        if (restore):
            os.system('cp %s.bak %s' % (f,f))
        print "Fixing ", f
        os.system('cp %s %s.bak' % (f,f))
        i = open(f,'r')
        lines = i.read()
        loc = lines.find('><')
        lines = lines[:loc+1] + '\n' + lines[loc+1:]
        i.close()
        i = open(f,'w')
        i.write(lines)
        i.close()

def fixuvw(vis, field):
    """
    Uses the imtool toolkit to fix the uvw coordinates of a measurement set.
    field: an integer list of fields to correct, or a comma-delimited string (tilde supported)
    -Todd Hunter
    """
    myim = createCasaTool(imtool)
    myim.open(vis, usescratch=False)
    if (type(field) == str):
        tokens = field.split(',')
        field = []
        for token in tokens: # ['0','3~7']
            if (token.find('~') < 0):
                if (token.isdigit()):
                    field.append(int(token))
                else:
                    mymsmd = createCasaTool(msmdtool)
                    mymsmd.open(vis)
                    for fieldid in mymsmd.fieldsforname(token):
                        field.append(fieldid)
                    mymsmd.close()
            else:
                start = int(token.split('~')[0])
                stop = int(token.split('~')[1])+1
                for i in range(start,stop):
                    field.append(i)
    print "Using field = ", field
    myim.calcuvw(field, refcode='J2000', reuse=False)
    myim.close()
    return

def flipSignDeclinationSourcexml(asdm, srcid):
    """
    Flip the sign of declination for a specified source ID in the Source.xml file of an ASDM.
    Note that the pipeline copies this file to the measurement set for later usage.
    srcid: single integer or single string integer
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find asdm"
        return
    fname = asdm + '/Source.xml'
    os.system('cp %s %s.bak'% (fname,fname))
    f = open(fname,'r')
    lines = f.readlines()
    f.close()
    oname = fname
    o = open(oname,'w')
    for line in lines:
        if (line.find('<sourceId>') >= 0):
            if (line.find('<sourceId>%s<' % str(srcid)) >= 0):
                flipSign = True
            else:
                flipSign = False
        if (line.find('<direction>') >= 0):
            if flipSign:
                token = line.split()
                if (token[3][0] == '-'):  # remove minus sign
                    line = line.replace(token[3],token[3][1:])
                else:  # insert minus sign
                    line = line.replace(token[3],'-'+token[3])
        o.write(line)
    o.close()

def flipSignDeclination(vis, srcid, updateFieldTable=True, updateSourceTable=True, updateASDMSourceTable=True):
    """
    Flip the sign of declination for a specified source ID in the source and/or field tables 
    of a measurement set.
    srcid: integer or string integer
    updateFieldTable: process the field table
    updateSourceTable: process the source table
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if updateFieldTable or updateSourceTable or updateASDMSourceTable:
        mytb = createCasaTool(tbtool)
    if updateFieldTable:
        print "Updating FIELD table."
        srcid == int(srcid)
        mytb.open(vis+'/FIELD', nomodify=False)
        source_id = mytb.getcol('SOURCE_ID')
        for col in ['PHASE_DIR','DELAY_DIR','REFERENCE_DIR']:
            idx = np.where(source_id == srcid)[0]
            mydirection = mytb.getcol(col)
            for i in idx:
                mydirection[1][0][i] *= -1
            mytb.putcol(col,mydirection)
        mytb.close()
    if updateSourceTable:
        print "Updating SOURCE table."
        mytb.open(vis+'/SOURCE', nomodify=False)
        source_id = mytb.getcol('SOURCE_ID')
        idx = np.where(source_id == srcid)[0]
        mydirection = mytb.getcol('DIRECTION')
        for i in idx:
            mydirection[1][i] *= -1
        mytb.putcol('DIRECTION',mydirection)
        mytb.close()
    if updateASDMSourceTable and os.path.exists(vis+'/ASDM_SOURCE'):
        print "Updating ASDM_SOURCE table."
        mytb.open(vis+'/ASDM_SOURCE', nomodify=False)
        source_id = mytb.getcol('sourceId')
        idx = np.where(source_id == srcid)[0]
        mydirection = mytb.getcol('direction')
        for i in idx:
            mydirection[1][i] *= -1
        mytb.putcol('direction',mydirection)
        mytb.close()

def editFieldDirection(vis, field, direction, column='DELAY_DIR'):
    """
    Updates the direction in the FIELD table for a specified FIELD.
    field: the integer ID
    direction: the new direction in [ra, dec] in radians, e.g. [[1.1, -0.3]]
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not find measurement set"
        return
    if (type(direction) != list and type(direction) != np.ndarray):
        print "direction must be an array of length 2"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/FIELD', nomodify=False)
    oldDirection = mytb.getcell(column,field)
    print "Changing existing direction from %s to %s" % (str(oldDirection), str(direction))
    mytb.putcell(column, field, direction)
    mytb.close()

def dminfo(vis, outfile=''):
    """
    Prints the result of tb.getdminfo into a text file.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Could not open measurement set"
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis)
    d = mytb.getdminfo()
    mytb.close()
    if outfile == '':
        outfile = vis+'.dminfo.txt'
    f = open(outfile, 'w')
    f.write(str(d))
    f.close()
    print "Result left in text file = ", outfile

def pressureCorrectionFactor(heightDiff, temperatureK):
    """
    Computes scale factor to apply to weather station to reference
    it to a different height above sea level.
    """
    gM_over_R = 0.03417207
    return((1.0-(6.5e-3*heightDiff)/temperatureK)**(gM_over_R/6.5e-3))

def readTMCDBWeatherDataFile(datafile):
    """
    Reads an ASCII weather datafile from the TMCDB, consisting of two columns:
    MJD seconds and a single weather quantity.
    Returns a dictionary, keyed by 'mjdsec' and 'value'
    -Todd Hunter
    """
    f = open(datafile,'r')
    mjdsec = []
    value = []
    for line in f.readlines():
        a,b = line.split()
        mjdsec.append(dateStringToMJDSec(a,verbose=False))
        value.append(float(b))
    f.close()
    return({'mjdsec':np.array(mjdsec), 'value':np.array(value)})

def readAIVWeatherDataFile(datafile):
    """
    Reads an ASCII weather datafile extracted from the AIV webserver, consisting of 6
    columns: MJD, humidityFraction, temperatureC, winddirRad, windspeed, pressurePascal
    Returns a list of 6 lists.
    -Todd Hunter
    """
    f = open(datafile,'r')
    lines = f.readlines()
    f.close()
    mjdsec = []
    humidityFraction = []
    temperatureC = []
    winddirRad = []
    windspeed = []
    pressurePascal = []
    for line in lines:
        tokens = line.split()
        if (len(tokens) == 6):
            mjdsec.append(float(tokens[0]))
            humidityFraction.append(float(tokens[1]))
            temperatureC.append(float(tokens[2]))
            winddirRad.append(float(tokens[3]))
            windspeed.append(float(tokens[4]))
            pressurePascal.append(float(tokens[5]))
    return([mjdsec, humidityFraction, temperatureC, winddirRad, windspeed, pressurePascal])

def readAIVWeatherDataFiles(station):
    """
    Reads all files in the current directory named:  MeteoXXX.YYYY-MM-DD.dat
    and returns the results, converting units in some cases (winddir and pressure):
    [mjdsec, humidityFraction, temperatureC, winddirDeg, windspeed, pressurembar], startdate, enddate
    -Todd Hunter
    """
    files = sorted(glob.glob(station+'*.dat'))
    mjdsec = []
    humidityFraction = []
    temperatureC = []
    winddir = []
    windspeed = []
    pressure = []
    startdate = files[0].split('.')[1]
    enddate = files[-1].split('.')[1]
    for f in files:
        tokens = readAIVWeatherDataFile(f)
        mjdsec += tokens[0]
        humidityFraction += tokens[1]
        temperatureC += tokens[2]
        winddir += tokens[3]
        windspeed += tokens[4]
        pressure += tokens[5]
    return([mjdsec, humidityFraction, temperatureC, np.degrees(winddir), windspeed, 0.01*np.array(pressure)], 
           startdate, enddate)
 
def weatherHistogram(station, quantity='windspeed', bins='auto', plotfile=''):
    """
    Generates a histogram from all the AIV weather data files in the current 
    directory named:  <station>.YYYY-MM-DD.dat
    -Todd Hunter
    """
    data,startdate,enddate = readAIVWeatherDataFiles(station)
    length = len(data[0])
    print "length = ", length
    index = {'humidity':1, 'temperature':2, 'winddir':3, 'windspeed':4, 'pressure':5}
    units = {'humidity':'%', 'temperature':'C', 'winddir':'deg', 'windspeed':'m/s', 'pressure':'mb'}
    resolution = {'humidity':1, 'temperature':0.1, 'winddir':1, 'windspeed':0.5, 'pressure':0.1}
    pb.clf()
    desc = pb.subplot(111)
    mydata = data[index[quantity]]
    if (bins == 'auto'): 
        bins = int((np.max(mydata)-np.min(mydata))/resolution[quantity])
        print "Choosing bins = %d, width = %g" % (bins, (np.max(mydata)-np.min(mydata))/bins)
    pb.hist(mydata, bins=bins)
    pb.ylabel('Number of measurements')
    pb.xlabel('%s (%s)' % (quantity,units[quantity]))
    pb.title(station+' (%s to %s)'%(startdate,enddate))
    pb.text(0.5,0.95,'median +- (mad*1.48):  %s +- %s %s' % (roundFiguresToString(np.median(mydata),3),
                                                          roundFiguresToString(MAD(mydata),3),units[quantity]), 
            ha='center', transform=desc.transAxes)
    pb.draw()
    if (plotfile == ''):
        plotfile = station+'_'+quantity+'.png'
    pb.savefig(plotfile)

def plotDailyWeather(startdate, enddate, wind=True, plotsPerDay=1,
                     overwrite=False, apex=True, osf=False,
                     tmcdb=False, pdf=False, aste=True):
    """
    Calls plotWeatherFromDatabase for several days in a row and
    assembles the pressure difference plots into a movie.
    startdate, enddate: string of format 'YYYY-MM-DD'
    wind: if True, show wind symbols
    plotsPerDay: if >1, then produce this many plots per day
    overwrite: if True, create new data files even if they already exist
    pdf: if True, then also build a PDF, in addition to an animated gif
    -Todd Hunter
    """
    starttime = timeUtilities.time()
    interval = computeIntervalBetweenTwoDays(enddate, startdate)
    pngs = []
    for day in range(interval+1):
        mydate = subtractDays(enddate,day)
        rebuild = False
        trialPngs = []
        for plots in range(plotsPerDay):
            png = 'chajnantorWeather_%s_%02d-%02d.png' % (mydate,plots,plots+1)
            if (not os.path.exists(png)):
                rebuild = True
                break
            trialPngs.append(png)
        if rebuild:
            print "Running plotWeatherFromDatabase('%s')" % (mydate)
            png = plotWeatherFromDatabase(mydate,pressureCorrection=True,plotsPerDay=plotsPerDay,
                                          multipanel=True, plotfile=True, wind=wind, osf=osf,
                                          overwrite=overwrite, apex=apex, tmcdb=tmcdb, aste=aste)
        else:
            print "Using %d pre-existing images for %s" % (len(trialPngs),mydate)
            png = trialPngs
        if (png is not None):
            if (type(png) == list):
                pngs += png
            else:
                pngs.append(png)
    pngs = sorted(pngs)
    if (pdf):
        buildPdfFromPngs(pngs,'chajnantorWeatherMovie_%s_%s.pdf'%(startdate,enddate))
    gif = 'chajnantorWeatherMovie_%s_%s.gif' % (startdate, enddate)
    makeMovie(pngs, gif)
    donetime = timeUtilities.time()
    print "time to generate %d frames = %.1f sec" % (len(pngs),donetime-starttime)

def getMedianWeatherFromTMCDB(asdm, quantity='PRESSURE',station='Meteo201',
                              referenceStation='MeteoCentral',
                              pressureCorrection=True, overwrite=False,
                              tempCorrectionFixed=False, difference=True,
                              verbose=False, apex=False, tmcdb=True):
    """
    Gets the median weather for the timerange of an ASDM from the monitor
    database.
    difference: if True, take the difference w.r.t. the referenceStation
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    startdate = getObservationStartDateFromASDM(asdm)[0].split()[0]
    enddate = getObservationEndDateFromASDM(asdm)[0].split()[0]
    results = getResampledWeatherFromDatabase(startdate, enddate, quantity,
                                        referenceStation, pressureCorrection,
                                        overwrite, tempCorrectionFixed, verbose, apex, tmcdb)
    data, deltaHeights = results
    startmjdsec, stopmjdsec = getObservationMJDSecRangeFromASDM(asdm)
    mbar = data[station]['value']
    if (difference):
        mbar = mbar - data[referenceStation]['value']
    if (quantity == 'PRESSURE'):
        mbar *= 0.01
    idx1 = np.where(data[station]['mjdsec'] > startmjdsec)[0]
    idx2 = np.where(data[station]['mjdsec'] < stopmjdsec)[0]
    rows = np.intersect1d(idx1,idx2)
    if verbose: print "%d rows = " % (len(rows)), rows
    median = np.median(mbar[rows])
    mad = MAD(mbar[rows])
    return(median, mad)

def weatherCorrelationMontage(startdate, enddate, stations=[],
                              x='WINDDIRECTION', y='PRESSURE',
                              pressureCorrection=True,apex=True,
                              referenceStation='MeteoCentral',
                              ylim=[-2.7,2.7], aste=False):
    """
    Builds plots of all weather stations and places the results on a
    single page in their relative configuration on Chajnantor.
    -Todd Hunter
    """
    if (len(stations) < 1):
        stations = dict(allWeatherStationPositions)
        stations.pop('MeteoTB1')
        stations.pop('MeteoOSF')
        if not apex:
            stations.pop('MeteoAPEX')
        if not aste:
            stations.pop('MeteoASTE')
        stations.pop(referenceStation)
        stations = stations.keys()
        print "stations = ", stations
    png = {}
    for station in stations:
        png[station] = '%s_%s.%s.%s.vs.%s.png' % (startdate,enddate,station,y,x)
        if (not os.path.exists(png[station])):
            print "png does not exist: ", png[station]
            weatherCorrelation(startdate, enddate, station, x, y,
                               pressureCorrection, referenceStation,
                               ylim=ylim, plotfile=True)
        else:
            print "Using existing png = ", png[station]
        cmd = 'montage -geometry +2+2 -trim %s %s' % (png[station],png[station].replace('.png','.trim.png'))
        png[station] = png[station].replace('.png','.trim.png')
        if (not os.path.exists(png[station])):
            print "Running ", cmd
            os.system(cmd)
                                       
    cmd = 'montage -geometry +2+2 '
    cmd += 'null: null: null: %s ' % (png['Meteo410'])
    if apex:
        cmd += 'null: null: %s %s ' % (png['MeteoAPEX'], png['Meteo129'])
    else:
        cmd += 'null: null: null: %s ' % (png['Meteo129'])
    cmd += '%s %s %s null: ' % (png['Meteo201'],png['Meteo130'],png['MeteoTB2'])
    cmd += 'null: null: %s null: ' % (png['Meteo131'])
    cmd += 'null: null: null: %s ' % (png['Meteo309'])
    pngname = '%s_%s.%s.vs.%s_montage.png' % (startdate,enddate,y,x)
    cmd += '-tile 4x5 %s' % (pngname)
    print "Running ", cmd
    os.system(cmd)

def weatherCorrelation(startdate, enddate=None,station='Meteo201',x='WINDSPEED',
                       y='PRESSURE',pressureCorrection=True,
                       referenceStation='MeteoCentral',ignoreDates=[],
                       pressureDifference=True, overwrite=False, plotfile='',
                       kde=False, minWindspeed=0, ylim='', aste=False):
    """
    Generates scatter plots of one ALMA weather variable against another for one
    station.
    -Todd Hunter
    """
    if (enddate is None):
        enddate = startdate
    if (station=='Meteo129' and len(ignoreDates)<2):
        ignoreDates = ['2015-10-22','2015-10-23']
    if ('MeteoAPEX' != station and 'MeteoAPEX' != referenceStation):
        apex = False
    else:
        print "Setting APEX to True"
        apex = True
    if (x=='PRESSURE' or y =='PRESSURE'):
        # if pressure correction is going to be done, then we need to request it as the main quanitity
        quantity = 'PRESSURE'
    results,deltaHeights = getResampledWeatherFromDatabase(startdate, enddate, quantity,
                                                           referenceStation,
                                                           pressureCorrection, overwrite,
                                                           tmcdb=False, apex=apex,aste=aste,
                                                           ignoreDates=ignoreDates)
    pb.clf()
    desc = pb.subplot(111)
    if (y == 'PRESSURE'):
        if (pressureDifference):
            yname = station + '_minus_' + referenceStation + '_' + y
            ydata = results[station]['value']-results[referenceStation]['value']
            if (pressureCorrection):
                ylabel = r'%s (mb, corrected for $\Delta$h)' % (yname)
            else:
                ylabel = yname +' (mb)'
        else:
            ydata = results[station]['value']
            ylabel = 'PRESSURE (mb)'
        ydata *= 0.01
    elif (y == 'WINDDIRECTION'):
        ydata = np.degrees(results[station][y])
        pb.ylim([0,360])
        desc.yaxis.set_major_locator(MultipleLocator(30))
    else:
        ydata = results[station][y]
    if (x == 'WINDDIRECTION'):
        xdata = np.degrees(results[station][x])
        pb.xlim([0,360])
        desc.xaxis.set_major_locator(MultipleLocator(30))
    else:
        xdata = results[station][x]
    if (kde):
        nbins = 20
        k = scipy.stats.kde.gaussian_kde((xdata,ydata))
        xi, yi = np.mgrid[xdata.min():xdata.max():nbins*1j,
                          ydata.min():ydata.max():nbins*1j]
        zi = k(np.vstack([xi.flatten(), yi.flatten()]))
        desc.pcolormesh(xi,yi,zi.reshape(xi.shape))
    elif (x == 'WINDDIRECTION'):
        xcolorvar = results[station]['WINDSPEED']
        idx = np.where(xcolorvar>minWindspeed)[0]
        xcolorvar = xcolorvar[idx]
        xdata = xdata[idx]
        ydata = ydata[idx]
        if True:
            percentiles = [10,25,50,75,90]
            perc = computePercentiles(xcolorvar, values=percentiles)
            print "Windspeed percentiles = ", perc
            idx2 = np.where(xcolorvar<perc[10])[0]
            pb.plot(xdata[idx2], ydata[idx2], 'k.')
            #           10  25  50  75  90
            colors = ['k','b','g','y','orange','r']
            keys = sorted(perc.keys())
            y0 = 0.76
            pb.text(0.1,y0,'v<%.1fm/s'%perc[10],transform=desc.transAxes,color=colors[0],
                    weight='bold')
            for i in range(1,len(perc)):
                idx2 = np.where(xcolorvar < perc[keys[i]])[0]
                idx3 = np.where(xcolorvar > perc[keys[i-1]])[0]
                idx4 = np.intersect1d(idx3,idx2)
                print "plotting %d points for perc=%d" % (len(idx4),percentiles[i])
                pb.plot(xdata[idx4], ydata[idx4], '.', mfc=colors[i],mec=colors[i])
                pb.text(0.1,y0+i*0.04,'%.1f<v<%.1fm/s'%(perc[keys[i-1]],perc[keys[i]]),
                        transform=desc.transAxes,color=colors[i], weight='bold')
            idx2 = np.where(xcolorvar > perc[keys[-1]])[0]
            pb.plot(xdata[idx2], ydata[idx2], '.', mfc=colors[-1], mec=colors[-1])
            pb.text(0.1,0.96,'v>%.1fm/s'%perc[keys[-1]],transform=desc.transAxes,
                    color=colors[-1], weight='bold',size=13)
#            for i,p in enumerate(percentiles[1:-1]):
#                pb.text(0.005,y0+i*0.04+0.02, '%d-%d%%', transform=desc.transAxes)
        else:
            pb.scatter(xdata, ydata, c=xcolorvar, marker='.', cmap='rainbow')
    else:
        pb.plot(xdata, ydata, 'k.')
    if (ylim == ''):
        y0,y1 = pb.ylim()
        pb.ylim([-np.max(np.abs([y0,y1])), np.max(np.abs([y0,y1]))])
    else:
        pb.ylim(ylim)
    pb.xlabel(station+' '+x, size=16)
    pb.ylabel(ylabel,size=12)
    mytitle = '%s to %s (%s, $\Delta$h = %+.0fm)' % (startdate,enddate,station,deltaHeights[station])  
    if (minWindspeed > 0):
        mytitle += ' (windspeed > %.1f m/s)' % (minWindspeed)
    pb.title(mytitle, size=16)
    if (plotfile != ''):
        if (plotfile == True):
            if (minWindspeed > 0):
                png = startdate+'_'+enddate+'.'+station+'.'+y+'.vs.'+x+'.wind.gt.'+str(minWindspeed)+'.png'
            else:
                png = startdate+'_'+enddate+'.'+station+'.'+y+'.vs.'+x+'.png'
        else:
            png = plotfile
        pb.savefig(png)
        print "Wrote png = ", png
        return(png)

def plotWeatherFromDatabase(startdate=None, enddate=None, quantity='PRESSURE',
                            referenceStation='MeteoCentral',
                            colors='', overlayRows=2, pixels=700,
                            showHumidityAsPartialPressure=False,
                            ylimitsIgnoreStations=['Meteo131'],
                            xaxisUnits='days', pressureCorrection=True,
                            overwrite=False, plotfile='', window='',
                            window_len=5, ylimits={'PRESSURE':[548,560]},
                            removeMedianFromDifferences=False, apex=True, osf=False,
                            tmcdb=False, multipanel=True, tempCorrectionFixed=False,
                            verbose=False, wind=True, meteoColor='r',plotsPerDay=1,
                            antennas={'Meteo201':'DA65','Meteo130':'DV09','MeteoTB2':'DV13'},
                            pdf=False, aste=False):
    """
    Gathers weather data from TMCDB, interpolates to common time grid, and
    plots the results.
    startdate and enddate:  'YYYY-MM-DD'
    referenceStation: the reference station to scale other stations' pressure to
    window: type of window from 'flat','hanning','hamming','bartlett','blackman'
            flat window will produce a moving average smoothing.
    window_len: the dimension of the smoothing window
    ylimits: for the top panel of the first plot (in mbar)
    removeMedianFromDifferences: subtract each station's median from itself
             before taking differences
    multipanel: if True, then the first plot will include the pressure difference panels
    tempCorrectionFixed: if True, then use a fixed temperature (0C) in the pressure conversion
    ylimitsIgnoreStations: for the difference plots, set ylimits to cover all
         data from all stations except those named in this list
    verbose: if True, print message for each file downloaded
    antennas: the mapping of weather station to antenna name (this could be replaced
              by a call to the TMCDB if it becomes accessible from outside JAO)
    plotsPerDay: if >1, then produce this many pngs per day for the polar plot
    apex: if True, then also grab and plot APEX weather
    aste: if True, then also grab and plot ASTE weather
    osf: if True, then also grab and plot OSF weather
    tmcdb: if True, use TMCDB, otherwise use weather.aiv.alma.cl
    pixels: width of logarithmic polar plot image in pixels
    pdf: if True, then also build a multi-page PDF if plotsPerDay>1
    """
    if (type(ylimits)==list):
        ylimits = {quantity: ylimits}
    if (colors == ''):
        colors = list(weatherStationColors)
    if (startdate is None):
        startdate = getCurrentDate(delimiter='-')
    if (enddate is None):
        enddate = startdate
    results = getResampledWeatherFromDatabase(startdate, enddate, quantity,
                                           referenceStation, pressureCorrection,
                                           overwrite, tempCorrectionFixed, verbose,
                                           showHumidityAsPartialPressure, apex,
                                              tmcdb, osf, aste)
    if (wind):
        if (tmcdb):
            windspeed, ignore = getResampledWeatherFromDatabase(startdate, enddate, 'WINDSPEED', 
                                                         overwrite=overwrite, verbose=verbose,
                                                         apex=apex, tmcdb=tmcdb)
            winddir, ignore = getResampledWeatherFromDatabase(startdate, enddate, 'WINDDIRECTION',
                                                       overwrite=overwrite, verbose=verbose,
                                                       apex=apex, tmcdb=tmcdb)
        else:
            data, deltaHeights = results
            windspeed = {}
            winddir = {}
            for station in data.keys():
                windspeed[station] = {}
                windspeed[station]['value'] = np.array(data[station]['WINDSPEED'])
                windspeed[station]['mjdsec'] = np.array(data[station]['mjdsec'])
                winddir[station] = {}
                winddir[station]['value'] = np.array(data[station]['WINDDIRECTION'])
                winddir[station]['mjdsec'] = np.array(data[station]['mjdsec'])
            
        # compute full-day statistics
        for station in windspeed.keys():
            windspeed[station]['median'] = np.median(windspeed[station]['value'])
            sinWindDirection = np.sin(np.array(winddir[station]['value']))
            cosWindDirection = np.cos(np.array(winddir[station]['value']))
            winddir[station]['median'] = np.arctan2(np.mean(sinWindDirection),
                                                    np.mean(cosWindDirection))
            if (winddir[station]['median'] < 0):
                winddir[station]['median'] += 2*np.pi
        if plotsPerDay>1:
            # compute plotsPerDay statistics
            secondsPerPlot = 86400/plotsPerDay
            for station in windspeed.keys():
                for h in range(plotsPerDay):
                    idx1 = np.where(windspeed[station]['mjdsec']%86400 > h*secondsPerPlot)[0]
                    idx2 = np.where(windspeed[station]['mjdsec']%86400 < (h+1)*secondsPerPlot)[0]
                    rows = np.intersect1d(idx1,idx2)
                    windspeed[station][h] = np.median(np.array(windspeed[station]['value'])[rows])
                    sinWindDirection = np.sin(np.array(winddir[station]['value'])[rows])
                    cosWindDirection = np.cos(np.array(winddir[station]['value'])[rows])
                    winddir[station][h] = np.arctan2(np.mean(sinWindDirection),
                                                     np.mean(cosWindDirection))
                    if (winddir[station][h] < 0):
                        winddir[station][h] += 2*np.pi
            
    else:
        windspeed = {}
        winddir = {}
    
    if (results is None): return results
    data, deltaHeights = results
    stations = data.keys()
    if (len(data[stations[0]]['mjdsec']) == 0):
        print "No times found for station 0 = ", stations[0]
        return None
    x0 = np.min(data[stations[0]]['mjdsec'])
    pb.clf()
    if (multipanel):
        mng = pb.get_current_fig_manager()
        mng.resize(700,1000)
        rows = overlayRows+len(stations)-1
        columns = 1
        fontsize = 8
        desc = pb.subplot2grid((rows,columns),(0,0),rowspan=overlayRows)
    else:
        desc = pb.subplot(111)
        fontsize = 9
    list_of_date_times = mjdSecondsListToDateTime(data[referenceStation]['mjdsec'])
    timeplot = pb.date2num(list_of_date_times)
    for i,station in enumerate(stations):
        if (window != ''):
            data[station]['value'] = smooth(data[station]['value'], window_len,
                                            window)
        if (quantity == 'PRESSURE'):
            value = np.array(data[station]['value'])*0.01
            mbar = value
        elif (quantity == 'HUMIDITY'):
            value = np.array(data[station]['value'])
            if (not showHumidityAsPartialPressure):
                # convert humidity fraction to percentage
                value *= 100
        else:
            value = np.array(data[station]['value'])
        try:
            pb.plot_date(timeplot, value,'-',color=colors[i])
        except:
            print "i=%d, len(colors)=%d, colors=" % (i,len(colors)), colors
            raise
        pb.text(-0.1+i*0.14, 1+.025*(1+int(multipanel)), station, color=colors[i],
                transform=desc.transAxes,size=fontsize+1)
        if (station == referenceStation):
            pb.text(-0.1+i*0.14, 1+.07*(1+int(multipanel)), '(reference)', color=colors[i],
                    transform=desc.transAxes,size=fontsize+1)
    if (startdate==enddate):
        xaxisUnits = 'hours'
    setXaxisDateFormatter(desc, xaxisUnits)
    if (quantity in ylimits.keys()):
        if (len(ylimits[quantity]) == 2):
            pb.ylim(ylimits[quantity])
    RescaleXAxisTimeTicks(pb.xlim(), desc)
    daytimeRanges = findDaytime(startdate, enddate, finestSearch=4.0)
    shadeRanges(desc, daytimeRanges)
    resizeFontsOnly(desc, fontsize)
    yaxisUnits = {'P':'mb', 'T':'C', 'H':'%', 'S':'m/s', 'D':'deg' }
    if (showHumidityAsPartialPressure):
        yaxisUnits['H'] = 'mb'
    yaxisLabel = (quantity.replace('WIND',''))[0]
    if (pressureCorrection and quantity == 'PRESSURE'):
        if multipanel:
            pb.ylabel('P(%s, corrected)'%(yaxisUnits[yaxisLabel]), size=fontsize)
        else:
            pb.ylabel('PRESSURE (corrected for delta height) (%s)'%(yaxisUnits[yaxisLabel]), size=fontsize)
    else:
        pb.ylabel('%s (%s)'%(quantity,yaxisUnits[yaxisLabel]), size=fontsize)
    if pressureCorrection:
        medianTemp = kelvinToCelsius(np.median(data[referenceStation]['temperatureK']))
        medianPressure = np.median(data[referenceStation]['value'])*0.01
        yvalue = 0.95-0.1*int(multipanel)
        pb.text(0.02,yvalue,'median T = %+.2fC, P=%.2fmb' % (medianTemp,medianPressure),
                size=fontsize, transform=desc.transAxes)
        if (wind):
            print "%12s: median T=%+.2fC, W=%5.2fm/s @%3.0fdeg P=%.2fmb, dH=0.0m" % (referenceStation,medianTemp,windspeed[referenceStation]['median'],np.degrees(winddir[referenceStation]['median']),medianPressure)
        else:
            print "%12s: median T=%+.2fC, P=%.2fmb, dH=0.0m" % (referenceStation,medianTemp,medianPressure)
    if (multipanel):
        desc.xaxis.set_ticklabels([])
        colors.remove(colors[stations.index(referenceStation)])
        allStations = stations[:]
        stations.remove(referenceStation)
        differences = {}
        for i,station in enumerate(stations):
            mbar = (data[station]['value'] - data[referenceStation]['value'])
            if (quantity == 'PRESSURE'):
                mbar *= 0.01
            elif (quantity == 'HUMIDITY'):
                if (not showHumidityAsPartialPressure):
                    mbar *= 100
            differences[station] = mbar
            if (removeMedianFromDifferences):
                differences[station] -= np.median(mbar)
        mbar = []
        for i,station in enumerate(stations):
            if (station in ylimitsIgnoreStations): continue
            mbar += list(differences[station])
        mbar = np.array(mbar)
        idx = np.where(mbar > -250)[0]  # ignore non-existent (i.e. 0) values
        if (len(idx) > 1):
            ylimits = [np.min(mbar[idx]), np.max(mbar[idx])]
        P = []
        dP = []
        dPmad = []
        dH = []
        i = 0
        for station in allStations:
            if pressureCorrection:
                dH.append(deltaHeights[station])
            if (station == referenceStation):
                if (plotsPerDay>1):
                    dP.append(np.zeros(plotsPerDay))
                    dPmad.append(np.zeros(plotsPerDay))
                else:
                    dP.append(0.0)
                    dPmad.append(0.0)
                continue
            desc = pb.subplot2grid((rows,columns),(overlayRows+i,0),rowspan=1)
            mbar = differences[station]
            pb.plot_date(timeplot, mbar, '-', color=colors[i])
            pb.plot(pb.xlim(),[0,0],'k:')
            if (station in antennas.keys()):
                if (station == 'Meteo201'):
                    yvalue = 0.8
                else:
                    yvalue = 0.1
                pb.text(0.05,yvalue,antennas[station],transform=desc.transAxes,size=fontsize)
            pb.ylabel(r'$\Delta$%s(%s)'%(yaxisLabel,yaxisUnits[yaxisLabel]), size=fontsize)
            pb.ylim(ylimits)
            setXaxisDateFormatter(desc, xaxisUnits)
#            RescaleXAxisTimeTicks(pb.xlim(), desc)
            if (i < len(stations)-1):
                desc.xaxis.set_ticklabels([])
            shadeRanges(desc, daytimeRanges)
            resizeFontsOnly(desc, fontsize)
            if pressureCorrection:
                medianTemp = kelvinToCelsius(np.median(data[station]['temperatureK']))
                medianPressure = np.median(data[station]['value'])*0.01
                madPressure = MAD(mbar)
                if (wind):
                    mystring = "%12s: median T=%+.2fC, W=%5.2fm/s @%.0fdeg P=%.2fmb, dP=%+.2f+-%.2fmb, dH=%0.1fm" % (station,medianTemp,windspeed[station]['median'],np.degrees(winddir[station]['median']),medianPressure,np.median(mbar),madPressure,deltaHeights[station])
                else:
                    mystring = '%12s: median T=%+.2fC, P=%.2fmb, dP=%+.2f+-%.2fmb, dH=%+.1fm' % (station,medianTemp,medianPressure,np.median(mbar),madPressure,deltaHeights[station])
                print mystring
                if (station == 'Meteo201'):
                    pb.text(0.02, 0.1, mystring, size=fontsize, transform=desc.transAxes)
                else:
                    pb.text(0.02, 0.70, mystring, size=fontsize, transform=desc.transAxes)
                P.append(medianPressure)
                if (plotsPerDay>1):
                    secondsPerPlot = 86400/plotsPerDay
                    medianMbar = []
                    madMbar = []
                    for h in range(plotsPerDay):
                        idx1 = np.where(np.array(data[station]['mjdsec'])%86400 > h*secondsPerPlot)[0]
                        idx2 = np.where(np.array(data[station]['mjdsec'])%86400 < (h+1)*secondsPerPlot)[0]
                        idx = np.intersect1d(idx1,idx2)
#                        print "Using %d points for hour=%d" % (len(idx), h)
                        medianMbar.append(np.median(mbar[idx]))
                        madMbar.append(MAD(mbar[idx]))
                    dP.append(medianMbar)
                    dPmad.append(madMbar)
                else:
                    dP.append(np.median(mbar))
                    dPmad.append(madPressure)
            i += 1
    day = mjdsecToDate(data[station]['mjdsec'][0])
    year = day.split('-')[0]
    if (xaxisUnits == 'days'):
        pb.xlabel('UT (%s)'%year)
    else:
        pb.xlabel('UT (%s)'%startdate)
    if (len(timeplot) < 10):
        print "Not enough data to plot on %s" % (startdate)
        return None
    pb.draw()
    if (plotfile != ''):
        if (plotfile == True):
            if (startdate == enddate):
                png = "%s_vs_time_%s.png" % (quantity,startdate)
            else:
                png = "%s_vs_time_%s_%s.png" % (quantity,startdate,enddate)
        else:
            png = plotfile
    else:
        png = '_'.join([quantity,startdate,enddate])+'.png'
    pb.savefig(png)
    print "Saved figure ", png
    if (pressureCorrection and multipanel and quantity=='PRESSURE'):
        pb.figure(2)
        pb.clf()
        pb.subplot(111)
        for i in range(len(dH)): # loop over stations
            if (not plotsPerDay>1):
                if (abs(dP[i]) < 50):
                    # don't plot crazy values
                    pb.errorbar(dH[i], dP[i], yerr=dPmad[i], color='k', fmt='o')
            else:
                if (np.abs(nanmedian(dP[i])) < 50):
                    pb.errorbar(dH[i], nanmedian(dP[i]), yerr=nanmedian(dPmad[i]), color='k', fmt='o')
                else:
                    print "Not plotting dP=%.2f for %s" % (nanmedian(dP[i]),allStations[i])
                    print "P = ", P[i]
                    print "dP = ", dP[i]
        pb.plot(pb.xlim(),[0,0],'k:')
        labelWeatherStations = {}
        u = simutil.simutil()
        xpositions = []
        ypositions = []
        stationNames = []
        for i,stationName in enumerate(allStations):
            if (stationName.find('131')>=0 and startdate <= '2015-10-17'): continue
            stationNames.append(stationName)
            stationLabel = stationName[:]
            if stationLabel in antennas.keys():
                stationLabel += '(%s)' % (antennas[stationName])
            if plotsPerDay>1:
                pb.text(dH[i], nanmedian(dP[i]), stationLabel)
                for h in range(plotsPerDay):
                    if (h not in labelWeatherStations.keys()):
                        labelWeatherStations[h] = {}
                    labelWeatherStations[h][stationName] = dP[i][h]
            elif (abs(dP[i]) < 50):
                pb.text(dH[i], dP[i], stationLabel)
                labelWeatherStations[stationName] = dP[i]
            else:
                print "Not labeling %s because dP[i] = %f" % (stationName,dP[i])
            x0,y0,z0 = u.itrf2loc(allWeatherStationPositions[stationName][0],
                                  allWeatherStationPositions[stationName][1],
                                  allWeatherStationPositions[stationName][2],
                                  allWeatherStationPositions[referenceStation][0],
                                  allWeatherStationPositions[referenceStation][1],
                                  allWeatherStationPositions[referenceStation][2])
            xpositions.append(x0)
            ypositions.append(y0)
        pb.xlabel(r'$\Delta$ Height (m)')
        pb.ylabel(r'Median $\Delta$P(station-reference) (mb) after correcting for $\Delta$Height')
        pb.title('%s to %s: relative to %s' % (startdate,enddate,referenceStation))
        png = png.replace('.png','dPvsdH.png')
        pb.savefig(png)
        print "Saved figure ", png
        pb.figure(3)
        if (plotsPerDay>1):
            images = plotsPerDay
            if (plotfile == ''):
                plotfile = True
        else:
            images = 1
        if (wind):
            windstring = 'wind symbols in knots'
        else:
            windstring = ''
        xcenter = 0
        ycenter = 0
        showAzimuthLabels = True
        includeAntennas = False
        plotfiles = []
        for i in range(images):
            pb.clf()
            shade = ''
            if pressureCorrection:
                mytitle = 'Median pressure difference after height correction (mb)'
            else:
                mytitle = 'Median pressure difference (mb)'
            if plotsPerDay>1:
                if (plotfile == ''):
                    plotfile = True
                lws = labelWeatherStations[i]
                ws = {}
                wd = {}
                # pPL wants a dictionary keyed by station name, with value = {'median': value}
                for sta in windspeed.keys():
                    ws[sta] = {}
                    wd[sta] = {}
                    ws[sta]['median'] = windspeed[sta][i]
                    wd[sta]['median'] = winddir[sta][i]
                day = startdate.split()[0]
                label2 = windstring
                label3 = '%s UT %s-%s' % (day,hoursToHM(i*24.0/plotsPerDay),hoursToHM((i+1)*24.0/plotsPerDay))
                if plotfile == True:
                    png = 'chajnantorWeather_%s_%02d-%02d.png' % (day,i,i+1)
                else:
                    png = plotfile
                if (i>=plotsPerDay/2 and i<plotsPerDay):  # noon-midnight UT, i.e. 9AM to 9PM CLT
                    shade = 'palegoldenrod'
            else:
                lws = labelWeatherStations
                ws = windspeed
                wd = winddir
                label2 = windstring
                label3 = day
                if plotfile == True:
                    if (startdate == enddate):
                        png = 'chajnantorWeather_%s.png' % (startdate)
                    else:
                        png = 'chajnantorWeather_%s_%s.png' % (startdate,enddate)
                else:
                    png = plotfile
            plotPositionsLogarithmic(stationNames, xpositions, ypositions,
                                     xcenter, ycenter, mytitle, png,
                                     includeAntennas, lws, meteoColor,
                                     showAzimuthLabels, ws, wd, antennas,
                                     shade, deltaHeights, label2, label3,
                                     pixels, debug=verbose)
            plotfiles.append(png)
        pb.figure(1)
        if (plotsPerDay>1):
            if (pdf):
                pdf = 'chajnantorWeather_%s.pdf'%(day)
                buildPdfFromPngs(plotfiles, pdf, quiet=True)
            return plotfiles
        else:
            return png
    # end of plotWeatherFromDatabase
        
def setXaxisDateFormatter(desc, xaxisUnits):
    """
    Choose between hours or days for the xaxis of a plot_date plot.
    """
    if xaxisUnits=='minutes':
        desc.xaxis.set_major_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,15)))
        desc.xaxis.set_minor_locator(matplotlib.dates.MinuteLocator(byminute=range(0,60,5)))
        desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M'))
        desc.fmt_xdata = matplotlib.dates.DateFormatter('%H:%M')
    elif xaxisUnits=='hours':
        desc.xaxis.set_major_locator(matplotlib.dates.HourLocator(byhour=range(0,24,6)))
        desc.xaxis.set_minor_locator(matplotlib.dates.HourLocator(byhour=range(0,24,1)))
        desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H'))
        desc.fmt_xdata = matplotlib.dates.DateFormatter('%H')
    else:  # days
        desc.xaxis.set_major_locator(matplotlib.dates.HourLocator(byhour=range(0,240,24)))
        desc.xaxis.set_minor_locator(matplotlib.dates.HourLocator(byhour=range(0,24,6)))
        myformat = '%b-%d'
        desc.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(myformat))
        desc.fmt_xdata = matplotlib.dates.DateFormatter(myformat)

def findDaytime(startdate, enddate=None, observatory='ALMA',
                intervalMinutes=30, finestSearch=4.0):
    """
    Finds the range of date values (suitable for pylab.plot_date) that
    correspond to daylight hours at the specified observatory for the
    specified range of dates.
    intervalMinutes: initial grid size to use in the search
    finestSearch: final grid to use (in minutes)
    Returns: a list of 2-element arrays corresponding to sunrise, sunset
    -Todd Hunter
    """
    if (enddate is None): enddate = startdate
    daysToPlot = computeIntervalBetweenTwoDays(enddate,startdate)
    ranges = []
    for i in range(daysToPlot+1):
        day = subtractDays(enddate,i)
        mylist = sunrise(day,observatory,intervalMinutes,finestSearch,verbose=False)
        if (mylist is None): return
        sun_num = pb.date2num(mjdSecondsListToDateTime(mylist))
        ranges.append(sun_num)
    return ranges

def shadeDaytime(desc, startdate, enddate):
    ranges = findDaytime(desc, startdate, enddate)
    shadeRanges(ranges)

def shadeRanges(desc, daytimeRanges, color='lemonchiffon'):
    """
    Shades a specified x-axis date range on a pylab.plot_date plot.
    -Todd Hunter
    """
    for r in daytimeRanges:
        desc.axvspan(r[0], r[1], color=color)

def fitLapseRateAndScaleHeightASDMs(filename, datestring='',asdm='',pdf=''):
    """
    Calls fitLapseRAteAndScaleHeightASDM for a list of ASDMs and compiles the results
    into a multi-page PDF.
    filename: name of O2 sounder csv file to use
    datestring: use the profile recorded closest to this time 'YYYY-MM-DD HH:MM:SS'
    asdm: use the profile recorded closest to the beginning of this dataset
    pdf: name of the PDF to produce
    -Todd Hunter
    """
    if (type(asdm) == str):
        if (asdm.find('*') >= 0):
            asdms = glob.glob('uid*')
        else:
            asdms = asdm.split(',')
    else:
        asdms = asdm
    pngs = []
    for asdm in asdms:
        print "Working on ASDM ", asdm
        profile = -1
        slope,intercept,profile = fitLapseRate(filename, profile, 'T',
                                               datestring=datestring, asdm=asdm)
        scaleHeight, value, groundValue = fitScaleHeight(filename, profile, 'VD',
                                                         datestring=datestring, asdm=asdm)
        mytitle = asdm + ', ' + getObservationStartDateFromASDM(asdm)[0]
        pngs.append(o2sounder(filename, returnProfiles=False, fitLR=[intercept,slope],
                             fitSH=scaleHeight, profile=profile, title=mytitle, plotfile=True))
    if (pdf == ''):
        pdf = 'lapseRate_scaleHeight.pdf'
    buildPdfFromPngs(pngs, pdf)
    return(pdf)

def fitLapseRateAndScaleHeightASDM(filename, datestring='',asdm=''):
    """
    Reads an ALMA O2 sounder dataset and fits for temperature lapse rate and
    water vapor density scale height.
    filename: name of O2 sounder csv file to use
    datestring: use the profile recorded closest to this time 'YYYY-MM-DD HH:MM:SS'
    asdm: use the profile recorded closest to the beginning of this dataset
    -Todd Hunter
    """
    profile = -1
    slope,intercept,profile = fitLapseRate(filename, profile, 'T',
                                           datestring=datestring, asdm=asdm)
    scaleHeight, value, groundValue = fitScaleHeight(filename, profile, 'VD',
                                        datestring=datestring, asdm=asdm)
    png = o2sounder(filename, returnProfiles=False, fitLR=[intercept,slope],
                    fitSH=scaleHeight, profile=profile, title=asdm, plotfile=True)
    return(png)    
    
def fitLapseRate(filename, profile=-1, quantity='T', datestring='',asdm='', 
                 plotfile=''):
    """
    Fits a line to the temperature vs. height curve from the O2 sounder.
    filename: csv file produced by the oxygen sounder
    profile: which time-series profile to fit (-1 means to compute all).
    quantity: 'T' for temperature or 'RH' for relative humidity
    datestring: use the data closest to this date 'YYYY-MM-DD HH:MM:SS'
    Returns: for 1 profile: slope (K/km), intercept, and profile#
      for multiple: medianDay, madDay, medianNight, madNight, medianTotal, madTotal
    -Todd Hunter
    """
    if (quantity not in ['T','RH']): 
        print "quantity must be T or RH"
        return
    height, profiles, datestamp = o2sounder(filename, returnProfiles=True, 
                                            quantity=quantity, plotfile=plotfile)
    dateTimeStamp = datestamp[0::4]
    integerSeconds = np.array(dateTimeListToMJDSeconds(dateTimeStamp,verbose=False))
    if (profile > -1 or datestring != '' or asdm != ''):
        if (profile > -1):
            profiles = [profiles[profile]]
        else:
            if (datestring != ''):
                targetSeconds = dateStringToMJDSec(datestring,verbose=False)
            elif (asdm != ''):
                targetSeconds = getObservationStartDateFromASDM(asdm)[1]
            else:
                print "You need to specify profile, datestring or asdm"
                return
            profile = np.argmin(np.abs(integerSeconds-targetSeconds))
            profiles = [profiles[profile]]
            print "Fitting profile %d at %s" % (profile, mjdsecToUT(integerSeconds[profile]))
    else:
        print "Fitting %d profiles" % (len(profiles))
    slopesDay = []
    slopesNight = []
    for i,prof in enumerate(profiles):
        slope, intercept = linfit().linfit(height, prof, 0.01*prof)
        if (integerSeconds[i]%86400 > 43200):  # daytime
            slopesDay.append(slope)
        else:
            slopesNight.append(slope)
    if (profile == -1):
        startDate = mjdsecToDate(integerSeconds[0])
        endDate = mjdsecToDate(integerSeconds[-1])
        medDay = np.median(slopesDay)
        madDay = MAD(slopesDay)
        medNight = np.median(slopesNight)
        madNight = MAD(slopesNight)
        medTotal = np.median(slopesDay+slopesNight)
        madTotal = MAD(slopesDay+slopesNight)
        filename = '%s.%s_%s.lapseRates' % (quantity,startDate,endDate)
        f = open(filename,'w')
        p = "%s) day:   lapse rate %.3f +- %.3f K/km" %(quantity,medDay,madDay)
        print p
        f.write(p+'\n')
        p = "%s) night: lapse rate %.3f +- %.3f K/km" %(quantity,medNight,madNight)
        print p
        f.write(p+'\n')
        p = "%s) total: lapse rate %.3f +- %.3f K/km" %(quantity,medTotal,madTotal)
        print p
        f.write(p+'\n')
        f.close()
        return(medDay, madDay, medNight, madNight, medTotal, madTotal)
    else:
        png = o2sounder(filename, quantity=quantity, fitLR=[intercept,slope],
                        profile=profile, plotfile=plotfile)
        return(slope, intercept, profile)

def fitScaleHeight(filename, profile=-1, quantity='VD', datestring='', asdm='',
                   plotfile=''):
    """
    Computes the scale height of a quantity measured by the O2 sounder.
    filename: csv file produced by the oxygen sounder
    profile: which time-series profile to fit (-1 means to compute all)
    quantity: RH, VD, LD (relative humidity, vapor density, liquid density).
    Returns: for 1 profile: scaleHeightFromGround, scaleHeightValue, groundValue
      for multiple:  medianDay, madDay, medianNight, madNight, medianTotal, madTotal
    -Todd Hunter
    """
    if (quantity not in ['T','RH','VD','LD']): 
        print "quantity must be T, RH, VD or LD"
        return
    height, profiles, datestamp = o2sounder(filename, returnProfiles=True, 
                                            quantity=quantity, plotfile=plotfile)
    dateTimeStamp = datestamp[0::4]
    integerSeconds = np.array(dateTimeListToMJDSeconds(dateTimeStamp,verbose=False))
    if (profile > -1 or datestring != '' or asdm != ''):
        if (profile > -1):
            profiles = [profiles[profile]]
        else:
            if (datestring != ''):
                targetSeconds = dateStringToMJDSec(datestring,verbose=False)
            elif (asdm != ''):
                targetSeconds = getObservationStartDateFromASDM(asdm)[1]
            else:
                print "You need to specify profile, datestring or asdm"
                return
            profile = np.argmin(np.abs(integerSeconds-targetSeconds))
            profiles = [profiles[profile]]
            print "Fitting profile %d at %s" % (profile, mjdsecToUT(integerSeconds[profile]))
    else:
        print "Fitting %d profiles" % (len(profiles))
    sHFGD = []  # day
    sHFMD = []  # day
    sHFGN = []  # night
    sHFMN = []  # night
    for i,prof in enumerate(profiles):
        groundValue = prof[0]
        maxValue = np.max(prof)
        # Note: groundValue is always maxValue for VD, but not 
        # for LD, so just use maxValue
        scaleHeightValue = maxValue/np.e
        # spline interpolatation for the point passing the 1/e level
        spline = scipy.interpolate.UnivariateSpline(height, 
                                             prof-scaleHeightValue, s=0)
        scaleHeightFromGround = spline.roots()[0]
        if (integerSeconds[i]%86400 > 43200):  # daytime
            sHFGD.append(scaleHeightFromGround)
        else: # nighttime
            sHFGN.append(scaleHeightFromGround)
    if (profile == -1):
        startDate = mjdsecToDate(integerSeconds[0])
        endDate = mjdsecToDate(integerSeconds[-1])
        medFGD = np.median(sHFGD)
        madFGD = MAD(sHFGD)
        medFGN = np.median(sHFGN)
        madFGN = MAD(sHFGN)
        medFGT = np.median(sHFGD+sHFGN)
        madFGT = MAD(sHFGD+sHFGN)
        filename = '%s.%s_%s.scaleHeights' % (quantity,startDate,endDate)
        f = open(filename,'w')
        p = "%s) day:   scale height %.3f +- %.3f km" %(quantity,medFGD,madFGD)
        print p
        f.write(p+'\n')
        p = "%s) night: scale height %.3f +- %.3f km" %(quantity,medFGN,madFGN)
        print p
        f.write(p+'\n')
        p = "%s) total: scale height %.3f +- %.3f km" %(quantity,medFGT,madFGT)
        print p
        f.write(p+'\n')
        f.close()
        return(medFGD, madFGD, medFGN, madFGN, medFGT, madFGT)
    else:
        png = o2sounder(filename, returnProfiles=False, profile=profile,
                        quantity=quantity, fitSH=scaleHeightFromGround, 
                        plotfile=plotfile)
        return(scaleHeightFromGround, scaleHeightValue, groundValue)

def retrieveO2sounderData(server='vesta'):
    """
    Data is contained at vesta,  username='oxygen'
    Need to open a tunnel via tatio, find latest datafile, and rsync it.
    """
    print "Not yet implemented."
    return
    
def o2sounder(filename, profile=0, makemovie=False, Tlimits=[210,290],
              VDlimits=[0,2.0], LDlimits=[0,0.05], RHlimits=[0,30], 
              delay=10, returnProfiles=False, quantity='T', fitLR=[],
              fitSH=None, title='', plotfile=''):
    """
    Loads a csv file from the O2 sounder and generates a plot or
    a movie, or returns profiles of T, RH, VD, LD.
    -Todd Hunter
    """
    o2 = O2SounderPlayer.o2SounderPlayer()
    height, profiles, weather, integrated = o2.readLv2Data(filename)
    height = np.array(height)
    if (returnProfiles):
        return (np.array(height), np.array(profiles[quantity]),np.array(profiles['t']))
    numberProfiles = len(profiles['T'])
    dateTimeStamp = profiles['t'][0::4]
    if makemovie:
        allProfiles = range(numberProfiles)
        pngs = []
    else: 
        allProfiles = [profile]
    shade = 'palegoldenrod'
    fontsize = 10
    integerSeconds = dateTimeListToMJDSeconds(dateTimeStamp,verbose=False)
    for prof in allProfiles:
        pb.clf()
        desc = pb.subplot(221)
        pb.plot(profiles['T'][prof], height, 'k-')
        pb.title(r'ALMA O$_2$ sounder')
        pb.xlabel('Temperature (K)')
        pb.ylabel('Height (km)')
        pb.xlim(Tlimits)
        resizeFontsOnly(desc, fontsize)
        if (integerSeconds[prof]%86400 > 43200):
            desc.set_axis_bgcolor(shade)
        if (len(fitLR) == 2):
            pb.plot(np.array(pb.ylim())*fitLR[1]+fitLR[0],pb.ylim(),'k--')
            pb.text(0.4,0.9,'%.3f K/km'%(fitLR[1]),transform=desc.transAxes)
            pb.text(0.4,0.8,'%.1f K at ground'%(fitLR[0]),transform=desc.transAxes)

        desc = pb.subplot(222)
        pb.plot(profiles['RH'][prof], height, 'k-')
        pb.xlabel('Relative humidity')
        if (len(RHlimits)==2):
            pb.xlim(RHlimits)
        if (makemovie):
            pb.title(str(dateTimeStamp[prof])+'  (%4d of %4d)'%(prof+1,numberProfiles),size=12)
        elif (title != ''):
            pb.title(title, size=10)
            
        resizeFontsOnly(desc, fontsize)
        if (integerSeconds[prof]%86400 > 43200):
            desc.set_axis_bgcolor(shade)

        desc = pb.subplot(223)
        pb.plot(profiles['VD'][prof], height, 'k-')
        pb.xlabel(r'Vapor density (g/m$^3$)')
        pb.ylabel('Height (km)')
        if (len(VDlimits)==2):
            pb.xlim(VDlimits)
        resizeFontsOnly(desc, fontsize)
        if (integerSeconds[prof]%86400 > 43200):
            desc.set_axis_bgcolor(shade)
        if (fitSH is not None):
            # y=0 when x=max
            # y=scaleHeight when x = max/e
            # y = C*exp(-x)
            # y = scaleHeight*(exp(-x))
            # y = scaleHeight*(exp(-(x-max/e)))
            pb.plot(np.max(profiles['VD'][prof])*np.exp(-height/fitSH),
                    height,'k--')
            pb.text(0.3,0.9,'%.3f km'%(fitSH),transform=desc.transAxes)
            pb.text(0.3,0.8,r'%.3f g/m$^3$ at ground'%(np.max(profiles['VD'][prof])),transform=desc.transAxes)
            pb.plot(np.ones(2)*np.max(profiles['VD'][prof])/np.e, [0,fitSH], 'k:')
            pb.plot([0,np.max(profiles['VD'][prof])/np.e], [fitSH,fitSH], 'k:')

        desc = pb.subplot(224)
        pb.plot(profiles['LD'][prof], height, 'k-')
        pb.xlabel(r'Liquid density (g/m$^3$)')
        if (len(LDlimits)==2):
            pb.xlim(LDlimits)
        resizeFontsOnly(desc, fontsize)
        if (integerSeconds[prof]%86400 > 43200):
            desc.set_axis_bgcolor(shade)
        pb.draw()
        mystring = str(dateTimeStamp[prof]).replace(' ','_')
        if (plotfile != ''):
            if (plotfile == True):
                png = 'o2_profiles_%s_%d.png' % (mystring,profile)
            else:
                png = plotfile
            pb.savefig(png)
            print "Wrote ", png
        if makemovie:
            pngs.append(png)
    if makemovie:
        gif = 'o2_profiles_%s_%s.gif'%(dateTimeStamp[0].replace(' ','_'),
                                       dateTimeStamp[allProfiles[-1]].replace(' ','_'))
        makeMovie(pngs, gif, delay)
        return gif
    elif plotfile != '':
        return (png)
    
def plotApexPWV(startdate=None, enddate=None, plotfile='', asdm=[],
                asdmzoom=True, antenna=''):
    """
    Retrieves and plots the PWV measured at APEX telescope, near ALMA.
    If asdm is specified, then it marks the range of time for that asdm
    or list of asdms and automatically widens the x-axis to contain all asdms.
    startdate: date on which to begin (at midnight)
    endate: date on which to end (at midnight)
    asdm: either a comma-delimited string or a list of strings, or a single
            string with wildcard character (.ms and .png are ignored)
    asdmzoom: if True then zoom to the timespan of the asdm(s)
    antenna: if asdm is specified, then also overlay PWV from this WVR
    -Todd Hunter
    """
    if (len(asdm) > 0):
        if (type(asdm) == str):
            if (asdm.find('*') >= 0):
                asdm = glob.glob(asdm)
                realasdms = []
                for a in asdm:
                    if (a.find('.ms') < 0 and a.find('.png') < 0):
                        realasdms.append(a)
                asdm = realasdms
            else:
                asdm = asdm.split(',')
        mjdsec = []
        for a in asdm:
            mjdsec += getObservationMJDSecRangeFromASDM(a)
        t0 = np.min(mjdsec)
        t1 = np.max(mjdsec)
        startdate = mjdsecToDate(t0)
        enddate = addDays(mjdsecToDate(t1),1)
    else:
        if (startdate is None):
            startdate = getCurrentDate(delimiter='-')
        if (enddate is None):
            enddate = addDays(startdate,1)
    data = getApexWeather(startdate,enddate)
    interval = abs(computeIntervalBetweenTwoDays(startdate,enddate))
    pb.clf()
    desc = pb.subplot(111)
    list_of_date_times = mjdSecondsListToDateTime(data['mjdsec'])
    timeplot = pb.date2num(list_of_date_times)
    pb.ylabel('Zenith PWV (mm)')
    data['pwv'] = np.array(data['PWV'])
    idx = np.where(data['pwv'] > 0)[0]
    pb.plot_date(timeplot[idx], data['pwv'][idx], '-')
    daytimeRanges = findDaytime(startdate, addDays(startdate,interval-1))
    shadeRanges(desc, daytimeRanges)
    pb.xlabel('UT')
    colors = ['k','r']
    antennaString = ''
    for i,a in enumerate(asdm):
        mjdsec = getObservationMJDSecRangeFromASDM(a)
        list_of_date_times = mjdSecondsListToDateTime(mjdsec)
        timeplot = pb.date2num(list_of_date_times)
        pb.plot_date(timeplot, np.ones(2)*0.95*np.mean(pb.ylim()), '-', color=colors[i%2], lw=2)
        pb.text(np.mean(timeplot), np.mean(pb.ylim()),
                a, va='bottom', ha='center', rotation=90, size=9)
        if (antenna != ''):
            pb.hold(True)
            [watertime,water,antennaName] = readpwv(a)
            idx = np.where(np.array(antennaName) == antenna)[0]
            if (len(idx) > 0):
                water = np.array(water)[idx]
                list_of_date_times = mjdSecondsListToDateTime(np.array(watertime)[idx])
                timeplot = pb.date2num(list_of_date_times)
                pb.plot_date(timeplot,water*1000,'g-')
                antennaString = 'with ' + antenna
            else:
                print "Antenna %s is not in dataset" % (antenna)
            
    if (asdmzoom and len(asdm) > 0):
        timeplot = pb.date2num(mjdSecondsListToDateTime([t0,t1]))
        pb.xlim([np.min(timeplot)-0.1*(t1-t0)/86400.,
                 np.max(timeplot)+0.1*(t1-t0)/86400.])
    RescaleXAxisTimeTicks(pb.xlim(), desc)
    interval = pb.xlim()[1]-pb.xlim()[0]
    if (interval > 1.2):
        xaxisUnits = 'days'
        pb.title('APEX PWV (%s to %s) %s' % (startdate, enddate, antennaString))
    else:
        xaxisUnits = 'hours'
        pb.title('APEX PWV (%s) %s' % (startdate,antennaString))
    setXaxisDateFormatter(desc, xaxisUnits)        
    if (plotfile != ''):
        if (plotfile == True):
            plotfile = 'apexpwv_%s.png' % startdate
        pb.savefig(plotfile)
        print "Wrote plot: ", plotfile

def getAsteWeather(directory='aste-1s', startdate=None, enddate=None):
    """
    Reads ASCII files containing ASTE weather values
    obtained via email from Takeshi Okuda.
    -Todd Hunter
    """
    if (startdate is None):
        startdate = getCurrentDate(delimiter='-')
        enddate = addDays(startdate,1)
    elif (enddate is None):
        enddate = startdate
    data = {'TEMPERATURE':[], 'HUMIDITY': [], 'PRESSURE':[],
            'WINDSPEED':[], 'WINDDIRECTION': [], 'mjdsec':[]}
    for i in range(1+abs(computeIntervalBetweenTwoDays(startdate,enddate))):
        myDay = addDays(startdate,i).replace('-','')
        filename = directory + '/weather_%s*.log' % (myDay)
        filenames = sorted(glob.glob(filename))
        for filename in filenames:
           f = open(filename,'r')
           lines = f.readlines()
           f.close()
           for line in lines:
               day, hhmm, temp, humid, tempOut, humidOut, solar, rain, pressure, velocity, direction, ignore, ignore = line.split()
               data['mjdsec'].append(dateStringToMJDSec(day+' '+hhmm,verbose=False))
               if (tempOut.find('---')>=0):
                   if (len(data['TEMPERATURE']) < 1):
                       data['TEMPERATURE'].append(0)
                   else:
                       data['TEMPERATURE'].append(data['TEMPERATURE'][-1])
               else:
                   data['TEMPERATURE'].append(float(tempOut))
               if (humidOut.find('---')>=0):
                   if (len(data['HUMIDITY']) < 1):
                       data['HUMIDITY'].append(0)
                   else:
                       data['HUMIDITY'].append(data['HUMIDITY'][-1])
               else:
                   data['HUMIDITY'].append(float(humidOut))
               if (pressure.find('---')>=0):
                   if (len(data['PRESSURE']) < 1):
                       data['PRESSURE'].append(0)
                   else:
                       data['PRESSURE'].append(data['PRESSURE'][-1])
               else:
                   data['PRESSURE'].append(float(pressure)*100) # convert to Pascals
               if (velocity.find('---')>=0):
                   if (len(data['WINDSPEED']) < 1):
                       data['WINDSPEED'].append(0)
                   else:
                       data['WINDSPEED'].append(data['WINDSPEED'][-1])
               else:
                   data['WINDSPEED'].append(float(velocity))
               if (direction.find('---')>=0):
                   if (len(data['WINDDIRECTION']) < 1):
                       data['WINDDIRECTION'].append(0)
                   else:
                       data['WINDDIRECTION'].append(data['WINDDIRECTION'][-1])
               else:
                   data['WINDDIRECTION'].append(np.radians(float(direction)))
        print "Found %d existing file(s) for ASTE, median pressure = %.3fmb" % (len(filenames),np.median(data['PRESSURE'])*0.01)
    return data

def getApexWeather(startdate=None, enddate=None):
    """
    Retrieves weather for a whole day(s) from APEX archive.
    Units match the ALMA weather stations (C,hPa,m/s,radian)
    -Todd Hunter
    """
    if (startdate is None):
        startdate = getCurrentDate(delimiter='-')
        enddate = addDays(startdate,1)
    elif (enddate is None):
        enddate = addDays(startdate,1)
    elif (startdate == enddate):
        print "Startdate cannot equal enddate"
        return
    filename = 'APEX.%s_%s.dat' % (startdate,enddate)
    data = {'PWV': [], 'HUMIDITY': [], 'PRESSURE': [], 'TEMPERATURE': [],
            'WINDDIRECTION': [], 'WINDSPEED': [], 'mjdsec': []}
    if (not os.path.exists(filename) or
        enddate==addDays(getCurrentDate(delimiter='-'),1)):
        url = 'http://archive.eso.org/wdb/wdb/eso/meteo_apex/query/?'
        form_data = {'start_date': '%s..%s'%(startdate,enddate),
                     'wdbo':'ascii/download'}
        params = urllib.urlencode(form_data)
        response = urllib2.urlopen(url+params)
        lines = response.readlines()
        for line in lines:
            if (line.find('SHUTTER')>=0):
                d, w, a, e, s, h, p, t, angle, v = line.split()
                if (w == 'N/A'):
                    w = 0
                if (h == 'N/A'):
                    h = 0
                if (p == 'N/A'):
                    p = 0
                if (t == 'N/A'):
                    t = 0
                if (angle == 'N/A'):
                    angle = 0
                if (v == 'N/A'):
                    v = 0
                if (w!=0 or h!=0 or p!=0 or t!=0 or angle!=0 or v!=0):
                    data['mjdsec'].append(dateStringToMJDSec(d,verbose=False))
                    data['PWV'].append(float(w))
                    data['HUMIDITY'].append(float(h))
                    data['PRESSURE'].append(float(p)*100) # convert to ALMA units hPA
                    data['TEMPERATURE'].append(float(t))
                    data['WINDDIRECTION'].append(np.radians(float(angle)))
                    data['WINDSPEED'].append(float(v))
        fi = open(filename, 'w')
        for i in range(len(data['mjdsec'])):
            fi.write('%f %f %f %f %f %f %f\n' % (data['mjdsec'][i],
                                                 data['PWV'][i],
                                                 data['HUMIDITY'][i],
                                                 data['PRESSURE'][i],
                                                 data['TEMPERATURE'][i],
                                                 data['WINDDIRECTION'][i],
                                                 data['WINDSPEED'][i]))
    else:
        fi = open(filename, 'r')
        for line in fi.readlines():
            a,b,c,d,e,f,g = line.split()
            data['mjdsec'].append(float(a))
            data['PWV'].append(float(b))
            data['HUMIDITY'].append(float(c))
            data['PRESSURE'].append(float(d))
            data['TEMPERATURE'].append(float(e))
            data['WINDDIRECTION'].append(float(f))
            data['WINDSPEED'].append(float(g))
        print "Reading existing file = %s, median pressure=%.3fmb" % (filename,np.median(data['PRESSURE'])*0.01)
    fi.close()
    return(data)

def waterPartialPressure(relativeHumidityFraction, temperatureCelsius):
    """
    Converts relative humidity and temperature into water partial pressure.
    """
    p = relativeHumidityFraction * waterVaporPressure(temperatureCelsius)
    return p
    
def waterVaporPressure(temperatureCelsius):
    """
    Antoine equation for pressure valid from <100C, returned in mbar.
    """
    A = 8.07131
    B = 1730.63
    C = 233.426
    P_mmHg = 10**(A - (B/(C+temperatureCelsius)))
    P_mbar = P_mmHg/.750061561303
    return P_mbar

def getResampledWeatherFromDatabase(startdate, enddate=None, quantity='PRESSURE',
                                    referenceStation='MeteoTB2',
                                    pressureCorrection=True, overwrite=False,
                                    tempCorrectionFixed=False, verbose=True,
                                    showHumidityAsPartialPressure=False,
                                    apex=True, tmcdb=False, osf=False, aste=False,
                                    ignoreDates=[]):
    """
    Gets weather data (either from TMCDB or AIV) for all stations, currently:
       ['Meteo129','Meteo130','Meteo201','Meteo309',
        'Meteo410','MeteoCentral','MeteoTB2']
    then resamples them onto the time grid of the specified reference station.
    Writes data into files (one per weather station per day), and
    returns a dictionary keyed by station name with values of 'mjdsec',
        'value' and 'temperatureK'.
    Inputs:
    startdate and enddate:  'YYYY-MM-DD'
    pressureCorrection: if True, apply correction for height differences
    overwrite: if True, create new data files even if they already exist
    tempCorrectionFixed: if True, use 0 C as the correction temperature
          if False, use the temperature at each station to be corrected
    -Todd Hunter
    """
    weatherStationPositions = dict(allWeatherStationPositions)
    weatherStationPositions.pop("MeteoTB1", None)
    if not apex:
        weatherStationPositions.pop("MeteoAPEX", None)
    if not aste:
        weatherStationPositions.pop("MeteoASTE", None)
    if not osf:
        weatherStationPositions.pop("MeteoOSF", None)
    if (enddate is None):
        enddate = startdate
    if pressureCorrection:
        deltaHeights = computeDeltaEllipsoidalHeights(weatherStationPositions,
                                                      referenceStation)
    else:
        deltaHeights = None
    if (tmcdb):
        datafile = getWeatherFromTMCDB(startdate, enddate, quantity,
                                       weatherStationPositions.keys(), overwrite,
                                       verbose, apex)
    else:
        almaStations = weatherStationPositions.keys()
        if ('MeteoAPEX' in almaStations):
            almaStations.remove('MeteoAPEX')
        if ('MeteoASTE' in almaStations):
            almaStations.remove('MeteoASTE')
        datafile = {}
        for i in range(1+abs(computeIntervalBetweenTwoDays(startdate,enddate))):
            myDay = addDays(startdate,i)
            if (myDay in ignoreDates): continue
            datafileOneday = getWeatherFromAIV(myDay,almaStations,overwrite, verbose, apex,
                                               aste)
            if (datafile == {}):
                datafile = python_copy.deepcopy(datafileOneday)
            else:
                for myStation in datafile.keys():
                    for value in datafile[myStation].keys():
                        datafile[myStation][value] += datafileOneday[myStation][value]
                        
    stationNames = datafile.keys()
    if (tmcdb):
        if (len(datafile[referenceStation]) == 0):
            print "No files retrieved for reference station on %s." % (startdate)
            return
        if (not os.path.exists(datafile[referenceStation])):
            print "Could not find file for reference station"
            return
        data = {referenceStation: readTMCDBWeatherDataFile(datafile[referenceStation])}
    else:
        # it is actually the data dictionary already
        data = {referenceStation: datafile[referenceStation]}
        data[referenceStation]['value'] = data[referenceStation]['PRESSURE']
        data[referenceStation]['WINDSPEED'] = data[referenceStation]['WINDSPEED']
        data[referenceStation]['WINDDIRECTION'] = data[referenceStation]['WINDDIRECTION']
    for stationName in stationNames:
        if (tmcdb):
            if (datafile[stationName] is None):
                print "No data found for %s" % (stationName)
                continue
            if (len(datafile[stationName]) == 0):
                print "No %s data found for %s" % (quantity,stationName)
                continue
        if (stationName != referenceStation):
            if (stationName in ['MeteoAPEX','MeteoASTE'] or not tmcdb):
                # it is actually the data dictionary already
                data[stationName] = {}
                data[stationName]['mjdsec'] = datafile[stationName]['mjdsec']
                data[stationName]['value'] = datafile[stationName][quantity]
                data[stationName]['WINDSPEED'] = datafile[stationName]['WINDSPEED']
                data[stationName]['WINDDIRECTION'] = datafile[stationName]['WINDDIRECTION']
            else:
                data[stationName] = readTMCDBWeatherDataFile(datafile[stationName])
            # Protect against duplicate data points causing interpolation to crash
            idx = np.argsort(data[stationName]['mjdsec'])
            data[stationName]['mjdsec'] = np.array(data[stationName]['mjdsec'])[idx]
            data[stationName]['value'] = np.array(data[stationName]['value'])[idx]
            if (len(data[stationName]['mjdsec']) > 0):
                newdata = interpolateSpectrum(data[stationName]['mjdsec'],
                                              data[stationName]['value'],
                                              data[referenceStation]['mjdsec'],k='linear',
                                              bounds_error=False,
                                              fill_value=np.median(data[stationName]['value']))
            else: # protect against total lack of data
                newdata = np.zeros(len(data[referenceStation]['mjdsec']))
            data[stationName]['value'] = newdata
            for myquantity in ['WINDSPEED','WINDDIRECTION']:
                if (len(data[stationName]['mjdsec']) > 0 and myquantity in data[stationName] and 
                    myquantity in data[referenceStation]):
                    if (len(data[stationName][myquantity]) != len(data[referenceStation][myquantity])):
                        data[stationName][myquantity] = interpolateSpectrum(data[stationName]['mjdsec'],
                                                                            data[stationName][myquantity],
                                                                            data[referenceStation]['mjdsec'],k='linear',
                                                                            bounds_error=False,
                                                                            fill_value=np.median(data[stationName][myquantity]))
                else:
                    data[stationName][myquantity] = np.zeros(len(data[referenceStation]['mjdsec']))
                        
            data[stationName]['mjdsec'] = data[referenceStation]['mjdsec']
        if ((pressureCorrection and len(stationNames) > 1 and quantity=='PRESSURE') or (quantity=='HUMIDITY' and showHumidityAsPartialPressure)):
            # Then we need the temperature
            if (stationName in ['MeteoAPEX','MeteoASTE'] or not tmcdb):
                temperature = {}
                temperature['mjdsec'] = datafile[stationName]['mjdsec']
                temperature['value'] = datafile[stationName]['TEMPERATURE']
            else:
                temperature = readTMCDBWeatherDataFile(datafile[stationName].replace('PRESSURE','TEMPERATURE'))
            if (tmcdb):
                # Protect against duplicate data points causing interpolation to crash
                idx = np.argsort(temperature['mjdsec'])
            else:
                idx = range(len(temperature['mjdsec']))
            temperature['mjdsec'] = np.array(temperature['mjdsec'])[idx]
            temperature['value'] = np.array(temperature['value'])[idx]
            if (len(temperature['mjdsec']) > 0):
                temperature = interpolateSpectrum(temperature['mjdsec'],
                                              temperature['value'],
                                              data[referenceStation]['mjdsec'],
                                              k='linear',bounds_error=False,
                                              fill_value=np.median(temperature['value']))
            else: # protect against total lack of data
                temperature = np.zeros(len(data[referenceStation]['mjdsec']))
            if (np.median(temperature) < 100):
                # Auto correct to Kelvin
                temperatureK = celsiusToKelvin(temperature)
                data[stationName]['temperatureK'] = temperatureK
                data[stationName]['temperatureC'] = temperature
            else:
                temperatureK = temperature
                data[stationName]['temperatureK'] = temperatureK
                data[stationName]['temperatureC'] = kelvinToCelsius(temperature)
            if tempCorrectionFixed:
                temperatureK = celsiusToKelvin(0.0)
            if (pressureCorrection and quantity=='PRESSURE'):
                heightDiff = -deltaHeights[stationName]
                pCF = pressureCorrectionFactor(heightDiff,temperatureK)
                data[stationName]['value'] *= pCF
                print "%s: median pCF=%f" % (stationName, np.median(pCF))
            if (showHumidityAsPartialPressure and quantity=='HUMIDITY'):
                data[stationName]['value'] = waterPartialPressure(data[stationName]['value'], data[stationName]['temperatureC'])
    return data, deltaHeights

def plotMedianWeatherFromAIVForASDMs(asdms, quantities='', station='MeteoTB2',
                                     plotfile=''):
    """
    Plots the median of the 5 main weather quantities for the list of ASDMs.
    -Todd Hunter
    """
    if (quantities == ''):
        quantities = ['TEMPERATURE','HUMIDITY','PRESSURE','WINDSPEED',
                      'WINDDIRECTION']
    rows = int(np.ceil(len(quantities)**0.5))
    columns = int(np.ceil(len(quantities)*1.0/rows))
    day = []
    if (type(asdms) == str):
        if (asdms.find('*') >= 0):
            asdms = glob.glob(asdms)
            realasdms = []
            for asdm in asdms:
                tokens = asdm.split('_')
                if (len(tokens) == 6 and tokens[1] == '' and tokens[2] == ''):
                    if (os.path.exists(asdm+'/ASDM.xml')):
                        realasdms.append(asdm)
            asdms = realasdms
            print "Using %d asdms: " % (len(asdms)), asdms
        else:
            asdms = asdms.split(',')
    day0 = getObservationStartDateFromASDM(asdms[0])[0].split()[0]
    day = [0]
    for asdm in asdms[1:]:
        day1 = getObservationStartDateFromASDM(asdm)[0].split()[0]
        day.append(computeIntervalBetweenTwoDays(day1,day0))
    day = np.array(day)
    maxDay = int(np.max(day))
    day = day - np.max(day)
    pb.clf()
    pb.subplots_adjust(wspace=0.30)
    for i,quantity in enumerate(quantities):
        desc = pb.subplot(rows, columns, i+1)
        if (i == 0):
            pb.title('Median values from %s'%station)
        if (i == 1):
            pb.title('Day 0 = %s' % (addDays(day0,maxDay)))
        medians = []
        mads = []
        for a,asdm in enumerate(asdms):
            data = getMedianWeatherFromAIVForASDM(asdm, quantity, station,
                                                  perscan=False)
            medians.append(data['median'])
            mads.append(data['MAD'])
            pb.errorbar([day[a]], medians[-1:], yerr=mads[-1:],
                        fmt=overlayMarkers[a], color=overlayColors[a],
                        markeredgecolor=overlayColors[a])
        pb.ylabel(quantity)
        desc.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))
    for a,asdm in enumerate(asdms):
        pb.text(1.2+(a/20)*0.4, 1.0-(a%20)/15., asdm.replace('uid___A002_',''),
                transform=desc.transAxes,size=7,va='center')
        pb.plot([1.15+(a/20)*0.4], [1.0-(a%20)/15.], overlayMarkers[a],
                color=overlayColors[a], clip_on=False,
                transform=desc.transAxes, mec=overlayColors[a])
    pb.xlabel('Days')
    pb.draw()
    if (plotfile != ''):
        if plotfile == True:
            plotfile = 'weatherForASDMs.png'
        pb.savefig(plotfile)
        print "Wrote ", plotfile

def plotMedianWeatherFromAIVForASDM(asdm, quantity='PRESSURE',station='MeteoTB2',
                                    overwrite=False, timestamp=''):
    """
    Calls getMedianWeatherFromAIVForASDM and plots it vs. scan number of
    the asdm.
    -Todd Hunter
    """
    asdm = asdm.rstrip('/')
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    results = getMedianWeatherFromAIVForASDM(asdm, quantity, station, overwrite,
                                      timestamp=timestamp)
    if (timestamp == ''):
        mydict = results
    else:
        mydict, nearestValue = results
        print "Nearest value to %s is %f" % (timestamp,nearestValue)
    scans = mydict.keys()
    pb.clf()
    desc = pb.subplot(211)
    for scan in scans:
        pb.errorbar([scan], mydict[scan]['median'], yerr=mydict[scan]['stddev'], fmt='.',
                    color='k', lw=2)
        pb.plot([scan], [mydict[scan]['max']], 'r+')
        pb.plot([scan], [mydict[scan]['min']], 'g+')
    yaxisUnits = {'P':'mb', 'T':'C', 'H':'%', 'S':'m/s', 'D':'deg' }
    units = yaxisUnits[quantity[0]]
    pb.ylabel(quantity+' on '+station+' (%s)'%units)
    startdatetime = getObservationStartDateFromASDM(asdm)[0]
    pb.title(asdm + ' (%s)'%startdatetime)
    pb.text(0.72,0.92,'black = median & rms',transform=desc.transAxes,size=10)
    pb.text(0.72,0.84,'red = max',transform=desc.transAxes,size=10,color='r')
    pb.text(0.72,0.76,'green = min',transform=desc.transAxes,size=10,color='g')
    desc.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))
    desc = pb.subplot(212)
    for scan in scans:
        pb.plot([scan], [mydict[scan]['stddev']], 'ko')
        pb.plot([scan], [mydict[scan]['MAD']], 'ro')
        pb.plot([scan], [mydict[scan]['max']-mydict[scan]['median']], 'r+')
        pb.plot([scan], [mydict[scan]['median']-mydict[scan]['min']], 'g+')
    pb.xlabel('Scan')
    pb.ylabel('MAD (red) & rms (black) (%s)' % units)
    pb.draw()
    filename = asdm + '.%s.%s.statistics.png'%(station,quantity)
    pb.savefig(filename)
    print "Wrote ", filename

def getMedianWeatherFromAIV(startDate, endDate, quantity='PRESSURE',
                            station='MeteoTB2', overwrite=True, verbose=False,
                            apex=False):
    """
    Gets the weather statistics over a time interval from the
    weather.aiv.alma.cl database for a single station and quantity.
    Returns a dictionary keyed by scan number of specified asdm, with subkeys
    of 'median', 'MAD', 'mean', 'stddev', 'max' and 'min'.
    startDate and stopDate:  format = 'YYYY-MM-DD HH:MM:SS.SSS' (time is optional)
    overwrite: if True, then regenerate files even if they already exist
    apex: include weather from APEX as well
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    startMjdsec = dateStringToMJDSec(startDate)
    endMjdsec = dateStringToMJDSec(endDate)
    startDate = mjdsecToDate(startMjdsec)
    endDate = mjdsecToDate(endMjdsec)
    if (startDate != endDate):
        print "multiple dates not yet supported."
        return
    stations = [station]
    results = getWeatherFromAIV(startdate, stations, overwrite=overwrite,
                                verbose=verbose, apex=apex)
    data = {}
    weatherMjdsec = np.array(results[station]['mjdsec'])
    weatherQuantity = np.array(results[station][quantity])
    if (quantity == 'PRESSURE'):
        weatherQuantity *= 0.01
    idx1 = np.where(weatherMjdsec >= startMjdsec)[0]
    idx2 = np.where(weatherMjdsec < endMjdsec)[0]
    idx = np.intersect1d(idx1,idx2)
    data = {'median': np.median(weatherQuantity[idx]),
            'MAD': MAD(weatherQuantity[idx]),
            'mean': np.median(weatherQuantity[idx]),
            'stddev': np.std(weatherQuantity[idx]),
            'min': np.min(weatherQuantity[idx]),
            'max': np.max(weatherQuantity[idx]),
            'npts': len(idx)}
    return(data)
    
def getMedianWeatherFromAIVForASDM(asdm, quantity='PRESSURE',station='MeteoTB2',
                                   overwrite=False, verbose=False, apex=False,
                                   timestamp='', perscan=True):
    """
    Gets the median weather per scan of an ASDM from the weather.aiv.alma.cl
    database. Returns a dictionary keyed by scan number of the specified asdm,
    with subkeys of 'median', 'MAD', 'mean', 'stddev', 'max' and 'min'.
    overwrite: if True, then regenerate files even if they already exist
    apex: include weather from APEX as well
    timestamp: if specified, report the single closest value to this time
               format = 'YYYY-MM-DDTHH:MM:SS.SSS'
    -Todd Hunter
    """
    if (not os.path.exists(asdm)):
        print "Could not find ASDM."
        return
    if (type(asdm) == str):
        asdms = asdm.split(',')
    else:  # it is already a list
        asdms = asdm
    for asdm in asdms:
        mydict = readscans(asdm)[0]
        startdate = getObservationStartDateFromASDM(asdm)[0].split()[0]
        enddate = getObservationEndDateFromASDM(asdm)[0].split()[0]
        stations = [station]
        results = getWeatherFromAIV(startdate, stations, overwrite=overwrite,
                                    verbose=verbose, apex=apex)
        data = results
        scans = mydict.keys()
        filename = asdm+'.%s.%s.statistics.txt' % (station,quantity)
        f = open(filename, 'w')
        f.write('# Scan #pts Median MAD mean stddev\n')
        data = {}
        weatherMjdsec = np.array(results[station]['mjdsec'])
        weatherQuantity = np.array(results[station][quantity])
        if (quantity == 'PRESSURE'):
            weatherQuantity *= 0.01
        if (quantity == 'HUMIDITY'):
            weatherQuantity *= 100
        if (quantity == 'WINDDIRECTION'):
            weatherQuantity = np.degrees(weatherQuantity)
        if (timestamp != ''):
            mjdsec = dateStringToMJDSec(timestamp)
            nearestValue = weatherQuantity[np.argmin(np.abs(mjdsec-weatherMjdsec))]
        allValues = []
        for scan in scans:
            scanStartMjdsec = mydict[scan]['startmjd'] * 86400
            scanEndMjdsec = mydict[scan]['endmjd'] * 86400
            idx1 = np.where(weatherMjdsec >= scanStartMjdsec)[0]
            idx2 = np.where(weatherMjdsec < scanEndMjdsec)[0]
            idx = np.intersect1d(idx1,idx2)
            if (len(idx) > 0):
                allValues += list(weatherQuantity[idx])
                data[scan] = {'median': np.median(weatherQuantity[idx]),
                          'MAD': MAD(weatherQuantity[idx]),
                          'mean': np.median(weatherQuantity[idx]),
                          'stddev': np.std(weatherQuantity[idx]),
                          'min': np.min(weatherQuantity[idx]),
                          'max': np.max(weatherQuantity[idx]),
                          'npts': len(idx)}
                f.write('%3d %d %f %f %f %f %f %f\n' % (scan, len(idx), data[scan]['median'],
                                                    data[scan]['MAD'], data[scan]['mean'],
                                                    data[scan]['stddev'],data[scan]['min'],
                                                    data[scan]['max']))
        f.close()
        print "Wrote ", filename
        if (not perscan):
            data = {'median': np.median(allValues),
                    'MAD': MAD(allValues),
                    'mean': np.median(allValues),
                    'stddev': np.std(allValues),
                    'min': np.min(allValues),
                    'max': np.max(allValues),
                    'npts': len(idx)}
        if (timestamp != ''):
            return(data,nearestValue)
        else:
            return(data)

def plotOxygenSounder(startdate='', enddate='', plotfile='', rows=4, columns=1,
                      asdm='', vis='', xlim=''):
    """
    Retrieves (from weather.aiv.alma.cl) and plots the Tamb, RelHum, Tir (cloud sensor), 
    and rain detector data from the ALMA oxygen sounder.
    startdate: date at which to begin (at UT midnight)
    enddate: date through which to plot
    rows: number of rows of plotting sub-panels
    columns: number of columns of plotting sub-panels
    asdm: get the date range from this ASDM
    vis: get the date range from this measurement set

    -Todd Hunter
    """
    if (startdate == ''):
        if (asdm == '' and vis==''):
            startdate = getCurrentDate(delimiter='-')
        elif (asdm != ''):
            asdm = asdm.rstrip('/')
            startdate = getObservationStartDateFromASDM(asdm)[0].split()[0]
            enddate = getObservationEndDateFromASDM(asdm)[0].split()[0]
            xlim = getObservationMJDSecRangeFromASDM(asdm)
        elif (vis != ''):
            vis = vis.rstrip('/')
            startdate = getObservationStartDate(vis).split()[0]
            enddate = getObservationStopDate(vis).split()[0]
            xlim = getObservationMJDSecRange(vis)
        else:
            print "You must specify one of: startdate, asdm, vis"
            return
    if (startdate.find('uid') >= 0):
        print "Use the vis or asdm parameter."
        return
    if (enddate == ''):
        enddate = startdate
    data = getSounderData(startdate, enddate)
    if (data == {}):
        print "Cannot make plot because sounder was not operational on this day."
        return
    list_of_date_times = mjdSecondsListToDateTime(data['mjdsec'])
    print "Retrieved %d samples" % (len(list_of_date_times))
    if (len(list_of_date_times) < 1):
        print "Cannot make plot because sounder was not operational on this day."
        return
    pb.clf()
    timeplot = pb.date2num(list_of_date_times)
    desc = pb.subplot(rows,columns,1)
    if (columns == 2 and rows == 2):
        pb.subplots_adjust(wspace=0.3)
    # ignore bogus values at restarts
    idx = np.where(data['Tamb'] > -100)
    pb.plot_date(timeplot[idx], data['Tamb'][idx], 'k-')
    mytext = 'white regions: nighttime, yellow: daytime (defined by sunrise/sunset)'
    if (asdm != ''):
        pb.title(mytext,size=12)
        pb.text(0.5,1.25,os.path.basename(asdm),transform=desc.transAxes,ha='center',size=12)
    elif (vis != ''):
        pb.title(mytext,size=12)
        pb.text(0.5,1.25,os.path.basename(vis),transform=desc.transAxes,ha='center',size=12)
    else:
        pb.title (mytext,size=12)
    if (rows <= 2):
        pb.ylabel('Ambient temperature (C)')
    else:
        pb.ylabel('T_amb (C)')
    if (asdm != '' or vis != ''):
        xaxisUnits = 'minutes'
        xlabel = 'UT on ' + startdate
    elif (startdate==enddate):
        xaxisUnits = 'hours'
        xlabel = 'UT on ' + startdate
        xlabel += ' to ' + enddate
    else:
        xaxisUnits = 'days'
        xlabel = 'UT'
    daytimeRanges = findDaytime(startdate, enddate)
    shadeRanges(desc, daytimeRanges)
    if (xlim != ''):
        print "Setting xlim from mjdSecondsList = ", xlim
        pb.xlim(pb.date2num(mjdSecondsListToDateTime(xlim)))
    setXaxisDateFormatter(desc, xaxisUnits)
        
    desc = pb.subplot(rows,columns,2)
    pb.plot_date(timeplot[idx], data['Rh'][idx], 'k-')
    if (rows <= 2):
        pb.ylabel('Relative humidity (%)')
    else:
        pb.ylabel('R. humid. (%)')
    setXaxisDateFormatter(desc, xaxisUnits)
    shadeRanges(desc, daytimeRanges)
    if (xlim != ''):
        pb.xlim(pb.date2num(mjdSecondsListToDateTime(xlim)))

    desc = pb.subplot(rows,columns,3)
    pb.plot_date(timeplot[idx], data['Tir'][idx], 'k-')
    if (rows <= 2):
        pb.ylabel('IR cloud sensor (K)')
    else:
        pb.ylabel('IR cloud (K)')
    setXaxisDateFormatter(desc, xaxisUnits)
    shadeRanges(desc, daytimeRanges)
    if (xlim != ''):
        pb.xlim(pb.date2num(mjdSecondsListToDateTime(xlim)))

    desc = pb.subplot(rows,columns,4)
    pb.plot_date(timeplot[idx], data['Rain'][idx], 'k-')
    pb.ylabel('Rain sensor (V)')
    pb.xlabel(xlabel)
    setXaxisDateFormatter(desc, xaxisUnits)
#    RescaleXAxisTimeTicks(pb.xlim(), desc)
    shadeRanges(desc, daytimeRanges)
    if (xlim != ''):
        pb.xlim(pb.date2num(mjdSecondsListToDateTime(xlim)))
    if (plotfile != ''):
        if plotfile == True:
            if (startdate == enddate):
                if (asdm != ''):
                    png = asdm + '.oxygenSounder.png'
                elif (vis != ''):
                    png = vis+ '.oxygenSounder.png'
                else:
                    png = 'oxygenSounder_%s.png' % (startdate)
            else:
                png = 'oxygenSounder_%s_%s.png' % (startdate, enddate)
        else:
            png = plotfile
        pb.savefig(png)
        print "Wrote plot = ", png
    
def getSounderData(startdate, enddate='', overwrite=False):
    """
    Gets oxygen sounder level 0 data products from weather.aiv.alma.cl for a sequence of days.
    Returns a dictionary with keys = 
            ['mjdsec', 'Tamb', 'Tir', 'Rcvr1', 'TkBB', 'Rain', 'Rcvr0', 'Rh']
    -Todd Hunter
    """
    if (enddate == ''):
        enddate = startdate
    data = {}
    for i in range(1+abs(computeIntervalBetweenTwoDays(startdate,enddate))):
        myDay = addDays(startdate,i)
        dataOneday = getSounderDataFromAIV(myDay,overwrite)
        if (dataOneday is None): continue
        if (data == {}):
            data = dict(dataOneday)
        else:
            for key in dataOneday.keys():
                data[key] += dataOneday[key]
    for key in data.keys():
        data[key] = np.array(data[key])
    return data

def getSounderDataFromAIV(startdate, overwrite=False):
    """
    Gets oxygen sounder level 0 data products for one day from weather.aiv.alma.cl.
    Writes to a file called oxygenSounder.YYYY-MM-DD.dat and returns a dictionary
    with keys:  ['mjdsec', 'Tamb', 'Tir', 'Rcvr1', 'TkBB', 'Rain', 'Rcvr0', 'Rh']
    startdate: YYYY-MM-DD
    -Todd Hunter
    """
    data = {'mjdsec':[], 'Rcvr0':[], 'Rcvr1':[], 'TkBB':[],
            'Tamb':[], 'Rh':[], 'Tir':[], 'Rain':[] }
    if (startdate == ''): startdate = getCurrentDate(delimiter='-')
    weatherValue = {'Rcvr0':1, 'Rcvr1':2, 'TkBB':3, 'Tamb': 4,
                    'Rh':5, 'Tir':6, 'Rain':7, 'ALL':99}
    filename = 'oxygenSounder.%s.dat' % (startdate)
    if (not os.path.exists(filename) or startdate==getCurrentDate(delimiter='-') or overwrite):
        url = 'http://weather.aiv.alma.cl/all/oxygen_data.php?'
        form_data = [('start',startdate), 
                     ('idsensor',99),
                     ('idweatherstation',1),
                     ('format', 'txt')]
        params = urllib.urlencode(form_data)
        response = urllib2.urlopen(url+params)
        lines = response.readlines()
        fi = open(filename, 'w')
        for line in lines:
            if (line.find('#') >= 0):
                continue
            a,b,c,d,e,f,g,h = line.split(';')
            data['mjdsec'].append(dateStringToMJDSec(a,verbose=False,use_metool=False))
            data['Rcvr0'].append(float(b))
            data['Rcvr1'].append(float(c))
            data['TkBB'].append(kelvinToCelsius(float(d)))
            data['Tamb'].append(kelvinToCelsius(float(e)))
            data['Rh'].append(float(f))
            data['Tir'].append(float(g))
            data['Rain'].append(float(h))
            fi.write('%f %f %f %f %f %f %f %f\n' % (data['mjdsec'][-1], float(b), float(c),
               kelvinToCelsius(float(d)), kelvinToCelsius(float(e)), float(f), float(g), float(h)))
        if (len(data['mjdsec']) < 1):
            print "No data received for %s." % (startdate)
    else:
        fi = open(filename, 'r')
        lines = fi.readlines()
        for line in lines:
            a,b,c,d,e,f,g,h = line.split()
            data['mjdsec'].append(float(a))
            data['Rcvr0'].append(float(b))
            data['Rcvr1'].append(float(c))
            data['TkBB'].append(float(d))
            data['Tamb'].append(float(e))
            data['Rh'].append(float(f))
            data['Tir'].append(float(g))
            data['Rain'].append(float(h))
        if (len(lines) < 1):
            print "Existing file is blank (%s)." % (filename)
            return
        print "Reading existing file = %s, median Tir=%.1fK" % (filename,np.median(data['Tir']))
    fi.close()
    return(data)
    
def getWeatherFromAIV(startdate='', stations='', overwrite=False, verbose=True,
                      apex=True, aste=False):
    """
    Queries weather.aiv.alma.cl for one day's worth of weather.
    Writes data to file (one file per weather station).
    Returns a dictionary keyed by weather station name.
    startdate: 'YYYY-MM-DD'
    stations: a list of stations (as a python list of strings), blank=>all
    overwrite: if True, then regenerate files even if they already exist
    apex: include weather from APEX as well
    aste: include weather from ASTE files
    -Todd Hunter
    """
    data = {}
    if (startdate == ''): startdate = getCurrentDate(delimiter='-')
    if (stations == ''):
        stations =  ['Meteo129','Meteo130','Meteo131','Meteo201','Meteo309',
                     'Meteo410','MeteoCentral','MeteoTB2']
    weatherValue = {'HUMIDITY':1, 'PRESSURE':8, 'TEMPERATURE':2, 'WINDDIRECTION': 5,
                    'WINDSPEED':6, 'ALL':99}
    weatherStation = {'MeteoTB1':1, 'MeteoTB2':2, 'MeteoItinerant':4, 'Meteo201':5,
                      'MeteoCentral': 6, 'Meteo309': 7, 'Meteo410': 8, 'Meteo131':9,
                      'Meteo129':10, 'Meteo130':11, 'MeteoOSF':3}
    for station in stations:
        filename = station+'.%s.dat' % (startdate)
        data[station] = {'mjdsec':[], 'HUMIDITY':[], 'PRESSURE':[], 'TEMPERATURE':[],
                         'WINDDIRECTION': [], 'WINDSPEED': []}
        if (not os.path.exists(filename) or startdate==getCurrentDate(delimiter='-') or overwrite):
            print "%s %s" % (startdate,station)
            url = 'http://weather.aiv.alma.cl/all/advanced_data.php?'
            form_data = [('start','+'+startdate), ('format', 'txt'), 
                         ('idsensor',weatherValue['ALL']),
                         ('idweatherstation',weatherStation[station])]
            params = urllib.urlencode(form_data)
            response = urllib2.urlopen(url+params)
            lines = response.readlines()
            fi = open(filename, 'w')
            for line in lines:
                if (line.find('#') >= 0):
                    continue
                a,b,c,d,e,f,g = line.split(';')
                data[station]['mjdsec'].append(dateStringToMJDSec(a,verbose=False,use_metool=False))
                data[station]['HUMIDITY'].append(float(b)*0.01) # convert from % to fraction
                data[station]['TEMPERATURE'].append(float(c))
                data[station]['WINDDIRECTION'].append(np.radians(float(e)))
                data[station]['WINDSPEED'].append(float(f))
                data[station]['PRESSURE'].append(float(g)*100) # convert to hPa
                fi.write('%f %f %f %f %f %f\n' % (data[station]['mjdsec'][-1], float(b)*0.01,
                                          float(c), np.radians(float(e)), float(f), 100*float(g)))
            fi.close()
        else:
            mylist = readAIVWeatherDataFile(filename)
            data[station]['mjdsec'] = mylist[0]
            data[station]['HUMIDITY'] = mylist[1]
            data[station]['TEMPERATURE'] = mylist[2]
            data[station]['WINDDIRECTION'] = mylist[3]
            data[station]['WINDSPEED'] = mylist[4]
            data[station]['PRESSURE'] = mylist[5]
            print "Read existing file = %s, median pressure=%.3fmb" % (filename,np.median(data[station]['PRESSURE'])*0.01)
    if (apex):
        enddate = addDays(startdate,1)
        data['MeteoAPEX'] = getApexWeather(startdate, enddate)
    if (aste):
        data['MeteoASTE'] = getAsteWeather(startdate=startdate)
    return data

def getWeatherFromTMCDB(startdate, enddate, quantity='PRESSURE', stations='',
                        overwrite=False, verbose=True, apex=True):
    """
    Gets weather data for all stations, currently:
      ['Meteo129','Meteo130','Meteo131','Meteo201','Meteo309',
       'Meteo410','MeteoCentral','MeteoTB2']
    stations: an optional list of stations to use instead of the default
    Returns a dictionary keyed by station name.
    -Todd Hunter
    """
    data = {}
    if (stations == ''):
        stations =  ['Meteo129','Meteo130','Meteo131','Meteo201','Meteo309',
                     'Meteo410','MeteoCentral','MeteoTB2']
    for station in stations:
        filename = '%s_%s_WeatherStationController_%s_%s.txt'%(startdate,enddate,station,quantity)
        if (overwrite or not os.path.exists(filename)):
            data[station] = tmu.retrieve_tmc_data_files('WeatherStationController',
                                                        station,quantity,startdate,
                                                        enddate, verbose)
            if (quantity == 'PRESSURE'):
                # also get the TEMPERATURE in order to correct for height
                tempfiles = tmu.retrieve_tmc_data_files('WeatherStationController',
                                                        station,'TEMPERATURE',startdate,
                                                        enddate, verbose)
                if (len(tempfiles) > 0):
                    concatenateFiles(tempfiles)
            if (len(data[station]) > 0):
                data[station] = concatenateFiles(data[station])
        else:
            print "Reading existing file: %s" % (filename)
            data[station] = filename
    if (apex):
        if (startdate == enddate):
            enddate = addDays(startdate,1)
        data['MeteoAPEX'] = getApexWeather(startdate, enddate)
    return data

def uniqueValuesInASCIIFileColumn(filelist, column=0, column2=None, 
                                  scaleFactor=1.0,
                                  ignoreZeroZero=True):
    """
    Examines one or a list of text files, and 1 (or 2) columns and
    reports the unique values (or combination of values) as a 
    dictionary keyed by filename.  For examining pointing offsets
    files, set column=7, column2=8, scaleFactor=206264.8.
    column: first column = 0
    column2: default=None
    ignoreZeroZero: if True, then in the column2 !=None case, ignore 
                    points where both columns are zero.
    -Todd Hunter
    """
    if (type(filelist) == str):
        filelist = glob.glob(filelist)
    mydict = {}
    for filename in filelist:
        f = open(filename,'r')
        lines = f.readlines()
        values = []
        for line in lines:
            if (line[0] == '#'): continue
            tokens = line.split()
            if (column2 is not None):
                if (len(tokens) < np.max([column,column2])+1): continue
                values.append((float(tokens[column]) * scaleFactor, 
                               float(tokens[column2]) * scaleFactor))
            else:
                if (len(tokens) < column+1): continue
                values.append(float(tokens[column])*scaleFactor)
        v = np.unique(values)
        if (column2 is not None):
            v = [list(i) for i in v]
        if (filename.find('subscan')>=0):
            subscan = filename[filename.find('subscan')+7:].split('_')[0]
        else:
            subscan = filename
        if (np.shape(v) == (1,2)):
            if (v[0] != [0.0,0.0] or ignoreZeroZero==False):
                mydict[subscan] = v
        else:
            mydict[subscan] = v
    return mydict

def concatenateFiles(filelist, remove=True):
    """
    Takes a list of text files, concatenates them, names the result as
    the firstFile_lastFile, and (if remove==True), removes the original files.
    -Todd Hunter
    """
    catlist = ' '.join(filelist)
    outfile = filelist[0].lstrip('./').split('_')[0] +'_'+ filelist[-1].lstrip('./')
    os.system('cat %s > %s' % (catlist,outfile))
    if (remove):
        if (catlist != '*'):
            os.system('rm -f %s' % catlist)
    return(outfile)

def checkLogsForDelayJumps(vis=None, startTime=None, stopTime=None,
                          cleanup=False, verbose=False, asdm=None):
    """
    Calls checkALMALogs with the search string: 'Delay command for'
    See ICT-6006.
    -Todd Hunter
    """
    checkALMALogs(vis, startTime, stopTime, cleanup, verbose, asdm,
                  text='Delay command for')


def checkLogsForSubarrays(vis=None, startTime=None, stopTime=None,
                          cleanup=False, verbose=False, asdm=None):
    """
    Calls checkALMALogs with the search string: ' has been created at:'
    -Todd Hunter
    """
    checkALMALogs(vis, startTime, stopTime, cleanup, verbose, asdm,
                  text=' has been created at:')

def checkLogsForValidationFailures(vis=None, startTime=None, stopTime=None,
                          cleanup=False, verbose=False, asdm=None):
    """
    Calls checkALMALogs with the search string: 'failed to validate'
    -Todd Hunter
    """
    checkALMALogs(vis, startTime, stopTime, cleanup, verbose, asdm,
                  text='failed to validate')

def checkLogsForDelayUpdates(vis=None, startTime=None, stopTime=None, cleanup=False, 
                             verbose=False, asdm=None, outfile='', sort=True,
                             removeAdjacentDuplicates=True, arrayName='', overwrite=False):
    """
    Given a measurement set (or ASDM or time range), downloads the ALMA logs
    recorded during the execution period and checks for delay direction updates
    during that time.
    vis: measurement set (or ASDM name)
    asdm: ASDM name
    startTime: alternative to specifying measurement set, e.g. 2015-07-12T21:07:54
    stopTime:  alternative to specifying measurement set, e.g. 2015-07-12T22:07:54
    cleanup: if True, the remove the directory of log files it creates
    outfile: text file to generate
    sorted: if True, then sort the messages (which will then be in UT order)
    arrayName: if included, then also require this string to be present (e.g. 'Array009')
    -Todd Hunter
    """
    lines = checkALMALogs(vis, startTime, stopTime, cleanup, verbose, asdm,
#                          text='RA/Dec at ', printStartingAfter='CDATA[', insertLineBreaks=True, 
                          text=' source RA/Dec ', printStartingAfter='CDATA[Equatorial source', insertLineBreaks=True, 
                          arrayName=arrayName, overwrite=overwrite)
    if lines==None: return
    if verbose: print "Got %d lines" % len(lines)
    if outfile != '':
        f = open(outfile,'w')
        if sort:
            lines = sorted(lines)
        previousLine = ''
        for line in lines:
            line = line.strip()
            if (len(line.replace(' ','')) > 0):
                if (line != previousLine or not removeAdjacentDuplicates):
                    f.write(line+'\n')
                previousLine = line
        f.close()
        print "Wrote ", outfile

def checkALMALogs(vis=None, startTime=None, stopTime=None, cleanup=False, 
                  verbose=False, asdm=None, text=' has been created at:', 
                  printStartingAfter='', insertLineBreaks=True, arrayName='',
                  overwrite=False):
    """
    Given a measurement set (or ASDM or time range), downloads the ALMA logs
    recorded during the execution period and checks for array creation events
    during that time.
    vis: measurement set (or ASDM name)
    asdm: ASDM name
    startTime: alternative to specifying measurement set, e.g. 2015-07-12T21:07:54
    stopTime:  alternative to specifying measurement set, e.g. 2015-07-12T22:07:54
    cleanup: if True, the remove the directory of log files it creates
    text: the text for which to search
    printStartingAfter: the character string after which to start printing matches
    insertLineBreaks: when printStartingAfter is specified, add line breaks before
                      each match of 'text' is found
    arrayName: if included, then also require this string to be present on the line
            if 'Array' is present (e.g. 'Array009')
               
    -Todd Hunter
    """
    if (vis is not None):
        startMJDSec = getObservationStart(vis)
        if (startMJDSec is None):
            if (os.path.exists(vis)):
                print "Checking if it is an ASDM..."
                result = getObservationStartDateFromASDM(vis)
                if (result is None): return
                startDatestamp, startMJDSec = result
                stopDatestamp, stopMJDSec = getObservationEndDateFromASDM(vis)
            else:
                return
        else:
            stopMJDSec = getObservationStop(vis)
            startDatestamp = getObservationStartDate(vis)
            stopDatestamp = getObservationStopDate(vis)
        print "start-stop = ", startDatestamp, stopDatestamp
    elif (asdm is not None):
        result = getObservationStartDateFromASDM(asdm)
        if (result is None): return
        startDatestamp, startMJDSec = result
        stopDatestamp, stopMJDSec = getObservationEndDateFromASDM(asdm)
    elif (startTime is None or stopTime is None):
        print "You must specify either a measurement set or a start and stop time"
        return
    else:
        startDatestamp = startTime
        stopDatestamp = stopTime
        startMJDSec = dateStringToMJDSec(startTime, verbose=False)
        stopMJDSec = dateStringToMJDSec(stopTime, verbose=False)
    files = compUtils.retrieve_aos_system_logs(startDatestamp, stopDatestamp, overwrite)
    print "Grepping %d files (any matches will be printed)...." % (len(files))
    if (verbose):
        print str(files)
    returnValue = []
    filtered = 0
    for f in files:
        if (verbose):
            print "Grepping for %s in file: " % (text), f
        stdout, stderr = grep(f, text)
        if verbose:
            print "  length of result: %d, len(arrayName)=%d" % (len(stdout),len(arrayName))
        if (len(stdout) > 0):
            creationDate = stdout.split('TimeStamp="')[1].split('" File=')[0]
            creationMJDSec = dateStringToMJDSec(creationDate, verbose=False)
            if (creationMJDSec >= startMJDSec and creationMJDSec <= stopMJDSec):
                if printStartingAfter == '':
                    print stdout+'\n'
                    returnValue.append(stdout)
                else:
                    lines = stdout.split('<Info')
                    for stdout in lines:
                        if (stdout.find("TimeStamp") >= 0):
                            timestamp = stdout.split("TimeStamp=")[1].split(' ')[0].strip('"')
                        else:
                            timestamp = ''
                        startchar = stdout.find(printStartingAfter)
                        if (len(arrayName) > 0):
                            if (stdout.find(arrayName) < 0 and stdout.find('Array') >= 0): 
                                filtered += 1
                                continue
                        if (startchar >= 0):
                            mjdsec = dateStringToMJDSec(timestamp,verbose=False)
                            if (mjdsec<stopMJDSec and mjdsec>=startMJDSec):
                                myline = timestamp + ' ' + stdout[startchar+len(printStartingAfter):].split('\n')[0].replace(']]></Info>','')
                                if insertLineBreaks:
                                    myline = myline.replace(text,'\n'+text)
                                print myline
                                myline = myline.split('\n')
                                returnValue += myline
                            elif verbose:
                                print "message lies outside of range %.1f-%.1f" % (startMJDSec,stopMJDSec)
    if (filtered > 0):
        print "Skipped %d lines that were not for this array" % filtered
    if (cleanup):
        tree = os.path.dirname(f)
        print "Removing files in %s" % (tree)
        shutil.rmtree(tree)
    return returnValue

def mostRecentPipelineParentDirectory(user='', withProducts=False):
    """
    Finds the parent directory of the most recent pipeline run of a NA user.
    withProducts: if True, then only find parents that contain a products dir
    -Todd Hunter
    """
    if (user == ''):
        user = os.getenv('USER')
    mydir = '/lustre/naasc/sciops/comm/%s/pipeline/root/20*' % user
    print "Searching ", mydir
    mydir = sorted(glob.glob(mydir), key=os.path.getmtime, reverse=True)
    if (len(mydir) > 0):
        if withProducts:
            for d in mydir:
                searchdir = d+'/*/*/*/products'
                print "Checking for ", searchdir
                if len(glob.glob(searchdir)) > 0:
                    return d
    print "No qualifying pipeline run directories found."
    return
    
def mostRecentPipelineWorkingDirectory(user='', withProducts=False):
    """
    Finds the working directory of the most recent pipeline run of a NA user.
    -Todd Hunter
    """
    mydir = mostRecentPipelineParentDirectory(user, withProducts)
    sous = glob.glob(mydir+'/SOUS*')
    if (len(sous) < 1):
        print "No SOUS found"
        return
    newdir = sous[0]+'/GOUS*'
    gous = glob.glob(newdir)
    if (len(gous) < 1):
        print "No GOUS found"
        return
    newdir = gous[0]+'/MOUS*'
    mous = glob.glob(newdir)
    if (len(mous) < 1):
        print "No MOUS found"
        return
    return (mous[0] + '/working')
    
def grep(filename, arg, outfile=None):
    """
    Runs grep in a subprocess.  Returns 2 items: 
    * the contents of stdout (i.e. the result of the grep)
    * the contents of stderr
    -Todd Hunter
    """
    process = subprocess.Popen(['grep', '-n', arg, filename], stdout=subprocess.PIPE)
    stdout, stderr = process.communicate()
    if outfile is not None:
        f = open(outfile,'w')
        f.write(stdout)
        f.close()
        print "Sent output to ", outfile
    return stdout, stderr

def addToStateTable(vis, rows=1):
    """
    Appends a row to the STATE table of a measurement set.
    Useful for testing SMA data in CASA 4.4.
    -Todd Hunter
    """
    if (not os.path.exists(vis)):
        print "Measurement set not found."
        return
    mytb = createCasaTool(tbtool)
    mytb.open(vis+'/STATE', nomodify=False)
    mytb.addrows(rows)
    row = mytb.nrows()-1
    mytb.putcell('CAL', row, 0)
    mytb.putcell('FLAG_ROW', row, False)
    mytb.putcell('LOAD', row, 0)
#    mytb.putcell('OBS_MODE', row, np.array([''], dtype='|S1'))
    mytb.putcell('REF', row, False)
    mytb.putcell('SIG', row, True)
#    mytb.putcell('SUB_SCAN', row, np.array([1], dtype=np.int32))
    print "There are now %d rows in the STATE table." % (mytb.nrows())
    mytb.close()

def compareAntPosResults(antposlist='', errmax=2., antennasToPlot=[],
                         doWvrCorrection=False, dropAntennas=[], 
                         drawFits=False):
    """
    Uses Robert Lucas' modules to compare multiple results from tc_antpos
    and generate plots of XYZ vs. time and PWV like those Robert produces.
    This function is useful for examining the data and potential
    corrections due to the partial pressure of water vapor and differential
    barometric correction.  See the function averageAntPosResults for 
    producing xml files suitable for updating positions in the TMCDB.
    -Todd Hunter
    Inputs:
    errmax: maximum error (in mm) for a dataset to be plotted on 'vs. Date' plot
    antennasToPlot: an empty list means all antennas
    dropAntennas: antennas to drop when fitting for rms vs. distance
    drawFits: if True, then run it twice, drawing rms vs. distance fits
                     on the second time
    """
    if (not CAPRAvailable):
        if (casadef.python_library_directory.find('telcalsa') < 0):
            print "The TelCal libraries are not available to plain casa on this machine."
            print "Instead, you will need to run this command in casapy-telcal."
        else:
            print "For some reason, the TelCal libraries are not importable in au in casapy-telcal on this machine."
        return
    if (antposlist == ''):
        antposlist = sorted(glob.glob('*WET_antpos_result'), reverse=True)
        nresults = len(antposlist)
        print "Found %d results to compare" % (nresults)
        if (nresults < 1):
            return
    elif (antposlist.find('*') >= 0):
        antposlist = sorted(glob.glob(antposlist), reverse=True)
        nresults = len(antposlist)
        print "Found %d results to compare" % (nresults)
        if (nresults < 1):
            return
    elif (type(antposlist) == str):
        antposlist = sorted(antposlist.split(','), reverse=True)
    for ant in antposlist:
        loc = ant.find('_delays_')
        asdm = ant[:loc]
        if (not os.path.exists(asdm)):
            print "Could not find ASDM=%s. Exporting it with -m." % (asdm)
            os.system('asdmExport -m '+asdm)
    c = CAPR.CompareAntPosResults()
    wet = 'WET'
    c.addResults(antposlist, wet, errmax)
    if (len(antennasToPlot) > 0):
        if (type(antennasToPlot) == str):
            antennasToPlot = antennasToPlot.split(',')
        pngs = []
        for a in antennasToPlot:
            mean, rms, distance, height = c.plotAntenna(a, errmax, doWvrCorrection=doWvrCorrection)
            station = c.station[a]
            pb.figtext(0.1, 0.95, '%s/%s d=%6.0fm h=%3.0fm %s'%\
                       (a, station, distance, height, wet), ha='left', va='top')
            png = 'XYZ_%s_%s_%s.png'%(wet, a, station)
            pb.savefig(png)
            pngs.append(png)
    else:
        pngs, [aa, xx, yy_x, yy_y, yy_z] = c.plotAll(wet, errmax, doWvrCorrection, returnRms=True)
    print "Produced per-antenna png plots in current working directory."
    if (len(dropAntennas) > 0):
        for dropAntenna in dropAntennas:
            if dropAntenna in aa:
                idx = aa.index(dropAntenna)
                aa.pop(idx)
                xx.pop(idx)
                yy_x.pop(idx)
                yy_y.pop(idx)
                yy_z.pop(idx)
    slope_x, intercept_x = linfit().linfit(xx, yy_x, 0.1*np.array(yy_x))
    slope_y, intercept_y = linfit().linfit(xx, yy_y, 0.1*np.array(yy_y))
    slope_z, intercept_z = linfit().linfit(xx, yy_z, 0.1*np.array(yy_z))
    print "Slopes: x=%f, y=%f, z=%f, z/mean(x+y)=%f" % (slope_x, slope_y, slope_z,
                                                        2*slope_z/(slope_x+slope_y))
    print "Intercepts: x=%f, y=%f, z=%f" % (intercept_x, intercept_y, intercept_z)
    if drawFits:
        slopes = [slope_x, slope_y, slope_z]
        intercepts = [intercept_x, intercept_y, intercept_z]
        pngs = c.plotAll(wet, errmax, doWvrCorrection, drawFits=[intercepts,slopes])
    if (len(pngs) > 1):
        buildPdfFromPngs(pngs,'XYZ_%s_all_antennas.pdf'%(wet),quiet=True)

def readAntennasFromCalPosition(xmlfile):
    """
    Reads the antenna names in a CalPosition.xml file, as written by tc_antpos, and returns
    a list of names.
    -Todd Hunter
    """
    if (not os.path.exists(xmlfile)):
        print "Could not find file"
        return
    if (os.path.isdir(xmlfile)):
        xmlfile += '/CalPosition.xml'
    f = open(xmlfile,'r')
    antennas = []
    for line in f.readlines():
        loc = line.find('<antennaName>')
        if (loc >= 0):
            antennas.append(line[loc+len('<antennaName>'):].split('</antennaName>')[0].strip())
    f.close()
    return(np.unique(antennas))

def averageAntPosResults(antposlist='', antennas='', dropDatasets={},
                         errmax=2.0, minSnr=4.0, writeFile='', verbose=False):
    """
    This function runs Robert's CompareAntPosResults.py for a list of tc_antpos
    results files, takes the resulting weighted mean corrections, and writes
    them into a new synthetic results file that is meant to be used with
    EditPositions.py and UpdatePosition.sh.  Specific datasets can be dropped
    for specific antennas.  If you simply want to plot the comparision, then
    use au.compareAntPosResults
    -Todd Hunter
    Inputs:
    antposlist: list of results files, '' => use all in current directory
         These files are expected to be named in the following format:
              uid___XXXX_XXXXXXXX_XXXX_delays_U_refAnt_WET_antpos_result
    antennas: list of antennas to process, '' => use all in results files
    errmax: mm, passed to CompareAntPosResults.addResults()
    minSnr: passed to CompareAntPosResults.plotAntenna and used to recommend
            which antennas to update
    writeFile: (partial) name of one of the ASDM UIDs to be used when creating
               the new mean result. If not specified, then the first will be used.
    dropDatasets: dictionary keyed by antenna name, where values are the
                  datasets to ignore for that antenna.  If an antenna is not 
                  present in a dataset, then it is automatically ignored.
           Example: {'DA41':['Xc5ef'], 'DA43':['Xc5ef'], 'DA46':['Xc5ef'],
                     'DA47':['Xc5ef'], 'DA48':['Xc5ef'], 'DA49':['Xc5ef'],
                     'DA57':['Xc5ef'], 'DA59':['Xc5ef'], 'DA63':['Xc5ef'],
                     'DV01': ['Xc5ef'], 'DV20': ['Xc5ef'], 'DV21': ['Xc5ef'], 
                     'PM03':['Xa587','Xaf1b','X212a']}
    """
    if (not CAPRAvailable):
        if (casadef.python_library_directory.find('telcalsa') < 0):
            print "The TelCal libraries are not available to plain casa on this machine."
            print "Instead, you will need to run this command in casapy-telcal."
        else:
            print "For some reason, the TelCal libraries are not importable in au in casapy-telcal on this machine."
        return
    if (antposlist == ''):
        # sort so that newest observation is first
        antposlist = sorted(glob.glob('*WET_antpos_result'), reverse=True)
        nresults = len(antposlist)
        print "Found %d results to compare" % (nresults)
        if (nresults < 1):
            return
    elif (antposlist.find('*') >= 0):
        # sort so that newest observation is first
        antposlist = sorted(glob.glob(antposlist), reverse=True)
        nresults = len(antposlist)
        print "Found %d results to compare" % (nresults)
        if (nresults < 1):
            return
    elif (type(antposlist) == str):
        antposlist = sorted(antposlist.split(','), reverse=True)
    from PositionEditor import PositionEditor  # used by averageAntPosResults and compareTMCDB
    threshold = 50e-6 # meters
    if (len(antennas) == 0):
        antennas = []
        for ap in antposlist:
            antennas += readAntennasFromCalPosition(ap+'/CalPosition.xml')
        antennas = np.unique(antennas)
    elif (type(antennas) == str):
        antennas = antennas.split(',')
    # Make sure that ASDM metadata is present in this directory for all datasets
    for ap in antposlist:
        asdm = ap[:ap.find('_delays')]
        if (not os.path.exists(asdm)):
            print "Exporting metadata for this asdm"
            os.system('asdmExport -m '+asdm)
    print "Found a total of %d antennas" % (len(antennas))
    if (len(writeFile) == 0):
        writeFile = antposlist[0]
        asdm0 = writeFile[:writeFile.find('_delays')]
        newresults = writeFile + '.weightedMean'
        print "Will write results into new directory: %s" % (newresults)
    else:
        for ap in antposlist:
            if (ap.find(writeFile) >= 0):
                writeFile = ap
                asdm0 = ap[:ap.find('_delays')]
                break
        newresults = ap + '.weightedMean'
        print "Will write results into selected new directory: %s" % (newresults)
    if (os.path.exists(newresults)):
        print "Removing previous mean result"
        shutil.rmtree(newresults)
    os.mkdir(newresults)
    # Copy the three files that do not need to be changed
    for f in ['ASDM','CalData','CalReduction']:
        shutil.copyfile(writeFile+'/'+f+'.xml', newresults+'/'+f+'.xml')
    # Create a new file to receive the mean results
    f = open(newresults+'/CalPosition.xml', 'w')
    previous = open(antposlist[0]+'/CalPosition.xml','r')
    lines = previous.readlines()
    previous.close()
    # copy the first two header lines to the new file
    f.write(lines[0])
    f.write(lines[1].replace('<row>','')) # this will be written later
    means = {}
    rmss = {}
    pngs = []
    antennasToUpdate1Axis = []
    antennasToUpdate2Axes = []
    antennasToUpdate3Axes = []
    for antnum,antenna in enumerate(antennas):
        print "*******  Processing antenna %s (%d of %d) ***********" % (antenna, antnum+1, len(antennas))
        myAntennaResults = antposlist[:]
        antennaResults = myAntennaResults[:]
        if antenna in dropDatasets.keys():
            if (type(dropDatasets[antenna]) == str):
                dropDatasets[antenna] = dropDatasets[antenna].split(',')
            for dataset in dropDatasets[antenna]:
                for result in antennaResults:
                    if (result.find(dataset) >= 0):
                        print "Dropping dataset %s for %s because it contains %s" % (result, antenna,dataset)
                        myAntennaResults.remove(result)
        antennaResults = myAntennaResults[:]
        for result in antennaResults:
            myAntennas = readAntennasFromCalPosition(result+'/CalPosition.xml')
            if (antenna not in myAntennas):
                print "Dropping %s for %s because it was not in the array" % (result, antenna)
                myAntennaResults.remove(result)
        antennaResults = myAntennaResults[:]

        # Read pad and antenna position from each dataset
        asdmPad = []
        asdmPadPosition = []
        asdmAntennaPosition = []
        for result in antennaResults:
            myasdm = result[:result.find('_delays')]
            print "Processing ", myasdm
            asdmPad.append(getAntennaPadsFromASDM(myasdm)[antenna])
            asdmPadPosition.append(getPadPositionsFromASDM(myasdm)[asdmPad[-1]])
            asdmAntennaPosition.append(readAntennaPositionFromASDM(myasdm)[antenna]['position'])
            
        # Reinstate the class for each antenna, since we may be using a different list of datasets.
        # In principle, this could be made faster by processing all antennas with no dropDatasets at once.
        c = CAPR.CompareAntPosResults()
        wet = 'WET'  # this is to emphasize that we choose the full wet path rather than the delta wet path
        c.addResults(antennaResults, wet, errmax, doWvrCorrection=False)
        station = c.station[antenna]
        if (antenna != c.refAntenna):
            print "Plotting antenna ", antenna
            mean, rms, distance, height, meanAbsolute, recommendUpdate = c.plotAntenna(antenna, errmax, minSnr=minSnr)
            if (recommendUpdate == 1):
                antennasToUpdate1Axis.append(antenna)
            elif (recommendUpdate == 2):
                antennasToUpdate2Axes.append(antenna)
            elif (recommendUpdate == 3):
                antennasToUpdate3Axes.append(antenna)
            means[antenna] = mean  # ENU, in mm
            rmss[antenna] = rms    # ENU, in mm
            
            pb.figtext(0.1, 0.95, '%s/%s d=%6.0fm h=%3.0fm %s'%\
                       (antenna, station, distance, height, wet), ha='left', va='top')
            png = 'XYZ_%s_%s_%s.png'%(wet, antenna, station)
            pb.savefig(png)
            pngs.append(png)
        else:
            means[antenna] = [0,0,0]
            rmss[antenna] = [0,0,0]
        # Find this antenna's entry in the first antpos_result/CalPosition.xml file, read it, 
        # update the new positions, and write it to the new file in the new directory.
        # Note that the subsequent execution of EditPositions.py will not typically
        # apply all the updates due to the minSigma and threshold options.
        if (writeFile != ''):
#            previous = open(writeFile+'/CalPosition.xml','r')
            previous = open(antennaResults[0]+'/CalPosition.xml','r')
            lines = previous.readlines()
            previous.close()
            foundAntenna = False
            for line in lines:
                if (line.find('<antennaName> %s'%antenna) >= 0):
                    foundAntenna = True
                    totalChange = np.linalg.norm(means[antenna])
                    print "Putting position correction of %.3f mm for antenna %s." % (totalChange, antenna)
                    loc = line.find('positionOffset')
                    newline = line[:loc]
                    eastMeters = means[antenna][0]*0.001
                    northMeters = means[antenna][1]*0.001
                    upMeters = means[antenna][2]*0.001
                    # replace the existing offset from a single dataset with the mean values from all datasets
                    newline += 'positionOffset> 1 3 %.22f %.22f %.22f ' % (eastMeters, northMeters, upMeters)
                    newline += line[line.find('</positionOffset'):line.find('positionErr')]
                    newline += 'positionErr> 1 3 %.22f %.22f %.22f ' % (rmss[antenna][0]*0.001,
                                                                        rmss[antenna][1]*0.001,
                                                                        rmss[antenna][2]*0.001)
                    newline += line[line.find('</positionErr'):]
                    f.write('<row>\n')
                    f.write(newline)
            if not foundAntenna:
                print "Did not find an entry for %s in %s.  This should not happen, so there must be a bug." % (antenna,antennaResults[0])
                return
    if writeFile != '':
        if (casadef.casa_version >= '4.2' and os.path.exists(asdm0)):
            png = asdm0+'.plotants_log.png'
            plotantsFromASDM(asdm,plotfile=png,logarithmicOnly=True)
            pngs.append(png)
        pdfname = newresults + '_averageAntPosResults.pdf'
    else:
        pdfname = 'averageAntPosResults.pdf'
    buildPdfFromPngs(pngs, pdfname, quiet=True)
    if writeFile != '':
        f.write('</CalPositionTable>\n')
        f.close()
        print "Wrote mean corrections into new directory = ", newresults
        print "%d antennas have corrections > %.1f sigma on 1 axis: " % (len(antennasToUpdate1Axis),minSnr), antennasToUpdate1Axis
        print "%d antennas have corrections > %.1f sigma on 2 axis: " % (len(antennasToUpdate2Axes),minSnr), antennasToUpdate2Axes
        print "%d antennas have corrections > %.1f sigma on 3 axes: " % (len(antennasToUpdate3Axes),minSnr), antennasToUpdate3Axes
        print "Now you can transfer this directory to red-osf and run:"
        print "  ExportPositionModel.py -c CURRENT.AOS"
        print "  EditPositions.py -f %s -i PositionModel-nnnnn.xml" % (newresults)
    return c

def findLineNumberAndTimestamp(lines, string, start=0):
    """
    Takes a CASA log file, locates the specified string (starting from a specified line number)
    and computes the timestamp of the line that contains it.
    Returns: line number, and value in MJD seconds
    -Todd Hunter
    """
    lineNumber = findLineNumber(lines, string, start)
    token = lines[lineNumber].split()
    timestamp = dateStringToMJDSec(token[0] + ' ' + token[1], verbose=False)
    return lineNumber, timestamp
    
def findLineNumber(lines, string, start=0):
    """
    Finds the first line number in a text file that contains the specified string
    -Todd Hunter
    """
    startLine = -1
    for i,line in enumerate(lines[start:]):
        if line.find(string) > 0:
            startLine = i+start
            break
    return startLine

def findImageSpwsFromCasalog(casalog, intent='OBSERVE_TARGET', debug=False):
    """
    Reads an ALMA imaging pipeline CASA log file (i.e. containing tclean commands) and 
    determines the list of spws imaged.
    casalog: either the name of a CASA log file, or a list of lines read from one.
    intent: limit the search to tclean commands that specify this intent string
    """
    if type(casalog) == str:
        f = open(casalog,'r')
        lines = f.readlines()
        f.close()
    else:
        lines = casalog
    spws = []
    cleaningPresent = False
    for line in lines:
        if (line.find('Executing tclean(') > 0):
            cleaningPresent = True
            if (line.find(intent) > 0):
                if debug: print line
                token = line.split(', spw=[')
                if len(token) > 1:
                    myspw = int(token[1].split(',')[0].split(':')[0].rstrip("]").strip("'"))
                    spws.append(myspw)
    if cleaningPresent and len(spws) == 0 and intent.find('OBSERVE_TARGET') == 0:
        print "Only calibrator imaging is present in this log file."
    if not cleaningPresent:
        print "Did not find any tclean commands in this log file."
    return sorted(np.unique(spws))
    
def timeTclean(casalog, spw=None, majorCycle=2, showLineNumber=False, showTimestamp=True, 
               field=None, intent='OBSERVE_TARGET', debug=False):
    """
    Searches for the appearance of spw%d.cube.I.iter1' in an ALMA pipeline casa log file
    and computes the time required for each stage of the specified major cycle (2 or higher)
    spw: integer or string integer; if not specified, then it will list the available spws and exit
    majorCycle: integer >= 2
    field: string specifying name of field to restrict the search to
    intent: limit the search to tclean commands that specify this intent string. Note that cubes
         are only produced for OBSERVE_TARGET objects, so this is the only sensible value to use.
    """
    if not os.path.exists(casalog):
        print "Could not find casa log"
        return
    f = open(casalog,'r')
    lines = f.readlines()
    f.close()
    if spw is None:
        spws = findImageSpwsFromCasalog(lines, intent=intent)
        print "You must specify one spw.  Available: %s." % str(spws)
        return
    targets = []
    style = 'cube'
    if field is None:
        targets.append("spw%s.%s.I.iter1'" % (str(spw), style))
    else:
        targets.append("%s_sci.spw%s.%s.I.iter1'" % (field,str(spw),style))
    targets.append('Run Major Cycle %d' % (majorCycle))
    targets.append("Setting up an auto-mask")
    targets.append("Pruning the current mask")
    targets.append("Growing the previous mask")
    targets.append("Pruning the growed previous mask")
    targets.append("Creating a mask for negative features")
    targets.append("Number of pixels in the clean mask")
    targets.append("Run Minor Cycle")
    targets.append("Run Major Cycle %d" % (majorCycle+1))
    mjdsec = {}
    target = targets[0]
    lineNumber, mjdsec[target] = findLineNumberAndTimestamp(lines, target)
    if lineNumber < 0: 
        if field is not None:
            targets[0] = "%s__sci.spw%s.cube.I.iter1'" % (field,str(spw))
            target = targets[0]
            lineNumber, mjdsec[target] = findLineNumberAndTimestamp(lines, target)
        if lineNumber < 0:
            print "Could not find ", target 
            return
    strchars = 34
    cube = lines[lineNumber].split("imagename='")[1].split("'")[0]
    print "Working with cube: ", cube
    for i, target in enumerate(targets[1:]):
        newLineNumber, mjdsec[target] = findLineNumberAndTimestamp(lines, target, lineNumber+1)
        if newLineNumber < 0: 
            if target.find('Major Cycle') >= 0:
                if debug:
                    print "a) Could not find %s from line %d" % (target, lineNumber+1)
                target = target.replace('Run ','Run (Last) ')
                newLineNumber, mjdsec[target] = findLineNumberAndTimestamp(lines, target, lineNumber+1)
                if newLineNumber < 0: 
                    print "a) Could not find %s from line %d" % (target, lineNumber+1)
                    return
                else:
                    print "Changing '%s' to '%s', which has mjdsec=%f" % (targets[i+1],target,mjdsec[target])
                    targets[i+1] = target
            else:
                print "b) Could not find ", target
                return
        lineNumber = newLineNumber
        myline = ''
        if showLineNumber:
            myline += '%d: ' % (lineNumber)
        if showTimestamp:
            myline += '%s: ' % (mjdsecToDatestring(mjdsec[targets[i]]))
        myline += "%*s -- %7.1f minutes -- %-*s" % (strchars, targets[i][:strchars], (mjdsec[target]-mjdsec[targets[i]])/60., strchars, target[:strchars])
        if showTimestamp:
            myline += ' :%s' % (mjdsecToDatestring(mjdsec[target]))
        print myline
        if debug:
            print "     %f to %f   (line X to %d)" % (mjdsec[targets[i]], mjdsec[target], lineNumber)

def findPipelineCasaLogfile(mydir, asdmNoPath=None, ignoredir='html',
                            verbose=False, searchString='Analyzing pipeline',
                            sortByModificationTime=False):
    """
    Finds the *newest* casapy logfile in the specified directory tree that 
    contains "Analyzing pipeline" (or other specified string).  It is usually 
    of the format:  casa-YYYYMMDD-HHMMSS.log. 
    asdmNoPath: if specified, then find the one that contains "applycal(" and 
        the specified asdm on the same line. This avoids the chafe of the lots 
        of little log files created when restarting casa frequently that may
        be newer than the actual pipeline run.
    searchString:  set to "Beginning pipeline" to find the initial importdata log
    sortByModificationTime: 
       if True, then search only the specified directory and sort by time (fast)
       if False, then sort by name and search whole tree (very slow)
          if you do not know the path to the working directory but only a 
          parent, then it is better to first run findPipelineRunCasaLog, which
          searches on the known pattern of S*/G*/M*/working.
    Example:
    logs = findPipelineRunCasaLogs('pipeline/root/2013.1.00001.S_blah')
    log = findPipelineCasaLogfile(os.path.dirname(logs[0]),sortByModificationTim
    Returns: a single matching logfile
    """
    debug = False
    if (mydir==''):
        mydir = './'
    if (mydir[-1] != '/'):
        mydir += '/'
    # Make a list with the most recent file first
    if verbose:
        print("Search dir = %s" % mydir)
    if sortByModificationTime:
        # old style
        mySearchString = mydir+'*casa*.log'
        # The following would work to search the tree in python 3.5+.
        #    mySearchString = mydir+'**/*casa*.log'
        if verbose:
            print("Search string = %s" % mySearchString)
        dirlist = sorted(glob.glob(mySearchString), key=os.path.getmtime, reverse=True)
    else:
        dirlist = []
        for root, dirnames, filenames in os.walk(mydir):
            for filename in fnmatch.filter(filenames, 'casa*.log'):
                if (ignoredir == ''):
                    dirlist.append(os.path.join(root, filename))
                elif (root.find(ignoredir) < 0):
                    dirlist.append(os.path.join(root, filename))
        # The following sorts by filename, so latest one created will get returned
        dirlist = sorted(dirlist, reverse=True)
    if verbose:
        print("dirlist = %s"% dirlist)
    if (dirlist == []):
        print('WARNING: unknown (no log file found in %s)'%(mydir))
        return None
    else:
        newdirlist = []
        for mydir in dirlist:
            if (grep(mydir,searchString)[0] != ''):
                newdirlist.append(mydir)
        dirlist = newdirlist
        if (asdmNoPath == None):
            if (len(dirlist) < 1):
                print("No files found containing: ", searchString)
                return ''
            else:
                return(dirlist[0])
        for logfile in dirlist:
            if (debug): print("Checking logfile = %s" % (logfile))
            f = open(logfile,'r')
            lines = f.readlines()
            f.close()
            for line in lines:
                if (line.find('applycal(')>0):
                    if (debug): print("    Checking line = %s" % (line))
                    if (line.find(asdmNoPath) > 0):
                        print("Found most recent logfile containing applycal(%s): %s" % (asdmNoPath, logfile))
                        return(logfile)
    print("EROR: I didn't find a pipeline casa log with an applycal(%s)!" % (asdmNoPath))
    return None

def findPipelineRunCasaLogs(root, tasklist=''):
    """
    Searches a pipeline execution directory tree 
    (20xx.x.xxxxx.x_YYYY_MM_DDTHH_MM_SS.SSS/S*/G*/M*/working) or any subset
    thereof, for casa-*.log files and returns a list of them. This is much 
    faster than the os.walk that is implemented in findPipelineCasaLogfile.  
    It is best to run this function first, and then pass the directory to 
    au.findPipelineCasaLogfile(sortByModificationTime=True).
    Example:
    logs = findPipelineRunCasaLogs('pipeline/root/2013.1.00001.S_blah')
    log = findPipelineCasaLogfile(os.path.dirname(logs[0]),sortByModificationTime=True)
    root: any directory path unique to one pipeline run:
      e.g. '/lustre/naasc/sciops/comm/sbooth/pipeline/root/2013.1.0001.S_blah'
      e.g. '/lustre/naasc/sciops/comm/sbooth/pipeline/root/2013.1.0001.S_blah/SOUS_blah'
    tasklist: a python list of strings or a comma-delimited string
    Returns: a list of log files
    -Todd Hunter
    """
    logs = glob.glob(os.path.join(root,'S*','G*','M*','working/casa-*log'))
    if len(logs) == 0:
        logs = glob.glob(os.path.join(root,'G*','M*','working/casa-*log'))
        if len(logs) == 0:
            logs = glob.glob(os.path.join(root,'M*','working/casa-*log'))
            if len(logs) == 0:
                logs = glob.glob(os.path.join(root,'working/casa-*log'))
                if len(logs) == 0:
                    logs = glob.glob(os.path.join(root,'casa-*log'))
    if tasklist != '':
        if type(tasklist) == str:
            tasklist = tasklist.split(',')
        goodlogs = []
        for log in logs:
            if tasklist == '':
                goodlogs.append(log)
            else:
                for task in tasklist:
                    if len(grep(log,'Executing command ...'+task)[0]) > 0:
                        goodlogs.append(log)
                        break
        logs = goodlogs
    return sorted(logs)

def multiTaskExecutionTimesGlob(directory, 
       tasklist='hifa_imageprecheck,hif_checkproductsize,hif_makeimlist,hif_makeimages',
                                termination=['','','','Begin Task: tclean'],
                                outfile="multiTaskExecutionTimes_apparentsens.txt", 
                                maxdir=-1, verbose=False, tabDelimited=False):
    """
    For each pipeline run in a directory, finds the list of CASA logs that
    contain any of the specified tasks in the tasklist, and runs 
    multiTaskExecutionTimes on them.  Produces a text file of format:
    MOUS  timeTask1  timeTask2  timeTask3 ...
    tasklist: a python list of strings or a comma-delimited string
    termination: a python list of strings or a comma-delimited string that sets
       an optional early termination string for the corresponding task in the
       tasklist -- the reported time will be up to the first appearance of this string
    maxdir: maximum number of directories to process
    tabDelimited: if True, then use tabs to delimit the data columns; otherwise
        use a number of spaces that makes the default tasklist human readable
    -Todd Hunter
    """
    dirlist = sorted(glob.glob(directory+'/*'))
    f = open(outfile,'w')
    f.write('# Directory;  time in minutes:  ')
    if type(tasklist) == str:
        tasklist = tasklist.split(',')
    for i,task in enumerate(tasklist):
        f.write('%s '%task.replace('hif_','').replace('hifa_',''))
        if task in ['hif_makeimlist', 'hif_makeimages']:
            f.write(16*'-'+'   ')
    f.write('\n')
    if maxdir != -1:
        dirlist = dirlist[:maxdir]
    for dir in dirlist:
        if os.path.isdir(dir):
            if verbose:
                print "=========Working on directory: ", dir
            logs = findPipelineRunCasaLogs(dir, tasklist)
            times = {}
            for log in logs:
                if verbose:
                    print "==============Working logfile: ", log
                times = multiTaskExecutionTimes(tasklist, log, times, termination, verbose=verbose)
            print "times = ", times
            if tabDelimited:
                 f.write('%s\t' % (os.path.basename(dir)))
                 for i,task in enumerate(tasklist):
                     for t in times[task]:
                         f.write('%5.1f\t'%(t/60.))
            else:
                 f.write('%s ' % (os.path.basename(dir)))
                 for i,task in enumerate(tasklist):
                     for t in times[task]:
                         f.write('%5.1f '%(t/60.))
                     if i < 2:
                         f.write('     ')
            f.write('\n')
            f.flush()
    f.close()
    print "Wrote ", outfile

def multiTaskExecutionTimes(tasklist, log='', times={}, termination=None, verbose=False):
    """
    For the specified CASA log file, calls taskExecutionTimes for the
    specified list of CASA tasks and returns a dictionary keyed by task name, 
    with values being a list of times in seconds for that task.
    tasklist: a python list of strings or a comma-delimited string
    log: name of a CASA log file, default -> current log
    times: a dictionary, possibly blank, with keys from the tasklist
    termination: a python list of strings or a comma-delimited string that sets
       an optional early termination string for the corresponding task in the
       tasklist -- the reported time will be up to the first appearance of this string
    -Todd Hunter
    """
    if (log == ''): log = casalog.logfile()
    if type(tasklist) == str:
        tasklist = tasklist.split(',')
    if termination is None:
        termination = ['']*len(tasklist)
    elif type(termination) == str:
        termination = termination.split(',')
    if len(termination) != len(tasklist):
        print "Mismatch in length of tasklist vs. termination string."
        return
    for i,task in enumerate(tasklist):
        newtimes = taskExecutionTimes(task, log, termination[i], verbose=verbose)
        if task not in times:
            times[task] = newtimes
        else:
            times[task] += newtimes
    return times

def findPipelineTaskExecutionTimes(log='', imagingLog='', debug=False):
    """
    Assembles time for each task.
    Returns: 4 lists: task names, startTimes (mjdsec), elapsedTimes (seconds),
            startTimeStrings (string)
    """
    if (log == ''): log = casalog.logfile()
    logs = [log]
    if imagingLog != '':
        logs.append(imagingLog)
    startTimes = []
    startTimeStrings = []
    elapsedTimes = []
    tasks = []
    for log in logs:
        if debug: print "Operating on ", log
        f = open(log,'r')
        lines = f.readlines()
        f.close()
        for line in lines:
            if line.find('Executing command ...') >= 0:
                if debug: print line.rstrip('\n')
                task = line.split('Executing command ...')[1].rstrip('\n')
                dateString = ' '.join(line.split()[:2])
                startTime = dateStringToMJDSec(dateString, verbose=False)
                i = len(startTimes)
                if i > 0:
                    elapsedTimes.append(startTime-startTimes[i-1])
                    if debug: print "Appending elapsedTime for task ", task
                startTimes.append(startTime)
                tasks.append(task)
                startTimeStrings.append(dateString)
                if debug: print "  appending task: ", task
            if (line.find('Terminating procedure execution') >= 0):
                if debug: print '  ' + line.rstrip('\n')
                dateString = ' '.join(line.split()[:2])
                finalTime = dateStringToMJDSec(dateString, verbose=False)
    if len(startTimes) > 0:
        elapsedTimes.append(finalTime-startTimes[-1])
        if debug: print "final append for elapsedTime for task ", task
    if debug:
        print "lengths: start=%d elapsed=%d tasks=%d" % (len(startTimes),len(elapsedTimes),len(tasks))
    return tasks, startTimes, elapsedTimes, startTimeStrings

def intervalToHMS(seconds, showDays='auto'):
    """
    Convert number of seconds to an interval string:
    Example: 34400 --> '00d09h33m20s'
    -Todd Hunter
    """
    if showDays == 'auto':
        showDays = seconds > 86400
    if showDays:
        days = int(seconds / 86400)
        hours = int((seconds - days*86400) / 3600)
        minutes = int((seconds - days*86400 - hours*3600) / 60)
        myseconds = seconds - days*86400 - hours*3600 - minutes*60
        return '%3dd%02dh%02dm%02.0fs' % (days, hours, minutes, myseconds)
    else:
        hours = int(seconds / 3600)
        minutes = int((seconds - hours*3600) / 60)
        myseconds = seconds - hours*3600 - minutes*60
        return '%3dh%02dm%02.0fs' % (hours, minutes, myseconds)

def pipelineTaskExecutionTimes(log='', imagingLog='', debug=False):
    """
    Assembles time for each task and prints it to the screen.  Calls
    findPipelineTaskExecutionTimes.
    log: default is currently open CASA log,
        if the value is a directory, it searches for hif_applycal to find
        the calibration log, and if hif_mstransform is not present, it searches
        for the imaging log
    imagingLog: default is none
    Returns: 3 lists: task names, startTimes (mjdsec), elapsedTimes (seconds)
    """
    if not os.path.exists(log):
        print "Could not find path: ", log
        return
    if os.path.isdir(log):
        print "Searching for casa log file for calibration."
        mylog = findPipelineRunCasaLogs(log)
        path = os.path.dirname(mylog[0])
        print "path found: ", path
        log = findPipelineCasaLogfile(path,searchString=' ...hif_applycal',sortByModificationTime=True)
        stdout,stderr = grep(log,'hif_mstransform')
        if len(stdout) == 0:
            print "Searching for casa log file for imaging."
            imagingLog = findPipelineCasaLogfile(path,searchString=' ...hif_mstransform',sortByModificationTime=True)
        if imagingLog == log:
            imagingLog = ''
    tasks, startTimes, elapsedTimes, startTimeStrings = findPipelineTaskExecutionTimes(log, imagingLog, debug)
    totalSeconds = 0
    elapsedTimes = np.array(elapsedTimes)
    if len(np.where(elapsedTimes >= 86400)[0]) > 0:
        elapsedShowDays = True
    else:
        elapsedShowDays = False
    totalShowDays = sum(elapsedTimes) >= 86400
    print "Stage       Task name   %s   splitTime  %s   totalTime       startTime (UT)" % (' '*int(elapsedShowDays)*3,' '*int(totalShowDays)*3)
    for i,task in enumerate(tasks):
        t = intervalToHMS(elapsedTimes[i], showDays=elapsedShowDays)
        totalSeconds += elapsedTimes[i]
#        print "   elapsedTimes[i]=%f, totalSeconds = %f" % (elapsedTimes[i],totalSeconds)
        total = intervalToHMS(totalSeconds, showDays=totalShowDays)
        print "%2d. %20s   %s    %s    %s" % (i+1,task,t, total, startTimeStrings[i])
    
def taskExecutionTimes(task, log='', termination='', filterSeconds=0, showTimes=True,
                       stripPath='/lustre', verbose=False, extraPhrase='', 
                       parameter='', getIterations=False, worldWrite=False,
                       returnImageSizes=False, returnImageNames=False, 
                       fullpath=True, histogram=False):
    """
    Computes the time taken to execute a task in a casa log (all appearances
    of it) and writes the results (if any are found) to a new text file.
    Example: t,s,p,n=au.taskExecutionTimes('imstat',stripPath='',parameter='chauvenet',returnImageSizes=True,returnImageNames=True)
             au.plotTaskExecutionTimes(p,t)
    task: name of task
    log: name of casa log file (default is current log)
    termination: a string that sets an optional early termination string for the 
       corresponding task in the tasklist -- the reported time will be up to the 
       first appearance of this string, or the normal end, whichever comes first
    filterSeconds: only show results if time is larger than or equal to this value
    showTimes: if False, then don't print the times, just the task calls
    stripPath: if not blank, the look for this directory tree and remove all
               the subdirectories below it from the file parameters.
    extraPhrase: also print lines that contain this phrase
    parameter: if specified, then the call must also contain this string
    getIterations: if True, then return the number of iterations in the
                  final matching line that contains the word iterations.
      (requires extraPhrase to be set to, e.g., mergeCycleExecutionRecord or Completed)
    fullpath: if True, then returnImageNames includes full path
    Returns:
    a list of timings in seconds, unless getIterations is set True
    If returnImageSizes is set, then it returns 3 things: list of timings,
    list of ia.shape, list of total pixels.
    if returnImageNames is set, it is also returned (last in the list)
    -Todd Hunter
    """
    if (task.find('/') >= 0):
        print "The first argument is the task name to measure."
        return
    if verbose: print "------taskExecutionTimes(%s)--------" % (task)
    if (log == ''): log = casalog.logfile()
    f = open(log,'r')
    lines = f.readlines()
    f.close()
    timings = []
    if returnImageNames:
        imagenames = []
    if returnImageSizes:
        sizes = []
        pixels = []
        myia = createCasaTool(iatool)
    if showTimes:
        # make this different from casa*.log to avoid confusion with future globs
        filename = log+'.%s.timings.logfile' % (task)
    else:
        filename = log+'.taskcalls.logfile'
    dirname = os.path.dirname(filename)
    if dirname == '':
        dirname = './'
    if (os.access(dirname, os.W_OK)):
        if (not os.path.exists(filename)):
            if verbose: print "Creating ", filename
            output = open(filename, 'w')
            outputLines = []
        elif (os.access(filename, os.W_OK)):
            if verbose: print "Overwriting ", filename
            output = open(filename, 'w')
            outputLines = []
        else:
            print "No permission to overwrite the file."
            output = None
    else:
        print "No permission to write in this directory: ", dirname
        output = None
    sawParameter = False
    if getIterations:
        iterations = -1
    inPipelineTask = False
    for i in range(len(lines)):
        line = lines[i]
        if (line.find('Begin Task: '+task) > 0 or
            line.find('Executing command ...'+task) > 0):
            if verbose: print line
            if line.find('Begin Task: ') > 0:
                beginTask = line.split('Begin Task: ')[1].split()[0]
                j = i+1
            else:
                j = i
                beginTask = line.split('Executing command ...')[1].split()[0]
                inPipelineTask = True
            sawParameter = False
            dateString = ' '.join(line.split()[:2])
            startTime = dateStringToMJDSec(dateString, verbose=False)
            if (lines[j].find('::::casa') > 0):
                format = 0
                call = lines[j][lines[j].find('::::casa')+9:]
            else:
                format = 1
                startchar = lines[j].find(task)
                # doing this in 2 steps allows one to use minimum-match 
                # (i.e. 'im' will find imhead,imstat,immoments etc.)
                startchar += lines[j][startchar:].find('::::') + 4
                call = lines[j][startchar:]
                if verbose: print "call = ", call
            dateTimeString = lines[j][:20]
            j += 1
            while (lines[j].find('casa+') > 0 or
                   lines[j].find('::::+') > 0):
                if format == 0:
                    call += lines[j][lines[j].find('casa+')+5:]
                else:
                    startchar = lines[j].find(task)
                    startchar += lines[j][startchar:].find('::::+') + 5
                    call += lines[j][startchar:]
                j += 1
        foundEndOfNormalTask = line.find('End Task: '+task) > 0
        foundCrashOfNormalTask = line.find('An error occurred running task '+task) > 0
        foundBeginTaskWithinPipelineTask = line.find(termination) > 0 and len(termination)>0
        foundEndOfPipelineTask = ((line.find('Executing command ...') > 0 and 
                                   line.find('Executing command ...'+task) < 0) or 
                                  foundBeginTaskWithinPipelineTask) and inPipelineTask
        if (foundEndOfNormalTask or foundCrashOfNormalTask or
            # or we have found the next pipeline task, since pipeline tasks do
            # not announce their ending
            foundEndOfPipelineTask):
            if foundEndOfNormalTask:
                crashed = ''
            elif foundEndOfPipelineTask:
                crashed = ''
                inPipelineTask = False
                if foundBeginTaskWithinPipelineTask and verbose:
                    print "terminating timing of %s because we saw %s" % (task, termination)
            else:
                crashed = 'crashed!'
            if verbose: print line
            endTime = dateStringToMJDSec(' '.join(line.split()[:2]), verbose=False)
            duration = endTime-startTime
            if (duration >= filterSeconds):
                if stripPath != '':
                    loc = call.find(stripPath)
                    if (loc >= 0):
                        mydir = os.path.dirname(call[loc:].split('"')[0])+'/'
                        call = call.replace(mydir,'')
                        loc = call.find(stripPath)
                        # Now look for another surviving dir, such as products
                        if (loc >= 0):
                            mydir = os.path.dirname(call[loc:].split('"')[0])+'/'
                            call = call.replace(mydir,'')
                if (parameter == '' or call.find(parameter) > 0):
                    if (parameter != ''):
                        sawParameter = True
                    timings.append(duration)
                    if returnImageSizes:
                        imagename = call.split('imagename="')[1].split('"')[0]
                        myia.open(imagename)
                        myshape = myia.shape()
                        sizes.append(list(myshape))
                        pixels.append(np.product(myshape))
                        myia.close()
                    if returnImageNames:
                        if fullpath:
                            imagenames.append(call.split('imagename="')[1].split('"')[0])
                        else:
                            imagenames.append(os.path.basename(call.split('imagename="')[1].split('"')[0]))
                    if (showTimes):
                        print "%4d seconds: %s" % (duration, call),
                        if (output is not None):
                            outputLines.append("%4d seconds: %s" % (duration, call))
                    else:
                        dateTimeString = '#%s  %s %s\n' % (dateTimeString,beginTask,crashed)
                        print 2*'\n'+dateTimeString+call.strip(),
                        if (output is not None):
                            outputLines.append(2*'\n'+dateTimeString+call.strip())
        if (extraPhrase != '' and (sawParameter or parameter == '')):
            if (line.find(extraPhrase) >= 0):
                call += line
                if (getIterations):
                    iterations = line.split('iterations')[0].split()[-1]
                    if (iterations.isdigit()):
                        iterations = int(iterations)
        if (line.find(parameter) > 0):
            sawParameter = True
        if (sawParameter and getIterations and line.find('empty model image') > 0):
            iterations = 0
    if (output is not None):
        for i in outputLines:
            output.write(i)
        output.close()
        if worldWrite:
            os.system('chmod g+w ' + filename)
    if histogram:
        pb.clf()
        print "plotting %d timings" % (len(timings))
        pb.hist(timings, bins=int(len(timings)/20))
        pb.xlabel('Execution time (seconds)')
        pb.ylabel('Number of occurrences')
        pb.title('%d %s, %s' % (len(timings),task,parameter))
        png = log+'_%s_%s.png'%(task,parameter)
        pb.savefig(png)
        print "Wrote ", png
    if getIterations:
        return iterations
    else:
        if returnImageSizes:
            myia.close()
            if returnImageNames:
                return timings, sizes, pixels, imagenames
            else:
                return timings, sizes, pixels
        else:
            if returnImageNames:
                return timings, imagenames
            else:
                return timings

def plotTaskExecutionTimes(pixels, timings, ylim=[0,4000], xlim=[0,7e9]):
    """
    Plots time vs. number of pixels, as computed by 
    au.taskExecutionTimes(returnImageSizes=True)
    -Todd Hunter
    """
    pb.clf()
    pb.plot(pixels, timings, 'o')
    pb.ylim(ylim)
    pb.xlim(xlim)
    pb.plot([6.93e9],[3600],'ro')
    pb.text(6.93e9,3400,'Time required is 24 times higher than red point',
            ha='right')
    pb.draw()
    pb.savefig('taskExecutionTimes.png')

def getMemorySize():
    """
    Returns the memory size of the current machine (in bytes).
    -Todd Hunter
    """
    try:
        return(os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES'))
    except ValueError:
        # SC_PHYS_PAGES can be missing on OS X
        return int(subprocess.check_output(['sysctl', '-n', 'hw.memsize']).strip())

class smearing:
    # original equations and comments taken from Anita Richards' scripts.
    def __init__(self):
        pass

    # case 1.3
    def GS(self, R, B, theta):
        beta_GS = (2./1.665)*math.sqrt((10.- math.sqrt(360.*R - 260.))/6.)
        dnu_GS = beta_GS/(1.E+06 * theta*math.pi/(180.*3600.) * B/3.E+08)
        return dnu_GS

    # case 1.4
    def GG(self, R, B, theta):
        beta_GG = math.sqrt(1./R/R - 1.)
        dnu_GG= 300.*beta_GG/(B*theta*(math.pi/(180.*3600.)))
        return dnu_GG

    def bandwidthSmearing(self, nu=115000, R=0.95, B=450., theta=30.):
        """
        Enter parameters to find bandwidth for acceptable smearing 
        nu = 115000       # Frequency in MHz
        R = 0.95               # lowest acceptable dimunition of signal (Iobs/Ireal)
        B = 450.               # max baseline, metres
        theta = 62./2.         # outermost source, arcsec from centre  
        Returns:
        two bandwidth values in MHz: for a few channels, and for many channels
        """
        # Synthesized beam FWHM is given by theta_B = bm*lambda/B where
        # bm=1.0; if a more sophisticated expression is desired change bm
        bm=1.0

        # TBD - similar for RM synthesis limitations?
        # This form is useful for predictions; it could also be modified to
        # run inside CASA on a given MS to extract frequency and other
        # parameters and apply smoothing automatically.

        # Calculate bandwidth smearing
        # thetaPB = [62./2., 27./2., 18./2., 9./2.]
        # Based on Bridle & Schwab (B&S) ch 18 in Synthesis Imaging II
        # (Taylor, Carilli & Perley 1999)
        ####              Assumptions and warnings:                ####
        #
        # Other effects e.g. primary beam, spectral index, may provide worse
        # distortions at theta.
        #
        # Confusing as well as wanted sources should be considered
        #
        #####################################################
        # B&S gives three expressions for bandwidth smearing:
        #######################################################
        # Parameter beta is given by
        # beta = (dnu/nu) (theta/theta_B) (in SI units)
        # or for dnu in MHz, theta in arcsec, for maximum baseline B metres
        # (1) beta = dnu*1.E+06 * theta*pi/(180.*3600.) * B/3.E+08
        # 
        ####################################################################
        # 1.2 square uv coverage, square bandpass - least realistic?
        #
        ########################################################
        # 1.3 Gaussian distribution of uv coverage, square bandpass
        # (denoted where required using _GS)
        #     This is probably closest to a good range of hour angle coverage
        #     and more than a few channels averaged e.g. an entire spw
        # B&S Eq (18-24) gives
        # R = sqrt(math.pi)/(1.665*beta) * erf(beta*1.665/2.)
        # for observing frequency nu 
        #
        # This can be inverted using the first few terms of the Maclaurin
        # series for erf (http://mathworld.wolfram.com/Erf.html)
        #
        # (2) R = (sqrt(pi)/(1.665*beta))*((2./sqrt(pi))*(z-z**3/3.+z**5/10.))
        # where z = beta1*1.665/2.
        # This reduces to a quadratic equation in z^2 which has real roots for
        # R > 13/18 and beta is accurate to a few percent or better for R > 0.8
        # 
        # (3) beta_GS = (2./1.665)*sqrt((10.- sqrt(360.*R - 260.))/6.)
        # Comparing (1) and (3) gives
        #
        # (4) dnu_GS = beta_GS/(1.E+06 * theta*pi/(180.*3600.) * B/3.E+08)
        #
        ##################################################################
        # 1.4 Gaussian uv coverage, Gaussian bandpass
        #     This is probably better than 1.3 for single or a few channels
        #     which have been Hanning smoothed
        # B&S equation 18-29 gives
        # (5) R = 1/sqrt(1+beta^2)
        # so
        # (6) beta_GG = sqrt(1/R^2 - 1.)
        # This can easily be inverted analytically and compared with (1) to give
        # (7) dnu_GG= 300.*beta_GG/(B*theta*(pi/(180.*3600.)))

        #####################################################################
        if R >= 26./36.:
            dnu_GS = self.GS(R, B, theta)
            dnu_GG = self.GG(R, B, theta)

        if  R < 26./36.:
            dnu_GG = self.GG(R, B, theta)
            dnu_GS = 0

        return(dnu_GG, dnu_GS)
    
    def timeSmearing(self, R, theta, thetaB, Nant, prec=1):
        """
        To calculate the time averaging interval dt to achieve time-smearing
        at radius theta of no worse than R where R = apparent/true amplitude
        of an unresolved source, for synthesised beamwidth thetaB
        
        thetaB can be approximated as (wavelength/longest baseline) but for
        short tracks or low-elevation sources, the natural, synthesised
        beam-width should be used. This expression becomes less accurate for
        non-circular uv tracks; using the minor beam axis will give a
        conservative estimate of dt.

        The phase-rate dphi/dt may also cause smearing at large theta.

        prec: number of digits after decimal to show for times
        """
        ###############################################################
        #
        # This form is useful for predictions; it could also be modified to
        # run inside CASA on a given MS to extract frequency and other
        # parameters and apply smoothing automatically.
        #
        #################################################################
        # Calculate time smearing
        #
        # Other effects e.g. primary beam, phase rate, may provide worse
        # distortions at theta.
        # Confusing as well as wanted sources should be considered
        #
        # Based on Bridle & Schwab (B&S) ch 18 in Synthesis Imaging II
        # (Taylor, Carilli & Perley 1999)
        # Average intensity loss for a circumpolar point source is given by
        # R = 1-const (theta/thetaB)^2 dt^2
        #
        # where const = 1.08E-09 for uniform, circular uv coverage (possibly
        # suitable for the most compact configurations) and
        # C = 1.22E-09 for a Gaussian distribution of uv coverage (more
        # suitable for most, especially extended configurations).
        # So
        # dt = sqrt[(1-R)/const] (thetaB/theta) 
        ######################################################
        C = [1.08E-09, 1.22E-09]
        dtU = (math.sqrt((1.-R)/C[0]))*thetaB/theta
        dtG = (math.sqrt((1.-R)/C[1]))*thetaB/theta
        # Phase rate df = dphi/dt = 2 pi (theta/thetaB)/24/3600 (rad/sec)
        df = 2.*math.pi*(theta/thetaB)/86400.
        # leading to an amplitude reduction of Rf = sinc(df*dtG/2.) 
        # (Perley, ch 13 ibid, eq 13-15).
        # But, (theta/thetaB) cancels, giving
        Rf = (sin(1.041*math.sqrt(1-R)))/(1.041*math.sqrt(1-R))

        # total phase change in dtG
        tf = df*dtG

        # time interval for phase change of pi/6
        dtF = math.pi/6./df

        t = min(dtG, dtF) # tightest constraint on averaging time

        # Dynamic range in 1 hr of t-sec integrations, 50 antennas, pi/6 phase
        # change. This assumes that each integration is independent which may
        # not be true for small t
        DdtFNant = sqrt(3600./t)*Nant/(math.pi/6.)
        # time required for dynamic range of 1000
        t1000 = (3600.*Nant**2./(df*1000.)**2)**(1./3.)

        print 'Sources at a radius of %.1f arcsec, observed using a synthesised beam width of %.3f arcsec' % (theta, thetaB)
        print "  will show an an apparent to actual flux density reduction ratio ~ %.3f" % (R)
        print "  due to time-smearing in averaged integration time of %.1f-%.1f sec" % (dtU,dtG)
        print "  for very well-filled to more extended array configurations."
        print "The phase rate at %.1f arcsec is %.2f deg/sec, leading to a reduction" % (theta,df)
        print "  of amplitude to %.3f in %.1f seconds." % (Rf, dtG)
        print "To avoid calibration and imaging errors a phase change < 30 deg and so"
        print "  an averaging time of < %.1f sec is required." % (dtF)
        print "The shortest of these averaging times, %.1f sec limits the dynamic range to %.4f in 1 hr" % (t,DdtFNant)
        print "  on-source, %d antennas. An averaging time <%.1f sec is needed for dynamic range 1000." % (Nant,t1000)
        print "This may be further reduced by noise and calibration errors."
        return t

def maxTimeWithoutSmearing(frequency, config='', maxBaseline=0,
                           gainloss=0.01, minpb=0.2, diameter=12, 
                           taper=10, obscuration=0.75, Nant=50, 
                           theta=None, verbose=False, prec=1):
    """
    frequency: in Hz, GHz, or a string with untis
    config: name of an antenna configuration file known to CASA
    maxBaseline: in meters (alternative to specifying configuration)
    gainloss: lowest acceptable dimunition of signal: (Ireal-Iobs)/Ireal
    minpb: how far out to consider in the primary beam response
    diameter: in meters (used to define beam response)
    taper: illumination taper in dB (used to define beam response)
    obscuration:  in meters (used to define beam response)
    Nant: only used if config is not specified
    theta: if specified, then use this radius (in arcsec) instead of minpb
    Returns:
    time value in seconds
    """
    if (config=='' and maxBaseline<=0):
        print "You must specify either a maximum baseline or an antenna configuration name."
        return
    R = 1-gainloss  
    freq = parseFrequencyArgumentToHz(frequency)
    if config != '':
        thetaB = estimateSynthesizedBeamForConfig(config, frequency)
        Nant = len(getPadsForConfig(config))
    else:
        thetaB = c_mks/freq/maxBaseline
    fwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter, taper=taper, 
                             obscuration=obscuration, showEquation=verbose)
    if theta is None:
        theta = gaussianBeamOffset(minpb, fwhm)
    timeValue = smearing().timeSmearing(R, theta, thetaB, Nant)
    return timeValue

def maxBandwidthWithoutSmearing(frequency, config='', maxBaseline=0,
                                gainloss=0.01, minpb=0.2, diameter=12, 
                                taper=10, obscuration=0.75, theta=None,
                                verbose=False):
    """
    Computes the maximum bandwidth you can use without suffering more 
    than 5% gain loss due to bandwidth smearing.
    frequency: in Hz, GHz, or a string with untis
    config: name of an antenna configuration file known to CASA
    maxBaseline: in meters (alternative to specifying configuration)
    minpb: how far out to consider in the primary beam response
    diameter: in meters (used to define beam response)
    taper: illumination taper in dB (used to define beam response)
    obscuration:  in meters (used to define beam response)
    theta: if specified, then use this radius (in arcsec) instead of minpb
    Returns:
    bandwidth value in MHz, assuming a Gaussian bandpass (i.e. dnu_GS)
    """
    if (config=='' and maxBaseline<=0):
        print "You must specify either a maximum baseline or an antenna configuration name."
        return
    R = 1-gainloss
    nu = parseFrequencyArgumentToGHz(frequency)*1e-3
    if config != '':
        result = getBaselineStats(config=config, verbose=verbose)
        if result is None: return
        B = result[2]
    else:
        B = maxBaseline
    fwhm = primaryBeamArcsec(frequency=frequency, diameter=diameter, taper=taper, 
                             obscuration=obscuration, showEquation=verbose)
    if theta is None:
        theta = gaussianBeamOffset(minpb, fwhm)
    dnu_GG, dnu_GS = smearing().bandwidthSmearing(nu, R, B, theta)
    if R >= 26./36.:
        print "The signal will be reduced to %.2f of its actual value at a radius of %.2f arcsec" % (R, theta)
        print "for a maximum baseline of %.1fm for a frequency interval of:" % (B)
        print "dnu_GS = %.2f MHz for many channels averaged (square bandpass) or " % (dnu_GS)
        print "dnu_GG = %.2f MHz for a few channels (Gaussian bandpass)." % (dnu_GG)
    if R < 0.8:
        print "For 26/36 < R < 0.8, this method over-estimates dnu_GS slightly \nbut in this range the true value is still up to 20% > du_GG."
    if  R < 26./36.:
        print "The signal will be reduced to R = %.2f of its actual value at a radius of %.2f arcsec." % (R, theta)
        print "for a maximum baseline of %.1fm for a channel width of:" % (B)
        print "dnu_GS = %.3f MHz for a few channels (Gaussian bandpass) (ignoring other effects)." % (dnu_GG) 
        print "This program cannot estimate smearing for a square bandpass for R < 26./36."
        print "It will be ~20% > dnu_GS at R = 0.5, decreasing at lower and higher R."
    return dnu_GG

def visstat2uvrange(mydict):
    """
    Takes a dictionary output by visstat, and computes and returns the global min/max 
    of the individual uv'min' and 'max' keys for each spw.
    -Todd Hunter
    """
    maxs = []
    mins = []
    for key in mydict.keys():
        maxs.append(mydict[key]['max'])
        mins.append(mydict[key]['min'])
    return([np.min(mins), np.max(maxs)])

def crossCaiSelection(vis, ignoreAntennas=[]):
    """
    Downloads the correlator container log files, concatenates them,
    then calls Neil's script to determine the baselines whose antenna
    combinations cross the CAI=32 border.  For SCIREQ-779.
    See also au.lowCaiSelection.
    vis: name of measurement set or ASDM
    date: yyyy-mm-dd (instead of vis)
    """
    import crossCaiFlag
    startMJDSec = getObservationStart(vis)
    if (startMJDSec is None):
        if (os.path.exists(vis)):
            print "Checking if it is an ASDM..."
            result = getObservationStartDateFromASDM(vis)
            if (result is None): return
            startDatestamp, startMJDSec = result
            stopDatestamp, stopMJDSec = getObservationEndDateFromASDM(vis)
        else:
            return
    else:
        stopMJDSec = getObservationStop(vis)
        startDatestamp = getObservationStartDate(vis)
        stopDatestamp = getObservationStopDate(vis)
    startDate = startDatestamp.split()[0]
    containerLog = compUtils.retrieve_ccc_container_data_files(startDate, 
                                               overwrite=False)
    selection = crossCaiFlag.crossCaiAntennaSelection(vis, containerLog)
    if type(ignoreAntennas) == str:
        ignoreAntennas = ignoreAntennas.split(',')
    if len(ignoreAntennas) > 0:
        selection = selection.split(';')
        newselection = []
        print "ignoreAntennas = ", ignoreAntennas
        for s in selection:
            ignore = False
            for ignoreAntenna in ignoreAntennas:
                if s.find(ignoreAntenna) >= 0:
                    ignore = True
                    print "dropping ", s
                    break
            if not ignore:
                newselection.append(s)
        selection = ';'.join(newselection)
    return selection

def lowCaiSelection(vis, ignoreAntennas=[]):
    """
    Downloads the correlator container log files, concatenates them,
    then calls Neil's script to determine the baselines whose antenna
    combinations are all less than the CAI=32 border. For PRTSPR-25246.
    See also au.crossCaiSelection.
    vis: name of measurement set or ASDM
    date: yyyy-mm-dd (instead of vis)
    """
    import crossCaiFlag
    startMJDSec = getObservationStart(vis)
    if (startMJDSec is None):
        if (os.path.exists(vis)):
            print "Checking if it is an ASDM..."
            result = getObservationStartDateFromASDM(vis)
            if (result is None): return
            startDatestamp, startMJDSec = result
            stopDatestamp, stopMJDSec = getObservationEndDateFromASDM(vis)
        else:
            return
    else:
        stopMJDSec = getObservationStop(vis)
        startDatestamp = getObservationStartDate(vis)
        stopDatestamp = getObservationStopDate(vis)
    startDate = startDatestamp.split()[0]
    containerLog = compUtils.retrieve_ccc_container_data_files(startDate, 
                                               overwrite=False)
    selection = crossCaiFlag.lowCaiAntennaSelection(vis, containerLog)
    if type(ignoreAntennas) == str:
        ignoreAntennas = ignoreAntennas.split(',')
    if len(ignoreAntennas) > 0:
        selection = selection.split(';')
        newselection = []
        print "ignoreAntennas = ", ignoreAntennas
        for s in selection:
            ignore = False
            for ignoreAntenna in ignoreAntennas:
                if s.find(ignoreAntenna) >= 0:
                    ignore = True
                    print "dropping ", s
                    break
            if not ignore:
                newselection.append(s)
        selection = ';'.join(newselection)
    return selection

def plotGfluxscaleHistogram(scaleFactors, nbins=10, plotfile='',size=18,title='',majorTickSpacing=0.25):
    """
    Makes a histogram of the scale factor list returned by plotGfluxscale.
    nbins: an integer or list, e.g. np.arange(0.575, 2.725, 0.05)
    """
    pb.clf()
    adesc = pb.subplot(111)
    pb.hist(scaleFactors, nbins)
    pb.xlabel('scale factor required to match catalog',size=size)
    pb.ylabel('number of occurrences (out of %d)'%(len(scaleFactors)),size=size)
    pb.text(0.97,0.95,'min = %.2f, median = %.2f, max = %.2f, scaled MAD = %.2f' % (np.min(scaleFactors),np.median(scaleFactors),np.max(scaleFactors),MAD(scaleFactors)),transform=adesc.transAxes,ha='right')
    majorLocator = MultipleLocator(majorTickSpacing)
    adesc.xaxis.set_major_locator(majorLocator)
    pb.title(title,size=size)
    if plotfile != '':
        if plotfile == True:
            plotfile = 'scaleFactors.png'
        print "Wrote ", plotfile
        pb.savefig(plotfile)
    
def plotGfluxscale(root, catalogColor='b', derivedColor='k', plotfile='',
                   fitImages=True, imageFluxColor='m', minspwWidth=0.9, intent=''):
    """
    Reads the pipeline AQUA report from one (or a list of) projects and 
    plots the gfluxscale results vs. frequency
    as per-spw error bars, and the per-spw catalog flux density as a line.
    Operates on the first derived field but in all measurement sets, which
    are shown in separate subplots on one page (per project).
    root: parent directory of a pipeline run -- anything that contains 
          at least one *aquareport.xml in a subdirectory
          It can also be a comma-delimited list, python list, or a string
          with a wildcard.
    plotfile: default is basename of AQUA report + '_plotGfluxscale.png'
    fitImages: if True, then also run imfit on the images and also plot the
          integrated flux density and uncertainty.
    minspwWidth: in GHz, only use spws wider than this in computing mean
       difference between image flux density and gfluxscale values.
    intent: 'PHASE', 'BANDPASS', or 'INTENT', or '' meaning first source in aquareport
    Produces: one plot per ASDM and two summary text files:  
    1) diff_vs_snr.dat: one line per spw per ASDM
    2) diff_vs_snr_%gMHz.dat: one line per ASDM (averaged over wide spws)
    Example: au.plotGfluxscale('/lustre/naasc/sciops/comm/sbooth/pipeline/root/5.1.0_validation/*_2017*/S*/G*/M*/working')
    -Todd Hunter
    """
# The following report has two TDM and two 234MHz FDM tuned to same center freqs:  /lustre/naasc/sciops/comm/amcnicho/pipeline/root/5.1_r40812/2013.1.00658.S_2017_09_12T17_03_39.871/SOUS_uid___A001_X13c_X36/GOUS_uid___A001_X13c_X37/MOUS_uid___A001_X13c_X38/working/pipeline_aquareport.xml
    if type(root) == str:
        if root.find('*') >= 0:
            roots = sorted(glob.glob(root))
        else:
            roots = root.split(',')
    else:
        roots = root
    pngs = []
    if fitImages:
        f = open('diff_vs_snr%s_%gMHz.dat' % (intent,minspwWidth*1000),'w')
        f.write('#SNR meanDiff percentageDiff rms\n')
        f2 = open('diff_vs_snr%s.dat'%intent,'w')
        f2.write('#N band SNR diff  percentDiffModel  percentDiffBox percentRecovered bw(GHz) nAntennas project  intent\n')
    ctr = 0
    f2lines = 0 # number of lines written to f2 output file
    scaleFactors = []
    phasecals = 0
    other = 0
    checksource = 0
    bandpasscals = 0
    for root in roots:
        root = root.rstrip('/')
        if not os.path.isdir(root):
            continue
        print "%s: Will try to get fluxes from AQUA report" % (os.path.basename(root))
        result = getFluxesFromAquaReport(root)
        if result is None: return
        derivedFluxes,catalogFluxes,workingdir = result
        uniqueAsdms = np.unique(derivedFluxes['ms'])
        nAsdms = len(uniqueAsdms)
        nrows = int(np.ceil(sqrt(nAsdms)))
        ncols = int(np.ceil(float(nAsdms) / nrows))
        pb.clf()
        # Define dictionaries to be used later when plotting catalog fluxes.
        derivedFlux = {}
        derivedUncertainty = {}
        derivedField = {}
        derivedSpws = {}
        derivedFreqs = {}
        rmsdiffFromImage = {}
        meandiffFromImage = {}
        meanPercentageDiff = {}
        numberWideWindows = {}
        meanSNRWideWindows = {}
        diffFromImage = []
        diffFromImageBox = []
        percentageRecoveredByModel = []
        percentageDiff = []
        percentageDiffBox = []
        nAntennas = []
        pngnames = []
        snr = []
        band = []  # alma receiver band integer
        bw = []    # spw bandwidth in GHz
        ctrs = []  # running index of spw derived flux, will not be sequential if an image fit fails 
        mymsmd = createCasaTool(msmdtool)
        for j,asdm in enumerate(uniqueAsdms):
            desc = pb.subplot(nrows, ncols, j+1)
            idx = np.where(asdm == np.array(derivedFluxes['ms']))
            # Just choose one field per ms for now (the first one)
            vis = os.path.join(os.path.dirname(root),'working/'+asdm+'.ms')
            mymsmd.open(vis)
            if intent.find('PHASE') >= 0:
                derivedField[asdm] = getPhaseCalibrators(vis, mymsmd=mymsmd, byname=True)[0]
            elif intent.find('BANDPASS') >= 0:
                derivedField[asdm] = getPhaseCalibrators(vis, mymsmd=mymsmd, byname=True, intent='CALIBRATE_BANDPASS#ON_SOURCE')[0]
            elif intent.find('CHECK') >= 0:
                derivedField[asdm] = getPhaseCalibrators(vis, mymsmd=mymsmd, byname=True, intent='OBSERVE_CHECK_SOURCE#ON_SOURCE')[0]
            else:
                # just take the first field
                derivedField[asdm] = np.array(derivedFluxes['fieldname'])[idx][0]
            if derivedField[asdm] in getPhaseCalibrators(vis, mymsmd=mymsmd, byname=True):
                phasecals += 1
                myintent = 'phase'
            elif derivedField[asdm] in getPhaseCalibrators(vis, mymsmd=mymsmd, intent='CALIBRATE_BANDPASS#ON_SOURCE', byname=True):
                bandpasscals += 1
                myintent = 'bandpass'
            elif derivedField[asdm] in getPhaseCalibrators(vis, mymsmd=mymsmd, intent='OBSERVE_CHECK_SOURCE#ON_SOURCE', byname=True):
                checksource += 1
                myintent = 'checksource'
            else:
                other += 1
                print "%s: intents for derived field %s: " % (asdm,derivedField[asdm]), mymsmd.intentsforfield(derivedField[asdm])
                return
            if intent != '' and myintent != intent.lower():
                print "%s: intents for derived field %s: " % (asdm,derivedField[asdm]), mymsmd.intentsforfield(derivedField[asdm])
                return
            idx = np.where((derivedField[asdm] == np.array(derivedFluxes['fieldname'])) * (asdm == np.array(derivedFluxes['ms'])))
            if (len(idx[0]) == 0):
                print "No matching entries of derived flux for combination: %s %s" % (asdm, derivedField[asdm])
                print derivedFluxes
                return
            xerr = np.array([0.5*derivedFluxes['bandwidths'][spw] for spw in np.array(derivedFluxes['spw'])[idx]])
            xdata = np.array([float(i) for i in np.array(derivedFluxes['freq'])[idx]])
            ydata = np.array([float(i) for i in np.array(derivedFluxes['I'])[idx]])
            yerr = np.array([float(i) for i in np.array(derivedFluxes['dI'])[idx]])
            derivedFlux[asdm] = ydata
            derivedUncertainty[asdm] = yerr
            derivedSpws[asdm] = list(np.array(derivedFluxes['spw'],dtype=int)[idx])
            derivedFreqs[asdm] = xdata
            wide_idx = np.where(xerr > minspwWidth/2.)[0]
            numberWideWindows[asdm] = len(wide_idx)
            meanSNRWideWindows[asdm] = np.mean(ydata[wide_idx] / yerr[wide_idx])
            i = np.argsort(xdata)
            pb.errorbar(xdata[i], ydata[i], xerr=xerr[i], yerr=yerr[i], fmt='.', lw=2,
                       color=derivedColor, mec=derivedColor, mfc=derivedColor)
            pb.title(asdm + ', ' + myintent + ', ' + derivedFluxes['date'][asdm], size=14-2*ncols)
            if fitImages:
                spws = np.array(derivedFluxes['spw'])[idx]
                xdataImg = []
                ydataImg = []
                xerrImg = []
                yerrImg = []
                fluxDiff = []
                blackRms = []  # rms of the gfluxscale value (drawn in black)
                for i, spw in enumerate(spws):
                    img = findPipelineImage(workingdir, derivedField[asdm], spw)
                    if img != '':
                        ctr += 1
                        pngname = 'img%d_%s.imfit.png'%(ctr,os.path.basename(img))
                        imageFlux = imageFitFluxAtPhaseCenter(img, pngname=pngname)
                        print "%s: imageFlux = %s" % (os.path.basename(img), str(imageFlux))
                        if imageFlux is not None:
                            # fill local lists
                            xdataImg.append(np.array(derivedFluxes['freq'])[idx][i])
                            ydataImg.append(imageFlux[0])
                            # derivedFluxes['bandwidths'] is a dictionary in GHz that looks like:   
                            #   {16: 0.0625, 18: 0.0625, 20: 2.0, 22: 0.0625, 24: 0.0625, 26: 2.0}
                            xerrImg.append(0.5*derivedFluxes['bandwidths'][spw])
                            yerrImg.append(imageFlux[1])
                            blackRms.append(yerr[i])
                            fluxDiff.append(imageFlux[0]-ydata[i])
                            # fill global lists
                            diffFromImage.append(imageFlux[0]-ydata[i])
                            diffFromImageBox.append(imageFlux[2]-ydata[i])
                            pngnames.append(pngname)
                            nAntennas.append(derivedFluxes["nAntennas"][asdm])
                            if imageFlux[2] > 0:
                                percentageRecoveredByModel.append(100*imageFlux[0]/imageFlux[2])
                            else:
                                percentageRecoveredByModel.append(0)
                            percentageDiff.append(100*diffFromImage[-1]/imageFlux[0])
                            percentageDiffBox.append(100*diffFromImageBox[-1]/imageFlux[0])
                            snr.append(ydata[i]/yerr[i])
                            band.append(freqToBand(parseFrequencyArgumentToHz(xdata[i]))[0])
                            bw.append(xerr[i]*2) # derivedFluxes['bandwidths'][spw])
                            ctrs.append(ctr)
                            if fitImages:   
                                # write out as we go, so the plot can be updated while the function continues to run
                                f2.write('%d %d %f %f %f %f %.2f %g %d %s %s\n' % (ctrs[-1], band[-1], snr[-1],diffFromImage[-1], percentageDiff[-1], percentageDiffBox[-1], percentageRecoveredByModel[-1], bw[-1], nAntennas[-1], os.path.basename(root), myintent))
                                f2.flush()
                fluxDiff = np.array(fluxDiff)
                if len(xdataImg) > 0:
                    # convert from string freq to float
                    xdataImg = np.array([float(i) for i in xdataImg])
                    pb.errorbar(xdataImg, ydataImg, xerr=xerrImg, yerr=yerrImg, 
                                fmt='.', lw=2, color=imageFluxColor, 
                                mec=imageFluxColor, mfc=imageFluxColor)
                    meandiffFromImage[asdm] = np.mean(fluxDiff/blackRms)
                    meanPercentageDiff[asdm] = np.mean(100*fluxDiff/ydataImg)
                    rmsdiffFromImage[asdm] = np.std(fluxDiff/blackRms)
                else:
                    rmsdiffFromImage[asdm] = None
            pb.hold(True)
            mysize = 14-2*ncols
            if j >= (nrows-1)*ncols:
                if ncols == 1:
                    pb.xlabel(derivedFluxes['project'] + '    Frequency (GHz)    MOUS=' + derivedFluxes['mous'])
                elif j==(nrows-1)*ncols:
                    pb.xlabel(derivedFluxes['project'] + '    Frequency (GHz)', size=mysize)
                elif j==(nrows-1)*ncols+1:
                    pb.xlabel('Frequency (GHz)    ' + derivedFluxes['mous'], size=mysize)
                else:
                    pb.xlabel('Frequency (GHz)', size=mysize)
            elif nrows > 2:
                # We are not on the final row, and there are 3 or more rows, so need
                # to make space for the title of each subplot by removing tick labels
                pb.gca().get_xaxis().set_ticks([])
            pb.setp(desc.get_xticklabels(), fontsize=mysize)
            pb.setp(desc.get_yticklabels(), fontsize=mysize)
            if (j % ncols) == 0:
                pb.ylabel('Flux density (Jy)')
        uniqueAsdms = np.unique(catalogFluxes['asdm'])
        for j,asdm in enumerate(uniqueAsdms): 
            desc = pb.subplot(nrows, ncols, j+1)
            # Just choose one field per ms for now
            idx = np.where((derivedField[asdm]==np.array(catalogFluxes['fieldname'])) * (asdm==np.array(catalogFluxes['asdm'])))
            if (len(idx[0]) == 0):
                print "No matching entries of catalog flux for combination: %s %s" % (asdm, derivedField[asdm])
                print catalogFluxes
                return
            # Sometimes importdata loads duplicate entries for each spw. Example: same calibrator
            # observed with 2 positions, only 1.3 mas apart:  EB=uid___A002_Xc2ae09_X27f
#/lustre/naasc/sciops/comm/amcnicho/pipeline/root/5.1_r40825/E2E5.1.00015.S_2017_09_18T20_02_46.192/SOUS_uid___A001_X1271_X8/GOUS_uid___A001_X1271_X9/MOUS_uid___A001_X1271_Xa/working/pipeline_aquareport.xml
#Field =         Names (*=phasecal)           Separations
#01-03 =     *J1733-1304-    *J1733-1304: 3.57879e-07 deg = 0.00128837 arcsec
            # The following loop eliminates such duplicates.
            uniqueSpws = np.unique(np.array(catalogFluxes['spw'])[idx])
            if len(uniqueSpws) < len(idx[0]):
                print "There are duplicate entries in this dataset: %s %s" % (derivedFluxes['project'], derivedFluxes['mous'])
                idx = []
                for spw in uniqueSpws:
                    i = np.where(catalogFluxes['spw'] == spw)[0]
                    idx.append(i[0])
                uniqueSpws = np.unique(np.array(catalogFluxes['spw'])[idx])

            xdata = np.array([float(i) for i in np.array(catalogFluxes['freq'])[idx]])
            ydata = np.array([float(i) for i in np.array(catalogFluxes['I'])[idx]])
            yspws = [int(i) for i in np.array(catalogFluxes['spw'])[idx]]
            numMissingSpws = len(uniqueSpws) - len(derivedSpws[asdm])
            if numMissingSpws > 0:
                # an spw is missing from the derivedFlux list, e.g. fully flagged, so
                # remove it from catalog fluxes to prevent mismatch in subsequent 
                # subtraction to find the mean difference.
                spwidx = []
                for spw in derivedSpws[asdm]:
                    spwidx.append(yspws.index(spw))
                missingSpws = list(set(yspws) - set(derivedSpws[asdm]))
                print "%d spw(s) missing from the derivedFlux dictionary: %s" % (numMissingSpws, str(missingSpws))
                catalogFreqs = xdata[spwidx]
                catalogData = ydata[spwidx]
            else:
                catalogFreqs = xdata
                catalogData = ydata
            # Determine the mean scale factor by which the derived values differ
            # from the catalog.
            scaleFactor = np.average(catalogData/derivedFlux[asdm], weights=1/derivedUncertainty[asdm]**2)
            # Shift the catalog values by the mean of the differences from derived data
            # to remove any variability since the catalog observation was performed.
            ydataOffset = catalogData / scaleFactor
            i = np.argsort(catalogFreqs)
            scaledCatalogFit = linfit().spectralindex(freqs=catalogFreqs, fluxes=ydataOffset, 
                                                      errors=ydataOffset*0.1, silent=True, 
                                                      showplot=False, xaxis=catalogFreqs[i])
            scaledCatalogFitFlux = np.array(scaledCatalogFit['yaxis'])
            pb.plot(catalogFreqs[i], scaledCatalogFitFlux, '-', lw=2, 
                    mec=catalogColor, mfc=catalogColor, color=catalogColor)
            yLegendOffset = -0.02
            yLegendSpacing = 0.04
            if len(xdata) > 1:
                yLegendOffset += yLegendSpacing
                # Assume 10 percent errors on all catalog measurements
                catalogFit = linfit().spectralindex(freqs=xdata, fluxes=ydata, errors=ydata*0.1, silent=True, showplot=False, xaxis=xdata)
                catalogSpectralIndex = catalogFit['spectralIndex']
                catalogFitFlux = np.array(catalogFit['yaxis'])
                # Sort by frequency, so that dashed lines look dashed instead of going 
                # back and forth overwriting itself.
                i = np.argsort(xdata)
                # Draw the catalog values as points
                pb.plot(xdata[i], ydata[i], 'o', lw=2, mec=catalogColor, 
                        mfc='white', mew=2)
                # Draw the dashed line using the fitted catalog values because it will 
                # be a straight line whereas the values in the aqua report are 
                # truncated at nearest mJy and will be staggered
                pb.plot(xdata[i], catalogFitFlux[i], '--', lw=2, mec=catalogColor, 
                        mfc=catalogColor, color=catalogColor)
                scatter = np.std((ydataOffset-derivedFlux[asdm])/derivedUncertainty[asdm])
                pb.text(0.98,1-yLegendOffset*nrows**0.75,'scale factor to match catalog: %.2f'%(scaleFactor),ha='right',va='top',color='k',
                        transform=desc.transAxes,size=14-ncols*2)
                yLegendOffset += yLegendSpacing
                pb.text(0.98,1-yLegendOffset*nrows**0.75, 'scatter wrt shifted cat.: %.2f$\sigma$ ($\\alpha$: %+.2f)'%(scatter,catalogSpectralIndex),ha='right',va='top',color='b',
                        transform=desc.transAxes,size=14-ncols*2)
                
            if len(derivedFreqs[asdm]) > 1:
                yLegendOffset += yLegendSpacing
                # Use the derived uncertanties
                derivedFit = linfit().spectralindex(freqs=derivedFreqs[asdm], fluxes=derivedFlux[asdm], errors=derivedUncertainty[asdm], silent=True, showplot=False, xaxis=derivedFreqs[asdm])
                derivedSpectralIndex = derivedFit['spectralIndex']
                fitFlux = np.array(derivedFit['yaxis'])
                scatter = np.std((fitFlux-derivedFlux[asdm])/derivedUncertainty[asdm])
                pb.text(0.97,1-yLegendOffset*nrows**0.75, 'scatter w.r.t. fit: %.2f$\sigma$ ($\\alpha$: %+.2f)'%(scatter,derivedSpectralIndex),ha='right',va='top',color='r',
                        transform=desc.transAxes,size=14-ncols*2)
                i = np.argsort(derivedFreqs[asdm])
                pb.plot(derivedFreqs[asdm][i], fitFlux[i], 'r-')

            if fitImages:
                yLegendOffset += yLegendSpacing
                if rmsdiffFromImage[asdm] is not None:
                    pb.text(0.97,1-yLegendOffset*nrows**0.75,'mean+-rms w.r.t. images: %+.1f(%.0f%%)+-%.1f$\sigma$' % (meandiffFromImage[asdm], meanPercentageDiff[asdm], rmsdiffFromImage[asdm]),
                            ha='right',va='top',color=imageFluxColor,
                            transform=desc.transAxes,size=13-ncols*2)
                    f.write('%f %f %f %f\n' % (meanSNRWideWindows[asdm],meandiffFromImage[asdm],meanPercentageDiff[asdm],rmsdiffFromImage[asdm]))
                    f.flush()
            if numberWideWindows[asdm] > 0:
                yLegendOffset += yLegendSpacing
                pb.text(0.97,1-yLegendOffset*nrows**0.75,'mean S/N of %d spws > 300MHz: %.1f' % (numberWideWindows[asdm], meanSNRWideWindows[asdm]),
                        ha='right',va='top',color=derivedColor, transform=desc.transAxes,size=13-ncols*2)
            # Draw the field name on the legend
            yLegendOffset += yLegendSpacing*1.2
            pb.text(0.95,1-yLegendOffset*nrows,derivedField[asdm],ha='right',va='top',transform=desc.transAxes,size=13-nrows)

            spws = np.array(catalogFluxes['spw'])[idx]
            freqs = np.array(catalogFluxes['freq'])[idx]
            # Use the data limits for x-axis and panel limits for y-axis so that
            # we can put the spw label at the bottom of the panel.
            trans = matplotlib.transforms.blended_transform_factory(desc.transData, 
                                                                    desc.transAxes)
            # Make dedicated space for the spw labels at the bottom of the 
            # panel, and the scatter values at the top of the panel.
            ylim = pb.ylim()
            yrange = ylim[1]-ylim[0]
            if scaleFactor > 2:
                pad = 2
            else:
                pad = 1
            ylim = [ylim[0]-0.15*yrange*nrows, ylim[1]+0.15*yrange*nrows*pad]
            pb.ylim(ylim)
            # Make dedicated space on the right an left edge so that error bars
            # are separated from the plot edges.
            xlim = pb.xlim()
            Xrange = xlim[1]-xlim[0]
            pb.xlim([xlim[0]-0.05*Xrange, xlim[1]+0.05*Xrange])
            xlim = pb.xlim()
            Xrange = xlim[1]-xlim[0]
            # Draw the spw labels, avoiding collisions when people overlap spws
            labelLocations = []
            for i,spw in enumerate(spws):
                y0 = 0.03
                for labelLocation in labelLocations:
                    if abs(labelLocation[0]-xdata[i]) < 0.05*Xrange and labelLocation[1] == 0.03:
                        y0 = 0.03*(nrows+1)
                pb.text(xdata[i], y0, str(spw), ha='center', transform=trans, size=13-nrows-ncols)
                labelLocations.append([xdata[i],y0])
            scaleFactors.append(scaleFactor)
        # end 'for' loop over ASDMs
        if plotfile == '':
            project = os.path.join(root,'')
            tokens = root.split('/')
            for i in tokens:
                if i.find('_2017') > 0:
                    project = i
            png = project+'_plotGfluxscale.png'
        else:
            png = plotfile
        pb.draw()
        pb.savefig(png, bbox_inches='tight')
        print "Wrote ", png
        pngs.append(png)
    # end 'for' loop over projects
    print "Processed %d phasecals, %d bandpasscals, %d checksource, and %d other" % (phasecals, bandpasscals, checksource, other)
    if fitImages:
        f.close()
        f2.close()
    if len(pngs) > 1:
        buildPdfFromPngs(pngs,'plotGfluxscale.pdf')
        if fitImages:
            buildPdfFromPngs(pngnames,'plotGfluxscale_imfitplots.pdf')
        plotGfluxscaleHistogram(scaleFactors, nbins=10, plotfile='5.1.0_validation_%s.png'%myintent,
                                size=18,title=os.path.basename(root),
                                majorTickSpacing=0.25)
    return scaleFactors

def plotGfluxscaleSummary(filename='diff_vs_snr.dat', markersize=7, plotfile='diff_vs_snr.png', 
                          xlim=[-50,2000], legendUpperRight=True):
    """
    Plots a textfile produced by plotGfluxscale, like that posted to CAS-10792.
    There are 2 subpanels with axes:
    1) percent difference (Gaussian fit - gfluxscale) vs gfluxscale SNR
    2) percent difference (image box - gfluxscale) vs. gfluxscale SNR
    legendUpperRight: if False, then put it in the lower right
    -Todd hunter
    """
    pb.close('all')
    pb.figure(figsize=(8,14))
    pb.clf()
    desc = pb.subplot(211)
    x,y = getxyFromFile(filename,2,4) # SNR, percentDiffModel
    bw, band = getxyFromFile(filename, 7, 1)
    percentDiffBox, percentRecovered = getxyFromFile(filename, 5, 6)
    ctr, ignore = getxyFromFile(filename, 0, 0)
    colors = ['k','m','b','c','g','orange','r']
    bws = [2.0, 1.875]
    for i in range(5):
        bws += [bws[-1]/2.]
    bws = np.array(bws)
    idx = np.where(percentRecovered > 90)[0]
    #           0   1   2   3   4   5   6   7   8   9  10
    symbols = ['.','.','.','o','s','^','v','+','x','d','*']
    #     0 1 2  3 4 5  6 7 8 9 10
    lw = [1,1,1, 1,1,1, 1,2,2,1,1]
    band8seen = False
    band9seen = False
    band10seen = False
    for i in idx:
        diffs = bws - float(bw[i])
        j = np.argmin(np.abs(diffs))
        if j == 0:
            mec = 'k'
        else:
            mec = colors[j]
        if int(band[i]) == 10:
            band10seen = True
        if int(band[i]) == 9:
            band9seen = True
        if int(band[i]) == 8:
            band8seen = True
        symbol = symbols[int(band[i])]
        if (np.abs(y[i]) > 30):
            print "outlier: img%d at y=%f" % (ctr[i],y[i]) 
        pb.plot(x[i], y[i], symbol, color=colors[j], mec=mec, ms=markersize, mfc=colors[j], mew=lw[int(band[i])])
    ############
    # draw legend
    ############
    for i in range(9+band9seen+band10seen):
        if i > 2:
            if legendUpperRight:
                yleg = 0.97-(i-3)*0.05
            else:
                yleg = 0.03+(i-3)*0.05
            pb.text(0.7, yleg, 'Band %d'%(i), va='center', ha='right', transform=desc.transAxes)
            pb.plot([0.72], [yleg], symbols[i], transform=desc.transAxes, color='k', ms=markersize, mew=lw[i])
    for i in range(len(bws)):
        if i == 0:
            mec = 'k'
        else:
            mec = colors[i]
        if legendUpperRight:
            yleg = 0.97-i*0.05
        else:
            yleg = 0.03+i*0.05
        pb.text(0.94,yleg,'%d MHz'%int(bws[i]*1000), color=mec, 
                transform=desc.transAxes, va='center', ha='right')
#        pb.plot(0.96,yleg,'o',color=colors[i], mec=mec, ms=markersize, mfc=colors[i],
#                transform=desc.transAxes)
    pb.xlabel('gfluxscale SNR')
    pb.ylabel('percent difference (Gaussian fit - gfluxscale)')
    pb.xlim(xlim)
    pb.title('Results from 55 Cycle 5 pipeline benchmark runs (%d/%d spws)' % (len(idx),len(bw)))

    #
    desc = pb.subplot(212)
    y = percentDiffBox
    for i in idx:
        diffs = bws - float(bw[i])
        j = np.argmin(np.abs(diffs))
        if j == 0:
            mec = 'k'
        else:
            mec = colors[j]
        symbol = symbols[int(band[i])]
        pb.plot(x[i],y[i],symbol, color=colors[j], mec=mec, ms=markersize, mfc=colors[j], mew=lw[int(band[i])])
    # draw legend
    for i in range(9+band9seen+band10seen):
        if i > 2:
            if legendUpperRight:
                yleg = 0.97-(i-3)*0.05
            else:
                yleg = 0.03+(i-3)*0.05
            pb.text(0.7, yleg, 'Band %d'%(i), va='center', ha='right', transform=desc.transAxes)
            pb.plot([0.72], [yleg], symbols[i], transform=desc.transAxes, color='k', ms=markersize, mew=lw[i])
    for i in range(len(bws)):
        if i == 0:
            mec = 'k'
        else:
            mec = colors[i]
        if legendUpperRight:
            yleg = 0.97-i*0.05
        else:
            yleg = 0.03+i*0.05
        pb.text(0.94,yleg,'%d MHz'%int(bws[i]*1000), color=mec, 
                transform=desc.transAxes, va='center', ha='right')
#        pb.plot(0.96,yleg,'o',color=colors[i], mec=mec, ms=markersize, mfc=colors[i],
#                transform=desc.transAxes)
    pb.xlabel('gfluxscale SNR')
    pb.ylabel('percent difference (image box - gfluxscale)')
    pb.xlim(xlim)
    pb.title('Results from 55 Cycle 5 pipeline benchmark runs (%d/%d spws)' % (len(idx),len(bw)))
    pb.savefig(plotfile)

def removeWhiteSpace(string):
    """
    Removes all white spaces from a string (space, newline, tab)
    """
    return ''.join(string.split())

def getFluxesFromAquaReport(root, debug=False):
    """
    Finds an AQUA report in the specified root tree and generates two
    dictionaries: derivedFluxes and catalogFluxes. It also uses mymsmd
    to read the scienceSpws, their bandwidths, and timerange of observations.
    root: parent directory of a pipeline run -- anything that contains 
          at least one *aquareport.xml in a subdirectory
    Returns: derivedFluxes dict, catalogFluxes dict, working directory string
    -Todd Hunter, based on picklePipeRun by Remy
    """
    import xml.etree.ElementTree as ET
    aquafile = ''
    workingdir = ''
    print "Searching for AQUA report in this directory tree."
    for dirpath, dnames, fnames in os.walk(root):
        for f in fnames:
            if f.find('aquareport.xml') >= 0:
                # ***** USE FIRST ONE FOUND
                aquafile = os.path.join(dirpath, f)
                workingdir = os.path.dirname(aquafile)
                idx = aquafile.find('aquareport.xml#')
                if idx < 0:
                    # otherwise keep looking for one without trailing hash
                    break
    if len(aquafile) < 1:
        print "**can't find aquareport.xml file in "+root
        return
    print "Using AQUA report: ", aquafile
    e = ET.parse(aquafile).getroot()
    msinfo={}
    derivedfluxes={}
    catalogfluxes={}
    tags=["FluxJy","Field","Asdm","ErrorJy","FrequencyGHz","MsSpwId"]
    # translate to use the same field names as csvfluxes
    # put extra names at the end:
    names=["I","fieldname","ms","dI","freq",  "spw"]
    projectStructure = e.find("ProjectStructure")
    derivedfluxes['project'] = removeWhiteSpace(projectStructure.find("ProposalCode").text) 
    derivedfluxes['mous'] = removeWhiteSpace(projectStructure.find("OusEntityId").text)
    for name in names:
        derivedfluxes[name]=[]
        # initialize the ASDM-dependent dictionaries
        derivedfluxes['date']={}
        derivedfluxes['nAntennas']={}
    catalogtags=["FluxJy","Field","Asdm","MsSpwId","FrequencyGHz"]
    catnames=["I","fieldname","asdm","spw","freq"]
    for name in catnames:
        catalogfluxes[name]=[]
    # protect against old aquafile before "PerTopic":
    if e.find("QaPerTopic") is not None:
        for derflux in e.find("QaPerTopic").find("Calibration").find("FluxMeasurements").findall("FluxMeasurement"):
            for j in range(len(tags)):
                if names[j]=="spw":
                    derivedfluxes["spw"].append(int(derflux.get(tags[j])))
                else:
                    derivedfluxes[names[j]].append(derflux.get(tags[j]))
            # to map freqs to spwIDs we need the MS
            thisasdm = derflux.get("Asdm")
            if thisasdm[-3:] == ".ms": # they call it an asdm but its an ms
                thisasdm = thisasdm[0:-3]
            if not msinfo.has_key(thisasdm):
                mss = []
                for dirpath, dnames, fnames in os.walk(root):
                    for d in dnames:
                        if d.find(thisasdm+'.ms') >= 0 and d[-3:] == '.ms':
                            mss.append(os.path.join(dirpath, d))
                if len(mss) == 0:
                    print "No measurement sets found!"
                    return
                for iss in range(len(mss)):
                    if os.listdir(mss[iss]).count("table.dat"):
                        vis = str(mss[iss])
                        if debug or True:
                            print "opening "+vis
                        mymsmd = createCasaTool(msmdtool)
                        mymsmd.open(vis)
                        spws = getScienceSpws(vis,returnString=False,mymsmd=mymsmd)
                        if debug: print "Got science spws = ", spws
                        bandwidths = {}
                        for spw in spws:
                            bandwidths[spw] = mymsmd.bandwidths(spw) * 1e-9
                        msinfo[thisasdm] = {'ms':vis, 'msmd':mymsmd, 'spws':spws, 
                                            'bandwidths': bandwidths, 'nAntennas': mymsmd.nantennas(),
                                            'date': mjdToUT(mymsmd.timerangeforobs(0)['begin']['m0']['value'])[:-6]}
                        mymsmd.close()
            if msinfo.has_key(thisasdm):
                derivedfluxes["bandwidths"] = msinfo[thisasdm]['bandwidths']
                derivedfluxes["date"][thisasdm] = msinfo[thisasdm]['date']
                derivedfluxes["nAntennas"][thisasdm] = msinfo[thisasdm]['nAntennas']
            if debug:
                print thisasdm,derivedfluxes["fieldname"][-1],derivedfluxes["spw"][-1]
        # Now get the catalog flux densities
        if e.find("QaPerTopic").find("Dataset") is None:
            print "No Dataset section found in AQUA report."
            return
        for derflux in e.find("QaPerTopic").find("Dataset").find("FluxMeasurements").findall("FluxMeasurement"):
            for j in range(len(catalogtags)):
                if catnames[j]=="spw":
                    catalogfluxes["spw"].append(int(derflux.get(catalogtags[j])))
                else:
                    catalogfluxes[catnames[j]].append(derflux.get(catalogtags[j]))
        # close msmdtools when done
        for k in msinfo.keys():
            msinfo[k]['msmd'].done()
    return derivedfluxes, catalogfluxes, workingdir

def plotRefantScore(log='.', plotfile='', bins=None):
    """
    Plots refant score from the specified casa log.
    log: if a directory is specified, then find the first casa log that 
         contains refant scores.
    bins: integer, None=auto (nAntennas/3)
    -Todd Hunter
    """
    if os.path.isdir(log):
        logs = glob.glob('casa*log')
        for f in logs:
            sout,serr = grep(f,' total score')
            if len(sout) > 0:
                log = f
                break
    if os.path.isdir(log): 
        print "No log files found containing refant scores."
        return
    f = open(log,'r')
    lines = f.readlines()
    score = {}
    mydata = []
    maxScore = -1
    for line in lines:
        if line.find(' total score ') > 0:
            loc = line.find('Antenna ')
            if (loc > 0):
                antenna = line[loc:].split()[1]
                score[antenna] = float(line.split()[-1])
                mydata.append(score[antenna])
                if score[antenna] > maxScore:
                    maxScore = score[antenna]
                    bestAntenna = antenna
    pb.clf()
    if len(mydata) < 1:
        return
    nAntennas = len(score)
    if bins is None:
        bins = nAntennas/3
    pb.hist(mydata, bins=bins)
    pb.xlabel('refant total score')
    pb.ylabel('number of antennas (out of %d)' % nAntennas)
    pb.title(os.path.basename(log)+', best antenna = %s'%bestAntenna)
    pb.draw()
    if plotfile != '':
        if plotfile == True:
            plotfile = 'refantScores.png'
        pb.savefig(plotfile)
    return score

def lineSeparation(line1=230.538, line2=220.39868, velocity=0, bw=0.128,
                   bandlimit=211):
    """
    Computes the separation of high-freq edge of the highest-frequency possible
    LSB spw and the low-freq edge of the lowest-frequency possible USB spw.
    Designed to explore setting a new IF range for Band 6 with 13CO,12CO.
    See SCIREQ-1124.
    line1: Hz, GHz or string with units
    line2: Hz, GHz or string with units
    bw: Hz, GHz or string with units
    velocity: in km/s
    bandlimit: lower edge of RF band (e.g. 211 GHz for Band 6)
    """
    line1 = parseFrequencyArgumentToGHz(line1)
    line2 = parseFrequencyArgumentToGHz(line2)
    bw = parseFrequencyArgumentToGHz(bw)
    vc = velocity*1000/c_mks
    z = ((1+vc)/(1-vc))**0.5-1
    line1obs = line1/(1+z)
    line2obs = line2/(1+z)
    centerDiffGHz = abs(line2obs-line1obs)
    edgeDiffGHz = centerDiffGHz - bw
    requiredIFLow = edgeDiffGHz*0.5
    bwvel = c_mks*(bw/float(line1)) * 0.001
    print "BW: %dMHz = %dkm/s (effective width = %f km/s)" % (bw*1000, bwvel, bwvel*1875/2000.)
    print "Center separation = %f GHz (IF = %f GHz)" % (centerDiffGHz,0.5*centerDiffGHz)
    print "Edge separation = %f GHz" % (edgeDiffGHz)
    print "Lowest IF of pre-FDM-stitched spw = %f GHz" % (requiredIFLow)
    print "line1 skyfreq = %f GHz,  line2 skyfreq = %f GHz" % (line1obs,line2obs)
    if bandlimit is not None:
        if line1obs < bandlimit or line2obs < bandlimit:
            print "WARNING: One or both lines fall outside the RF band!!!"
        if line1obs < bandlimit+bw*0.5 or line2obs < bandlimit+bw*0.5:
            cutoff = np.max([bandlimit+bw*0.5-line1obs,bandlimit+bw*0.5-line2obs])
            print "WARNING: The RF band edge cuts off the line coverage by %f MHz" % (cutoff)
    return requiredIFLow

#-----------------------------------------------------------------------
#-----------------------------------------------------------------------
def picklePipeRun(root,outfile=None,debug=False,use_astropy=False):
    """
    Save information about a pipeline run.  
    Parts of this use the pipeline context object, so the directory should 
      not have been changed since running the pipeline, and also the same
      version of the pipeline heuristics needs to be used again. 
      These requirements are relaxed if you don't need the extra information
      from the pipeine context (see list below)

    comparePipeRuns can be used to subsequently compare two pickled runs.

    Information saved and compared includes:
       derived flux densities of secondary calibrators (from aqua report, 
         also uses actual ms for meta-information)
       input flux densities of QSO amp cals (from flux.csv)
       calibrator imaging QA scores (from context)
       statistics on all images created (from the directory)

    Input root is the directory e.g. 
      /lustre/user/pipeline/root/2015.1.00123.S_2017_06_13T17_22_22.547
    Default output is the end of the pipeline root directory, plus '.pkl' e.g. 
      /lustre/user/pipeline/root/2015.1.00123.S_2017_06_13T17_22_22.547.pkl
    the output pickle file can be specified with outfile=
    -- Remy Indebetouw
    """
    
    import numpy as np
    import subprocess
    from glob import glob
    
    # astropy doesn't work well in casa:
    have_astropy=False
    if use_astropy:
        try:
            from astropy.table import Table
        except:
            have_astropy=False
        else:
            have_astropy=True
    
    # primarily for debugging, to turn off creation of certain reports
    # in general all these should be left True
    dofluxscale=True
    docalqa=True
    doimstats=True

    #=======================================================================
    # metadata
    metadata={"root":root}
    # PL version added below

    
    #=======================================================================
    # read flux.csv 
    findCMD = 'find -L '+root+' -name "*flux.csv"'
    out = subprocess.Popen(findCMD,shell=True,stdin=subprocess.PIPE, 
                           stdout=subprocess.PIPE,stderr=subprocess.PIPE)
    (stdout, stderr) = out.communicate()
    csvfiles = stdout.decode().split()
    if len(csvfiles)<1:
        print "**can't find flux.csv file in "+root
        fluxfile=""
        csvfluxes={}
    else:
        # **** USE FIRST CSV FILE
        # TODO should we have a preference for working/ or products/ ?
        fluxfile=csvfiles[0]
        print "csv="+fluxfile        
        if have_astropy:
            csvfluxes=Table.read(fluxfile,format="ascii")
            csvfluxes.rename_column("field","fieldid")
        else:
            # check for old-format with spix not in yet
            firstline=open(fluxfile,"ra").readline()
            if len(firstline.split(","))<9:
                csvfluxes=np.loadtxt(fluxfile,delimiter=",",dtype={'names':('ms','fieldid','spw','I','Q','U','V','comment'),'formats':('S30','i1','i2','f','f','f','f','S50')},skiprows=1,usecols=range(8))
            else:
                csvfluxes=np.loadtxt(fluxfile,delimiter=",",dtype={'names':('ms','fieldid','spw','I','Q','U','V','spix','comment'),'formats':('S30','i1','i2','f','f','f','f','f','S100')},skiprows=1,usecols=range(9))
    
        nrow=len(csvfluxes)
        # create a column in the table indicating quickly if its an ampcal
        if have_astropy:
            newcol=csvfluxes.Column(np.zeros(nrow,dtype=bool),name="isampcal")
            newcol2=csvfluxes.Column(np.zeros(nrow,dtype=bool),name="fieldname")
        else:
            newcol=np.zeros(nrow,dtype=bool)
            newcol2=np.zeros(nrow,dtype=bool)
        for irow in range(nrow):
            if csvfluxes['comment'][irow].count("AMP"):
                newcol[irow]=True
            newcol2[irow]=csvfluxes['comment'][irow].split()[0]
        if have_astropy:
            csvfluxes.add_column(newcol)
            csvfluxes.add_column(newcol2)
        else:
            from numpy.lib import recfunctions
            csvfluxes=recfunctions.append_fields(csvfluxes,"isampcal",newcol)
            csvfluxes=recfunctions.append_fields(csvfluxes,"fieldname",newcol2)
    
    
    
    #=======================================================================
    # read AQUA report
     
    findCMD = 'find -L '+root+' -name "*aquareport.xml"'
    out = subprocess.Popen(findCMD,shell=True,stdin=subprocess.PIPE, 
                           stdout=subprocess.PIPE,stderr=subprocess.PIPE)
    (stdout, stderr) = out.communicate()
    aquafiles = stdout.decode().split()
    if len(aquafiles)<1:
        print "**can't find aquareport.xml file in "+root
        aquafile=""
        derivedfluxes={}
    else:
        aquafile=aquafiles[0]
        print "aqua="+aquafile
        msinfo={} # [location,msmdtool,scispws]
        
        import xml.etree.ElementTree as ET
        # ***** USE FIRST ONE
        e=ET.parse(aquafile).getroot()
        
        # ====== versions and structure ==========
        for ee in e.find("ProjectStructure"):
            metadata[ee.tag]=ee.text
        metadata["casaversion"]=e.find("QaSummary").find("CasaVersion").text.split()[0]
        metadata["pipeversion"]=e.find("QaSummary").find("PipelineVersion").text.split()[0]

        # ====== derived flux densities ==========
        if dofluxscale:
            derivedfluxes={}
            tags=["FluxJy","Field","Asdm","ErrorJy","FrequencyGHz"]
            # translate to use the same field names as csvfluxes
            # put extra names at the end:
            names=["I","fieldname","ms","dI","freq",  "spw"]
            for name in names:
                derivedfluxes[name]=[]
            # protect against old aquafile before "PerTopic":
            if e.find("QaPerTopic") is not None:
                for derflux in e.find("QaPerTopic").find("Calibration").find("FluxMeasurements").findall("FluxMeasurement"):
                    for j in range(len(tags)):
                        if names[j]=="spw":
                            derivedfluxes["spw"].append(int(derflux.get(tags[j])))
                        else:
                            derivedfluxes[names[j]].append(derflux.get(tags[j]))
        
                    # to map freqs to spwIDs we need the MS
                    thisasdm=derflux.get("Asdm")
                    if thisasdm[-3:]==".ms": # they call it an asdm but its an ms
                        thisasdm=thisasdm[0:-3]
                    if not msinfo.has_key(thisasdm):
                        findCMD = 'find -L '+root+' -name "'+thisasdm+'.ms"'
                        out = subprocess.Popen(findCMD,shell=True,
                                               stdin=subprocess.PIPE, 
                                               stdout=subprocess.PIPE,
                                               stderr=subprocess.PIPE)
                        (stdout, stderr) = out.communicate()
                        mss = stdout.decode().split()
                        for iss in range(len(mss)):
                            # *** USE LAST INSTANCE
                            if os.listdir(mss[iss]).count("table.dat"):
                                vis=str(mss[iss])
                                if debug:
                                    print "opening "+vis
                                spws=getScienceSpws(vis,returnString=False)
                                print "Got science spws = ", spws
                                mymsmd = createCasaTool(msmdtool)
                                mymsmd.open(vis)
                                msinfo[thisasdm]={'ms':vis,'msmd':mymsmd,'spws':spws}
        
                    if msinfo.has_key(thisasdm):
                        spws2 = []
                        delta = []
                        frequency=1e9*float(derflux.get("FrequencyGHz"))
                        for spw in msinfo[thisasdm]['spws']:
                            freqs = msinfo[thisasdm]['msmd'].chanfreqs(spw)
                            if (np.min(freqs) <= frequency and np.max(freqs) >= frequency):
                                spws2.append(spw)
                                delta.append(abs(frequency-mymsmd.meanfreq(spw)))
                        derivedfluxes["spw"].append(spws2[np.argmin(delta)])
                    else: 
                        print "can't find asdm "+thisasdm
                        derivedfluxes["spw"].append(-1)
                    if debug:
                        print thisasdm,derivedfluxes["fieldname"][-1],derivedfluxes["spw"][-1]
        
                # close tools when done
                for k in msinfo.keys():
                    msinfo[k]['msmd'].done()
        else:
            derivedfluxes="not requested"





    # ====== imaging cal qa scores ==================================
    # get these put into the aqua report - for now, need to use context?
    if docalqa:
        findCMD = 'find -L '+root+' -name "*context"'
        out = subprocess.Popen(findCMD,shell=True,stdin=subprocess.PIPE, 
                               stdout=subprocess.PIPE,stderr=subprocess.PIPE)
        (stdout, stderr) = out.communicate()
        contextfiles = stdout.decode().split()
        if len(contextfiles)<1:
            print "**can't find pipeline context in "+root
            contextfile=""
            calqa={}
            havecontext=False
        else:
            contextfiles.sort()
            contextfile=contextfiles[1] # was [-1] but if someone ran iPL manually...
            if debug:
                print "context ",contextfile
            #c=h_resume(contextfile)
            import pickle
            try:
                c=pickle.load(open(contextfile,"rb"))
                blurg=c.results[0].read() # this requires dir to be the same
                havecontext=True
            except:
                print "Can't load context file - PL not imported or working dir has been moved"
                havecontext=False
                calqa="not found"
        if havecontext:
            n=c.task_counter
            i=-1
            name=""
            # ASSUME FIRST MAKEIMAGES = CAL IMAGES            
            while (name.count("hif_makeimages")<=0 and i<n):
                i=i+1
                name=c.results[i].read().pipeline_casa_task
            if i<n:                
                x=c.results[i].read()
                ct=x.inputs['target_list']
                cq=x.qa.pool
                nt=len(ct)
                keys=["field","intent","spw"]
                names=["fieldname","intent","spw", "score"]
                calqa={}
                for k in names:
                    calqa[k]=[]
                for it in range(nt):
                    for ik in range(len(keys)):
                        if names[ik]=="spw":
                            calqa["spw"].append(int(ct[it]["spw"]))
                        else:
                            calqa[names[ik]].append(ct[it][keys[ik]])
                    # now get the scores
                    if len(cq)==nt: # old version just had the single score
                        calqa["score"].append(cq[it].score)
                    else:
                        calqa["score"].append(cq[0].score)
            else:
                calqa="not found"
                print "error: cal imaging not found in context "+contextfile
    else:
        calqa="not requested"



    # ====== imaging stats ==================================
    # again, maybe put in aqua report b/c can use mask, but for now

    if doimstats:

        # prefer, in order:  _.image, _.image.pbcor, _.pbcor.fits
        
        suffixes=["image","image.pbcor","pbcor.fits"]
        #suffixes=["pbcor.fits"]
        imstats={}
        
        # stats that have one scalar value:
        ksingle=['flux','max','mean','medabsdevmed','median','min','q1','q3','quartile','rms','sigma','sumsq']
        # stats that are a position, so 4 values
        kpos=['maxposf','minposf']
        
        
        for isuffix in range(len(suffixes)):
            findCMD = 'find -L '+root+' -name "*.'+suffixes[isuffix]+'"'
            out = subprocess.Popen(findCMD,shell=True,stdin=subprocess.PIPE, 
                                   stdout=subprocess.PIPE,stderr=subprocess.PIPE)
            (stdout, stderr) = out.communicate()
            files=stdout.decode().split()
            if debug:
                print len(files)," *."+suffixes[isuffix]+" in ",root
        
            for ifile in range(len(files)):

                # Skip concatenated (sub)images
                def is_concat_image(img_filename, suffix_searched):
                    concat_img_re = '.n[0-9]+.' + suffix_searched
                    concat_match = re.search(concat_img_re, img_filename)
                    return concat_match

                if is_concat_image(files[ifile], suffixes[isuffix]):
                    print 'Note: skipping concatenated image {0}'.format(files[ifile])
                    continue

                # used to have pbcor.image - now have image.pbcor
                # decompose into ous, tgt_intent, spw, type, (stokes, iter1)
                # discard stage# because could change with recipe
                imroot= files[ifile].split("/")[-1].split(suffixes[isuffix])[0][:-1]
                if not ((suffixes[isuffix]=="image" and imroot.count("pbcor"))
                        or imroot.count("manual")):
                    if debug:
                        print "   - "+imroot
                    
                    xx = imroot.split(".")
                    im_ous = xx[0]
                    xx=xx[1:]
                    if suffixes[isuffix].count("fits")==0: # image have stage number in name, unless soeone manually fscked around.
                        im_stage=xx[0]
                        xx=xx[1:]
                    rest=".".join(xx)
                    # source name can have . in it so be careful:
                    xx=rest.split(".spw")
                    im_tgt=xx[0]
                    xx=xx[1].split(".")
                    im_spw,im_type,im_stokes=xx[0:3]
                    im_spw="spw"+im_spw
                    xx=xx[3:]
                    if suffixes[isuffix].count("fits")==0: # have iter
                        im_iter=xx[0]
                        xx=xx[1:]
                    else:
                        im_iter=""
                    # if xx is not none at this point, it should be tt0/tt1
                    decomposed=True
                    if len(xx)>0:
                        if xx[0][0:2]=="tt":
                            im_type=im_type+"_"+xx[0]
                        else:
                            print "ERROR decomposing imroot ",imroot
                            decomposed=False
#                            print "      ",im_tgt,im_spw,im_type,im_iter
#                            import pdb
#                            pdb.set_trace()
                    
                    if decomposed:
                        if debug:
                            print"     ","|".join([im_ous, im_tgt, im_spw, im_type, im_stokes, im_iter])
                        iminfo=str(".".join([im_ous,im_tgt,im_spw,im_type]))
                        if imstats.has_key(iminfo)==False:
                            imstats[iminfo]={}
                
                        # nomask, then mask
                        itype=suffixes[isuffix]+"_nomask"
                        if not imstats[iminfo].has_key(itype):
                            imstats[iminfo][itype]={}
                            if debug:
                                print "new ",iminfo,itype
                        s1=imstat(str(files[ifile]),verbose=False,listit=False)
                        for k in ksingle:
                            imstats[iminfo][itype][k]=s1[k][0]
                        for k in kpos: # don't parse string yet
                            imstats[iminfo][itype][k]=s1[k]
                
                
                        # then mask - have to find the mask
                        itype=suffixes[isuffix]+"_mask"
                
                        # export to fits switches axis order so for a fits 
                        # image we need a fits mask, but we don't export 
                        # that at this time, so only look for images:
                        if suffixes[isuffix].count("fits")==0:
                            findCMD = 'find -L '+root+' -name "'+(".".join([im_ous,"*",im_tgt,im_spw,im_type,im_stokes,im_iter]))+'.mask"'
                            out = subprocess.Popen(findCMD,shell=True,
                                                   stdin=subprocess.PIPE, 
                                                   stdout=subprocess.PIPE,
                                                   stderr=subprocess.PIPE)
                            (stdout, stderr) = out.communicate()
                            masks=stdout.decode().split()
                            if debug:
                                print "   >masks=",masks
                            if len(masks)>0:
                                if not imstats[iminfo].has_key(itype):
                                    imstats[iminfo][itype]={}
                                    if debug:
                                        print "    ",itype
                                s1=imstat(str(files[ifile]),verbose=False,listit=False,mask="'"+str(masks[0])+"'")
                                if len(s1['max'])==0: # blank mask or other err
                                    for k in ksingle:
                                        imstats[iminfo][itype][k]=0
                                    for k in kpos: 
                                        imstats[iminfo][itype][k]=""
                                else:
                                    for k in ksingle:
                                        imstats[iminfo][itype][k]=s1[k][0]
                                    for k in kpos: # don't parse string yet
                                        imstats[iminfo][itype][k]=s1[k]
                

    #========================================================
    import pickle
    # output 
    if outfile:
        outname=outfile
    else:
        # strip trailing / from root
        if root[-1]=="/":
            outname=root[0:-1]+".pkl"
        else:
            outname=root+".pkl"
    
    outstruc={"fluxfile":fluxfile,"csvfluxes":csvfluxes,"aquafile":aquafile,
              "metadata":metadata}
    if dofluxscale:
        outstruc["derivedfluxes"]=derivedfluxes
    if docalqa:
        outstruc["calqa"]=calqa
    if doimstats:
        outstruc["kpos"]=kpos
        outstruc["ksingle"]=ksingle
        outstruc["suffixes"]=suffixes
        outstruc["imstats"]=imstats
        
    pickle.dump(outstruc,open(outname,'wb'))

def compareHeaders(mydict0, mydict1):
    """
    Compares two dictionaries, such as returned by imhead(mode='list')
    -Todd Hunter
    """
    keys = np.unique(mydict1.keys()+mydict0.keys())
    for key in keys:
        if key not in mydict0:
            print "%s not in mydict0" % (key)
        elif key not in mydict1:
            print "%s not in mydict1" % (key)
        else:
            if type(mydict0[key]) == np.ndarray:
                test = (mydict0[key] != mydict1[key]).any()
            else:
                test = mydict0[key] != mydict1[key]
            if test:
                print "%s is %s in mydict0" % (key, mydict0[key])
                print "%s is %s in mydict1" % (' '*len(key), mydict1[key])

def comparePipeRuns(pkls, threshold=0.1, sigthreshold=1., debug=False):
    """
    Compare information about pipeline runs pickled with picklePipeRun

    Information saved and compared includes:
       derived flux densities of secondary calibrators (from aqua report, 
         also uses actual ms for meta-information)
       input flux densities of QSO amp cals (from flux.csv)
       calibrator imaging QA scores (from context)
       statistics on all images created (from the directory)
    Input is an array of two outputs from picklePipeRun e.g. 
       ["run1.pkl","run2.pkl"]
    threshold is the relative change in compared quantities required to 
       print information to the screen.  Changes smaller than threshold
       will be silently not reported to you.
    sigthreshold is the relative change to report, in sigma units. 
       this is only used for image statistics, and if sigthreshold>0, 
       will override "threshold"

    -- Remy Indebetouw
    """

    import numpy as np
    # load pickles
    import pickle
    data=[]
    for i in range(len(pkls)):
        data.append(pickle.load(open(pkls[i],'rb')))
    
    # line up the datasets in case the order changed, also add the input fluxes
    matchdata=[]
    
    # first dataset = reference
    t0=data[0]['derivedfluxes'].copy()

    for idata in range(len(data)):  # written generally but for now just 2 runs
        ti=data[idata]['derivedfluxes']

        # if something failed, then don't proceed:
        if len(t0['I'])>0 and len(ti['I'])>0:

            tiout={}
            for k in t0.keys():
                tiout[k]=[]
            tiout['ampcalname']=[]
            tiout['ampcalflux']=[]
   
            nrow=len(ti['I'])
            # keep track in case any new derived fluxes show up rel to first dataset
            tifound=np.zeros(nrow,dtype="bool")
       
            isampcal=data[idata]['csvfluxes']['isampcal'].data
            for i in range(nrow):
                if idata==0:
                    for k in t0.keys():
                        tiout[k].append(t0[k][i])
                else:
                    # find match for each row of first derived fluxes list
                    z=np.where( np.array([t0['ms'][i]==y for y in ti['ms']])*
                                np.array([t0['fieldname'][i]==y for y in ti['fieldname']])*
                                (t0['spw'][i]==ti['spw']) )[0]
                    if len(z)>0:
                        if len(z)>1:
                            print "warning: multiple matches for ",t1['ms'][i],ti['fieldame'][i],ti['spw'][i]
                        tifound[z[0]]=True
                        for k in t0.keys():
                            tiout[k].append(ti[k][z[0]])
                    else:
                        for k in t0.keys():
                            tiout[k].append(-1)
   
                # find a corresponding ampcal flux 
                fz=np.where( (isampcal)*
                             np.array([(tiout['ms'][i]+".ms")==y for y in data[idata]['csvfluxes']['ms']])*
                             (tiout['spw'][i]== data[idata]['csvfluxes']['spw']) )[0]
                if len(fz)>0:
                    tiout['ampcalname'].append(data[idata]['csvfluxes']['comment'][fz[0]].split()[0].strip('"').strip("'"))

                    tiout['ampcalflux'].append(data[idata]['csvfluxes']['I'][fz[0]])
                else:
                    tiout['ampcalname'].append('none')
                    tiout['ampcalflux'].append(-1)
       
            if debug:
                print tiout
                import pdb
                pdb.set_trace()
            matchdata.append(tiout)

   
        

    #=================================================================
    # now list if anything changed in the derived fluxes:
    if len(matchdata)>1:
        print "-"*60
        print "percent changes in derived flux densities:"
        print "  (second line is the % change in setjy flux density)"
        print "  if a flux density can't be found, X is printed"
        
        if len(pkls)>2:
            print "haven't written the comparator output formatter for >2 dirs yet!"
        
        mss =np.unique(matchdata[0]['ms'])
        spws=np.unique(matchdata[0]['spw'])
        fieldnames=np.unique([y.split()[0] for y in matchdata[0]['fieldname']])
        maxlen=-1
        for fname in fieldnames:
            if len(fname)>maxlen:
                maxlen=len(fname)
        
        nspw=len(spws)
        outstr=("%-"+str(maxlen)+"s ")%"fld"
        for ispw in range(nspw): outstr=outstr+"   %2i "%spws[ispw]
        print outstr
        
        for ims in range(len(mss)):
            print "  "+mss[ims]+":"
            for ifield in range(len(fieldnames)):    
                outstr1=("%-"+str(maxlen)+"s ")%fieldnames[ifield]
#                outstr2=" "*(maxlen+1) # for the setjy difference if required
                outstr2=""
                anynonzero=False
                for ispw in range(nspw):
                    z=np.where( (matchdata[0]['spw']==spws[ispw])*
                                np.array([fieldnames[ifield] in y for y in matchdata[0]['fieldname']])*
                                np.array([mss[ims]==y for y in matchdata[0]['ms']]) )[0]
                    gooddiff=True
                    if len(outstr2)<1:
                        outstr2=("-%-"+str(maxlen)+"s")%matchdata[0]['ampcalname'][z[0]]

                    if len(z)==0:
                        outstr1=outstr1+"    X "
                        outstr2=outstr2+"    X "
                    elif len(z)>1:
                        print "logic error, spw=%i, fieldname=%s"%(spws[ispw],fieldnames[ifield])
                        stop
        
                    else:
                        f0=float(matchdata[0]['I'][z[0]])
                        f1=float(matchdata[1]['I'][z[0]])
                        if f0>0 and f1>0:
                            reldeltaderived=np.absolute((f1-f0)*2./(f0+f1))
                        else:
                            reldeltaderived=np.nan
                        f0=float(matchdata[0]['ampcalflux'][z[0]])
                        f1=float(matchdata[1]['ampcalflux'][z[0]])
                        if f0>0 and f1>0:
                            reldeltaset=np.absolute((f1-f0)*2./(f0+f1))
                        else:
                            reldeltaset=np.nan
    
                        
                        if np.isnan(reldeltaderived):
                            outstr1=outstr1+"    X "
                        elif np.absolute(reldeltaderived)>threshold:
                            outstr1=outstr1+ (" %+5.1f"%(reldeltaderived*100))
                            anynonzero=True                        
                        else:
                            outstr1=outstr1+"    0 "
    
                        if np.isnan(reldeltaset):
                            outstr2=outstr2+"    ? "
                        elif np.absolute(reldeltaset)>1e-3:
                            outstr2=outstr2+ (" %+5.1f"%(reldeltaset*100))
                        else:
                            outstr2=outstr2+"    0 "
                print outstr1
#                if anynonzero:
                print outstr2
    
    #====================================================================
    # CALQA
    

    if type(data[0]['calqa'])==type({}) and  \
       type(data[1]['calqa'])==type({}):


        # now list if anything changed in the calqa score:
        print 
        print "-"*60
        print "change in cal qa score:"
        print "  (nothing printed if it is 1.0 before and after)"
        print "  ('X' printed if there is no score in the 2nd run)"
        
        spws=np.unique(data[0]['calqa']['spw'])
        fieldnames=np.unique([y.split()[0] for y in data[0]['calqa']['fieldname']])
        maxlen=-1
        for fname in fieldnames:
            if len(fname)>maxlen:
                maxlen=len(fname)
        nspw=len(spws)
        outstr=("%-"+str(maxlen)+"s ")%"fld"
        for ispw in range(nspw): outstr=outstr+"    %2i     "%spws[ispw]
        print outstr
        
        for ifield in range(len(fieldnames)):    
            outstr1=("%"+str(maxlen)+"s ")%fieldnames[ifield]
            for ispw in range(nspw):
                z0=np.where( (data[0]['calqa']['spw']==spws[ispw])*
                            np.array([fieldnames[ifield] in y for y in data[0]['calqa']['fieldname']]) )[0]
                if len(z0)!=1:
                    print "calqa logic error, spw=%i, fieldname=%s"%(spws[ispw],fieldnames[ifield])
                    stop        
                score0=data[0]['calqa']['score'][z0[0]]
    
                z1=np.where( (data[1]['calqa']['spw']==spws[ispw])*
                             np.array([fieldnames[ifield] in y for y in data[1]['calqa']['fieldname']]) )[0]
                if len(z1)>0:
                    score1=data[1]['calqa']['score'][z1[0]]
                else:
                    # not found in second run.
                    score1=-1
                if score0>0.98 and score1>0.98:
                    outstr1=outstr1+(" "*10)
                elif score1>=0:
                    outstr1=outstr1+ ("% 4.2f>%4.2f"%(score0,score1))
                else:
                    outstr1=outstr1+ ("% 4.2f>  X "%(score0))
            print outstr1


    #========================================================================

    # compare images
    print 
    print "-"*60
    print "change in image stats:"
    if sigthreshold>0:
        print "  (nothing printed if all within %f sigma)"%sigthreshold
        threshold=0
    else:
        print "  (nothing printed if all within %f)"%threshold
            
    suffixes=data[0]['suffixes']
    # can override here: 
    suffixes=["image"]

    ksingle=data[0]['ksingle']
    kpos=data[0]['kpos']
    # again, override possible:
    ksingle=["flux","min","max","rms"]
    kpos=[]

    maxlen=0
    for iminfo in data[0]['imstats'].keys():
        if len(iminfo)>maxlen: 
            maxlen=len(iminfo)
    maxlensuff=0
    for suff in suffixes:
        if len(suff)>maxlensuff: 
            maxlensuff=len(suff)
    
    for iminfo in data[0]['imstats'].keys():
        if data[1]['imstats'].has_key(iminfo):
            print 
            for isuffix in range(len(suffixes)):
                # prefer masked to not-masked:
                for tt in ["_mask","_nomask"]:
                    itype=suffixes[isuffix]+tt
                    if data[0]['imstats'][iminfo].has_key(itype) and data[1]['imstats'][iminfo].has_key(itype):
                        any_nonzero=False
                        for k in ksingle:
                            s0=data[0]['imstats'][iminfo][itype][k]
                            s1=data[1]['imstats'][iminfo][itype][k]
                            if s0 != s1:
                                dd=(s1-s0)*2./(s0+s1)
                                if np.absolute(dd)>threshold:
                                    any_nonzero=True

                        if any_nonzero or debug: 
                            print ("%"+str(maxlen)+"s: %"+str(maxlensuff+7)+"s: ")%(iminfo,itype)
                            rms0=data[0]['imstats'][iminfo][itype]['rms']
                            rms1=data[1]['imstats'][iminfo][itype]['rms']
                            rms=np.minimum(rms0,rms1)
                            
                            for k in ksingle:
                                s0=data[0]['imstats'][iminfo][itype][k]
                                s1=data[1]['imstats'][iminfo][itype][k]
                                if s0 != s1:
                                    drms=(s1-s0)/rms
                                    dd=(s1-s0)*2./(s0+s1)
                                    if sigthreshold>0:
                                        if np.absolute(drms)>sigthreshold:
                                            print "   "+k+": "+str(s0)+" > "+str(s1)+" ("+str(dd)+", "+("%6.1f sigma)"%drms)
                                    else:
                                        if np.absolute(dd)>threshold:
                                            print "   "+k+": "+str(s0)+" > "+str(s1)+" ("+str(dd)+", "+("%6.1f sigma)"%drms)
                            for k in kpos:
                                s0=data[0]['imstats'][iminfo][itype][k]
                                s1=data[1]['imstats'][iminfo][itype][k]
                                # TODO POSITION DIFF
#                                print "   "+k+": "+str(s0)+" > "+str(s1)

#===========

def genImageName(vis='', spw='', field='', imtype='mfs', targettype='sci', stokes='I', mous='', modtext='manual', spwmap=[]):
    # DPetry, Sept 2017, Apr 2018

    """
    Generate image name to be used in clean command
    following the ALMA archive conventions (see SCIREQ-110, draft recommendations v4.8).
      vis         = MS to be imaged (to extract object name, SPW frequencies
      spw         = ID of SPW to be imaged
                    If several SPWs are imaged at once, enter list of SPWs.
      field       = ID of field to be imaged (to extract object name).
                    in case of mosaic, give any ID of field belonging to the mosaic
      imtype      = image type, 'mfs' (default) - aggregate bandwidth
                    'cont' - mfs with lines excluded
                    'cube' - spectrally resolved cube
      targettype  = 'sci' (default) for science target
                    'bp' for bandpass calibrator
                    'ph' for phase calibrator
                    'chk' for checksource
                    'amp' for flux calibrator
                    'polleak' for polarisation calibrator
      stokes      = 'I' (default) for Stokes I image
                    any combination of 'I', 'Q', 'U', 'V', 'P', 'A'
      mous        = '' (default) normally this is filled by the archive.
                    But if you know the MOUS UID, enter it in the format with "_"
                    e.g.  uid___A001_X888_X66
      modtext     = 'manual' (default) - this string can be used to add text,
                    i.e. a modification, to the standard file name.
                    It is appended at the end of the name.
                    It should not contain the characters "_" and "." .
      spwmap      = SPW IDs to be used in the final image name.
                    If a non-empty list is specified, it must contain at least as many 
                    elements as the parameter "spw" above. The given SPW IDs are then
                    used to replace the ones given in parameter "spw",
                    e.g. spw=[0,1,2,3], spwmap=[19,21,23,25] will result in ID 19
                    being used instead of 0 in the output name, 21 instead of 1 etc.
                    default: [] (empty list) - use the SPW IDs as they are in the MS.
    - Dirk Petry
    """

    themous = ''
    theobject = ''
    thetargettype = ''
    targettypes = ['sci', 'bp', 'ph', 'chk', 'amp', 'polleak']
    thespwid = ''
    theimtype = ''
    imtypes = ['mfs', 'cont', 'cube']
    thestokes = ''
    stokess = ['I', 'Q', 'U', 'V', 'IQU', 'IQUV', 'P', 'A']
    themodtext = ''
    thespwmap = []

    rval = ''

    mymsmd = createCasaTool(msmdtool)

    # MOUS
    if (mous != ''):
        themous = mous+'.'

    # object
    try:
        mymsmd.open(vis)
    except:
        mymsmd.done()
        raise Exception("ERROR: problem opening vis")

    myfieldnames = mymsmd.fieldnames()
    if type(field)==str and (field in myfieldnames):
        theobject = field
    elif field in range(mymsmd.nfields()):
        theobject = myfieldnames[field]
    else:
        print "ERROR: invalid field: "+field
        print "Valid entries are ", myfieldnames
        print " or ", range(mymsmd.nfields())
        raise Exception("ERROR: invalid field: "+field)
    myspws = mymsmd.spwsforfield(theobject)
    mymsmd.close()

    # target type
    if targettype in targettypes:
        thetargettype = targettype
    else:
        print "ERROR: invalid targettype ", targettype
        print "  Valid entries are ", targettypes
        raise  Exception("ERROR: invalid targettype ", targettype)

    # spw
    if type(spw) != type([]):
        spw = [spw]
    for myspw in spw:
        if myspw in myspws:
            if thespwid=='':
                thespwid = str(myspw)
            else:
                thespwid = thespwid+'_'+str(myspw)                
        else:
            if not (type(myspw) == int or type(myspw) == np.int32):
                print "ERROR: invalid spw: "+str(myspw)+". Valid entries are ", myspws
                raise Exception("ERROR: invalid spw: "+str(myspw)+' Data type must be int.')
            else:
                print "ERROR: invalid spw: "+str(myspw)+". Valid entries are ", myspws
                raise Exception("ERROR: invalid spw: "+str(myspw))

    # spwmap
    if type(spwmap) != type([]):
        raise Exception("ERROR: invalid spwmap, must be list: "+str(spwmap))
    if spwmap == []:
        thespwmap = spw
    else:
        thespwmap = spwmap
        if len(spwmap)<len(spw):
            raise Exception("ERROR: invalid spwmap, list must be at least as long as that in parameter spw.")
        # use spwmap to generate spwid string
        thespwid = ''
        for myspw in spw:
            mappedid = thespwmap[spw.index(myspw)]
            if type(mappedid) == int or type(mappedid) == np.int32: 
                if thespwid=='':
                    thespwid = str(mappedid)
                else:
                    thespwid = thespwid+'_'+str(mappedid)                
            else:
                raise Exception("ERROR: invalid spwmap. Must only contain integers:"+str(spwmap))
                
    # imtype
    if imtype in imtypes:
        theimtype = imtype
    else:
        print "ERROR: invalid imtype ", imtype
        print "  Valid entries are ", imtypes
        raise Exception( "ERROR: invalid imtype "+str(imtype))

    # stokes
    if stokes in stokess:
        thestokes = stokes
    else:
        print "ERROR: invalid stokes ", stokes
        print "  Valid entries are ", stokess
        raise Exception("ERROR: invalid stokes "+str(stokes))

    # modifying text

    if modtext != '':
        themodtext = '.'+modtext
        if ' ' in modtext:
            raise Exception("ERROR: modtext must not contain spaces")
        if '_' in modtext:
            raise Exception("ERROR: modtext must not contain underscores. Use hyphen instead.")
        if '.' in modtext:
            raise Exception("ERROR: modtext must not contain dots. Use hyphen instead.")

    rval = themous+theobject+'_'+thetargettype+'.spw'+thespwid+'.'+theimtype+'.'+thestokes+themodtext

    if ' ' in rval:
        raise Exception("ERROR: generated name contains spaces: \""+rval+"\"")
    if '/' in rval:
        raise Exception("ERROR: generated name contains slash: \""+rval+"\"")
    if '*' in rval:
        raise Exception("ERROR: generated name contains star: \""+rval+"\"")
    if '?' in rval:
        raise Exception("ERROR: generated name contains question mark: \""+rval+"\"") 

    return rval


#-----------------------------------------------------------------------
#-----------------------------------------------------------------------
